<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="Blither Boom"><meta name="copyright" content="Blither Boom"><meta name="generator" content="Hexo 6.2.0"><meta name="theme" content="hexo-theme-yun"><title>Êï∞Â≠óÁ≥ªÁªüËÆæËÆ° | Guo_Yun</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...true?.options,
  });
});</script><link rel="icon" type="image/svg+xml" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"blitherboom812.github.io","root":"/","title":["Êë∏","üêü","‰∫∫","ÁöÑ","Êó•","Â∏∏"],"version":"1.10.11","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}.","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","fireworks":{"colors":null},"vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/hexo-theme-yun.js" type="module"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap"><meta name="description" content="Áª™ËÆ∫ËΩØÁ°¨‰ª∂ÂçèÂêåÔºåÂà∂‰ΩúÊ∑±Â∫¶Â≠¶‰π†Á°¨‰ª∂ ÁêÜËÆ∫ËØæÔºåËÆ≤Â∫ßÔºåLab ‰∏ìÁî®ÁîµË∑Ø ÁõÆÊ†áÔºöÂÅö‰∏Ä‰∏™Á±ª‰ºº‰∫éGoogle TPU‰∏≠ÁöÑÊüêËÆ°ÁÆóÊ®°Âùó benchmark: ML ÊØè4Âë®‰∏Ä‰∏™LabÔºåÊó†Êúü‰∏≠ÊúüÊú´ ‰Ωú‰∏öÔºö AlexNet Paper Quantization of CNN DNNTraining &amp; InferenceTraining: forward and backward Inference: back">
<meta property="og:type" content="article">
<meta property="og:title" content="Êï∞Â≠óÁ≥ªÁªüËÆæËÆ°">
<meta property="og:url" content="https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/index.html">
<meta property="og:site_name" content="Guo_Yun">
<meta property="og:description" content="Áª™ËÆ∫ËΩØÁ°¨‰ª∂ÂçèÂêåÔºåÂà∂‰ΩúÊ∑±Â∫¶Â≠¶‰π†Á°¨‰ª∂ ÁêÜËÆ∫ËØæÔºåËÆ≤Â∫ßÔºåLab ‰∏ìÁî®ÁîµË∑Ø ÁõÆÊ†áÔºöÂÅö‰∏Ä‰∏™Á±ª‰ºº‰∫éGoogle TPU‰∏≠ÁöÑÊüêËÆ°ÁÆóÊ®°Âùó benchmark: ML ÊØè4Âë®‰∏Ä‰∏™LabÔºåÊó†Êúü‰∏≠ÊúüÊú´ ‰Ωú‰∏öÔºö AlexNet Paper Quantization of CNN DNNTraining &amp; InferenceTraining: forward and backward Inference: back">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_1.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_2.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_3.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_4.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_1.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_3.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_2.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_4.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_5.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_6.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_7.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_8.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_9.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_10.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_1.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_2.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_4.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_5.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_6.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_7.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_8.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_10.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_9.jpg">
<meta property="article:published_time" content="2023-09-20T05:33:09.000Z">
<meta property="article:modified_time" content="2023-10-26T00:44:21.000Z">
<meta property="article:author" content="Blither Boom">
<meta property="article:tag" content="note">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blitherboom812.github.io/images/DSD/2_1.jpg"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script><!-- hexo injector head_end start --><link rel="stylesheet" type="text/css" href="/css/latex.css"><link rel="stylesheet" type="text/css" href="/css/fonts.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><script defer src="https://fastly.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js" type="module"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="Blither Boom"><img width="96" loading="lazy" src="/images/avatar.jpg" alt="Blither Boom"></a><div class="site-author-name"><a href="/about/">Blither Boom</a></div><span class="site-name">Guo_Yun</span><sub class="site-subtitle"></sub><div class="site-description"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="/archives/" title="Archives"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:archive-line"></span></span><span class="site-state-item-count">32</span></a></div><div class="site-state-item"><a href="/categories/" title="Categories"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:folder-2-line"></span></span><span class="site-state-item-count">0</span></a></div><div class="site-state-item"><a href="/tags/" title="Tags"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="site-state-item-count">7</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="ÊñáÊ°£"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:settings-line"></span></span></a></nav><hr style="margin-bottom:0.5rem"><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="ÊàëÁöÑÂ∞è‰ºô‰º¥‰ª¨" style="color:dodgerblue"><span class="icon iconify" data-icon="ri:genderless-line"></span></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><span class="icon iconify" data-icon="ri:contrast-2-line"></span></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%AA%E8%AE%BA"><span class="toc-number">1.</span> <span class="toc-text">Áª™ËÆ∫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DNN"><span class="toc-number">2.</span> <span class="toc-text">DNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Training-amp-Inference"><span class="toc-number">2.1.</span> <span class="toc-text">Training &amp; Inference</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model"><span class="toc-number">2.2.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dataset"><span class="toc-number">2.3.</span> <span class="toc-text">Dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cost-function"><span class="toc-number">2.4.</span> <span class="toc-text">Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimization"><span class="toc-number">2.5.</span> <span class="toc-text">Optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluation"><span class="toc-number">2.6.</span> <span class="toc-text">Evaluation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95%E5%92%8C%E8%AE%A8%E8%AE%BA"><span class="toc-number">2.7.</span> <span class="toc-text">ÁΩëÁªúÁªìÊûÑÁöÑÂèëÂ±ïÂíåËÆ®ËÆ∫</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Quantization"><span class="toc-number">3.</span> <span class="toc-text">Quantization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Fixed-point-and-floating-point-representation"><span class="toc-number">3.1.</span> <span class="toc-text">Fixed-point and floating-point representation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Fixed-Point-arithmetic"><span class="toc-number">3.1.1.</span> <span class="toc-text">Fixed Point arithmetic</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Floating-poing-arithmatic"><span class="toc-number">3.1.2.</span> <span class="toc-text">Floating-poing arithmatic</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hardware-implications"><span class="toc-number">3.2.</span> <span class="toc-text">Hardware implications</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Quantization-for-deep-learning"><span class="toc-number">3.3.</span> <span class="toc-text">Quantization for deep learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Classic-research-for-quantization-methods"><span class="toc-number">3.4.</span> <span class="toc-text">Classic research for quantization methods</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pruning"><span class="toc-number">4.</span> <span class="toc-text">Pruning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sparsity-New-Dimension-For-Efficiency"><span class="toc-number">4.1.</span> <span class="toc-text">Sparsity: New Dimension For Efficiency</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Weight-Sparsity-Pruning"><span class="toc-number">4.1.1.</span> <span class="toc-text">Weight Sparsity: Pruning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Activation-Sparsity-ReLU"><span class="toc-number">4.1.2.</span> <span class="toc-text">Activation Sparsity: ReLU</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Weight-Sparsity-Perspective"><span class="toc-number">4.2.</span> <span class="toc-text">Weight Sparsity Perspective</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Unstructured-Sparsity"><span class="toc-number">4.2.1.</span> <span class="toc-text">Unstructured Sparsity</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Structural-Sparsity"><span class="toc-number">4.2.2.</span> <span class="toc-text">Structural Sparsity</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Unstructured-vs-structured"><span class="toc-number">4.2.3.</span> <span class="toc-text">Unstructured vs. structured</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Frequency-Domain-Sparsity"><span class="toc-number">4.2.4.</span> <span class="toc-text">Frequency-Domain Sparsity</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Activation-Sparsity-Perspective"><span class="toc-number">4.3.</span> <span class="toc-text">Activation Sparsity Perspective</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Inter-Frame-Sparsity"><span class="toc-number">4.3.1.</span> <span class="toc-text">Inter-Frame Sparsity</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ROI-Spasity%EF%BC%9AInput-Dependent"><span class="toc-number">4.3.2.</span> <span class="toc-text">ROI SpasityÔºöInput Dependent</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Leveraging-Sparsity-in-Storage"><span class="toc-number">4.4.</span> <span class="toc-text">Leveraging Sparsity in Storage</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Bitmask-Compression"><span class="toc-number">4.4.1.</span> <span class="toc-text">Bitmask Compression</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Run-Length-Encoding"><span class="toc-number">4.4.2.</span> <span class="toc-text">Run-Length Encoding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Compressed-Sparse-Row-CSR"><span class="toc-number">4.4.3.</span> <span class="toc-text">Compressed Sparse Row (CSR)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Compressed-Sparse-Column-CSC"><span class="toc-number">4.4.4.</span> <span class="toc-text">Compressed Sparse Column (CSC)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#The-Taco-Notation"><span class="toc-number">4.4.5.</span> <span class="toc-text">The Taco Notation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%B2%E5%BA%A7"><span class="toc-number">5.</span> <span class="toc-text">ËÆ≤Â∫ß</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8F%E5%8C%96"><span class="toc-number">5.1.</span> <span class="toc-text">ÈáèÂåñ</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#0078E7;"><link itemprop="mainEntityOfPage" href="https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Blither Boom"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Guo_Yun"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Êï∞Â≠óÁ≥ªÁªüËÆæËÆ°</h1><div class="post-meta"><div class="post-time"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="Created: 2023-09-20 13:33:09" itemprop="dateCreated datePublished" datetime="2023-09-20T13:33:09+08:00">2023-09-20</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-2-line"></span></span> <time title="Modified: 2023-10-26 08:44:21" itemprop="dateModified" datetime="2023-10-26T08:44:21+08:00">2023-10-26</time></div><div class="post-classify"><span class="post-tag"><a class="tag-item" href="/tags/note/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="tag-name">note</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><h2 id="Áª™ËÆ∫"><a href="#Áª™ËÆ∫" class="headerlink" title="Áª™ËÆ∫"></a>Áª™ËÆ∫</h2><p>ËΩØÁ°¨‰ª∂ÂçèÂêåÔºåÂà∂‰ΩúÊ∑±Â∫¶Â≠¶‰π†Á°¨‰ª∂</p>
<p>ÁêÜËÆ∫ËØæÔºåËÆ≤Â∫ßÔºåLab</p>
<p>‰∏ìÁî®ÁîµË∑Ø</p>
<p>ÁõÆÊ†áÔºöÂÅö‰∏Ä‰∏™Á±ª‰ºº‰∫éGoogle TPU‰∏≠ÁöÑÊüêËÆ°ÁÆóÊ®°Âùó</p>
<p>benchmark: ML</p>
<p>ÊØè4Âë®‰∏Ä‰∏™LabÔºåÊó†Êúü‰∏≠ÊúüÊú´</p>
<p>‰Ωú‰∏öÔºö</p>
<p>AlexNet Paper</p>
<p>Quantization of CNN</p>
<h2 id="DNN"><a href="#DNN" class="headerlink" title="DNN"></a>DNN</h2><h3 id="Training-amp-Inference"><a href="#Training-amp-Inference" class="headerlink" title="Training &amp; Inference"></a>Training &amp; Inference</h3><p>Training: forward and backward</p>
<p>Inference: backward</p>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p><img src="/../images/DSD/2_1.jpg" loading="lazy"></p>
<p>‰∫îÁ±ªÁÆóÂ≠êÔºö</p>
<p><img src="/../images/DSD/2_2.jpg" loading="lazy"></p>
<p>ÁâπÂæÅÊèêÂèñÂô®ÔºöÂç∑ÁßØÂ±ÇÔºåÊ±†ÂåñÂ±ÇÔºõ</p>
<p>ÂàÜÁ±ªÂô®ÔºöÂÖ®ËøûÊé•Â±Ç</p>
<p><strong>Á∫øÊÄßÂç∑ÁßØÂ±Ç</strong></p>
<p>ËæπÁïåÊâ©ÂÖÖ(Padding)ÔºöÂú®ÂõæÂÉèÂë®Âõ¥Êâ©Â±ï‰∏ÄÂúà0ÔºåÈÅøÂÖçÂ§öÊ¨°Âç∑ÁßØÂØºËá¥Êï∞ÊçÆÂ∞∫ÂØ∏Ë∂äÊù•Ë∂äÂ∞è</p>
<p>Âç∑ÁßØÊ≠•Èïø(Stride)ÔºöÂç∑ÁßØÊ†∏ÊØèÊ¨°Ë∑≥ÁöÑÊ≠•Êï∞„ÄÇÂèØ‰ª•Áî®Êù•ËÆ©Êï∞ÊçÆÂ∞∫ÂØ∏Âø´ÈÄüÂèòÂåñ</p>
<p>ÈùûÁ∫øÊÄßÂáΩÊï∞-ÊøÄÊ¥ªÂáΩÊï∞</p>
<p>ÈùûÁ∫øÊÄß-Ê≠£ÂàôÂåñÂáΩÊï∞</p>
<p>ÈùûÁ∫øÊÄß-Ê±†ÂåñÂáΩÊï∞</p>
<p><strong>Ê±†ÂåñÂ±Ç</strong></p>
<p>Ê±†ÂåñÂ±ÇÂáèÂ∞èÂõæÁâáÁöÑÂ∞∫ÂØ∏Ôºå‰ªéËÄåÂáèÂ∞èÂèÇÊï∞ÁöÑÊï∞ÈáèÂíåËÆ°ÁÆóÈáè„ÄÇ</p>
<p>ÊúÄÂ§ßÊ±†ÂåñÔºöÂú®Ê±†ÂåñÁ™óÂè£ÂÜÖÂèñÊúÄÂ§ßÂÄº‰Ωú‰∏∫ËæìÂá∫„ÄÇ</p>
<ul>
<li>Â§çÊùÇÂ∫¶‰ΩéÔºåÁ°¨‰ª∂ÂÆûÁé∞ÂÆπÊòì</li>
<li>ÊúÄ‰∏∫Â∏∏Áî®</li>
</ul>
<p>Âπ≥ÂùáÊ±†ÂåñÔºöÂèñÊ±†ÂåñÁ™óÂè£ÂÜÖÁöÑÂπ≥ÂùáÂÄº‰Ωú‰∏∫ËæìÂá∫„ÄÇ</p>
<p>$L^2$ Ê±†ÂåñÊ≥ïÔºöÂØπÊâÄÊúâÁöÑÊï∞ËÆ°ÁÆóÂπ≥ÊñπÂêéÁ¥ØÂä†Ê±ÇÂíåÂÜçÂºÄÂπ≥Êñπ„ÄÇ</p>
<ul>
<li>ËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´ò</li>
<li>Âá†‰ΩïÂπ≥ÂùáÊ±†ÂåñÁöÑÂ§çÊùÇÂ∫¶Êõ¥È´ò</li>
</ul>
<p><strong>Á∫øÊÄßÂÖ®ËøûÊé•Â±Ç</strong></p>
<p>Â∞ÜÁâπÂæÅÂõæÊò†Â∞Ñ‰∏∫ÂàÜÁ±ªÁªìÊûú</p>
<p><strong>Softmax Â±Ç</strong></p>
<p>ÊúâÁöÑÊ®°ÂûãÂú®ËæìÂá∫Â±Ç‰ΩøÁî®softmaxÂØπËæìÂá∫ËøõË°åÂΩí‰∏ÄÂåñÔºö</p>
<div>$$
f(z_j) = \dfrac{e^{z_j}}{\sum_{i = 0}^n e^{z_j}}
$$</div>

<ul>
<li>ËæìÂÖ•ÂíåËæìÂá∫ËßÑÊ®°Áõ∏Âêå</li>
<li>ÂΩí‰∏ÄÂåñËÆ°ÁÆóÔºåËÆ©ËæÉÂ§ßÁöÑÂÄºÂá∏ÊòæÔºåËÆ©ËæÉÂ∞èÁöÑÂÄºË¢´ÊäëÂà∂Ôºå‰ªéËÄåÂÜ≥ÂÆöÂàÜÁ±ªÊ¶ÇÁéá</li>
</ul>
<p><strong>Âç∑ÁßØÁ•ûÁªèÁΩëÁªúÁöÑÊÄª‰ΩìÁªìÊûÑ</strong></p>
<h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>Êï∞ÊçÆÈõÜÁöÑÂª∫Á´ãÔºöÊï∞ÊçÆÈááÈõÜÔºåÊï∞ÊçÆÊ†áÁ≠æÔºåÊï∞ÊçÆÊ∏ÖÊ¥óÔºåÊï∞ÊçÆÂ¢ûÂº∫ÔºåÊï∞ÊçÆÂàÜÂâ≤</p>
<h3 id="Cost-function"><a href="#Cost-function" class="headerlink" title="Cost function"></a>Cost function</h3><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><ul>
<li>Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï</li>
<li>SGD</li>
<li>Âä®ÈáèÊ≥ïÔºöËÆ°ÁÆóËøáÂéªÁöÑÂπ≥ÂùáÊ¢ØÂ∫¶</li>
<li>AdaGradÊ≥ïÔºöÁ¥ØÂä†Ê¢ØÂ∫¶ÊñπÂ∑Æ</li>
<li>RMSPropÔºöÊåâÊó∂Èó¥Èôç‰ΩéÂ≠¶‰π†Áéá</li>
<li>Adam ÁÆóÊ≥ïÔºöÊåáÊï∞Âä†ÊùÉÁßªÂä®Âπ≥ÂùáÂÄºËÆ°ÁÆóÊ¢ØÂ∫¶Âä®ÈáèÂíå‰∫åÊ¨°Áü©</li>
<li>SGDÁÆÄÂçïÔºå‰ΩÜÊòØËÆ≠ÁªÉËøáÁ®ãËæπÈïøÔºåËá™ÈÄÇÂ∫îÁÆóÊ≥ï‰ºöÊõ¥È´òÊïà</li>
</ul>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p><strong>ÂõûÂΩíÈóÆÈ¢òÊåáÊ†á</strong></p>
<p>PSNR</p>
<div>$$
PSNR = 10 \cdot \log_{10}(\frac{MAX_I^2}{MSE})
$$</div>

<p><strong>ÂàÜÁ±ªÈóÆÈ¢òÊåáÊ†á</strong></p>
<ul>
<li>Top1 accuracy</li>
<li>Top5 accuracy</li>
</ul>
<p><strong>IoU</strong></p>
<p>Intersection of Union?</p>
<div>$$
\text{IoU} = \frac{|A\cap B|}{|A \cup B|}
$$</div>

<p><strong>Ê£ÄÊµã‰ªªÂä°ËØÑ‰ª∑ÊåáÊ†á mAP</strong></p>
<p>mean average precision</p>
<p>ÁúüÈò≥ÊÄßTP: È¢ÑÊµã‰∏∫ÁúüÔºåÂÆûÈôÖ‰∏∫Áúü</p>
<p>ÂÅáÈò≥ÊÄßFPÔºöÈ¢ÑÊµã‰∏∫ÁúüÔºåÂÆûÈôÖ‰∏∫ÂÅá</p>
<p>ÂÅáÈò¥ÊÄßFNÔºöÈ¢ÑÊµã‰∏∫ÂÅáÔºåÂÆûÈôÖ‰∏∫Áúü</p>
<p><strong>Êü•ÂÖ®ÁéáÔºàÂè¨ÂõûÁéáÔºåRecallÔºâÂíåÊü•ÂáÜÁéáÔºàÂáÜÁ°ÆÁéáÔºåPrecisionÔºâ</strong></p>
<div>$$
\text{Precision} = \frac{TP}{TP + FP}\\
\text{Recall} = \frac{TP}{TP + FN}
$$</div>

<p>ÁΩÆ‰ø°Â∫¶Ë°°ÈáèÁöÑÊòØÊ®°ÂûãËÆ§‰∏∫ÊúâÊïàÁöÑËá™‰ø°Á®ãÂ∫¶„ÄÇÊàë‰ª¨ÂÖàÂ∞ÜÁªìÊûúÊåâÁÖßÁΩÆ‰ø°Â∫¶‰ªéÈ´òÂà∞‰ΩéÊéíÂ∫è„ÄÇ</p>
<p>mAPÊòØ‰∏çÂêåÊü•ÂÖ®Áéá‰∏ãÔºåÊúÄÈ´òÊü•ÂáÜÁéáÁöÑÂπ≥ÂùáÂÄº„ÄÇ</p>
<h3 id="ÁΩëÁªúÁªìÊûÑÁöÑÂèëÂ±ïÂíåËÆ®ËÆ∫"><a href="#ÁΩëÁªúÁªìÊûÑÁöÑÂèëÂ±ïÂíåËÆ®ËÆ∫" class="headerlink" title="ÁΩëÁªúÁªìÊûÑÁöÑÂèëÂ±ïÂíåËÆ®ËÆ∫"></a>ÁΩëÁªúÁªìÊûÑÁöÑÂèëÂ±ïÂíåËÆ®ËÆ∫</h3><p><strong>ÂàÜÁ±ª‰ªªÂä°</strong></p>
<p>AlexNet</p>
<ul>
<li>‰ΩøÁî®Â§ö‰∏™Âç∑ÁßØÂ±ÇÔºåÊúâÊïàÊèêÂèñÂõæÂÉèÁâπÂæÅ</li>
<li>ReLU ÊèêÈ´òËÆ≠ÁªÉÈÄüÂ∫¶</li>
<li>Dropout„ÄÅÊï∞ÊçÆÂ¢ûÂº∫Êâ©Â§ßËÆ≠ÁªÉÈõÜÔºåÈò≤Ê≠¢ËøáÊãüÂêà</li>
</ul>
<p>VGG</p>
<ul>
<li>‰ΩøÁî® 3 * 3 ÁöÑÂç∑ÁßØÊ†∏Âèñ‰ª£ AlexNet ÁöÑÂ§ßÂç∑ÁßØÊ†∏<ul>
<li>ÊèêÂçáÊî∂ÊïõÈÄüÂ∫¶</li>
<li>ÂèÇÊï∞ÈáèÊõ¥Â∞ë</li>
<li>ÂèØ‰ª•ÊûÑÂª∫Êõ¥Ê∑±ÁöÑÁΩëÁªúÔºåÊúâÊõ¥Â§öÁöÑÈùûÁ∫øÊÄßÂèòÊç¢ÔºåËøòÊúâÊõ¥Âº∫ÁöÑË°®ÂæÅËÉΩÂäõ</li>
</ul>
</li>
<li>ÂèÇÊï∞È¢ÑÂàùÂßãÂåñÁ≠ñÁï•</li>
</ul>
<p>ResNet</p>
<p>?</p>
<p><strong>ÁõÆÊ†áÊ£ÄÊµã</strong></p>
<p>Two-stage v.s. One-stage</p>
<p><strong>Two-stage</strong></p>
<p>ÂÖàÁîªÊ°ÜÔºåÂÜçÂàÜÁ±ª</p>
<p>MS CoCo Dataset</p>
<ul>
<li>Áî®ÁöÑÊúÄÂ§öÁöÑËøòÊòØÁõÆÊ†áÊ£ÄÊµã‰ªªÂä°</li>
</ul>
<p>R-CNN</p>
<ul>
<li>ËæìÂÖ•ÂõæÂÉè</li>
<li>ÊèêÂèñÂÄôÈÄâÊ°Ü</li>
<li>ÊØè‰∏Ä‰∏™ÂÄôÈÄâÊ°ÜÊèêÂèñÂçïÁã¨ÁöÑÁâπÂæÅ</li>
<li>ËøõË°åÂàÜÁ±ª</li>
</ul>
<p>Fast R-CNN</p>
<ul>
<li>ËæìÂÖ•ÂõæÂÉè</li>
<li>‰∏ÄÊ¨°ÁâπÂæÅÊèêÂèñ</li>
<li>ÊèêÂèñÂÄôÈÄâÊ°Ü</li>
<li>ËøõË°åÂàÜÁ±ª</li>
</ul>
<p>Faster R-CNN</p>
<ul>
<li>ËæìÂÖ•ÂõæÂÉè</li>
<li>‰∏ÄÊ¨°ÁâπÂæÅÊèêÂèñ</li>
<li>ÊèêÂèñÂÄôÈÄâÊ°Ü</li>
<li>ËøõË°åÂàÜÁ±ª</li>
</ul>
<p><strong>One-stage</strong></p>
<p>YOLO</p>
<p>‰∫î‰ª£ÂèëÂ±ïÔºåÊúÄÂπøÊ≥õÁöÑÁõÆÊ†áÊ£ÄÊµãÁÆóÊ≥ï</p>
<p>ÂØπ‰∫éÊØè‰∏Ä‰∏™ÂÉèÁ¥†ÔºåÈÉΩ‰ºöËæìÂá∫‰∏Ä‰∏™ÂØπÂ∫îÁöÑÁâπÂæÅÂêëÈáèÔºåÂåÖÂê´Ôºö</p>
<ul>
<li>‰∫åÂàÜÁ±ªÔºöÊòØÁâ©‰Ωì‰∏≠ÂøÉÁöÑÁΩÆ‰ø°Â∫¶</li>
<li>ÂõûÂΩíÔºöÂÅèÁ¶ªÁâ©‰Ωì‰∏≠ÂøÉÁöÑÈïøÂ∫¶ $\Delta x$ Âíå $\Delta y$</li>
<li>ÂàÜÁ±ªÔºöÂØπÂ∫îÁöÑÁâ©‰ΩìÂàÜÁ±ª‰ª•ÂèäÁΩÆ‰ø°Â∫¶</li>
<li>ÂõûÂΩíÔºöËØ•ÂÉèÁ¥†ÊâÄ‰ª£Ë°®ÁöÑÁâ©‰ΩìÁöÑÈïøÂÆΩÔºåYOLOÊúâ‰∏Ä‰∫õÂü∫Á°ÄÊ°Ü(anchor)ÔºåËæìÂá∫ÂÄºÊòØÁõ∏ÂØπÂü∫Á°ÄÊ°ÜÁöÑÂΩ¢Âèò $\Delta h$ Âíå $\Delta w$</li>
</ul>
<p><strong>NMS (Non-Maximum Suppression)</strong><br>Bounding boxes for one instance may overlap.<br>Method: For each type, use NMS to eliminate redundant bounding boxes (greedy approach).<br>Workflow:</p>
<ol>
<li>Sort candidate bounding boxes by classification confidence.</li>
<li>Adding the boxes b with most confidence to output list, and delete it from the candidate boxes.</li>
<li>Calculate IoU between b and other boxes bi. If &gt; threshold, delete bi.</li>
<li>Repeat until no candidate bounding boxes.</li>
</ol>
<p><strong>Â∫èÂàóÊ®°ÂûãÔºàSerial ModelÔºâ</strong></p>
<p>to process Speech, text, video, audio, etc.</p>
<p>Feature: </p>
<ol>
<li>The data input is in the time sequence.</li>
<li>There is a correlation between the data before and after.</li>
</ol>
<p>So the model should have the ability to ‚Äústore‚Äù information.</p>
<p>Speech dataset: TIMIT</p>
<ol>
<li>It consists of recordings of 630 speakers of 8 dialects of American English each reading 10 phonetically-rich sentences.</li>
<li>It also comes with the word and phone-level transcriptions of the speech.</li>
</ol>
<p>Video dataset: DAVIS</p>
<p>The Densely Annotation Video Segmentation dataset (DAVIS) is a high quality and high resolution densely annotated video segmentation dataset under two resolutions, 480p and 1080p.</p>
<p>There are 50 video sequences with 3455 densely annotated frames in pixel level. 30 videos with 2079 frames are for training and 20 videos with 1376 frames are for validation.</p>
<p>NLP dataset: GLUE</p>
<p>General Language Understanding Evaluation (GLUE) benchmark: Standard split of data totrain, validation, test, where labels for the test set is only held in the server.</p>
<ul>
<li>Sentence pair tasks<ul>
<li>MNLI, Multi-Genre Natural Language Inference</li>
<li>QQP, Ouora Ouestion Pairs</li>
<li>QNLI, Ouestion Natural Language Inference</li>
<li>STS-B The Semantic Textual Similarity Benchmark</li>
<li>MRPC Microsoft Research Paraphrase Corpus</li>
<li>RTE Recognizing Textual Entailment</li>
<li>WNLI Winograd NLI is a small natural language inference</li>
</ul>
</li>
<li>datasetSingle sentence classification<ul>
<li>SST-2 The Stanford Sentiment Treebank</li>
<li>CoLA The Corpus of Linguistic Acceptability</li>
</ul>
</li>
</ul>
<p><strong>Models</strong></p>
<p><strong>RNN: Recurrent Neural Network</strong></p>
<ul>
<li>one to one </li>
<li>one to many</li>
<li>many to one</li>
<li>many to many</li>
<li>many to many</li>
</ul>
<p><img src="/../images/DSD/2_3.jpg" loading="lazy"></p>
<p>ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆ°ÁÆóÔºö</p>
<p>Âçï‰∏™Êó∂ÂàªÔºö</p>
<div>$$
L^{(t)} = -\mathbf y^{(t)} \ln \mathbf {\hat {y}}^{(t)}
$$</div>

<p>Êï¥‰∏™Â∫èÂàóÔºö</p>
<div>$$
L = \sum\limits_{t=1}^{\tau}L^{(t)} = - \sum\limits_{t=1}^{\tau} \mathbf y^{(t)} \ln \mathbf {\hat {y}}^{(t)}
$$</div>

<p>ÁÑ∂ÂêéÂèØÊ±ÇÊ¢ØÂ∫¶Ôºö</p>
<p><img src="/../images/DSD/2_4.jpg" alt="alt" loading="lazy"></p>
<p>Âæ™ÁéØÁ•ûÁªèÁΩëÁªúÂ≠òÂú®Ê¢ØÂ∫¶ÁàÜÁÇ∏ÊàñÊ¢ØÂ∫¶Ê∂àÂ§±ÔºåÂõ†Ê≠§Êó†Ê≥ïÂ§ÑÁêÜÈïøÊúüÁöÑ‰æùËµñÂÖ≥Á≥ª„ÄÇ</p>
<p><strong>LSTM: Solving the Gradient</strong></p>
<p><strong>Transformer</strong></p>
<p>Self attention:</p>
<div>$$
\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK}{\sqrt d_k})V
$$</div>

<h2 id="Quantization"><a href="#Quantization" class="headerlink" title="Quantization"></a>Quantization</h2><h3 id="Fixed-point-and-floating-point-representation"><a href="#Fixed-point-and-floating-point-representation" class="headerlink" title="Fixed-point and floating-point representation"></a>Fixed-point and floating-point representation</h3><h4 id="Fixed-Point-arithmetic"><a href="#Fixed-Point-arithmetic" class="headerlink" title="Fixed Point arithmetic"></a>Fixed Point arithmetic</h4><div>$$
\underbrace{0}_{\text{Sign bit}}\ \ \underbrace{10\dots01}_{n\text{ bit integer part}}\ \ .\underbrace{10\dots01}_{m\text{ bit fractional part}}
$$</div>

<p><strong>Fixed point with slope and bias</strong></p>
<p>apply a linear transform on fixed point:</p>
<div>$$
y = s*x + z
$$</div>



<h4 id="Floating-poing-arithmatic"><a href="#Floating-poing-arithmatic" class="headerlink" title="Floating-poing arithmatic"></a>Floating-poing arithmatic</h4><p><img src="/../images/DSD/3_1.jpg" alt="alt" loading="lazy"></p>
<p><strong>IEEE 754 Floating Point Standard</strong></p>
<ul>
<li>Called Biased Notation, where bias is number subtracted to get real number. </li>
<li>IEEE 754 uses bias of 127 for single precision, 1023 for double precision.</li>
</ul>
<p><img src="/../images/DSD/3_3.jpg" alt="alt" loading="lazy"></p>
<div>$$
(-1)^S \times (1 + m) \times 2^{(E - \text{Bias})}
$$</div>

<p><strong>fp15(helf precision)</strong></p>
<p><img src="/../images/DSD/3_2.jpg" alt="alt" loading="lazy"></p>
<h3 id="Hardware-implications"><a href="#Hardware-implications" class="headerlink" title="Hardware implications"></a>Hardware implications</h3><p><img src="/../images/DSD/3_4.jpg" alt="alt" loading="lazy"></p>
<p>Âä†Ê≥ï‰∏ãÂÆöÁÇπÊï∞ÊØîÊµÆÁÇπÊï∞ÂäüËÄóÂ∞èÂæóÂ§öÔºå‰ΩÜÊòØ‰πòÊ≥ï‰∏ãÂÆöÁÇπÊï∞ÂíåÊµÆÁÇπÊï∞ÁöÑÊÄßËÉΩÂ∑Æ‰∏çÂ§ö„ÄÇ</p>
<p>Low bit Fixed-point representations on digital system</p>
<h3 id="Quantization-for-deep-learning"><a href="#Quantization-for-deep-learning" class="headerlink" title="Quantization for deep learning"></a>Quantization for deep learning</h3><ul>
<li>Post-training quantization</li>
<li>Quantization-aware training</li>
</ul>
<p><strong>Post-training quantization</strong></p>
<div>$$
r = S(Q - Z)\\
OA[i, k] =\sum\limits_{j=1}^{N}(W[i, j] * IA[j, k])\\
q_{OA}^{(i, k)} = Z_{OA} + \frac{S_W * S_{IA}}{S_{OA}}\sum\limits_{j=1}^{N} (q_W^{(i, j)} * q_{IA}^{(j, k)})
$$</div>

<p>Choose the optimal threshold</p>
<p>No saturation is bad </p>
<h3 id="Classic-research-for-quantization-methods"><a href="#Classic-research-for-quantization-methods" class="headerlink" title="Classic research for quantization methods"></a>Classic research for quantization methods</h3><p><strong>Basic structure</strong></p>
<p>Weight Quantization &amp; Activation Quantization</p>
<p><img src="/../images/DSD/3_5.jpg" alt="alt" loading="lazy"></p>
<p><strong>Dorefa Net</strong></p>
<ul>
<li>quantization for gradient</li>
<li>normalize data to ensure the data distribution not change after quantization</li>
<li>uniform noise to offset the quantization noise for gradient</li>
<li>replace accumulate with bitcount operation</li>
<li>result is that gradient precision is most sensitive in TAQ(G &gt; A &gt; W)</li>
</ul>
<p><strong>INQ</strong></p>
<ul>
<li>quantization first half and freeze the other, then unfreeze other to train normally</li>
<li>exchange the first half and second half, and repeat above</li>
</ul>
<p><img src="/../images/DSD/3_6.jpg" alt="alt" loading="lazy"></p>
<p><strong>Pact</strong></p>
<ul>
<li>clipping the activation before quantization is better</li>
</ul>
<div>$$
PACT(x) = 0.5(|x| - |x - \alpha| + \alpha) = \begin{cases}
    0, x< 0,\\
    x, 0\le x \lt \alpha,\\
    \alpha, x \ge \alpha 
\end{cases}
$$</div>

<p>Different layers need different Œ±</p>
<p>alpha should be learnable</p>
<p><strong>Outlier quantization</strong></p>
<ul>
<li>Use different quantized bits to quantize different weights. Some weight can have higher precision while others not.</li>
</ul>
<p><img src="/../images/DSD/3_7.jpg" alt="alt" loading="lazy"></p>
<p><strong>Quantization interval learning</strong></p>
<ul>
<li>Most of the weights are very small. Minor weights can have too large value.</li>
</ul>
<p><img src="/../images/DSD/3_8.jpg" alt="alt" loading="lazy"></p>
<p>a should be pruned, c should be clipped, only b worths quantizing.</p>
<p><strong>Binary neural networks (BNN)</strong></p>
<ul>
<li>Networks with weights composed of {-1, 1}</li>
</ul>
<p><img src="/../images/DSD/3_9.jpg" alt="alt" loading="lazy"></p>
<ul>
<li>ËÆ°ÁÆóÊó∂ÈïøË∑üÁ≤æÂ∫¶ÊúâÂπ≥ÊñπÂèçÊØîÁöÑÂÖ≥Á≥ªÔºå‰ºòÂåñÊòØÂπ≥ÊñπÁöÑ</li>
<li>Â≠òÂÇ®Ë∑üÁ≤æÂ∫¶Âè™ÊúâÁ∫øÊÄßÁöÑÂÖ≥Á≥ªÔºå‰ºòÂåñÊòØÁ∫øÊÄßÁöÑÔºåÁî±‰∫éBNN bitÊï∞Â∞ëÔºåÊÄªÁöÑÂèÇÊï∞ÈáèÊõ¥Â§öÔºåÂÆûÈôÖ‰∏äÂ≠òÂÇ®Ê≤°ÊÄé‰πà‰ºòÂåñ</li>
<li>BNN Â§ßÂπÖ‰ºòÂåñ‰∫ÜËÆ°ÁÆóÔºå‰ΩÜÊòØÂ≠òÂÇ®Ê≤°ÂèòÔºåÊ≠§Êó∂Â≠òÂÇ®Êàê‰∏∫‰∫ÜÁì∂È¢à</li>
</ul>
<p><strong>State-of-the-art hardware support for low<br>precision DNNs</strong></p>
<p><img src="/../images/DSD/3_10.jpg" alt="alt" loading="lazy"></p>
<h2 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h2><p>Á®ÄÁñèÁü©ÈòµÊòØÊåáÁü©Èòµ‰∏≠Â§ßÈÉ®ÂàÜÂÖÉÁ¥†ÈÉΩÊòØ0ÁöÑÁü©Èòµ„ÄÇËé∑ÂæóÁ®ÄÁñèÁü©ÈòµÔºåÊúâÂä©‰∫éÂä†ÈÄüËÆ≠ÁªÉÂíåÊé®ÁêÜÈÄüÂ∫¶„ÄÇ</p>
<h3 id="Sparsity-New-Dimension-For-Efficiency"><a href="#Sparsity-New-Dimension-For-Efficiency" class="headerlink" title="Sparsity: New Dimension For Efficiency"></a>Sparsity: New Dimension For Efficiency</h3><p>Á®ÄÁñèÊÄßÁöÑÊù•Ê∫êÔºö</p>
<ul>
<li>Ââ™Êûù - ÊùÉÈáç</li>
<li>ReLU - ÊøÄÊ¥ª</li>
<li>Domain Specific</li>
</ul>
<h4 id="Weight-Sparsity-Pruning"><a href="#Weight-Sparsity-Pruning" class="headerlink" title="Weight Sparsity: Pruning"></a>Weight Sparsity: Pruning</h4><p>Ââ™ÊûùÊñπÊ≥ïÔºö</p>
<ul>
<li>ÂæàÂ§öÂèÇÊï∞ÂÖ∂ÂÆûÊòØÂæàÊé•Ëøë0ÁöÑÊï∞</li>
<li>Âõ†Ê≠§Ôºå‰Ωé‰∫éÊüê‰∏ÄÈòàÂÄºÊó∂ÔºåÁõ¥Êé•Â∞ÜÂÖ∂Ëµã0.‰ΩÜÊòØËøôÊ†∑‰ºöÂΩ±ÂìçÁ≤æÂ∫¶„ÄÇ</li>
<li>ËøòÂèØ‰ª•Áî®Ê∑ªÂä†Ê≠£ÂàôÈ°πÁöÑÊñπÊ≥ïÔºàWeight decayÔºâÔºö<ul>
<li>$CF &#x3D; MSE_{train} + \lambda \sum_i w_i^2$</li>
<li>$CF &#x3D; MSE_{train} + \lambda \sum_i |w_i|$</li>
</ul>
</li>
</ul>
<h4 id="Activation-Sparsity-ReLU"><a href="#Activation-Sparsity-ReLU" class="headerlink" title="Activation Sparsity: ReLU"></a>Activation Sparsity: ReLU</h4><h3 id="Weight-Sparsity-Perspective"><a href="#Weight-Sparsity-Perspective" class="headerlink" title="Weight Sparsity Perspective"></a>Weight Sparsity Perspective</h3><p>‰∏çÂêåÁöÑÁ®ÄÁñèÁ®ãÂ∫¶Ôºö</p>
<p><img src="/../images/DSD/4_1.jpg" alt="alt" loading="lazy"></p>
<h4 id="Unstructured-Sparsity"><a href="#Unstructured-Sparsity" class="headerlink" title="Unstructured Sparsity"></a>Unstructured Sparsity</h4><p>Han Song@NIPS2015 ÁöÑÂâ™ÊûùÁ≠ñÁï•Ôºö</p>
<p><img src="/../images/DSD/4_2.jpg" alt="alt" loading="lazy"></p>
<p>Á¨¨‰∏ÄËΩÆËÆ≠ÁªÉÂêéÔºåÂ∞ÜÊâÄÊúâÊé•Ëøë0ÁöÑÁ•ûÁªèÂÖÉÂâ™Èô§ÔºåÂÜçÈáçÊñ∞ÂØπÂâ©‰∏ãÁöÑËøõË°åËÆ≠ÁªÉ(retrain)„ÄÇ</p>
<ul>
<li>ÂéãÁº©ÊØîÂæàÈ´òÔºåËÄåÂáÜÁ°ÆÁéáÂá†‰πé‰∏ç‰∏ãÈôç</li>
<li>ÂØπ‰∫éÁ°¨‰ª∂Âπ∂‰∏çÂèãÂ•ΩÔºåËôΩÁÑ∂ÊúâÂæàÂ§ö0Ôºå‰ΩÜÊòØÁ°¨‰ª∂‰∏äÊ≤°Ê≥ïÊääÂÆÉ‰ª¨ÂéãÁº©Êéâ„ÄÇ</li>
<li>ËÆ°ÁÆóÈÄüÂ∫¶Âπ∂Ê≤°ÊúâÊèêÈ´òÔºåÁîöËá≥Èôç‰Ωé‰∫Ü</li>
</ul>
<h4 id="Structural-Sparsity"><a href="#Structural-Sparsity" class="headerlink" title="Structural Sparsity"></a>Structural Sparsity</h4><p><strong>SSL Ââ™ÊûùÁ≠ñÁï•(Structured weight pruning)</strong></p>
<ul>
<li>‰∏çÊòØÂâ™‰∏Ä‰∏™Á•ûÁªèÂÖÉÔºåËÄåÊòØÊää‰∏ÄË°å&#x2F;‰∏ÄÂàó&#x2F;‰∏Ä‰∏™ÈÄöÈÅìÂÖ®ÈÉ®Ââ™Êéâ„ÄÇÔºà‰∏çËøáÔºå‰∏çÊòØÁúüÁöÑÂâ™ÊûùÔºåËÄåÊòØ‰øÆÊîπ‰ª£‰ª∑ÂáΩÊï∞ÁöÑÊ≠£ÂàôÈ°πÔºâ</li>
<li>ËßÑÂàôÂåñÁöÑÂâ™ÊûùÂØπÁ°¨‰ª∂Êõ¥Âä†ÂèãÂ•Ω</li>
</ul>
<p>‰ª£‰ª∑ÂáΩÊï∞ÁöÑË°®ËææÂºèÔºö</p>
<p><img src="/../images/DSD/4_4.jpg" alt="alt" loading="lazy"></p>
<ul>
<li>ÊàêÂäüÂú®‰∏ÄËà¨ËÆæÂ§á‰∏äÂä†ÈÄü‰∫Ü</li>
</ul>
<p><strong>Pattern Pruning</strong></p>
<p>Á†îÁ©∂Âç∑ÁßØÊ†∏ÂÜÖÈùû0ÁöÑÊùÉÈáçÊòØÂ¶Ç‰ΩïÂàÜÂ∏ÉÁöÑ„ÄÇ</p>
<p><img src="/../images/DSD/4_5.jpg" alt="alt" loading="lazy"></p>
<p>Â¶ÇÊûúÊüê‰∏™‚ÄúÂàÜÂ∏ÉÊ®°Âºè‚ÄùÂèçÂ§çÁöÑÂá∫Áé∞ÔºåÂ∞±ÂèØ‰ª•ÂØπÂÆÉËøõË°åÂéãÁº©Â≠òÂÇ®Ôºö</p>
<p><img src="/../images/DSD/4_6.jpg" alt="alt" loading="lazy"></p>
<p>Ëøô‰∏ÄÊñπÈù¢ÁöÑÊàêÊûúÔºö</p>
<ul>
<li>Flexible-Length Pattern PruningÔºöÁî®Ê¶ÇÁéáÁªüËÆ°ÊñπÊ≥ïÂæóÂà∞ÁâπÂÆöÁöÑÊ®°Âºè</li>
<li>Fixed-Length Pattern PruningÔºöÁ∫¶Êùü‰∫ÜÊ®°ÂºèÈáåÈù¢Èùû0ÂÖÉÁ¥†ÁöÑ‰∏™Êï∞</li>
</ul>
<h4 id="Unstructured-vs-structured"><a href="#Unstructured-vs-structured" class="headerlink" title="Unstructured vs. structured"></a>Unstructured vs. structured</h4><p>Ââ™ÊûùÊäÄÊúØÂü∫Êú¨‰∏äÂ∑≤ÁªèÊàêÁÜüÔºö</p>
<ul>
<li>Non-stuctured pruning<ul>
<li>È´òÂéãÁº©Áéá</li>
<li>Âè™ËÉΩÂú®ÁâπÂÆöËÆæÂ§á‰∏äÊù•Èôç‰ΩéÂäüËÄóÔºå‰ΩÜÊòØÊÄßËÉΩÂÖ∂ÂÆûÊ≤°‰ªÄ‰πàÊèêÂçá</li>
</ul>
</li>
<li>Structured pruning<ul>
<li>ÂØπÁ°¨‰ª∂Êõ¥ÂèãÂ•Ω</li>
<li>‰ΩéÂéãÁº©Áéá</li>
</ul>
</li>
</ul>
<p>ÔºàÂéãÁº©ÁéáÊåáÁöÑÊòØËÆ≠ÁªÉÁöÑÈÄüÂ∫¶ÔºåÂç≥Â∞ÜÊï∞ÊçÆ‚ÄúÂéãÁº©‚Äù‰∏∫Á•ûÁªèÁΩëÁªúÁöÑÂÜÖËï¥Áü•ËØÜÁöÑËÉΩÂäõ„ÄÇÔºâ</p>
<h4 id="Frequency-Domain-Sparsity"><a href="#Frequency-Domain-Sparsity" class="headerlink" title="Frequency-Domain Sparsity"></a>Frequency-Domain Sparsity</h4><p>ÈááÁî®Âæ™ÁéØÁöÑÂç∑ÁßØÊ†∏</p>
<ul>
<li>Âõ†‰∏∫Âæ™ÁéØÂá∫Áé∞ÁöÑÂÖÉÁ¥†ÔºåÂ≠òÂÇ®Èôç‰Ωé</li>
<li>ËÆ°ÁÆóÁ≠â‰ª∑‰∏∫Âæ™ÁéØÂç∑ÁßØÔºåÂèØ‰ª•ËΩ¨Êç¢‰∏∫ FFT È¢ëÂüüÁõ∏‰πòÔºåËé∑ÂæóÊõ¥È´òÊïàÁöÑËÆ°ÁÆó</li>
</ul>
<h3 id="Activation-Sparsity-Perspective"><a href="#Activation-Sparsity-Perspective" class="headerlink" title="Activation Sparsity Perspective"></a>Activation Sparsity Perspective</h3><h4 id="Inter-Frame-Sparsity"><a href="#Inter-Frame-Sparsity" class="headerlink" title="Inter-Frame Sparsity"></a>Inter-Frame Sparsity</h4><p>‰∏ÄÊÆµÂ∫èÂàóÁöÑÁõ∏ÈÇªÂ∏ß‰πãÈó¥ÂÖ∑ÊúâÁõ∏‰ººÊÄß„ÄÇÂõ†Ê≠§Âè™ÈúÄË¶ÅÂ≠òÂÇ®Â∏ß‰∏éÂ∏ß‰πãÈó¥ÁöÑÂ∑ÆÂÄºÂ∞±Ë°å‰∫Ü„ÄÇ</p>
<p>Yuan Z@ISSCC 2020 ÁöÑÁªìËÆ∫Ôºö</p>
<ul>
<li>Â∑ÆÂàÜÂ∏ßÂπ∂‰∏çÊòØÁ®ÄÁñèÁöÑ</li>
<li>Â∑ÆÂàÜÂ∏ßÁöÑÊï∞ÂÄºÈõÜ‰∏≠‰∫é‰ΩéÁöÑbit‰ΩçÔºåÂàÜÂ∏ÉÈõÜ‰∏≠</li>
<li>ËÄåÈ´òbit‰ΩçÂæàÂ§öÈÉΩÊòØ0ÔºåÈùûÂ∏∏Á®ÄÁñè</li>
</ul>
<p>Âõ†Ê≠§ÔºåÂèØ‰ª•ÂØπ‰Ωé bit ‰ΩçÂíåÈ´ò bit ‰ΩçÊãÜÂàÜÂ§ÑÁêÜ„ÄÇ</p>
<h4 id="ROI-SpasityÔºöInput-Dependent"><a href="#ROI-SpasityÔºöInput-Dependent" class="headerlink" title="ROI SpasityÔºöInput Dependent"></a>ROI SpasityÔºöInput Dependent</h4><p>ROI: Region of Interest</p>
<p>ÂõæÂÉèÈáåÂåÖÂê´ÁöÑ‰ø°ÊÅØÔºåÊúâÁöÑ‰∏∞ÂØåÔºåÊúâÁöÑË¥´‰πèÔºåÊúâÁöÑÂÆπÊòìËØÜÂà´ÔºåÊúâÁöÑÂæàÈöæËØÜÂà´„ÄÇ</p>
<ul>
<li>Á®†ÂØÜÁöÑËæìÂÖ•Áî®Â§ßÊ†∏ÔºåÁ®ÄÁñèÁöÑËæìÂÖ•Áî®Â∞èÊ†∏Ôºü</li>
</ul>
<p>Âü∫‰∫é‰∏çÂêåÁöÑËæìÂÖ•ÔºåÈááÁî®‰∏çÂêåÁöÑÁΩëÁªúÔºö</p>
<ul>
<li>ÂõæÂÉè‰∏≠ÈöæÂ∫¶È´òÁöÑÂå∫ÂüüÈÄöËøáÊõ¥Ê∑±ÁöÑÁΩëÁªúÂ±Ç</li>
<li>ÈöæÂ∫¶‰ΩéÁöÑÂå∫ÂüüÈÄöËøáÊõ¥ÊµÖÁöÑÁΩëÁªúÂ±Ç</li>
</ul>
<h3 id="Leveraging-Sparsity-in-Storage"><a href="#Leveraging-Sparsity-in-Storage" class="headerlink" title="Leveraging Sparsity in Storage"></a>Leveraging Sparsity in Storage</h3><p>Â¶Ç‰ΩïÂéãÁº©Á®ÄÁñèÁü©ÈòµÁöÑÂ≠òÂÇ®Á©∫Èó¥Ôºü</p>
<h4 id="Bitmask-Compression"><a href="#Bitmask-Compression" class="headerlink" title="Bitmask Compression"></a>Bitmask Compression</h4><p><img src="/../images/DSD/4_7.jpg" alt="alt" loading="lazy"></p>
<h4 id="Run-Length-Encoding"><a href="#Run-Length-Encoding" class="headerlink" title="Run-Length Encoding"></a>Run-Length Encoding</h4><p>Ê∏∏Á®ãÁºñÁ†Å<br>(matlabË≠¶Âëä)</p>
<p><img src="/../images/DSD/4_8.jpg" alt="alt" loading="lazy"></p>
<h4 id="Compressed-Sparse-Row-CSR"><a href="#Compressed-Sparse-Row-CSR" class="headerlink" title="Compressed Sparse Row (CSR)"></a>Compressed Sparse Row (CSR)</h4><p><img src="/../images/DSD/4_10.jpg" alt="alt" loading="lazy"></p>
<h4 id="Compressed-Sparse-Column-CSC"><a href="#Compressed-Sparse-Column-CSC" class="headerlink" title="Compressed Sparse Column (CSC)"></a>Compressed Sparse Column (CSC)</h4><p><img src="/../images/DSD/4_9.jpg" alt="alt" loading="lazy"></p>
<h4 id="The-Taco-Notation"><a href="#The-Taco-Notation" class="headerlink" title="The Taco Notation"></a>The Taco Notation</h4><p>?</p>
<h2 id="ËÆ≤Â∫ß"><a href="#ËÆ≤Â∫ß" class="headerlink" title="ËÆ≤Â∫ß"></a>ËÆ≤Â∫ß</h2><h3 id="ÈáèÂåñ"><a href="#ÈáèÂåñ" class="headerlink" title="ÈáèÂåñ"></a>ÈáèÂåñ</h3><p>Uniform &amp; Non-uniform</p>
<p>Non-uniform quantization is not efficient for hardware deployment</p>
<p>Symmetric vs Asymmetric Quantization</p>
<p>Quantization Granularity: Layer-wise vs Channel-wise</p>
<p>Dynamic vs Static Quantization</p>
<p>ÈùôÊÄÅÁöÑÊõ¥Â∏∏Áî®ÔºåÂõ†‰∏∫ÈáèÂåñÊú¨Ë∫´Â∞±ÊòØ‰∏∫‰∫ÜÂä†Âø´ÈÄüÂ∫¶ÔºåÂä®ÊÄÅÈáèÂåñÂç¥‰∏ÄËæπËÆ≠Ê®°Âûã‰∏ÄËæπÊõ¥Êñ∞ÈáèÂåñÂå∫Èó¥ÁöÑËåÉÂõ¥ÔºåÂèçËÄåÂáèÊÖ¢‰∫ÜÈÄüÂ∫¶„ÄÇ‰∏çËøá‰πüÊúâ‰ΩøÁî®Âä®ÊÄÅÈáèÂåñÁöÑÊó∂ÂÄôÔºàMid Journey ÁîüÊàêÂõæÂÉèÔºâ„ÄÇ</p>
<p>‰ªÄ‰πàÊòØmixed-precsion quantizationÔºü</p>
</div></section><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>Blither Boom</li><li class="post-copyright-link"><strong>Post link: </strong><a href="https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" title="Êï∞Â≠óÁ≥ªÁªüËÆæËÆ°">https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><span class="icon iconify" data-icon="ri:creative-commons-line"></span><span class="icon iconify" data-icon="ri:creative-commons-by-line"></span><span class="icon iconify" data-icon="ri:creative-commons-nc-line"></span><span class="icon iconify" data-icon="ri:creative-commons-sa-line"></span></a> unless otherwise stated.</li></ul></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2023/09/21/Stochastic-Process/" rel="prev" title="Stochastic-Process"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">Stochastic-Process</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2023/09/20/Digital-Signal-Processing/" rel="next" title="Digital Signal Processing"><span class="post-nav-text">Digital Signal Processing</span><span class="icon iconify" data-icon="ri:arrow-right-s-line"></span></a></div></div></div><div class="hty-card" id="comment"></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 ‚Äì 2025 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> Blither Boom</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v6.2.0</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.11</span></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><script>function initMourn() {
  const date = new Date();
  const today = (date.getMonth() + 1) + "-" + date.getDate()
  const mourn_days = ["4-4","9-18","12-13"]
  if (mourn_days.includes(today)) {
    document.documentElement.style.filter = "grayscale(1)";
  }
}
initMourn();</script></body></html>
<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="Blither Boom"><meta name="copyright" content="Blither Boom"><meta name="generator" content="Hexo 6.2.0"><meta name="theme" content="hexo-theme-yun"><title>æ•°å­—ç³»ç»Ÿè®¾è®¡ | Guo_Yun</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...true?.options,
  });
});</script><link rel="icon" type="image/svg+xml" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"blitherboom812.github.io","root":"/","title":["æ‘¸","ğŸŸ","äºº","çš„","æ—¥","å¸¸"],"version":"1.10.11","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}.","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","fireworks":{"colors":null},"vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/hexo-theme-yun.js" type="module"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap"><meta name="description" content="ç»ªè®ºè½¯ç¡¬ä»¶ååŒï¼Œåˆ¶ä½œæ·±åº¦å­¦ä¹ ç¡¬ä»¶ ç†è®ºè¯¾ï¼Œè®²åº§ï¼ŒLab ä¸“ç”¨ç”µè·¯ ç›®æ ‡ï¼šåšä¸€ä¸ªç±»ä¼¼äºGoogle TPUä¸­çš„æŸè®¡ç®—æ¨¡å— benchmark: ML æ¯4å‘¨ä¸€ä¸ªLabï¼Œæ— æœŸä¸­æœŸæœ« ä½œä¸šï¼š AlexNet Paper Quantization of CNN DNNTraining &amp; InferenceTraining: forward and backward Inference: back">
<meta property="og:type" content="article">
<meta property="og:title" content="æ•°å­—ç³»ç»Ÿè®¾è®¡">
<meta property="og:url" content="https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/index.html">
<meta property="og:site_name" content="Guo_Yun">
<meta property="og:description" content="ç»ªè®ºè½¯ç¡¬ä»¶ååŒï¼Œåˆ¶ä½œæ·±åº¦å­¦ä¹ ç¡¬ä»¶ ç†è®ºè¯¾ï¼Œè®²åº§ï¼ŒLab ä¸“ç”¨ç”µè·¯ ç›®æ ‡ï¼šåšä¸€ä¸ªç±»ä¼¼äºGoogle TPUä¸­çš„æŸè®¡ç®—æ¨¡å— benchmark: ML æ¯4å‘¨ä¸€ä¸ªLabï¼Œæ— æœŸä¸­æœŸæœ« ä½œä¸šï¼š AlexNet Paper Quantization of CNN DNNTraining &amp; InferenceTraining: forward and backward Inference: back">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_1.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_2.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_3.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/2_4.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_1.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_3.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_2.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_4.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_5.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_6.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_7.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_8.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_9.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/3_10.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_1.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_2.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_4.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_5.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_6.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_7.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_8.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_10.jpg">
<meta property="og:image" content="https://blitherboom812.github.io/images/DSD/4_9.jpg">
<meta property="article:published_time" content="2023-09-20T05:33:09.000Z">
<meta property="article:modified_time" content="2023-10-26T00:44:21.000Z">
<meta property="article:author" content="Blither Boom">
<meta property="article:tag" content="note">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blitherboom812.github.io/images/DSD/2_1.jpg"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script><!-- hexo injector head_end start --><link rel="stylesheet" type="text/css" href="/css/latex.css"><link rel="stylesheet" type="text/css" href="/css/fonts.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><script defer src="https://fastly.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js" type="module"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="Blither Boom"><img width="96" loading="lazy" src="/images/avatar.jpg" alt="Blither Boom"></a><div class="site-author-name"><a href="/about/">Blither Boom</a></div><span class="site-name">Guo_Yun</span><sub class="site-subtitle"></sub><div class="site-description"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="/archives/" title="Archives"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:archive-line"></span></span><span class="site-state-item-count">33</span></a></div><div class="site-state-item"><a href="/categories/" title="Categories"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:folder-2-line"></span></span><span class="site-state-item-count">0</span></a></div><div class="site-state-item"><a href="/tags/" title="Tags"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="site-state-item-count">7</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="æ–‡æ¡£"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:settings-line"></span></span></a></nav><hr style="margin-bottom:0.5rem"><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="æˆ‘çš„å°ä¼™ä¼´ä»¬" style="color:dodgerblue"><span class="icon iconify" data-icon="ri:genderless-line"></span></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><span class="icon iconify" data-icon="ri:contrast-2-line"></span></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%AA%E8%AE%BA"><span class="toc-number">1.</span> <span class="toc-text">ç»ªè®º</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DNN"><span class="toc-number">2.</span> <span class="toc-text">DNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Training-amp-Inference"><span class="toc-number">2.1.</span> <span class="toc-text">Training &amp; Inference</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model"><span class="toc-number">2.2.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dataset"><span class="toc-number">2.3.</span> <span class="toc-text">Dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cost-function"><span class="toc-number">2.4.</span> <span class="toc-text">Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimization"><span class="toc-number">2.5.</span> <span class="toc-text">Optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluation"><span class="toc-number">2.6.</span> <span class="toc-text">Evaluation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95%E5%92%8C%E8%AE%A8%E8%AE%BA"><span class="toc-number">2.7.</span> <span class="toc-text">ç½‘ç»œç»“æ„çš„å‘å±•å’Œè®¨è®º</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Quantization"><span class="toc-number">3.</span> <span class="toc-text">Quantization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Fixed-point-and-floating-point-representation"><span class="toc-number">3.1.</span> <span class="toc-text">Fixed-point and floating-point representation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Fixed-Point-arithmetic"><span class="toc-number">3.1.1.</span> <span class="toc-text">Fixed Point arithmetic</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Floating-poing-arithmatic"><span class="toc-number">3.1.2.</span> <span class="toc-text">Floating-poing arithmatic</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hardware-implications"><span class="toc-number">3.2.</span> <span class="toc-text">Hardware implications</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Quantization-for-deep-learning"><span class="toc-number">3.3.</span> <span class="toc-text">Quantization for deep learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Classic-research-for-quantization-methods"><span class="toc-number">3.4.</span> <span class="toc-text">Classic research for quantization methods</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pruning"><span class="toc-number">4.</span> <span class="toc-text">Pruning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sparsity-New-Dimension-For-Efficiency"><span class="toc-number">4.1.</span> <span class="toc-text">Sparsity: New Dimension For Efficiency</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Weight-Sparsity-Pruning"><span class="toc-number">4.1.1.</span> <span class="toc-text">Weight Sparsity: Pruning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Activation-Sparsity-ReLU"><span class="toc-number">4.1.2.</span> <span class="toc-text">Activation Sparsity: ReLU</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Weight-Sparsity-Perspective"><span class="toc-number">4.2.</span> <span class="toc-text">Weight Sparsity Perspective</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Unstructured-Sparsity"><span class="toc-number">4.2.1.</span> <span class="toc-text">Unstructured Sparsity</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Structural-Sparsity"><span class="toc-number">4.2.2.</span> <span class="toc-text">Structural Sparsity</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Unstructured-vs-structured"><span class="toc-number">4.2.3.</span> <span class="toc-text">Unstructured vs. structured</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Frequency-Domain-Sparsity"><span class="toc-number">4.2.4.</span> <span class="toc-text">Frequency-Domain Sparsity</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Activation-Sparsity-Perspective"><span class="toc-number">4.3.</span> <span class="toc-text">Activation Sparsity Perspective</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Inter-Frame-Sparsity"><span class="toc-number">4.3.1.</span> <span class="toc-text">Inter-Frame Sparsity</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ROI-Spasity%EF%BC%9AInput-Dependent"><span class="toc-number">4.3.2.</span> <span class="toc-text">ROI Spasityï¼šInput Dependent</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Leveraging-Sparsity-in-Storage"><span class="toc-number">4.4.</span> <span class="toc-text">Leveraging Sparsity in Storage</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Bitmask-Compression"><span class="toc-number">4.4.1.</span> <span class="toc-text">Bitmask Compression</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Run-Length-Encoding"><span class="toc-number">4.4.2.</span> <span class="toc-text">Run-Length Encoding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Compressed-Sparse-Row-CSR"><span class="toc-number">4.4.3.</span> <span class="toc-text">Compressed Sparse Row (CSR)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Compressed-Sparse-Column-CSC"><span class="toc-number">4.4.4.</span> <span class="toc-text">Compressed Sparse Column (CSC)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#The-Taco-Notation"><span class="toc-number">4.4.5.</span> <span class="toc-text">The Taco Notation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%B2%E5%BA%A7"><span class="toc-number">5.</span> <span class="toc-text">è®²åº§</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8F%E5%8C%96"><span class="toc-number">5.1.</span> <span class="toc-text">é‡åŒ–</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#0078E7;"><link itemprop="mainEntityOfPage" href="https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Blither Boom"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Guo_Yun"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">æ•°å­—ç³»ç»Ÿè®¾è®¡</h1><div class="post-meta"><div class="post-time"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="Created: 2023-09-20 13:33:09" itemprop="dateCreated datePublished" datetime="2023-09-20T13:33:09+08:00">2023-09-20</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-2-line"></span></span> <time title="Modified: 2023-10-26 08:44:21" itemprop="dateModified" datetime="2023-10-26T08:44:21+08:00">2023-10-26</time></div><div class="post-classify"><span class="post-tag"><a class="tag-item" href="/tags/note/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="tag-name">note</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><h2 id="ç»ªè®º"><a href="#ç»ªè®º" class="headerlink" title="ç»ªè®º"></a>ç»ªè®º</h2><p>è½¯ç¡¬ä»¶ååŒï¼Œåˆ¶ä½œæ·±åº¦å­¦ä¹ ç¡¬ä»¶</p>
<p>ç†è®ºè¯¾ï¼Œè®²åº§ï¼ŒLab</p>
<p>ä¸“ç”¨ç”µè·¯</p>
<p>ç›®æ ‡ï¼šåšä¸€ä¸ªç±»ä¼¼äºGoogle TPUä¸­çš„æŸè®¡ç®—æ¨¡å—</p>
<p>benchmark: ML</p>
<p>æ¯4å‘¨ä¸€ä¸ªLabï¼Œæ— æœŸä¸­æœŸæœ«</p>
<p>ä½œä¸šï¼š</p>
<p>AlexNet Paper</p>
<p>Quantization of CNN</p>
<h2 id="DNN"><a href="#DNN" class="headerlink" title="DNN"></a>DNN</h2><h3 id="Training-amp-Inference"><a href="#Training-amp-Inference" class="headerlink" title="Training &amp; Inference"></a>Training &amp; Inference</h3><p>Training: forward and backward</p>
<p>Inference: backward</p>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p><img src="/../images/DSD/2_1.jpg" loading="lazy"></p>
<p>äº”ç±»ç®—å­ï¼š</p>
<p><img src="/../images/DSD/2_2.jpg" loading="lazy"></p>
<p>ç‰¹å¾æå–å™¨ï¼šå·ç§¯å±‚ï¼Œæ± åŒ–å±‚ï¼›</p>
<p>åˆ†ç±»å™¨ï¼šå…¨è¿æ¥å±‚</p>
<p><strong>çº¿æ€§å·ç§¯å±‚</strong></p>
<p>è¾¹ç•Œæ‰©å……(Padding)ï¼šåœ¨å›¾åƒå‘¨å›´æ‰©å±•ä¸€åœˆ0ï¼Œé¿å…å¤šæ¬¡å·ç§¯å¯¼è‡´æ•°æ®å°ºå¯¸è¶Šæ¥è¶Šå°</p>
<p>å·ç§¯æ­¥é•¿(Stride)ï¼šå·ç§¯æ ¸æ¯æ¬¡è·³çš„æ­¥æ•°ã€‚å¯ä»¥ç”¨æ¥è®©æ•°æ®å°ºå¯¸å¿«é€Ÿå˜åŒ–</p>
<p>éçº¿æ€§å‡½æ•°-æ¿€æ´»å‡½æ•°</p>
<p>éçº¿æ€§-æ­£åˆ™åŒ–å‡½æ•°</p>
<p>éçº¿æ€§-æ± åŒ–å‡½æ•°</p>
<p><strong>æ± åŒ–å±‚</strong></p>
<p>æ± åŒ–å±‚å‡å°å›¾ç‰‡çš„å°ºå¯¸ï¼Œä»è€Œå‡å°å‚æ•°çš„æ•°é‡å’Œè®¡ç®—é‡ã€‚</p>
<p>æœ€å¤§æ± åŒ–ï¼šåœ¨æ± åŒ–çª—å£å†…å–æœ€å¤§å€¼ä½œä¸ºè¾“å‡ºã€‚</p>
<ul>
<li>å¤æ‚åº¦ä½ï¼Œç¡¬ä»¶å®ç°å®¹æ˜“</li>
<li>æœ€ä¸ºå¸¸ç”¨</li>
</ul>
<p>å¹³å‡æ± åŒ–ï¼šå–æ± åŒ–çª—å£å†…çš„å¹³å‡å€¼ä½œä¸ºè¾“å‡ºã€‚</p>
 $L^2$  æ± åŒ–æ³•ï¼šå¯¹æ‰€æœ‰çš„æ•°è®¡ç®—å¹³æ–¹åç´¯åŠ æ±‚å’Œå†å¼€å¹³æ–¹ã€‚
<ul>
<li>è®¡ç®—å¤æ‚åº¦é«˜</li>
<li>å‡ ä½•å¹³å‡æ± åŒ–çš„å¤æ‚åº¦æ›´é«˜</li>
</ul>
<p><strong>çº¿æ€§å…¨è¿æ¥å±‚</strong></p>
<p>å°†ç‰¹å¾å›¾æ˜ å°„ä¸ºåˆ†ç±»ç»“æœ</p>
<p><strong>Softmax å±‚</strong></p>
<p>æœ‰çš„æ¨¡å‹åœ¨è¾“å‡ºå±‚ä½¿ç”¨softmaxå¯¹è¾“å‡ºè¿›è¡Œå½’ä¸€åŒ–ï¼š</p>

$$
f(z_j) = \dfrac{e^{z_j}}{\sum_{i = 0}^n e^{z_j}}
$$


<ul>
<li>è¾“å…¥å’Œè¾“å‡ºè§„æ¨¡ç›¸åŒ</li>
<li>å½’ä¸€åŒ–è®¡ç®—ï¼Œè®©è¾ƒå¤§çš„å€¼å‡¸æ˜¾ï¼Œè®©è¾ƒå°çš„å€¼è¢«æŠ‘åˆ¶ï¼Œä»è€Œå†³å®šåˆ†ç±»æ¦‚ç‡</li>
</ul>
<p><strong>å·ç§¯ç¥ç»ç½‘ç»œçš„æ€»ä½“ç»“æ„</strong></p>
<h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>æ•°æ®é›†çš„å»ºç«‹ï¼šæ•°æ®é‡‡é›†ï¼Œæ•°æ®æ ‡ç­¾ï¼Œæ•°æ®æ¸…æ´—ï¼Œæ•°æ®å¢å¼ºï¼Œæ•°æ®åˆ†å‰²</p>
<h3 id="Cost-function"><a href="#Cost-function" class="headerlink" title="Cost function"></a>Cost function</h3><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><ul>
<li>æ¢¯åº¦ä¸‹é™æ³•</li>
<li>SGD</li>
<li>åŠ¨é‡æ³•ï¼šè®¡ç®—è¿‡å»çš„å¹³å‡æ¢¯åº¦</li>
<li>AdaGradæ³•ï¼šç´¯åŠ æ¢¯åº¦æ–¹å·®</li>
<li>RMSPropï¼šæŒ‰æ—¶é—´é™ä½å­¦ä¹ ç‡</li>
<li>Adam ç®—æ³•ï¼šæŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡å€¼è®¡ç®—æ¢¯åº¦åŠ¨é‡å’ŒäºŒæ¬¡çŸ©</li>
<li>SGDç®€å•ï¼Œä½†æ˜¯è®­ç»ƒè¿‡ç¨‹è¾¹é•¿ï¼Œè‡ªé€‚åº”ç®—æ³•ä¼šæ›´é«˜æ•ˆ</li>
</ul>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p><strong>å›å½’é—®é¢˜æŒ‡æ ‡</strong></p>
<p>PSNR</p>

$$
PSNR = 10 \cdot \log_{10}(\frac{MAX_I^2}{MSE})
$$


<p><strong>åˆ†ç±»é—®é¢˜æŒ‡æ ‡</strong></p>
<ul>
<li>Top1 accuracy</li>
<li>Top5 accuracy</li>
</ul>
<p><strong>IoU</strong></p>
<p>Intersection of Union?</p>

$$
\text{IoU} = \frac{|A\cap B|}{|A \cup B|}
$$


<p><strong>æ£€æµ‹ä»»åŠ¡è¯„ä»·æŒ‡æ ‡ mAP</strong></p>
<p>mean average precision</p>
<p>çœŸé˜³æ€§TP: é¢„æµ‹ä¸ºçœŸï¼Œå®é™…ä¸ºçœŸ</p>
<p>å‡é˜³æ€§FPï¼šé¢„æµ‹ä¸ºçœŸï¼Œå®é™…ä¸ºå‡</p>
<p>å‡é˜´æ€§FNï¼šé¢„æµ‹ä¸ºå‡ï¼Œå®é™…ä¸ºçœŸ</p>
<p><strong>æŸ¥å…¨ç‡ï¼ˆå¬å›ç‡ï¼ŒRecallï¼‰å’ŒæŸ¥å‡†ç‡ï¼ˆå‡†ç¡®ç‡ï¼ŒPrecisionï¼‰</strong></p>

$$
\text{Precision} = \frac{TP}{TP + FP}\\
\text{Recall} = \frac{TP}{TP + FN}
$$


<p>ç½®ä¿¡åº¦è¡¡é‡çš„æ˜¯æ¨¡å‹è®¤ä¸ºæœ‰æ•ˆçš„è‡ªä¿¡ç¨‹åº¦ã€‚æˆ‘ä»¬å…ˆå°†ç»“æœæŒ‰ç…§ç½®ä¿¡åº¦ä»é«˜åˆ°ä½æ’åºã€‚</p>
<p>mAPæ˜¯ä¸åŒæŸ¥å…¨ç‡ä¸‹ï¼Œæœ€é«˜æŸ¥å‡†ç‡çš„å¹³å‡å€¼ã€‚</p>
<h3 id="ç½‘ç»œç»“æ„çš„å‘å±•å’Œè®¨è®º"><a href="#ç½‘ç»œç»“æ„çš„å‘å±•å’Œè®¨è®º" class="headerlink" title="ç½‘ç»œç»“æ„çš„å‘å±•å’Œè®¨è®º"></a>ç½‘ç»œç»“æ„çš„å‘å±•å’Œè®¨è®º</h3><p><strong>åˆ†ç±»ä»»åŠ¡</strong></p>
<p>AlexNet</p>
<ul>
<li>ä½¿ç”¨å¤šä¸ªå·ç§¯å±‚ï¼Œæœ‰æ•ˆæå–å›¾åƒç‰¹å¾</li>
<li>ReLU æé«˜è®­ç»ƒé€Ÿåº¦</li>
<li>Dropoutã€æ•°æ®å¢å¼ºæ‰©å¤§è®­ç»ƒé›†ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ</li>
</ul>
<p>VGG</p>
<ul>
<li>ä½¿ç”¨ 3 * 3 çš„å·ç§¯æ ¸å–ä»£ AlexNet çš„å¤§å·ç§¯æ ¸<ul>
<li>æå‡æ”¶æ•›é€Ÿåº¦</li>
<li>å‚æ•°é‡æ›´å°‘</li>
<li>å¯ä»¥æ„å»ºæ›´æ·±çš„ç½‘ç»œï¼Œæœ‰æ›´å¤šçš„éçº¿æ€§å˜æ¢ï¼Œè¿˜æœ‰æ›´å¼ºçš„è¡¨å¾èƒ½åŠ›</li>
</ul>
</li>
<li>å‚æ•°é¢„åˆå§‹åŒ–ç­–ç•¥</li>
</ul>
<p>ResNet</p>
<p>?</p>
<p><strong>ç›®æ ‡æ£€æµ‹</strong></p>
<p>Two-stage v.s. One-stage</p>
<p><strong>Two-stage</strong></p>
<p>å…ˆç”»æ¡†ï¼Œå†åˆ†ç±»</p>
<p>MS CoCo Dataset</p>
<ul>
<li>ç”¨çš„æœ€å¤šçš„è¿˜æ˜¯ç›®æ ‡æ£€æµ‹ä»»åŠ¡</li>
</ul>
<p>R-CNN</p>
<ul>
<li>è¾“å…¥å›¾åƒ</li>
<li>æå–å€™é€‰æ¡†</li>
<li>æ¯ä¸€ä¸ªå€™é€‰æ¡†æå–å•ç‹¬çš„ç‰¹å¾</li>
<li>è¿›è¡Œåˆ†ç±»</li>
</ul>
<p>Fast R-CNN</p>
<ul>
<li>è¾“å…¥å›¾åƒ</li>
<li>ä¸€æ¬¡ç‰¹å¾æå–</li>
<li>æå–å€™é€‰æ¡†</li>
<li>è¿›è¡Œåˆ†ç±»</li>
</ul>
<p>Faster R-CNN</p>
<ul>
<li>è¾“å…¥å›¾åƒ</li>
<li>ä¸€æ¬¡ç‰¹å¾æå–</li>
<li>æå–å€™é€‰æ¡†</li>
<li>è¿›è¡Œåˆ†ç±»</li>
</ul>
<p><strong>One-stage</strong></p>
<p>YOLO</p>
<p>äº”ä»£å‘å±•ï¼Œæœ€å¹¿æ³›çš„ç›®æ ‡æ£€æµ‹ç®—æ³•</p>
<p>å¯¹äºæ¯ä¸€ä¸ªåƒç´ ï¼Œéƒ½ä¼šè¾“å‡ºä¸€ä¸ªå¯¹åº”çš„ç‰¹å¾å‘é‡ï¼ŒåŒ…å«ï¼š</p>
<ul>
<li>äºŒåˆ†ç±»ï¼šæ˜¯ç‰©ä½“ä¸­å¿ƒçš„ç½®ä¿¡åº¦</li>
<li>å›å½’ï¼šåç¦»ç‰©ä½“ä¸­å¿ƒçš„é•¿åº¦  $\Delta x$  å’Œ  $\Delta y$ </li>
<li>åˆ†ç±»ï¼šå¯¹åº”çš„ç‰©ä½“åˆ†ç±»ä»¥åŠç½®ä¿¡åº¦</li>
<li>å›å½’ï¼šè¯¥åƒç´ æ‰€ä»£è¡¨çš„ç‰©ä½“çš„é•¿å®½ï¼ŒYOLOæœ‰ä¸€äº›åŸºç¡€æ¡†(anchor)ï¼Œè¾“å‡ºå€¼æ˜¯ç›¸å¯¹åŸºç¡€æ¡†çš„å½¢å˜  $\Delta h$  å’Œ  $\Delta w$ </li>
</ul>
<p><strong>NMS (Non-Maximum Suppression)</strong><br>Bounding boxes for one instance may overlap.<br>Method: For each type, use NMS to eliminate redundant bounding boxes (greedy approach).<br>Workflow:</p>
<ol>
<li>Sort candidate bounding boxes by classification confidence.</li>
<li>Adding the boxes b with most confidence to output list, and delete it from the candidate boxes.</li>
<li>Calculate IoU between b and other boxes bi. If &gt; threshold, delete bi.</li>
<li>Repeat until no candidate bounding boxes.</li>
</ol>
<p><strong>åºåˆ—æ¨¡å‹ï¼ˆSerial Modelï¼‰</strong></p>
<p>to process Speech, text, video, audio, etc.</p>
<p>Feature: </p>
<ol>
<li>The data input is in the time sequence.</li>
<li>There is a correlation between the data before and after.</li>
</ol>
<p>So the model should have the ability to â€œstoreâ€ information.</p>
<p>Speech dataset: TIMIT</p>
<ol>
<li>It consists of recordings of 630 speakers of 8 dialects of American English each reading 10 phonetically-rich sentences.</li>
<li>It also comes with the word and phone-level transcriptions of the speech.</li>
</ol>
<p>Video dataset: DAVIS</p>
<p>The Densely Annotation Video Segmentation dataset (DAVIS) is a high quality and high resolution densely annotated video segmentation dataset under two resolutions, 480p and 1080p.</p>
<p>There are 50 video sequences with 3455 densely annotated frames in pixel level. 30 videos with 2079 frames are for training and 20 videos with 1376 frames are for validation.</p>
<p>NLP dataset: GLUE</p>
<p>General Language Understanding Evaluation (GLUE) benchmark: Standard split of data totrain, validation, test, where labels for the test set is only held in the server.</p>
<ul>
<li>Sentence pair tasks<ul>
<li>MNLI, Multi-Genre Natural Language Inference</li>
<li>QQP, Ouora Ouestion Pairs</li>
<li>QNLI, Ouestion Natural Language Inference</li>
<li>STS-B The Semantic Textual Similarity Benchmark</li>
<li>MRPC Microsoft Research Paraphrase Corpus</li>
<li>RTE Recognizing Textual Entailment</li>
<li>WNLI Winograd NLI is a small natural language inference</li>
</ul>
</li>
<li>datasetSingle sentence classification<ul>
<li>SST-2 The Stanford Sentiment Treebank</li>
<li>CoLA The Corpus of Linguistic Acceptability</li>
</ul>
</li>
</ul>
<p><strong>Models</strong></p>
<p><strong>RNN: Recurrent Neural Network</strong></p>
<ul>
<li>one to one </li>
<li>one to many</li>
<li>many to one</li>
<li>many to many</li>
<li>many to many</li>
</ul>
<p><img src="/../images/DSD/2_3.jpg" loading="lazy"></p>
<p>æŸå¤±å‡½æ•°çš„è®¡ç®—ï¼š</p>
<p>å•ä¸ªæ—¶åˆ»ï¼š</p>

$$
L^{(t)} = -\mathbf y^{(t)} \ln \mathbf {\hat {y}}^{(t)}
$$


<p>æ•´ä¸ªåºåˆ—ï¼š</p>

$$
L = \sum\limits_{t=1}^{\tau}L^{(t)} = - \sum\limits_{t=1}^{\tau} \mathbf y^{(t)} \ln \mathbf {\hat {y}}^{(t)}
$$


<p>ç„¶åå¯æ±‚æ¢¯åº¦ï¼š</p>
<p><img src="/../images/DSD/2_4.jpg" alt="alt" loading="lazy"></p>
<p>å¾ªç¯ç¥ç»ç½‘ç»œå­˜åœ¨æ¢¯åº¦çˆ†ç‚¸æˆ–æ¢¯åº¦æ¶ˆå¤±ï¼Œå› æ­¤æ— æ³•å¤„ç†é•¿æœŸçš„ä¾èµ–å…³ç³»ã€‚</p>
<p><strong>LSTM: Solving the Gradient</strong></p>
<p><strong>Transformer</strong></p>
<p>Self attention:</p>

$$
\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK}{\sqrt d_k})V
$$


<h2 id="Quantization"><a href="#Quantization" class="headerlink" title="Quantization"></a>Quantization</h2><h3 id="Fixed-point-and-floating-point-representation"><a href="#Fixed-point-and-floating-point-representation" class="headerlink" title="Fixed-point and floating-point representation"></a>Fixed-point and floating-point representation</h3><h4 id="Fixed-Point-arithmetic"><a href="#Fixed-Point-arithmetic" class="headerlink" title="Fixed Point arithmetic"></a>Fixed Point arithmetic</h4>
$$
\underbrace{0}_{\text{Sign bit}}\ \ \underbrace{10\dots01}_{n\text{ bit integer part}}\ \ .\underbrace{10\dots01}_{m\text{ bit fractional part}}
$$


<p><strong>Fixed point with slope and bias</strong></p>
<p>apply a linear transform on fixed point:</p>

$$
y = s*x + z
$$




<h4 id="Floating-poing-arithmatic"><a href="#Floating-poing-arithmatic" class="headerlink" title="Floating-poing arithmatic"></a>Floating-poing arithmatic</h4><p><img src="/../images/DSD/3_1.jpg" alt="alt" loading="lazy"></p>
<p><strong>IEEE 754 Floating Point Standard</strong></p>
<ul>
<li>Called Biased Notation, where bias is number subtracted to get real number. </li>
<li>IEEE 754 uses bias of 127 for single precision, 1023 for double precision.</li>
</ul>
<p><img src="/../images/DSD/3_3.jpg" alt="alt" loading="lazy"></p>

$$
(-1)^S \times (1 + m) \times 2^{(E - \text{Bias})}
$$


<p><strong>fp15(helf precision)</strong></p>
<p><img src="/../images/DSD/3_2.jpg" alt="alt" loading="lazy"></p>
<h3 id="Hardware-implications"><a href="#Hardware-implications" class="headerlink" title="Hardware implications"></a>Hardware implications</h3><p><img src="/../images/DSD/3_4.jpg" alt="alt" loading="lazy"></p>
<p>åŠ æ³•ä¸‹å®šç‚¹æ•°æ¯”æµ®ç‚¹æ•°åŠŸè€—å°å¾—å¤šï¼Œä½†æ˜¯ä¹˜æ³•ä¸‹å®šç‚¹æ•°å’Œæµ®ç‚¹æ•°çš„æ€§èƒ½å·®ä¸å¤šã€‚</p>
<p>Low bit Fixed-point representations on digital system</p>
<h3 id="Quantization-for-deep-learning"><a href="#Quantization-for-deep-learning" class="headerlink" title="Quantization for deep learning"></a>Quantization for deep learning</h3><ul>
<li>Post-training quantization</li>
<li>Quantization-aware training</li>
</ul>
<p><strong>Post-training quantization</strong></p>

$$
r = S(Q - Z)\\
OA[i, k] =\sum\limits_{j=1}^{N}(W[i, j] * IA[j, k])\\
q_{OA}^{(i, k)} = Z_{OA} + \frac{S_W * S_{IA}}{S_{OA}}\sum\limits_{j=1}^{N} (q_W^{(i, j)} * q_{IA}^{(j, k)})
$$


<p>Choose the optimal threshold</p>
<p>No saturation is bad </p>
<h3 id="Classic-research-for-quantization-methods"><a href="#Classic-research-for-quantization-methods" class="headerlink" title="Classic research for quantization methods"></a>Classic research for quantization methods</h3><p><strong>Basic structure</strong></p>
<p>Weight Quantization &amp; Activation Quantization</p>
<p><img src="/../images/DSD/3_5.jpg" alt="alt" loading="lazy"></p>
<p><strong>Dorefa Net</strong></p>
<ul>
<li>quantization for gradient</li>
<li>normalize data to ensure the data distribution not change after quantization</li>
<li>uniform noise to offset the quantization noise for gradient</li>
<li>replace accumulate with bitcount operation</li>
<li>result is that gradient precision is most sensitive in TAQ(G &gt; A &gt; W)</li>
</ul>
<p><strong>INQ</strong></p>
<ul>
<li>quantization first half and freeze the other, then unfreeze other to train normally</li>
<li>exchange the first half and second half, and repeat above</li>
</ul>
<p><img src="/../images/DSD/3_6.jpg" alt="alt" loading="lazy"></p>
<p><strong>Pact</strong></p>
<ul>
<li>clipping the activation before quantization is better</li>
</ul>

$$
PACT(x) = 0.5(|x| - |x - \alpha| + \alpha) = \begin{cases}
    0, x&lt;0,\\
    x, 0\le x \lt \alpha,\\
    \alpha, x \ge \alpha 
\end{cases}
$$


<p>Different layers need different Î±</p>
<p>alpha should be learnable</p>
<p><strong>Outlier quantization</strong></p>
<ul>
<li>Use different quantized bits to quantize different weights. Some weight can have higher precision while others not.</li>
</ul>
<p><img src="/../images/DSD/3_7.jpg" alt="alt" loading="lazy"></p>
<p><strong>Quantization interval learning</strong></p>
<ul>
<li>Most of the weights are very small. Minor weights can have too large value.</li>
</ul>
<p><img src="/../images/DSD/3_8.jpg" alt="alt" loading="lazy"></p>
<p>a should be pruned, c should be clipped, only b worths quantizing.</p>
<p><strong>Binary neural networks (BNN)</strong></p>
<ul>
<li>Networks with weights composed of {-1, 1}</li>
</ul>
<p><img src="/../images/DSD/3_9.jpg" alt="alt" loading="lazy"></p>
<ul>
<li>è®¡ç®—æ—¶é•¿è·Ÿç²¾åº¦æœ‰å¹³æ–¹åæ¯”çš„å…³ç³»ï¼Œä¼˜åŒ–æ˜¯å¹³æ–¹çš„</li>
<li>å­˜å‚¨è·Ÿç²¾åº¦åªæœ‰çº¿æ€§çš„å…³ç³»ï¼Œä¼˜åŒ–æ˜¯çº¿æ€§çš„ï¼Œç”±äºBNN bitæ•°å°‘ï¼Œæ€»çš„å‚æ•°é‡æ›´å¤šï¼Œå®é™…ä¸Šå­˜å‚¨æ²¡æ€ä¹ˆä¼˜åŒ–</li>
<li>BNN å¤§å¹…ä¼˜åŒ–äº†è®¡ç®—ï¼Œä½†æ˜¯å­˜å‚¨æ²¡å˜ï¼Œæ­¤æ—¶å­˜å‚¨æˆä¸ºäº†ç“¶é¢ˆ</li>
</ul>
<p><strong>State-of-the-art hardware support for low<br>precision DNNs</strong></p>
<p><img src="/../images/DSD/3_10.jpg" alt="alt" loading="lazy"></p>
<h2 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h2><p>ç¨€ç–çŸ©é˜µæ˜¯æŒ‡çŸ©é˜µä¸­å¤§éƒ¨åˆ†å…ƒç´ éƒ½æ˜¯0çš„çŸ©é˜µã€‚è·å¾—ç¨€ç–çŸ©é˜µï¼Œæœ‰åŠ©äºåŠ é€Ÿè®­ç»ƒå’Œæ¨ç†é€Ÿåº¦ã€‚</p>
<h3 id="Sparsity-New-Dimension-For-Efficiency"><a href="#Sparsity-New-Dimension-For-Efficiency" class="headerlink" title="Sparsity: New Dimension For Efficiency"></a>Sparsity: New Dimension For Efficiency</h3><p>ç¨€ç–æ€§çš„æ¥æºï¼š</p>
<ul>
<li>å‰ªæ - æƒé‡</li>
<li>ReLU - æ¿€æ´»</li>
<li>Domain Specific</li>
</ul>
<h4 id="Weight-Sparsity-Pruning"><a href="#Weight-Sparsity-Pruning" class="headerlink" title="Weight Sparsity: Pruning"></a>Weight Sparsity: Pruning</h4><p>å‰ªææ–¹æ³•ï¼š</p>
<ul>
<li>å¾ˆå¤šå‚æ•°å…¶å®æ˜¯å¾ˆæ¥è¿‘0çš„æ•°</li>
<li>å› æ­¤ï¼Œä½äºæŸä¸€é˜ˆå€¼æ—¶ï¼Œç›´æ¥å°†å…¶èµ‹0.ä½†æ˜¯è¿™æ ·ä¼šå½±å“ç²¾åº¦ã€‚</li>
<li>è¿˜å¯ä»¥ç”¨æ·»åŠ æ­£åˆ™é¡¹çš„æ–¹æ³•ï¼ˆWeight decayï¼‰ï¼š<ul>
<li> $CF = MSE_{train} + \lambda \sum_i w_i^2$ </li>
<li> $CF = MSE_{train} + \lambda \sum_i |w_i|$ </li>
</ul>
</li>
</ul>
<h4 id="Activation-Sparsity-ReLU"><a href="#Activation-Sparsity-ReLU" class="headerlink" title="Activation Sparsity: ReLU"></a>Activation Sparsity: ReLU</h4><h3 id="Weight-Sparsity-Perspective"><a href="#Weight-Sparsity-Perspective" class="headerlink" title="Weight Sparsity Perspective"></a>Weight Sparsity Perspective</h3><p>ä¸åŒçš„ç¨€ç–ç¨‹åº¦ï¼š</p>
<p><img src="/../images/DSD/4_1.jpg" alt="alt" loading="lazy"></p>
<h4 id="Unstructured-Sparsity"><a href="#Unstructured-Sparsity" class="headerlink" title="Unstructured Sparsity"></a>Unstructured Sparsity</h4><p>Han Song@NIPS2015 çš„å‰ªæç­–ç•¥ï¼š</p>
<p><img src="/../images/DSD/4_2.jpg" alt="alt" loading="lazy"></p>
<p>ç¬¬ä¸€è½®è®­ç»ƒåï¼Œå°†æ‰€æœ‰æ¥è¿‘0çš„ç¥ç»å…ƒå‰ªé™¤ï¼Œå†é‡æ–°å¯¹å‰©ä¸‹çš„è¿›è¡Œè®­ç»ƒ(retrain)ã€‚</p>
<ul>
<li>å‹ç¼©æ¯”å¾ˆé«˜ï¼Œè€Œå‡†ç¡®ç‡å‡ ä¹ä¸ä¸‹é™</li>
<li>å¯¹äºç¡¬ä»¶å¹¶ä¸å‹å¥½ï¼Œè™½ç„¶æœ‰å¾ˆå¤š0ï¼Œä½†æ˜¯ç¡¬ä»¶ä¸Šæ²¡æ³•æŠŠå®ƒä»¬å‹ç¼©æ‰ã€‚</li>
<li>è®¡ç®—é€Ÿåº¦å¹¶æ²¡æœ‰æé«˜ï¼Œç”šè‡³é™ä½äº†</li>
</ul>
<h4 id="Structural-Sparsity"><a href="#Structural-Sparsity" class="headerlink" title="Structural Sparsity"></a>Structural Sparsity</h4><p><strong>SSL å‰ªæç­–ç•¥(Structured weight pruning)</strong></p>
<ul>
<li>ä¸æ˜¯å‰ªä¸€ä¸ªç¥ç»å…ƒï¼Œè€Œæ˜¯æŠŠä¸€è¡Œ&#x2F;ä¸€åˆ—&#x2F;ä¸€ä¸ªé€šé“å…¨éƒ¨å‰ªæ‰ã€‚ï¼ˆä¸è¿‡ï¼Œä¸æ˜¯çœŸçš„å‰ªæï¼Œè€Œæ˜¯ä¿®æ”¹ä»£ä»·å‡½æ•°çš„æ­£åˆ™é¡¹ï¼‰</li>
<li>è§„åˆ™åŒ–çš„å‰ªæå¯¹ç¡¬ä»¶æ›´åŠ å‹å¥½</li>
</ul>
<p>ä»£ä»·å‡½æ•°çš„è¡¨è¾¾å¼ï¼š</p>
<p><img src="/../images/DSD/4_4.jpg" alt="alt" loading="lazy"></p>
<ul>
<li>æˆåŠŸåœ¨ä¸€èˆ¬è®¾å¤‡ä¸ŠåŠ é€Ÿäº†</li>
</ul>
<p><strong>Pattern Pruning</strong></p>
<p>ç ”ç©¶å·ç§¯æ ¸å†…é0çš„æƒé‡æ˜¯å¦‚ä½•åˆ†å¸ƒçš„ã€‚</p>
<p><img src="/../images/DSD/4_5.jpg" alt="alt" loading="lazy"></p>
<p>å¦‚æœæŸä¸ªâ€œåˆ†å¸ƒæ¨¡å¼â€åå¤çš„å‡ºç°ï¼Œå°±å¯ä»¥å¯¹å®ƒè¿›è¡Œå‹ç¼©å­˜å‚¨ï¼š</p>
<p><img src="/../images/DSD/4_6.jpg" alt="alt" loading="lazy"></p>
<p>è¿™ä¸€æ–¹é¢çš„æˆæœï¼š</p>
<ul>
<li>Flexible-Length Pattern Pruningï¼šç”¨æ¦‚ç‡ç»Ÿè®¡æ–¹æ³•å¾—åˆ°ç‰¹å®šçš„æ¨¡å¼</li>
<li>Fixed-Length Pattern Pruningï¼šçº¦æŸäº†æ¨¡å¼é‡Œé¢é0å…ƒç´ çš„ä¸ªæ•°</li>
</ul>
<h4 id="Unstructured-vs-structured"><a href="#Unstructured-vs-structured" class="headerlink" title="Unstructured vs. structured"></a>Unstructured vs. structured</h4><p>å‰ªææŠ€æœ¯åŸºæœ¬ä¸Šå·²ç»æˆç†Ÿï¼š</p>
<ul>
<li>Non-stuctured pruning<ul>
<li>é«˜å‹ç¼©ç‡</li>
<li>åªèƒ½åœ¨ç‰¹å®šè®¾å¤‡ä¸Šæ¥é™ä½åŠŸè€—ï¼Œä½†æ˜¯æ€§èƒ½å…¶å®æ²¡ä»€ä¹ˆæå‡</li>
</ul>
</li>
<li>Structured pruning<ul>
<li>å¯¹ç¡¬ä»¶æ›´å‹å¥½</li>
<li>ä½å‹ç¼©ç‡</li>
</ul>
</li>
</ul>
<p>ï¼ˆå‹ç¼©ç‡æŒ‡çš„æ˜¯è®­ç»ƒçš„é€Ÿåº¦ï¼Œå³å°†æ•°æ®â€œå‹ç¼©â€ä¸ºç¥ç»ç½‘ç»œçš„å†…è•´çŸ¥è¯†çš„èƒ½åŠ›ã€‚ï¼‰</p>
<h4 id="Frequency-Domain-Sparsity"><a href="#Frequency-Domain-Sparsity" class="headerlink" title="Frequency-Domain Sparsity"></a>Frequency-Domain Sparsity</h4><p>é‡‡ç”¨å¾ªç¯çš„å·ç§¯æ ¸</p>
<ul>
<li>å› ä¸ºå¾ªç¯å‡ºç°çš„å…ƒç´ ï¼Œå­˜å‚¨é™ä½</li>
<li>è®¡ç®—ç­‰ä»·ä¸ºå¾ªç¯å·ç§¯ï¼Œå¯ä»¥è½¬æ¢ä¸º FFT é¢‘åŸŸç›¸ä¹˜ï¼Œè·å¾—æ›´é«˜æ•ˆçš„è®¡ç®—</li>
</ul>
<h3 id="Activation-Sparsity-Perspective"><a href="#Activation-Sparsity-Perspective" class="headerlink" title="Activation Sparsity Perspective"></a>Activation Sparsity Perspective</h3><h4 id="Inter-Frame-Sparsity"><a href="#Inter-Frame-Sparsity" class="headerlink" title="Inter-Frame Sparsity"></a>Inter-Frame Sparsity</h4><p>ä¸€æ®µåºåˆ—çš„ç›¸é‚»å¸§ä¹‹é—´å…·æœ‰ç›¸ä¼¼æ€§ã€‚å› æ­¤åªéœ€è¦å­˜å‚¨å¸§ä¸å¸§ä¹‹é—´çš„å·®å€¼å°±è¡Œäº†ã€‚</p>
<p>Yuan Z@ISSCC 2020 çš„ç»“è®ºï¼š</p>
<ul>
<li>å·®åˆ†å¸§å¹¶ä¸æ˜¯ç¨€ç–çš„</li>
<li>å·®åˆ†å¸§çš„æ•°å€¼é›†ä¸­äºä½çš„bitä½ï¼Œåˆ†å¸ƒé›†ä¸­</li>
<li>è€Œé«˜bitä½å¾ˆå¤šéƒ½æ˜¯0ï¼Œéå¸¸ç¨€ç–</li>
</ul>
<p>å› æ­¤ï¼Œå¯ä»¥å¯¹ä½ bit ä½å’Œé«˜ bit ä½æ‹†åˆ†å¤„ç†ã€‚</p>
<h4 id="ROI-Spasityï¼šInput-Dependent"><a href="#ROI-Spasityï¼šInput-Dependent" class="headerlink" title="ROI Spasityï¼šInput Dependent"></a>ROI Spasityï¼šInput Dependent</h4><p>ROI: Region of Interest</p>
<p>å›¾åƒé‡ŒåŒ…å«çš„ä¿¡æ¯ï¼Œæœ‰çš„ä¸°å¯Œï¼Œæœ‰çš„è´«ä¹ï¼Œæœ‰çš„å®¹æ˜“è¯†åˆ«ï¼Œæœ‰çš„å¾ˆéš¾è¯†åˆ«ã€‚</p>
<ul>
<li>ç¨ å¯†çš„è¾“å…¥ç”¨å¤§æ ¸ï¼Œç¨€ç–çš„è¾“å…¥ç”¨å°æ ¸ï¼Ÿ</li>
</ul>
<p>åŸºäºä¸åŒçš„è¾“å…¥ï¼Œé‡‡ç”¨ä¸åŒçš„ç½‘ç»œï¼š</p>
<ul>
<li>å›¾åƒä¸­éš¾åº¦é«˜çš„åŒºåŸŸé€šè¿‡æ›´æ·±çš„ç½‘ç»œå±‚</li>
<li>éš¾åº¦ä½çš„åŒºåŸŸé€šè¿‡æ›´æµ…çš„ç½‘ç»œå±‚</li>
</ul>
<h3 id="Leveraging-Sparsity-in-Storage"><a href="#Leveraging-Sparsity-in-Storage" class="headerlink" title="Leveraging Sparsity in Storage"></a>Leveraging Sparsity in Storage</h3><p>å¦‚ä½•å‹ç¼©ç¨€ç–çŸ©é˜µçš„å­˜å‚¨ç©ºé—´ï¼Ÿ</p>
<h4 id="Bitmask-Compression"><a href="#Bitmask-Compression" class="headerlink" title="Bitmask Compression"></a>Bitmask Compression</h4><p><img src="/../images/DSD/4_7.jpg" alt="alt" loading="lazy"></p>
<h4 id="Run-Length-Encoding"><a href="#Run-Length-Encoding" class="headerlink" title="Run-Length Encoding"></a>Run-Length Encoding</h4><p>æ¸¸ç¨‹ç¼–ç <br>(matlabè­¦å‘Š)</p>
<p><img src="/../images/DSD/4_8.jpg" alt="alt" loading="lazy"></p>
<h4 id="Compressed-Sparse-Row-CSR"><a href="#Compressed-Sparse-Row-CSR" class="headerlink" title="Compressed Sparse Row (CSR)"></a>Compressed Sparse Row (CSR)</h4><p><img src="/../images/DSD/4_10.jpg" alt="alt" loading="lazy"></p>
<h4 id="Compressed-Sparse-Column-CSC"><a href="#Compressed-Sparse-Column-CSC" class="headerlink" title="Compressed Sparse Column (CSC)"></a>Compressed Sparse Column (CSC)</h4><p><img src="/../images/DSD/4_9.jpg" alt="alt" loading="lazy"></p>
<h4 id="The-Taco-Notation"><a href="#The-Taco-Notation" class="headerlink" title="The Taco Notation"></a>The Taco Notation</h4><p>?</p>
<h2 id="è®²åº§"><a href="#è®²åº§" class="headerlink" title="è®²åº§"></a>è®²åº§</h2><h3 id="é‡åŒ–"><a href="#é‡åŒ–" class="headerlink" title="é‡åŒ–"></a>é‡åŒ–</h3><p>Uniform &amp; Non-uniform</p>
<p>Non-uniform quantization is not efficient for hardware deployment</p>
<p>Symmetric vs Asymmetric Quantization</p>
<p>Quantization Granularity: Layer-wise vs Channel-wise</p>
<p>Dynamic vs Static Quantization</p>
<p>é™æ€çš„æ›´å¸¸ç”¨ï¼Œå› ä¸ºé‡åŒ–æœ¬èº«å°±æ˜¯ä¸ºäº†åŠ å¿«é€Ÿåº¦ï¼ŒåŠ¨æ€é‡åŒ–å´ä¸€è¾¹è®­æ¨¡å‹ä¸€è¾¹æ›´æ–°é‡åŒ–åŒºé—´çš„èŒƒå›´ï¼Œåè€Œå‡æ…¢äº†é€Ÿåº¦ã€‚ä¸è¿‡ä¹Ÿæœ‰ä½¿ç”¨åŠ¨æ€é‡åŒ–çš„æ—¶å€™ï¼ˆMid Journey ç”Ÿæˆå›¾åƒï¼‰ã€‚</p>
<p>ä»€ä¹ˆæ˜¯mixed-precsion quantizationï¼Ÿ</p>
</div></section><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>Blither Boom</li><li class="post-copyright-link"><strong>Post link: </strong><a href="https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/" title="æ•°å­—ç³»ç»Ÿè®¾è®¡">https://blitherboom812.github.io/2023/09/20/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><span class="icon iconify" data-icon="ri:creative-commons-line"></span><span class="icon iconify" data-icon="ri:creative-commons-by-line"></span><span class="icon iconify" data-icon="ri:creative-commons-nc-line"></span><span class="icon iconify" data-icon="ri:creative-commons-sa-line"></span></a> unless otherwise stated.</li></ul></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2023/09/21/Stochastic-Process/" rel="prev" title="Stochastic-Process"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">Stochastic-Process</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2023/09/20/Digital-Signal-Processing/" rel="next" title="Digital Signal Processing"><span class="post-nav-text">Digital Signal Processing</span><span class="icon iconify" data-icon="ri:arrow-right-s-line"></span></a></div></div></div><div class="hty-card" id="comment"></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 â€“ 2026 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> Blither Boom</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v6.2.0</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.11</span></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><script>function initMourn() {
  const date = new Date();
  const today = (date.getMonth() + 1) + "-" + date.getDate()
  const mourn_days = ["4-4","9-18","12-13"]
  if (mourn_days.includes(today)) {
    document.documentElement.style.filter = "grayscale(1)";
  }
}
initMourn();</script></body></html>
{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/images/csapp1.jpg","path":"images/csapp1.jpg","modified":0,"renderable":0},{"_id":"source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":0},{"_id":"source/images/pht.png","path":"images/pht.png","modified":0,"renderable":0},{"_id":"source/images/DSA/Dijkstra.jpg","path":"images/DSA/Dijkstra.jpg","modified":0,"renderable":0},{"_id":"source/images/DSA/Duopule.jpg","path":"images/DSA/Duopule.jpg","modified":0,"renderable":0},{"_id":"source/images/DSA/Kruskal.jpg","path":"images/DSA/Kruskal.jpg","modified":0,"renderable":0},{"_id":"source/images/DSA/Prim.jpg","path":"images/DSA/Prim.jpg","modified":0,"renderable":0},{"_id":"source/images/DSA/waveDuopl.jpg","path":"images/DSA/waveDuopl.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/2_1.jpg","path":"images/DSD/2_1.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/2_2.jpg","path":"images/DSD/2_2.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/2_3.jpg","path":"images/DSD/2_3.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/2_4.jpg","path":"images/DSD/2_4.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_1.jpg","path":"images/DSD/3_1.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_10.jpg","path":"images/DSD/3_10.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_2.jpg","path":"images/DSD/3_2.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_3.jpg","path":"images/DSD/3_3.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_4.jpg","path":"images/DSD/3_4.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_5.jpg","path":"images/DSD/3_5.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_6.jpg","path":"images/DSD/3_6.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_7.jpg","path":"images/DSD/3_7.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_8.jpg","path":"images/DSD/3_8.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/3_9.jpg","path":"images/DSD/3_9.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_1.jpg","path":"images/DSD/4_1.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_10.jpg","path":"images/DSD/4_10.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_3.jpg","path":"images/DSD/4_3.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_2.jpg","path":"images/DSD/4_2.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_4.jpg","path":"images/DSD/4_4.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_5.jpg","path":"images/DSD/4_5.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_6.jpg","path":"images/DSD/4_6.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_7.jpg","path":"images/DSD/4_7.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_8.jpg","path":"images/DSD/4_8.jpg","modified":0,"renderable":0},{"_id":"source/images/DSD/4_9.jpg","path":"images/DSD/4_9.jpg","modified":0,"renderable":0},{"_id":"source/images/DSP/4_2.jpg","path":"images/DSP/4_2.jpg","modified":0,"renderable":0},{"_id":"source/images/DSP/5_2.jpg","path":"images/DSP/5_2.jpg","modified":0,"renderable":0},{"_id":"source/images/DSP/5_1.jpg","path":"images/DSP/5_1.jpg","modified":0,"renderable":0},{"_id":"source/images/StaSP/1_1.jpg","path":"images/StaSP/1_1.jpg","modified":0,"renderable":0},{"_id":"source/images/prob/L14_1.jpg","path":"images/prob/L14_1.jpg","modified":0,"renderable":0},{"_id":"source/images/StaSP/2_1.jpg","path":"images/StaSP/2_1.jpg","modified":0,"renderable":0},{"_id":"source/images/StaSP/2_2.png","path":"images/StaSP/2_2.png","modified":0,"renderable":0},{"_id":"source/images/prob/L15_1.jpg","path":"images/prob/L15_1.jpg","modified":0,"renderable":0},{"_id":"source/images/prob/L2_1.jpg","path":"images/prob/L2_1.jpg","modified":0,"renderable":0},{"_id":"source/images/oj/1.jpg","path":"images/oj/1.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/Exer9.29.jpg","path":"images/physics/Exer9.29.jpg","modified":0,"renderable":0},{"_id":"source/images/prob/L6_1.jpg","path":"images/prob/L6_1.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/RealGasTemp.png","path":"images/physics/RealGasTemp.png","modified":0,"renderable":0},{"_id":"source/images/physics/STM.jpg","path":"images/physics/STM.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/VanGas.png","path":"images/physics/VanGas.png","modified":0,"renderable":0},{"_id":"source/images/physics/VanGasTemp.png","path":"images/physics/VanGasTemp.png","modified":0,"renderable":0},{"_id":"source/images/physics/abaaba.jpg","path":"images/physics/abaaba.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/guocheng.png","path":"images/physics/guocheng.png","modified":0,"renderable":0},{"_id":"source/images/physics/niudunhuan.jpg","path":"images/physics/niudunhuan.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/rexunhuan.png","path":"images/physics/rexunhuan.png","modified":0,"renderable":0},{"_id":"source/images/physics/shuangfeng.jpg","path":"images/physics/shuangfeng.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/shuangzheshe.jpg","path":"images/physics/shuangzheshe.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/xunhuantu.png","path":"images/physics/xunhuantu.png","modified":0,"renderable":0},{"_id":"source/images/physics/zhilengxunhuan.png","path":"images/physics/zhilengxunhuan.png","modified":0,"renderable":0},{"_id":"source/images/physics/准单色光.jpg","path":"images/physics/准单色光.jpg","modified":0,"renderable":0},{"_id":"source/images/physics/非单色光.jpg","path":"images/physics/非单色光.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_10.jpg","path":"images/digital/lec_10_10.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_1.jpg","path":"images/digital/lec_10_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_2.jpg","path":"images/digital/lec_10_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_3.jpg","path":"images/digital/lec_10_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_4.jpg","path":"images/digital/lec_10_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_5.jpg","path":"images/digital/lec_10_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_6.jpg","path":"images/digital/lec_10_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_7.jpg","path":"images/digital/lec_10_7.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_8.jpg","path":"images/digital/lec_10_8.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_10_9.jpg","path":"images/digital/lec_10_9.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_11_1.jpg","path":"images/digital/lec_11_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_12_1.jpg","path":"images/digital/lec_12_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_12_2.jpg","path":"images/digital/lec_12_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_12_3.jpg","path":"images/digital/lec_12_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_12_4.jpg","path":"images/digital/lec_12_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_12_5.jpg","path":"images/digital/lec_12_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_12_6.jpg","path":"images/digital/lec_12_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_3_1.jpg","path":"images/digital/lec_3_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_1.jpg","path":"images/digital/lec_4_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_1.jpg8.jpg","path":"images/digital/lec_4_1.jpg8.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_10.jpg","path":"images/digital/lec_4_10.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_11.jpg","path":"images/digital/lec_4_11.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_12.jpg","path":"images/digital/lec_4_12.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_13.jpg","path":"images/digital/lec_4_13.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_14.jpg","path":"images/digital/lec_4_14.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_15.jpg","path":"images/digital/lec_4_15.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_16.jpg","path":"images/digital/lec_4_16.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_17.jpg","path":"images/digital/lec_4_17.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_2.jpg","path":"images/digital/lec_4_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_3.jpg","path":"images/digital/lec_4_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_4.jpg","path":"images/digital/lec_4_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_5.jpg","path":"images/digital/lec_4_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_6.jpg","path":"images/digital/lec_4_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_7.jpg","path":"images/digital/lec_4_7.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_8.jpg","path":"images/digital/lec_4_8.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_4_9.jpg","path":"images/digital/lec_4_9.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_1.jpg","path":"images/digital/lec_5_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_10.jpg","path":"images/digital/lec_5_10.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_12.jpg","path":"images/digital/lec_5_12.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_11.jpg","path":"images/digital/lec_5_11.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_13.jpg","path":"images/digital/lec_5_13.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_14.jpg","path":"images/digital/lec_5_14.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_17.jpg","path":"images/digital/lec_5_17.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_15.jpg","path":"images/digital/lec_5_15.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_16.jpg","path":"images/digital/lec_5_16.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_18.jpg","path":"images/digital/lec_5_18.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_19.jpg","path":"images/digital/lec_5_19.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_2.jpg","path":"images/digital/lec_5_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_21.jpg","path":"images/digital/lec_5_21.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_22.jpg","path":"images/digital/lec_5_22.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_20.jpg","path":"images/digital/lec_5_20.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_23.jpg","path":"images/digital/lec_5_23.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_24.jpg","path":"images/digital/lec_5_24.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_26.jpg","path":"images/digital/lec_5_26.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_25.jpg","path":"images/digital/lec_5_25.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_3.jpg","path":"images/digital/lec_5_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_4.jpg","path":"images/digital/lec_5_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_5.jpg","path":"images/digital/lec_5_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_6.jpg","path":"images/digital/lec_5_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_7.jpg","path":"images/digital/lec_5_7.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_8.jpg","path":"images/digital/lec_5_8.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_5_9.jpg","path":"images/digital/lec_5_9.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_1.jpg","path":"images/digital/lec_6_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_2.jpg","path":"images/digital/lec_6_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_3.jpg","path":"images/digital/lec_6_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_4.jpg","path":"images/digital/lec_6_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_5.jpg","path":"images/digital/lec_6_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_6.jpg","path":"images/digital/lec_6_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_7.jpg","path":"images/digital/lec_6_7.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_8.jpg","path":"images/digital/lec_6_8.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_6_9.jpg","path":"images/digital/lec_6_9.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_.jpg","path":"images/digital/lec_7_.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_1.jpg","path":"images/digital/lec_7_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_10.jpg","path":"images/digital/lec_7_10.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_11.jpg","path":"images/digital/lec_7_11.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_12.jpg","path":"images/digital/lec_7_12.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_13.jpg","path":"images/digital/lec_7_13.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_14.jpg","path":"images/digital/lec_7_14.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_15.jpg","path":"images/digital/lec_7_15.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_16.jpg","path":"images/digital/lec_7_16.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_17.jpg","path":"images/digital/lec_7_17.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_18.jpg","path":"images/digital/lec_7_18.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_2.jpg","path":"images/digital/lec_7_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_20.jpg","path":"images/digital/lec_7_20.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_19.jpg","path":"images/digital/lec_7_19.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_21.jpg","path":"images/digital/lec_7_21.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_22.jpg","path":"images/digital/lec_7_22.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_23.jpg","path":"images/digital/lec_7_23.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_24.jpg","path":"images/digital/lec_7_24.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_3.jpg","path":"images/digital/lec_7_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_4.jpg","path":"images/digital/lec_7_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_5.jpg","path":"images/digital/lec_7_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_6.jpg","path":"images/digital/lec_7_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_7.jpg","path":"images/digital/lec_7_7.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_7_9.jpg","path":"images/digital/lec_7_9.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_1.jpg","path":"images/digital/lec_8_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_11.jpg","path":"images/digital/lec_8_11.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_10.jpg","path":"images/digital/lec_8_10.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_12.jpg","path":"images/digital/lec_8_12.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_13.jpg","path":"images/digital/lec_8_13.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_14.jpg","path":"images/digital/lec_8_14.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_15.jpg","path":"images/digital/lec_8_15.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_16.jpg","path":"images/digital/lec_8_16.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_17.jpg","path":"images/digital/lec_8_17.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_18.jpg","path":"images/digital/lec_8_18.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_19.jpg","path":"images/digital/lec_8_19.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_2.jpg","path":"images/digital/lec_8_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_20.jpg","path":"images/digital/lec_8_20.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_22.jpg","path":"images/digital/lec_8_22.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_23.jpg","path":"images/digital/lec_8_23.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_21.jpg","path":"images/digital/lec_8_21.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_24.jpg","path":"images/digital/lec_8_24.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_25.jpg","path":"images/digital/lec_8_25.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_26.jpg","path":"images/digital/lec_8_26.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_27.jpg","path":"images/digital/lec_8_27.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_28.jpg","path":"images/digital/lec_8_28.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_29.jpg","path":"images/digital/lec_8_29.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_3.jpg","path":"images/digital/lec_8_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_30.jpg","path":"images/digital/lec_8_30.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_4.jpg","path":"images/digital/lec_8_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_31.jpg","path":"images/digital/lec_8_31.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_5.jpg","path":"images/digital/lec_8_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_6.jpg","path":"images/digital/lec_8_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_7.jpg","path":"images/digital/lec_8_7.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_8.jpg","path":"images/digital/lec_8_8.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_8_9.jpg","path":"images/digital/lec_8_9.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_1.jpg","path":"images/digital/lec_9_1.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_10.jpg","path":"images/digital/lec_9_10.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_12.jpg","path":"images/digital/lec_9_12.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_11.jpg","path":"images/digital/lec_9_11.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_13.jpg","path":"images/digital/lec_9_13.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_14.jpg","path":"images/digital/lec_9_14.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_3.jpg","path":"images/digital/lec_9_3.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_4.jpg","path":"images/digital/lec_9_4.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_2.jpg","path":"images/digital/lec_9_2.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_15.jpg","path":"images/digital/lec_9_15.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_7.jpg","path":"images/digital/lec_9_7.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_6.jpg","path":"images/digital/lec_9_6.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_5.jpg","path":"images/digital/lec_9_5.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_8.jpg","path":"images/digital/lec_9_8.jpg","modified":0,"renderable":0},{"_id":"source/images/digital/lec_9_9.jpg","path":"images/digital/lec_9_9.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_1.jpg","path":"images/ss/lec10_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_3.jpg","path":"images/ss/lec10_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_2.jpg","path":"images/ss/lec10_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_4.jpg","path":"images/ss/lec10_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_5.jpg","path":"images/ss/lec10_5.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_6.jpg","path":"images/ss/lec10_6.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_7.jpg","path":"images/ss/lec10_7.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec10_8.jpg","path":"images/ss/lec10_8.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec11_1.jpg","path":"images/ss/lec11_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec11_2.jpg","path":"images/ss/lec11_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec11_3.jpg","path":"images/ss/lec11_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_1.jpg","path":"images/ss/lec12_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_2.jpg","path":"images/ss/lec12_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_3.jpg","path":"images/ss/lec12_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_4.jpg","path":"images/ss/lec12_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_5.jpg","path":"images/ss/lec12_5.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_6.jpg","path":"images/ss/lec12_6.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_7.jpg","path":"images/ss/lec12_7.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec12_8.jpg","path":"images/ss/lec12_8.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec13_1.jpg","path":"images/ss/lec13_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec14_1.jpg","path":"images/ss/lec14_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec14_3.jpg","path":"images/ss/lec14_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec14_2.jpg","path":"images/ss/lec14_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec14_4.jpg","path":"images/ss/lec14_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec14_5.jpg","path":"images/ss/lec14_5.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec14_6.jpg","path":"images/ss/lec14_6.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec14_7.jpg","path":"images/ss/lec14_7.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec15_1.jpg","path":"images/ss/lec15_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec15_2.jpg","path":"images/ss/lec15_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec15_3.jpg","path":"images/ss/lec15_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec15_5.jpg","path":"images/ss/lec15_5.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec15_6.jpg","path":"images/ss/lec15_6.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec16_.jpg","path":"images/ss/lec16_.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec15_4.jpg","path":"images/ss/lec15_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec16_1.jpg","path":"images/ss/lec16_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec16_2.jpg","path":"images/ss/lec16_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec16_3.jpg","path":"images/ss/lec16_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec16_4.jpg","path":"images/ss/lec16_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec17_1.jpg","path":"images/ss/lec17_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec18_1.jpg","path":"images/ss/lec18_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec18_2.jpg","path":"images/ss/lec18_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec18_3.jpg","path":"images/ss/lec18_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec18_34jpg.jpg","path":"images/ss/lec18_34jpg.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec18_5jpg.jpg","path":"images/ss/lec18_5jpg.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec18_6.jpg","path":"images/ss/lec18_6.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec19_1jpg.jpg","path":"images/ss/lec19_1jpg.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec19_2jpg.jpg","path":"images/ss/lec19_2jpg.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec19_3.jpg","path":"images/ss/lec19_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_2.jpg","path":"images/ss/lec20_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_1.jpg","path":"images/ss/lec20_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_4.jpg","path":"images/ss/lec20_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_3.jpg","path":"images/ss/lec20_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_5.jpg","path":"images/ss/lec20_5.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_6.jpg","path":"images/ss/lec20_6.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_7.jpg","path":"images/ss/lec20_7.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec20_8.jpg","path":"images/ss/lec20_8.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_1.jpg","path":"images/ss/lec21_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_10.jpg","path":"images/ss/lec21_10.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_2.jpg","path":"images/ss/lec21_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_3.jpg","path":"images/ss/lec21_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_4.jpg","path":"images/ss/lec21_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_5.jpg","path":"images/ss/lec21_5.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_6.jpg","path":"images/ss/lec21_6.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_8.jpg","path":"images/ss/lec21_8.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_7.jpg","path":"images/ss/lec21_7.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_11.jpg","path":"images/ss/lec22_11.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec21_9.jpg","path":"images/ss/lec21_9.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_13.jpg","path":"images/ss/lec22_13.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_12.jpg","path":"images/ss/lec22_12.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_14.jpg","path":"images/ss/lec22_14.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_15.jpg","path":"images/ss/lec22_15.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_16.jpg","path":"images/ss/lec22_16.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_17.jpg","path":"images/ss/lec22_17.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_18.jpg","path":"images/ss/lec22_18.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_19.jpg","path":"images/ss/lec22_19.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec22_20.jpg","path":"images/ss/lec22_20.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec23_1.jpg","path":"images/ss/lec23_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec2_.jpg","path":"images/ss/lec2_.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec2_2.jpg","path":"images/ss/lec2_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec2_3.jpg","path":"images/ss/lec2_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec3_1.jpg","path":"images/ss/lec3_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec3_2.jpg","path":"images/ss/lec3_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec7_1.jpg","path":"images/ss/lec7_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec7_2.jpg","path":"images/ss/lec7_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec7_3.jpg","path":"images/ss/lec7_3.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec7_4.jpg","path":"images/ss/lec7_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec9_1.jpg","path":"images/ss/lec9_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec9_2.jpg","path":"images/ss/lec9_2.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec9_3.jpg","path":"images/ss/lec9_3.jpg","modified":0,"renderable":0},{"_id":"source/images/stochastic/exer_1.jpg","path":"images/stochastic/exer_1.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec9_4.jpg","path":"images/ss/lec9_4.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec9_5.jpg","path":"images/ss/lec9_5.jpg","modified":0,"renderable":0},{"_id":"source/images/ss/lec9_6.jpg","path":"images/ss/lec9_6.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/3_1.jpg","path":"images/计网/3_1.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/3_2.jpg","path":"images/计网/3_2.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/3_3.jpg","path":"images/计网/3_3.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/3_4.jpg","path":"images/计网/3_4.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/3_5.jpg","path":"images/计网/3_5.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/3_6.jpg","path":"images/计网/3_6.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/3_7.jpg","path":"images/计网/3_7.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/5_1.jpg","path":"images/计网/5_1.jpg","modified":0,"renderable":0},{"_id":"source/images/计网/5_2.jpg","path":"images/计网/5_2.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/4——1.jpg","path":"images/量筒/4——1.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/4_2.jpg","path":"images/量筒/4_2.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/5_1.jpg","path":"images/量筒/5_1.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/7_1.jpg","path":"images/量筒/7_1.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/8_1.jpg","path":"images/量筒/8_1.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/8_2.jpg","path":"images/量筒/8_2.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/8_3.jpg","path":"images/量筒/8_3.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/8_4.jpg","path":"images/量筒/8_4.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/xt_2_1.jpg","path":"images/量筒/xt_2_1.jpg","modified":0,"renderable":0},{"_id":"source/images/量筒/xt_2_2.jpg","path":"images/量筒/xt_2_2.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/1_.jpg","path":"images/通网/1_.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/1_1.jpg","path":"images/通网/1_1.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_1.jpg","path":"images/通网/2_1.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_2.jpg","path":"images/通网/2_2.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_3.jpg","path":"images/通网/2_3.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_4.jpg","path":"images/通网/2_4.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_7.jpg","path":"images/通网/2_7.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_6.jpg","path":"images/通网/2_6.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_5.jpg","path":"images/通网/2_5.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_8.jpg","path":"images/通网/2_8.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/2_9.jpg","path":"images/通网/2_9.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/3_2.jpg","path":"images/通网/3_2.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/3_1.jpg","path":"images/通网/3_1.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/3_3.jpg","path":"images/通网/3_3.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/3_4.jpg","path":"images/通网/3_4.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/3_5.jpg","path":"images/通网/3_5.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/3_6.jpg","path":"images/通网/3_6.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_1.jpg","path":"images/通网/4_1.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_10.jpg","path":"images/通网/4_10.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_2.jpg","path":"images/通网/4_2.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_3.jpg","path":"images/通网/4_3.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_4.jpg","path":"images/通网/4_4.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_5.jpg","path":"images/通网/4_5.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_6.jpg","path":"images/通网/4_6.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_7.jpg","path":"images/通网/4_7.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_8.jpg","path":"images/通网/4_8.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/4_9.jpg","path":"images/通网/4_9.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_1.jpg","path":"images/通网/5_1.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_10.jpg","path":"images/通网/5_10.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_2.jpg","path":"images/通网/5_2.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_3.jpg","path":"images/通网/5_3.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_4.jpg","path":"images/通网/5_4.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_6.jpg","path":"images/通网/5_6.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_5.jpg","path":"images/通网/5_5.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_7.jpg","path":"images/通网/5_7.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_8.jpg","path":"images/通网/5_8.jpg","modified":0,"renderable":0},{"_id":"source/images/通网/5_9.jpg","path":"images/通网/5_9.jpg","modified":0,"renderable":0},{"_id":"node_modules/hexo-theme-yun/source/yun.png","path":"yun.png","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/yun.svg","path":"yun.svg","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/css/README.md","path":"css/README.md","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/css/hexo-theme-yun.styl","path":"css/hexo-theme-yun.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/chunk-72ZP56JR.js","path":"js/chunk-72ZP56JR.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/hexo-theme-yun.js","path":"js/hexo-theme-yun.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/gallery-decrypt.js","path":"js/gallery-decrypt.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/pjax.js","path":"js/pjax.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/say.js","path":"js/say.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/sidebar.js","path":"js/sidebar.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/chunk-FEIY7W7S.js","path":"js/chunk-FEIY7W7S.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/analytics/leancloud-visitors.js","path":"js/analytics/leancloud-visitors.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/comments/disqus.js","path":"js/comments/disqus.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/comments/waline.js","path":"js/comments/waline.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/search/algolia-search.js","path":"js/search/algolia-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/search/local-search.js","path":"js/search/local-search.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/ui/banner.js","path":"js/ui/banner.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-yun/source/js/ui/fireworks.js","path":"js/ui/fireworks.js","modified":0,"renderable":1},{"_id":"source/fonts/LMROMAN10-REGULAR.OTF","path":"fonts/LMROMAN10-REGULAR.OTF","modified":0,"renderable":0},{"_id":"source/fonts/LMROMAN10-BOLD.OTF","path":"fonts/LMROMAN10-BOLD.OTF","modified":0,"renderable":0},{"_id":"source/fonts/LMROMAN10-BOLDITALIC.OTF","path":"fonts/LMROMAN10-BOLDITALIC.OTF","modified":0,"renderable":0},{"_id":"source/fonts/LMROMAN10-ITALIC.OTF","path":"fonts/LMROMAN10-ITALIC.OTF","modified":0,"renderable":0},{"_id":"source/fonts/SIMSUN.TTC","path":"fonts/SIMSUN.TTC","modified":0,"renderable":0},{"_id":"source/fonts/SmileySans-Oblique.otf","path":"fonts/SmileySans-Oblique.otf","modified":0,"renderable":0},{"_id":"source/fonts/STFANGSO.TTF","path":"fonts/STFANGSO.TTF","modified":0,"renderable":0},{"_id":"source/fonts/STKAITI.TTF","path":"fonts/STKAITI.TTF","modified":0,"renderable":0},{"_id":"source/fonts/STSONG.TTF","path":"fonts/STSONG.TTF","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711090268476.png","path":"images/Antenna/1711090268476.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711091202619.png","path":"images/Antenna/1711091202619.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711090528566.png","path":"images/Antenna/1711090528566.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711090565574.png","path":"images/Antenna/1711090565574.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711091212947.png","path":"images/Antenna/1711091212947.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711254850893.png","path":"images/StaSP/1711254850893.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711255303038.png","path":"images/StaSP/1711255303038.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713166706648.png","path":"images/AI/1713166706648.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713169419702.png","path":"images/AI/1713169419702.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713171808270.png","path":"images/AI/1713171808270.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713171795959.png","path":"images/AI/1713171795959.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711693683771.png","path":"images/Antenna/1711693683771.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711693701192.png","path":"images/Antenna/1711693701192.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711693749686.png","path":"images/Antenna/1711693749686.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711693845822.png","path":"images/Antenna/1711693845822.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711693861642.png","path":"images/Antenna/1711693861642.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711693936592.png","path":"images/Antenna/1711693936592.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711694027177.png","path":"images/Antenna/1711694027177.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711694083583.png","path":"images/Antenna/1711694083583.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711694243897.png","path":"images/Antenna/1711694243897.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711694350257.png","path":"images/Antenna/1711694350257.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711694462059.png","path":"images/Antenna/1711694462059.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711694619870.png","path":"images/Antenna/1711694619870.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711694639638.png","path":"images/Antenna/1711694639638.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1711695738159.png","path":"images/Antenna/1711695738159.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712471419276.png","path":"images/Antenna/1712471419276.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712471436962.png","path":"images/Antenna/1712471436962.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712471499226.png","path":"images/Antenna/1712471499226.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712473473687.png","path":"images/Antenna/1712473473687.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712900712333.png","path":"images/Antenna/1712900712333.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712901375924.png","path":"images/Antenna/1712901375924.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712902160882.png","path":"images/Antenna/1712902160882.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712903308547.png","path":"images/Antenna/1712903308547.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712905110844.png","path":"images/Antenna/1712905110844.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712905233876.png","path":"images/Antenna/1712905233876.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1712905317317.png","path":"images/Antenna/1712905317317.png","modified":0,"renderable":0},{"_id":"source/images/DRL/1712925351346.png","path":"images/DRL/1712925351346.png","modified":0,"renderable":0},{"_id":"source/images/DRL/1712925354266.png","path":"images/DRL/1712925354266.png","modified":0,"renderable":0},{"_id":"source/images/OS/1713266591628.png","path":"images/OS/1713266591628.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713233318260.png","path":"images/SolidPhysics/1713233318260.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713234834861.png","path":"images/SolidPhysics/1713234834861.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713234874686.png","path":"images/SolidPhysics/1713234874686.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713235941206.png","path":"images/SolidPhysics/1713235941206.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713236189430.png","path":"images/SolidPhysics/1713236189430.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713236233045.png","path":"images/SolidPhysics/1713236233045.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713236269885.png","path":"images/SolidPhysics/1713236269885.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713236929581.png","path":"images/SolidPhysics/1713236929581.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713236984022.png","path":"images/SolidPhysics/1713236984022.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713237051369.png","path":"images/SolidPhysics/1713237051369.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713237069207.png","path":"images/SolidPhysics/1713237069207.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713237158982.png","path":"images/SolidPhysics/1713237158982.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713237357342.png","path":"images/SolidPhysics/1713237357342.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713239832006.png","path":"images/SolidPhysics/1713239832006.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1713240457384.png","path":"images/SolidPhysics/1713240457384.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339192281.png","path":"images/StaSP/1711339192281.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339154789.png","path":"images/StaSP/1711339154789.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339216759.png","path":"images/StaSP/1711339216759.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339249863.png","path":"images/StaSP/1711339249863.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339773571.png","path":"images/StaSP/1711339773571.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339786814.png","path":"images/StaSP/1711339786814.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339865703.png","path":"images/StaSP/1711339865703.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711339831807.png","path":"images/StaSP/1711339831807.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711340151724.png","path":"images/StaSP/1711340151724.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711340163113.png","path":"images/StaSP/1711340163113.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711340177961.png","path":"images/StaSP/1711340177961.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711340277148.png","path":"images/StaSP/1711340277148.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1711340293644.png","path":"images/StaSP/1711340293644.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1712549632251.png","path":"images/StaSP/1712549632251.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1712549637885.png","path":"images/StaSP/1712549637885.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713066463994.png","path":"images/StaSP/1713066463994.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713150631533.png","path":"images/StaSP/1713150631533.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713150674892.png","path":"images/StaSP/1713150674892.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713150692811.png","path":"images/StaSP/1713150692811.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713150769252.png","path":"images/StaSP/1713150769252.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713151589324.png","path":"images/StaSP/1713151589324.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713152016025.png","path":"images/StaSP/1713152016025.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713152970273.png","path":"images/StaSP/1713152970273.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1713152987612.png","path":"images/StaSP/1713152987612.png","modified":0,"renderable":0},{"_id":"source/images/stuffs/1713000493686.png","path":"images/stuffs/1713000493686.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713771652191.png","path":"images/AI/1713771652191.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713772489046.png","path":"images/AI/1713772489046.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713775669844.png","path":"images/AI/1713775669844.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713776156049.png","path":"images/AI/1713776156049.png","modified":0,"renderable":0},{"_id":"source/images/AI/1713776168789.png","path":"images/AI/1713776168789.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714379335929.png","path":"images/AI/1714379335929.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714379943169.png","path":"images/AI/1714379943169.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714380111476.png","path":"images/AI/1714380111476.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714380132725.png","path":"images/AI/1714380132725.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714380159356.png","path":"images/AI/1714380159356.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714380343254.png","path":"images/AI/1714380343254.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714380233071.png","path":"images/AI/1714380233071.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714380578105.png","path":"images/AI/1714380578105.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714380763838.png","path":"images/AI/1714380763838.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713506228135.png","path":"images/Antenna/1713506228135.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713506258888.png","path":"images/Antenna/1713506258888.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713506275022.png","path":"images/Antenna/1713506275022.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713506363705.png","path":"images/Antenna/1713506363705.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713506921640.png","path":"images/Antenna/1713506921640.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713506837120.png","path":"images/Antenna/1713506837120.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713507175699.png","path":"images/Antenna/1713507175699.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713507190746.png","path":"images/Antenna/1713507190746.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713507205996.png","path":"images/Antenna/1713507205996.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713508252106.png","path":"images/Antenna/1713508252106.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713508669926.png","path":"images/Antenna/1713508669926.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713508379111.png","path":"images/Antenna/1713508379111.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713508784675.png","path":"images/Antenna/1713508784675.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713509120707.png","path":"images/Antenna/1713509120707.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713509771675.png","path":"images/Antenna/1713509771675.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1713509734724.png","path":"images/Antenna/1713509734724.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713958735363.png","path":"images/Speech-SP/1713958735363.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713958768829.png","path":"images/Speech-SP/1713958768829.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713959362056.png","path":"images/Speech-SP/1713959362056.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713960064882.png","path":"images/Speech-SP/1713960064882.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713960093567.png","path":"images/Speech-SP/1713960093567.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713961039467.png","path":"images/Speech-SP/1713961039467.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713962223184.png","path":"images/Speech-SP/1713962223184.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713963710139.png","path":"images/Speech-SP/1713963710139.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713963726242.png","path":"images/Speech-SP/1713963726242.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713963786950.png","path":"images/Speech-SP/1713963786950.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713965424496.png","path":"images/Speech-SP/1713965424496.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1713963998639.png","path":"images/Speech-SP/1713963998639.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714360717248.png","path":"images/StaSP/1714360717248.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714360782259.png","path":"images/StaSP/1714360782259.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714360742651.png","path":"images/StaSP/1714360742651.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714360809348.png","path":"images/StaSP/1714360809348.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714361011137.png","path":"images/StaSP/1714361011137.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714361027958.png","path":"images/StaSP/1714361027958.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714966200160.png","path":"images/StaSP/1714966200160.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714966226811.png","path":"images/StaSP/1714966226811.png","modified":0,"renderable":0},{"_id":"source/images/StaSP/1714966230536.png","path":"images/StaSP/1714966230536.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714982108981.png","path":"images/AI/1714982108981.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714982075164.png","path":"images/AI/1714982075164.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714982133935.png","path":"images/AI/1714982133935.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714982215920.png","path":"images/AI/1714982215920.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714982188331.png","path":"images/AI/1714982188331.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714982405665.png","path":"images/AI/1714982405665.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714983390325.png","path":"images/AI/1714983390325.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714983452419.png","path":"images/AI/1714983452419.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714983641507.png","path":"images/AI/1714983641507.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714983788461.png","path":"images/AI/1714983788461.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714983988587.png","path":"images/AI/1714983988587.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714984460020.png","path":"images/AI/1714984460020.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714984778231.png","path":"images/AI/1714984778231.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714985419724.png","path":"images/AI/1714985419724.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714985971187.png","path":"images/AI/1714985971187.png","modified":0,"renderable":0},{"_id":"source/images/AI/1714986050538.png","path":"images/AI/1714986050538.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716191759894.png","path":"images/AI/1716191759894.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716192135361.png","path":"images/AI/1716192135361.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716192175996.png","path":"images/AI/1716192175996.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716192519850.png","path":"images/AI/1716192519850.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716192534058.png","path":"images/AI/1716192534058.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716193180893.png","path":"images/AI/1716193180893.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716193473766.png","path":"images/AI/1716193473766.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716194228666.png","path":"images/AI/1716194228666.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716194320872.png","path":"images/AI/1716194320872.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716194583833.png","path":"images/AI/1716194583833.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716194633162.png","path":"images/AI/1716194633162.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716194757145.png","path":"images/AI/1716194757145.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716195002371.png","path":"images/AI/1716195002371.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716195398036.png","path":"images/AI/1716195398036.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716195442145.png","path":"images/AI/1716195442145.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716795255535.png","path":"images/AI/1716795255535.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716795740579.png","path":"images/AI/1716795740579.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716795753326.png","path":"images/AI/1716795753326.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716796053911.png","path":"images/AI/1716796053911.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716796227758.png","path":"images/AI/1716796227758.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716796229664.png","path":"images/AI/1716796229664.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716797001550.png","path":"images/AI/1716797001550.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716797936119.png","path":"images/AI/1716797936119.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716798687551.png","path":"images/AI/1716798687551.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716798247574.png","path":"images/AI/1716798247574.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716798850106.png","path":"images/AI/1716798850106.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716798927981.png","path":"images/AI/1716798927981.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716799063581.png","path":"images/AI/1716799063581.png","modified":0,"renderable":0},{"_id":"source/images/AI/1716799707301.png","path":"images/AI/1716799707301.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717400667281.png","path":"images/AI/1717400667281.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717400852805.png","path":"images/AI/1717400852805.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717400854837.png","path":"images/AI/1717400854837.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717401031002.png","path":"images/AI/1717401031002.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717401124879.png","path":"images/AI/1717401124879.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717401517265.png","path":"images/AI/1717401517265.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717401591545.png","path":"images/AI/1717401591545.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717403664862.png","path":"images/AI/1717403664862.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717403702542.png","path":"images/AI/1717403702542.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717403725888.png","path":"images/AI/1717403725888.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717404024479.png","path":"images/AI/1717404024479.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717404790783.png","path":"images/AI/1717404790783.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717404907709.png","path":"images/AI/1717404907709.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717405435705.png","path":"images/AI/1717405435705.png","modified":0,"renderable":0},{"_id":"source/images/AI/1717405465141.png","path":"images/AI/1717405465141.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715324548326.png","path":"images/Antenna/1715324548326.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715324559069.png","path":"images/Antenna/1715324559069.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715324583382.png","path":"images/Antenna/1715324583382.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715324769403.png","path":"images/Antenna/1715324769403.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715325834911.png","path":"images/Antenna/1715325834911.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715328812089.png","path":"images/Antenna/1715328812089.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715924283522.png","path":"images/Antenna/1715924283522.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715924294266.png","path":"images/Antenna/1715924294266.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715924314079.png","path":"images/Antenna/1715924314079.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715924338243.png","path":"images/Antenna/1715924338243.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715924463502.png","path":"images/Antenna/1715924463502.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715924364965.png","path":"images/Antenna/1715924364965.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715927654495.png","path":"images/Antenna/1715927654495.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715927982080.png","path":"images/Antenna/1715927982080.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715928380068.png","path":"images/Antenna/1715928380068.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929169213.png","path":"images/Antenna/1715929169213.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929138391.png","path":"images/Antenna/1715929138391.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929396692.png","path":"images/Antenna/1715929396692.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929046320.png","path":"images/Antenna/1715929046320.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929501432.png","path":"images/Antenna/1715929501432.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929523072.png","path":"images/Antenna/1715929523072.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929531751.png","path":"images/Antenna/1715929531751.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1715929546494.png","path":"images/Antenna/1715929546494.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717133859909.png","path":"images/Antenna/1717133859909.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717133876692.png","path":"images/Antenna/1717133876692.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717133761533.png","path":"images/Antenna/1717133761533.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717133858173.png","path":"images/Antenna/1717133858173.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134287481.png","path":"images/Antenna/1717134287481.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134268805.png","path":"images/Antenna/1717134268805.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134331603.png","path":"images/Antenna/1717134331603.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134353772.png","path":"images/Antenna/1717134353772.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134725130.png","path":"images/Antenna/1717134725130.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134745100.png","path":"images/Antenna/1717134745100.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134942873.png","path":"images/Antenna/1717134942873.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134897852.png","path":"images/Antenna/1717134897852.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717134955235.png","path":"images/Antenna/1717134955235.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717135386351.png","path":"images/Antenna/1717135386351.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717135044895.png","path":"images/Antenna/1717135044895.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717135198414.png","path":"images/Antenna/1717135198414.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717135171215.png","path":"images/Antenna/1717135171215.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717136115015.png","path":"images/Antenna/1717136115015.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717136046473.png","path":"images/Antenna/1717136046473.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717135675789.png","path":"images/Antenna/1717135675789.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717135951201.png","path":"images/Antenna/1717135951201.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717137646795.png","path":"images/Antenna/1717137646795.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717137633424.png","path":"images/Antenna/1717137633424.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717138873279.png","path":"images/Antenna/1717138873279.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717138714524.png","path":"images/Antenna/1717138714524.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740667735.png","path":"images/Antenna/1717740667735.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740670364.png","path":"images/Antenna/1717740670364.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740680573.png","path":"images/Antenna/1717740680573.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740726098.png","path":"images/Antenna/1717740726098.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740758890.png","path":"images/Antenna/1717740758890.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740768183.png","path":"images/Antenna/1717740768183.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740786849.png","path":"images/Antenna/1717740786849.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717740801741.png","path":"images/Antenna/1717740801741.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717742374397.png","path":"images/Antenna/1717742374397.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717742413544.png","path":"images/Antenna/1717742413544.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717742626807.png","path":"images/Antenna/1717742626807.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717743460723.png","path":"images/Antenna/1717743460723.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717743468657.png","path":"images/Antenna/1717743468657.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717743681072.png","path":"images/Antenna/1717743681072.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717743691321.png","path":"images/Antenna/1717743691321.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1717743927411.png","path":"images/Antenna/1717743927411.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718344358151.png","path":"images/Antenna/1718344358151.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718345601277.png","path":"images/Antenna/1718345601277.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718345718761.png","path":"images/Antenna/1718345718761.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718345727630.png","path":"images/Antenna/1718345727630.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718346371235.png","path":"images/Antenna/1718346371235.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718346212882.png","path":"images/Antenna/1718346212882.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718346571584.png","path":"images/Antenna/1718346571584.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718346379534.png","path":"images/Antenna/1718346379534.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718347859765.png","path":"images/Antenna/1718347859765.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718346830900.png","path":"images/Antenna/1718346830900.png","modified":0,"renderable":0},{"_id":"source/images/Antenna/1718347869028.png","path":"images/Antenna/1718347869028.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1717937154526.png","path":"images/Mobile-LLM/1717937154526.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1717937675502.png","path":"images/Mobile-LLM/1717937675502.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1717940196994.png","path":"images/Mobile-LLM/1717940196994.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1717937734857.png","path":"images/Mobile-LLM/1717937734857.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1717939486804.png","path":"images/Mobile-LLM/1717939486804.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1718003623779.png","path":"images/Mobile-LLM/1718003623779.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1718003792356.png","path":"images/Mobile-LLM/1718003792356.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1718009240031.png","path":"images/Mobile-LLM/1718009240031.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1718009413946.png","path":"images/Mobile-LLM/1718009413946.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721230554686.png","path":"images/Mobile-LLM/1721230554686.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721231007829.png","path":"images/Mobile-LLM/1721231007829.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721232302611.png","path":"images/DigiRL/1721232302611.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721296305153.png","path":"images/DigiRL/1721296305153.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721296320033.png","path":"images/DigiRL/1721296320033.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721316668685.png","path":"images/DigiRL/1721316668685.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721316686785.png","path":"images/DigiRL/1721316686785.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1715172378465.png","path":"images/Speech-SP/1715172378465.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1715172404966.png","path":"images/Speech-SP/1715172404966.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1715172645812.png","path":"images/Speech-SP/1715172645812.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1715172680511.png","path":"images/Speech-SP/1715172680511.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1715173923794.png","path":"images/Speech-SP/1715173923794.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1716988653084.png","path":"images/Speech-SP/1716988653084.png","modified":0,"renderable":0},{"_id":"source/images/Speech-SP/1715174312556.png","path":"images/Speech-SP/1715174312556.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715047577458.png","path":"images/SolidPhysics/1715047577458.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715048162767.png","path":"images/SolidPhysics/1715048162767.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715048234147.png","path":"images/SolidPhysics/1715048234147.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715048857194.png","path":"images/SolidPhysics/1715048857194.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715050052696.png","path":"images/SolidPhysics/1715050052696.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715051145151.png","path":"images/SolidPhysics/1715051145151.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715052169711.png","path":"images/SolidPhysics/1715052169711.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715053184570.png","path":"images/SolidPhysics/1715053184570.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715051313166.png","path":"images/SolidPhysics/1715051313166.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715053936706.png","path":"images/SolidPhysics/1715053936706.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715053408715.png","path":"images/SolidPhysics/1715053408715.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715657785337.png","path":"images/SolidPhysics/1715657785337.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715658350241.png","path":"images/SolidPhysics/1715658350241.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715659347111.png","path":"images/SolidPhysics/1715659347111.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715658620805.png","path":"images/SolidPhysics/1715658620805.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1715659894626.png","path":"images/SolidPhysics/1715659894626.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716257919907.png","path":"images/SolidPhysics/1716257919907.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716257709851.png","path":"images/SolidPhysics/1716257709851.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716257832298.png","path":"images/SolidPhysics/1716257832298.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716258191070.png","path":"images/SolidPhysics/1716258191070.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716258157706.png","path":"images/SolidPhysics/1716258157706.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716259850103.png","path":"images/SolidPhysics/1716259850103.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716258575169.png","path":"images/SolidPhysics/1716258575169.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716259893782.png","path":"images/SolidPhysics/1716259893782.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716259987276.png","path":"images/SolidPhysics/1716259987276.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716260746330.png","path":"images/SolidPhysics/1716260746330.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716260901275.png","path":"images/SolidPhysics/1716260901275.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716261409659.png","path":"images/SolidPhysics/1716261409659.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716261766058.png","path":"images/SolidPhysics/1716261766058.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716261781489.png","path":"images/SolidPhysics/1716261781489.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716261236429.png","path":"images/SolidPhysics/1716261236429.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716262570823.png","path":"images/SolidPhysics/1716262570823.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716262583215.png","path":"images/SolidPhysics/1716262583215.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716263334906.png","path":"images/SolidPhysics/1716263334906.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716263538645.png","path":"images/SolidPhysics/1716263538645.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716263526504.png","path":"images/SolidPhysics/1716263526504.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716263918247.png","path":"images/SolidPhysics/1716263918247.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716263941957.png","path":"images/SolidPhysics/1716263941957.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716863556246.png","path":"images/SolidPhysics/1716863556246.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716864038557.png","path":"images/SolidPhysics/1716864038557.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716868157804.png","path":"images/SolidPhysics/1716868157804.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716868762789.png","path":"images/SolidPhysics/1716868762789.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716864050264.png","path":"images/SolidPhysics/1716864050264.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717467815166.png","path":"images/SolidPhysics/1717467815166.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717467681404.png","path":"images/SolidPhysics/1717467681404.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716869179928.png","path":"images/SolidPhysics/1716869179928.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717467825452.png","path":"images/SolidPhysics/1717467825452.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717467885133.png","path":"images/SolidPhysics/1717467885133.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1716869156196.png","path":"images/SolidPhysics/1716869156196.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717468003069.png","path":"images/SolidPhysics/1717468003069.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717468150691.png","path":"images/SolidPhysics/1717468150691.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717468014637.png","path":"images/SolidPhysics/1717468014637.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717467940325.png","path":"images/SolidPhysics/1717467940325.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717468250438.png","path":"images/SolidPhysics/1717468250438.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717468352260.png","path":"images/SolidPhysics/1717468352260.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717468279238.png","path":"images/SolidPhysics/1717468279238.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717468364464.png","path":"images/SolidPhysics/1717468364464.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717469037238.png","path":"images/SolidPhysics/1717469037238.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717469056663.png","path":"images/SolidPhysics/1717469056663.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717469080107.png","path":"images/SolidPhysics/1717469080107.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717469005887.png","path":"images/SolidPhysics/1717469005887.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717469702087.png","path":"images/SolidPhysics/1717469702087.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717470027229.png","path":"images/SolidPhysics/1717470027229.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717470756612.png","path":"images/SolidPhysics/1717470756612.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717473805195.png","path":"images/SolidPhysics/1717473805195.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1717473776761.png","path":"images/SolidPhysics/1717473776761.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718071135404.png","path":"images/SolidPhysics/1718071135404.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718071202034.png","path":"images/SolidPhysics/1718071202034.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718071363760.png","path":"images/SolidPhysics/1718071363760.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718071692546.png","path":"images/SolidPhysics/1718071692546.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718071563960.png","path":"images/SolidPhysics/1718071563960.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718071922789.png","path":"images/SolidPhysics/1718071922789.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718072084533.png","path":"images/SolidPhysics/1718072084533.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718072235738.png","path":"images/SolidPhysics/1718072235738.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718072255786.png","path":"images/SolidPhysics/1718072255786.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718072474995.png","path":"images/SolidPhysics/1718072474995.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718072707268.png","path":"images/SolidPhysics/1718072707268.png","modified":0,"renderable":0},{"_id":"source/images/SolidPhysics/1718072997880.png","path":"images/SolidPhysics/1718072997880.png","modified":0,"renderable":0},{"_id":"source/images/mathmagic/1721059328456.png","path":"images/mathmagic/1721059328456.png","modified":0,"renderable":0},{"_id":"source/images/mathmagic/1721059341655.png","path":"images/mathmagic/1721059341655.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721554892738.png","path":"images/DigiRL/1721554892738.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721555459238.png","path":"images/DigiRL/1721555459238.png","modified":0,"renderable":0},{"_id":"source/images/DigiRL/1721555695196.png","path":"images/DigiRL/1721555695196.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721718047655.png","path":"images/Mobile-LLM/1721718047655.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721792120662.png","path":"images/Mobile-LLM/1721792120662.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721792309928.png","path":"images/Mobile-LLM/1721792309928.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721962899191.png","path":"images/Mobile-LLM/1721962899191.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721924737611.png","path":"images/Mobile-LLM/1721924737611.png","modified":0,"renderable":0},{"_id":"source/images/Mobile-LLM/1721962961205.png","path":"images/Mobile-LLM/1721962961205.png","modified":0,"renderable":0},{"_id":"source/images/DDPM/1753424129654.png","path":"images/DDPM/1753424129654.png","modified":0,"renderable":0},{"_id":"source/images/DDPM/1753442174434.png","path":"images/DDPM/1753442174434.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/images/avatar.jpg","hash":"82fa7e5d64578f76a3f099524be413d04f02b716","modified":1710828076214},{"_id":"source/images/csapp1.jpg","hash":"8d0d45d69ac337393818f5f58ecdf2a3641d7ec3","modified":1710828076214},{"_id":"source/_posts/AI.md","hash":"15a730f0f5caca9850273b378f2fb1f811714d84","modified":1717405466606},{"_id":"source/_posts/Antenna.md","hash":"d1ed996888d2c058a8b0123d9d33e00763926dbf","modified":1718347870497},{"_id":"source/_posts/DataAndAlgorithms.md","hash":"59b0f28bf153e6ca1ed72cc5674309f9115610af","modified":1710828076157},{"_id":"source/_posts/CSAPP学习笔记.md","hash":"d37ac2dd58ac0fdb70e3fec4799c0239bf4311ff","modified":1710828076155},{"_id":"source/_posts/Introduction-to-Probability.md","hash":"0b37324cc16c6d73c847babfa8df5a1a00cd3e80","modified":1710828076158},{"_id":"source/_posts/Computer-Network.md","hash":"ced15b73abb21612e03816bac72d423d9438b10a","modified":1710828076156},{"_id":"source/_posts/Digital-Signal-Processing.md","hash":"9d618c74ccaaedee7691ae18334f9f3fcb4d0cf8","modified":1710828076158},{"_id":"source/_posts/Python-OJ.md","hash":"9dba878185c7a6e83076e6309b97de61c85bad6b","modified":1710828076160},{"_id":"source/_posts/PhysicsExercise.md","hash":"b0f2ea58aee7f5677fbd36b722b41da7ea4d26a2","modified":1710828076160},{"_id":"source/_posts/SSP.md","hash":"0392ab0e42eb5df5d572e52e0ead9bff6ea7888b","modified":1711255009705},{"_id":"source/_posts/Speech-SP.md","hash":"e7a4be58f922f3770b8f787eed3f25f7b79c9fb3","modified":1716988742607},{"_id":"source/_posts/github-command.md","hash":"caaa5180e0598fb2c80841e8aa927233ea0de311","modified":1710828076164},{"_id":"source/_posts/Stochastic-Process.md","hash":"ae6b1a7d0ab5b56d8297f0972a83d54b4f553837","modified":1710828076164},{"_id":"source/_posts/stuffs.md","hash":"fce31a4287cfa4067f0082d6b320ee7d3b293867","modified":1756993626003},{"_id":"source/_posts/cpp-multi-file.md","hash":"0307497a46ad26e667d38e792af3526b811de7bc","modified":1710828076164},{"_id":"source/_posts/hello-world.md","hash":"7cb66df1b742d7488b6247ae3fed0e14d6206cf5","modified":1711069622466},{"_id":"source/images/DSA/Duopule.jpg","hash":"e5ad81d5fa199a2c4f0bc88fb3d8428aef4a578e","modified":1710828076164},{"_id":"source/_posts/数字系统设计.md","hash":"a837cc33cfd433b80a46a99fa261e384b7eb23d7","modified":1710828076164},{"_id":"source/_posts/数逻.md","hash":"7ba712f259840181bcd093100a9c76dea12fa760","modified":1710828076164},{"_id":"source/images/DSA/waveDuopl.jpg","hash":"3fbe893ed33fe4d8ddc8faca1b1280a47a0bc96c","modified":1710828076180},{"_id":"source/_posts/通网.md","hash":"238ff9c1e33830cd6244b1775d78c4a5817cfa0c","modified":1710828076164},{"_id":"source/_posts/量筒.md","hash":"43c952fac05a20e994dc1f6735532f61b4b6a47b","modified":1710828076164},{"_id":"source/images/DSD/2_1.jpg","hash":"9f1da44162d92692c574ffb029818da84b8bdbbb","modified":1710828076182},{"_id":"source/images/DSD/2_4.jpg","hash":"aa5b1c3ef80f88077efd1942526d2bd0720044b6","modified":1710828076186},{"_id":"source/images/DSD/3_10.jpg","hash":"0f8cb4b6d48c96af6a129d9839d913a9fbad6a2f","modified":1710828076188},{"_id":"source/images/DSD/3_1.jpg","hash":"cffbec97b2de3330bf135fa2fe4eeb5e56906af3","modified":1710828076187},{"_id":"source/images/DSD/3_5.jpg","hash":"0103a7fdddc1171e20106661c139e6a33a64d5ca","modified":1710828076193},{"_id":"source/images/DSD/3_3.jpg","hash":"f04d4ff79c5f1a9e7ddfa7c9fc017aaf09b884a2","modified":1710828076190},{"_id":"source/images/DSD/3_7.jpg","hash":"55a1515bdab5b05d92f9789d7b4dd990a31c2634","modified":1710828076196},{"_id":"source/images/DSD/3_2.jpg","hash":"75d3c702edcad3cc9d331c20045a9154a3a17c04","modified":1710828076189},{"_id":"source/images/DSD/3_8.jpg","hash":"b0ee9ed7902c4e38c1028bb0c4588d0a0e1377b7","modified":1710828076197},{"_id":"source/images/DSD/4_1.jpg","hash":"d8069f98033119cd01625a3e8cce988a827bc449","modified":1710828076199},{"_id":"source/images/DSP/5_2.jpg","hash":"c2bb6812241758a968869828d12feab3793fe774","modified":1710828076214},{"_id":"source/images/prob/L14_1.jpg","hash":"3927ec89bf5887d4ac7ba528a3b5f8c84efd2fb9","modified":1710828076514},{"_id":"source/images/oj/1.jpg","hash":"b3a341db0e8f930e9568c18885ce84f53faa9af1","modified":1710828076464},{"_id":"source/images/physics/STM.jpg","hash":"596bef4a79f8a4b91a1c34e82e642d18db6ba4e3","modified":1710828076505},{"_id":"source/images/digital/lec_3_1.jpg","hash":"edada7524ca5edfdb7f322f0a39cd09b178029c7","modified":1710828076263},{"_id":"source/images/digital/lec_4_1.jpg","hash":"c25f9444da893d365559dd58067ab629ea119855","modified":1710828076263},{"_id":"source/images/digital/lec_4_12.jpg","hash":"d862d0d9e99fb7e62eb385dd0967092fa7c0c7d5","modified":1710828076263},{"_id":"source/images/digital/lec_4_13.jpg","hash":"6a50965180a5397a3888c4defcfa8c4ae5aa200a","modified":1710828076263},{"_id":"source/images/digital/lec_4_2.jpg","hash":"2a4da85dfcb43240c8b2f3cecc6b47932b27a16f","modified":1710828076279},{"_id":"source/images/digital/lec_4_3.jpg","hash":"6bc9184cb64471c0ff4e1c8a16c4dd6ee23f8c0d","modified":1710828076280},{"_id":"source/images/digital/lec_4_4.jpg","hash":"e3aa49a288afcfba35c3b2ae9137bea527e9a830","modified":1710828076281},{"_id":"source/images/digital/lec_4_6.jpg","hash":"eba9a1f88300b5e816fc20472cb29b34d54d72c7","modified":1710828076283},{"_id":"source/images/digital/lec_5_10.jpg","hash":"887cd7c3d824363c5810690736c48f4e74fd5434","modified":1710828076290},{"_id":"source/images/digital/lec_5_18.jpg","hash":"6c95687ec98555ece9b8e10661915000dcec7d9e","modified":1710828076303},{"_id":"source/images/digital/lec_5_22.jpg","hash":"db4956160fd4341e3c6cf7c1185343a8d0b86424","modified":1710828076311},{"_id":"source/images/digital/lec_5_23.jpg","hash":"ec9fc53fc59887c6312216f347e93dbf58d1260c","modified":1710828076312},{"_id":"source/images/digital/lec_5_24.jpg","hash":"9714b01e61c2ac2c8f9788734e3b061d626fdeab","modified":1710828076313},{"_id":"source/images/digital/lec_5_25.jpg","hash":"3f3aacd93c5d58c51538a58a840b80d35b298735","modified":1710828076313},{"_id":"source/images/digital/lec_5_9.jpg","hash":"f5dd319180a7613ff1e6f6f3fa8ee465a4b91e01","modified":1710828076313},{"_id":"source/images/digital/lec_9_2.jpg","hash":"f6f2f7b49d1fb080f2bfba5b06c43763e0116ea1","modified":1710828076463},{"_id":"source/images/ss/lec10_8.jpg","hash":"d7747774782b5a99b398befbb5d24b0ad998a2c5","modified":1710828076543},{"_id":"source/images/ss/lec11_1.jpg","hash":"ebd5178b7810226dbdee7284378029dd6e0de850","modified":1710828076544},{"_id":"source/images/ss/lec17_1.jpg","hash":"46b8fb403aaeb79557f2dafbf6303336a1eaf6e5","modified":1710828076583},{"_id":"source/images/ss/lec19_1jpg.jpg","hash":"ca4809664ab4a92d92a85a9956325be4f0b8e008","modified":1710828076593},{"_id":"source/images/ss/lec20_1.jpg","hash":"ebd8e54c71d2e5ac13e1d2deff0eb3aca907fed3","modified":1710828076597},{"_id":"source/images/ss/lec20_4.jpg","hash":"976d51da842b56042fe680e7f73f1fd28593e83f","modified":1710828076601},{"_id":"source/images/ss/lec20_5.jpg","hash":"7c3aa78e8d22ddc4794a9bf575933e4f8456900d","modified":1710828076602},{"_id":"source/images/ss/lec21_7.jpg","hash":"ea49ade0ad5bd1bbd96cc0192de6dcc6aad8a246","modified":1710828076614},{"_id":"source/images/ss/lec21_9.jpg","hash":"ea49ade0ad5bd1bbd96cc0192de6dcc6aad8a246","modified":1710828076614},{"_id":"source/images/ss/lec22_11.jpg","hash":"c675a9bbe46209ced1117832ec356321f76e394a","modified":1710828076614},{"_id":"source/images/ss/lec22_16.jpg","hash":"0a37144a5783a883ccb90bf5af79943bc144862a","modified":1710828076633},{"_id":"source/images/ss/lec22_15.jpg","hash":"731c358606e81d7e331defd0522042c48beccbef","modified":1710828076632},{"_id":"source/images/ss/lec22_20.jpg","hash":"438d61b76e2806bc7f71025256d5ff063da3a56e","modified":1710828076638},{"_id":"source/images/ss/lec2_.jpg","hash":"5fa6ec6fe9b51852f00097275cb5aaa27dd39ca7","modified":1710828076640},{"_id":"source/images/ss/lec7_1.jpg","hash":"c2c6ec7a602e674cdaeab8206dca12156227b2b0","modified":1710828076647},{"_id":"source/images/ss/lec7_3.jpg","hash":"333d27a9f5caba2d62377e87e81f114c5aa710d1","modified":1710828076650},{"_id":"source/images/ss/lec7_2.jpg","hash":"250d81f6c2966194529349bb0cd68b778beb16a9","modified":1710828076648},{"_id":"source/images/ss/lec9_1.jpg","hash":"51dd547f87a1b7d9a049522fdd61e3e96c9ed245","modified":1710828076651},{"_id":"source/images/ss/lec9_2.jpg","hash":"884ab6452f9d9eece080e898dc737ad8e9910876","modified":1710828076652},{"_id":"source/images/ss/lec9_3.jpg","hash":"8fad27b2b76bb97d8a6b49ab0802383bf7bc15cc","modified":1710828076653},{"_id":"source/images/ss/lec9_5.jpg","hash":"0a0b1cb86fb99d82bd8e19169e268a1271f3011c","modified":1710828076655},{"_id":"source/images/ss/lec9_4.jpg","hash":"db13d6870f53e2c19ada8e8ecef11a9b77fbbb26","modified":1710828076654},{"_id":"source/images/量筒/xt_2_2.jpg","hash":"1938bc966a250f61150f63942f2d2081abcb26ef","modified":1710828076763},{"_id":"source/images/通网/4_2.jpg","hash":"d01055cd7a5883ccd3677249084d1378a8899aff","modified":1710828076705},{"_id":"source/images/通网/4_3.jpg","hash":"911a6745b6c95f67cf621df474098cf98356a093","modified":1710828076706},{"_id":"source/images/通网/4_4.jpg","hash":"c4d406015e582a2048e6b13194d54daf0285de6e","modified":1710828076707},{"_id":"source/images/通网/5_6.jpg","hash":"2cb41812aca27f170c53cc1c98b51615e69f772f","modified":1710828076728},{"_id":"source/images/通网/5_5.jpg","hash":"82bf6a741df61e1e33ae9f4e66550e100b201ef1","modified":1710828076726},{"_id":"source/images/通网/5_9.jpg","hash":"bee1b86c80bec9fd58c7cca6858dbad4eb97534b","modified":1710828076736},{"_id":"source/_posts/Physics.md","hash":"bd1814fbd087b3dc305fa640387f44edac8b2f32","modified":1710828076159},{"_id":"source/_posts/Signal-and-Systems.md","hash":"ad898cc1b8f5438196437148c4f29aa5c2070b3c","modified":1710828076162},{"_id":"source/images/DSD/2_3.jpg","hash":"2b14827af4eed02b175b1b343bd11385ff47e33a","modified":1710828076185},{"_id":"source/images/DSD/2_2.jpg","hash":"b5290376215b2785bcdd78466d82709e51d43592","modified":1710828076184},{"_id":"source/images/DSD/3_4.jpg","hash":"f958ced57a88f845b4457be5503e9d23ff9d6a0a","modified":1710828076192},{"_id":"source/images/DSD/3_6.jpg","hash":"6b3c2f12024cfdff8d3e156bb709ea953c16e052","modified":1710828076195},{"_id":"source/images/DSD/4_10.jpg","hash":"8bf7fe44e993c474a1136e0746153816651f01eb","modified":1710828076201},{"_id":"source/images/DSD/4_3.jpg","hash":"3f8979ba7e5a717b85ec700a11e33d08738e6371","modified":1710828076204},{"_id":"source/images/DSD/4_6.jpg","hash":"7323c73c34be17971da156274a7d8add13295998","modified":1710828076210},{"_id":"source/images/DSD/4_8.jpg","hash":"1c566a4a8a8727c2fc25a9883e0097763f893e12","modified":1710828076214},{"_id":"source/images/DSD/4_7.jpg","hash":"f1ad605512ad26cd7ceda74a8e85addcb67e8322","modified":1710828076211},{"_id":"source/images/DSP/4_2.jpg","hash":"b51c2a45d2ccba2f34005c7894671f90cfbe2a49","modified":1710828076214},{"_id":"source/images/DSD/4_9.jpg","hash":"2ddda7367a7e91a948d0c4604fe14c4a4a3bea8e","modified":1710828076214},{"_id":"source/images/StaSP/2_1.jpg","hash":"c346abd8c965cfd79f62ad73e377009b0bc47827","modified":1710828076214},{"_id":"source/images/DSP/5_1.jpg","hash":"445e6dd85968287a4b03e9c090d57ae0e98eb354","modified":1710828076214},{"_id":"source/images/StaSP/2_2.png","hash":"7fb646fb83a0d610e3b36253c39408130df3790b","modified":1710828076214},{"_id":"source/images/prob/L15_1.jpg","hash":"2f58838aa5f9c71ff1a725030555d6bb4a2bf97a","modified":1710828076514},{"_id":"source/images/prob/L2_1.jpg","hash":"6bc13a99f6db10bb9d24355b95afa33df70f32c8","modified":1710828076514},{"_id":"source/images/physics/guocheng.png","hash":"888f3071bfcf910ba32e6e3c58efa1126bec17dd","modified":1710828076512},{"_id":"source/images/physics/shuangzheshe.jpg","hash":"ee9e38a400cf844be2594c9139c8bc6a0a798e93","modified":1710828076514},{"_id":"source/images/physics/zhilengxunhuan.png","hash":"9cbb28af11c3d23dcced351be6e0e94f3130a495","modified":1710828076514},{"_id":"source/images/physics/shuangfeng.jpg","hash":"5d7aea11be84af2c958a4a74c1e4eb33e02fa673","modified":1710828076514},{"_id":"source/images/physics/xunhuantu.png","hash":"2217ae80004a1eb0a1e6e704c047f3c30b37a076","modified":1710828076514},{"_id":"source/images/physics/非单色光.jpg","hash":"8a7ab7c4fd301daa6bf31ee320e42d05d49173a4","modified":1710828076514},{"_id":"source/images/physics/准单色光.jpg","hash":"d0af0831771212a7074979ce82522a1942363ad3","modified":1710828076514},{"_id":"source/images/digital/lec_10_3.jpg","hash":"df407f03cc70cfc1a938f8b10cb9b0690c5b5e73","modified":1710828076235},{"_id":"source/images/digital/lec_11_1.jpg","hash":"72d2768f50b72e65b4676f4b1949812d79db8f73","modified":1710828076249},{"_id":"source/images/digital/lec_4_1.jpg8.jpg","hash":"ab85d2d03a50046744cea89e39a397cb8a5c81bc","modified":1710828076263},{"_id":"source/images/digital/lec_4_11.jpg","hash":"c7c73afa94fc0b361349584e779d7ad672cc975a","modified":1710828076263},{"_id":"source/images/digital/lec_4_10.jpg","hash":"5f31069580e49e94edf5ee5c3bca7e3b96206736","modified":1710828076263},{"_id":"source/images/digital/lec_4_14.jpg","hash":"300164959d00570d67e76786c981451c76161187","modified":1710828076263},{"_id":"source/images/digital/lec_4_16.jpg","hash":"365346fe9c012ffedca74ba97e59036b9d291d92","modified":1710828076263},{"_id":"source/images/digital/lec_4_17.jpg","hash":"d7e723a63e6a84f9d3fcb0c98677534fa0082230","modified":1710828076263},{"_id":"source/images/digital/lec_4_15.jpg","hash":"f8e19d0a13554cded65a49caf0f18933893e048b","modified":1710828076263},{"_id":"source/images/digital/lec_4_5.jpg","hash":"1093a862a0f2be73602cee1a392d2c01c4ec9190","modified":1710828076282},{"_id":"source/images/digital/lec_4_8.jpg","hash":"45452409372207868e50cb1fb2add3102ffdb28a","modified":1710828076287},{"_id":"source/images/digital/lec_4_9.jpg","hash":"c858ff4bd01cbfd89943aebad19457144efbd761","modified":1710828076288},{"_id":"source/images/digital/lec_5_1.jpg","hash":"a44fb2fe181038ef167ce43009d4e6d9e0099b0d","modified":1710828076290},{"_id":"source/images/digital/lec_5_17.jpg","hash":"ea0787376daa123e92a7d3ecb8129d4239629a60","modified":1710828076302},{"_id":"source/images/digital/lec_5_13.jpg","hash":"8290c0bd2a4724d50ce2278f77fed500db3d99a3","modified":1710828076296},{"_id":"source/images/digital/lec_5_16.jpg","hash":"e48d460a1385f716b426ed354572d9d24cf93b7b","modified":1710828076301},{"_id":"source/images/digital/lec_5_26.jpg","hash":"c348de049108cfac6c679861b3358ed8c773dc6f","modified":1710828076313},{"_id":"source/images/digital/lec_5_3.jpg","hash":"a76126dc14c4895249dadeea74f2ca87ca46b397","modified":1710828076313},{"_id":"source/images/digital/lec_5_4.jpg","hash":"94ca9923fb72e4efb1670d655331c59c0a155167","modified":1710828076313},{"_id":"source/images/digital/lec_5_7.jpg","hash":"5bca98e70f3b3c8714a10de3fdb8d5661068d5e9","modified":1710828076313},{"_id":"source/images/digital/lec_5_6.jpg","hash":"a3d2964b5cf46c4fe3de20b0a848db1843e5ec32","modified":1710828076313},{"_id":"source/images/digital/lec_5_5.jpg","hash":"ffcaf91ad9d8c88f8e2484abf70f5eb70b103bb2","modified":1710828076313},{"_id":"source/images/digital/lec_7_15.jpg","hash":"7a8e4863c4b191c37c921290da6ed5694d4ddcba","modified":1710828076357},{"_id":"source/images/digital/lec_7_16.jpg","hash":"f61a278543108441e51035a02abe9df4dca3680f","modified":1710828076359},{"_id":"source/images/digital/lec_7_18.jpg","hash":"f6e0fe5be468fb3b144cdbaf90698f86d4c9a058","modified":1710828076362},{"_id":"source/images/digital/lec_7_6.jpg","hash":"7d89400fe1ca832246d4305f635ec5f230fc701b","modified":1710828076381},{"_id":"source/images/digital/lec_7_7.jpg","hash":"e1d8df6eb6519a15423f92dd7071db717b5ed78d","modified":1710828076382},{"_id":"source/images/digital/lec_8_23.jpg","hash":"39b63f83481b0981eb73c91304a1a02b3125fa8a","modified":1710828076413},{"_id":"source/images/digital/lec_8_25.jpg","hash":"34314d405ebec5480851ef1bc889ceb5bda8d441","modified":1710828076413},{"_id":"source/images/ss/lec10_2.jpg","hash":"21a5eef090129732e232f0f17a25d770042ef329","modified":1710828076535},{"_id":"source/images/ss/lec10_3.jpg","hash":"0497895930678d17632d40fd23e16d17bd4751c1","modified":1710828076536},{"_id":"source/images/ss/lec10_4.jpg","hash":"07debb0b6e0f7b5062b042744022d0151f7b46a3","modified":1710828076538},{"_id":"source/images/ss/lec10_5.jpg","hash":"a4f0ba9415e97ec2c47d2f363de896d0f81579fe","modified":1710828076539},{"_id":"source/images/ss/lec10_6.jpg","hash":"ef65d398b672595ab110affe00be9a3b70ebb34d","modified":1710828076540},{"_id":"source/images/ss/lec10_7.jpg","hash":"831de2e97fa41c69d61588bff361e598f1e53565","modified":1710828076542},{"_id":"source/images/ss/lec11_3.jpg","hash":"7da5e0d3fe410924ebeb78018444b310c0f7c222","modified":1710828076547},{"_id":"source/images/ss/lec11_2.jpg","hash":"75511dc4fb4423ec46119ea09031d06bc04e8dc4","modified":1710828076545},{"_id":"source/images/ss/lec12_3.jpg","hash":"1fe84a4b27abf017283111a7e0209c3bc8e25390","modified":1710828076552},{"_id":"source/images/ss/lec12_4.jpg","hash":"80350c462c2f119af20bc370ed6cde5c626daf27","modified":1710828076553},{"_id":"source/images/ss/lec12_1.jpg","hash":"a930599c713068b260ed644a462b1d3e2c41fd8f","modified":1710828076549},{"_id":"source/images/ss/lec12_2.jpg","hash":"b22d597dc7b1d96135d459e552fea741a6cf690c","modified":1710828076550},{"_id":"source/images/ss/lec12_5.jpg","hash":"b9e8dcd6a2c7645114dc5f51f3861e7241a17381","modified":1710828076554},{"_id":"source/images/ss/lec12_6.jpg","hash":"49c28104827079cdf09f531688be6c5f63eaba8e","modified":1710828076555},{"_id":"source/images/ss/lec13_1.jpg","hash":"9631b1fc35580f91005a193eb3d491ec34572930","modified":1710828076559},{"_id":"source/images/ss/lec12_8.jpg","hash":"73b0291e93b29d6a2fd5ba2fc773935a2572dc54","modified":1710828076557},{"_id":"source/images/ss/lec12_7.jpg","hash":"a4d254ae3f4ecf067e13332084e1625c007569d3","modified":1710828076556},{"_id":"source/images/ss/lec14_3.jpg","hash":"91a426fd4496d592268867c5d29f2f236190e901","modified":1710828076563},{"_id":"source/images/ss/lec14_1.jpg","hash":"c08e651599e2ebb24fe4cc2e86d00f755fc10ac5","modified":1710828076560},{"_id":"source/images/ss/lec14_2.jpg","hash":"202676a12cafa1d93dd10a3d67da15fc14e3f6fc","modified":1710828076561},{"_id":"source/images/ss/lec14_4.jpg","hash":"4b59afa50f050fc0a19b8a978ba056af45c9d178","modified":1710828076564},{"_id":"source/images/ss/lec14_5.jpg","hash":"a674ffb041eb69fda2a49ab9c5539f7c26c88fef","modified":1710828076564},{"_id":"source/images/ss/lec14_6.jpg","hash":"a464a171400069fc550de5e910609eed1742510c","modified":1710828076564},{"_id":"source/images/ss/lec15_2.jpg","hash":"7e1d7d2ae08676437709fe55085648d6661e7076","modified":1710828076564},{"_id":"source/images/ss/lec15_1.jpg","hash":"ccbef01147233a721388ba36037825eea7e26f31","modified":1710828076564},{"_id":"source/images/ss/lec15_3.jpg","hash":"20cf8f7d6a87f8d1fd3e45eb6cd32d764a04ba72","modified":1710828076564},{"_id":"source/images/ss/lec15_5.jpg","hash":"4961bda2c87a59f3aed7119ca3514494fb621578","modified":1710828076564},{"_id":"source/images/ss/lec16_.jpg","hash":"abb1b5008bf02ec34a20e9d73550a53c16caf061","modified":1710828076564},{"_id":"source/images/ss/lec15_6.jpg","hash":"aaa851dedcf7a6d1f0c15f1a052d9449a24e6a3b","modified":1710828076564},{"_id":"source/images/ss/lec15_4.jpg","hash":"79b6366ab7d12125acd887b44c5a998877a6e31d","modified":1710828076564},{"_id":"source/images/ss/lec16_1.jpg","hash":"c44f634c1b25b0ccf5395956ee0274c3ec2cc661","modified":1710828076564},{"_id":"source/images/ss/lec16_3.jpg","hash":"95e9d390437a4faffd28371efe50dd016993bf09","modified":1710828076581},{"_id":"source/images/ss/lec16_2.jpg","hash":"ba37f611661b74c3721f1b9c85950c433b3b1b9e","modified":1710828076564},{"_id":"source/images/ss/lec16_4.jpg","hash":"b047472123193bf630fdb12b788c0b047237aafa","modified":1710828076582},{"_id":"source/images/ss/lec18_2.jpg","hash":"036740d8df8c8b5426859df715dfa660c4b86eb5","modified":1710828076587},{"_id":"source/images/ss/lec18_3.jpg","hash":"8f714384027748b7623f59fd229067eab0af3230","modified":1710828076588},{"_id":"source/images/ss/lec18_34jpg.jpg","hash":"98af5db7d2b8cffd6f5767e96fff29fe0593289a","modified":1710828076589},{"_id":"source/images/ss/lec19_2jpg.jpg","hash":"8731e0ee32cf1a390a69b043aa636561113d7dbc","modified":1710828076594},{"_id":"source/images/ss/lec18_5jpg.jpg","hash":"b8ff1222f8c78c97522dfaa1248756d1f49b9d89","modified":1710828076590},{"_id":"source/images/ss/lec19_3.jpg","hash":"35c4a0b41f6e55fc5dca85287a280b91692d623f","modified":1710828076596},{"_id":"source/images/ss/lec20_6.jpg","hash":"7e68a488b20b1f1ecf35f2568d47b67891bf3ad5","modified":1710828076604},{"_id":"source/images/ss/lec20_7.jpg","hash":"ffc0c7117a0d866929a7955b63563893b8554eae","modified":1710828076605},{"_id":"source/images/ss/lec20_8.jpg","hash":"a12a5b78db4a1be853e897e6e584b55458c25f71","modified":1710828076606},{"_id":"source/images/ss/lec21_4.jpg","hash":"007b49c5c4be30b46905a49ccb2cbb18811af6d9","modified":1710828076614},{"_id":"source/images/ss/lec21_5.jpg","hash":"79690f154924316f63bc099c76adc471ff220771","modified":1710828076614},{"_id":"source/images/ss/lec21_6.jpg","hash":"2e32bb32f9ca6ad047ae96ec68cb1862d4f7ce5e","modified":1710828076614},{"_id":"source/images/ss/lec22_13.jpg","hash":"dccb43f0fa9c701ff0932394960ced50c69d3635","modified":1710828076614},{"_id":"source/images/ss/lec22_12.jpg","hash":"fdf34d0d1fa024b6ee39e20170b9472da408470e","modified":1710828076614},{"_id":"source/images/ss/lec22_14.jpg","hash":"3264b29db2fa8cd74aaaa26220052e4f82b7b3db","modified":1710828076630},{"_id":"source/images/ss/lec22_17.jpg","hash":"6de11febc03de48065165fd7121a39769b54bb96","modified":1710828076634},{"_id":"source/images/ss/lec22_18.jpg","hash":"96642dac70f0e02421222fbc44ce3d41fa1b0272","modified":1710828076635},{"_id":"source/images/ss/lec22_19.jpg","hash":"bf45a5c325d558407edc626979fe0456d1596e92","modified":1710828076637},{"_id":"source/images/ss/lec23_1.jpg","hash":"eaa2dc9fa1eba2402e7c92a9b4491e727c8290df","modified":1710828076639},{"_id":"source/images/ss/lec2_2.jpg","hash":"a162bb87e16215e0a94f9117ed2ea6b8b647949d","modified":1710828076641},{"_id":"source/images/ss/lec2_3.jpg","hash":"725316bead110ce017dd3de8184fe5f0228f1f5b","modified":1710828076643},{"_id":"source/images/ss/lec3_1.jpg","hash":"2f0fe1a07c93e6b427b32ef33498f6239e901e45","modified":1710828076644},{"_id":"source/images/ss/lec7_4.jpg","hash":"66be79b0fdaf36028454719f642a440126c96177","modified":1710828076651},{"_id":"source/images/stochastic/exer_1.jpg","hash":"32f00f5be748ed38e8aea6fbba094d3c8d1517af","modified":1710828076658},{"_id":"source/images/计网/3_2.jpg","hash":"2cbcfcc7943d25460bf8c50f5030571af4718f98","modified":1710828076661},{"_id":"source/images/ss/lec9_6.jpg","hash":"2bda5b76668b88a752ff0e639f0ebbe2194070a1","modified":1710828076656},{"_id":"source/images/计网/3_6.jpg","hash":"4f0cfa50ecc467ce7ad6cba2ec74b86c4d2e77e3","modified":1710828076663},{"_id":"source/images/计网/3_4.jpg","hash":"ff27e894e52d63cccb9e9d9404f77de9edf2d9fa","modified":1710828076663},{"_id":"source/images/计网/3_5.jpg","hash":"55fd8e991d94dfcc55f6ae94ddb049d7e8fec8af","modified":1710828076663},{"_id":"source/images/计网/5_2.jpg","hash":"b20c156e34760e33b8f1a294ea7cee01b6a91cf5","modified":1710828076663},{"_id":"source/images/量筒/8_4.jpg","hash":"421abf88818ef5d029dbdaf9448399237bda558f","modified":1710828076759},{"_id":"source/images/通网/2_2.jpg","hash":"40ceeefeb6ade57c2bb18a3cc0ea218fd0e5c0a2","modified":1710828076681},{"_id":"source/images/通网/3_2.jpg","hash":"1cd46305eea0f5d2349f57e50a68fc6787b806f5","modified":1710828076696},{"_id":"source/images/通网/2_9.jpg","hash":"4b899dea9f8cc94fb2750be57465073210ae571f","modified":1710828076693},{"_id":"source/images/通网/3_3.jpg","hash":"8379204f1d0df2dcbec9cbc29a5f34b147b729eb","modified":1710828076697},{"_id":"source/images/通网/3_6.jpg","hash":"27be953951b0461e0aa5cc410aa644e3db816289","modified":1710828076701},{"_id":"source/images/通网/3_4.jpg","hash":"a23e38041320adbfb831fcb17708f11d2bc57d4a","modified":1710828076698},{"_id":"source/images/通网/3_5.jpg","hash":"3b1cb3b75084a1a60e827a94583eefe8daddcd20","modified":1710828076699},{"_id":"source/images/通网/4_5.jpg","hash":"b4088e5b435c89e0818990a3c577c2f8d4df0f8f","modified":1710828076708},{"_id":"source/images/通网/4_7.jpg","hash":"31ec5772752d7e0fe82e146b65b7c4cb8722ca83","modified":1710828076711},{"_id":"source/images/pht.png","hash":"b8620d73e45d53a8cd90ee95d9d54d6962b46903","modified":1710828076480},{"_id":"source/images/DSA/Dijkstra.jpg","hash":"4eef33b8fee3a96661dd74b148881e3922d31e44","modified":1710828076164},{"_id":"source/images/DSD/3_9.jpg","hash":"2d1794a0b4c0eddb14556ed27beb362a79521301","modified":1710828076198},{"_id":"source/images/DSD/4_2.jpg","hash":"77cb7871dd5b62b562457e8bc2be0b89f5a6697f","modified":1710828076203},{"_id":"source/images/DSD/4_4.jpg","hash":"50c8ee11addd6480f4ea3bccb2650de5fa1065f3","modified":1710828076206},{"_id":"source/images/StaSP/1_1.jpg","hash":"31135420c357f9d13f5bcac3b585984900d87f89","modified":1710828076214},{"_id":"source/images/prob/L6_1.jpg","hash":"13eb76996c2c53e2b86ee78198e053e46ede1272","modified":1710828076530},{"_id":"source/images/physics/VanGas.png","hash":"6b6b27fc32f30de20ce9ff40f147ebe06f320c26","modified":1710828076507},{"_id":"source/images/physics/abaaba.jpg","hash":"618d3f739521c43a12d6bd5f420c0f87bc647500","modified":1710828076511},{"_id":"source/images/physics/niudunhuan.jpg","hash":"eb504efd970be083ade5d94914590aeed1897230","modified":1710828076514},{"_id":"source/images/physics/rexunhuan.png","hash":"0b2df0ba960f3f2aa4133349af7a8bf396ea7202","modified":1710828076514},{"_id":"source/images/digital/lec_10_4.jpg","hash":"35b7b69fca21bdd0760ba1e86826ab79712e4c95","modified":1710828076237},{"_id":"source/images/digital/lec_10_6.jpg","hash":"340f6842eb362fe6d843d762e5fbe2eb947fe162","modified":1710828076241},{"_id":"source/images/digital/lec_10_5.jpg","hash":"9d134940ec421c5f88f6483093ad2eb866488717","modified":1710828076239},{"_id":"source/images/digital/lec_10_7.jpg","hash":"a9952524683952a437e6553221df6ce3894206ea","modified":1710828076243},{"_id":"source/images/digital/lec_10_8.jpg","hash":"ecdf70e1620a1f99e80ab84b28f3fcf360c5fec8","modified":1710828076245},{"_id":"source/images/digital/lec_10_9.jpg","hash":"a180dcb7661c5844ef1d824de09540d0a6a5ec59","modified":1710828076247},{"_id":"source/images/digital/lec_12_4.jpg","hash":"db855b375313eedbc32248132a8f17eddba15b5e","modified":1710828076258},{"_id":"source/images/digital/lec_12_5.jpg","hash":"4a8f65c24fe7a2e92fadff746f091e9377d25610","modified":1710828076260},{"_id":"source/images/digital/lec_4_7.jpg","hash":"e29188e3a2bca41ccb521653d7e3288c78fe086b","modified":1710828076285},{"_id":"source/images/digital/lec_5_12.jpg","hash":"380d94316a1cd2d4fa193fe535ce964ac860159c","modified":1710828076294},{"_id":"source/images/digital/lec_5_11.jpg","hash":"29a8c5b9a48ef863f1b4d22669193505a3060eb1","modified":1710828076292},{"_id":"source/images/digital/lec_5_15.jpg","hash":"ede82664e5d1e18c9d2e834d6873c6f49567dc80","modified":1710828076300},{"_id":"source/images/digital/lec_5_19.jpg","hash":"5640b4599915df5e2884b95fe1cc2e5db50a5266","modified":1710828076305},{"_id":"source/images/digital/lec_5_2.jpg","hash":"832f64bc363443593dff117cd801ffd00116860b","modified":1710828076306},{"_id":"source/images/digital/lec_5_21.jpg","hash":"e8a4fa2e25e70627d7704a8beb0c9291ceac4f79","modified":1710828076310},{"_id":"source/images/digital/lec_5_20.jpg","hash":"2a9c93f6fd82c88f39b574aaaec3fc7d0f306836","modified":1710828076308},{"_id":"source/images/digital/lec_5_8.jpg","hash":"bd65701efefbe7854149fd92b70bb0c1b36b50a0","modified":1710828076313},{"_id":"source/images/digital/lec_6_1.jpg","hash":"4fea1050f1f2f00e10763feca1991a536705c874","modified":1710828076313},{"_id":"source/images/digital/lec_6_2.jpg","hash":"ddefebfb295f54d7a14322182b86cd2decd3bd91","modified":1710828076331},{"_id":"source/images/digital/lec_6_4.jpg","hash":"7642493ee4c3d3e133a5556cffaaa4a2544ee431","modified":1710828076335},{"_id":"source/images/digital/lec_6_5.jpg","hash":"d4a02f8d7a14676a75b606a68b79121698d25a40","modified":1710828076336},{"_id":"source/images/digital/lec_6_7.jpg","hash":"dd667d6e2c54f25201231775dcd315c48d781ded","modified":1710828076340},{"_id":"source/images/digital/lec_6_8.jpg","hash":"0e88389774f0acdbc22c7302b18542825968ac0f","modified":1710828076341},{"_id":"source/images/digital/lec_6_3.jpg","hash":"4df0c8a5a1f85629bc3b246cefd30898720248b2","modified":1710828076333},{"_id":"source/images/digital/lec_6_6.jpg","hash":"4a891d561c2df4ae040f2d4dbf8e3a23913be328","modified":1710828076338},{"_id":"source/images/digital/lec_6_9.jpg","hash":"7618bf3c5033ffae1b1a9b77b0542930d6baea11","modified":1710828076343},{"_id":"source/images/digital/lec_7_.jpg","hash":"a3c97b001cc6ddc868ee3e562d06cb3e40975744","modified":1710828076345},{"_id":"source/images/digital/lec_7_11.jpg","hash":"698f6203a31a273cb6483da768469029738d237a","modified":1710828076351},{"_id":"source/images/digital/lec_7_12.jpg","hash":"b0b815b406e22f4a1da1eb3a79baed43a44b9b15","modified":1710828076352},{"_id":"source/images/digital/lec_7_10.jpg","hash":"3320cf85eebdece4724113b2bcc512338e4674b0","modified":1710828076349},{"_id":"source/images/digital/lec_7_1.jpg","hash":"0442970c3cb7893cc6f08cce621f96f7f036f9b5","modified":1710828076347},{"_id":"source/images/digital/lec_7_13.jpg","hash":"7671c90a6f9615adebefd300693426bff68fff3c","modified":1710828076354},{"_id":"source/images/digital/lec_7_14.jpg","hash":"3ae2633c956c40dd100aca48767b10d12b7a40ab","modified":1710828076356},{"_id":"source/images/digital/lec_7_17.jpg","hash":"8ede2f303b4fec3588be55619b272e12a5a5ffed","modified":1710828076360},{"_id":"source/images/digital/lec_7_2.jpg","hash":"4c00b00a17e0609a7951dfa3a93e9699acb24c23","modified":1710828076364},{"_id":"source/images/digital/lec_7_19.jpg","hash":"2e5c99f67fa20c839874e3293dfbe9eec6f7b25c","modified":1710828076364},{"_id":"source/images/digital/lec_7_20.jpg","hash":"43bc22242263a68070b3ffbf507e382b24a0a86d","modified":1710828076364},{"_id":"source/images/digital/lec_7_21.jpg","hash":"d4ea0bb23f64fe3710f5c8f0cf50749801ba37cb","modified":1710828076364},{"_id":"source/images/digital/lec_7_3.jpg","hash":"da8fc67f4fb0187a99f41dfef84fa6611f57ca62","modified":1710828076364},{"_id":"source/images/digital/lec_7_24.jpg","hash":"58bf400f31cf18ee0d32b26bc5d6efe67caa5a74","modified":1710828076364},{"_id":"source/images/digital/lec_7_5.jpg","hash":"140f804a57b423b92f96c3888c8c988cc5c9231c","modified":1710828076380},{"_id":"source/images/digital/lec_7_4.jpg","hash":"d7443865e0937d8e4364f0a7688de6acf9fa11f6","modified":1710828076364},{"_id":"source/images/digital/lec_8_1.jpg","hash":"be0347c9bcfa2d6f9622c111c6906ba67cb2fde5","modified":1710828076386},{"_id":"source/images/digital/lec_7_9.jpg","hash":"dedae3cdcffd40bf88c659901393b4b90536aef4","modified":1710828076384},{"_id":"source/images/digital/lec_8_12.jpg","hash":"f41f0e6add7b0a78fc0b06298c569e2318672c83","modified":1710828076392},{"_id":"source/images/digital/lec_8_13.jpg","hash":"db227cc960c93db3713226ed3a3216aa052a76a7","modified":1710828076393},{"_id":"source/images/digital/lec_8_14.jpg","hash":"16720de5361ffe49251e088548b4346c883f34c8","modified":1710828076395},{"_id":"source/images/digital/lec_8_11.jpg","hash":"aeff4c1c924d326243eb15f219a7688aa5ad1193","modified":1710828076390},{"_id":"source/images/digital/lec_8_15.jpg","hash":"80907c2b0cd82af84a60aacad5baf39829ab98b3","modified":1710828076397},{"_id":"source/images/digital/lec_8_16.jpg","hash":"844f4f188aa14b4beb3c19afb328208f357dfbdb","modified":1710828076399},{"_id":"source/images/digital/lec_8_18.jpg","hash":"1481678d4268bd34dd59e4a37ef2a7e010a45352","modified":1710828076402},{"_id":"source/images/digital/lec_8_19.jpg","hash":"5736c322861a12b51349a29b67b4fb5c960dd706","modified":1710828076404},{"_id":"source/images/digital/lec_8_22.jpg","hash":"8a9846cf58e03c058328116764ac6983053340b3","modified":1710828076412},{"_id":"source/images/digital/lec_8_21.jpg","hash":"d2a64d5a6a413a182ecbdb212e3c5e4a5519fa8b","modified":1710828076410},{"_id":"source/images/digital/lec_8_26.jpg","hash":"e3e229c92edce4d6fd87e251995080f23cbb545e","modified":1710828076413},{"_id":"source/images/digital/lec_8_24.jpg","hash":"8a78cd785165f3a65f100bf2e38cd18fcdd7567f","modified":1710828076413},{"_id":"source/images/digital/lec_8_27.jpg","hash":"766b669af3ffb087fd22721301045cc36132dab3","modified":1710828076413},{"_id":"source/images/digital/lec_8_28.jpg","hash":"e15ea17927c165f190151a8a9594acbbdc427495","modified":1710828076413},{"_id":"source/images/digital/lec_8_30.jpg","hash":"9f4833ce36d6d7b35abb3af7dfab98a93f6839b9","modified":1710828076431},{"_id":"source/images/digital/lec_8_31.jpg","hash":"593fa7efabdef3f2faeb15a7411a99dc74a4e4b7","modified":1710828076432},{"_id":"source/images/digital/lec_8_9.jpg","hash":"9e5bcd63f2520efb160a863c0171f20da2d79199","modified":1710828076448},{"_id":"source/images/digital/lec_9_10.jpg","hash":"ec2f8d0fea4752c1f8424dbc02484a255db063a4","modified":1710828076452},{"_id":"source/images/digital/lec_9_1.jpg","hash":"90d3b7c25486ccf52b308004bd7e0eb56f17d359","modified":1710828076450},{"_id":"source/images/digital/lec_9_12.jpg","hash":"f2943c01d1488ccb2a08bf563fc4035ba0b2804a","modified":1710828076456},{"_id":"source/images/digital/lec_9_11.jpg","hash":"9d9fb5a2301ef24a85968e0b12174639130398a6","modified":1710828076454},{"_id":"source/images/digital/lec_9_3.jpg","hash":"9c4db64e5e3a554506d6282e7db97459bb263a2a","modified":1710828076464},{"_id":"source/images/digital/lec_9_15.jpg","hash":"b8db983196f9ece3ed5e00d752ec5520a7cf46ad","modified":1710828076461},{"_id":"source/images/digital/lec_9_7.jpg","hash":"c2d61b2adb1d0f604d64c491a91ba8ca756d8a55","modified":1710828076464},{"_id":"source/images/digital/lec_9_6.jpg","hash":"d204f2bcf7a4067347580a77575be037a5f74937","modified":1710828076464},{"_id":"source/images/digital/lec_9_5.jpg","hash":"7d8597771bc19f1d9057ff4c13efa99cc0e83e56","modified":1710828076464},{"_id":"source/images/digital/lec_9_8.jpg","hash":"60e573b4be8658dc509d89658e01173051b2e594","modified":1710828076464},{"_id":"source/images/ss/lec14_7.jpg","hash":"2e36ab49ceed1fd39fab92f5464e3c25682016df","modified":1710828076564},{"_id":"source/images/ss/lec18_1.jpg","hash":"a7fa8ed7027fd0a34028dae2349faa095ec506a7","modified":1710828076585},{"_id":"source/images/ss/lec20_2.jpg","hash":"0a5fbee433b7e2bbeaec6131f848f2d6a50d8a05","modified":1710828076598},{"_id":"source/images/ss/lec18_6.jpg","hash":"f3549d95c4c81c1be0220798d807d979343f77fe","modified":1710828076592},{"_id":"source/images/ss/lec21_10.jpg","hash":"fe9f19d429acc43f76d9717886dc5309687afff6","modified":1710828076610},{"_id":"source/images/ss/lec3_2.jpg","hash":"a906a19d8e0634eaac5c0e1fc96cba999a9b7492","modified":1710828076646},{"_id":"source/images/计网/3_1.jpg","hash":"927a4946d1ca4d2882b0eccac78528713e44728e","modified":1710828076660},{"_id":"source/images/计网/3_3.jpg","hash":"5e0e302dab6df19d34540ff784d0b8d555ec9f34","modified":1710828076662},{"_id":"source/images/计网/3_7.jpg","hash":"173baed282253a13aceb6188e19085312746b797","modified":1710828076663},{"_id":"source/images/计网/5_1.jpg","hash":"6eef9e3839a5282cd1eefbaa3a5561dc13b210fd","modified":1710828076663},{"_id":"source/images/量筒/4_2.jpg","hash":"853f848229d5c658937941a937ab12649e5834ef","modified":1710828076739},{"_id":"source/images/量筒/5_1.jpg","hash":"eb74b8b4b9c0f44392f97b18a910dc0791b68dd3","modified":1710828076744},{"_id":"source/images/量筒/7_1.jpg","hash":"1714ca73675784421aa698e4df9f74cc23163a97","modified":1710828076748},{"_id":"source/images/量筒/xt_2_1.jpg","hash":"d7b18f090424cbc525805a62397fac2ccd6d0ea0","modified":1710828076761},{"_id":"source/images/通网/1_1.jpg","hash":"1b713b4f6587c0871033c5a6342391cf00e644d3","modified":1710828076663},{"_id":"source/images/通网/2_3.jpg","hash":"81f6c171ddc17f78e4b3acc2188633fa7e4c0165","modified":1710828076683},{"_id":"source/images/通网/2_6.jpg","hash":"197a16baefd7e69615e168bcb96030f480822bf5","modified":1710828076688},{"_id":"source/images/通网/2_7.jpg","hash":"4a2f0bebe2aa05389c984a1541f2e6d263dc12d8","modified":1710828076690},{"_id":"source/images/通网/2_1.jpg","hash":"a1048e294070504440b9d5309bb64fe7a61816d0","modified":1710828076679},{"_id":"source/images/通网/2_4.jpg","hash":"703106a3442e0ea30ff30019f8e3a283fb5de6d5","modified":1710828076684},{"_id":"source/images/通网/2_5.jpg","hash":"e9feeb6cbf1e46667d9f6d5fd7faf19f0f2f7df9","modified":1710828076686},{"_id":"source/images/通网/2_8.jpg","hash":"67e316302cab91bd3b727f9a6a46ca81579571fd","modified":1710828076692},{"_id":"source/images/通网/3_1.jpg","hash":"fa079c80e5582049e9d66da9d71f24a2f302b971","modified":1710828076694},{"_id":"source/images/通网/4_1.jpg","hash":"6829a1ebd018d381c2790c89c1fbe9987232d232","modified":1710828076702},{"_id":"source/images/通网/4_10.jpg","hash":"1fb1b3a3c8a7cf21e0216ed76c96889444e3a5e1","modified":1710828076704},{"_id":"source/images/通网/4_9.jpg","hash":"e4c02b62a7267dcc69abfb8b8038c5f2da3b231b","modified":1710828076715},{"_id":"source/images/通网/4_6.jpg","hash":"8ae655a7368410904cfc37b58f2cde91d564d188","modified":1710828076710},{"_id":"source/images/通网/4_8.jpg","hash":"daeb0a5d737099634c8255363d7b7d3168102d34","modified":1710828076714},{"_id":"source/images/通网/5_10.jpg","hash":"542669ad2d030e46fee3783437752cf2c24a1421","modified":1710828076719},{"_id":"source/images/通网/5_3.jpg","hash":"4e3cb527d58fe86e77979b276b72bf553ec74395","modified":1710828076723},{"_id":"source/images/通网/5_2.jpg","hash":"42156ca5327625de657e5b930ead8748098dfee9","modified":1710828076721},{"_id":"source/images/通网/5_1.jpg","hash":"5728e87d4898ceb92bafa8a59268d2bd0543e9be","modified":1710828076717},{"_id":"source/images/通网/5_7.jpg","hash":"dd77f472209d400caa4420a387401f027f72ed20","modified":1710828076731},{"_id":"source/images/通网/5_4.jpg","hash":"433150062daba05ac57d1e2e9196ea30879cc1f0","modified":1710828076725},{"_id":"source/images/通网/5_8.jpg","hash":"3c3527be32e2c7e954bb170bc08aac893e52383f","modified":1710828076734},{"_id":"source/images/DSA/Kruskal.jpg","hash":"873e13364b99f36fa0ccbaa2daff33d7298d1fed","modified":1710828076164},{"_id":"source/images/DSA/Prim.jpg","hash":"3279d8faad802dee5a6f7c1f245bd02146382070","modified":1710828076164},{"_id":"source/images/DSD/4_5.jpg","hash":"2931fd2cb79c624486bd789434f792ce5881f986","modified":1710828076209},{"_id":"source/images/digital/lec_12_3.jpg","hash":"3b247c788750d8fa2d8464a365f100f3c06039c2","modified":1710828076256},{"_id":"source/images/digital/lec_12_2.jpg","hash":"bc3911e20af46d67e0d87f15e9f9a898de8ae76a","modified":1710828076254},{"_id":"source/images/digital/lec_12_6.jpg","hash":"6f3dd256c76b26b6e3266d689dcca17de01d8b07","modified":1710828076262},{"_id":"source/images/digital/lec_5_14.jpg","hash":"4821f92a7b36db344e614664623a07d396228307","modified":1710828076298},{"_id":"source/images/digital/lec_7_23.jpg","hash":"6f602729f7d36d9cc8798018507fc8c7ea40ceef","modified":1710828076364},{"_id":"source/images/digital/lec_7_22.jpg","hash":"30e38709a2c518499da631333e9c3b59cdf04414","modified":1710828076364},{"_id":"source/images/digital/lec_8_10.jpg","hash":"6e002121b4634585b688c0c8651f7d36b66effa4","modified":1710828076388},{"_id":"source/images/digital/lec_8_17.jpg","hash":"02a3c638a22db900f51414d6c23843303700040d","modified":1710828076401},{"_id":"source/images/digital/lec_8_20.jpg","hash":"5e6c12b150a103ab4dad99bc7d2964408f8d57f3","modified":1710828076408},{"_id":"source/images/digital/lec_9_13.jpg","hash":"29d877020561fc6fd898f834c4a6aefd15c9df07","modified":1710828076458},{"_id":"source/images/digital/lec_9_14.jpg","hash":"62ba0c3330057d109e745358f17054428f45b9aa","modified":1710828076460},{"_id":"source/images/digital/lec_9_4.jpg","hash":"5724ce755665b949e21789a4a0c53c87dcdeb2c5","modified":1710828076464},{"_id":"source/images/digital/lec_9_9.jpg","hash":"5e411a2eff07906097aceafc28f9818b701070e2","modified":1710828076464},{"_id":"source/images/ss/lec20_3.jpg","hash":"2a9f788702b330b3726f8f0cad4f0d91ac111daf","modified":1710828076600},{"_id":"source/images/ss/lec21_3.jpg","hash":"a5cc04a441dd7539fa709d3def5c2bee70ad4eaa","modified":1710828076614},{"_id":"source/images/量筒/4——1.jpg","hash":"f7b4c70ddc1b045c078a9caef7989654ab9f6708","modified":1710828076742},{"_id":"source/images/通网/1_.jpg","hash":"13b2ffb4b4b587a7b9ff8fa3fea2e16ee2793a02","modified":1710828076663},{"_id":"source/images/量筒/8_2.jpg","hash":"8e839bf73a82e86a16158855f5751c0d0a47fd0e","modified":1710828076754},{"_id":"source/images/量筒/8_3.jpg","hash":"9cdfc11411da5cbe4116977b6bdf84379610caaa","modified":1710828076757},{"_id":"source/images/physics/RealGasTemp.png","hash":"3b2951ff9cbce1a60b0e14e7fad6370cbc0459cd","modified":1710828076504},{"_id":"source/images/physics/VanGasTemp.png","hash":"03759bcaea762e486db7e504d21eb6cff8c447b3","modified":1710828076509},{"_id":"source/images/digital/lec_10_10.jpg","hash":"e4914c28f39ef774ffb33795b15fabdb149ddfc8","modified":1710828076231},{"_id":"source/images/digital/lec_10_2.jpg","hash":"ca344aec7fa4127b283a05cbe54fd2d3227f04a8","modified":1710828076234},{"_id":"source/images/digital/lec_10_1.jpg","hash":"0614b3d28af8e10148471404c55498567e12de6c","modified":1710828076214},{"_id":"source/images/digital/lec_12_1.jpg","hash":"89d7f9a80d64a90f26d332a64fef17b822b7a0d9","modified":1710828076252},{"_id":"source/images/digital/lec_8_2.jpg","hash":"732dc6ede25a4010f0132f3b94885d8f99149888","modified":1710828076406},{"_id":"source/images/digital/lec_8_29.jpg","hash":"388f8fcfa82a3e67a86a51a03698567f1fbc4864","modified":1710828076413},{"_id":"source/images/digital/lec_8_8.jpg","hash":"356c29bc21a5b198d539525ccf02c725411f6b6a","modified":1710828076447},{"_id":"source/images/ss/lec21_1.jpg","hash":"5aeb4ff3438a113f1cd19ef8b17bf59eed813b11","modified":1710828076609},{"_id":"source/images/ss/lec21_8.jpg","hash":"c996fe97685e144e9b3de9cb249b1700884b452f","modified":1710828076614},{"_id":"source/images/量筒/8_1.jpg","hash":"2d576cfbb5ac4f4ca300ff6bc30c3994712eab48","modified":1710828076751},{"_id":"source/images/digital/lec_8_3.jpg","hash":"b331931b9bb43fe9c9b47d4e077143ce03a66f09","modified":1710828076429},{"_id":"source/images/digital/lec_8_4.jpg","hash":"51f44c78ef4cda452cd350dad779b06133404660","modified":1710828076435},{"_id":"source/images/digital/lec_8_5.jpg","hash":"080b493fb430863c7c66c33765815f52b7aed1b6","modified":1710828076438},{"_id":"source/images/digital/lec_8_6.jpg","hash":"fe977f317899d5c9279a7cdf49e90925a18de144","modified":1710828076441},{"_id":"source/images/digital/lec_8_7.jpg","hash":"1463983bd58c43cc75a5ba3b4f5b01cf6d8383d1","modified":1710828076443},{"_id":"source/images/ss/lec10_1.jpg","hash":"14ac8fca4864d718874bc156f8ce20d501c38a0c","modified":1710828076533},{"_id":"source/images/ss/lec21_2.jpg","hash":"f025e0cf9db1ba9a044e401a6a950892b5ab7467","modified":1710828076613},{"_id":"node_modules/hexo-theme-yun/LICENSE","hash":"29328e43254bc306816efe3b09018581e18db788","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/_config.yml","hash":"d64b00a8b357d09112a8b9ea2b608fbfd3a7536a","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/languages/en.yml","hash":"f6bdd8f04501bad6cb0480d4233cfea346147f22","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/_vendors.yml","hash":"690029ce3fd9f55b4307ae4d2afaf500530b5ab0","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/languages/zh-CN.yml","hash":"0d84fd939b07db22137b122ed4e9615f4e3a47c3","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/package.json","hash":"d15d101d5e04ab99a684ab066f6f4f80cccb67eb","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/languages/ja.yml","hash":"17354770a46fdd7c7301ee2278fbba411922eb02","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/404.pug","hash":"e96d09b7d27c22c0759514b00ebcf21c711cb021","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/category.pug","hash":"7466056d9d443ea04cef25c0c574385d050976a5","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/languages/default.yml","hash":"5d50a944a8b527fd857c81b17a60e5cc414c5729","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/archive.pug","hash":"2fff8c7364d0457b6a61342b30bac5330ff72a80","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/gallery.pug","hash":"0c4335cd31b8ce3a999f6d1c1d09365d67e46cba","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/girls.pug","hash":"b22b459f7be4d91c00d85eeac5d00aee915e70a0","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/links.pug","hash":"64d298ae7d0bd7126621b0b34b099e8808959161","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/index.pug","hash":"7322ea6d9cfb29b1bb13a31bb5f98abcf5d9f409","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/page.pug","hash":"664a20a4a316c16727d279d75cad9b29a06bc06e","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/post.pug","hash":"538c280a308326a058972828b4f69d16b232fd58","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/tag.pug","hash":"826b722d39b900a0ce12b3b1045a27d22450f61f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/yun.svg","hash":"aa027a0a9e7ba96c906b9fd2d9cd3f8018ff2e2d","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/yun.png","hash":"b8ae426fa5dd7579d23d189c222641d812c51c0a","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/background.pug","hash":"2c369cbdbfd9c9c1fa31a860a77617c4d33e5e21","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/footer.pug","hash":"2d2efc8a97b7f824adbc08721f449ecb5a937a31","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/banner.pug","hash":"ec089f56b2c37054223734ea9161d9b6e5ae0373","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/extended.pug","hash":"185c2238e8678ff9cb32a7b14c144a1f14dd5f92","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/pagination.pug","hash":"f65cce84f7ceec372b2d4b91433e9ec6c7145690","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/head.pug","hash":"b298a57c049ad041beeaee517938bf22da4c6a81","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/layout/_partial/layout.pug","hash":"01e47cdf6a793fb65169637cabca8afce7f614cc","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/layout/_mixin/icon.pug","hash":"c4b1ceb94fa522b22028aaef3b28c7da7c5e19b7","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/recent-posts.pug","hash":"d975fb3bad39e4a8644a470b3a58e71d7415f3e1","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_mixin/index.pug","hash":"378b5ccf052e951ee130d2ff56245e8faa7e020f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_mixin/page-header.pug","hash":"7ab9c1a6099eda3a64f355caa4d8fac5deff94c6","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/sidebar.pug","hash":"93d38e5a982e8fa14d9b11c9f4e70cf10a45e4f8","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_mixin/post-meta.pug","hash":"6889f73c69c952d7974cd2fc9ee8dd9220b3f519","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_mixin/post-categories.pug","hash":"c5d1b78d024ee44ca88e94a692c8a27f7ac5073a","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_mixin/post-collapse.pug","hash":"741195a5a29ecb5863b1fd0c3b203d960aae05c1","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_mixin/post-tags.pug","hash":"fc0ea25a55fc31180d578003a71ad3c2bb4d1ffa","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/aplayer.pug","hash":"642445a227e8b702be443958b49901d7c884555f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/cdn.pug","hash":"3c03f2ebc0c931f64f7daeffb10b289c3117beed","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/iconify.pug","hash":"03121fc0ae99dcf9ae9039beb1a6b26bd289c988","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/google-tagmanager.pug","hash":"01724665b723aaa1b5fc3a63e3b538970efcd13c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/index.pug","hash":"c7ca05ff19e71b141ecfbe031a63e225178c2eec","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/lightgallery.pug","hash":"30f493d3780e0f928554d2adb8094c8e07c39a94","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/pjax.pug","hash":"4c137fe0ba8cac806f5c9a4ca723c0bc233ca8da","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/medium-zoom.pug","hash":"7bed328c65aa03c3cb0753b31a16793912ff52af","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/back-to-top.pug","hash":"d0b2e84e2126252163810505a58d9f38101efba1","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/aplayer.pug","hash":"45675643a8d5e64117f94612e517ce4dff6ca053","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/index.pug","hash":"4d1a35e4e0dc485733b0697d073d4f56afb7c1a2","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/cloud.pug","hash":"8903d1311bf5f68dcc23e520cb4f1e4385aff70d","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/mourn.pug","hash":"22fab84749be6a28814e4d79fb074a31dee44e1b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/notice.pug","hash":"780a10dbf308022790c58a4d2117dc2f48581531","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/say.pug","hash":"e02ffa7b837e3ff387d0cc888b9fed39c717628b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/hexo-theme-yun.styl","hash":"9d7a11fc1d8196812907fc4a0557ffd10420c39c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/chunk-72ZP56JR.js","hash":"4618a0cf40d36ab1c97f8ac98231924a88f8d6f5","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/README.md","hash":"9f65c9d90a2764bd7b1a32cabc7013bfd3285594","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/chunk-FEIY7W7S.js","hash":"bdf31df5623cdbe4d6629c1d602cad7a15e5cf78","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/hexo-theme-yun.js","hash":"45ee98382ef218b24d8156bab7fad44421aca638","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/gallery-decrypt.js","hash":"e49d0d197ea23c3614899587164bea0fad52745e","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/pjax.js","hash":"eef6ca01fa183a8c48315931f26b99f51d0a148b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/say.js","hash":"03b1fe9cba03d6817fbe6c47a8d78925ba28fa75","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/sidebar.js","hash":"f175377750f4213fc37ccf0fbeeeb21550e0f805","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/source/js/utils.js","hash":"fbd0119a09d6a60d967921b163a4e1dc3e32b5aa","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/filters/index.js","hash":"d8fec37863999499ade184cd471a48325864eba0","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/events/config.js","hash":"3163021ffbf200299c6744470be6c8f7b58c58f5","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/tags/prompt.js","hash":"2ba1a0e819f7d5ac9efa3b4032930392fc06e5a3","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/events/data.js","hash":"1001c5ed41fc2fe40336be559c3e567733ad781b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/events/index.js","hash":"2aa296b4b382c2ba82651c0da5cfc7397602a65f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/helpers/encrypt.js","hash":"2dea8e32ccddbb3cdade7f5d1012b2aeb6d283d2","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/events/utils.js","hash":"700ad26e83b53358f6c01c42708be02f735f647c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/helpers/engine.js","hash":"d64dee6563404df3fd2bff5357b06fecde1051df","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/post/post-content.pug","hash":"eb5a9b48e1a2172af74ac1b4c3851d7c6a9fc6f8","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/helpers/yun-config.js","hash":"fc40b7b64cad441ae6b2157d778373dc1025040e","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/footer/gongan.pug","hash":"3228a1599255180742e459937d6f97081f9701f5","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/post/post-nav.pug","hash":"a639a10e40124439cb6ccb4756672b830d657277","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/scripts/helpers/index.js","hash":"91d0bf1064a6fa8f4423185018908a1b16e9ba6a","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/post/post-copyright.pug","hash":"bceb7bbf27e0544f2a6ad723518d15df95f485ac","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/post/post-schema.pug","hash":"ec85079174da20c9f608b142e7fda2c28a9b1dac","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/post/reward.pug","hash":"8b23b929840a5d2a69a68dce7a9ee025cbf61d92","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/post/post-edit.pug","hash":"84323ed7abb8d3f0009528c5ef299258bf892bb7","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_partial/sidebar/info.pug","hash":"6886c2be8a2272c946516411abdb7560601e5926","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/adsense/google-adsense.pug","hash":"ae63305d776ebec0d88f91197b5c78cdaa401585","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/disqus.pug","hash":"71e78e45545ac6872ca921fe84af15b8e797e8e6","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/analytics/busuanzi.pug","hash":"a2503ff7bbaf05e9205fd36177f803cf91021e05","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/analytics/google-analytics.pug","hash":"3cb12c4ec3f5dbaeccf1a63a6aaa9e31dcaf926e","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/disqusjs.pug","hash":"dea47f1db45f60f9c03498f628591f0197e3df0c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/github-discussions.pug","hash":"84ba9bc5f4c1daf9636648c181c9a781706fb18d","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/analytics/leancloud-visitors.pug","hash":"e7debe84507235c2a92a78e2367727a061e94ba1","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/giscus.pug","hash":"f4c1eeb652839300b7358a117cb89cee72fa257b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/github-issues.pug","hash":"a2209c9d873b88a830c518d80a754fe2068e0b55","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/livere.pug","hash":"b81ed4fb8a0ca32ccfb8e22c37ac48e4be1f4152","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/index.pug","hash":"15dfd819b31a0e8467ea5f980a317606dd430396","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/waline.pug","hash":"19058980ff135ebab8a1195dd56e63a60b066d12","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/minivaline.pug","hash":"639030d030f51cbcae8175d589108836ad52f95b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/twikoo.pug","hash":"f9b0e4704b8ce83212529caffb50b6e27a2a761f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/comments/utterances.pug","hash":"712f893469f258e969806e1b55d0d2ac926761be","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/search/algolia-search.pug","hash":"df52fcef82e01d1b1d96dad2df516acffc298435","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/math/index.pug","hash":"9a61d4923fad7c778f0bf2ce8c81744b126e6a1f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/math/katex.pug","hash":"e1e7cb8213c9616f2b50482b69386120dc02206b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/search/local-search.pug","hash":"21f2e85869c793b7d58d58961eb7073c4126cf71","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_widget/search/index.pug","hash":"9903cc7e20213ed087a4357a73f28b9694442100","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/mermaid/index.pug","hash":"52b8567a5527fe85b41ac2a0a6adb113ba6b7205","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/mermaid/mermaid.pug","hash":"61d15ed524f67704d00282216bd0109bb2b279da","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/layout/_third-party/seo/baidu-push.pug","hash":"0669b8c7e54c0a80e1f36e720e299cf0cd1182fe","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/card.styl","hash":"1e5f8da293d53c6f352aa17fc625f88bd0840fa6","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/button.styl","hash":"3315fc12b1b7659a06120b042a1a2e87a839ebe1","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_extend/albums.styl","hash":"1e7c7730c89b6d81da37f6565239679b5075234b","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/scrollbar.styl","hash":"2d735d019b58a1e6fea297e0027c33a4a7bc1858","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_helper/index.styl","hash":"d90450879368750b46720c2c74c83040c237f41f","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/source/css/_components/ui.styl","hash":"8ef28ee3363f3676c9327a6d163032a003520f40","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_extend/girls.styl","hash":"e83c8b1219d0117bc342c40030e106b21245dddf","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_global/dark.styl","hash":"41e12c5a989dbe66464e113b0457d1d3c0dfdb2b","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/source/js/analytics/leancloud-visitors.js","hash":"71bef1d46be5c6df6c00b29ea2faab00da6224c5","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/source/css/_global/index.styl","hash":"6ee9d2bd59706e79e8932bcfc09d86c124467452","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_mixins/base.styl","hash":"2531c22a33aa929dd6bf6c1b9975efc0a70e4a8d","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_global/reset.styl","hash":"d1640eb4f76a3cf792c5149e93c42c85da5a29b2","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_layout/footer.styl","hash":"ed3afcddad7358ebd89f01846157e26a586e7adf","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_layout/banner.styl","hash":"94e2005f3a3f51985679768c6e2acf888a5c934f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_variables/_base.styl","hash":"0288e3196318b116f991b043486fbc0b4b0bc579","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_layout/page.styl","hash":"6ec814a0fccf73a22ba6b94f6d4bba889cbaf0b5","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_layout/main.styl","hash":"2c39ba5d789224bdece3f7c16bc7a82b3e899bf4","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_layout/links.styl","hash":"3174cf42a1f79f814ea0a14798f6c5fe28b5dda9","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/comment.styl","hash":"02807b754a7f2ef605888737bc939a0aa2945c5a","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/source/css/_layout/pagination.styl","hash":"a4da4433f5c11b4de36782b7dac059bf67dde938","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_layout/post.styl","hash":"2d495981c7456095ae62f97e9c032e1f3fb03cda","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/back-to-top.styl","hash":"5898b0c6c36fd1d2ff5408ca098e345ebf04008c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_variables/_code.styl","hash":"2674ad7562f5b6f42d26291e8f5ead7f501a3c46","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/index.styl","hash":"a740126826a0ae9a1a2860fbb9c8d805d006aad6","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_variables/var.styl","hash":"53534672909e34f190c18c9e79cf089bcb46a6c7","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_variables/_colors.styl","hash":"e7ab9ed3d8698317394e5c88cf30c79e14d99ec2","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/ui/banner.js","hash":"543b262da6e813cca107a26fd56078a87cd8441f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/notice.styl","hash":"1d68860529a4fd8d3f63d2f257ed32b4e0f1167f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/say.styl","hash":"c47dd38477c08d31e0813610263200322e8f5ebe","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/comments/waline.js","hash":"82958804027c29812ae2df7d01029082adafb95e","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/comments/disqus.js","hash":"f53352ecb1a7a1b0c738ab16a095658810e563e5","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/search/algolia-search.js","hash":"871c2e2b9bdbd36329e928e9213a425d4ff420d6","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/js/ui/fireworks.js","hash":"e4e9bfe099c01c32e622144c381470307de49a09","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/source/js/search/local-search.js","hash":"b3d73b7357a791fff676d918178a4554ad7d4912","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_extend/tags/index.styl","hash":"1c4ae0e519bb8629425235f2efd80addfc2bee93","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/search/algolia-search.styl","hash":"69916b23d54859160c4fda5ee809b8375fc56151","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_extend/tags/prompt.styl","hash":"553d59840e1c9217b49b902cfe1ac520bbf71e5c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/search/index.styl","hash":"c396e3205eb672c96fdb93c12ff66e730ab323ee","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_widget/search/local-search.styl","hash":"06eca018b7d1b9bed271956c0eba1537b6e3de87","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/sidebar/sidebar-nav.styl","hash":"d8feec6f13ca9bd714e4fe7189abf1907848efef","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/sidebar/hamburger.styl","hash":"0fa240e8a71fdad14d3fd6b3fd49cf697d4c8153","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/post/post-card.styl","hash":"048208163b5554110708b9c791fd64468b76f8ca","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/post/post-codebloack.styl","hash":"c3cf80ace92d9ba5711cdf487f818cd31598866c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/sidebar/sidebar.styl","hash":"c1266c1039f6ac26884f4619265b29bdb1a9e31c","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/post/post-header.styl","hash":"2e674b76b47b3e6226269fe357d8b937b7a007a8","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/post/post-collapse.styl","hash":"6741c225a37e7e121d4159f129b7024402a8eeec","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/sidebar/site-overview.styl","hash":"fbdc24be19edeb15f66350aa4f6cc5d800c55ff0","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/post/post-markdown.styl","hash":"07cd57ec4b3c8524703030c17f9872389d723aa8","modified":1711039832388},{"_id":"node_modules/hexo-theme-yun/source/css/_components/sidebar/sidebar-toc.styl","hash":"b4b42a6dc949b52b5a861239905d333e1db6c64f","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/post/post-reward.styl","hash":"f69f5770e0908a8e8a0931f67e2417b0e1692613","modified":1664243804627},{"_id":"node_modules/hexo-theme-yun/source/css/_components/post/post-nav.styl","hash":"a9e5f18cee94944c43b0c09d6ec840b78c1f1aa0","modified":1664243804627},{"_id":"source/images/physics/Exer9.29.jpg","hash":"21fd05a68ca3ffa4aa828512784a53ba943a9faf","modified":1710828076501},{"_id":"public/2024/03/19/hello-world/index.html","hash":"e3085ff29e6d0afe29e93b09e4e8d13c9cd6ecfa","modified":1711042857417},{"_id":"public/2024/03/01/Antenna/index.html","hash":"a23f91aad7d9453547188ff1f5e16ac096f5b8f3","modified":1711042857417},{"_id":"public/2024/02/28/Speech-SP/index.html","hash":"feea69c9cef9339212831905f4e701316bb61b5f","modified":1711042857417},{"_id":"public/2024/02/26/AI/index.html","hash":"b46712a986a2ae987213e1c30553a0972267249b","modified":1711042857417},{"_id":"public/2023/01/21/CSAPP学习笔记/index.html","hash":"14154f38c6319f5c4cd9942ca9248a35041f46e6","modified":1711042857417},{"_id":"public/2022/10/04/PhysicsExercise/index.html","hash":"8daac21767e3cb951886414b6d6854cd29283fa2","modified":1711042857417},{"_id":"public/archives/index.html","hash":"9c219900862473899cfc343c637cefb9f8defae6","modified":1711039858048},{"_id":"public/archives/page/2/index.html","hash":"39e6621015a2483a9a83aa9d27ad5fa454724032","modified":1711039858048},{"_id":"public/archives/page/3/index.html","hash":"a681b5e497143c730ce0c5358143efa91d2407f0","modified":1711039858048},{"_id":"public/archives/2022/index.html","hash":"38a67f89ed55e17c244e40ccb0d4f2b3c6d3af75","modified":1711039858048},{"_id":"public/archives/2022/09/index.html","hash":"0596ae681572b54921015f19afe9d936e12aabff","modified":1711039858048},{"_id":"public/archives/2022/10/index.html","hash":"b1297af63b0088b242222bbfce81df62da35cea4","modified":1711039858048},{"_id":"public/archives/2022/11/index.html","hash":"bc933c3b1f7a3c068ea588c6dcdeaebdd8a9ac16","modified":1711039858048},{"_id":"public/archives/2023/index.html","hash":"2e65c01a11a43fda1b466a4d7cbd75e27bc478e8","modified":1711039858048},{"_id":"public/archives/2023/page/2/index.html","hash":"fbfd9041d2a50cc4dc8318e3958fcfbb05efdf5a","modified":1711039858048},{"_id":"public/archives/2023/01/index.html","hash":"ccf8874efc2dbeac70f95b995ca463cbf4ca1742","modified":1711039858048},{"_id":"public/archives/2023/02/index.html","hash":"05ac1dfdfbfbd0c196858ca08fb94478ab6ae730","modified":1711039858048},{"_id":"public/archives/2023/09/index.html","hash":"1b04d7277d837e087169ef3f624508fc2503e5ae","modified":1711039858048},{"_id":"public/archives/2023/10/index.html","hash":"bb4b466494c78e0a2cfe4505c47f721983e591f0","modified":1711039858048},{"_id":"public/archives/2024/index.html","hash":"6eaee7598f15053c1945850ed582fe8bb92f9cc2","modified":1711039858048},{"_id":"public/archives/2024/02/index.html","hash":"70c8724e82a65a12ed37ee472ba35a52c61ba46e","modified":1711039858048},{"_id":"public/archives/2024/03/index.html","hash":"1461de5676715133ffe0422fcf706a3b62b1ff39","modified":1711039858048},{"_id":"public/tags/note/index.html","hash":"0ed004fcbe09a35ab65bbd97e23d0dd60a1e625e","modified":1711039858048},{"_id":"public/tags/note/page/2/index.html","hash":"179f9235d5cb884919f8181bfc4ebca85cb12c58","modified":1711039858048},{"_id":"public/page/3/index.html","hash":"e6b7381d996bcacf7d2e1b74f9d2f169855b5076","modified":1711039858048},{"_id":"public/2024/02/26/SSP/index.html","hash":"caf45153035e98629a1f2e74db4ef4063ad7f4a3","modified":1711042857417},{"_id":"public/2023/10/09/Python-OJ/index.html","hash":"594d432eca88584a13ad7711107726d6a9c2d361","modified":1711042857417},{"_id":"public/2023/09/21/Stochastic-Process/index.html","hash":"6becbd8f7f7251fbc4992d2da91f375b9e0878de","modified":1711042857417},{"_id":"public/2023/09/20/数字系统设计/index.html","hash":"8a5c71b634d40e94e366220de81b9672c467deb3","modified":1711042857417},{"_id":"public/2023/09/20/Digital-Signal-Processing/index.html","hash":"72e7890c59d0785382739d651976bebd37ac6485","modified":1711042857417},{"_id":"public/2023/09/20/量筒/index.html","hash":"f67b12d2240c80c6c226d45cca3a3a5a1d7e83d1","modified":1711042857417},{"_id":"public/2023/09/18/Computer-Network/index.html","hash":"0d72d82643d53d1b4e333ff009ccc2879eac82f3","modified":1711042857417},{"_id":"public/2023/09/18/通网/index.html","hash":"5e12570a968e61e27dacf3635856c49417bef1c5","modified":1711042857417},{"_id":"public/2023/02/27/数逻/index.html","hash":"145f211540cd6352ae55cf8ff21900ba2b8b2026","modified":1711042857417},{"_id":"public/2023/02/22/Signal-and-Systems/index.html","hash":"23c65e213bde989c57797755987b3c519cc25878","modified":1711042857417},{"_id":"public/2023/02/20/Introduction-to-Probability/index.html","hash":"ccf9800b6599c7709b6c4bd8fce4af1853a536ff","modified":1711042857417},{"_id":"public/2022/11/10/stuffs/index.html","hash":"48b4d7cc9555fdd4f4366dfc4e3039a5c59eef13","modified":1711042857417},{"_id":"public/2022/09/28/github-command/index.html","hash":"7254ed615e4eefc735f173a1706e80165e653508","modified":1711042857417},{"_id":"public/2022/09/14/Physics/index.html","hash":"fa31409fc3da9b965189aa3427586dbdfc6fec0f","modified":1711042857417},{"_id":"public/2022/09/13/DataAndAlgorithms/index.html","hash":"428a1c8716fe8e6ce613e40d7ea9ca1db6a03239","modified":1711042857417},{"_id":"public/2022/09/02/cpp-multi-file/index.html","hash":"67aecdec480601e872012288b4c5b6075c391a58","modified":1711042857417},{"_id":"public/index.html","hash":"3a8a6ca054f77816ee44526f7540dfcad632c1bc","modified":1711039858048},{"_id":"public/page/2/index.html","hash":"5e5f8bd1c9761e832ccf420ad30d967b4bfe6eb9","modified":1711042857417},{"_id":"public/yun.png","hash":"b8ae426fa5dd7579d23d189c222641d812c51c0a","modified":1711039858048},{"_id":"public/yun.svg","hash":"aa027a0a9e7ba96c906b9fd2d9cd3f8018ff2e2d","modified":1711039858048},{"_id":"public/images/avatar.jpg","hash":"82fa7e5d64578f76a3f099524be413d04f02b716","modified":1711039690221},{"_id":"public/images/csapp1.jpg","hash":"8d0d45d69ac337393818f5f58ecdf2a3641d7ec3","modified":1711039690221},{"_id":"public/images/DSA/Duopule.jpg","hash":"e5ad81d5fa199a2c4f0bc88fb3d8428aef4a578e","modified":1711039690221},{"_id":"public/images/DSA/waveDuopl.jpg","hash":"3fbe893ed33fe4d8ddc8faca1b1280a47a0bc96c","modified":1711039690221},{"_id":"public/images/DSD/2_1.jpg","hash":"9f1da44162d92692c574ffb029818da84b8bdbbb","modified":1711039690221},{"_id":"public/images/DSD/2_4.jpg","hash":"aa5b1c3ef80f88077efd1942526d2bd0720044b6","modified":1711039690221},{"_id":"public/images/DSD/3_1.jpg","hash":"cffbec97b2de3330bf135fa2fe4eeb5e56906af3","modified":1711039690221},{"_id":"public/images/DSD/3_3.jpg","hash":"f04d4ff79c5f1a9e7ddfa7c9fc017aaf09b884a2","modified":1711039690221},{"_id":"public/images/DSD/3_2.jpg","hash":"75d3c702edcad3cc9d331c20045a9154a3a17c04","modified":1711039690221},{"_id":"public/images/DSD/3_10.jpg","hash":"0f8cb4b6d48c96af6a129d9839d913a9fbad6a2f","modified":1711039690221},{"_id":"public/images/DSD/3_5.jpg","hash":"0103a7fdddc1171e20106661c139e6a33a64d5ca","modified":1711039690221},{"_id":"public/images/DSD/3_8.jpg","hash":"b0ee9ed7902c4e38c1028bb0c4588d0a0e1377b7","modified":1711039690221},{"_id":"public/images/DSD/3_7.jpg","hash":"55a1515bdab5b05d92f9789d7b4dd990a31c2634","modified":1711039690221},{"_id":"public/images/DSD/4_1.jpg","hash":"d8069f98033119cd01625a3e8cce988a827bc449","modified":1711039690221},{"_id":"public/images/DSP/5_2.jpg","hash":"c2bb6812241758a968869828d12feab3793fe774","modified":1711039690221},{"_id":"public/images/prob/L14_1.jpg","hash":"3927ec89bf5887d4ac7ba528a3b5f8c84efd2fb9","modified":1711039690221},{"_id":"public/images/oj/1.jpg","hash":"b3a341db0e8f930e9568c18885ce84f53faa9af1","modified":1711039690221},{"_id":"public/images/physics/STM.jpg","hash":"596bef4a79f8a4b91a1c34e82e642d18db6ba4e3","modified":1711039690221},{"_id":"public/images/digital/lec_4_1.jpg","hash":"c25f9444da893d365559dd58067ab629ea119855","modified":1711039690221},{"_id":"public/images/digital/lec_3_1.jpg","hash":"edada7524ca5edfdb7f322f0a39cd09b178029c7","modified":1711039690221},{"_id":"public/images/digital/lec_4_12.jpg","hash":"d862d0d9e99fb7e62eb385dd0967092fa7c0c7d5","modified":1711039690221},{"_id":"public/images/digital/lec_4_13.jpg","hash":"6a50965180a5397a3888c4defcfa8c4ae5aa200a","modified":1711039690221},{"_id":"public/images/digital/lec_4_3.jpg","hash":"6bc9184cb64471c0ff4e1c8a16c4dd6ee23f8c0d","modified":1711039690221},{"_id":"public/images/digital/lec_4_2.jpg","hash":"2a4da85dfcb43240c8b2f3cecc6b47932b27a16f","modified":1711039690221},{"_id":"public/images/digital/lec_4_4.jpg","hash":"e3aa49a288afcfba35c3b2ae9137bea527e9a830","modified":1711039690221},{"_id":"public/images/digital/lec_4_6.jpg","hash":"eba9a1f88300b5e816fc20472cb29b34d54d72c7","modified":1711039690221},{"_id":"public/images/digital/lec_5_10.jpg","hash":"887cd7c3d824363c5810690736c48f4e74fd5434","modified":1711039690221},{"_id":"public/images/digital/lec_5_18.jpg","hash":"6c95687ec98555ece9b8e10661915000dcec7d9e","modified":1711039690221},{"_id":"public/images/digital/lec_5_22.jpg","hash":"db4956160fd4341e3c6cf7c1185343a8d0b86424","modified":1711039690221},{"_id":"public/images/digital/lec_5_23.jpg","hash":"ec9fc53fc59887c6312216f347e93dbf58d1260c","modified":1711039690221},{"_id":"public/images/digital/lec_5_24.jpg","hash":"9714b01e61c2ac2c8f9788734e3b061d626fdeab","modified":1711039690221},{"_id":"public/images/digital/lec_5_25.jpg","hash":"3f3aacd93c5d58c51538a58a840b80d35b298735","modified":1711039690221},{"_id":"public/images/digital/lec_5_9.jpg","hash":"f5dd319180a7613ff1e6f6f3fa8ee465a4b91e01","modified":1711039690221},{"_id":"public/images/digital/lec_9_2.jpg","hash":"f6f2f7b49d1fb080f2bfba5b06c43763e0116ea1","modified":1711039690221},{"_id":"public/images/DSD/2_3.jpg","hash":"2b14827af4eed02b175b1b343bd11385ff47e33a","modified":1711039690221},{"_id":"public/images/DSD/2_2.jpg","hash":"b5290376215b2785bcdd78466d82709e51d43592","modified":1711039690221},{"_id":"public/css/README.html","hash":"3c68b48595e975dd7614b64f71ffa1113d784228","modified":1711039858048},{"_id":"public/js/chunk-72ZP56JR.js","hash":"4618a0cf40d36ab1c97f8ac98231924a88f8d6f5","modified":1711039858048},{"_id":"public/css/hexo-theme-yun.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1711039858048},{"_id":"public/js/gallery-decrypt.js","hash":"e49d0d197ea23c3614899587164bea0fad52745e","modified":1711039858048},{"_id":"public/js/chunk-FEIY7W7S.js","hash":"bdf31df5623cdbe4d6629c1d602cad7a15e5cf78","modified":1711039858048},{"_id":"public/js/say.js","hash":"03b1fe9cba03d6817fbe6c47a8d78925ba28fa75","modified":1711039858048},{"_id":"public/js/pjax.js","hash":"eef6ca01fa183a8c48315931f26b99f51d0a148b","modified":1711039858048},{"_id":"public/js/hexo-theme-yun.js","hash":"45ee98382ef218b24d8156bab7fad44421aca638","modified":1711039858048},{"_id":"public/js/ui/banner.js","hash":"543b262da6e813cca107a26fd56078a87cd8441f","modified":1711039858048},{"_id":"public/js/sidebar.js","hash":"f175377750f4213fc37ccf0fbeeeb21550e0f805","modified":1711039858048},{"_id":"public/js/analytics/leancloud-visitors.js","hash":"71bef1d46be5c6df6c00b29ea2faab00da6224c5","modified":1711039858048},{"_id":"public/js/comments/waline.js","hash":"82958804027c29812ae2df7d01029082adafb95e","modified":1711039858048},{"_id":"public/js/utils.js","hash":"fbd0119a09d6a60d967921b163a4e1dc3e32b5aa","modified":1711039858048},{"_id":"public/js/ui/fireworks.js","hash":"e4e9bfe099c01c32e622144c381470307de49a09","modified":1711039858048},{"_id":"public/js/search/local-search.js","hash":"b3d73b7357a791fff676d918178a4554ad7d4912","modified":1711039858048},{"_id":"public/js/search/algolia-search.js","hash":"871c2e2b9bdbd36329e928e9213a425d4ff420d6","modified":1711039858048},{"_id":"public/js/comments/disqus.js","hash":"f53352ecb1a7a1b0c738ab16a095658810e563e5","modified":1711039858048},{"_id":"public/images/ss/lec10_8.jpg","hash":"d7747774782b5a99b398befbb5d24b0ad998a2c5","modified":1711039690221},{"_id":"public/images/ss/lec11_1.jpg","hash":"ebd5178b7810226dbdee7284378029dd6e0de850","modified":1711039690221},{"_id":"public/images/ss/lec17_1.jpg","hash":"46b8fb403aaeb79557f2dafbf6303336a1eaf6e5","modified":1711039690221},{"_id":"public/images/ss/lec19_1jpg.jpg","hash":"ca4809664ab4a92d92a85a9956325be4f0b8e008","modified":1711039690221},{"_id":"public/images/ss/lec20_1.jpg","hash":"ebd8e54c71d2e5ac13e1d2deff0eb3aca907fed3","modified":1711039690221},{"_id":"public/images/ss/lec20_4.jpg","hash":"976d51da842b56042fe680e7f73f1fd28593e83f","modified":1711039690221},{"_id":"public/images/ss/lec20_5.jpg","hash":"7c3aa78e8d22ddc4794a9bf575933e4f8456900d","modified":1711039690221},{"_id":"public/images/ss/lec21_7.jpg","hash":"ea49ade0ad5bd1bbd96cc0192de6dcc6aad8a246","modified":1711039690221},{"_id":"public/images/ss/lec22_11.jpg","hash":"c675a9bbe46209ced1117832ec356321f76e394a","modified":1711039690221},{"_id":"public/images/ss/lec21_9.jpg","hash":"ea49ade0ad5bd1bbd96cc0192de6dcc6aad8a246","modified":1711039690221},{"_id":"public/images/ss/lec22_15.jpg","hash":"731c358606e81d7e331defd0522042c48beccbef","modified":1711039690221},{"_id":"public/images/ss/lec22_16.jpg","hash":"0a37144a5783a883ccb90bf5af79943bc144862a","modified":1711039690221},{"_id":"public/images/ss/lec2_.jpg","hash":"5fa6ec6fe9b51852f00097275cb5aaa27dd39ca7","modified":1711039690221},{"_id":"public/images/ss/lec22_20.jpg","hash":"438d61b76e2806bc7f71025256d5ff063da3a56e","modified":1711039690221},{"_id":"public/images/ss/lec7_1.jpg","hash":"c2c6ec7a602e674cdaeab8206dca12156227b2b0","modified":1711039690221},{"_id":"public/images/ss/lec7_2.jpg","hash":"250d81f6c2966194529349bb0cd68b778beb16a9","modified":1711039690221},{"_id":"public/images/ss/lec7_3.jpg","hash":"333d27a9f5caba2d62377e87e81f114c5aa710d1","modified":1711039690221},{"_id":"public/images/ss/lec9_1.jpg","hash":"51dd547f87a1b7d9a049522fdd61e3e96c9ed245","modified":1711039690221},{"_id":"public/images/ss/lec9_2.jpg","hash":"884ab6452f9d9eece080e898dc737ad8e9910876","modified":1711039690221},{"_id":"public/images/ss/lec9_3.jpg","hash":"8fad27b2b76bb97d8a6b49ab0802383bf7bc15cc","modified":1711039690221},{"_id":"public/images/ss/lec9_4.jpg","hash":"db13d6870f53e2c19ada8e8ecef11a9b77fbbb26","modified":1711039690221},{"_id":"public/images/ss/lec9_5.jpg","hash":"0a0b1cb86fb99d82bd8e19169e268a1271f3011c","modified":1711039690221},{"_id":"public/images/量筒/xt_2_2.jpg","hash":"1938bc966a250f61150f63942f2d2081abcb26ef","modified":1711039690221},{"_id":"public/images/通网/4_2.jpg","hash":"d01055cd7a5883ccd3677249084d1378a8899aff","modified":1711039690221},{"_id":"public/images/通网/4_3.jpg","hash":"911a6745b6c95f67cf621df474098cf98356a093","modified":1711039690221},{"_id":"public/images/通网/4_4.jpg","hash":"c4d406015e582a2048e6b13194d54daf0285de6e","modified":1711039690221},{"_id":"public/images/通网/5_6.jpg","hash":"2cb41812aca27f170c53cc1c98b51615e69f772f","modified":1711039690221},{"_id":"public/images/通网/5_5.jpg","hash":"82bf6a741df61e1e33ae9f4e66550e100b201ef1","modified":1711039690221},{"_id":"public/images/DSD/3_4.jpg","hash":"f958ced57a88f845b4457be5503e9d23ff9d6a0a","modified":1711039690221},{"_id":"public/images/通网/5_9.jpg","hash":"bee1b86c80bec9fd58c7cca6858dbad4eb97534b","modified":1711039690221},{"_id":"public/images/DSD/3_6.jpg","hash":"6b3c2f12024cfdff8d3e156bb709ea953c16e052","modified":1711039690221},{"_id":"public/images/DSD/4_10.jpg","hash":"8bf7fe44e993c474a1136e0746153816651f01eb","modified":1711039690221},{"_id":"public/images/DSD/4_3.jpg","hash":"3f8979ba7e5a717b85ec700a11e33d08738e6371","modified":1711039690221},{"_id":"public/images/DSD/4_8.jpg","hash":"1c566a4a8a8727c2fc25a9883e0097763f893e12","modified":1711039690221},{"_id":"public/images/DSD/4_9.jpg","hash":"2ddda7367a7e91a948d0c4604fe14c4a4a3bea8e","modified":1711039690221},{"_id":"public/images/DSD/4_6.jpg","hash":"7323c73c34be17971da156274a7d8add13295998","modified":1711039690221},{"_id":"public/images/DSD/4_7.jpg","hash":"f1ad605512ad26cd7ceda74a8e85addcb67e8322","modified":1711039690221},{"_id":"public/images/DSP/5_1.jpg","hash":"445e6dd85968287a4b03e9c090d57ae0e98eb354","modified":1711039690221},{"_id":"public/images/DSP/4_2.jpg","hash":"b51c2a45d2ccba2f34005c7894671f90cfbe2a49","modified":1711039690221},{"_id":"public/images/StaSP/2_1.jpg","hash":"c346abd8c965cfd79f62ad73e377009b0bc47827","modified":1711039690221},{"_id":"public/images/prob/L15_1.jpg","hash":"2f58838aa5f9c71ff1a725030555d6bb4a2bf97a","modified":1711039690221},{"_id":"public/images/StaSP/2_2.png","hash":"7fb646fb83a0d610e3b36253c39408130df3790b","modified":1711039690221},{"_id":"public/images/prob/L2_1.jpg","hash":"6bc13a99f6db10bb9d24355b95afa33df70f32c8","modified":1711039690221},{"_id":"public/images/physics/guocheng.png","hash":"888f3071bfcf910ba32e6e3c58efa1126bec17dd","modified":1711039690221},{"_id":"public/images/physics/shuangfeng.jpg","hash":"5d7aea11be84af2c958a4a74c1e4eb33e02fa673","modified":1711039690221},{"_id":"public/images/physics/xunhuantu.png","hash":"2217ae80004a1eb0a1e6e704c047f3c30b37a076","modified":1711039690221},{"_id":"public/images/physics/shuangzheshe.jpg","hash":"ee9e38a400cf844be2594c9139c8bc6a0a798e93","modified":1711039690221},{"_id":"public/images/physics/zhilengxunhuan.png","hash":"9cbb28af11c3d23dcced351be6e0e94f3130a495","modified":1711039690221},{"_id":"public/images/physics/非单色光.jpg","hash":"8a7ab7c4fd301daa6bf31ee320e42d05d49173a4","modified":1711039690221},{"_id":"public/images/digital/lec_10_3.jpg","hash":"df407f03cc70cfc1a938f8b10cb9b0690c5b5e73","modified":1711039690221},{"_id":"public/images/physics/准单色光.jpg","hash":"d0af0831771212a7074979ce82522a1942363ad3","modified":1711039690221},{"_id":"public/images/digital/lec_11_1.jpg","hash":"72d2768f50b72e65b4676f4b1949812d79db8f73","modified":1711039690221},{"_id":"public/images/digital/lec_4_1.jpg8.jpg","hash":"ab85d2d03a50046744cea89e39a397cb8a5c81bc","modified":1711039690221},{"_id":"public/images/digital/lec_4_11.jpg","hash":"c7c73afa94fc0b361349584e779d7ad672cc975a","modified":1711039690221},{"_id":"public/images/digital/lec_4_15.jpg","hash":"f8e19d0a13554cded65a49caf0f18933893e048b","modified":1711039690221},{"_id":"public/images/digital/lec_4_10.jpg","hash":"5f31069580e49e94edf5ee5c3bca7e3b96206736","modified":1711039690221},{"_id":"public/images/digital/lec_4_14.jpg","hash":"300164959d00570d67e76786c981451c76161187","modified":1711039690221},{"_id":"public/images/digital/lec_4_17.jpg","hash":"d7e723a63e6a84f9d3fcb0c98677534fa0082230","modified":1711039690221},{"_id":"public/images/digital/lec_4_16.jpg","hash":"365346fe9c012ffedca74ba97e59036b9d291d92","modified":1711039690221},{"_id":"public/images/digital/lec_4_8.jpg","hash":"45452409372207868e50cb1fb2add3102ffdb28a","modified":1711039690221},{"_id":"public/images/digital/lec_4_5.jpg","hash":"1093a862a0f2be73602cee1a392d2c01c4ec9190","modified":1711039690221},{"_id":"public/images/digital/lec_4_9.jpg","hash":"c858ff4bd01cbfd89943aebad19457144efbd761","modified":1711039690221},{"_id":"public/images/digital/lec_5_1.jpg","hash":"a44fb2fe181038ef167ce43009d4e6d9e0099b0d","modified":1711039690221},{"_id":"public/images/digital/lec_5_17.jpg","hash":"ea0787376daa123e92a7d3ecb8129d4239629a60","modified":1711039690221},{"_id":"public/images/digital/lec_5_16.jpg","hash":"e48d460a1385f716b426ed354572d9d24cf93b7b","modified":1711039690221},{"_id":"public/images/digital/lec_5_13.jpg","hash":"8290c0bd2a4724d50ce2278f77fed500db3d99a3","modified":1711039690221},{"_id":"public/images/digital/lec_5_26.jpg","hash":"c348de049108cfac6c679861b3358ed8c773dc6f","modified":1711039690221},{"_id":"public/images/digital/lec_5_3.jpg","hash":"a76126dc14c4895249dadeea74f2ca87ca46b397","modified":1711039690221},{"_id":"public/images/digital/lec_5_4.jpg","hash":"94ca9923fb72e4efb1670d655331c59c0a155167","modified":1711039690221},{"_id":"public/images/digital/lec_5_6.jpg","hash":"a3d2964b5cf46c4fe3de20b0a848db1843e5ec32","modified":1711039690221},{"_id":"public/images/digital/lec_5_5.jpg","hash":"ffcaf91ad9d8c88f8e2484abf70f5eb70b103bb2","modified":1711039690221},{"_id":"public/images/digital/lec_5_7.jpg","hash":"5bca98e70f3b3c8714a10de3fdb8d5661068d5e9","modified":1711039690221},{"_id":"public/images/digital/lec_7_15.jpg","hash":"7a8e4863c4b191c37c921290da6ed5694d4ddcba","modified":1711039690221},{"_id":"public/images/digital/lec_7_16.jpg","hash":"f61a278543108441e51035a02abe9df4dca3680f","modified":1711039690221},{"_id":"public/images/digital/lec_7_18.jpg","hash":"f6e0fe5be468fb3b144cdbaf90698f86d4c9a058","modified":1711039690221},{"_id":"public/images/digital/lec_7_6.jpg","hash":"7d89400fe1ca832246d4305f635ec5f230fc701b","modified":1711039690221},{"_id":"public/images/digital/lec_7_7.jpg","hash":"e1d8df6eb6519a15423f92dd7071db717b5ed78d","modified":1711039690221},{"_id":"public/images/digital/lec_8_23.jpg","hash":"39b63f83481b0981eb73c91304a1a02b3125fa8a","modified":1711039690221},{"_id":"public/images/digital/lec_8_25.jpg","hash":"34314d405ebec5480851ef1bc889ceb5bda8d441","modified":1711039690221},{"_id":"public/images/ss/lec10_4.jpg","hash":"07debb0b6e0f7b5062b042744022d0151f7b46a3","modified":1711039690221},{"_id":"public/images/ss/lec10_3.jpg","hash":"0497895930678d17632d40fd23e16d17bd4751c1","modified":1711039690221},{"_id":"public/images/ss/lec10_5.jpg","hash":"a4f0ba9415e97ec2c47d2f363de896d0f81579fe","modified":1711039690221},{"_id":"public/images/ss/lec10_2.jpg","hash":"21a5eef090129732e232f0f17a25d770042ef329","modified":1711039690221},{"_id":"public/images/ss/lec10_6.jpg","hash":"ef65d398b672595ab110affe00be9a3b70ebb34d","modified":1711039690221},{"_id":"public/images/pht.png","hash":"b8620d73e45d53a8cd90ee95d9d54d6962b46903","modified":1711039690221},{"_id":"public/images/DSA/Dijkstra.jpg","hash":"4eef33b8fee3a96661dd74b148881e3922d31e44","modified":1711039690221},{"_id":"public/images/ss/lec10_7.jpg","hash":"831de2e97fa41c69d61588bff361e598f1e53565","modified":1711039690221},{"_id":"public/images/ss/lec11_3.jpg","hash":"7da5e0d3fe410924ebeb78018444b310c0f7c222","modified":1711039690221},{"_id":"public/images/ss/lec11_2.jpg","hash":"75511dc4fb4423ec46119ea09031d06bc04e8dc4","modified":1711039690221},{"_id":"public/images/ss/lec12_1.jpg","hash":"a930599c713068b260ed644a462b1d3e2c41fd8f","modified":1711039690221},{"_id":"public/images/ss/lec12_3.jpg","hash":"1fe84a4b27abf017283111a7e0209c3bc8e25390","modified":1711039690221},{"_id":"public/images/ss/lec12_2.jpg","hash":"b22d597dc7b1d96135d459e552fea741a6cf690c","modified":1711039690221},{"_id":"public/images/ss/lec12_4.jpg","hash":"80350c462c2f119af20bc370ed6cde5c626daf27","modified":1711039690221},{"_id":"public/images/ss/lec12_5.jpg","hash":"b9e8dcd6a2c7645114dc5f51f3861e7241a17381","modified":1711039690221},{"_id":"public/images/ss/lec12_6.jpg","hash":"49c28104827079cdf09f531688be6c5f63eaba8e","modified":1711039690221},{"_id":"public/images/ss/lec12_7.jpg","hash":"a4d254ae3f4ecf067e13332084e1625c007569d3","modified":1711039690221},{"_id":"public/images/ss/lec13_1.jpg","hash":"9631b1fc35580f91005a193eb3d491ec34572930","modified":1711039690221},{"_id":"public/images/ss/lec12_8.jpg","hash":"73b0291e93b29d6a2fd5ba2fc773935a2572dc54","modified":1711039690221},{"_id":"public/images/ss/lec14_1.jpg","hash":"c08e651599e2ebb24fe4cc2e86d00f755fc10ac5","modified":1711039690221},{"_id":"public/images/ss/lec14_6.jpg","hash":"a464a171400069fc550de5e910609eed1742510c","modified":1711039690221},{"_id":"public/images/ss/lec14_3.jpg","hash":"91a426fd4496d592268867c5d29f2f236190e901","modified":1711039690221},{"_id":"public/images/ss/lec14_5.jpg","hash":"a674ffb041eb69fda2a49ab9c5539f7c26c88fef","modified":1711039690221},{"_id":"public/images/ss/lec14_2.jpg","hash":"202676a12cafa1d93dd10a3d67da15fc14e3f6fc","modified":1711039690221},{"_id":"public/images/ss/lec14_4.jpg","hash":"4b59afa50f050fc0a19b8a978ba056af45c9d178","modified":1711039690221},{"_id":"public/images/ss/lec15_2.jpg","hash":"7e1d7d2ae08676437709fe55085648d6661e7076","modified":1711039690221},{"_id":"public/images/ss/lec15_1.jpg","hash":"ccbef01147233a721388ba36037825eea7e26f31","modified":1711039690221},{"_id":"public/images/ss/lec15_3.jpg","hash":"20cf8f7d6a87f8d1fd3e45eb6cd32d764a04ba72","modified":1711039690221},{"_id":"public/images/ss/lec15_5.jpg","hash":"4961bda2c87a59f3aed7119ca3514494fb621578","modified":1711039690221},{"_id":"public/images/ss/lec16_.jpg","hash":"abb1b5008bf02ec34a20e9d73550a53c16caf061","modified":1711039690221},{"_id":"public/images/ss/lec15_6.jpg","hash":"aaa851dedcf7a6d1f0c15f1a052d9449a24e6a3b","modified":1711039690221},{"_id":"public/images/ss/lec16_1.jpg","hash":"c44f634c1b25b0ccf5395956ee0274c3ec2cc661","modified":1711039690221},{"_id":"public/images/ss/lec16_2.jpg","hash":"ba37f611661b74c3721f1b9c85950c433b3b1b9e","modified":1711039690221},{"_id":"public/images/ss/lec15_4.jpg","hash":"79b6366ab7d12125acd887b44c5a998877a6e31d","modified":1711039690221},{"_id":"public/images/ss/lec16_4.jpg","hash":"b047472123193bf630fdb12b788c0b047237aafa","modified":1711039690221},{"_id":"public/images/ss/lec16_3.jpg","hash":"95e9d390437a4faffd28371efe50dd016993bf09","modified":1711039690221},{"_id":"public/images/ss/lec18_2.jpg","hash":"036740d8df8c8b5426859df715dfa660c4b86eb5","modified":1711039690221},{"_id":"public/images/ss/lec18_34jpg.jpg","hash":"98af5db7d2b8cffd6f5767e96fff29fe0593289a","modified":1711039690221},{"_id":"public/images/ss/lec18_5jpg.jpg","hash":"b8ff1222f8c78c97522dfaa1248756d1f49b9d89","modified":1711039690221},{"_id":"public/images/ss/lec18_3.jpg","hash":"8f714384027748b7623f59fd229067eab0af3230","modified":1711039690221},{"_id":"public/images/ss/lec19_2jpg.jpg","hash":"8731e0ee32cf1a390a69b043aa636561113d7dbc","modified":1711039690221},{"_id":"public/images/ss/lec19_3.jpg","hash":"35c4a0b41f6e55fc5dca85287a280b91692d623f","modified":1711039690221},{"_id":"public/images/ss/lec20_7.jpg","hash":"ffc0c7117a0d866929a7955b63563893b8554eae","modified":1711039690221},{"_id":"public/images/ss/lec20_6.jpg","hash":"7e68a488b20b1f1ecf35f2568d47b67891bf3ad5","modified":1711039690221},{"_id":"public/images/ss/lec20_8.jpg","hash":"a12a5b78db4a1be853e897e6e584b55458c25f71","modified":1711039690221},{"_id":"public/images/ss/lec21_4.jpg","hash":"007b49c5c4be30b46905a49ccb2cbb18811af6d9","modified":1711039690221},{"_id":"public/images/ss/lec21_5.jpg","hash":"79690f154924316f63bc099c76adc471ff220771","modified":1711039690221},{"_id":"public/images/ss/lec21_6.jpg","hash":"2e32bb32f9ca6ad047ae96ec68cb1862d4f7ce5e","modified":1711039690221},{"_id":"public/images/ss/lec22_12.jpg","hash":"fdf34d0d1fa024b6ee39e20170b9472da408470e","modified":1711039690221},{"_id":"public/images/ss/lec22_14.jpg","hash":"3264b29db2fa8cd74aaaa26220052e4f82b7b3db","modified":1711039690221},{"_id":"public/images/ss/lec22_13.jpg","hash":"dccb43f0fa9c701ff0932394960ced50c69d3635","modified":1711039690221},{"_id":"public/images/ss/lec22_17.jpg","hash":"6de11febc03de48065165fd7121a39769b54bb96","modified":1711039690221},{"_id":"public/images/ss/lec22_18.jpg","hash":"96642dac70f0e02421222fbc44ce3d41fa1b0272","modified":1711039690221},{"_id":"public/images/ss/lec22_19.jpg","hash":"bf45a5c325d558407edc626979fe0456d1596e92","modified":1711039690221},{"_id":"public/images/ss/lec2_2.jpg","hash":"a162bb87e16215e0a94f9117ed2ea6b8b647949d","modified":1711039690221},{"_id":"public/images/ss/lec2_3.jpg","hash":"725316bead110ce017dd3de8184fe5f0228f1f5b","modified":1711039690221},{"_id":"public/images/ss/lec3_1.jpg","hash":"2f0fe1a07c93e6b427b32ef33498f6239e901e45","modified":1711039690221},{"_id":"public/images/ss/lec23_1.jpg","hash":"eaa2dc9fa1eba2402e7c92a9b4491e727c8290df","modified":1711039690221},{"_id":"public/images/ss/lec7_4.jpg","hash":"66be79b0fdaf36028454719f642a440126c96177","modified":1711039690221},{"_id":"public/images/stochastic/exer_1.jpg","hash":"32f00f5be748ed38e8aea6fbba094d3c8d1517af","modified":1711039690221},{"_id":"public/images/ss/lec9_6.jpg","hash":"2bda5b76668b88a752ff0e639f0ebbe2194070a1","modified":1711039690221},{"_id":"public/images/计网/3_2.jpg","hash":"2cbcfcc7943d25460bf8c50f5030571af4718f98","modified":1711039690221},{"_id":"public/images/计网/3_4.jpg","hash":"ff27e894e52d63cccb9e9d9404f77de9edf2d9fa","modified":1711039690221},{"_id":"public/images/计网/3_5.jpg","hash":"55fd8e991d94dfcc55f6ae94ddb049d7e8fec8af","modified":1711039690221},{"_id":"public/images/计网/3_6.jpg","hash":"4f0cfa50ecc467ce7ad6cba2ec74b86c4d2e77e3","modified":1711039690221},{"_id":"public/images/计网/5_2.jpg","hash":"b20c156e34760e33b8f1a294ea7cee01b6a91cf5","modified":1711039690221},{"_id":"public/images/量筒/8_4.jpg","hash":"421abf88818ef5d029dbdaf9448399237bda558f","modified":1711039690221},{"_id":"public/images/通网/2_2.jpg","hash":"40ceeefeb6ade57c2bb18a3cc0ea218fd0e5c0a2","modified":1711039690221},{"_id":"public/images/通网/2_9.jpg","hash":"4b899dea9f8cc94fb2750be57465073210ae571f","modified":1711039690221},{"_id":"public/images/通网/3_2.jpg","hash":"1cd46305eea0f5d2349f57e50a68fc6787b806f5","modified":1711039690221},{"_id":"public/images/通网/3_3.jpg","hash":"8379204f1d0df2dcbec9cbc29a5f34b147b729eb","modified":1711039690221},{"_id":"public/images/通网/3_4.jpg","hash":"a23e38041320adbfb831fcb17708f11d2bc57d4a","modified":1711039690221},{"_id":"public/images/通网/3_6.jpg","hash":"27be953951b0461e0aa5cc410aa644e3db816289","modified":1711039690221},{"_id":"public/images/通网/3_5.jpg","hash":"3b1cb3b75084a1a60e827a94583eefe8daddcd20","modified":1711039690221},{"_id":"public/images/通网/4_5.jpg","hash":"b4088e5b435c89e0818990a3c577c2f8d4df0f8f","modified":1711039690221},{"_id":"public/images/通网/4_7.jpg","hash":"31ec5772752d7e0fe82e146b65b7c4cb8722ca83","modified":1711039690221},{"_id":"public/images/DSD/3_9.jpg","hash":"2d1794a0b4c0eddb14556ed27beb362a79521301","modified":1711039690221},{"_id":"public/images/DSD/4_2.jpg","hash":"77cb7871dd5b62b562457e8bc2be0b89f5a6697f","modified":1711039690221},{"_id":"public/images/DSD/4_4.jpg","hash":"50c8ee11addd6480f4ea3bccb2650de5fa1065f3","modified":1711039690221},{"_id":"public/images/StaSP/1_1.jpg","hash":"31135420c357f9d13f5bcac3b585984900d87f89","modified":1711039690221},{"_id":"public/images/physics/VanGas.png","hash":"6b6b27fc32f30de20ce9ff40f147ebe06f320c26","modified":1711039690221},{"_id":"public/images/prob/L6_1.jpg","hash":"13eb76996c2c53e2b86ee78198e053e46ede1272","modified":1711039690221},{"_id":"public/images/physics/abaaba.jpg","hash":"618d3f739521c43a12d6bd5f420c0f87bc647500","modified":1711039690221},{"_id":"public/images/physics/niudunhuan.jpg","hash":"eb504efd970be083ade5d94914590aeed1897230","modified":1711039690221},{"_id":"public/images/physics/rexunhuan.png","hash":"0b2df0ba960f3f2aa4133349af7a8bf396ea7202","modified":1711039690221},{"_id":"public/images/digital/lec_10_4.jpg","hash":"35b7b69fca21bdd0760ba1e86826ab79712e4c95","modified":1711039690221},{"_id":"public/images/digital/lec_10_6.jpg","hash":"340f6842eb362fe6d843d762e5fbe2eb947fe162","modified":1711039690221},{"_id":"public/images/digital/lec_10_5.jpg","hash":"9d134940ec421c5f88f6483093ad2eb866488717","modified":1711039690221},{"_id":"public/images/digital/lec_10_7.jpg","hash":"a9952524683952a437e6553221df6ce3894206ea","modified":1711039690221},{"_id":"public/images/digital/lec_10_8.jpg","hash":"ecdf70e1620a1f99e80ab84b28f3fcf360c5fec8","modified":1711039690221},{"_id":"public/images/digital/lec_10_9.jpg","hash":"a180dcb7661c5844ef1d824de09540d0a6a5ec59","modified":1711039690221},{"_id":"public/images/digital/lec_12_4.jpg","hash":"db855b375313eedbc32248132a8f17eddba15b5e","modified":1711039690221},{"_id":"public/images/digital/lec_12_5.jpg","hash":"4a8f65c24fe7a2e92fadff746f091e9377d25610","modified":1711039690221},{"_id":"public/images/digital/lec_4_7.jpg","hash":"e29188e3a2bca41ccb521653d7e3288c78fe086b","modified":1711039690221},{"_id":"public/images/digital/lec_5_12.jpg","hash":"380d94316a1cd2d4fa193fe535ce964ac860159c","modified":1711039690221},{"_id":"public/images/digital/lec_5_11.jpg","hash":"29a8c5b9a48ef863f1b4d22669193505a3060eb1","modified":1711039690221},{"_id":"public/images/digital/lec_5_15.jpg","hash":"ede82664e5d1e18c9d2e834d6873c6f49567dc80","modified":1711039690221},{"_id":"public/images/digital/lec_5_2.jpg","hash":"832f64bc363443593dff117cd801ffd00116860b","modified":1711039690221},{"_id":"public/images/digital/lec_5_19.jpg","hash":"5640b4599915df5e2884b95fe1cc2e5db50a5266","modified":1711039690221},{"_id":"public/images/digital/lec_5_21.jpg","hash":"e8a4fa2e25e70627d7704a8beb0c9291ceac4f79","modified":1711039690221},{"_id":"public/images/digital/lec_5_20.jpg","hash":"2a9c93f6fd82c88f39b574aaaec3fc7d0f306836","modified":1711039690221},{"_id":"public/images/digital/lec_5_8.jpg","hash":"bd65701efefbe7854149fd92b70bb0c1b36b50a0","modified":1711039690221},{"_id":"public/images/digital/lec_6_1.jpg","hash":"4fea1050f1f2f00e10763feca1991a536705c874","modified":1711039690221},{"_id":"public/images/digital/lec_6_2.jpg","hash":"ddefebfb295f54d7a14322182b86cd2decd3bd91","modified":1711039690221},{"_id":"public/images/digital/lec_6_3.jpg","hash":"4df0c8a5a1f85629bc3b246cefd30898720248b2","modified":1711039690221},{"_id":"public/images/digital/lec_6_4.jpg","hash":"7642493ee4c3d3e133a5556cffaaa4a2544ee431","modified":1711039690221},{"_id":"public/images/digital/lec_6_5.jpg","hash":"d4a02f8d7a14676a75b606a68b79121698d25a40","modified":1711039690221},{"_id":"public/images/digital/lec_6_6.jpg","hash":"4a891d561c2df4ae040f2d4dbf8e3a23913be328","modified":1711039690221},{"_id":"public/images/digital/lec_6_8.jpg","hash":"0e88389774f0acdbc22c7302b18542825968ac0f","modified":1711039690221},{"_id":"public/images/digital/lec_6_9.jpg","hash":"7618bf3c5033ffae1b1a9b77b0542930d6baea11","modified":1711039690221},{"_id":"public/images/digital/lec_6_7.jpg","hash":"dd667d6e2c54f25201231775dcd315c48d781ded","modified":1711039690221},{"_id":"public/images/digital/lec_7_.jpg","hash":"a3c97b001cc6ddc868ee3e562d06cb3e40975744","modified":1711039690221},{"_id":"public/images/digital/lec_7_10.jpg","hash":"3320cf85eebdece4724113b2bcc512338e4674b0","modified":1711039690221},{"_id":"public/images/digital/lec_7_1.jpg","hash":"0442970c3cb7893cc6f08cce621f96f7f036f9b5","modified":1711039690221},{"_id":"public/images/digital/lec_7_11.jpg","hash":"698f6203a31a273cb6483da768469029738d237a","modified":1711039690221},{"_id":"public/images/digital/lec_7_14.jpg","hash":"3ae2633c956c40dd100aca48767b10d12b7a40ab","modified":1711039690221},{"_id":"public/images/digital/lec_7_12.jpg","hash":"b0b815b406e22f4a1da1eb3a79baed43a44b9b15","modified":1711039690221},{"_id":"public/images/digital/lec_7_13.jpg","hash":"7671c90a6f9615adebefd300693426bff68fff3c","modified":1711039690221},{"_id":"public/images/digital/lec_7_17.jpg","hash":"8ede2f303b4fec3588be55619b272e12a5a5ffed","modified":1711039690221},{"_id":"public/images/digital/lec_7_19.jpg","hash":"2e5c99f67fa20c839874e3293dfbe9eec6f7b25c","modified":1711039690221},{"_id":"public/images/digital/lec_7_2.jpg","hash":"4c00b00a17e0609a7951dfa3a93e9699acb24c23","modified":1711039690221},{"_id":"public/images/digital/lec_7_21.jpg","hash":"d4ea0bb23f64fe3710f5c8f0cf50749801ba37cb","modified":1711039690221},{"_id":"public/images/digital/lec_7_20.jpg","hash":"43bc22242263a68070b3ffbf507e382b24a0a86d","modified":1711039690221},{"_id":"public/images/digital/lec_7_4.jpg","hash":"d7443865e0937d8e4364f0a7688de6acf9fa11f6","modified":1711039690221},{"_id":"public/images/digital/lec_7_24.jpg","hash":"58bf400f31cf18ee0d32b26bc5d6efe67caa5a74","modified":1711039690221},{"_id":"public/images/digital/lec_7_3.jpg","hash":"da8fc67f4fb0187a99f41dfef84fa6611f57ca62","modified":1711039690221},{"_id":"public/images/digital/lec_7_9.jpg","hash":"dedae3cdcffd40bf88c659901393b4b90536aef4","modified":1711039690221},{"_id":"public/images/digital/lec_7_5.jpg","hash":"140f804a57b423b92f96c3888c8c988cc5c9231c","modified":1711039690221},{"_id":"public/images/digital/lec_8_12.jpg","hash":"f41f0e6add7b0a78fc0b06298c569e2318672c83","modified":1711039690221},{"_id":"public/images/digital/lec_8_1.jpg","hash":"be0347c9bcfa2d6f9622c111c6906ba67cb2fde5","modified":1711039690221},{"_id":"public/images/digital/lec_8_11.jpg","hash":"aeff4c1c924d326243eb15f219a7688aa5ad1193","modified":1711039690221},{"_id":"public/images/digital/lec_8_14.jpg","hash":"16720de5361ffe49251e088548b4346c883f34c8","modified":1711039690221},{"_id":"public/images/digital/lec_8_15.jpg","hash":"80907c2b0cd82af84a60aacad5baf39829ab98b3","modified":1711039690221},{"_id":"public/images/digital/lec_8_13.jpg","hash":"db227cc960c93db3713226ed3a3216aa052a76a7","modified":1711039690221},{"_id":"public/images/digital/lec_8_18.jpg","hash":"1481678d4268bd34dd59e4a37ef2a7e010a45352","modified":1711039690221},{"_id":"public/images/digital/lec_8_16.jpg","hash":"844f4f188aa14b4beb3c19afb328208f357dfbdb","modified":1711039690221},{"_id":"public/images/digital/lec_8_19.jpg","hash":"5736c322861a12b51349a29b67b4fb5c960dd706","modified":1711039690221},{"_id":"public/images/digital/lec_8_22.jpg","hash":"8a9846cf58e03c058328116764ac6983053340b3","modified":1711039690221},{"_id":"public/images/digital/lec_8_21.jpg","hash":"d2a64d5a6a413a182ecbdb212e3c5e4a5519fa8b","modified":1711039690221},{"_id":"public/images/digital/lec_8_24.jpg","hash":"8a78cd785165f3a65f100bf2e38cd18fcdd7567f","modified":1711039690221},{"_id":"public/images/digital/lec_8_26.jpg","hash":"e3e229c92edce4d6fd87e251995080f23cbb545e","modified":1711039690221},{"_id":"public/images/digital/lec_8_27.jpg","hash":"766b669af3ffb087fd22721301045cc36132dab3","modified":1711039690221},{"_id":"public/images/digital/lec_8_28.jpg","hash":"e15ea17927c165f190151a8a9594acbbdc427495","modified":1711039690221},{"_id":"public/images/digital/lec_8_30.jpg","hash":"9f4833ce36d6d7b35abb3af7dfab98a93f6839b9","modified":1711039690221},{"_id":"public/images/digital/lec_8_31.jpg","hash":"593fa7efabdef3f2faeb15a7411a99dc74a4e4b7","modified":1711039690221},{"_id":"public/images/digital/lec_9_10.jpg","hash":"ec2f8d0fea4752c1f8424dbc02484a255db063a4","modified":1711039690221},{"_id":"public/images/digital/lec_9_12.jpg","hash":"f2943c01d1488ccb2a08bf563fc4035ba0b2804a","modified":1711039690221},{"_id":"public/images/digital/lec_8_9.jpg","hash":"9e5bcd63f2520efb160a863c0171f20da2d79199","modified":1711039690221},{"_id":"public/images/digital/lec_9_1.jpg","hash":"90d3b7c25486ccf52b308004bd7e0eb56f17d359","modified":1711039690221},{"_id":"public/images/digital/lec_9_11.jpg","hash":"9d9fb5a2301ef24a85968e0b12174639130398a6","modified":1711039690221},{"_id":"public/images/digital/lec_9_3.jpg","hash":"9c4db64e5e3a554506d6282e7db97459bb263a2a","modified":1711039690221},{"_id":"public/images/digital/lec_9_7.jpg","hash":"c2d61b2adb1d0f604d64c491a91ba8ca756d8a55","modified":1711039690221},{"_id":"public/images/digital/lec_9_15.jpg","hash":"b8db983196f9ece3ed5e00d752ec5520a7cf46ad","modified":1711039690221},{"_id":"public/images/digital/lec_9_6.jpg","hash":"d204f2bcf7a4067347580a77575be037a5f74937","modified":1711039690221},{"_id":"public/images/digital/lec_9_5.jpg","hash":"7d8597771bc19f1d9057ff4c13efa99cc0e83e56","modified":1711039690221},{"_id":"public/images/digital/lec_9_8.jpg","hash":"60e573b4be8658dc509d89658e01173051b2e594","modified":1711039690221},{"_id":"public/images/DSA/Kruskal.jpg","hash":"873e13364b99f36fa0ccbaa2daff33d7298d1fed","modified":1711039690221},{"_id":"public/images/DSA/Prim.jpg","hash":"3279d8faad802dee5a6f7c1f245bd02146382070","modified":1711039690221},{"_id":"public/images/ss/lec14_7.jpg","hash":"2e36ab49ceed1fd39fab92f5464e3c25682016df","modified":1711039690221},{"_id":"public/images/ss/lec18_6.jpg","hash":"f3549d95c4c81c1be0220798d807d979343f77fe","modified":1711039690221},{"_id":"public/images/ss/lec18_1.jpg","hash":"a7fa8ed7027fd0a34028dae2349faa095ec506a7","modified":1711039690221},{"_id":"public/images/ss/lec20_2.jpg","hash":"0a5fbee433b7e2bbeaec6131f848f2d6a50d8a05","modified":1711039690221},{"_id":"public/images/ss/lec21_10.jpg","hash":"fe9f19d429acc43f76d9717886dc5309687afff6","modified":1711039690221},{"_id":"public/images/ss/lec3_2.jpg","hash":"a906a19d8e0634eaac5c0e1fc96cba999a9b7492","modified":1711039690221},{"_id":"public/images/计网/3_3.jpg","hash":"5e0e302dab6df19d34540ff784d0b8d555ec9f34","modified":1711039690221},{"_id":"public/images/计网/3_1.jpg","hash":"927a4946d1ca4d2882b0eccac78528713e44728e","modified":1711039690221},{"_id":"public/images/计网/5_1.jpg","hash":"6eef9e3839a5282cd1eefbaa3a5561dc13b210fd","modified":1711039690221},{"_id":"public/images/计网/3_7.jpg","hash":"173baed282253a13aceb6188e19085312746b797","modified":1711039690221},{"_id":"public/images/量筒/4_2.jpg","hash":"853f848229d5c658937941a937ab12649e5834ef","modified":1711039690221},{"_id":"public/images/量筒/7_1.jpg","hash":"1714ca73675784421aa698e4df9f74cc23163a97","modified":1711039690221},{"_id":"public/images/量筒/5_1.jpg","hash":"eb74b8b4b9c0f44392f97b18a910dc0791b68dd3","modified":1711039690221},{"_id":"public/images/量筒/xt_2_1.jpg","hash":"d7b18f090424cbc525805a62397fac2ccd6d0ea0","modified":1711039690221},{"_id":"public/images/通网/1_1.jpg","hash":"1b713b4f6587c0871033c5a6342391cf00e644d3","modified":1711039690221},{"_id":"public/images/通网/2_1.jpg","hash":"a1048e294070504440b9d5309bb64fe7a61816d0","modified":1711039690221},{"_id":"public/images/通网/2_3.jpg","hash":"81f6c171ddc17f78e4b3acc2188633fa7e4c0165","modified":1711039690221},{"_id":"public/images/通网/2_6.jpg","hash":"197a16baefd7e69615e168bcb96030f480822bf5","modified":1711039690221},{"_id":"public/images/通网/2_4.jpg","hash":"703106a3442e0ea30ff30019f8e3a283fb5de6d5","modified":1711039690221},{"_id":"public/images/通网/2_7.jpg","hash":"4a2f0bebe2aa05389c984a1541f2e6d263dc12d8","modified":1711039690221},{"_id":"public/images/通网/2_5.jpg","hash":"e9feeb6cbf1e46667d9f6d5fd7faf19f0f2f7df9","modified":1711039690221},{"_id":"public/images/通网/2_8.jpg","hash":"67e316302cab91bd3b727f9a6a46ca81579571fd","modified":1711039690221},{"_id":"public/images/通网/3_1.jpg","hash":"fa079c80e5582049e9d66da9d71f24a2f302b971","modified":1711039690221},{"_id":"public/images/通网/4_1.jpg","hash":"6829a1ebd018d381c2790c89c1fbe9987232d232","modified":1711039690221},{"_id":"public/images/通网/4_10.jpg","hash":"1fb1b3a3c8a7cf21e0216ed76c96889444e3a5e1","modified":1711039690221},{"_id":"public/images/通网/4_6.jpg","hash":"8ae655a7368410904cfc37b58f2cde91d564d188","modified":1711039690221},{"_id":"public/images/通网/4_8.jpg","hash":"daeb0a5d737099634c8255363d7b7d3168102d34","modified":1711039690221},{"_id":"public/images/通网/5_1.jpg","hash":"5728e87d4898ceb92bafa8a59268d2bd0543e9be","modified":1711039690221},{"_id":"public/images/通网/4_9.jpg","hash":"e4c02b62a7267dcc69abfb8b8038c5f2da3b231b","modified":1711039690221},{"_id":"public/images/通网/5_10.jpg","hash":"542669ad2d030e46fee3783437752cf2c24a1421","modified":1711039690221},{"_id":"public/images/通网/5_2.jpg","hash":"42156ca5327625de657e5b930ead8748098dfee9","modified":1711039690221},{"_id":"public/images/通网/5_3.jpg","hash":"4e3cb527d58fe86e77979b276b72bf553ec74395","modified":1711039690221},{"_id":"public/images/通网/5_4.jpg","hash":"433150062daba05ac57d1e2e9196ea30879cc1f0","modified":1711039690221},{"_id":"public/images/通网/5_7.jpg","hash":"dd77f472209d400caa4420a387401f027f72ed20","modified":1711039690221},{"_id":"public/images/通网/5_8.jpg","hash":"3c3527be32e2c7e954bb170bc08aac893e52383f","modified":1711039690221},{"_id":"public/images/DSD/4_5.jpg","hash":"2931fd2cb79c624486bd789434f792ce5881f986","modified":1711039690221},{"_id":"public/images/digital/lec_12_6.jpg","hash":"6f3dd256c76b26b6e3266d689dcca17de01d8b07","modified":1711039690221},{"_id":"public/images/digital/lec_12_3.jpg","hash":"3b247c788750d8fa2d8464a365f100f3c06039c2","modified":1711039690221},{"_id":"public/images/digital/lec_12_2.jpg","hash":"bc3911e20af46d67e0d87f15e9f9a898de8ae76a","modified":1711039690221},{"_id":"public/images/digital/lec_5_14.jpg","hash":"4821f92a7b36db344e614664623a07d396228307","modified":1711039690221},{"_id":"public/images/digital/lec_7_22.jpg","hash":"30e38709a2c518499da631333e9c3b59cdf04414","modified":1711039690221},{"_id":"public/images/digital/lec_7_23.jpg","hash":"6f602729f7d36d9cc8798018507fc8c7ea40ceef","modified":1711039690221},{"_id":"public/images/digital/lec_8_10.jpg","hash":"6e002121b4634585b688c0c8651f7d36b66effa4","modified":1711039690221},{"_id":"public/images/digital/lec_8_17.jpg","hash":"02a3c638a22db900f51414d6c23843303700040d","modified":1711039690221},{"_id":"public/images/digital/lec_8_20.jpg","hash":"5e6c12b150a103ab4dad99bc7d2964408f8d57f3","modified":1711039690221},{"_id":"public/images/digital/lec_9_13.jpg","hash":"29d877020561fc6fd898f834c4a6aefd15c9df07","modified":1711039690221},{"_id":"public/images/digital/lec_9_14.jpg","hash":"62ba0c3330057d109e745358f17054428f45b9aa","modified":1711039690221},{"_id":"public/images/digital/lec_9_4.jpg","hash":"5724ce755665b949e21789a4a0c53c87dcdeb2c5","modified":1711039690221},{"_id":"public/images/digital/lec_9_9.jpg","hash":"5e411a2eff07906097aceafc28f9818b701070e2","modified":1711039690221},{"_id":"public/images/ss/lec20_3.jpg","hash":"2a9f788702b330b3726f8f0cad4f0d91ac111daf","modified":1711039690221},{"_id":"public/images/ss/lec21_3.jpg","hash":"a5cc04a441dd7539fa709d3def5c2bee70ad4eaa","modified":1711039690221},{"_id":"public/images/量筒/4——1.jpg","hash":"f7b4c70ddc1b045c078a9caef7989654ab9f6708","modified":1711039690221},{"_id":"public/images/量筒/8_2.jpg","hash":"8e839bf73a82e86a16158855f5751c0d0a47fd0e","modified":1711039690221},{"_id":"public/images/量筒/8_3.jpg","hash":"9cdfc11411da5cbe4116977b6bdf84379610caaa","modified":1711039690221},{"_id":"public/images/通网/1_.jpg","hash":"13b2ffb4b4b587a7b9ff8fa3fea2e16ee2793a02","modified":1711039690221},{"_id":"public/images/digital/lec_10_1.jpg","hash":"0614b3d28af8e10148471404c55498567e12de6c","modified":1711039690221},{"_id":"public/images/physics/RealGasTemp.png","hash":"3b2951ff9cbce1a60b0e14e7fad6370cbc0459cd","modified":1711039690221},{"_id":"public/images/digital/lec_10_10.jpg","hash":"e4914c28f39ef774ffb33795b15fabdb149ddfc8","modified":1711039690221},{"_id":"public/images/physics/VanGasTemp.png","hash":"03759bcaea762e486db7e504d21eb6cff8c447b3","modified":1711039690221},{"_id":"public/images/digital/lec_10_2.jpg","hash":"ca344aec7fa4127b283a05cbe54fd2d3227f04a8","modified":1711039690221},{"_id":"public/images/digital/lec_12_1.jpg","hash":"89d7f9a80d64a90f26d332a64fef17b822b7a0d9","modified":1711039690221},{"_id":"public/images/digital/lec_8_2.jpg","hash":"732dc6ede25a4010f0132f3b94885d8f99149888","modified":1711039690221},{"_id":"public/images/digital/lec_8_29.jpg","hash":"388f8fcfa82a3e67a86a51a03698567f1fbc4864","modified":1711039690221},{"_id":"public/images/digital/lec_8_8.jpg","hash":"356c29bc21a5b198d539525ccf02c725411f6b6a","modified":1711039690221},{"_id":"public/images/ss/lec21_1.jpg","hash":"5aeb4ff3438a113f1cd19ef8b17bf59eed813b11","modified":1711039690221},{"_id":"public/images/ss/lec21_8.jpg","hash":"c996fe97685e144e9b3de9cb249b1700884b452f","modified":1711039690221},{"_id":"public/images/量筒/8_1.jpg","hash":"2d576cfbb5ac4f4ca300ff6bc30c3994712eab48","modified":1711039690221},{"_id":"public/images/digital/lec_8_4.jpg","hash":"51f44c78ef4cda452cd350dad779b06133404660","modified":1711039690221},{"_id":"public/images/digital/lec_8_3.jpg","hash":"b331931b9bb43fe9c9b47d4e077143ce03a66f09","modified":1711039690221},{"_id":"public/images/digital/lec_8_6.jpg","hash":"fe977f317899d5c9279a7cdf49e90925a18de144","modified":1711039690221},{"_id":"public/images/digital/lec_8_5.jpg","hash":"080b493fb430863c7c66c33765815f52b7aed1b6","modified":1711039690221},{"_id":"public/images/digital/lec_8_7.jpg","hash":"1463983bd58c43cc75a5ba3b4f5b01cf6d8383d1","modified":1711039690221},{"_id":"public/images/ss/lec10_1.jpg","hash":"14ac8fca4864d718874bc156f8ce20d501c38a0c","modified":1711039690221},{"_id":"public/images/ss/lec21_2.jpg","hash":"f025e0cf9db1ba9a044e401a6a950892b5ab7467","modified":1711039690221},{"_id":"public/images/physics/Exer9.29.jpg","hash":"21fd05a68ca3ffa4aa828512784a53ba943a9faf","modified":1711039690221},{"_id":"node_modules/hexo-theme-yun/source/css/_helper/third.styl","hash":"6cff9d8475ed43a9285b9550cdee519b244c4f85","modified":1711039832388},{"_id":"source/css/latex.css","hash":"1640f3bb8565d462c61f1772b3d3f23fdfcc40db","modified":1754887352037},{"_id":"source/css/latex_backup.css","hash":"cfc25db305d8e84111051873b4dc503dd7000f98","modified":1711042007704},{"_id":"public/css/latex.css","hash":"b95b39e24b379a1351a19347b40658fc8887d58e","modified":1711042857417},{"_id":"public/css/latex_backup.css","hash":"dfbce7b61df26d2f69d3e8c646919d8f9e9232e2","modified":1711042857417},{"_id":"source/fonts/LMROMAN10-BOLD.OTF","hash":"357c5982e93c15f4708460f801af6738d66b91db","modified":1621623092000},{"_id":"source/fonts/LMROMAN10-ITALIC.OTF","hash":"11bd5bd9bdb67360af92a5634e54d84a8817ff15","modified":1621623092000},{"_id":"source/fonts/LMROMAN10-REGULAR.OTF","hash":"1659bb9e4044ad90bd51e34a637c82b9d776dc06","modified":1621623092000},{"_id":"source/fonts/LMROMAN10-BOLDITALIC.OTF","hash":"ed644d3c1cb53774e907bb9735fda999ac74f394","modified":1621623092000},{"_id":"source/css/fonts.css","hash":"b474c426fca4bf67eb171b97c1504f53206f3d22","modified":1711082351503},{"_id":"source/fonts/SIMSUN.TTC","hash":"d5253c35a9d52bd9a2ff9b52f75559be1477bd11","modified":1689130161726},{"_id":"source/fonts/SmileySans-Oblique.otf","hash":"aa2e5d12745620677931135e93f432860b9cfc2f","modified":1711081363876},{"_id":"source/fonts/STFANGSO.TTF","hash":"1f24b50196eeef60d8312ff1e99d24b163136390","modified":1622518961389},{"_id":"source/fonts/STSONG.TTF","hash":"675ac1c7f78ad40fa0397dc65d5993790df22a23","modified":1622518961514},{"_id":"source/fonts/STKAITI.TTF","hash":"a87a569f30424a3d97d4e3fb0c435d783c5a51ec","modified":1622518961404},{"_id":"source/_posts/image/Antenna/1711090268476.png","hash":"8413c2194bc61fb61d529c03563e3c9bb08c5f04","modified":1711090269089},{"_id":"source/images/Antenna/1711090268476.png","hash":"8413c2194bc61fb61d529c03563e3c9bb08c5f04","modified":1711090269089},{"_id":"source/images/Antenna/1711091202619.png","hash":"70624ae6188826f7e25c010daccfd8c5b0f0d14d","modified":1711091203053},{"_id":"source/images/Antenna/1711090528566.png","hash":"2a02014f9f29c765839f2275b000ae6db03fe6d1","modified":1711090529008},{"_id":"source/images/Antenna/1711090565574.png","hash":"bc5ba9e7ec5989f3898e26cdc15b058c8b4421c0","modified":1711090566008},{"_id":"source/images/Antenna/1711091212947.png","hash":"72e0e82f17d26b424efa2c4ab6cd2b22accdfb5e","modified":1711091213360},{"_id":"source/_posts/image/SSP/1711254850893.png","hash":"3cbffa6cf046d3932308be9a7c2be6392a0fd273","modified":1711254851580},{"_id":"source/images/SSP/1711254850893.png","hash":"3cbffa6cf046d3932308be9a7c2be6392a0fd273","modified":1711254851580},{"_id":"source/_posts/StaSP.md","hash":"653df6b949d20f83dfba3fe3c30d1f07910e93c0","modified":1717313461576},{"_id":"source/images/StaSP/1711255303038.png","hash":"930a822739697d84c7993e97b409f6ad7d8ed43c","modified":1711255303433},{"_id":"source/images/StaSP/1711254850893.png","hash":"3cbffa6cf046d3932308be9a7c2be6392a0fd273","modified":1711254851580},{"_id":"source/_posts/DRL.md","hash":"4af308e5c3640871cc6acfa23c55b76ca4c229a4","modified":1713336896587},{"_id":"source/_posts/OS.md","hash":"ec2968582983710d6e36bbc26df0f5323dcf89ff","modified":1713274055033},{"_id":"source/_posts/SolidPhysics.md","hash":"9459f2d95bbeff59f7f7bdc8615ed7e92f791e84","modified":1718073000585},{"_id":"source/images/Antenna/1712900712333.png","hash":"9ab05b0d1bae0b858fd5741bf37120788313a766","modified":1712900713036},{"_id":"source/images/Antenna/1712901375924.png","hash":"a9e447f19ab7b099cbe613a59760f1abc29bf5a7","modified":1712901376342},{"_id":"source/images/Antenna/1712903308547.png","hash":"3d1e689bf6334cbeaa9ce4b984f6c9012457aff8","modified":1712903308959},{"_id":"source/images/DRL/1712925351346.png","hash":"dd758631edc2ef5bd6947f140471feaa3588b674","modified":1712925352069},{"_id":"source/images/DRL/1712925354266.png","hash":"dd758631edc2ef5bd6947f140471feaa3588b674","modified":1712925354696},{"_id":"source/images/SolidPhysics/1713237051369.png","hash":"f777cd30cd475db797c3c864166c012aeca2503c","modified":1713237051785},{"_id":"source/images/SolidPhysics/1713236929581.png","hash":"6ec044fa90e9c46fc96211b68da9f9744440610f","modified":1713236930006},{"_id":"source/images/SolidPhysics/1713236984022.png","hash":"fbfd9a0bdfbaf1e89f682ec26055cc995dff9a45","modified":1713236984431},{"_id":"source/images/StaSP/1712549637885.png","hash":"e1c46d78b6946ec5808626821450a28d9bd93671","modified":1712549638274},{"_id":"source/images/StaSP/1713066463994.png","hash":"68a380903a97640c761b0a5469065457fb83d4ab","modified":1713066464454},{"_id":"source/images/StaSP/1712549632251.png","hash":"e1c46d78b6946ec5808626821450a28d9bd93671","modified":1712549632705},{"_id":"source/images/StaSP/1713150631533.png","hash":"762563496d9b1a67f9bd690d92784cd778d3150a","modified":1713150632168},{"_id":"source/images/StaSP/1713150674892.png","hash":"e91593c7ddd40a880617ea3a4bbc983f1df0084e","modified":1713150675286},{"_id":"source/images/StaSP/1713150769252.png","hash":"a23be272f52093bccd200802e0cd978af0719103","modified":1713150769657},{"_id":"source/images/StaSP/1713150692811.png","hash":"72b3478ec2670505d48700efada86abfe7b4f816","modified":1713150693194},{"_id":"source/images/StaSP/1713152016025.png","hash":"e6f15be755af3115a1b2c637b3da9ee8bdd4a074","modified":1713152016522},{"_id":"source/images/Antenna/1711693683771.png","hash":"058e6c738b1f8661a6d09ce790b209bf9823b496","modified":1711693684506},{"_id":"source/images/Antenna/1711693936592.png","hash":"d1bc373f0f89c49ddaf99b7f44e6b5fd12481235","modified":1711693936989},{"_id":"source/images/Antenna/1711694350257.png","hash":"46d087829083363074f9697794166a252430ddef","modified":1711694350684},{"_id":"source/images/Antenna/1712471419276.png","hash":"a8d9f26499d2e6f2619caa59f2c19c1f2943deac","modified":1712471419973},{"_id":"source/images/Antenna/1711694639638.png","hash":"79f640cb6f1dd2aec80ae7d430b8ad236e585582","modified":1711694640021},{"_id":"source/images/Antenna/1712905317317.png","hash":"95143939feafa577efbc4a45424b35ab19fa5b05","modified":1712905317714},{"_id":"source/images/SolidPhysics/1713234834861.png","hash":"b6beab8010524a4eb20e0170bf683d39bea4fe52","modified":1713234835261},{"_id":"source/images/SolidPhysics/1713236269885.png","hash":"71c796a0777611626588ca29c24ae510978d4785","modified":1713236270270},{"_id":"source/images/SolidPhysics/1713237069207.png","hash":"3a8c3cfb91aa39974907691d94b8fa9efbbf7434","modified":1713237069643},{"_id":"source/images/SolidPhysics/1713237357342.png","hash":"dc9c7ac33ce5b9eccc68b6b6ff04c9eb5bf0626f","modified":1713237357750},{"_id":"source/images/SolidPhysics/1713240457384.png","hash":"60eba0bd3a3d0ce5b34c00fc734e60d222ba01b7","modified":1713240457841},{"_id":"source/images/StaSP/1711339831807.png","hash":"b892b2b31f6481fe95ec3c19cd2ae24390c1cf4d","modified":1711339832263},{"_id":"source/images/StaSP/1711339865703.png","hash":"4bde87c44e21a7348545fc138a935c246ac5e74e","modified":1711339866209},{"_id":"source/images/StaSP/1713151589324.png","hash":"7a707664c879ab2e7b8cf81cb63ee915477a30a8","modified":1713151589786},{"_id":"source/images/StaSP/1713152970273.png","hash":"428a8222475798a38acf2c6481cbeed8ab29a0c1","modified":1713152970773},{"_id":"source/images/Antenna/1711693701192.png","hash":"90f950cab41a26fddafe5e802e267329ba1e3a91","modified":1711693701594},{"_id":"source/images/Antenna/1711694027177.png","hash":"d10fd4e208f7bce7852d527747b91729f34fd3f8","modified":1711694027583},{"_id":"source/images/Antenna/1711694083583.png","hash":"89e47b2252019ea8d5ffc0c786dd51ea9bb43e09","modified":1711694083993},{"_id":"source/images/Antenna/1711694243897.png","hash":"c880c6a4bcd0c1b401de6b35bbb954ff37edc0a4","modified":1711694244304},{"_id":"source/images/Antenna/1711694619870.png","hash":"49865ad3aabcd1f92af16d8adb18aa23e5429685","modified":1711694620268},{"_id":"source/images/Antenna/1711694462059.png","hash":"fb2b0d9d4a0853192036223f104a011e61818a8a","modified":1711694462491},{"_id":"source/images/Antenna/1712902160882.png","hash":"8b7ffe42dcb671d60cbb76dab74a86f2a1a40085","modified":1712902161372},{"_id":"source/images/Antenna/1712905233876.png","hash":"a8bc922aa693b87e6cc1d84423e7ff100618ec51","modified":1712905234352},{"_id":"source/images/Antenna/1712473473687.png","hash":"af9172ffc320b38c4d617d06362ccd220142e564","modified":1712473474119},{"_id":"source/images/SolidPhysics/1713233318260.png","hash":"3134d8d46c6d8d9f92e16e9c11f99b1f6b31c0ca","modified":1713233318942},{"_id":"source/images/SolidPhysics/1713235941206.png","hash":"b538786fe7aa3cf167f38709fed54288d9727145","modified":1713235941656},{"_id":"source/images/SolidPhysics/1713234874686.png","hash":"8fef6736b73b2dddee5cf51ce322fd5d355fc2e3","modified":1713234875072},{"_id":"source/images/SolidPhysics/1713236233045.png","hash":"b9957428d9fdc0001cef7c29af803ba32fbd56cf","modified":1713236233449},{"_id":"source/images/SolidPhysics/1713239832006.png","hash":"60efe1fd249622a0672267ade3fb553c7a6faa3b","modified":1713239832434},{"_id":"source/images/StaSP/1711339249863.png","hash":"7e003e95f1caaa6c9629270185c9e6c61c5a3341","modified":1711339250285},{"_id":"source/images/StaSP/1711339192281.png","hash":"dea86cef815e3bff8248decf2af23157b99e72bf","modified":1711339192715},{"_id":"source/images/StaSP/1711339773571.png","hash":"f35a2222c4f96fcada8c2805e4d0d08df5fa3410","modified":1711339774035},{"_id":"source/images/StaSP/1711340163113.png","hash":"f04e672597e8c789db9f490fd0b11d772ff26388","modified":1711340163724},{"_id":"source/images/StaSP/1711340293644.png","hash":"14a4e2041014d1e264905a734e4f3bdde97ee9a7","modified":1711340294057},{"_id":"source/images/StaSP/1713152987612.png","hash":"a97b70b378dd1e0d51cee6810f6120811473d25c","modified":1713152987990},{"_id":"source/images/Antenna/1711693749686.png","hash":"03dd3521ef46a4fae0ea63eea5557771b60cdc1b","modified":1711693750073},{"_id":"source/images/Antenna/1711693861642.png","hash":"1ac0c9a310faf8424f2a35b3ae87870e1b99b8fa","modified":1711693862044},{"_id":"source/images/Antenna/1711693845822.png","hash":"10b8aa792448f824da2c3b0ff7622d7656a89cf8","modified":1711693846222},{"_id":"source/images/Antenna/1712471436962.png","hash":"57de5b46114a90356be56be88dd9d80b27a51098","modified":1712471437399},{"_id":"source/images/Antenna/1712471499226.png","hash":"6e3d4279f7ee74997491665373427dec33a4c9b6","modified":1712471499678},{"_id":"source/images/Antenna/1712905110844.png","hash":"eb26303ecc30193084e01346a0be8e3c26adbdb4","modified":1712905111314},{"_id":"source/images/SolidPhysics/1713236189430.png","hash":"bcab3f0429b61cdd5de9bd1bdcdb95d258b60439","modified":1713236189854},{"_id":"source/images/StaSP/1711339154789.png","hash":"33e36f1bd42e01a3841a7eba611e5e74413c2a93","modified":1711339155500},{"_id":"source/images/SolidPhysics/1713237158982.png","hash":"1c38192267e5a964009c3dd9587ff99a072ead73","modified":1713237159395},{"_id":"source/images/StaSP/1711339786814.png","hash":"5ee11519c54ac491a36cdee582fa9ae07329699b","modified":1711339787278},{"_id":"source/images/StaSP/1711339216759.png","hash":"feca86a96db3e2f5359b60ff0a9716acd34ed984","modified":1711339217183},{"_id":"source/images/StaSP/1711340151724.png","hash":"dd959f6ca1391014bf38c237b3e117900a2f9794","modified":1711340152281},{"_id":"source/images/StaSP/1711340177961.png","hash":"05d224478ed5d7051be60a775a375eb3b59f31e7","modified":1711340178439},{"_id":"source/images/StaSP/1711340277148.png","hash":"92594bd5865a2626ce1901f5f344921a226c5338","modified":1711340277567},{"_id":"source/images/AI/1713166706648.png","hash":"6b7157e16f2db3e538dbe2b24b0c1c1598b995d9","modified":1713166707285},{"_id":"source/images/AI/1713169419702.png","hash":"cd1a9a20bc1188e95392196a3685f5c815b0375e","modified":1713169420209},{"_id":"source/images/Antenna/1711695738159.png","hash":"943fb3fad638762b51d110a684f99969422373d7","modified":1711695738607},{"_id":"source/images/OS/1713266591628.png","hash":"f9d6fd144eee0d3a5f4cdcb18e1ed48100e97a56","modified":1713266592362},{"_id":"source/images/stuffs/1713000493686.png","hash":"2541d9a15ed692c9eb431215656d3faf480353e0","modified":1713000494536},{"_id":"source/images/AI/1713171808270.png","hash":"f81fded04ae15d12d66133123a9b119b05f8aae8","modified":1713171808703},{"_id":"source/images/AI/1713171795959.png","hash":"edaa5b5c7ce77579a156398656ec68ea187f77d3","modified":1713171796659},{"_id":"source/images/Antenna/1713506228135.png","hash":"4b227785205fd198fef0c39d24bc67bc95ad2522","modified":1713506228806},{"_id":"source/images/Antenna/1713506363705.png","hash":"b5a0472a44be51e1264f027699e9922d983650c4","modified":1713506364102},{"_id":"source/images/Antenna/1713506921640.png","hash":"1d0a6db3a74ae37815e49473042e57ed102b9226","modified":1713506922154},{"_id":"source/images/Antenna/1713508252106.png","hash":"fc9085f295777cfd0df6ddd537ba1cdd1bb2ee49","modified":1713508252625},{"_id":"source/images/Antenna/1713508379111.png","hash":"03e07ae545d8f99884fd685c20871be32fc80ec0","modified":1713508379705},{"_id":"source/images/Antenna/1713508784675.png","hash":"bfb2107afdd5834db42a9f31dc70e9076ae0cf8a","modified":1713508785052},{"_id":"source/images/Speech-SP/1713959362056.png","hash":"1cdea130f2047da97ef45811806c4f6417afaaa7","modified":1713959362574},{"_id":"source/images/Speech-SP/1713958735363.png","hash":"6e3ea72da10b091a6b621e02a06c950dd15d9607","modified":1713958735978},{"_id":"source/images/Speech-SP/1713960093567.png","hash":"37df1239ad6c11c0e0972090456f39cccdec3571","modified":1713960093940},{"_id":"source/images/Speech-SP/1713961039467.png","hash":"dca9ad5cf0a9a58cfcdf2bb5119dd2c266e977c7","modified":1713961039831},{"_id":"source/images/Speech-SP/1713963726242.png","hash":"65ee02b3fd1dd8c19c001edcf18e97c7af6d8b91","modified":1713963726635},{"_id":"source/images/Speech-SP/1713963786950.png","hash":"2ea821e631a2adfa7184fbf001b381dd8646ac46","modified":1713963787347},{"_id":"source/images/Speech-SP/1713962223184.png","hash":"c901a6801ff2c66c52dab90a664b15e402d984d5","modified":1713962223595},{"_id":"source/images/Speech-SP/1713963710139.png","hash":"45f9f13d9d8751a0233c6ad9554ca858e53130e1","modified":1713963710637},{"_id":"source/images/StaSP/1714361011137.png","hash":"ca988ba6859fe8e2593e826d3be7bd85f4f89731","modified":1714361011636},{"_id":"source/images/AI/1713775669844.png","hash":"3c4f60a517ca8413995a866d3c3158030397466d","modified":1713775670280},{"_id":"source/images/Antenna/1713506275022.png","hash":"f77b6d017281b6dc876fd1b1d217c9b3835c6da4","modified":1713506275471},{"_id":"source/images/Antenna/1713507175699.png","hash":"f2e336814856a9b832257d8e30a09659b2854941","modified":1713507176113},{"_id":"source/images/Antenna/1713506258888.png","hash":"3f64fde9c47fe87ed2759f9a33a52a572671071f","modified":1713506259301},{"_id":"source/images/Antenna/1713508669926.png","hash":"305a8410df2e27e82167dd9eaf6d9216db6da05e","modified":1713508670306},{"_id":"source/images/Speech-SP/1713958768829.png","hash":"31c76c6fb327d7f2b2bc2d0c2fa393237e472f09","modified":1713958769226},{"_id":"source/images/Antenna/1713509771675.png","hash":"dc185c4bb031856c1184b3b0540cc64311984b6f","modified":1713509772050},{"_id":"source/images/Speech-SP/1713960064882.png","hash":"50b52085dcb1ccb3aa21755e1b2c5aa5fbb99ff5","modified":1713960065302},{"_id":"source/images/Speech-SP/1713963998639.png","hash":"1a4e5a905eb203f8b18a5b54c2a8dd0193a77c52","modified":1713963999049},{"_id":"source/images/StaSP/1714360809348.png","hash":"a77bae5262d32103236a44f53e00b736c4354154","modified":1714360809815},{"_id":"source/images/StaSP/1714361027958.png","hash":"534a06afede87d4b93d11c2907267e516c045652","modified":1714361028364},{"_id":"source/images/StaSP/1714966226811.png","hash":"bacecaf43229d53706ebc3c4f1d738298bbe4dc9","modified":1714966227196},{"_id":"source/images/StaSP/1714966230536.png","hash":"bacecaf43229d53706ebc3c4f1d738298bbe4dc9","modified":1714966230986},{"_id":"source/images/StaSP/1714966200160.png","hash":"e8a81b0b0f18ba2f089c0bf7aeeca30fbe506f3b","modified":1714966200868},{"_id":"source/images/AI/1714379943169.png","hash":"14f5c8eb0f3c82f8335c45eb83c98c9fa6cd812e","modified":1714379943592},{"_id":"source/images/Antenna/1713506837120.png","hash":"e9d959e32da310407845dc3396926f2680d0e023","modified":1713506837610},{"_id":"source/images/Speech-SP/1713965424496.png","hash":"50c987a55f9ec13b22daa95a9fd2f458f88a361c","modified":1713965424943},{"_id":"source/images/StaSP/1714360782259.png","hash":"fb60946a338acdf5225e86118646232610308692","modified":1714360782677},{"_id":"source/images/AI/1714380132725.png","hash":"4326bd424cba55c5e294c0fb05831c31c3b329d8","modified":1714380133239},{"_id":"source/images/StaSP/1714360717248.png","hash":"3df6481374031d0cb3031bbc2c3366e02e542cf0","modified":1714360717960},{"_id":"source/images/StaSP/1714360742651.png","hash":"56671f616004501c1a3cbdf4c0922722d0e877fd","modified":1714360743070},{"_id":"source/images/AI/1713771652191.png","hash":"1e5c7ee378190bb235af848db65427f7acde8141","modified":1713771652892},{"_id":"source/images/Antenna/1713507190746.png","hash":"fe591d7170d792ecb91cbeee6b367e457ffbff53","modified":1713507191159},{"_id":"source/images/AI/1714380159356.png","hash":"b4e5bdc0146c8657f4192c42fbda6ae68568b554","modified":1714380159887},{"_id":"source/images/Antenna/1713507205996.png","hash":"17405eecd65ce1dae007dad4beec1b8c9b7e4d2c","modified":1713507206464},{"_id":"source/images/Antenna/1713509734724.png","hash":"86800bf245aa4a9c483365f0e428567e295c6486","modified":1713509735184},{"_id":"source/images/AI/1714380578105.png","hash":"9947ee9b61dac0cca0b0ccee32c1b9b1f3d830b3","modified":1714380578565},{"_id":"source/images/AI/1714380233071.png","hash":"23c4a5a27d3804604942522ee0ee6d579793bcc0","modified":1714380233514},{"_id":"source/images/Antenna/1713509120707.png","hash":"1c6fc75c611d0dedbc46ac01999aeb5470bee8d9","modified":1713509121120},{"_id":"source/images/AI/1714380343254.png","hash":"b9ce7f0b40e2af3e1480539440149127cebff95c","modified":1714380343766},{"_id":"source/images/AI/1714380111476.png","hash":"ae052930b9741099c3341946c30fe3392c9bf44d","modified":1714380111925},{"_id":"source/images/AI/1713772489046.png","hash":"03261a7bf9b650cb114a02455e942094e332278a","modified":1713772489562},{"_id":"source/images/AI/1714380763838.png","hash":"9d48daed587567d167b48530856de1e461804ae3","modified":1714380764306},{"_id":"source/images/AI/1714379335929.png","hash":"31b96de615f78187ef484f7dc4a383a3427f3f55","modified":1714379336620},{"_id":"source/images/AI/1713776156049.png","hash":"1affe7b7a87dd17d54794115b075794c8085d371","modified":1713776156550},{"_id":"source/images/AI/1713776168789.png","hash":"c44f5d3e1eef1a4711b511c7dce2984590e0814d","modified":1713776169266},{"_id":"source/_posts/DigiRL.md","hash":"e6f94bc5aea0070324f48852f7f83bec141687d0","modified":1721557023738},{"_id":"source/_posts/Mobile-LLM.md","hash":"e5c6a9403c677bcc9ca7bb402cd7c842b0ac63cd","modified":1721985248075},{"_id":"source/_posts/mathmagic.md","hash":"c4ebae04a8320836d4f9522c61d6817b16de5baf","modified":1755265572152},{"_id":"source/images/AI/1716193473766.png","hash":"55fb80ff683bc8f939177ff3678d1f3b2ad86a69","modified":1716193474203},{"_id":"source/images/Antenna/1717133859909.png","hash":"869450e6d58090578718fc09353b7fef7bcade30","modified":1717133860309},{"_id":"source/images/Antenna/1717133876692.png","hash":"869450e6d58090578718fc09353b7fef7bcade30","modified":1717133877123},{"_id":"source/images/Antenna/1717133761533.png","hash":"d1a34b9381b51f36a0163b145bd18b529fce01b2","modified":1717133762325},{"_id":"source/images/Antenna/1717133858173.png","hash":"869450e6d58090578718fc09353b7fef7bcade30","modified":1717133858581},{"_id":"source/images/Antenna/1717134268805.png","hash":"aa1da474bc93a5ddecfc0a75a57fbc59116370c3","modified":1717134269252},{"_id":"source/images/Antenna/1717134287481.png","hash":"79dec6b199942e2319bccb1eca1e20e49d302c44","modified":1717134287866},{"_id":"source/images/Antenna/1717134331603.png","hash":"9dd3b16ea308bc17285a2aad748229c528813527","modified":1717134332068},{"_id":"source/images/Antenna/1717134942873.png","hash":"fa08e278f76192b1a1324ddddf4f0bd8929b813e","modified":1717134943392},{"_id":"source/images/Antenna/1717134955235.png","hash":"446c0d1c36ac19cc2c975fe2564cc35aa9a9f73e","modified":1717134955709},{"_id":"source/images/Antenna/1717137633424.png","hash":"2e4cd55262e29a6f8875d058941d7c3afce68242","modified":1717137633844},{"_id":"source/images/Antenna/1717740726098.png","hash":"1db72472832abf42dde3355df37f6ed450bb4284","modified":1717740726566},{"_id":"source/images/Antenna/1717740758890.png","hash":"12df746d43feb424a21734c9437b5f529a6b179c","modified":1717740759303},{"_id":"source/images/Antenna/1718344358151.png","hash":"9ff91391276413fa1be04b2fd648989a8948083d","modified":1718344358839},{"_id":"source/images/Mobile-LLM/1718003792356.png","hash":"eea26f69d0f5437ca0a479df7976619c69b4d08f","modified":1718003792761},{"_id":"source/images/DigiRL/1721296320033.png","hash":"76e68da2f2a30b75a377ac60f0ae3070a60c02d1","modified":1721296320436},{"_id":"source/images/DigiRL/1721316686785.png","hash":"073a18549dd9e27daffae643d365f0d22e5d4824","modified":1721316687161},{"_id":"source/images/DigiRL/1721296305153.png","hash":"8f766a639d839445bbbac359881e8a0da64030a9","modified":1721296305748},{"_id":"source/images/DigiRL/1721316668685.png","hash":"2d77a05ca4697b30b5d261632ec35bcd8126d585","modified":1721316669063},{"_id":"source/images/Speech-SP/1715172378465.png","hash":"3f53e5a043a7ad14ed205b65d962eb1cb137cb95","modified":1715172379184},{"_id":"source/images/Speech-SP/1715172404966.png","hash":"4e28708523c4f94969ced3bc89bbc9f3b997b1eb","modified":1715172405376},{"_id":"source/images/Speech-SP/1715174312556.png","hash":"511a84ab0976ee945d81dec6197e8cf965cfdf82","modified":1715174313016},{"_id":"source/images/SolidPhysics/1715047577458.png","hash":"773c37db61583500ba009601d51b43977f039ab8","modified":1715047578291},{"_id":"source/images/Speech-SP/1715173923794.png","hash":"7f0d6d76498365240322db5ea4ae91d569dc6fbd","modified":1715173924189},{"_id":"source/images/Speech-SP/1716988653084.png","hash":"5844f9d43588223f808a2ba7d5cf6b1b8c271b66","modified":1716988653750},{"_id":"source/images/SolidPhysics/1715048234147.png","hash":"b64b92d5b2d5d0b8cdb51e7499eb50f014cd698a","modified":1715048234513},{"_id":"source/images/SolidPhysics/1715050052696.png","hash":"87d66b984ee20f7571686d8b119845138105e213","modified":1715050053148},{"_id":"source/images/SolidPhysics/1715048857194.png","hash":"9f4a8b61fbd90cae473a3c595849e363892b0991","modified":1715048857631},{"_id":"source/images/SolidPhysics/1715052169711.png","hash":"013741f8e61b339f217e6f78790938ac6c422976","modified":1715052170147},{"_id":"source/images/SolidPhysics/1715053936706.png","hash":"2728bafecf8d8c09711ffbac00720a8a4f3c613b","modified":1715053937150},{"_id":"source/images/SolidPhysics/1715657785337.png","hash":"de95224fe1727c5a779b1d9b3fdcd8e225e1af00","modified":1715657785788},{"_id":"source/images/SolidPhysics/1715659347111.png","hash":"a4129c293863d3ab9106423e1ee1177e3db2a30e","modified":1715659347556},{"_id":"source/images/SolidPhysics/1716259987276.png","hash":"0ae435994c5ff058be8a075a961d08d5aa1eb749","modified":1716259987715},{"_id":"source/images/SolidPhysics/1716260746330.png","hash":"4e152a2839d64bbb2aea113b3019814c0f4df214","modified":1716260746803},{"_id":"source/images/SolidPhysics/1716868157804.png","hash":"10f240589ded329c591deaec9e3439cc1cd3ab30","modified":1716868158247},{"_id":"source/images/SolidPhysics/1717468150691.png","hash":"5e23fa6951ebac3ed07f67a7742d8e9b82a9cc4f","modified":1717468151143},{"_id":"source/images/SolidPhysics/1718071692546.png","hash":"9f6b2c80371d7651056994d4323e1ff52e57f730","modified":1718071692956},{"_id":"source/images/SolidPhysics/1718071563960.png","hash":"ba420cebe9236e4517ae8c543417578f1a1ac0c9","modified":1718071564420},{"_id":"source/images/SolidPhysics/1718072997880.png","hash":"7e1f46d19663582edb387740438a8245f4da85e3","modified":1718072998279},{"_id":"source/images/AI/1716795255535.png","hash":"ea231faf4463d86b43b0e46199f6f27f8ff75440","modified":1716795256211},{"_id":"source/images/Antenna/1715324559069.png","hash":"038ea489d7d35b397542ccd12c443f484b47d3d5","modified":1715324559447},{"_id":"source/images/Antenna/1715325834911.png","hash":"889d9f34c0d63cfe367974b9b6db85cf3ff967b8","modified":1715325835614},{"_id":"source/images/Antenna/1715924314079.png","hash":"ff520dee8b0ed4be37bcc293e85e233b3c917128","modified":1715924314455},{"_id":"source/images/Antenna/1717134725130.png","hash":"62fc101a9065437e056d5dfae258f100b772a418","modified":1717134725506},{"_id":"source/images/Antenna/1717135386351.png","hash":"8bf7bc1accb7516b35816015ad9aac05167ae3f9","modified":1717135386910},{"_id":"source/images/Antenna/1717138714524.png","hash":"7aaeb2026f1af95af5416fb8abd606570a400666","modified":1717138714954},{"_id":"source/images/Antenna/1717740670364.png","hash":"1c2fb3ab5b935a51b0f7e4e6ec688329a15fdcbe","modified":1717740670766},{"_id":"source/images/Antenna/1717740667735.png","hash":"1c2fb3ab5b935a51b0f7e4e6ec688329a15fdcbe","modified":1717740668508},{"_id":"source/images/Antenna/1717742413544.png","hash":"8c77e8e20dd49adaa8a273a320ada74f2e87fb82","modified":1717742413949},{"_id":"source/images/Antenna/1717743927411.png","hash":"4be888e06623471ae3220ec053ee09285bcd39b5","modified":1717743927842},{"_id":"source/images/Antenna/1718345727630.png","hash":"d4fd06e4465764dbf78f6d9e5cf8117338919a28","modified":1718345728012},{"_id":"source/images/Antenna/1718346212882.png","hash":"802dc95cbb9a78fe7d72ca60ec4eeb314a6b523c","modified":1718346213318},{"_id":"source/images/Antenna/1718346379534.png","hash":"006857ed080b3da9e3d152ccb951ef361d64f541","modified":1718346379961},{"_id":"source/images/Speech-SP/1715172680511.png","hash":"19c93a6ce77944d76f61010077221c9ecc5043cc","modified":1715172680917},{"_id":"source/images/SolidPhysics/1715053184570.png","hash":"84ba700abd7159a2e7a6f48da7eb94d62ee868a2","modified":1715053184992},{"_id":"source/images/SolidPhysics/1715658350241.png","hash":"93e1f00ba1dcd5c8571af33aa6f7dfd90d23a9e0","modified":1715658350657},{"_id":"source/images/SolidPhysics/1715659894626.png","hash":"b658b6580f8c6da3b15654966a91d325e4464187","modified":1715659895114},{"_id":"source/images/SolidPhysics/1716258157706.png","hash":"6055fd5102e6a939293b0309d591cf3757700aaf","modified":1716258158147},{"_id":"source/images/SolidPhysics/1716259893782.png","hash":"28efe4b3abf04b925dadf9a1d98c4ed3d62e5379","modified":1716259894166},{"_id":"source/images/SolidPhysics/1716261236429.png","hash":"296cdac0023fab9c85d286da0fee1eb73157fe9f","modified":1716261236863},{"_id":"source/images/SolidPhysics/1716262583215.png","hash":"4c209554b19b9bce6e25c6fdf8976113b0863b59","modified":1716262583671},{"_id":"source/images/SolidPhysics/1717467815166.png","hash":"ef4a480873bbc7de11de21dc4c7690e3ef213717","modified":1717467815654},{"_id":"source/images/SolidPhysics/1717467681404.png","hash":"c223c76c96cd613e1151e7ac6650ce248ffd853d","modified":1717467682175},{"_id":"source/images/SolidPhysics/1716869156196.png","hash":"04893c7c705bd2e6ec858f30043f4de41f85258b","modified":1716869156598},{"_id":"source/images/SolidPhysics/1717468003069.png","hash":"d1f6a8727daa5eb9cf302161487e64737694615d","modified":1717468003524},{"_id":"source/images/SolidPhysics/1717468014637.png","hash":"9ebf0a5f7e02600012351f04d0eeeb034d3c1918","modified":1717468015069},{"_id":"source/images/SolidPhysics/1717468279238.png","hash":"716120b6ba129d7934f5e4a81ec947d12d007ef0","modified":1717468279615},{"_id":"source/images/SolidPhysics/1717468352260.png","hash":"bdfc79b8f8d01267ce62514d9aec5bf6d4abe71e","modified":1717468352746},{"_id":"source/images/SolidPhysics/1717468364464.png","hash":"2212b076be3e3b5abf988ffe247a5b9731fed3a0","modified":1717468364871},{"_id":"source/images/SolidPhysics/1717469080107.png","hash":"b9b3dbd59ec17e5bb6f57bea4922077854d230a1","modified":1717469080539},{"_id":"source/images/SolidPhysics/1717470027229.png","hash":"bcd9fcdf503284a5e394ca220cc8fc65c349678b","modified":1717470027638},{"_id":"source/images/SolidPhysics/1717469005887.png","hash":"0e947d1064598c96c713215e2015576907e7f458","modified":1717469006308},{"_id":"source/images/SolidPhysics/1717473776761.png","hash":"0d432f42633402a03aba8a49522226889a304b54","modified":1717473777190},{"_id":"source/images/SolidPhysics/1718071202034.png","hash":"2c771a5df99218b1c14c266d708c2c870e782909","modified":1718071202463},{"_id":"source/images/SolidPhysics/1718071135404.png","hash":"0edd27fa5b004a05966b1b708e97ffad96994b27","modified":1718071136042},{"_id":"source/images/SolidPhysics/1718072235738.png","hash":"6a86eb0bca69cf4068f25809ac7659cb5361b933","modified":1718072236111},{"_id":"source/images/SolidPhysics/1718072474995.png","hash":"53a78dd849a2626ba38f6d081e027c8f29041b7c","modified":1718072475435},{"_id":"source/images/SolidPhysics/1718072707268.png","hash":"89e5081a4b23b8cb82361d9dd58c598d6ba09701","modified":1718072707650},{"_id":"source/images/SolidPhysics/1718072084533.png","hash":"7c0978e52cdddbe55f26b1433e897d4b5ffb2579","modified":1718072084937},{"_id":"source/images/SolidPhysics/1718071922789.png","hash":"a0df1e6655915401328df123997edf8930c13bb2","modified":1718071923209},{"_id":"source/images/SolidPhysics/1718072255786.png","hash":"dd1430de8685dcf9b5abe5a97bfdc19a83e02f18","modified":1718072256169},{"_id":"source/images/AI/1714984778231.png","hash":"64aff4a4b67f98f9ed62f03ef3c47a87227ea4e3","modified":1714984778689},{"_id":"source/images/AI/1716796227758.png","hash":"48510e39e963905d1d2d21db55f7c79b2033d3ab","modified":1716796228208},{"_id":"source/images/AI/1716796229664.png","hash":"48510e39e963905d1d2d21db55f7c79b2033d3ab","modified":1716796230151},{"_id":"source/images/AI/1717401124879.png","hash":"8ba8247fdac0b5de4c7fc7208652ee3d3d5dbe57","modified":1717401125309},{"_id":"source/images/AI/1717400852805.png","hash":"1003d5289bf8ae50233934f2e434cd8880a2e9fa","modified":1717400853222},{"_id":"source/images/AI/1717400854837.png","hash":"1003d5289bf8ae50233934f2e434cd8880a2e9fa","modified":1717400855272},{"_id":"source/images/Antenna/1715324548326.png","hash":"f26c1ac327255c5ab17728acd2baef40e4f43dfe","modified":1715324549090},{"_id":"source/images/Antenna/1715924283522.png","hash":"f03c134c5f1024fa7fb407b824fa79efb061a21b","modified":1715924284150},{"_id":"source/images/Antenna/1715924294266.png","hash":"d2a95b8f548cb6c69cfabb3be681d59b8e5a1f75","modified":1715924294630},{"_id":"source/images/Antenna/1715924338243.png","hash":"220cfad3d1f0307848d030c1f4bce6f6623f679b","modified":1715924338658},{"_id":"source/images/Antenna/1715924364965.png","hash":"2f07b31a989f5c4246d6a953b72fce8f49399a74","modified":1715924365353},{"_id":"source/images/Antenna/1715928380068.png","hash":"8163193057085b1fa8307d42c31f06ed93eacf12","modified":1715928380494},{"_id":"source/images/Antenna/1715924463502.png","hash":"2c4fe04c5a7269cddc267d00f36620038f78a66a","modified":1715924463903},{"_id":"source/images/Antenna/1715929523072.png","hash":"29a9c6ab1267cc34dea1e2bf6496d61b3fe2523b","modified":1715929523512},{"_id":"source/images/Antenna/1717134897852.png","hash":"adba25220cc2966b9872d2ecd0c67aab740cc9ae","modified":1717134898315},{"_id":"source/images/Antenna/1717134745100.png","hash":"7bca1cfb810e96ae409997a58be5161314a3f0ed","modified":1717134745551},{"_id":"source/images/Antenna/1717135951201.png","hash":"1eb6860218d8364f7797b0f701cd11860c420dee","modified":1717135951630},{"_id":"source/images/Antenna/1717740768183.png","hash":"21910f0704f85ea56f0951708e3171c43b4db81b","modified":1717740768706},{"_id":"source/images/Antenna/1717740680573.png","hash":"f54a34d87af6fe62e1fdd6547e76397b8197d57c","modified":1717740680987},{"_id":"source/images/Antenna/1717742374397.png","hash":"53a280e69e48e68ddb36c2ec2bb7ac7879fe21fb","modified":1717742374863},{"_id":"source/images/Antenna/1717740801741.png","hash":"29913f62912571e46161f816791aee37508763a7","modified":1717740802216},{"_id":"source/images/Antenna/1717743691321.png","hash":"a86d4909bf4652f532c955c9266bb570b9a582c3","modified":1717743691774},{"_id":"source/images/Antenna/1717743460723.png","hash":"b48892b748ea6fa08958c3525c724dbc2890d7e9","modified":1717743461135},{"_id":"source/images/Antenna/1718345718761.png","hash":"47267c2b3e2cce8bf2955af1fa22d31b6a6b7c18","modified":1718345719191},{"_id":"source/images/Mobile-LLM/1717937154526.png","hash":"61d79cfb505b42dad15ce59217b8bb3fefb2b5a2","modified":1717937155205},{"_id":"source/images/Mobile-LLM/1718003623779.png","hash":"69e46d12d2c5513589ea41b35184e0b02fbd9707","modified":1718003624528},{"_id":"source/images/SolidPhysics/1715048162767.png","hash":"c4246a43b48dd4779f82ebc75acae8c30caaccf0","modified":1715048163192},{"_id":"source/images/SolidPhysics/1716257919907.png","hash":"038acfd63df05afeefa3825fb4455c2062e02d81","modified":1716257920375},{"_id":"source/images/SolidPhysics/1716257832298.png","hash":"c309110871773464da8cad6f3c75ba0e85f28ecf","modified":1716257832726},{"_id":"source/images/SolidPhysics/1716259850103.png","hash":"1a7ce240f37b8af0caf339b51257586695e05baf","modified":1716259850508},{"_id":"source/images/SolidPhysics/1716258191070.png","hash":"ff045fc72869467a260c8839e5950ba3b9cb0da2","modified":1716258191487},{"_id":"source/images/SolidPhysics/1716261766058.png","hash":"56ef8c39fd68fce0311870d1f6a8ebbbf653da92","modified":1716261766482},{"_id":"source/images/SolidPhysics/1716262570823.png","hash":"fa1d7d1464736f33444fe2a117c194aadbaffe5c","modified":1716262571271},{"_id":"source/images/SolidPhysics/1716263538645.png","hash":"0bb45ae43a91546ed145d2b06f3b38839e945f81","modified":1716263539061},{"_id":"source/images/SolidPhysics/1716263526504.png","hash":"bad200cc6513ac657f4590653722a6bce82ca820","modified":1716263526972},{"_id":"source/images/SolidPhysics/1716263941957.png","hash":"80998d03fef31f35e0614223b4142d8d985654e3","modified":1716263942477},{"_id":"source/images/SolidPhysics/1716864038557.png","hash":"8ffa1f32b5ffdbf81c0078db29c752ac87818401","modified":1716864038974},{"_id":"source/images/SolidPhysics/1716864050264.png","hash":"de536e67dade2c8cbe58beeeec1081070e7af358","modified":1716864050699},{"_id":"source/images/SolidPhysics/1716869179928.png","hash":"0262bf59564d12195181a8e210db1e4bc71b4d45","modified":1716869180354},{"_id":"source/images/SolidPhysics/1717467940325.png","hash":"7904d685fc83faffae3cb43dd576a073e585229a","modified":1717467940798},{"_id":"source/images/SolidPhysics/1717468250438.png","hash":"289f736942d321aa0cc3ef236174f6af96ba9e6f","modified":1717468250872},{"_id":"source/images/SolidPhysics/1717469037238.png","hash":"d63d3866e484f08b5436afdd7b3dd8906b20235a","modified":1717469037804},{"_id":"source/images/SolidPhysics/1717469056663.png","hash":"9b38df9565fe3f3e28c246a3e5c0f87d0f895076","modified":1717469057115},{"_id":"source/images/SolidPhysics/1717473805195.png","hash":"e72c201a803aed1eeb0f5fc10325c5914c670831","modified":1717473805757},{"_id":"source/images/SolidPhysics/1718071363760.png","hash":"6a17e766a1f07c81498be8399c555bd510be4c14","modified":1718071364166},{"_id":"source/images/AI/1716796053911.png","hash":"04a7ec9f47946d1efd58991e2a098e1641f8b516","modified":1716796054330},{"_id":"source/images/Antenna/1715324769403.png","hash":"55a5856ef9f29d6bf3f2e8cba3288651969362f3","modified":1715324769849},{"_id":"source/images/Antenna/1717134353772.png","hash":"6d16d43dd155700f5efc443c3e5fbe04b88bc3e7","modified":1717134354190},{"_id":"source/images/Antenna/1717135198414.png","hash":"dfcff7db5694525d09af30523efed4f665a55abd","modified":1717135198913},{"_id":"source/images/Antenna/1717135044895.png","hash":"27ae56aec3412ef918ad5f21373f6ac13d05c8cd","modified":1717135045307},{"_id":"source/images/Antenna/1717135171215.png","hash":"ce816b2dae9018d6b17302220864a51b4d31d974","modified":1717135171652},{"_id":"source/images/Antenna/1717135675789.png","hash":"8f71f395ef3faaec8d0969f5070464148d06f442","modified":1717135676241},{"_id":"source/images/Antenna/1717740786849.png","hash":"f46bdfdee7a5252230dc6efb6f4b94d8291fa059","modified":1717740787376},{"_id":"source/images/Antenna/1717742626807.png","hash":"391031f21033258d68cc6f22b867fd99274cc2e2","modified":1717742627207},{"_id":"source/images/Antenna/1718346371235.png","hash":"216f9f83dedb6b1f971f247e44a93f9a3dfa56a0","modified":1718346371702},{"_id":"source/images/Antenna/1718346830900.png","hash":"dc17592d1211f55a82d1140b5bbebe54a1854ad2","modified":1718346831332},{"_id":"source/images/Antenna/1718346571584.png","hash":"0daf4a59791c5cf5e86ea5d43a24ed39898143fb","modified":1718346572216},{"_id":"source/images/Mobile-LLM/1717937734857.png","hash":"05dcd285c84847489f1be1a64301dbe8194d5c45","modified":1717937735281},{"_id":"source/images/Mobile-LLM/1717940196994.png","hash":"105e767082ebbb56b71cfcf10eb47d8a89756122","modified":1717940197428},{"_id":"source/images/Mobile-LLM/1718009413946.png","hash":"eeb0f19ccc446d86e885af519a82ff60bac2dc20","modified":1718009414649},{"_id":"source/images/Mobile-LLM/1721230554686.png","hash":"1f28270573804c245975e0a7a6ba4ea32455eaf9","modified":1721230555264},{"_id":"source/images/Speech-SP/1715172645812.png","hash":"408fbd226714fbba107158ac0ac2b2b5bc7657b1","modified":1715172646253},{"_id":"source/images/SolidPhysics/1715051145151.png","hash":"2c71261ee1d28aef85a32b3afb5bb10a9ebbc493","modified":1715051145585},{"_id":"source/images/SolidPhysics/1715051313166.png","hash":"451508e95fb9fe06cbfd333fe26f4fe919db995f","modified":1715051313601},{"_id":"source/images/SolidPhysics/1716258575169.png","hash":"bc2200c8ba2715122984f7c3fda6abc87d997463","modified":1716258575589},{"_id":"source/images/SolidPhysics/1716257709851.png","hash":"aa1a3d0a01af6afe25dc18ffc0a9f1dc6ee58c48","modified":1716257710554},{"_id":"source/images/SolidPhysics/1715658620805.png","hash":"495d7b2543a5e5d1e2a8ee5b19e289d57d671d24","modified":1715658621249},{"_id":"source/images/SolidPhysics/1716260901275.png","hash":"1804f4af394be28d3a40c7d6950cda36bb595c5c","modified":1716260901730},{"_id":"source/images/SolidPhysics/1716261409659.png","hash":"65e4c2bf5e27d0d81e858b1b9d56abd2e29ff202","modified":1716261410084},{"_id":"source/images/SolidPhysics/1716263918247.png","hash":"f716977841f38638ad71f1b138ec077faa0ff0fd","modified":1716263918690},{"_id":"source/images/SolidPhysics/1716863556246.png","hash":"66787133de88e9fba4ede5073375fe539603964e","modified":1716863556915},{"_id":"source/images/SolidPhysics/1716868762789.png","hash":"cfb78a9c96a4a85e306edf0fb4e77f30eeb70272","modified":1716868763320},{"_id":"source/images/SolidPhysics/1717467825452.png","hash":"26ae05253e9714069bb76f419d72bc92aa31e54c","modified":1717467826027},{"_id":"source/images/SolidPhysics/1717467885133.png","hash":"50068bd5af0c7636497e949558792a4b11ea543d","modified":1717467885617},{"_id":"source/images/SolidPhysics/1717469702087.png","hash":"9f97a42e68839504caeed08577e852b3e1cb9604","modified":1717469702515},{"_id":"source/images/mathmagic/1721059341655.png","hash":"7f385447865343cd5cc665ae79537bb1ab7f6047","modified":1721059341660},{"_id":"source/images/Antenna/1715324583382.png","hash":"6fff655a623e37a82acdb634de486a206f77062f","modified":1715324583820},{"_id":"source/images/Antenna/1715927654495.png","hash":"2e3619671b493390e134c5820fc04a0959fe47d9","modified":1715927654940},{"_id":"source/images/Antenna/1715929396692.png","hash":"5e135b5f9874e98cd02983f05a7d3744b5f6e49f","modified":1715929397165},{"_id":"source/images/Antenna/1715929046320.png","hash":"0c37a48eb713d1317e6b62bdebe97aeb2b309905","modified":1715929046844},{"_id":"source/images/Antenna/1715929531751.png","hash":"c23cdca559b015bf03e5677627044afaf769265d","modified":1715929532240},{"_id":"source/images/Antenna/1717136115015.png","hash":"8739ca0a4ed6c160310dbe3e69e53b17b2458674","modified":1717136115539},{"_id":"source/images/Antenna/1717743681072.png","hash":"d540d785e6e72a49daef9ff95c1f18287f1587f6","modified":1717743681539},{"_id":"source/images/Antenna/1718345601277.png","hash":"9a747d413bbfde902f027020286eedf6ae82fac0","modified":1718345601694},{"_id":"source/images/Mobile-LLM/1717937675502.png","hash":"8a9cc967ab43c38b919b152a1f8bbf05d6a16e10","modified":1717937675945},{"_id":"source/images/Mobile-LLM/1717939486804.png","hash":"e3dcc35181a5bc10797e780ae90bf9467e16f2e0","modified":1717939487474},{"_id":"source/images/Mobile-LLM/1718009240031.png","hash":"535daea25e04d087799357d531696710afcc798b","modified":1718009240748},{"_id":"source/images/Mobile-LLM/1721231007829.png","hash":"b1d8d2bec46744eccf6e65a1fdf31baa0aeb1c05","modified":1721231008279},{"_id":"source/images/DigiRL/1721232302611.png","hash":"6915fc979c7232675a180050f184a666e9f16d9c","modified":1721232303049},{"_id":"source/images/AI/1716795740579.png","hash":"94e4c9853a89f4a3980241798380a36e84a05ff8","modified":1716795741076},{"_id":"source/images/Antenna/1715328812089.png","hash":"3bdce3e09e8da0616a5b6b620c3ad1ca36850aa0","modified":1715328812837},{"_id":"source/images/Antenna/1715927982080.png","hash":"85bcc770909fea6bfe35263d71bce73db5a746b4","modified":1715927982504},{"_id":"source/images/Antenna/1715929138391.png","hash":"80ca61e88e2d34b1b4856d7faa92d2f36904c523","modified":1715929138862},{"_id":"source/images/Antenna/1715929501432.png","hash":"4b4a2adaba1df63007158c4bf2fd3de1dfe12cb7","modified":1715929501932},{"_id":"source/images/Antenna/1717137646795.png","hash":"6ccbef2f9bf92182e14b38880fc62f04e02b82a1","modified":1717137647192},{"_id":"source/images/Antenna/1717136046473.png","hash":"afb4bef8059ceed3d19b348188459351df637569","modified":1717136047008},{"_id":"source/images/Antenna/1717743468657.png","hash":"311fc6cd25394590c4a2258fd6701cb1e668da28","modified":1717743469078},{"_id":"source/images/SolidPhysics/1715053408715.png","hash":"438e2d17a0765697b2028f9fe7ef08fb9d8f86ff","modified":1715053409150},{"_id":"source/images/SolidPhysics/1716263334906.png","hash":"816bc22e34dce46914e19114285407c70743f2ce","modified":1716263335329},{"_id":"source/images/AI/1716194583833.png","hash":"e19228b5ae80100a1183ffa91917ac23a7032b3e","modified":1716194584320},{"_id":"source/images/AI/1716795753326.png","hash":"d37585f72f25f219a9e1bd4324470b1aa4983242","modified":1716795753760},{"_id":"source/images/AI/1717401031002.png","hash":"8c43b8f06e167b865255e74f0e9c4ad7d621e21b","modified":1717401031458},{"_id":"source/images/AI/1717401591545.png","hash":"39b4f7cbfef285145f29cefe4c136bfb1c8329ef","modified":1717401592000},{"_id":"source/images/SolidPhysics/1716261781489.png","hash":"69b7db34064eea6b2a1eca8f2d0cd1e9990d6b5b","modified":1716261781929},{"_id":"source/images/SolidPhysics/1717470756612.png","hash":"5be624515ae416a844ac119e0df9b9bcdc98e8ab","modified":1717470757056},{"_id":"source/images/AI/1716192175996.png","hash":"0ae0b32c47e92bc8f97bd59b52ca1a92809bd55a","modified":1716192176464},{"_id":"source/images/AI/1716192534058.png","hash":"496f61701a34a28b9b69118a1a8af4b012faa6db","modified":1716192534554},{"_id":"source/images/AI/1716192519850.png","hash":"0e046b30035ee0928a26405008d3639075c415fb","modified":1716192520360},{"_id":"source/images/AI/1716194320872.png","hash":"f191729760c87f269a7bcc1d55fb238ad2e255d9","modified":1716194321308},{"_id":"source/images/AI/1716194757145.png","hash":"63a5383cb40f4095e6e1da823822a9916e2150cb","modified":1716194757595},{"_id":"source/images/AI/1716195398036.png","hash":"f61f37202be33268a5c3851ab11280200cd7871e","modified":1716195398472},{"_id":"source/images/AI/1716798247574.png","hash":"83298a93bb99f889c54d1cc305827f5a2fb62aae","modified":1716798248045},{"_id":"source/images/AI/1716798850106.png","hash":"fca0e94319154b93ab4dc35db8f29e6b4bf4918f","modified":1716798850613},{"_id":"source/images/AI/1717400667281.png","hash":"a51e7898fdff1fc4a43b1e227dd324aa9cd28810","modified":1717400668015},{"_id":"source/images/AI/1717404907709.png","hash":"20407d40c44ab2f2a312eb59134c30417a643158","modified":1717404908152},{"_id":"source/images/Antenna/1717138873279.png","hash":"2cea3f5fc87314e6669755754ea007b4141cd65c","modified":1717138873750},{"_id":"source/images/mathmagic/1721059328456.png","hash":"9535715c2d71cc661712ea4db3f88fb3e18b5fd0","modified":1721059328462},{"_id":"source/images/AI/1714985971187.png","hash":"3dbf340bc8af88ab577a398077abe4e6d5a234ab","modified":1714985971658},{"_id":"source/images/AI/1716191759894.png","hash":"91301eb0bb42f67533cdd8a14ed74e63834d5687","modified":1716191760656},{"_id":"source/images/AI/1716194228666.png","hash":"8bbac5445261592c27f3bda0d167d7b8a321bd4c","modified":1716194229176},{"_id":"source/images/AI/1716195442145.png","hash":"4cf1a09c081624aba179e5517715ca69fb70daae","modified":1716195442600},{"_id":"source/images/AI/1716799063581.png","hash":"f17ce7189220ea772de489c7ccfb175f178332b9","modified":1716799064063},{"_id":"source/images/AI/1717404790783.png","hash":"2dc92de20f4e529c7ce93c062f141f241bfb4c91","modified":1717404791223},{"_id":"source/images/Antenna/1715929169213.png","hash":"d93c13a77d0e05246e7d3441a7b7f9a021debb9b","modified":1715929169748},{"_id":"source/images/Antenna/1715929546494.png","hash":"09e1e244bd3a8f5f268a2812cbb2050773084ae3","modified":1715929547031},{"_id":"source/images/AI/1714982075164.png","hash":"d0c5c947e639a5bce52adc673ad580700765637e","modified":1714982075800},{"_id":"source/images/AI/1714982215920.png","hash":"f7d212f44cbec053cbf7ab02fe75612032f97b93","modified":1714982216422},{"_id":"source/images/AI/1714983390325.png","hash":"7e4b5485b6a95944795a5f5beceb3d35d958ed56","modified":1714983390834},{"_id":"source/images/AI/1714985419724.png","hash":"a5e174c15091ea2bbeabfe0af6062746e570dc64","modified":1714985420209},{"_id":"source/images/AI/1716193180893.png","hash":"0221857bb9e1778dd6e3f1aee6a833ab1d9d09b3","modified":1716193181390},{"_id":"source/images/AI/1716195002371.png","hash":"03a1f98ace0311896f5cd70ca2640271824c2482","modified":1716195002875},{"_id":"source/images/AI/1716194633162.png","hash":"7eea5ec9a24187428e53ca04c4df291126cc0c6e","modified":1716194633681},{"_id":"source/images/AI/1716798927981.png","hash":"512b24b36d22436dfb28a1aa0b7fa7f8360a83bd","modified":1716798928537},{"_id":"source/images/AI/1716798687551.png","hash":"e7921042efb874a4fb745d1e75075344c71232b9","modified":1716798688069},{"_id":"source/images/AI/1716799707301.png","hash":"fa68f1f9dc0df0ef0d25baaa53c5a2d81c763daf","modified":1716799707802},{"_id":"source/images/AI/1717401517265.png","hash":"13eff601e7e3278e0d1071871f99f3fb65614c9d","modified":1717401517753},{"_id":"source/images/AI/1714982188331.png","hash":"bfa4479ee775dc43195d02f34346f281cdc504cb","modified":1714982188808},{"_id":"source/images/AI/1714983788461.png","hash":"980ab8baca522b929d674b1c669331d1fbd26f6a","modified":1714983788951},{"_id":"source/images/AI/1714986050538.png","hash":"9eb4f889436358b687aaa92d2f2ecfc99bf3c68d","modified":1714986050992},{"_id":"source/images/AI/1716192135361.png","hash":"bd2f9ebb7280c9077d1ebe316ed726bbb517c9e4","modified":1716192135838},{"_id":"source/images/AI/1716797001550.png","hash":"a4b676d8d91d657e3e24a15d2c556fc4d77645e5","modified":1716797002010},{"_id":"source/images/AI/1716797936119.png","hash":"e74c33eb56e0a025240ebc6b83500940aa0bec16","modified":1716797936593},{"_id":"source/images/AI/1717403664862.png","hash":"3cf906f5c769de9ae0fbbf28dc191643a7896f4c","modified":1717403665298},{"_id":"source/images/AI/1717405435705.png","hash":"3572cf76044a9be0fdcedd0deb7c219616305795","modified":1717405436191},{"_id":"source/images/AI/1717405465141.png","hash":"76f1f3d9a89ae90b5722264194e865296bfcae59","modified":1717405465601},{"_id":"source/images/AI/1714982405665.png","hash":"b9d7e95d487969ca46c86e967d9c32ecdf7cf7bc","modified":1714982406153},{"_id":"source/images/AI/1714983452419.png","hash":"a910396204799a63ac6db1a4cb1f3a482a90e85d","modified":1714983452902},{"_id":"source/images/AI/1717403702542.png","hash":"75e2a10f2361bdab08c933c1cfb889fd0b534704","modified":1717403703053},{"_id":"source/images/AI/1717404024479.png","hash":"59e11fd3f565a74573fabf0d18825cc0c7c5edeb","modified":1717404024946},{"_id":"source/images/AI/1714983988587.png","hash":"b389196ed01882db825cc771213069b5f6de3ec2","modified":1714983989033},{"_id":"source/images/AI/1717403725888.png","hash":"8c668bdd3a6a1d5d4aca3e918bb5ce4f6a7118f2","modified":1717403726404},{"_id":"source/images/AI/1714982108981.png","hash":"371e55b32a3c8e7426ea4b898b1e5f0961c6a003","modified":1714982109450},{"_id":"source/images/AI/1714982133935.png","hash":"4fdf76cd3c128b796ef871d8576708b872a2680b","modified":1714982134393},{"_id":"source/images/AI/1714983641507.png","hash":"cccb7207dc221bd0f15985413427d05dec4cc077","modified":1714983642019},{"_id":"source/images/Antenna/1718347869028.png","hash":"e53e12142520eeac4091106d9d4afe79b7f1145b","modified":1718347869485},{"_id":"source/images/Antenna/1718347859765.png","hash":"44be807e29ef5eb2aa68675c91cf02e0ffe54b20","modified":1718347860196},{"_id":"source/images/AI/1714984460020.png","hash":"db73229dea48b0ad19be7016a992ce89fc34f284","modified":1714984460697},{"_id":"source/_posts/llama3-1.md","hash":"4bb138d7501e792133aa948820582a9c092283df","modified":1721880943430},{"_id":"source/images/Mobile-LLM/1721962899191.png","hash":"7e399873a69dd1f8bd4bfefb4fdf9a2f20b2f57f","modified":1721962899763},{"_id":"source/images/Mobile-LLM/1721792309928.png","hash":"4cd6428f9451e65dbad826348e7c9f302623a4ab","modified":1721792310358},{"_id":"source/images/DigiRL/1721555695196.png","hash":"070e28114f0e7a2005119a83528209d5683d5b9b","modified":1721555695642},{"_id":"source/images/DigiRL/1721555459238.png","hash":"6e1ac9992d475734492ae0fed9a1cded8a49e48e","modified":1721555459664},{"_id":"source/images/Mobile-LLM/1721792120662.png","hash":"4909a7579a6562610eaeb059960194a3573480f4","modified":1721792121170},{"_id":"source/images/Mobile-LLM/1721962961205.png","hash":"f66ed6109d153bd5b075e5bc2067b03f6b86dfac","modified":1721962961610},{"_id":"source/images/DigiRL/1721554892738.png","hash":"6c8fbc1ea80c749e770c309e248e0875fd2179cc","modified":1721554893488},{"_id":"source/images/Mobile-LLM/1721718047655.png","hash":"d0210f2e13ff302d3943ad0f96c82e8f8040f512","modified":1721718048452},{"_id":"source/images/Mobile-LLM/1721924737611.png","hash":"c2b677b0761b3c8510e0b925ef52bc91946bf5b2","modified":1721924738417},{"_id":"source/_posts/DDPM.md","hash":"57033d27a2c00cf58b368eef9db86dd117d29daf","modified":1754828097325},{"_id":"source/images/DDPM/1753442174434.png","hash":"e230070f1eaa309bf19e23edc8793cfdd40f1662","modified":1753442175173},{"_id":"source/images/DDPM/1753424129654.png","hash":"82a39afe1f74084fdfdcea7d6d35cfbd1ae0effb","modified":1753424130885},{"_id":"source/_posts/DDIM.md","hash":"d39912142c430da1d7d8a22abd6a1ed6dd150953","modified":1754919679288},{"_id":"source/_posts/泛函分析.md","hash":"f9a2d9e8619c06c1cd99560be95180f707dccbe3","modified":1758878155683},{"_id":"source/_posts/最优化方法.md","hash":"8cb68d96001a25937c0033370ec23aad0f2e6c10","modified":1758864658823}],"Category":[],"Data":[],"Page":[{"_content":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"华文宋体\", \"宋体\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"Noto Serif SC\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"Noto Serif SC\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"Noto Serif SC\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"Noto Serif SC\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n.markdown-body {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n.markdown-body > h3.md-focus:before,\n.markdown-body > h4.md-focus:before,\n.markdown-body > h5.md-focus:before,\n.markdown-body > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n.markdown-body {\n  counter-reset: body-h2 0;\n}\n\n.post-title h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n\n.markdown-body h2 {\n  counter-reset: body-h3;\n}\n.markdown-body h3 {\n  counter-reset: body-h4;\n}\n.markdown-body h4 {\n  counter-reset: body-h5;\n}\n.markdown-body h5 {\n  counter-reset: body-h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: body-h2;\n  content: counter(body-h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.markdown-body:before {\n  counter-increment: body-h3;\n  content: counter(body-h2) \".\" counter(body-h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.markdown-body:before {\n  counter-increment: body-h4;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.markdown-body:before {\n  counter-increment: body-h5;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.markdown-body:before {\n  counter-increment: body-h6;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5) \".\" counter(body-h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n","source":"css/latex.css","raw":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"华文宋体\", \"宋体\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"Noto Serif SC\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"Noto Serif SC\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"Noto Serif SC\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"Noto Serif SC\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n.markdown-body {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n.markdown-body > h3.md-focus:before,\n.markdown-body > h4.md-focus:before,\n.markdown-body > h5.md-focus:before,\n.markdown-body > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n.markdown-body {\n  counter-reset: body-h2 0;\n}\n\n.post-title h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n\n.markdown-body h2 {\n  counter-reset: body-h3;\n}\n.markdown-body h3 {\n  counter-reset: body-h4;\n}\n.markdown-body h4 {\n  counter-reset: body-h5;\n}\n.markdown-body h5 {\n  counter-reset: body-h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: body-h2;\n  content: counter(body-h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.markdown-body:before {\n  counter-increment: body-h3;\n  content: counter(body-h2) \".\" counter(body-h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.markdown-body:before {\n  counter-increment: body-h4;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.markdown-body:before {\n  counter-increment: body-h5;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.markdown-body:before {\n  counter-increment: body-h6;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5) \".\" counter(body-h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n","date":"2025-08-11T04:42:32.037Z","updated":"2025-08-11T04:42:32.037Z","path":"css/latex.css","layout":"false","_id":"clu1h98mu00008cug15tk978b","title":"","comments":1,"content":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"华文宋体\", \"宋体\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"Noto Serif SC\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"Noto Serif SC\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"Noto Serif SC\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"Noto Serif SC\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n.markdown-body {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n.markdown-body > h3.md-focus:before,\n.markdown-body > h4.md-focus:before,\n.markdown-body > h5.md-focus:before,\n.markdown-body > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n.markdown-body {\n  counter-reset: body-h2 0;\n}\n\n.post-title h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n\n.markdown-body h2 {\n  counter-reset: body-h3;\n}\n.markdown-body h3 {\n  counter-reset: body-h4;\n}\n.markdown-body h4 {\n  counter-reset: body-h5;\n}\n.markdown-body h5 {\n  counter-reset: body-h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: body-h2;\n  content: counter(body-h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.markdown-body:before {\n  counter-increment: body-h3;\n  content: counter(body-h2) \".\" counter(body-h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.markdown-body:before {\n  counter-increment: body-h4;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.markdown-body:before {\n  counter-increment: body-h5;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.markdown-body:before {\n  counter-increment: body-h6;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5) \".\" counter(body-h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n","site":{"data":{}},"excerpt":"","more":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"华文宋体\", \"宋体\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"Noto Serif SC\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"Noto Serif SC\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"Noto Serif SC\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"Noto Serif SC\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n.markdown-body {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n.markdown-body > h3.md-focus:before,\n.markdown-body > h4.md-focus:before,\n.markdown-body > h5.md-focus:before,\n.markdown-body > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n.markdown-body {\n  counter-reset: body-h2 0;\n}\n\n.post-title h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n\n.markdown-body h2 {\n  counter-reset: body-h3;\n}\n.markdown-body h3 {\n  counter-reset: body-h4;\n}\n.markdown-body h4 {\n  counter-reset: body-h5;\n}\n.markdown-body h5 {\n  counter-reset: body-h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: body-h2;\n  content: counter(body-h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.markdown-body:before {\n  counter-increment: body-h3;\n  content: counter(body-h2) \".\" counter(body-h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.markdown-body:before {\n  counter-increment: body-h4;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.markdown-body:before {\n  counter-increment: body-h5;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.markdown-body:before {\n  counter-increment: body-h6;\n  content: counter(body-h2) \".\" counter(body-h3) \".\" counter(body-h4) \".\" counter(body-h5) \".\" counter(body-h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n"},{"_content":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"宋体\", \"华文宋体\", \"Noto Serif CJK SC\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"华光小标宋_CNKI\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"华光小标宋_CNKI\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"华光小标宋_CNKI\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"华光小标宋_CNKI\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n#write {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  background-color: white;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n#write > h3.md-focus:before,\n#write > h4.md-focus:before,\n#write > h5.md-focus:before,\n#write > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n#write {\n  counter-reset: h2 0 h3 0 h4 0 h5 0 h6 0;\n}\n#write h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-header .post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n.markdown-body h1 {\n  counter-reset: h2;\n}\n.markdown-body h2 {\n  counter-reset: h3;\n}\n.markdown-body h3 {\n  counter-reset: h4;\n}\n.markdown-body h4 {\n  counter-reset: h5;\n}\n.markdown-body h5 {\n  counter-reset: h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: h2;\n  content: counter(h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.md-focus.md-heading:before {\n  counter-increment: h3;\n  content: counter(h2) \".\" counter(h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.md-focus.md-heading:before {\n  counter-increment: h4;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.md-focus.md-heading:before {\n  counter-increment: h5;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.md-focus.md-heading:before {\n  counter-increment: h6;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* 无序列表 */\nul {\n  list-style: disc;\n}\nul ul {\n  /*list-style: circle;*/\n  /* 请勿删除“–”后的空格, 他们对缩进有一定影响, 下同 */\n  list-style: \"–   \";\n}\nul ul ul {\n  list-style: \"◦  \";\n}\n\n/* 有序列表 */\nol {\n  list-style: decimal;\n}\nol ol {\n  counter-reset: liist;\n  list-style: none;\n}\nol ol li {\n  counter-increment: liist;\n  position: relative;\n}\nol ol li::before {\n  content: \"(\" counter(liist,lower-alpha) \")\";\n  position: absolute;\n  left: -1.8em;\n}\nol ol ol {\n  counter-reset: liiist;\n  list-style: none;\n  margin: 0;\n}\nol ol ol li {\n  counter-increment: liiist;\n  position: relative;\n}\nol ol ol li::before {\n  content: counter(liiist,lower-roman) \".\";\n  align-self: flex-end;\n  position: absolute;\n  left: -4.5em;\n  /* -moz-box-sizing: border-box;\n    -webkit-box-sizing: border-box;\n    box-sizing: border-box;*/\n  /* 为了让项目编号是重新用句点对齐而不是左对齐 */\n  width: 4em;\n  text-align: right;\n}\n\nli {\n  position: relative;\n}\n\nol, ul {\n  padding-inline-start: 2em;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n","source":"css/latex_backup.css","raw":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"宋体\", \"华文宋体\", \"Noto Serif CJK SC\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"华光小标宋_CNKI\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"华光小标宋_CNKI\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"华光小标宋_CNKI\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"华光小标宋_CNKI\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n#write {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  background-color: white;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n#write > h3.md-focus:before,\n#write > h4.md-focus:before,\n#write > h5.md-focus:before,\n#write > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n#write {\n  counter-reset: h2 0 h3 0 h4 0 h5 0 h6 0;\n}\n#write h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-header .post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n.markdown-body h1 {\n  counter-reset: h2;\n}\n.markdown-body h2 {\n  counter-reset: h3;\n}\n.markdown-body h3 {\n  counter-reset: h4;\n}\n.markdown-body h4 {\n  counter-reset: h5;\n}\n.markdown-body h5 {\n  counter-reset: h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: h2;\n  content: counter(h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.md-focus.md-heading:before {\n  counter-increment: h3;\n  content: counter(h2) \".\" counter(h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.md-focus.md-heading:before {\n  counter-increment: h4;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.md-focus.md-heading:before {\n  counter-increment: h5;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.md-focus.md-heading:before {\n  counter-increment: h6;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* 无序列表 */\nul {\n  list-style: disc;\n}\nul ul {\n  /*list-style: circle;*/\n  /* 请勿删除“–”后的空格, 他们对缩进有一定影响, 下同 */\n  list-style: \"–   \";\n}\nul ul ul {\n  list-style: \"◦  \";\n}\n\n/* 有序列表 */\nol {\n  list-style: decimal;\n}\nol ol {\n  counter-reset: liist;\n  list-style: none;\n}\nol ol li {\n  counter-increment: liist;\n  position: relative;\n}\nol ol li::before {\n  content: \"(\" counter(liist,lower-alpha) \")\";\n  position: absolute;\n  left: -1.8em;\n}\nol ol ol {\n  counter-reset: liiist;\n  list-style: none;\n  margin: 0;\n}\nol ol ol li {\n  counter-increment: liiist;\n  position: relative;\n}\nol ol ol li::before {\n  content: counter(liiist,lower-roman) \".\";\n  align-self: flex-end;\n  position: absolute;\n  left: -4.5em;\n  /* -moz-box-sizing: border-box;\n    -webkit-box-sizing: border-box;\n    box-sizing: border-box;*/\n  /* 为了让项目编号是重新用句点对齐而不是左对齐 */\n  width: 4em;\n  text-align: right;\n}\n\nli {\n  position: relative;\n}\n\nol, ul {\n  padding-inline-start: 2em;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n","date":"2025-08-11T04:24:12.503Z","updated":"2025-08-11T04:24:12.503Z","path":"css/latex_backup.css","layout":"false","_id":"clu1i8d670001qkug9b0n245c","title":"","comments":1,"content":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"宋体\", \"华文宋体\", \"Noto Serif CJK SC\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"华光小标宋_CNKI\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"华光小标宋_CNKI\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"华光小标宋_CNKI\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"华光小标宋_CNKI\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n#write {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  background-color: white;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n#write > h3.md-focus:before,\n#write > h4.md-focus:before,\n#write > h5.md-focus:before,\n#write > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n#write {\n  counter-reset: h2 0 h3 0 h4 0 h5 0 h6 0;\n}\n#write h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-header .post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n.markdown-body h1 {\n  counter-reset: h2;\n}\n.markdown-body h2 {\n  counter-reset: h3;\n}\n.markdown-body h3 {\n  counter-reset: h4;\n}\n.markdown-body h4 {\n  counter-reset: h5;\n}\n.markdown-body h5 {\n  counter-reset: h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: h2;\n  content: counter(h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.md-focus.md-heading:before {\n  counter-increment: h3;\n  content: counter(h2) \".\" counter(h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.md-focus.md-heading:before {\n  counter-increment: h4;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.md-focus.md-heading:before {\n  counter-increment: h5;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.md-focus.md-heading:before {\n  counter-increment: h6;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* 无序列表 */\nul {\n  list-style: disc;\n}\nul ul {\n  /*list-style: circle;*/\n  /* 请勿删除“–”后的空格, 他们对缩进有一定影响, 下同 */\n  list-style: \"–   \";\n}\nul ul ul {\n  list-style: \"◦  \";\n}\n\n/* 有序列表 */\nol {\n  list-style: decimal;\n}\nol ol {\n  counter-reset: liist;\n  list-style: none;\n}\nol ol li {\n  counter-increment: liist;\n  position: relative;\n}\nol ol li::before {\n  content: \"(\" counter(liist,lower-alpha) \")\";\n  position: absolute;\n  left: -1.8em;\n}\nol ol ol {\n  counter-reset: liiist;\n  list-style: none;\n  margin: 0;\n}\nol ol ol li {\n  counter-increment: liiist;\n  position: relative;\n}\nol ol ol li::before {\n  content: counter(liiist,lower-roman) \".\";\n  align-self: flex-end;\n  position: absolute;\n  left: -4.5em;\n  /* -moz-box-sizing: border-box;\n    -webkit-box-sizing: border-box;\n    box-sizing: border-box;*/\n  /* 为了让项目编号是重新用句点对齐而不是左对齐 */\n  width: 4em;\n  text-align: right;\n}\n\nli {\n  position: relative;\n}\n\nol, ul {\n  padding-inline-start: 2em;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n","site":{"data":{}},"excerpt":"","more":"@charset \"UTF-8\";\n:root {\n  /* == 字体设置 == */\n  /* 基准字体 */\n  /* 备选：Times, \"Times New Roman\" */\n  --base-Latin-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times;\n  --base-Chinese-font: \"宋体\", \"华文宋体\", \"Noto Serif CJK SC\", \"微软雅黑\";\n  --base-font-size: 13pt;\n  /* 引言字体 */\n  --quote-font: \"Latin Modern Roman\", \"Latin Modern Roman 10\", Times,\n    \"Times New Roman\", \"华文仿宋\";\n  /* em单位为一个正文字符（--base-font-size）大小，\n  例如，如果您设置 --base-font-size 为 9.5pt，那么 1.05em = 1.05*9.5pt ≈ 10pt。下面的标题字体等设置也遵循该规则。\n  这样，您就可以仅通过调整基准字体大小，而动态对其他元素大小做出调整。\n  当然，您也可以直接设置以pt或px为单位的数值，将元素的大小固定下来，如 --quote-font-size: 10pt; */\n  --quote-font-size: 1.05em;\n  /* 代码字体（代码中的中文会调用 ui-font） */\n  /* \"Courier New\" 从 Windows 3.1 起成为 Windows 官方提供的字体 */\n  /* \"Consolas\" 从 Windows Vista 起成为 Windows 官方提供的字体 */\n  --code-font: \"Latin Modern Mono\", \"Latin Modern Mono 10\", \"Consolas\", \"Courier New\";\n  /* 侧边栏字体 */\n  --ui-font: \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* source mode 字体 */\n  /* 默认调用 code-font 和 ui-font */\n  --sourceMode-font: \"SF Mono\", \"阿里巴巴普惠体 2.0\", \"微软雅黑\";\n  /* 目录字体 */\n  /* 默认调用 base-font */\n  --toc-font: \"\";\n  /* 默认调用 base-font-size */\n  --toc-font-size: \"\";\n  /* 公式字体 */\n  --math-font-size: 1em;\n  /* 表格字体 */\n  /* 默认调用 heading-font */\n  --table-title-font: \"\";\n  /* 默认调用 base-font */\n  --table-font: \"\";\n  /* 标题字体（总设置） */\n  --heading-Latin-font: var(--base-Latin-font);\n  --heading-Chinese-font: \"华光小标宋_CNKI\";\n  /* 标题字体分别设置 */\n  /* 大标题（h1）字体 */\n  --title-Chinese-font: \"华光小标宋_CNKI\";\n  --title-font-size: 1.9em;\n  /* h2字体 */\n  --h2-Chinese-font: \"华光小标宋_CNKI\";\n  --h2-font-size: 1.5em;\n  /* h3字体 */\n  --h3-Chinese-font: \"华光小标宋_CNKI\";\n  --h3-font-size: 1.25em;\n  /* h4字体 */\n  --h4-Chinese-font: \"华文楷体\";\n  --h4-font-size: 1.15em;\n  /* h5字体 */\n  --h5-Chinese-font: \"华文仿宋\";\n  --h5-font-size: 1.10em;\n  /* h6字体 */\n  --h6-Chinese-font: \"华文仿宋\";\n  --h6-font-size: 1.05em;\n  /* 粗体样式设置 */\n  /* 加粗风格时使用的字重；400等同于 normal，700等同于 bold，900等同于 heavy */\n  --strong-weight: 900;\n  /* 基础行距 */\n  --base-line-height: 1.618em;\n  /* == 页面设置 == */\n  /* 打印页边距 */\n  --set-margin: 1.8cm 2cm 1.2cm 2cm !important;\n  /* == 控制设置 == */\n  /* 目录中是否显示一级标题 */\n  --toc-show-title: none;\n  /* == 颜色设置 == */\n  /* 超链接颜色 */\n  --link-color-light: #2E67D3;\n  --link-color-dark: #8bb1f9;\n}\n\nbody {\n  padding: 0 !important;\n  margin: 0 !important;\n  /* counter-reset: tableHead 0 imgHead 0; */\n}\n\n\n\n@media print {\n  #write {\n    padding: 0 !important;\n  }\n\n  @page {\n    margin: 1.8cm 2cm 1.2cm 2cm !important;\n    /* 页边距 */\n  }\n}\n#write {\n  font-family: var(--base-Latin-font), var(--base-Chinese-font);\n  font-size: var(--base-font-size);\n  /* A4标准宽度 */\n  max-width: 21cm;\n  background-color: white;\n  /* column-count: 2;\n    column-gap: 25px;\n    column-width: 8cm; \n    display: inline-block; */\n  /* 这里可以试分栏的，但确实不适合实现 */\n}\n#write .md-math-block,\n#write .md-rawblock,\n#write p {\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#write p {\n  text-align: left;\n  line-height: var(--base-line-height);\n}\n#write a {\n  color: var(--link-color-light);\n}\n\nhr {\n  border-top: solid 1px #ddd;\n  margin-top: 1.8em;\n  margin-bottom: 1.8em;\n}\n\nimg {\n  /* 避免图片在导出时被断开 */\n  page-break-inside: avoid;\n}\n\nstrong {\n  font-weight: var(--strong-weight);\n}\n\n@media screen {\n  #write {\n    padding: var(--set-margin);\n    /* 添加一个淡蓝色的边框 */\n    /* border: 0.8px solid #AAC ; */\n    /* 页边阴影 */\n    box-shadow: 0 0 24px 12px #cccccc;\n  }\n}\n.MathJax {\n  font-size: var(--math-font-size);\n}\n\n/* typora 编写模式 */\n#typora-source {\n  font-family: var(--sourceMode-font), var(--code-font), var(--ui-font), monospace;\n  line-height: 2em;\n}\n\n/* 侧边大纲标题 */\n.sidebar-content .outline-h1 {\n  counter-reset: outline-h2;\n}\n.sidebar-content .outline-h2 {\n  counter-reset: outline-h3;\n}\n.sidebar-content .outline-h2 .outline-label:before {\n  counter-increment: outline-h2;\n  content: counter(outline-h2) \" \";\n}\n.sidebar-content .outline-h3 {\n  counter-reset: outline-h4;\n}\n.sidebar-content .outline-h3 .outline-label:before {\n  counter-increment: outline-h3;\n  content: counter(outline-h2) \".\" counter(outline-h3) \"  \";\n}\n.sidebar-content .outline-h4 {\n  counter-reset: outline-h5;\n}\n.sidebar-content .outline-h4 .outline-label:before {\n  counter-increment: outline-h4;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \"  \";\n}\n.sidebar-content .outline-h5 {\n  counter-reset: outline-h6;\n}\n.sidebar-content .outline-h5 .outline-label:before {\n  counter-increment: outline-h5;\n  content: counter(outline-h2) \".\" counter(outline-h3) \".\" counter(outline-h4) \".\" counter(outline-h5) \"  \";\n}\n\n.sidebar-content {\n  /* 侧边栏的字体修改 */\n  font-family: var(--ui-font);\n  list-style: none;\n}\n\n/* 元数据（如 YAML front matter）的背景框 */\npre.md-meta-block {\n  background: #cccccc;\n  padding: 1.4em;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  font-size: 0.8em;\n}\n\n#write > h3.md-focus:before,\n#write > h4.md-focus:before,\n#write > h5.md-focus:before,\n#write > h6.md-focus:before,\nh3.md-focus:before,\nh4.md-focus:before,\nh5.md-focus:before,\nh6.md-focus:before {\n  color: inherit;\n  border: inherit;\n  border-radius: inherit;\n  position: inherit;\n  left: initial;\n  float: none;\n  top: initial;\n  font-size: inherit;\n  padding-left: inherit;\n  padding-right: inherit;\n  vertical-align: inherit;\n  font-weight: inherit;\n  line-height: inherit;\n}\n\n#write {\n  counter-reset: h2 0 h3 0 h4 0 h5 0 h6 0;\n}\n#write h1,\n.markdown-body h2,\n.markdown-body h3,\n.markdown-body h4,\n.markdown-body h5,\n.markdown-body h6 {\n  font-weight: bold;\n  page-break-after: avoid !important;\n}\n.post-header .post-title h1 {\n  font-family: var(--heading-Latin-font), var(--title-Chinese-font), serif;\n  text-align: center;\n  column-span: all;\n  font-size: var(--title-font-size);\n}\n.markdown-body h2 {\n  font-family: var(--heading-Latin-font), var(--h2-Chinese-font), serif;\n  font-size: var(--h2-font-size);\n}\n.markdown-body h3 {\n  font-family: var(--heading-Latin-font), var(--h3-Chinese-font), serif;\n  font-size: var(--h3-font-size);\n  line-height: var(--h3-font-size);\n}\n.markdown-body h4 {\n  font-family: var(--heading-Latin-font), var(--h4-Chinese-font), serif;\n  font-size: var(--h4-font-size);\n  line-height: var(--h4-font-size);\n}\n.markdown-body h5 {\n  font-family: var(--heading-Latin-font), var(--h5-Chinese-font), serif;\n  font-size: var(--h5-font-size);\n  line-height: var(--h5-font-size);\n}\n.markdown-body h6 {\n  font-family: var(--heading-Latin-font), var(--h6-Chinese-font), serif;\n  font-size: var(--h6-font-size);\n  /* 没有写错，为了避免行距太小才这么写 */\n  line-height: var(--h5-font-size);\n}\n.markdown-body h1 {\n  counter-reset: h2;\n}\n.markdown-body h2 {\n  counter-reset: h3;\n}\n.markdown-body h3 {\n  counter-reset: h4;\n}\n.markdown-body h4 {\n  counter-reset: h5;\n}\n.markdown-body h5 {\n  counter-reset: h6;\n}\n\n.markdown-body h2:before {\n  counter-increment: h2;\n  content: counter(h2);\n  margin-right: 1.2em;\n}\n\n.markdown-body h3:before, h3.md-focus.md-heading:before {\n  counter-increment: h3;\n  content: counter(h2) \".\" counter(h3);\n  margin-right: 1.2em;\n}\n\n.markdown-body h4:before, h4.md-focus.md-heading:before {\n  counter-increment: h4;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4);\n  margin-right: 1.2em;\n}\n\n.markdown-body h5:before, h5.md-focus.md-heading:before {\n  counter-increment: h5;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5);\n  margin-right: 1.2em;\n}\n\n.markdown-body h6:before, h6.md-focus.md-heading:before {\n  counter-increment: h6;\n  content: counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6);\n  margin-right: 1.2em;\n}\n\n/* 参考文献（脚注）块 */\n.footnotes {\n  font-size: 0.95em;\n}\n\n.footnotes-area .footnote-line {\n  color: var(--text-color);\n}\n.footnotes-area hr {\n  border: 0;\n  color: #00000000;\n}\n\n/* 无序列表 */\nul {\n  list-style: disc;\n}\nul ul {\n  /*list-style: circle;*/\n  /* 请勿删除“–”后的空格, 他们对缩进有一定影响, 下同 */\n  list-style: \"–   \";\n}\nul ul ul {\n  list-style: \"◦  \";\n}\n\n/* 有序列表 */\nol {\n  list-style: decimal;\n}\nol ol {\n  counter-reset: liist;\n  list-style: none;\n}\nol ol li {\n  counter-increment: liist;\n  position: relative;\n}\nol ol li::before {\n  content: \"(\" counter(liist,lower-alpha) \")\";\n  position: absolute;\n  left: -1.8em;\n}\nol ol ol {\n  counter-reset: liiist;\n  list-style: none;\n  margin: 0;\n}\nol ol ol li {\n  counter-increment: liiist;\n  position: relative;\n}\nol ol ol li::before {\n  content: counter(liiist,lower-roman) \".\";\n  align-self: flex-end;\n  position: absolute;\n  left: -4.5em;\n  /* -moz-box-sizing: border-box;\n    -webkit-box-sizing: border-box;\n    box-sizing: border-box;*/\n  /* 为了让项目编号是重新用句点对齐而不是左对齐 */\n  width: 4em;\n  text-align: right;\n}\n\nli {\n  position: relative;\n}\n\nol, ul {\n  padding-inline-start: 2em;\n}\n\n/* task列表 */\n.md-task-list-item > input {\n  margin-top: 0.42em;\n  margin-left: -1.5em;\n  width: 1em !important;\n  height: 1em !important;\n}\n\n#write table {\n  /* 三线表第一条线宽度 */\n  border-top: 1.2pt solid;\n  /* 三线表第二条线宽度 */\n  border-bottom: 1.2pt solid;\n  font-family: var(--table-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n  /* font-size: var(--base-font-size); */\n  text-align: center;\n  page-break-inside: avoid;\n  border-spacing: 6px;\n  /* 自动布局表格宽度，如果有时内容太紧建议直接加空格吧，我自己看不惯和页面等宽的大表格 */\n  width: auto;\n  /* 使表格默认居中；虽然这个代码不好，但好像没别的实现办法 */\n  margin: 0 auto;\n}\n#write table td {\n  padding: 2px;\n}\n#write table tr {\n  padding: 2px;\n}\n#write th {\n  padding: 0px 6px;\n}\n#write thead {\n  /* 表格标题（首行）样式 */\n  /* 三线表表头的线 */\n  border-bottom: 0.5pt solid;\n  font-family: var(--table-title-font), var(--heading-Latin-font), var(--heading-Chinese-font), serif !important;\n  font-size: var(--base-font-size);\n  font-weight: var(--strong-weight);\n}\n\n/* 一个>的引言仅为两字符缩进，使用>>的引言为传统引言样式，具有左竖线、左缩进 */\nblockquote {\n  font-style: normal;\n  font-family: var(--quote-font), var(--base-Latin-font), var(--base-Chinese-font), -apple-system, serif;\n  font-size: var(--quote-font-size);\n  /* 文字离左边框的距离 */\n  padding-left: 2em;\n  padding-right: 2em;\n  /* 左边框离页面边的距离 */\n  margin-left: 0;\n}\n\nblockquote p:first-child {\n  padding-top: 1ch;\n}\n\nblockquote p:last-child {\n  padding-bottom: 1ch;\n}\n\nblockquote blockquote {\n  border-left: 4px solid #b3b3b3;\n  padding-left: calc(2ch - 4px);\n  padding-right: 0;\n  margin-left: -4px;\n  border-radius: 0;\n}\n\n/* 行内代码 */\ncode {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\nh1 code, h2 code, h3 code, h4 code, h5 code, h6 code,\np code,\nli code {\n  color: #3c70c6;\n  background-color: #fefefe;\n  /* 阴影 */\n  box-shadow: 0 0 1px 1px #c8d3df;\n  font-family: var(--code-font), var(--ui-font), monospace;\n  box-sizing: border-box;\n  border-right: 0px;\n  margin: 0 2px 0 2px;\n  padding: 0 2px 0 2px;\n  /* 圆角 */\n  border-radius: 2px 2px 2px 2px;\n}\n\n/* 代码块样式 */\n.md-fences,\n.CodeMirror pre {\n  font-size: 1em;\n}\n\n.CodeMirror-wrap {\n  /* padding: 10px; */\n  font-size: 1em;\n}\n\n.CodeMirror-code pre {\n  font-family: var(--code-font), var(--ui-font), monospace;\n}\n\n/* 目录 */\n.md-toc {\n  font-size: var(--toc-font-size);\n}\n\n.md-toc-content {\n  margin-left: 2em;\n  /* 修复缺失上级标题时无法递增 */\n  counter-reset: toc-h2 toc-h3 toc-h4;\n  page-break-after: always;\n}\n\n.md-toc-inner {\n  margin-left: 0 !important;\n  color: var(--text-color) !important;\n}\n\n.md-toc-item {\n  color: var(--text-color) !important;\n}\n\n/* 目录标题内容属性 */\n.md-toc-h2,\n.md-toc-h3,\n.md-toc-h4,\n.md-toc-h5,\n.md-toc-h6 {\n  font-size: var(--toc-font-size);\n  font-family: var(--toc-font), var(--base-Latin-font), var(--base-Chinese-font), serif;\n}\n\n.md-toc-h2 {\n  font-weight: var(--strong-weight);\n}\n\n/* 目录标题前 */\n.md-toc-content .md-toc-h1 {\n  display: var(--toc-show-title);\n  counter-reset: toc-h2;\n}\n.md-toc-content .md-toc-h2 {\n  counter-reset: toc-h3;\n}\n.md-toc-content .md-toc-h3 {\n  counter-reset: toc-h4;\n}\n.md-toc-content .md-toc-h4 {\n  counter-reset: toc-h5;\n}\n.md-toc-content .md-toc-h5 {\n  counter-reset: toc-h6;\n}\n.md-toc-content .md-toc-h2:before {\n  counter-increment: toc-h2;\n  content: counter(toc-h2);\n  margin-right: 1em;\n  font-weight: var(--strong-weight);\n}\n.md-toc-content .md-toc-h3:before {\n  counter-increment: toc-h3;\n  content: counter(toc-h2) \".\" counter(toc-h3);\n  margin-left: 1.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h4:before {\n  counter-increment: toc-h4;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4);\n  margin-left: 3.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h5:before {\n  counter-increment: toc-h5;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5);\n  margin-left: 5.5em;\n  margin-right: 0.5em;\n}\n.md-toc-content .md-toc-h6:before {\n  counter-increment: toc-h6;\n  content: counter(toc-h2) \".\" counter(toc-h3) \".\" counter(toc-h4) \".\" counter(toc-h5) \".\" counter(toc-h6);\n  margin-left: 7.5em;\n  margin-right: 0.5em;\n}\n"},{"_content":"@font-face {\n    font-family: \"宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SIMSUN.TTC\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STSONG.TTF\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文楷体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文仿宋\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STFANGSO.TTF\");\n}\n\n@font-face {\n    font-family: \"SmileySans\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SmileySans-Oblique.otf\");\n}\n\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-REGULAR.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-BOLD.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-ITALIC.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-BOLDITALIC.OTF\");\n}","source":"css/fonts.css","raw":"@font-face {\n    font-family: \"宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SIMSUN.TTC\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STSONG.TTF\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文楷体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文仿宋\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STFANGSO.TTF\");\n}\n\n@font-face {\n    font-family: \"SmileySans\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SmileySans-Oblique.otf\");\n}\n\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-REGULAR.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-BOLD.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-ITALIC.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-BOLDITALIC.OTF\");\n}","date":"2025-08-11T04:43:20.240Z","updated":"2025-08-11T04:43:20.240Z","path":"css/fonts.css","layout":"false","_id":"clu1yqg0g0000ncuggf5ifrl1","title":"","comments":1,"content":"@font-face {\n    font-family: \"宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SIMSUN.TTC\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STSONG.TTF\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文楷体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文仿宋\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STFANGSO.TTF\");\n}\n\n@font-face {\n    font-family: \"SmileySans\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SmileySans-Oblique.otf\");\n}\n\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-REGULAR.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-BOLD.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-ITALIC.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-BOLDITALIC.OTF\");\n}","site":{"data":{}},"excerpt":"","more":"@font-face {\n    font-family: \"宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SIMSUN.TTC\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STSONG.TTF\");\n}\n\n@font-face {\n    font-family: \"华文宋体\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文楷体\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STKAITI.TTF\");\n}\n\n@font-face {\n    font-family: \"华文仿宋\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/STFANGSO.TTF\");\n}\n\n@font-face {\n    font-family: \"SmileySans\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/SmileySans-Oblique.otf\");\n}\n\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-REGULAR.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: normal;\n    src: url(\"/fonts/LMROMAN10-BOLD.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: normal;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-ITALIC.OTF\");\n}\n\n@font-face {\n    font-family: \"Latin Modern Roman 10\";\n    font-weight: bold;\n    font-style: italic;\n    src: url(\"/fonts/LMROMAN10-BOLDITALIC.OTF\");\n}"}],"Post":[{"title":"Introduction to Artificial Intelligence","katex":true,"date":"2024-02-26T07:20:37.000Z","_content":"## Learning\n\n### Linear Classification\n\n#### Logistic Regression\n\nUseful for classification problems.\n\nCross-Entropy Loss\n\n$$\n\\ell(h(\\boldsymbol{x}_{i}),y_{i})=\\begin{cases}-\\log[\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=1\\\\-\\log[1-\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=0\\end{cases}\n$$\n\nWith regularization:\n\n$$\n\\hat{\\epsilon}(w)=-\\sum_{i=1}^n\\{y_i\\log\\sigma(h_w(x))+(1-y_i)\\log[1-\\sigma(h_w(x))]+\\lambda\\sum_{j=1}^dw_j^2\n$$\n\nHow to deal with multiclass problems?\n\n#### Softmax Regression\n\nNormalizes multiple outputs in a probability vector.\n\n$$\np(y=i|x)=\\frac{\\exp(w_i^Tx)}{\\sum_{r=1}^C\\exp(w_r^Tx)}\n$$\n\nCross-Entropy Loss\n\n$$\n\\ell(h(x_i),y_i)=\\begin{cases}-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_1^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=1\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_2^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=2\\\\\\vdots\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_c^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=C\\end{cases}\n$$\n\nThis loss is convex. But there are many solutions that result in same outputs, so the regularizaton is indispensible to prevent divergence.\n\n![1713166706648](../images/AI/1713166706648.png)\n\n### Support Vector Machine (SVM)\n\n#### Soft-SVM (Hinge Loss)\n\n$$\n\\min_{w,b,\\xi}\\frac{1}{2}\\|w\\|_{2}^{2}+\\frac{C}{n}\\sum_{i=1}^{n}\\xi_{i}\\\\\\mathrm{s.t.~}y_i(\\boldsymbol{w}\\cdot\\boldsymbol{x}_i+b)\\geq1-\\xi_i\\\\\\xi_i\\geq0,1\\leq i\\leq n\n$$\n\nDefine Hinge Loss\n\n$$\n\\ell(f(x),y)=\\max\\{0,1-yf(x)\\}\n$$\n\nFor the linear hypothesis:\n\n$$\n\\ell(f(x),y)=\\max\\{0,1-y(w\\cdot x+b)\\}\n$$\n\nTheorem: Soft-SVM is equivalent to a Regularized Rise Minimization:\n\n$$\n\\min_{w,b}\\frac12\\|w\\|_2^2+\\frac Cn\\sum_{i=1}^n\\max\\{0,1-y_i(w\\cdot x_i+b)\\}\n$$\n\n这意味着SVM的“最大化”边界距离项本质上是一个正则化项。\n\n### Kernel Soft-SVM\n\nBasis function $\\Phi(x)$ can often replaced by kernal function $k(x_1, x_2)$.\n\nPolynomial Kernel: efficient computation: $O(d)$\n\n![1713169419702](../images/AI/1713169419702.png)\n\nConstruct new kernel function from exist kernel functions:\n\n$$\nk^{\\prime}(x_{1},x_{2})=k_{1}\\otimes k_{2}(x_{1},x_{2})=k_{1}\n(x_{1},x_{2})k_{2}(x_{1},x_{2})\n$$\n\nFor any function $g: \\mathcal X \\rightarrow \\R$\n\n$$\nk^\\prime(x_1,x_2)=g(x_1)k_1(x_1,x_2)g(x_2)\n$$\n\nApply Representer theorem:\n\n$$\n\\min_\\alpha\\frac12\\alpha^TK\\alpha+\\frac Cn\\sum_{i=1}^n\\max\\left\\{0,1-y_i\\sum_{j=1}^n\\alpha_jk(x_i,x_j)\\right\\}\n$$\n\n- $\\alpha_j$ is the weight of each reference point $\\color{red}{x_j}$ to the prediction of $\\color{red}{x_i}$.\n- lt is actually a Primal Form with kernel functions.\n\n### Decision Tree\n\nCriterion:\n\n* More balance\n* More pure\n\nMisclassification error (not used very frequently):\n\n$$\n\\mathrm{Err}(\\mathcal{D})=1-\\max_{1\\leq k\\leq K}\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)\n$$\n\nUse Entropy to measure purity:\n\n$$\nH(\\mathcal{D})=-\\sum_{k=1}^K\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\mathrm{log}\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\n$$\n\nGini Index:\n\n$$\n\\mathrm{Gini}(\\mathcal{D})=1-\\sum_{k=1}^K\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)^2\n$$\n\n#### ID3 Algorithm\n\n![1713171808270](../images/AI/1713171808270.png)\n\n### Multiplayer Perceptrons (MLP)\n\n#### MLP for XOR\n\n![1713771652191](../images/AI/1713771652191.png)\n\n#### Activation\n\n![1713772489046](../images/AI/1713772489046.png)\n\n#### Loss Functions\n\nEntropy\n\n$$\nH(q)=-\\sum_{j=1}^kq_j\\log q_j\n$$\n\nRelative-entropy\n\n$$\n\\mathrm{KL}(q||p)=-\\sum_{j=1}^kq_j\\log p_j-H(q)\n$$\n\nCross-entropy\n\n$$\nH(q,p)=-\\sum_{j=1}^kq_j\\log p_j\n$$\n\nRelationship:\n\n$$\n\\boxed{H(q,p)=\\mathrm{KL}(q||p)+H(q)}\n$$\n\nSoftmax in the output layer\n\n$$\n\\widehat{\\boldsymbol{y}}=\\boldsymbol{a}^{(n_l)}=f_\\theta\\big(\\boldsymbol{x}^{(i)}\\big)=\\begin{bmatrix}p\\big(\\boldsymbol{y}^{(i)}=1\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\p\\big(\\boldsymbol{y}^{(i)}=2\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\\\vdots\\\\p\\big(\\boldsymbol{y}^{(i)}=k\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\end{bmatrix}=\\frac{1}{\\sum_{j=1}^{k}\\exp(z_{j}^{(n_{l})})}\\begin{bmatrix}\\exp(z_{1}^{(n_{l})})\\\\\\exp(z_{2}^{(n_{l})})\\\\\\vdots\\\\\\exp(z_{k}^{(n_{l})})\\end{bmatrix}\n$$\n\nCross-entropy loss:\n\n$$\nJ(y,\\widehat{y})=-\\sum_{j=1}^ky_j\\log\\widehat{y}_j\n$$\n\nCost function:\n\n$$\n\\min J(\\theta)=-\\frac1m\\sum_{i=1}^m\\left[\\sum_{j=1}^k\\mathbf{1}\\{y^{(i)}=j\\}\\mathrm{log}\\frac{\\exp(\\mathbf{z}_j^{(n_\\iota)})}{\\sum_{j^{\\prime}=1}^k\\exp(\\mathbf{z}_{j^{\\prime}}^{(n_\\iota)})}\\right]\n$$\n\n#### Gradient-Based Training\n\n$$\n\\arg\\min_\\theta O(\\mathcal{D};\\theta)=\\sum_{i=1}^mL\\left(y_i,f(x_i);\\theta\\right)+\\Omega(\\theta)\n$$\n\nForward Propagation: to compute activations & objective $J(\\theta)$\n\nBackward Propagation: Update paramters in all layers\n\n##### Learning Rate decay\n\nExponential decay strategy:\n\n$$\n\\eta = \\eta_0e^{kt}\n$$\n\n1/t decay strategy:\n\n$$\n\\eta = \\eta_0/(1+kt)\n$$\n\n##### Weight Decay\n\nL2 regularization:\n\n$$\n\\Omega(\\theta)=\\frac\\lambda2\\sum_{l=1}^{n_l-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\theta_{ji}^{(l)})^2\\\\\\frac\\partial{\\partial\\theta^{(l)}}\\Omega(\\theta)=\\lambda\\theta^{(l)}\n$$\n\nL1:\n\n$$\n\\Omega(\\theta)=\\lambda\\sum_{l=1}^{n_{l}-1}\\sum_{i=1}^{s_{l}}\\sum_{j=1}^{s_{l+1}}|\\theta_{ji}^{(l)}|\\\\\\frac{\\partial}{\\partial\\theta^{(l)}}\\Omega(\\theta)_{ji}=\\lambda(1_{\\theta_{ji}^{(l)}>0}-1_{\\theta_{ji}^{(l)}<0})\n$$\n\n一般不调。\n\n##### Weight Initialization\n\nXavier initialization\n\n(Linear activations)\n\n$$\n\\mathrm{Var}(w)=1/n_{\\mathrm{in}}\n$$\n\n避免梯度爆炸或者消失；\n\nHe initialization\n\n(ReLU activations)\n\n$$\n\\mathrm{Var}(w)=2/n_{\\mathrm{in}}\n$$\n\n因为 ReLU 删除了一半的信息。\n\n![1713775669844](../images/AI/1713775669844.png)\n\n### Convolutional Neural Network (CNN)\n\n![1713776156049](../images/AI/1713776156049.png)\n\n![1713776168789](../images/AI/1713776168789.png)\n\n![1714379943169](../images/AI/1714379943169.png)\n\n#### Convoluion Kernel\n\n![1714380111476](../images/AI/1714380111476.png)\n\nStride\n\n![1714380132725](../images/AI/1714380132725.png)\n\nPadding\n\n![1714380159356](../images/AI/1714380159356.png)\n\n![1714380233071](../images/AI/1714380233071.png)\n\n#### Pooling\n\n![1714380343254](../images/AI/1714380343254.png)\n\nBatch Normalization\n\n![1714379335929](../images/AI/1714379335929.png)\n\n在 N 张图像的对应通道做归一化。\n\n可以增强训练的稳定性，使得学习率可以设大一点而仍然保证收敛。\n\n\n* 数据集成\n* 参数集成\n* 模型集成\n\n#### ResNet\n\n![1714380578105](../images/AI/1714380578105.png)\n\n![1714380763838](../images/AI/1714380763838.png)\n\n最后一层 Global Average Pooling：7\\*7\\*2048 -> 1\\* 1 \\* 2048\n\n### Recurrent Neural Network (RNN)\n\n#### Idea for Sequence Modeling\n\nLocal Dependency\n\n![1714982108981](../images/AI/1714982108981.png)\n\nParameter Sharing\n\n![1714982133935](../images/AI/1714982133935.png)\n\n### RNN\n\n![1714982188331](../images/AI/1714982188331.png)\n\nGo deeper\n\n![1714982215920](../images/AI/1714982215920.png)\n\n#### Standard Architectures\n\n![1714982075164](../images/AI/1714982075164.png)\n\n- RNNs can represent unbounded temporal dependencies\n- RNNs encode histories of words into a fixed size hidden vector \n- Parameter size does not grow with the length of dependencies\n- RNNs are hard to learn long range dependencies present in data\n\n#### LSTM\n\nMultihead, shared bottom.\n\n![1714982405665](../images/AI/1714982405665.png)\n\nGradient flow highway: remember history very well.\n\nNIPS 2015 Highway Network.\n\n#### Training Strategies\n\nShift in Training & Inference\n\n![1714983390325](../images/AI/1714983390325.png)\n\nUse Scheduled Sampling to solve this\n\n![1714983452419](../images/AI/1714983452419.png)\n\nProblem: Gradient Explosion during continuously multiplication.\n\nSolution: Gradient Clipping\n\n![1714983641507](../images/AI/1714983641507.png)\n\nVariational Dropout\n\n![1714983788461](../images/AI/1714983788461.png)\n\nLayer Normalization\n\n![1714983988587](../images/AI/1714983988587.png)\n\nBN: Easy to compare between channels\n\nLN: Easy to compare between samples\n\n在图像任务上，我们一般认为 channel 之间的地位应该是相同的，因此常常采用 BN。\n\n### Transformer\n\nuse attention to replace state space.\n\n![1714984460020](../images/AI/1714984460020.png)\n\n#### Attention\n\n![1714984778231](../images/AI/1714984778231.png)\n\n$$\n\\text{Attention}(Q,K,V)=\\text{Softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n$$\n\nMulti-Head Attention\n\n![1714985419724](../images/AI/1714985419724.png)\n\nSparse?\n\n$W^o$ to maintain shape and jointly attend to information from different representation subspaces.\n\n#### FFN\n\nPosition-wise FFN (Similar to multi convolution kernels in CNN, shared parameters in every word.)\n\n![1714985971187](../images/AI/1714985971187.png)\n\n#### Positional Encoding\n\n![1714986050538](../images/AI/1714986050538.png)\n\n## Reasoning\n\nReasoning (Probabilistic) = Modeling + Inference\n\nModeling:\n* Bayesian Networks\n* Markov random fields\n\nInference:\n* Elimination methods (变量消除法)\n* Latent variable models (因变量模型)\n* Variational methods (变分方法)\n* Sampling methods (采样方法) - 难学！\n\n### Bayesian Network\n\n$$\np(x_1,...,x_K)=p(x_K|x_1,...,x_{K-1})\\cdots p(x_2|x_1)p(x_1)\n$$\n\n#### Variable Elimination\n\n用于计算概率的边缘分布\n\n![1716191759894](../images/AI/1716191759894.png)\n\n一般而言是 NP-hard 问题。\n\n对于 Markov chain，复杂度为 $O(nk^2)$；对于一般的图，$O(k^{n-1})$；如果确定每个节点的父节点数不超过 m，则复杂度为 $O(nk^{m-1})$\n\n#### Message Passing\n\nReuse the computation from $P(Y|E=e)$ when calcuating another probability $P(Y_1|E_1=e_1)$\n\n![1716192135361](../images/AI/1716192135361.png)\n\n![1716192175996](../images/AI/1716192175996.png)\n\n“$\\propto$” 意味着只需要知道概率的相对值就够了，因为可以通过归一化算出最终的概率值。\n\nMAP 需要求概率分布的最大值。\n\nsum 与 max 同为聚合操作，因此同样满足分配律，只需要对应替换就可以得到第二种 Message Passing：\n\n![1716192534058](../images/AI/1716192534058.png)\n\n\n![1716192519850](../images/AI/1716192519850.png)\n\n![1716193180893](../images/AI/1716193180893.png)\n\n### Bayes Approach\n\n![1716193473766](../images/AI/1716193473766.png)\n\n### MLE method\n\n如果概率模型的参数知道，称为概率；不知道，称为统计推断。\n\n估计高斯分布的参数：\n\n方差是有偏估计，所以一般× $1/(n-1)$。\n\n![1716194228666](../images/AI/1716194228666.png)\n\n### Bayes Decision Rule\n\n![1716194320872](../images/AI/1716194320872.png)\n\n对于回归问题，可以采用高斯噪声假设：\n\n![1716194583833](../images/AI/1716194583833.png)\n\n这样就得到了最小二乘估计。\n\nMLE 是先验概率相等的 MAP。\n\n放在机器学习中，MAP 可以定义为：模型 = 数据 + 先验。\n\n![1716194633162](../images/AI/1716194633162.png)\n\n先验信息在机器学习中体现为正则化：\n\n2 范数正则化就是在认为模型参数服从高斯分布的先验假设情况下，利用 MAP 准则来估计参数。\n\n这也就是为什么正则化倾向于避免过拟合：高斯分布先验希望模型参数足够简单。\n\n![1716194757145](../images/AI/1716194757145.png)\n\n### Bayesian Model Averaging\n\n![1716195002371](../images/AI/1716195002371.png)\n\n意义：模型集成。\n\n### Discriminative Models\n\n上面的理论足够解释判别式模型的原理了。\n\n### Generative Models\n\n![1716195398036](../images/AI/1716195398036.png)\n\n![1716195442145](../images/AI/1716195442145.png)\n\n#### Naive Bayes Classifier\n\nmodel $Y$ as a bernoulli distribution with parameters $p(y=1)$ and $p(y=-1)$\n\nconditional independence: each dimension is independent given label y\n\n$$\np(X=x|Y=y)=\\prod_{j=1}^dp(x_{\\cdot j}|y)\n$$\n\nLaplacian smoothing for 0 samples:\n\n$$\np(x_{\\cdot j}=r_j|Y=+1)=\\frac{\\sum_{i=1}^n1\\{x_{\\cdot j}=r_j\\wedge y_i=+1\\}+1}{\\sum_{i=1}^n1\\{y_i=+1\\}+k_j}\n$$\n\nFor dataset with all continuous features: descretize it, or use another model based on a different assumption.\n\n\n#### Guassian Discriminant Analysis\n\n是一个生成模型！虽然它被用来分类，但是它的建模设计上采用的是生成式。\n\nFor dataset with all continuous features:\n\nUsing parametrice distribution to represent $P(X=x|Y=y)$\n\nA common assumption in classification:\n\n- We always assume that data points in a class is a cluster.\n\nStill model $p(Y=y)$ as Bernoulli distribution.\n\n$$\n\\text{So we can model }p(X=x|Y=y)\\text{ by Gaussian distribution:}\\\\p(X=x|Y=+1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{+})^{T}\\Sigma^{-1}(x-\\mu_{+})\\right)\\\\p(X=x|Y=-1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{-})^{T}\\Sigma^{-1}(x-\\mu_{-})\\right)\n$$\n\nNote the shared parameters $\\Sigma$ for positive and nagative classes.\n\nUse MLE to find the best solution:\n\n$$\n\\ell(\\phi,\\mu_+,\\mu_-,\\Sigma)=\\log\\prod_{i=1}^np(x_i,y_i;\\phi,\\mu_+,\\mu_-,\\Sigma)\\\\=\\log\\prod_{i=1}^np(x_i|y_i;\\mu_+,\\mu_-,\\Sigma)+\\boxed{\\log\\prod_{i=1}^np(y_i|\\phi)}\n$$\n\nThen:\n\n$$\n\\phi=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}}{n},\\mu_{+}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}},\\mu_{-}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}}\\\\\\boldsymbol{\\Sigma}=\\frac{1}{n}\\boldsymbol{\\Sigma}_{i=1}^{n}(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})^{T}\n$$\n\n#### Discriminative vs. Generative\n\n![1716795753326](../images/AI/1716795753326.png)\n\n### Mixture Models and EM\n\n#### Gaussian Mixture Model\n\nA Generative model. More assumption than Logistic Regression.\n\n![1716796053911](../images/AI/1716796053911.png)\n\nSample dataset from GMM:\n\n$$\np(x)=\\sum_{z=1}^k\\pi_z\\mathcal{N}(x|\\mu_z,\\Sigma_z)\n$$\n\nCompute log-likelihood:\n\n$$\n\\ell(\\boldsymbol{\\pi},\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})=\\log\\prod_{i=1}^n\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)\\right]\n$$\n\n$$\n\\ell(\\pi,\\mu,\\Sigma)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\frac{\\pi_z}{\\sqrt{|2\\pi\\Sigma_z|}}\\exp(-\\frac12(x_i-\\mu_z)^T\\Sigma^{-1}(x_i-\\mu_z))\\right]\n$$\n\nIntracable! Use EM method to estimate parameters.\n\n$z$ is latent variable.\n\n#### Expectation Maximization\n\n![1716797001550](../images/AI/1716797001550.png)\n\nLearing Problem:\n\nfind MLE\n\n$$\n\\widehat{\\theta}=\\underset{\\theta}{\\operatorname*{argmax\\ }}p(\\mathcal{D}|\\theta)\n$$\n\nInference Promblem:\n\nGiven $x$, find conditional variable of $z$:\n\n$$\np(z|x,\\theta)\n$$\n\nEM method is for both problems!\n\nit is hard to maximize the marginal likelihood directly:\n\n$$\n\\max_\\theta\\log p(x|\\theta)\n$$\n\nbut the complete data log-likelihood is easy typically:\n\n$$\n\\max_\\theta\\log p(x, z|\\theta)\n$$\n\nif we had a distribution $q(z)$ for z:\n\n$$\n\\max_\\theta\\sum_zq(z)\\log p(x,z|\\theta)\n$$\n\nWe have Evidence Lower Bound (ELBO):\n\n$$\n\\log p(x|\\theta)=\\log\\left[\\sum_zp(x,z|\\theta)\\right] \\ge \\underbrace{\\sum_zq(z)\\log(\\frac{p(x,z|\\theta)}{q(z)})}_{\\mathcal{L}(q,\\theta)}\n$$\n\nNow we optimize the ELBO iteratively:\n\n![1716797936119](../images/AI/1716797936119.png)\n\nThe math background for ELBO:\n\n![1716798247574](../images/AI/1716798247574.png)\n\nWe get back an equality for the marginal likelihood:\n\n$$\n\\log p(x|\\theta)=\\mathcal{L}(q,\\theta)+\\mathrm{KL}[q(z)||p(z|x,\\theta)]\n$$\n\nEvidence = ELBO + KL-Divergence\n\nIn E-step, if we want to maximize the ELBO without changing $\\theta$, we have to let KL be zero. Thus $q^*(z)=p(z|x,\\theta)$\n\nFor M-step, we find the $\\theta$ to maximize the ELBO.\n\n![1716798687551](../images/AI/1716798687551.png)\n\nIn MAP case:\n\n![1716798850106](../images/AI/1716798850106.png)\n\nFor GMM, E-step:\n\n![1716798927981](../images/AI/1716798927981.png)\n\nM-step:\n\n![1716799063581](../images/AI/1716799063581.png)\n\nRecommended Initialize:\n\n$$\n\\pi = 1/k\\\\\n\\mu = 0\\\\\n\\Sigma = \\sigma^2 I\n$$\n\nVariational Methods:\n\n![1716799707301](../images/AI/1716799707301.png)\n\n注意：E 步计算的是隐变量的后验（如果能计算出来），因为它是使得似然函数及ELBO最大的 $q(z)$。算不出来就用变分方法近似。\n\n$q(z)$ 既不是先验分布，也不是后验分布，它只是我们对隐变量分布的一种估计。\n\n### Probabilistic Topic Models\n\n#### Dirichlet-Multinomial Model\n\n![1717400667281](../images/AI/1717400667281.png)\n\nBeta Distribution:\n\n$$\nf(\\phi|\\alpha,\\beta)=\\frac1{B(\\alpha,\\beta)}\\phi^{\\alpha-1}(1-\\phi)^{\\beta-1}\n$$\n\nDirichlet Multinomial Model: Multi-dimensional version of Beta Distribution\n\n$$\n\\boxed{p(\\vec{\\theta}|\\boldsymbol{\\alpha})}=\\frac1{B(\\boldsymbol{\\alpha})}\\prod_{k=1}^K\\theta_k^{\\alpha_k-1}\\quad\\text{Where }B(\\alpha)=\\frac{\\Pi_{k=1}^K\\Gamma(\\alpha_k)}{\\Gamma(\\sum_{k=1}^K\\alpha_k)}\n$$\n\nConjugate prior:\n\n$$\n\\sum_{i=1}^K\\theta_i=1\n$$\n\n![1717400854837](../images/AI/1717400854837.png)\n\nAdmixture:\n\n![1717401031002](../images/AI/1717401031002.png)\n\nLatent Dirichlet Allocation (LDA):\n\n![1717401124879](../images/AI/1717401124879.png)\n\nProbabilistic Graphical Models:\n\n![1717401517265](../images/AI/1717401517265.png)\n\n![1717401591545](../images/AI/1717401591545.png)\n\nMaximum Likelihood Estimation\n\n$$\n\\log p(\\beta,\\theta,z,w|\\alpha,\\eta)\\\\\n=\\sum_{k=1}^K\\log p(\\vec{\\beta}_k|\\eta)+\\sum_{d=1}^D\\log p(\\vec{\\theta}_d|\\alpha)+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(z_{d,n}|\\vec{\\theta}_d)\\\\\n +\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(w_{d,n}|z_{d,n},\\vec{\\boldsymbol{\\beta}}_{1:K})\\\\\n \\begin{aligned}\n&=\\sum_{k=1}^{K}\\left(\\sum_{v=1}^{V}(\\eta_{v}-1)\\log\\beta_{kv}-\\log B(\\eta)\\right)+\\sum_{d=1}^{D}\\sum_{k=1}^{K}(\\alpha_{k}-1)\\log\\theta_{dk}-\\log B(\\alpha) \\\\\n&+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\theta_{d,z_{d,n}}+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\beta_{z_{d,n}w_{d,n}}\n\\end{aligned}\n$$\n\nTo learn the param $\\alpha, \\eta$, use EM method:\n\nIn E-step, calculate \n\n$$\nq^*(z)=p(z|x,\\theta^{\\mathrm{old}})\n$$\n\n$$\np(\\theta,z,\\beta\\mid w,\\alpha,\\eta)=\\frac{p(\\theta,z,\\beta,w\\mid\\alpha,\\eta)}{p(w\\mid\\alpha,\\eta)}\n$$\n\nHowever, the denominator is intractable:\n\n$$\np(\\mathbf{w}|\\alpha,\\eta)=\\int\\int\\sum_\\mathbf{z}p(\\boldsymbol{\\theta},\\mathbf{z},\\boldsymbol{\\beta},\\mathbf{w}|\\boldsymbol{\\alpha},\\boldsymbol{\\eta})d\\boldsymbol{\\theta}d\\boldsymbol{\\beta}\n$$\n\nThis problem is for general Bayesian models. We can use Variational Methods or Markov Chain Monte Carlo to solve it.\n\n#### Variational Methods\n\n![1717403664862](../images/AI/1717403664862.png)\n\n![1717403702542](../images/AI/1717403702542.png)\n\n![1717403725888](../images/AI/1717403725888.png)\n\n![1717404024479](../images/AI/1717404024479.png)\n\nUse Mean field assumption in LDA:\n\n![1717404907709](../images/AI/1717404907709.png)\n\n![1717404790783](../images/AI/1717404790783.png)\n\n### Variational Autoencoders (VAE)\n\n![1717405465141](../images/AI/1717405465141.png)\n\nReparameterization Trick: \n\n![1717405435705](../images/AI/1717405435705.png)\n\n","source":"_posts/AI.md","raw":"---\ntitle: Introduction to Artificial Intelligence\nkatex: true\ndate: 2024-02-26 15:20:37\ntags:\n---\n## Learning\n\n### Linear Classification\n\n#### Logistic Regression\n\nUseful for classification problems.\n\nCross-Entropy Loss\n\n$$\n\\ell(h(\\boldsymbol{x}_{i}),y_{i})=\\begin{cases}-\\log[\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=1\\\\-\\log[1-\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=0\\end{cases}\n$$\n\nWith regularization:\n\n$$\n\\hat{\\epsilon}(w)=-\\sum_{i=1}^n\\{y_i\\log\\sigma(h_w(x))+(1-y_i)\\log[1-\\sigma(h_w(x))]+\\lambda\\sum_{j=1}^dw_j^2\n$$\n\nHow to deal with multiclass problems?\n\n#### Softmax Regression\n\nNormalizes multiple outputs in a probability vector.\n\n$$\np(y=i|x)=\\frac{\\exp(w_i^Tx)}{\\sum_{r=1}^C\\exp(w_r^Tx)}\n$$\n\nCross-Entropy Loss\n\n$$\n\\ell(h(x_i),y_i)=\\begin{cases}-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_1^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=1\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_2^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=2\\\\\\vdots\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_c^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=C\\end{cases}\n$$\n\nThis loss is convex. But there are many solutions that result in same outputs, so the regularizaton is indispensible to prevent divergence.\n\n![1713166706648](../images/AI/1713166706648.png)\n\n### Support Vector Machine (SVM)\n\n#### Soft-SVM (Hinge Loss)\n\n$$\n\\min_{w,b,\\xi}\\frac{1}{2}\\|w\\|_{2}^{2}+\\frac{C}{n}\\sum_{i=1}^{n}\\xi_{i}\\\\\\mathrm{s.t.~}y_i(\\boldsymbol{w}\\cdot\\boldsymbol{x}_i+b)\\geq1-\\xi_i\\\\\\xi_i\\geq0,1\\leq i\\leq n\n$$\n\nDefine Hinge Loss\n\n$$\n\\ell(f(x),y)=\\max\\{0,1-yf(x)\\}\n$$\n\nFor the linear hypothesis:\n\n$$\n\\ell(f(x),y)=\\max\\{0,1-y(w\\cdot x+b)\\}\n$$\n\nTheorem: Soft-SVM is equivalent to a Regularized Rise Minimization:\n\n$$\n\\min_{w,b}\\frac12\\|w\\|_2^2+\\frac Cn\\sum_{i=1}^n\\max\\{0,1-y_i(w\\cdot x_i+b)\\}\n$$\n\n这意味着SVM的“最大化”边界距离项本质上是一个正则化项。\n\n### Kernel Soft-SVM\n\nBasis function $\\Phi(x)$ can often replaced by kernal function $k(x_1, x_2)$.\n\nPolynomial Kernel: efficient computation: $O(d)$\n\n![1713169419702](../images/AI/1713169419702.png)\n\nConstruct new kernel function from exist kernel functions:\n\n$$\nk^{\\prime}(x_{1},x_{2})=k_{1}\\otimes k_{2}(x_{1},x_{2})=k_{1}\n(x_{1},x_{2})k_{2}(x_{1},x_{2})\n$$\n\nFor any function $g: \\mathcal X \\rightarrow \\R$\n\n$$\nk^\\prime(x_1,x_2)=g(x_1)k_1(x_1,x_2)g(x_2)\n$$\n\nApply Representer theorem:\n\n$$\n\\min_\\alpha\\frac12\\alpha^TK\\alpha+\\frac Cn\\sum_{i=1}^n\\max\\left\\{0,1-y_i\\sum_{j=1}^n\\alpha_jk(x_i,x_j)\\right\\}\n$$\n\n- $\\alpha_j$ is the weight of each reference point $\\color{red}{x_j}$ to the prediction of $\\color{red}{x_i}$.\n- lt is actually a Primal Form with kernel functions.\n\n### Decision Tree\n\nCriterion:\n\n* More balance\n* More pure\n\nMisclassification error (not used very frequently):\n\n$$\n\\mathrm{Err}(\\mathcal{D})=1-\\max_{1\\leq k\\leq K}\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)\n$$\n\nUse Entropy to measure purity:\n\n$$\nH(\\mathcal{D})=-\\sum_{k=1}^K\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\mathrm{log}\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\n$$\n\nGini Index:\n\n$$\n\\mathrm{Gini}(\\mathcal{D})=1-\\sum_{k=1}^K\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)^2\n$$\n\n#### ID3 Algorithm\n\n![1713171808270](../images/AI/1713171808270.png)\n\n### Multiplayer Perceptrons (MLP)\n\n#### MLP for XOR\n\n![1713771652191](../images/AI/1713771652191.png)\n\n#### Activation\n\n![1713772489046](../images/AI/1713772489046.png)\n\n#### Loss Functions\n\nEntropy\n\n$$\nH(q)=-\\sum_{j=1}^kq_j\\log q_j\n$$\n\nRelative-entropy\n\n$$\n\\mathrm{KL}(q||p)=-\\sum_{j=1}^kq_j\\log p_j-H(q)\n$$\n\nCross-entropy\n\n$$\nH(q,p)=-\\sum_{j=1}^kq_j\\log p_j\n$$\n\nRelationship:\n\n$$\n\\boxed{H(q,p)=\\mathrm{KL}(q||p)+H(q)}\n$$\n\nSoftmax in the output layer\n\n$$\n\\widehat{\\boldsymbol{y}}=\\boldsymbol{a}^{(n_l)}=f_\\theta\\big(\\boldsymbol{x}^{(i)}\\big)=\\begin{bmatrix}p\\big(\\boldsymbol{y}^{(i)}=1\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\p\\big(\\boldsymbol{y}^{(i)}=2\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\\\vdots\\\\p\\big(\\boldsymbol{y}^{(i)}=k\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\end{bmatrix}=\\frac{1}{\\sum_{j=1}^{k}\\exp(z_{j}^{(n_{l})})}\\begin{bmatrix}\\exp(z_{1}^{(n_{l})})\\\\\\exp(z_{2}^{(n_{l})})\\\\\\vdots\\\\\\exp(z_{k}^{(n_{l})})\\end{bmatrix}\n$$\n\nCross-entropy loss:\n\n$$\nJ(y,\\widehat{y})=-\\sum_{j=1}^ky_j\\log\\widehat{y}_j\n$$\n\nCost function:\n\n$$\n\\min J(\\theta)=-\\frac1m\\sum_{i=1}^m\\left[\\sum_{j=1}^k\\mathbf{1}\\{y^{(i)}=j\\}\\mathrm{log}\\frac{\\exp(\\mathbf{z}_j^{(n_\\iota)})}{\\sum_{j^{\\prime}=1}^k\\exp(\\mathbf{z}_{j^{\\prime}}^{(n_\\iota)})}\\right]\n$$\n\n#### Gradient-Based Training\n\n$$\n\\arg\\min_\\theta O(\\mathcal{D};\\theta)=\\sum_{i=1}^mL\\left(y_i,f(x_i);\\theta\\right)+\\Omega(\\theta)\n$$\n\nForward Propagation: to compute activations & objective $J(\\theta)$\n\nBackward Propagation: Update paramters in all layers\n\n##### Learning Rate decay\n\nExponential decay strategy:\n\n$$\n\\eta = \\eta_0e^{kt}\n$$\n\n1/t decay strategy:\n\n$$\n\\eta = \\eta_0/(1+kt)\n$$\n\n##### Weight Decay\n\nL2 regularization:\n\n$$\n\\Omega(\\theta)=\\frac\\lambda2\\sum_{l=1}^{n_l-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\theta_{ji}^{(l)})^2\\\\\\frac\\partial{\\partial\\theta^{(l)}}\\Omega(\\theta)=\\lambda\\theta^{(l)}\n$$\n\nL1:\n\n$$\n\\Omega(\\theta)=\\lambda\\sum_{l=1}^{n_{l}-1}\\sum_{i=1}^{s_{l}}\\sum_{j=1}^{s_{l+1}}|\\theta_{ji}^{(l)}|\\\\\\frac{\\partial}{\\partial\\theta^{(l)}}\\Omega(\\theta)_{ji}=\\lambda(1_{\\theta_{ji}^{(l)}>0}-1_{\\theta_{ji}^{(l)}<0})\n$$\n\n一般不调。\n\n##### Weight Initialization\n\nXavier initialization\n\n(Linear activations)\n\n$$\n\\mathrm{Var}(w)=1/n_{\\mathrm{in}}\n$$\n\n避免梯度爆炸或者消失；\n\nHe initialization\n\n(ReLU activations)\n\n$$\n\\mathrm{Var}(w)=2/n_{\\mathrm{in}}\n$$\n\n因为 ReLU 删除了一半的信息。\n\n![1713775669844](../images/AI/1713775669844.png)\n\n### Convolutional Neural Network (CNN)\n\n![1713776156049](../images/AI/1713776156049.png)\n\n![1713776168789](../images/AI/1713776168789.png)\n\n![1714379943169](../images/AI/1714379943169.png)\n\n#### Convoluion Kernel\n\n![1714380111476](../images/AI/1714380111476.png)\n\nStride\n\n![1714380132725](../images/AI/1714380132725.png)\n\nPadding\n\n![1714380159356](../images/AI/1714380159356.png)\n\n![1714380233071](../images/AI/1714380233071.png)\n\n#### Pooling\n\n![1714380343254](../images/AI/1714380343254.png)\n\nBatch Normalization\n\n![1714379335929](../images/AI/1714379335929.png)\n\n在 N 张图像的对应通道做归一化。\n\n可以增强训练的稳定性，使得学习率可以设大一点而仍然保证收敛。\n\n\n* 数据集成\n* 参数集成\n* 模型集成\n\n#### ResNet\n\n![1714380578105](../images/AI/1714380578105.png)\n\n![1714380763838](../images/AI/1714380763838.png)\n\n最后一层 Global Average Pooling：7\\*7\\*2048 -> 1\\* 1 \\* 2048\n\n### Recurrent Neural Network (RNN)\n\n#### Idea for Sequence Modeling\n\nLocal Dependency\n\n![1714982108981](../images/AI/1714982108981.png)\n\nParameter Sharing\n\n![1714982133935](../images/AI/1714982133935.png)\n\n### RNN\n\n![1714982188331](../images/AI/1714982188331.png)\n\nGo deeper\n\n![1714982215920](../images/AI/1714982215920.png)\n\n#### Standard Architectures\n\n![1714982075164](../images/AI/1714982075164.png)\n\n- RNNs can represent unbounded temporal dependencies\n- RNNs encode histories of words into a fixed size hidden vector \n- Parameter size does not grow with the length of dependencies\n- RNNs are hard to learn long range dependencies present in data\n\n#### LSTM\n\nMultihead, shared bottom.\n\n![1714982405665](../images/AI/1714982405665.png)\n\nGradient flow highway: remember history very well.\n\nNIPS 2015 Highway Network.\n\n#### Training Strategies\n\nShift in Training & Inference\n\n![1714983390325](../images/AI/1714983390325.png)\n\nUse Scheduled Sampling to solve this\n\n![1714983452419](../images/AI/1714983452419.png)\n\nProblem: Gradient Explosion during continuously multiplication.\n\nSolution: Gradient Clipping\n\n![1714983641507](../images/AI/1714983641507.png)\n\nVariational Dropout\n\n![1714983788461](../images/AI/1714983788461.png)\n\nLayer Normalization\n\n![1714983988587](../images/AI/1714983988587.png)\n\nBN: Easy to compare between channels\n\nLN: Easy to compare between samples\n\n在图像任务上，我们一般认为 channel 之间的地位应该是相同的，因此常常采用 BN。\n\n### Transformer\n\nuse attention to replace state space.\n\n![1714984460020](../images/AI/1714984460020.png)\n\n#### Attention\n\n![1714984778231](../images/AI/1714984778231.png)\n\n$$\n\\text{Attention}(Q,K,V)=\\text{Softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n$$\n\nMulti-Head Attention\n\n![1714985419724](../images/AI/1714985419724.png)\n\nSparse?\n\n$W^o$ to maintain shape and jointly attend to information from different representation subspaces.\n\n#### FFN\n\nPosition-wise FFN (Similar to multi convolution kernels in CNN, shared parameters in every word.)\n\n![1714985971187](../images/AI/1714985971187.png)\n\n#### Positional Encoding\n\n![1714986050538](../images/AI/1714986050538.png)\n\n## Reasoning\n\nReasoning (Probabilistic) = Modeling + Inference\n\nModeling:\n* Bayesian Networks\n* Markov random fields\n\nInference:\n* Elimination methods (变量消除法)\n* Latent variable models (因变量模型)\n* Variational methods (变分方法)\n* Sampling methods (采样方法) - 难学！\n\n### Bayesian Network\n\n$$\np(x_1,...,x_K)=p(x_K|x_1,...,x_{K-1})\\cdots p(x_2|x_1)p(x_1)\n$$\n\n#### Variable Elimination\n\n用于计算概率的边缘分布\n\n![1716191759894](../images/AI/1716191759894.png)\n\n一般而言是 NP-hard 问题。\n\n对于 Markov chain，复杂度为 $O(nk^2)$；对于一般的图，$O(k^{n-1})$；如果确定每个节点的父节点数不超过 m，则复杂度为 $O(nk^{m-1})$\n\n#### Message Passing\n\nReuse the computation from $P(Y|E=e)$ when calcuating another probability $P(Y_1|E_1=e_1)$\n\n![1716192135361](../images/AI/1716192135361.png)\n\n![1716192175996](../images/AI/1716192175996.png)\n\n“$\\propto$” 意味着只需要知道概率的相对值就够了，因为可以通过归一化算出最终的概率值。\n\nMAP 需要求概率分布的最大值。\n\nsum 与 max 同为聚合操作，因此同样满足分配律，只需要对应替换就可以得到第二种 Message Passing：\n\n![1716192534058](../images/AI/1716192534058.png)\n\n\n![1716192519850](../images/AI/1716192519850.png)\n\n![1716193180893](../images/AI/1716193180893.png)\n\n### Bayes Approach\n\n![1716193473766](../images/AI/1716193473766.png)\n\n### MLE method\n\n如果概率模型的参数知道，称为概率；不知道，称为统计推断。\n\n估计高斯分布的参数：\n\n方差是有偏估计，所以一般× $1/(n-1)$。\n\n![1716194228666](../images/AI/1716194228666.png)\n\n### Bayes Decision Rule\n\n![1716194320872](../images/AI/1716194320872.png)\n\n对于回归问题，可以采用高斯噪声假设：\n\n![1716194583833](../images/AI/1716194583833.png)\n\n这样就得到了最小二乘估计。\n\nMLE 是先验概率相等的 MAP。\n\n放在机器学习中，MAP 可以定义为：模型 = 数据 + 先验。\n\n![1716194633162](../images/AI/1716194633162.png)\n\n先验信息在机器学习中体现为正则化：\n\n2 范数正则化就是在认为模型参数服从高斯分布的先验假设情况下，利用 MAP 准则来估计参数。\n\n这也就是为什么正则化倾向于避免过拟合：高斯分布先验希望模型参数足够简单。\n\n![1716194757145](../images/AI/1716194757145.png)\n\n### Bayesian Model Averaging\n\n![1716195002371](../images/AI/1716195002371.png)\n\n意义：模型集成。\n\n### Discriminative Models\n\n上面的理论足够解释判别式模型的原理了。\n\n### Generative Models\n\n![1716195398036](../images/AI/1716195398036.png)\n\n![1716195442145](../images/AI/1716195442145.png)\n\n#### Naive Bayes Classifier\n\nmodel $Y$ as a bernoulli distribution with parameters $p(y=1)$ and $p(y=-1)$\n\nconditional independence: each dimension is independent given label y\n\n$$\np(X=x|Y=y)=\\prod_{j=1}^dp(x_{\\cdot j}|y)\n$$\n\nLaplacian smoothing for 0 samples:\n\n$$\np(x_{\\cdot j}=r_j|Y=+1)=\\frac{\\sum_{i=1}^n1\\{x_{\\cdot j}=r_j\\wedge y_i=+1\\}+1}{\\sum_{i=1}^n1\\{y_i=+1\\}+k_j}\n$$\n\nFor dataset with all continuous features: descretize it, or use another model based on a different assumption.\n\n\n#### Guassian Discriminant Analysis\n\n是一个生成模型！虽然它被用来分类，但是它的建模设计上采用的是生成式。\n\nFor dataset with all continuous features:\n\nUsing parametrice distribution to represent $P(X=x|Y=y)$\n\nA common assumption in classification:\n\n- We always assume that data points in a class is a cluster.\n\nStill model $p(Y=y)$ as Bernoulli distribution.\n\n$$\n\\text{So we can model }p(X=x|Y=y)\\text{ by Gaussian distribution:}\\\\p(X=x|Y=+1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{+})^{T}\\Sigma^{-1}(x-\\mu_{+})\\right)\\\\p(X=x|Y=-1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{-})^{T}\\Sigma^{-1}(x-\\mu_{-})\\right)\n$$\n\nNote the shared parameters $\\Sigma$ for positive and nagative classes.\n\nUse MLE to find the best solution:\n\n$$\n\\ell(\\phi,\\mu_+,\\mu_-,\\Sigma)=\\log\\prod_{i=1}^np(x_i,y_i;\\phi,\\mu_+,\\mu_-,\\Sigma)\\\\=\\log\\prod_{i=1}^np(x_i|y_i;\\mu_+,\\mu_-,\\Sigma)+\\boxed{\\log\\prod_{i=1}^np(y_i|\\phi)}\n$$\n\nThen:\n\n$$\n\\phi=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}}{n},\\mu_{+}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}},\\mu_{-}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}}\\\\\\boldsymbol{\\Sigma}=\\frac{1}{n}\\boldsymbol{\\Sigma}_{i=1}^{n}(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})^{T}\n$$\n\n#### Discriminative vs. Generative\n\n![1716795753326](../images/AI/1716795753326.png)\n\n### Mixture Models and EM\n\n#### Gaussian Mixture Model\n\nA Generative model. More assumption than Logistic Regression.\n\n![1716796053911](../images/AI/1716796053911.png)\n\nSample dataset from GMM:\n\n$$\np(x)=\\sum_{z=1}^k\\pi_z\\mathcal{N}(x|\\mu_z,\\Sigma_z)\n$$\n\nCompute log-likelihood:\n\n$$\n\\ell(\\boldsymbol{\\pi},\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})=\\log\\prod_{i=1}^n\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)\\right]\n$$\n\n$$\n\\ell(\\pi,\\mu,\\Sigma)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\frac{\\pi_z}{\\sqrt{|2\\pi\\Sigma_z|}}\\exp(-\\frac12(x_i-\\mu_z)^T\\Sigma^{-1}(x_i-\\mu_z))\\right]\n$$\n\nIntracable! Use EM method to estimate parameters.\n\n$z$ is latent variable.\n\n#### Expectation Maximization\n\n![1716797001550](../images/AI/1716797001550.png)\n\nLearing Problem:\n\nfind MLE\n\n$$\n\\widehat{\\theta}=\\underset{\\theta}{\\operatorname*{argmax\\ }}p(\\mathcal{D}|\\theta)\n$$\n\nInference Promblem:\n\nGiven $x$, find conditional variable of $z$:\n\n$$\np(z|x,\\theta)\n$$\n\nEM method is for both problems!\n\nit is hard to maximize the marginal likelihood directly:\n\n$$\n\\max_\\theta\\log p(x|\\theta)\n$$\n\nbut the complete data log-likelihood is easy typically:\n\n$$\n\\max_\\theta\\log p(x, z|\\theta)\n$$\n\nif we had a distribution $q(z)$ for z:\n\n$$\n\\max_\\theta\\sum_zq(z)\\log p(x,z|\\theta)\n$$\n\nWe have Evidence Lower Bound (ELBO):\n\n$$\n\\log p(x|\\theta)=\\log\\left[\\sum_zp(x,z|\\theta)\\right] \\ge \\underbrace{\\sum_zq(z)\\log(\\frac{p(x,z|\\theta)}{q(z)})}_{\\mathcal{L}(q,\\theta)}\n$$\n\nNow we optimize the ELBO iteratively:\n\n![1716797936119](../images/AI/1716797936119.png)\n\nThe math background for ELBO:\n\n![1716798247574](../images/AI/1716798247574.png)\n\nWe get back an equality for the marginal likelihood:\n\n$$\n\\log p(x|\\theta)=\\mathcal{L}(q,\\theta)+\\mathrm{KL}[q(z)||p(z|x,\\theta)]\n$$\n\nEvidence = ELBO + KL-Divergence\n\nIn E-step, if we want to maximize the ELBO without changing $\\theta$, we have to let KL be zero. Thus $q^*(z)=p(z|x,\\theta)$\n\nFor M-step, we find the $\\theta$ to maximize the ELBO.\n\n![1716798687551](../images/AI/1716798687551.png)\n\nIn MAP case:\n\n![1716798850106](../images/AI/1716798850106.png)\n\nFor GMM, E-step:\n\n![1716798927981](../images/AI/1716798927981.png)\n\nM-step:\n\n![1716799063581](../images/AI/1716799063581.png)\n\nRecommended Initialize:\n\n$$\n\\pi = 1/k\\\\\n\\mu = 0\\\\\n\\Sigma = \\sigma^2 I\n$$\n\nVariational Methods:\n\n![1716799707301](../images/AI/1716799707301.png)\n\n注意：E 步计算的是隐变量的后验（如果能计算出来），因为它是使得似然函数及ELBO最大的 $q(z)$。算不出来就用变分方法近似。\n\n$q(z)$ 既不是先验分布，也不是后验分布，它只是我们对隐变量分布的一种估计。\n\n### Probabilistic Topic Models\n\n#### Dirichlet-Multinomial Model\n\n![1717400667281](../images/AI/1717400667281.png)\n\nBeta Distribution:\n\n$$\nf(\\phi|\\alpha,\\beta)=\\frac1{B(\\alpha,\\beta)}\\phi^{\\alpha-1}(1-\\phi)^{\\beta-1}\n$$\n\nDirichlet Multinomial Model: Multi-dimensional version of Beta Distribution\n\n$$\n\\boxed{p(\\vec{\\theta}|\\boldsymbol{\\alpha})}=\\frac1{B(\\boldsymbol{\\alpha})}\\prod_{k=1}^K\\theta_k^{\\alpha_k-1}\\quad\\text{Where }B(\\alpha)=\\frac{\\Pi_{k=1}^K\\Gamma(\\alpha_k)}{\\Gamma(\\sum_{k=1}^K\\alpha_k)}\n$$\n\nConjugate prior:\n\n$$\n\\sum_{i=1}^K\\theta_i=1\n$$\n\n![1717400854837](../images/AI/1717400854837.png)\n\nAdmixture:\n\n![1717401031002](../images/AI/1717401031002.png)\n\nLatent Dirichlet Allocation (LDA):\n\n![1717401124879](../images/AI/1717401124879.png)\n\nProbabilistic Graphical Models:\n\n![1717401517265](../images/AI/1717401517265.png)\n\n![1717401591545](../images/AI/1717401591545.png)\n\nMaximum Likelihood Estimation\n\n$$\n\\log p(\\beta,\\theta,z,w|\\alpha,\\eta)\\\\\n=\\sum_{k=1}^K\\log p(\\vec{\\beta}_k|\\eta)+\\sum_{d=1}^D\\log p(\\vec{\\theta}_d|\\alpha)+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(z_{d,n}|\\vec{\\theta}_d)\\\\\n +\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(w_{d,n}|z_{d,n},\\vec{\\boldsymbol{\\beta}}_{1:K})\\\\\n \\begin{aligned}\n&=\\sum_{k=1}^{K}\\left(\\sum_{v=1}^{V}(\\eta_{v}-1)\\log\\beta_{kv}-\\log B(\\eta)\\right)+\\sum_{d=1}^{D}\\sum_{k=1}^{K}(\\alpha_{k}-1)\\log\\theta_{dk}-\\log B(\\alpha) \\\\\n&+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\theta_{d,z_{d,n}}+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\beta_{z_{d,n}w_{d,n}}\n\\end{aligned}\n$$\n\nTo learn the param $\\alpha, \\eta$, use EM method:\n\nIn E-step, calculate \n\n$$\nq^*(z)=p(z|x,\\theta^{\\mathrm{old}})\n$$\n\n$$\np(\\theta,z,\\beta\\mid w,\\alpha,\\eta)=\\frac{p(\\theta,z,\\beta,w\\mid\\alpha,\\eta)}{p(w\\mid\\alpha,\\eta)}\n$$\n\nHowever, the denominator is intractable:\n\n$$\np(\\mathbf{w}|\\alpha,\\eta)=\\int\\int\\sum_\\mathbf{z}p(\\boldsymbol{\\theta},\\mathbf{z},\\boldsymbol{\\beta},\\mathbf{w}|\\boldsymbol{\\alpha},\\boldsymbol{\\eta})d\\boldsymbol{\\theta}d\\boldsymbol{\\beta}\n$$\n\nThis problem is for general Bayesian models. We can use Variational Methods or Markov Chain Monte Carlo to solve it.\n\n#### Variational Methods\n\n![1717403664862](../images/AI/1717403664862.png)\n\n![1717403702542](../images/AI/1717403702542.png)\n\n![1717403725888](../images/AI/1717403725888.png)\n\n![1717404024479](../images/AI/1717404024479.png)\n\nUse Mean field assumption in LDA:\n\n![1717404907709](../images/AI/1717404907709.png)\n\n![1717404790783](../images/AI/1717404790783.png)\n\n### Variational Autoencoders (VAE)\n\n![1717405465141](../images/AI/1717405465141.png)\n\nReparameterization Trick: \n\n![1717405435705](../images/AI/1717405435705.png)\n\n","slug":"AI","published":1,"updated":"2024-06-03T09:04:26.606Z","_id":"clu1gtfhk0000rsug8xn4cs6m","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Learning\"><a href=\"#Learning\" class=\"headerlink\" title=\"Learning\"></a>Learning</h2><h3 id=\"Linear-Classification\"><a href=\"#Linear-Classification\" class=\"headerlink\" title=\"Linear Classification\"></a>Linear Classification</h3><h4 id=\"Logistic-Regression\"><a href=\"#Logistic-Regression\" class=\"headerlink\" title=\"Logistic Regression\"></a>Logistic Regression</h4><p>Useful for classification problems.</p>\n<p>Cross-Entropy Loss</p>\n<div>$$\n\\ell(h(\\boldsymbol{x}_{i}),y_{i})=\\begin{cases}-\\log[\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=1\\\\-\\log[1-\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=0\\end{cases}\n$$</div>\n\n<p>With regularization:</p>\n<div>$$\n\\hat{\\epsilon}(w)=-\\sum_{i=1}^n\\lbracey_i\\log\\sigma(h_w(x))+(1-y_i)\\log[1-\\sigma(h_w(x))]+\\lambda\\sum_{j=1}^dw_j^2\n$$</div>\n\n<p>How to deal with multiclass problems?</p>\n<h4 id=\"Softmax-Regression\"><a href=\"#Softmax-Regression\" class=\"headerlink\" title=\"Softmax Regression\"></a>Softmax Regression</h4><p>Normalizes multiple outputs in a probability vector.</p>\n<div>$$\np(y=i|x)=\\frac{\\exp(w_i^Tx)}{\\sum_{r=1}^C\\exp(w_r^Tx)}\n$$</div>\n\n<p>Cross-Entropy Loss</p>\n<div>$$\n\\ell(h(x_i),y_i)=\\begin{cases}-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_1^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=1\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_2^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=2\\\\\\vdots\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_c^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=C\\end{cases}\n$$</div>\n\n<p>This loss is convex. But there are many solutions that result in same outputs, so the regularizaton is indispensible to prevent divergence.</p>\n<p><img src=\"/../images/AI/1713166706648.png\" alt=\"1713166706648\" loading=\"lazy\"></p>\n<h3 id=\"Support-Vector-Machine-SVM\"><a href=\"#Support-Vector-Machine-SVM\" class=\"headerlink\" title=\"Support Vector Machine (SVM)\"></a>Support Vector Machine (SVM)</h3><h4 id=\"Soft-SVM-Hinge-Loss\"><a href=\"#Soft-SVM-Hinge-Loss\" class=\"headerlink\" title=\"Soft-SVM (Hinge Loss)\"></a>Soft-SVM (Hinge Loss)</h4><div>$$\n\\min_{w,b,\\xi}\\frac{1}{2}\\|w\\|_{2}^{2}+\\frac{C}{n}\\sum_{i=1}^{n}\\xi_{i}\\\\\\mathrm{s.t.~}y_i(\\boldsymbol{w}\\cdot\\boldsymbol{x}_i+b)\\geq1-\\xi_i\\\\\\xi_i\\geq0,1\\leq i\\leq n\n$$</div>\n\n<p>Define Hinge Loss</p>\n<div>$$\n\\ell(f(x),y)=\\max\\{0,1-yf(x)\\rbrace\n$$</div>\n\n<p>For the linear hypothesis:</p>\n<div>$$\n\\ell(f(x),y)=\\max\\{0,1-y(w\\cdot x+b)\\}\n$$</div>\n\n<p>Theorem: Soft-SVM is equivalent to a Regularized Rise Minimization:</p>\n<div>$$\n\\min_{w,b}\\frac12\\|w\\|_2^2+\\frac Cn\\sum_{i=1}^n\\max\\{0,1-y_i(w\\cdot x_i+b)\\}\n$$</div>\n\n<p>这意味着SVM的“最大化”边界距离项本质上是一个正则化项。</p>\n<h3 id=\"Kernel-Soft-SVM\"><a href=\"#Kernel-Soft-SVM\" class=\"headerlink\" title=\"Kernel Soft-SVM\"></a>Kernel Soft-SVM</h3><p>Basis function $\\Phi(x)$ can often replaced by kernal function $k(x_1, x_2)$.</p>\n<p>Polynomial Kernel: efficient computation: $O(d)$</p>\n<p><img src=\"/../images/AI/1713169419702.png\" alt=\"1713169419702\" loading=\"lazy\"></p>\n<p>Construct new kernel function from exist kernel functions:</p>\n<div>$$\nk^{\\prime}(x_{1},x_{2})=k_{1}\\otimes k_{2}(x_{1},x_{2})=k_{1}\n(x_{1},x_{2})k_{2}(x_{1},x_{2})\n$$</div>\n\n<p>For any function $g: \\mathcal X \\rightarrow \\R$</p>\n<div>$$\nk^\\prime(x_1,x_2)=g(x_1)k_1(x_1,x_2)g(x_2)\n$$</div>\n\n<p>Apply Representer theorem:</p>\n<div>$$\n\\min_\\alpha\\frac12\\alpha^TK\\alpha+\\frac Cn\\sum_{i=1}^n\\max\\left\\{0,1-y_i\\sum_{j=1}^n\\alpha_jk(x_i,x_j)\\right\\}\n$$</div>\n\n<ul>\n<li>$\\alpha_j$ is the weight of each reference point $\\color{red}{x_j}$ to the prediction of $\\color{red}{x_i}$.</li>\n<li>lt is actually a Primal Form with kernel functions.</li>\n</ul>\n<h3 id=\"Decision-Tree\"><a href=\"#Decision-Tree\" class=\"headerlink\" title=\"Decision Tree\"></a>Decision Tree</h3><p>Criterion:</p>\n<ul>\n<li>More balance</li>\n<li>More pure</li>\n</ul>\n<p>Misclassification error (not used very frequently):</p>\n<div>$$\n\\mathrm{Err}(\\mathcal{D})=1-\\max_{1\\leq k\\leq K}\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)\n$$</div>\n\n<p>Use Entropy to measure purity:</p>\n<div>$$\nH(\\mathcal{D})=-\\sum_{k=1}^K\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\mathrm{log}\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\n$$</div>\n\n<p>Gini Index:</p>\n<div>$$\n\\mathrm{Gini}(\\mathcal{D})=1-\\sum_{k=1}^K\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)^2\n$$</div>\n\n<h4 id=\"ID3-Algorithm\"><a href=\"#ID3-Algorithm\" class=\"headerlink\" title=\"ID3 Algorithm\"></a>ID3 Algorithm</h4><p><img src=\"/../images/AI/1713171808270.png\" alt=\"1713171808270\" loading=\"lazy\"></p>\n<h3 id=\"Multiplayer-Perceptrons-MLP\"><a href=\"#Multiplayer-Perceptrons-MLP\" class=\"headerlink\" title=\"Multiplayer Perceptrons (MLP)\"></a>Multiplayer Perceptrons (MLP)</h3><h4 id=\"MLP-for-XOR\"><a href=\"#MLP-for-XOR\" class=\"headerlink\" title=\"MLP for XOR\"></a>MLP for XOR</h4><p><img src=\"/../images/AI/1713771652191.png\" alt=\"1713771652191\" loading=\"lazy\"></p>\n<h4 id=\"Activation\"><a href=\"#Activation\" class=\"headerlink\" title=\"Activation\"></a>Activation</h4><p><img src=\"/../images/AI/1713772489046.png\" alt=\"1713772489046\" loading=\"lazy\"></p>\n<h4 id=\"Loss-Functions\"><a href=\"#Loss-Functions\" class=\"headerlink\" title=\"Loss Functions\"></a>Loss Functions</h4><p>Entropy</p>\n<div>$$\nH(q)=-\\sum_{j=1}^kq_j\\log q_j\n$$</div>\n\n<p>Relative-entropy</p>\n<div>$$\n\\mathrm{KL}(q||p)=-\\sum_{j=1}^kq_j\\log p_j-H(q)\n$$</div>\n\n<p>Cross-entropy</p>\n<div>$$\nH(q,p)=-\\sum_{j=1}^kq_j\\log p_j\n$$</div>\n\n<p>Relationship:</p>\n<div>$$\n\\boxed{H(q,p)=\\mathrm{KL}(q||p)+H(q)}\n$$</div>\n\n<p>Softmax in the output layer</p>\n<div>$$\n\\widehat{\\boldsymbol{y}}=\\boldsymbol{a}^{(n_l)}=f_\\theta\\big(\\boldsymbol{x}^{(i)}\\big)=\\begin{bmatrix}p\\big(\\boldsymbol{y}^{(i)}=1\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\p\\big(\\boldsymbol{y}^{(i)}=2\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\\\vdots\\\\p\\big(\\boldsymbol{y}^{(i)}=k\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\end{bmatrix}=\\frac{1}{\\sum_{j=1}^{k}\\exp(z_{j}^{(n_{l})})}\\begin{bmatrix}\\exp(z_{1}^{(n_{l})})\\\\\\exp(z_{2}^{(n_{l})})\\\\\\vdots\\\\\\exp(z_{k}^{(n_{l})})\\end{bmatrix}\n$$</div>\n\n<p>Cross-entropy loss:</p>\n<div>$$\nJ(y,\\widehat{y})=-\\sum_{j=1}^ky_j\\log\\widehat{y}_j\n$$</div>\n\n<p>Cost function:</p>\n<div>$$\n\\min J(\\theta)=-\\frac1m\\sum_{i=1}^m\\left[\\sum_{j=1}^k\\mathbf{1}\\{y^{(i)}=j\\}\\mathrm{log}\\frac{\\exp(\\mathbf{z}_j^{(n_\\iota)})}{\\sum_{j^{\\prime}=1}^k\\exp(\\mathbf{z}_{j^{\\prime}}^{(n_\\iota)})}\\right]\n$$</div>\n\n<h4 id=\"Gradient-Based-Training\"><a href=\"#Gradient-Based-Training\" class=\"headerlink\" title=\"Gradient-Based Training\"></a>Gradient-Based Training</h4><div>$$\n\\arg\\min_\\theta O(\\mathcal{D};\\theta)=\\sum_{i=1}^mL\\left(y_i,f(x_i);\\theta\\right)+\\Omega(\\theta)\n$$</div>\n\n<p>Forward Propagation: to compute activations &amp; objective $J(\\theta)$</p>\n<p>Backward Propagation: Update paramters in all layers</p>\n<h5 id=\"Learning-Rate-decay\"><a href=\"#Learning-Rate-decay\" class=\"headerlink\" title=\"Learning Rate decay\"></a>Learning Rate decay</h5><p>Exponential decay strategy:</p>\n<div>$$\n\\eta = \\eta_0e^{kt}\n$$</div>\n\n<p>1&#x2F;t decay strategy:</p>\n<div>$$\n\\eta = \\eta_0/(1+kt)\n$$</div>\n\n<h5 id=\"Weight-Decay\"><a href=\"#Weight-Decay\" class=\"headerlink\" title=\"Weight Decay\"></a>Weight Decay</h5><p>L2 regularization:</p>\n<div>$$\n\\Omega(\\theta)=\\frac\\lambda2\\sum_{l=1}^{n_l-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\theta_{ji}^{(l)})^2\\\\\\frac\\partial{\\partial\\theta^{(l)}}\\Omega(\\theta)=\\lambda\\theta^{(l)}\n$$</div>\n\n<p>L1:</p>\n<div>$$\n\\Omega(\\theta)=\\lambda\\sum_{l=1}^{n_{l}-1}\\sum_{i=1}^{s_{l}}\\sum_{j=1}^{s_{l+1}}|\\theta_{ji}^{(l)}|\\\\\\frac{\\partial}{\\partial\\theta^{(l)}}\\Omega(\\theta)_{ji}=\\lambda(1_{\\theta_{ji}^{(l)}>0}-1_{\\theta_{ji}^{(l)}<0})\n$$</div>\n\n<p>一般不调。</p>\n<h5 id=\"Weight-Initialization\"><a href=\"#Weight-Initialization\" class=\"headerlink\" title=\"Weight Initialization\"></a>Weight Initialization</h5><p>Xavier initialization</p>\n<p>(Linear activations)</p>\n<div>$$\n\\mathrm{Var}(w)=1/n_{\\mathrm{in}}\n$$</div>\n\n<p>避免梯度爆炸或者消失；</p>\n<p>He initialization</p>\n<p>(ReLU activations)</p>\n<div>$$\n\\mathrm{Var}(w)=2/n_{\\mathrm{in}}\n$$</div>\n\n<p>因为 ReLU 删除了一半的信息。</p>\n<p><img src=\"/../images/AI/1713775669844.png\" alt=\"1713775669844\" loading=\"lazy\"></p>\n<h3 id=\"Convolutional-Neural-Network-CNN\"><a href=\"#Convolutional-Neural-Network-CNN\" class=\"headerlink\" title=\"Convolutional Neural Network (CNN)\"></a>Convolutional Neural Network (CNN)</h3><p><img src=\"/../images/AI/1713776156049.png\" alt=\"1713776156049\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1713776168789.png\" alt=\"1713776168789\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1714379943169.png\" alt=\"1714379943169\" loading=\"lazy\"></p>\n<h4 id=\"Convoluion-Kernel\"><a href=\"#Convoluion-Kernel\" class=\"headerlink\" title=\"Convoluion Kernel\"></a>Convoluion Kernel</h4><p><img src=\"/../images/AI/1714380111476.png\" alt=\"1714380111476\" loading=\"lazy\"></p>\n<p>Stride</p>\n<p><img src=\"/../images/AI/1714380132725.png\" alt=\"1714380132725\" loading=\"lazy\"></p>\n<p>Padding</p>\n<p><img src=\"/../images/AI/1714380159356.png\" alt=\"1714380159356\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1714380233071.png\" alt=\"1714380233071\" loading=\"lazy\"></p>\n<h4 id=\"Pooling\"><a href=\"#Pooling\" class=\"headerlink\" title=\"Pooling\"></a>Pooling</h4><p><img src=\"/../images/AI/1714380343254.png\" alt=\"1714380343254\" loading=\"lazy\"></p>\n<p>Batch Normalization</p>\n<p><img src=\"/../images/AI/1714379335929.png\" alt=\"1714379335929\" loading=\"lazy\"></p>\n<p>在 N 张图像的对应通道做归一化。</p>\n<p>可以增强训练的稳定性，使得学习率可以设大一点而仍然保证收敛。</p>\n<ul>\n<li>数据集成</li>\n<li>参数集成</li>\n<li>模型集成</li>\n</ul>\n<h4 id=\"ResNet\"><a href=\"#ResNet\" class=\"headerlink\" title=\"ResNet\"></a>ResNet</h4><p><img src=\"/../images/AI/1714380578105.png\" alt=\"1714380578105\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1714380763838.png\" alt=\"1714380763838\" loading=\"lazy\"></p>\n<p>最后一层 Global Average Pooling：7*7*2048 -&gt; 1* 1 * 2048</p>\n<h3 id=\"Recurrent-Neural-Network-RNN\"><a href=\"#Recurrent-Neural-Network-RNN\" class=\"headerlink\" title=\"Recurrent Neural Network (RNN)\"></a>Recurrent Neural Network (RNN)</h3><h4 id=\"Idea-for-Sequence-Modeling\"><a href=\"#Idea-for-Sequence-Modeling\" class=\"headerlink\" title=\"Idea for Sequence Modeling\"></a>Idea for Sequence Modeling</h4><p>Local Dependency</p>\n<p><img src=\"/../images/AI/1714982108981.png\" alt=\"1714982108981\" loading=\"lazy\"></p>\n<p>Parameter Sharing</p>\n<p><img src=\"/../images/AI/1714982133935.png\" alt=\"1714982133935\" loading=\"lazy\"></p>\n<h3 id=\"RNN\"><a href=\"#RNN\" class=\"headerlink\" title=\"RNN\"></a>RNN</h3><p><img src=\"/../images/AI/1714982188331.png\" alt=\"1714982188331\" loading=\"lazy\"></p>\n<p>Go deeper</p>\n<p><img src=\"/../images/AI/1714982215920.png\" alt=\"1714982215920\" loading=\"lazy\"></p>\n<h4 id=\"Standard-Architectures\"><a href=\"#Standard-Architectures\" class=\"headerlink\" title=\"Standard Architectures\"></a>Standard Architectures</h4><p><img src=\"/../images/AI/1714982075164.png\" alt=\"1714982075164\" loading=\"lazy\"></p>\n<ul>\n<li>RNNs can represent unbounded temporal dependencies</li>\n<li>RNNs encode histories of words into a fixed size hidden vector </li>\n<li>Parameter size does not grow with the length of dependencies</li>\n<li>RNNs are hard to learn long range dependencies present in data</li>\n</ul>\n<h4 id=\"LSTM\"><a href=\"#LSTM\" class=\"headerlink\" title=\"LSTM\"></a>LSTM</h4><p>Multihead, shared bottom.</p>\n<p><img src=\"/../images/AI/1714982405665.png\" alt=\"1714982405665\" loading=\"lazy\"></p>\n<p>Gradient flow highway: remember history very well.</p>\n<p>NIPS 2015 Highway Network.</p>\n<h4 id=\"Training-Strategies\"><a href=\"#Training-Strategies\" class=\"headerlink\" title=\"Training Strategies\"></a>Training Strategies</h4><p>Shift in Training &amp; Inference</p>\n<p><img src=\"/../images/AI/1714983390325.png\" alt=\"1714983390325\" loading=\"lazy\"></p>\n<p>Use Scheduled Sampling to solve this</p>\n<p><img src=\"/../images/AI/1714983452419.png\" alt=\"1714983452419\" loading=\"lazy\"></p>\n<p>Problem: Gradient Explosion during continuously multiplication.</p>\n<p>Solution: Gradient Clipping</p>\n<p><img src=\"/../images/AI/1714983641507.png\" alt=\"1714983641507\" loading=\"lazy\"></p>\n<p>Variational Dropout</p>\n<p><img src=\"/../images/AI/1714983788461.png\" alt=\"1714983788461\" loading=\"lazy\"></p>\n<p>Layer Normalization</p>\n<p><img src=\"/../images/AI/1714983988587.png\" alt=\"1714983988587\" loading=\"lazy\"></p>\n<p>BN: Easy to compare between channels</p>\n<p>LN: Easy to compare between samples</p>\n<p>在图像任务上，我们一般认为 channel 之间的地位应该是相同的，因此常常采用 BN。</p>\n<h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p>use attention to replace state space.</p>\n<p><img src=\"/../images/AI/1714984460020.png\" alt=\"1714984460020\" loading=\"lazy\"></p>\n<h4 id=\"Attention\"><a href=\"#Attention\" class=\"headerlink\" title=\"Attention\"></a>Attention</h4><p><img src=\"/../images/AI/1714984778231.png\" alt=\"1714984778231\" loading=\"lazy\"></p>\n<div>$$\n\\text{Attention}(Q,K,V)=\\text{Softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n$$</div>\n\n<p>Multi-Head Attention</p>\n<p><img src=\"/../images/AI/1714985419724.png\" alt=\"1714985419724\" loading=\"lazy\"></p>\n<p>Sparse?</p>\n<p>$W^o$ to maintain shape and jointly attend to information from different representation subspaces.</p>\n<h4 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h4><p>Position-wise FFN (Similar to multi convolution kernels in CNN, shared parameters in every word.)</p>\n<p><img src=\"/../images/AI/1714985971187.png\" alt=\"1714985971187\" loading=\"lazy\"></p>\n<h4 id=\"Positional-Encoding\"><a href=\"#Positional-Encoding\" class=\"headerlink\" title=\"Positional Encoding\"></a>Positional Encoding</h4><p><img src=\"/../images/AI/1714986050538.png\" alt=\"1714986050538\" loading=\"lazy\"></p>\n<h2 id=\"Reasoning\"><a href=\"#Reasoning\" class=\"headerlink\" title=\"Reasoning\"></a>Reasoning</h2><p>Reasoning (Probabilistic) &#x3D; Modeling + Inference</p>\n<p>Modeling:</p>\n<ul>\n<li>Bayesian Networks</li>\n<li>Markov random fields</li>\n</ul>\n<p>Inference:</p>\n<ul>\n<li>Elimination methods (变量消除法)</li>\n<li>Latent variable models (因变量模型)</li>\n<li>Variational methods (变分方法)</li>\n<li>Sampling methods (采样方法) - 难学！</li>\n</ul>\n<h3 id=\"Bayesian-Network\"><a href=\"#Bayesian-Network\" class=\"headerlink\" title=\"Bayesian Network\"></a>Bayesian Network</h3><div>$$\np(x_1,...,x_K)=p(x_K|x_1,...,x_{K-1})\\cdots p(x_2|x_1)p(x_1)\n$$</div>\n\n<h4 id=\"Variable-Elimination\"><a href=\"#Variable-Elimination\" class=\"headerlink\" title=\"Variable Elimination\"></a>Variable Elimination</h4><p>用于计算概率的边缘分布</p>\n<p><img src=\"/../images/AI/1716191759894.png\" alt=\"1716191759894\" loading=\"lazy\"></p>\n<p>一般而言是 NP-hard 问题。</p>\n<p>对于 Markov chain，复杂度为 $O(nk^2)$；对于一般的图，$O(k^{n-1})$；如果确定每个节点的父节点数不超过 m，则复杂度为 $O(nk^{m-1})$</p>\n<h4 id=\"Message-Passing\"><a href=\"#Message-Passing\" class=\"headerlink\" title=\"Message Passing\"></a>Message Passing</h4><p>Reuse the computation from $P(Y|E&#x3D;e)$ when calcuating another probability $P(Y_1|E_1&#x3D;e_1)$</p>\n<p><img src=\"/../images/AI/1716192135361.png\" alt=\"1716192135361\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1716192175996.png\" alt=\"1716192175996\" loading=\"lazy\"></p>\n<p>“$\\propto$” 意味着只需要知道概率的相对值就够了，因为可以通过归一化算出最终的概率值。</p>\n<p>MAP 需要求概率分布的最大值。</p>\n<p>sum 与 max 同为聚合操作，因此同样满足分配律，只需要对应替换就可以得到第二种 Message Passing：</p>\n<p><img src=\"/../images/AI/1716192534058.png\" alt=\"1716192534058\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1716192519850.png\" alt=\"1716192519850\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1716193180893.png\" alt=\"1716193180893\" loading=\"lazy\"></p>\n<h3 id=\"Bayes-Approach\"><a href=\"#Bayes-Approach\" class=\"headerlink\" title=\"Bayes Approach\"></a>Bayes Approach</h3><p><img src=\"/../images/AI/1716193473766.png\" alt=\"1716193473766\" loading=\"lazy\"></p>\n<h3 id=\"MLE-method\"><a href=\"#MLE-method\" class=\"headerlink\" title=\"MLE method\"></a>MLE method</h3><p>如果概率模型的参数知道，称为概率；不知道，称为统计推断。</p>\n<p>估计高斯分布的参数：</p>\n<p>方差是有偏估计，所以一般× $1&#x2F;(n-1)$。</p>\n<p><img src=\"/../images/AI/1716194228666.png\" alt=\"1716194228666\" loading=\"lazy\"></p>\n<h3 id=\"Bayes-Decision-Rule\"><a href=\"#Bayes-Decision-Rule\" class=\"headerlink\" title=\"Bayes Decision Rule\"></a>Bayes Decision Rule</h3><p><img src=\"/../images/AI/1716194320872.png\" alt=\"1716194320872\" loading=\"lazy\"></p>\n<p>对于回归问题，可以采用高斯噪声假设：</p>\n<p><img src=\"/../images/AI/1716194583833.png\" alt=\"1716194583833\" loading=\"lazy\"></p>\n<p>这样就得到了最小二乘估计。</p>\n<p>MLE 是先验概率相等的 MAP。</p>\n<p>放在机器学习中，MAP 可以定义为：模型 &#x3D; 数据 + 先验。</p>\n<p><img src=\"/../images/AI/1716194633162.png\" alt=\"1716194633162\" loading=\"lazy\"></p>\n<p>先验信息在机器学习中体现为正则化：</p>\n<p>2 范数正则化就是在认为模型参数服从高斯分布的先验假设情况下，利用 MAP 准则来估计参数。</p>\n<p>这也就是为什么正则化倾向于避免过拟合：高斯分布先验希望模型参数足够简单。</p>\n<p><img src=\"/../images/AI/1716194757145.png\" alt=\"1716194757145\" loading=\"lazy\"></p>\n<h3 id=\"Bayesian-Model-Averaging\"><a href=\"#Bayesian-Model-Averaging\" class=\"headerlink\" title=\"Bayesian Model Averaging\"></a>Bayesian Model Averaging</h3><p><img src=\"/../images/AI/1716195002371.png\" alt=\"1716195002371\" loading=\"lazy\"></p>\n<p>意义：模型集成。</p>\n<h3 id=\"Discriminative-Models\"><a href=\"#Discriminative-Models\" class=\"headerlink\" title=\"Discriminative Models\"></a>Discriminative Models</h3><p>上面的理论足够解释判别式模型的原理了。</p>\n<h3 id=\"Generative-Models\"><a href=\"#Generative-Models\" class=\"headerlink\" title=\"Generative Models\"></a>Generative Models</h3><p><img src=\"/../images/AI/1716195398036.png\" alt=\"1716195398036\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1716195442145.png\" alt=\"1716195442145\" loading=\"lazy\"></p>\n<h4 id=\"Naive-Bayes-Classifier\"><a href=\"#Naive-Bayes-Classifier\" class=\"headerlink\" title=\"Naive Bayes Classifier\"></a>Naive Bayes Classifier</h4><p>model $Y$ as a bernoulli distribution with parameters $p(y&#x3D;1)$ and $p(y&#x3D;-1)$</p>\n<p>conditional independence: each dimension is independent given label y</p>\n<div>$$\np(X=x|Y=y)=\\prod_{j=1}^dp(x_{\\cdot j}|y)\n$$</div>\n\n<p>Laplacian smoothing for 0 samples:</p>\n<div>$$\np(x_{\\cdot j}=r_j|Y=+1)=\\frac{\\sum_{i=1}^n1\\{x_{\\cdot j}=r_j\\wedge y_i=+1\\}+1}{\\sum_{i=1}^n1\\{y_i=+1\\}+k_j}\n$$</div>\n\n<p>For dataset with all continuous features: descretize it, or use another model based on a different assumption.</p>\n<h4 id=\"Guassian-Discriminant-Analysis\"><a href=\"#Guassian-Discriminant-Analysis\" class=\"headerlink\" title=\"Guassian Discriminant Analysis\"></a>Guassian Discriminant Analysis</h4><p>是一个生成模型！虽然它被用来分类，但是它的建模设计上采用的是生成式。</p>\n<p>For dataset with all continuous features:</p>\n<p>Using parametrice distribution to represent $P(X&#x3D;x|Y&#x3D;y)$</p>\n<p>A common assumption in classification:</p>\n<ul>\n<li>We always assume that data points in a class is a cluster.</li>\n</ul>\n<p>Still model $p(Y&#x3D;y)$ as Bernoulli distribution.</p>\n<div>$$\n\\text{So we can model }p(X=x|Y=y)\\text{ by Gaussian distribution:}\\\\p(X=x|Y=+1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{+})^{T}\\Sigma^{-1}(x-\\mu_{+})\\right)\\\\p(X=x|Y=-1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{-})^{T}\\Sigma^{-1}(x-\\mu_{-})\\right)\n$$</div>\n\n<p>Note the shared parameters $\\Sigma$ for positive and nagative classes.</p>\n<p>Use MLE to find the best solution:</p>\n<div>$$\n\\ell(\\phi,\\mu_+,\\mu_-,\\Sigma)=\\log\\prod_{i=1}^np(x_i,y_i;\\phi,\\mu_+,\\mu_-,\\Sigma)\\\\=\\log\\prod_{i=1}^np(x_i|y_i;\\mu_+,\\mu_-,\\Sigma)+\\boxed{\\log\\prod_{i=1}^np(y_i|\\phi)}\n$$</div>\n\n<p>Then:</p>\n<div>$$\n\\phi=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}}{n},\\mu_{+}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}},\\mu_{-}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}}\\\\\\boldsymbol{\\Sigma}=\\frac{1}{n}\\boldsymbol{\\Sigma}_{i=1}^{n}(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})^{T}\n$$</div>\n\n<h4 id=\"Discriminative-vs-Generative\"><a href=\"#Discriminative-vs-Generative\" class=\"headerlink\" title=\"Discriminative vs. Generative\"></a>Discriminative vs. Generative</h4><p><img src=\"/../images/AI/1716795753326.png\" alt=\"1716795753326\" loading=\"lazy\"></p>\n<h3 id=\"Mixture-Models-and-EM\"><a href=\"#Mixture-Models-and-EM\" class=\"headerlink\" title=\"Mixture Models and EM\"></a>Mixture Models and EM</h3><h4 id=\"Gaussian-Mixture-Model\"><a href=\"#Gaussian-Mixture-Model\" class=\"headerlink\" title=\"Gaussian Mixture Model\"></a>Gaussian Mixture Model</h4><p>A Generative model. More assumption than Logistic Regression.</p>\n<p><img src=\"/../images/AI/1716796053911.png\" alt=\"1716796053911\" loading=\"lazy\"></p>\n<p>Sample dataset from GMM:</p>\n<div>$$\np(x)=\\sum_{z=1}^k\\pi_z\\mathcal{N}(x|\\mu_z,\\Sigma_z)\n$$</div>\n\n<p>Compute log-likelihood:</p>\n<div>$$\n\\ell(\\boldsymbol{\\pi},\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})=\\log\\prod_{i=1}^n\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)\\right]\n$$</div>\n\n<div>$$\n\\ell(\\pi,\\mu,\\Sigma)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\frac{\\pi_z}{\\sqrt{|2\\pi\\Sigma_z|}}\\exp(-\\frac12(x_i-\\mu_z)^T\\Sigma^{-1}(x_i-\\mu_z))\\right]\n$$</div>\n\n<p>Intracable! Use EM method to estimate parameters.</p>\n<p>$z$ is latent variable.</p>\n<h4 id=\"Expectation-Maximization\"><a href=\"#Expectation-Maximization\" class=\"headerlink\" title=\"Expectation Maximization\"></a>Expectation Maximization</h4><p><img src=\"/../images/AI/1716797001550.png\" alt=\"1716797001550\" loading=\"lazy\"></p>\n<p>Learing Problem:</p>\n<p>find MLE</p>\n<div>$$\n\\widehat{\\theta}=\\underset{\\theta}{\\operatorname*{argmax\\ }}p(\\mathcal{D}|\\theta)\n$$</div>\n\n<p>Inference Promblem:</p>\n<p>Given $x$, find conditional variable of $z$:</p>\n<div>$$\np(z|x,\\theta)\n$$</div>\n\n<p>EM method is for both problems!</p>\n<p>it is hard to maximize the marginal likelihood directly:</p>\n<div>$$\n\\max_\\theta\\log p(x|\\theta)\n$$</div>\n\n<p>but the complete data log-likelihood is easy typically:</p>\n<div>$$\n\\max_\\theta\\log p(x, z|\\theta)\n$$</div>\n\n<p>if we had a distribution $q(z)$ for z:</p>\n<div>$$\n\\max_\\theta\\sum_zq(z)\\log p(x,z|\\theta)\n$$</div>\n\n<p>We have Evidence Lower Bound (ELBO):</p>\n<div>$$\n\\log p(x|\\theta)=\\log\\left[\\sum_zp(x,z|\\theta)\\right] \\ge \\underbrace{\\sum_zq(z)\\log(\\frac{p(x,z|\\theta)}{q(z)})}_{\\mathcal{L}(q,\\theta)}\n$$</div>\n\n<p>Now we optimize the ELBO iteratively:</p>\n<p><img src=\"/../images/AI/1716797936119.png\" alt=\"1716797936119\" loading=\"lazy\"></p>\n<p>The math background for ELBO:</p>\n<p><img src=\"/../images/AI/1716798247574.png\" alt=\"1716798247574\" loading=\"lazy\"></p>\n<p>We get back an equality for the marginal likelihood:</p>\n<div>$$\n\\log p(x|\\theta)=\\mathcal{L}(q,\\theta)+\\mathrm{KL}[q(z)||p(z|x,\\theta)]\n$$</div>\n\n<p>Evidence &#x3D; ELBO + KL-Divergence</p>\n<p>In E-step, if we want to maximize the ELBO without changing $\\theta$, we have to let KL be zero. Thus $q^*(z)&#x3D;p(z|x,\\theta)$</p>\n<p>For M-step, we find the $\\theta$ to maximize the ELBO.</p>\n<p><img src=\"/../images/AI/1716798687551.png\" alt=\"1716798687551\" loading=\"lazy\"></p>\n<p>In MAP case:</p>\n<p><img src=\"/../images/AI/1716798850106.png\" alt=\"1716798850106\" loading=\"lazy\"></p>\n<p>For GMM, E-step:</p>\n<p><img src=\"/../images/AI/1716798927981.png\" alt=\"1716798927981\" loading=\"lazy\"></p>\n<p>M-step:</p>\n<p><img src=\"/../images/AI/1716799063581.png\" alt=\"1716799063581\" loading=\"lazy\"></p>\n<p>Recommended Initialize:</p>\n<div>$$\n\\pi = 1/k\\\\\n\\mu = 0\\\\\n\\Sigma = \\sigma^2 I\n$$</div>\n\n<p>Variational Methods:</p>\n<p><img src=\"/../images/AI/1716799707301.png\" alt=\"1716799707301\" loading=\"lazy\"></p>\n<p>注意：E 步计算的是隐变量的后验（如果能计算出来），因为它是使得似然函数及ELBO最大的 $q(z)$。算不出来就用变分方法近似。</p>\n<p>$q(z)$ 既不是先验分布，也不是后验分布，它只是我们对隐变量分布的一种估计。</p>\n<h3 id=\"Probabilistic-Topic-Models\"><a href=\"#Probabilistic-Topic-Models\" class=\"headerlink\" title=\"Probabilistic Topic Models\"></a>Probabilistic Topic Models</h3><h4 id=\"Dirichlet-Multinomial-Model\"><a href=\"#Dirichlet-Multinomial-Model\" class=\"headerlink\" title=\"Dirichlet-Multinomial Model\"></a>Dirichlet-Multinomial Model</h4><p><img src=\"/../images/AI/1717400667281.png\" alt=\"1717400667281\" loading=\"lazy\"></p>\n<p>Beta Distribution:</p>\n<div>$$\nf(\\phi|\\alpha,\\beta)=\\frac1{B(\\alpha,\\beta)}\\phi^{\\alpha-1}(1-\\phi)^{\\beta-1}\n$$</div>\n\n<p>Dirichlet Multinomial Model: Multi-dimensional version of Beta Distribution</p>\n<div>$$\n\\boxed{p(\\vec{\\theta}|\\boldsymbol{\\alpha})}=\\frac1{B(\\boldsymbol{\\alpha})}\\prod_{k=1}^K\\theta_k^{\\alpha_k-1}\\quad\\text{Where }B(\\alpha)=\\frac{\\Pi_{k=1}^K\\Gamma(\\alpha_k)}{\\Gamma(\\sum_{k=1}^K\\alpha_k)}\n$$</div>\n\n<p>Conjugate prior:</p>\n<div>$$\n\\sum_{i=1}^K\\theta_i=1\n$$</div>\n\n<p><img src=\"/../images/AI/1717400854837.png\" alt=\"1717400854837\" loading=\"lazy\"></p>\n<p>Admixture:</p>\n<p><img src=\"/../images/AI/1717401031002.png\" alt=\"1717401031002\" loading=\"lazy\"></p>\n<p>Latent Dirichlet Allocation (LDA):</p>\n<p><img src=\"/../images/AI/1717401124879.png\" alt=\"1717401124879\" loading=\"lazy\"></p>\n<p>Probabilistic Graphical Models:</p>\n<p><img src=\"/../images/AI/1717401517265.png\" alt=\"1717401517265\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1717401591545.png\" alt=\"1717401591545\" loading=\"lazy\"></p>\n<p>Maximum Likelihood Estimation</p>\n<div>$$\n\\log p(\\beta,\\theta,z,w|\\alpha,\\eta)\\\\\n=\\sum_{k=1}^K\\log p(\\vec{\\beta}_k|\\eta)+\\sum_{d=1}^D\\log p(\\vec{\\theta}_d|\\alpha)+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(z_{d,n}|\\vec{\\theta}_d)\\\\\n +\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(w_{d,n}|z_{d,n},\\vec{\\boldsymbol{\\beta}}_{1:K})\\\\\n \\begin{aligned}\n&=\\sum_{k=1}^{K}\\left(\\sum_{v=1}^{V}(\\eta_{v}-1)\\log\\beta_{kv}-\\log B(\\eta)\\right)+\\sum_{d=1}^{D}\\sum_{k=1}^{K}(\\alpha_{k}-1)\\log\\theta_{dk}-\\log B(\\alpha) \\\\\n&+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\theta_{d,z_{d,n}}+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\beta_{z_{d,n}w_{d,n}}\n\\end{aligned}\n$$</div>\n\n<p>To learn the param $\\alpha, \\eta$, use EM method:</p>\n<p>In E-step, calculate </p>\n<div>$$\nq^*(z)=p(z|x,\\theta^{\\mathrm{old}})\n$$</div>\n\n<div>$$\np(\\theta,z,\\beta\\mid w,\\alpha,\\eta)=\\frac{p(\\theta,z,\\beta,w\\mid\\alpha,\\eta)}{p(w\\mid\\alpha,\\eta)}\n$$</div>\n\n<p>However, the denominator is intractable:</p>\n<div>$$\np(\\mathbf{w}|\\alpha,\\eta)=\\int\\int\\sum_\\mathbf{z}p(\\boldsymbol{\\theta},\\mathbf{z},\\boldsymbol{\\beta},\\mathbf{w}|\\boldsymbol{\\alpha},\\boldsymbol{\\eta})d\\boldsymbol{\\theta}d\\boldsymbol{\\beta}\n$$</div>\n\n<p>This problem is for general Bayesian models. We can use Variational Methods or Markov Chain Monte Carlo to solve it.</p>\n<h4 id=\"Variational-Methods\"><a href=\"#Variational-Methods\" class=\"headerlink\" title=\"Variational Methods\"></a>Variational Methods</h4><p><img src=\"/../images/AI/1717403664862.png\" alt=\"1717403664862\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1717403702542.png\" alt=\"1717403702542\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1717403725888.png\" alt=\"1717403725888\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1717404024479.png\" alt=\"1717404024479\" loading=\"lazy\"></p>\n<p>Use Mean field assumption in LDA:</p>\n<p><img src=\"/../images/AI/1717404907709.png\" alt=\"1717404907709\" loading=\"lazy\"></p>\n<p><img src=\"/../images/AI/1717404790783.png\" alt=\"1717404790783\" loading=\"lazy\"></p>\n<h3 id=\"Variational-Autoencoders-VAE\"><a href=\"#Variational-Autoencoders-VAE\" class=\"headerlink\" title=\"Variational Autoencoders (VAE)\"></a>Variational Autoencoders (VAE)</h3><p><img src=\"/../images/AI/1717405465141.png\" alt=\"1717405465141\" loading=\"lazy\"></p>\n<p>Reparameterization Trick: </p>\n<p><img src=\"/../images/AI/1717405435705.png\" alt=\"1717405435705\" loading=\"lazy\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Learning\"><a href=\"#Learning\" class=\"headerlink\" title=\"Learning\"></a>Learning</h2><h3 id=\"Linear-Classification\"><a href=\"#Linear-Classification\" class=\"headerlink\" title=\"Linear Classification\"></a>Linear Classification</h3><h4 id=\"Logistic-Regression\"><a href=\"#Logistic-Regression\" class=\"headerlink\" title=\"Logistic Regression\"></a>Logistic Regression</h4><p>Useful for classification problems.</p>\n<p>Cross-Entropy Loss</p>\n<div>$$\n\\ell(h(\\boldsymbol{x}_{i}),y_{i})=\\begin{cases}-\\log[\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=1\\\\-\\log[1-\\sigma(\\boldsymbol{w}^{T}\\boldsymbol{x}_{i})]&\\quad y_{i}=0\\end{cases}\n$$</div>\n\n<p>With regularization:</p>\n<div>$$\n\\hat{\\epsilon}(w)=-\\sum_{i=1}^n\\lbracey_i\\log\\sigma(h_w(x))+(1-y_i)\\log[1-\\sigma(h_w(x))]+\\lambda\\sum_{j=1}^dw_j^2\n$$</div>\n\n<p>How to deal with multiclass problems?</p>\n<h4 id=\"Softmax-Regression\"><a href=\"#Softmax-Regression\" class=\"headerlink\" title=\"Softmax Regression\"></a>Softmax Regression</h4><p>Normalizes multiple outputs in a probability vector.</p>\n<div>$$\np(y=i|x)=\\frac{\\exp(w_i^Tx)}{\\sum_{r=1}^C\\exp(w_r^Tx)}\n$$</div>\n\n<p>Cross-Entropy Loss</p>\n<div>$$\n\\ell(h(x_i),y_i)=\\begin{cases}-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_1^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=1\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_2^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=2\\\\\\vdots\\\\-\\log\\left[\\frac{\\exp(\\boldsymbol{w}_c^T\\boldsymbol{x})}{\\sum_{r=1}^C\\exp(\\boldsymbol{w}_r^T\\boldsymbol{x})}\\right]&y_i=C\\end{cases}\n$$</div>\n\n<p>This loss is convex. But there are many solutions that result in same outputs, so the regularizaton is indispensible to prevent divergence.</p>\n<p><img src=\"/../images/AI/1713166706648.png\" alt=\"1713166706648\"></p>\n<h3 id=\"Support-Vector-Machine-SVM\"><a href=\"#Support-Vector-Machine-SVM\" class=\"headerlink\" title=\"Support Vector Machine (SVM)\"></a>Support Vector Machine (SVM)</h3><h4 id=\"Soft-SVM-Hinge-Loss\"><a href=\"#Soft-SVM-Hinge-Loss\" class=\"headerlink\" title=\"Soft-SVM (Hinge Loss)\"></a>Soft-SVM (Hinge Loss)</h4><div>$$\n\\min_{w,b,\\xi}\\frac{1}{2}\\|w\\|_{2}^{2}+\\frac{C}{n}\\sum_{i=1}^{n}\\xi_{i}\\\\\\mathrm{s.t.~}y_i(\\boldsymbol{w}\\cdot\\boldsymbol{x}_i+b)\\geq1-\\xi_i\\\\\\xi_i\\geq0,1\\leq i\\leq n\n$$</div>\n\n<p>Define Hinge Loss</p>\n<div>$$\n\\ell(f(x),y)=\\max\\{0,1-yf(x)\\rbrace\n$$</div>\n\n<p>For the linear hypothesis:</p>\n<div>$$\n\\ell(f(x),y)=\\max\\{0,1-y(w\\cdot x+b)\\}\n$$</div>\n\n<p>Theorem: Soft-SVM is equivalent to a Regularized Rise Minimization:</p>\n<div>$$\n\\min_{w,b}\\frac12\\|w\\|_2^2+\\frac Cn\\sum_{i=1}^n\\max\\{0,1-y_i(w\\cdot x_i+b)\\}\n$$</div>\n\n<p>这意味着SVM的“最大化”边界距离项本质上是一个正则化项。</p>\n<h3 id=\"Kernel-Soft-SVM\"><a href=\"#Kernel-Soft-SVM\" class=\"headerlink\" title=\"Kernel Soft-SVM\"></a>Kernel Soft-SVM</h3><p>Basis function $\\Phi(x)$ can often replaced by kernal function $k(x_1, x_2)$.</p>\n<p>Polynomial Kernel: efficient computation: $O(d)$</p>\n<p><img src=\"/../images/AI/1713169419702.png\" alt=\"1713169419702\"></p>\n<p>Construct new kernel function from exist kernel functions:</p>\n<div>$$\nk^{\\prime}(x_{1},x_{2})=k_{1}\\otimes k_{2}(x_{1},x_{2})=k_{1}\n(x_{1},x_{2})k_{2}(x_{1},x_{2})\n$$</div>\n\n<p>For any function $g: \\mathcal X \\rightarrow \\R$</p>\n<div>$$\nk^\\prime(x_1,x_2)=g(x_1)k_1(x_1,x_2)g(x_2)\n$$</div>\n\n<p>Apply Representer theorem:</p>\n<div>$$\n\\min_\\alpha\\frac12\\alpha^TK\\alpha+\\frac Cn\\sum_{i=1}^n\\max\\left\\{0,1-y_i\\sum_{j=1}^n\\alpha_jk(x_i,x_j)\\right\\}\n$$</div>\n\n<ul>\n<li>$\\alpha_j$ is the weight of each reference point $\\color{red}{x_j}$ to the prediction of $\\color{red}{x_i}$.</li>\n<li>lt is actually a Primal Form with kernel functions.</li>\n</ul>\n<h3 id=\"Decision-Tree\"><a href=\"#Decision-Tree\" class=\"headerlink\" title=\"Decision Tree\"></a>Decision Tree</h3><p>Criterion:</p>\n<ul>\n<li>More balance</li>\n<li>More pure</li>\n</ul>\n<p>Misclassification error (not used very frequently):</p>\n<div>$$\n\\mathrm{Err}(\\mathcal{D})=1-\\max_{1\\leq k\\leq K}\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)\n$$</div>\n\n<p>Use Entropy to measure purity:</p>\n<div>$$\nH(\\mathcal{D})=-\\sum_{k=1}^K\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\mathrm{log}\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\n$$</div>\n\n<p>Gini Index:</p>\n<div>$$\n\\mathrm{Gini}(\\mathcal{D})=1-\\sum_{k=1}^K\\left(\\frac{|\\mathcal{C}_k|}{|\\mathcal{D}|}\\right)^2\n$$</div>\n\n<h4 id=\"ID3-Algorithm\"><a href=\"#ID3-Algorithm\" class=\"headerlink\" title=\"ID3 Algorithm\"></a>ID3 Algorithm</h4><p><img src=\"/../images/AI/1713171808270.png\" alt=\"1713171808270\"></p>\n<h3 id=\"Multiplayer-Perceptrons-MLP\"><a href=\"#Multiplayer-Perceptrons-MLP\" class=\"headerlink\" title=\"Multiplayer Perceptrons (MLP)\"></a>Multiplayer Perceptrons (MLP)</h3><h4 id=\"MLP-for-XOR\"><a href=\"#MLP-for-XOR\" class=\"headerlink\" title=\"MLP for XOR\"></a>MLP for XOR</h4><p><img src=\"/../images/AI/1713771652191.png\" alt=\"1713771652191\"></p>\n<h4 id=\"Activation\"><a href=\"#Activation\" class=\"headerlink\" title=\"Activation\"></a>Activation</h4><p><img src=\"/../images/AI/1713772489046.png\" alt=\"1713772489046\"></p>\n<h4 id=\"Loss-Functions\"><a href=\"#Loss-Functions\" class=\"headerlink\" title=\"Loss Functions\"></a>Loss Functions</h4><p>Entropy</p>\n<div>$$\nH(q)=-\\sum_{j=1}^kq_j\\log q_j\n$$</div>\n\n<p>Relative-entropy</p>\n<div>$$\n\\mathrm{KL}(q||p)=-\\sum_{j=1}^kq_j\\log p_j-H(q)\n$$</div>\n\n<p>Cross-entropy</p>\n<div>$$\nH(q,p)=-\\sum_{j=1}^kq_j\\log p_j\n$$</div>\n\n<p>Relationship:</p>\n<div>$$\n\\boxed{H(q,p)=\\mathrm{KL}(q||p)+H(q)}\n$$</div>\n\n<p>Softmax in the output layer</p>\n<div>$$\n\\widehat{\\boldsymbol{y}}=\\boldsymbol{a}^{(n_l)}=f_\\theta\\big(\\boldsymbol{x}^{(i)}\\big)=\\begin{bmatrix}p\\big(\\boldsymbol{y}^{(i)}=1\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\p\\big(\\boldsymbol{y}^{(i)}=2\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\\\\\vdots\\\\p\\big(\\boldsymbol{y}^{(i)}=k\\big|\\boldsymbol{x}^{(i)};\\boldsymbol{\\theta}\\big)\\end{bmatrix}=\\frac{1}{\\sum_{j=1}^{k}\\exp(z_{j}^{(n_{l})})}\\begin{bmatrix}\\exp(z_{1}^{(n_{l})})\\\\\\exp(z_{2}^{(n_{l})})\\\\\\vdots\\\\\\exp(z_{k}^{(n_{l})})\\end{bmatrix}\n$$</div>\n\n<p>Cross-entropy loss:</p>\n<div>$$\nJ(y,\\widehat{y})=-\\sum_{j=1}^ky_j\\log\\widehat{y}_j\n$$</div>\n\n<p>Cost function:</p>\n<div>$$\n\\min J(\\theta)=-\\frac1m\\sum_{i=1}^m\\left[\\sum_{j=1}^k\\mathbf{1}\\{y^{(i)}=j\\}\\mathrm{log}\\frac{\\exp(\\mathbf{z}_j^{(n_\\iota)})}{\\sum_{j^{\\prime}=1}^k\\exp(\\mathbf{z}_{j^{\\prime}}^{(n_\\iota)})}\\right]\n$$</div>\n\n<h4 id=\"Gradient-Based-Training\"><a href=\"#Gradient-Based-Training\" class=\"headerlink\" title=\"Gradient-Based Training\"></a>Gradient-Based Training</h4><div>$$\n\\arg\\min_\\theta O(\\mathcal{D};\\theta)=\\sum_{i=1}^mL\\left(y_i,f(x_i);\\theta\\right)+\\Omega(\\theta)\n$$</div>\n\n<p>Forward Propagation: to compute activations &amp; objective $J(\\theta)$</p>\n<p>Backward Propagation: Update paramters in all layers</p>\n<h5 id=\"Learning-Rate-decay\"><a href=\"#Learning-Rate-decay\" class=\"headerlink\" title=\"Learning Rate decay\"></a>Learning Rate decay</h5><p>Exponential decay strategy:</p>\n<div>$$\n\\eta = \\eta_0e^{kt}\n$$</div>\n\n<p>1&#x2F;t decay strategy:</p>\n<div>$$\n\\eta = \\eta_0/(1+kt)\n$$</div>\n\n<h5 id=\"Weight-Decay\"><a href=\"#Weight-Decay\" class=\"headerlink\" title=\"Weight Decay\"></a>Weight Decay</h5><p>L2 regularization:</p>\n<div>$$\n\\Omega(\\theta)=\\frac\\lambda2\\sum_{l=1}^{n_l-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(\\theta_{ji}^{(l)})^2\\\\\\frac\\partial{\\partial\\theta^{(l)}}\\Omega(\\theta)=\\lambda\\theta^{(l)}\n$$</div>\n\n<p>L1:</p>\n<div>$$\n\\Omega(\\theta)=\\lambda\\sum_{l=1}^{n_{l}-1}\\sum_{i=1}^{s_{l}}\\sum_{j=1}^{s_{l+1}}|\\theta_{ji}^{(l)}|\\\\\\frac{\\partial}{\\partial\\theta^{(l)}}\\Omega(\\theta)_{ji}=\\lambda(1_{\\theta_{ji}^{(l)}>0}-1_{\\theta_{ji}^{(l)}<0})\n$$</div>\n\n<p>一般不调。</p>\n<h5 id=\"Weight-Initialization\"><a href=\"#Weight-Initialization\" class=\"headerlink\" title=\"Weight Initialization\"></a>Weight Initialization</h5><p>Xavier initialization</p>\n<p>(Linear activations)</p>\n<div>$$\n\\mathrm{Var}(w)=1/n_{\\mathrm{in}}\n$$</div>\n\n<p>避免梯度爆炸或者消失；</p>\n<p>He initialization</p>\n<p>(ReLU activations)</p>\n<div>$$\n\\mathrm{Var}(w)=2/n_{\\mathrm{in}}\n$$</div>\n\n<p>因为 ReLU 删除了一半的信息。</p>\n<p><img src=\"/../images/AI/1713775669844.png\" alt=\"1713775669844\"></p>\n<h3 id=\"Convolutional-Neural-Network-CNN\"><a href=\"#Convolutional-Neural-Network-CNN\" class=\"headerlink\" title=\"Convolutional Neural Network (CNN)\"></a>Convolutional Neural Network (CNN)</h3><p><img src=\"/../images/AI/1713776156049.png\" alt=\"1713776156049\"></p>\n<p><img src=\"/../images/AI/1713776168789.png\" alt=\"1713776168789\"></p>\n<p><img src=\"/../images/AI/1714379943169.png\" alt=\"1714379943169\"></p>\n<h4 id=\"Convoluion-Kernel\"><a href=\"#Convoluion-Kernel\" class=\"headerlink\" title=\"Convoluion Kernel\"></a>Convoluion Kernel</h4><p><img src=\"/../images/AI/1714380111476.png\" alt=\"1714380111476\"></p>\n<p>Stride</p>\n<p><img src=\"/../images/AI/1714380132725.png\" alt=\"1714380132725\"></p>\n<p>Padding</p>\n<p><img src=\"/../images/AI/1714380159356.png\" alt=\"1714380159356\"></p>\n<p><img src=\"/../images/AI/1714380233071.png\" alt=\"1714380233071\"></p>\n<h4 id=\"Pooling\"><a href=\"#Pooling\" class=\"headerlink\" title=\"Pooling\"></a>Pooling</h4><p><img src=\"/../images/AI/1714380343254.png\" alt=\"1714380343254\"></p>\n<p>Batch Normalization</p>\n<p><img src=\"/../images/AI/1714379335929.png\" alt=\"1714379335929\"></p>\n<p>在 N 张图像的对应通道做归一化。</p>\n<p>可以增强训练的稳定性，使得学习率可以设大一点而仍然保证收敛。</p>\n<ul>\n<li>数据集成</li>\n<li>参数集成</li>\n<li>模型集成</li>\n</ul>\n<h4 id=\"ResNet\"><a href=\"#ResNet\" class=\"headerlink\" title=\"ResNet\"></a>ResNet</h4><p><img src=\"/../images/AI/1714380578105.png\" alt=\"1714380578105\"></p>\n<p><img src=\"/../images/AI/1714380763838.png\" alt=\"1714380763838\"></p>\n<p>最后一层 Global Average Pooling：7*7*2048 -&gt; 1* 1 * 2048</p>\n<h3 id=\"Recurrent-Neural-Network-RNN\"><a href=\"#Recurrent-Neural-Network-RNN\" class=\"headerlink\" title=\"Recurrent Neural Network (RNN)\"></a>Recurrent Neural Network (RNN)</h3><h4 id=\"Idea-for-Sequence-Modeling\"><a href=\"#Idea-for-Sequence-Modeling\" class=\"headerlink\" title=\"Idea for Sequence Modeling\"></a>Idea for Sequence Modeling</h4><p>Local Dependency</p>\n<p><img src=\"/../images/AI/1714982108981.png\" alt=\"1714982108981\"></p>\n<p>Parameter Sharing</p>\n<p><img src=\"/../images/AI/1714982133935.png\" alt=\"1714982133935\"></p>\n<h3 id=\"RNN\"><a href=\"#RNN\" class=\"headerlink\" title=\"RNN\"></a>RNN</h3><p><img src=\"/../images/AI/1714982188331.png\" alt=\"1714982188331\"></p>\n<p>Go deeper</p>\n<p><img src=\"/../images/AI/1714982215920.png\" alt=\"1714982215920\"></p>\n<h4 id=\"Standard-Architectures\"><a href=\"#Standard-Architectures\" class=\"headerlink\" title=\"Standard Architectures\"></a>Standard Architectures</h4><p><img src=\"/../images/AI/1714982075164.png\" alt=\"1714982075164\"></p>\n<ul>\n<li>RNNs can represent unbounded temporal dependencies</li>\n<li>RNNs encode histories of words into a fixed size hidden vector </li>\n<li>Parameter size does not grow with the length of dependencies</li>\n<li>RNNs are hard to learn long range dependencies present in data</li>\n</ul>\n<h4 id=\"LSTM\"><a href=\"#LSTM\" class=\"headerlink\" title=\"LSTM\"></a>LSTM</h4><p>Multihead, shared bottom.</p>\n<p><img src=\"/../images/AI/1714982405665.png\" alt=\"1714982405665\"></p>\n<p>Gradient flow highway: remember history very well.</p>\n<p>NIPS 2015 Highway Network.</p>\n<h4 id=\"Training-Strategies\"><a href=\"#Training-Strategies\" class=\"headerlink\" title=\"Training Strategies\"></a>Training Strategies</h4><p>Shift in Training &amp; Inference</p>\n<p><img src=\"/../images/AI/1714983390325.png\" alt=\"1714983390325\"></p>\n<p>Use Scheduled Sampling to solve this</p>\n<p><img src=\"/../images/AI/1714983452419.png\" alt=\"1714983452419\"></p>\n<p>Problem: Gradient Explosion during continuously multiplication.</p>\n<p>Solution: Gradient Clipping</p>\n<p><img src=\"/../images/AI/1714983641507.png\" alt=\"1714983641507\"></p>\n<p>Variational Dropout</p>\n<p><img src=\"/../images/AI/1714983788461.png\" alt=\"1714983788461\"></p>\n<p>Layer Normalization</p>\n<p><img src=\"/../images/AI/1714983988587.png\" alt=\"1714983988587\"></p>\n<p>BN: Easy to compare between channels</p>\n<p>LN: Easy to compare between samples</p>\n<p>在图像任务上，我们一般认为 channel 之间的地位应该是相同的，因此常常采用 BN。</p>\n<h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p>use attention to replace state space.</p>\n<p><img src=\"/../images/AI/1714984460020.png\" alt=\"1714984460020\"></p>\n<h4 id=\"Attention\"><a href=\"#Attention\" class=\"headerlink\" title=\"Attention\"></a>Attention</h4><p><img src=\"/../images/AI/1714984778231.png\" alt=\"1714984778231\"></p>\n<div>$$\n\\text{Attention}(Q,K,V)=\\text{Softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n$$</div>\n\n<p>Multi-Head Attention</p>\n<p><img src=\"/../images/AI/1714985419724.png\" alt=\"1714985419724\"></p>\n<p>Sparse?</p>\n<p>$W^o$ to maintain shape and jointly attend to information from different representation subspaces.</p>\n<h4 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h4><p>Position-wise FFN (Similar to multi convolution kernels in CNN, shared parameters in every word.)</p>\n<p><img src=\"/../images/AI/1714985971187.png\" alt=\"1714985971187\"></p>\n<h4 id=\"Positional-Encoding\"><a href=\"#Positional-Encoding\" class=\"headerlink\" title=\"Positional Encoding\"></a>Positional Encoding</h4><p><img src=\"/../images/AI/1714986050538.png\" alt=\"1714986050538\"></p>\n<h2 id=\"Reasoning\"><a href=\"#Reasoning\" class=\"headerlink\" title=\"Reasoning\"></a>Reasoning</h2><p>Reasoning (Probabilistic) &#x3D; Modeling + Inference</p>\n<p>Modeling:</p>\n<ul>\n<li>Bayesian Networks</li>\n<li>Markov random fields</li>\n</ul>\n<p>Inference:</p>\n<ul>\n<li>Elimination methods (变量消除法)</li>\n<li>Latent variable models (因变量模型)</li>\n<li>Variational methods (变分方法)</li>\n<li>Sampling methods (采样方法) - 难学！</li>\n</ul>\n<h3 id=\"Bayesian-Network\"><a href=\"#Bayesian-Network\" class=\"headerlink\" title=\"Bayesian Network\"></a>Bayesian Network</h3><div>$$\np(x_1,...,x_K)=p(x_K|x_1,...,x_{K-1})\\cdots p(x_2|x_1)p(x_1)\n$$</div>\n\n<h4 id=\"Variable-Elimination\"><a href=\"#Variable-Elimination\" class=\"headerlink\" title=\"Variable Elimination\"></a>Variable Elimination</h4><p>用于计算概率的边缘分布</p>\n<p><img src=\"/../images/AI/1716191759894.png\" alt=\"1716191759894\"></p>\n<p>一般而言是 NP-hard 问题。</p>\n<p>对于 Markov chain，复杂度为 $O(nk^2)$；对于一般的图，$O(k^{n-1})$；如果确定每个节点的父节点数不超过 m，则复杂度为 $O(nk^{m-1})$</p>\n<h4 id=\"Message-Passing\"><a href=\"#Message-Passing\" class=\"headerlink\" title=\"Message Passing\"></a>Message Passing</h4><p>Reuse the computation from $P(Y|E&#x3D;e)$ when calcuating another probability $P(Y_1|E_1&#x3D;e_1)$</p>\n<p><img src=\"/../images/AI/1716192135361.png\" alt=\"1716192135361\"></p>\n<p><img src=\"/../images/AI/1716192175996.png\" alt=\"1716192175996\"></p>\n<p>“$\\propto$” 意味着只需要知道概率的相对值就够了，因为可以通过归一化算出最终的概率值。</p>\n<p>MAP 需要求概率分布的最大值。</p>\n<p>sum 与 max 同为聚合操作，因此同样满足分配律，只需要对应替换就可以得到第二种 Message Passing：</p>\n<p><img src=\"/../images/AI/1716192534058.png\" alt=\"1716192534058\"></p>\n<p><img src=\"/../images/AI/1716192519850.png\" alt=\"1716192519850\"></p>\n<p><img src=\"/../images/AI/1716193180893.png\" alt=\"1716193180893\"></p>\n<h3 id=\"Bayes-Approach\"><a href=\"#Bayes-Approach\" class=\"headerlink\" title=\"Bayes Approach\"></a>Bayes Approach</h3><p><img src=\"/../images/AI/1716193473766.png\" alt=\"1716193473766\"></p>\n<h3 id=\"MLE-method\"><a href=\"#MLE-method\" class=\"headerlink\" title=\"MLE method\"></a>MLE method</h3><p>如果概率模型的参数知道，称为概率；不知道，称为统计推断。</p>\n<p>估计高斯分布的参数：</p>\n<p>方差是有偏估计，所以一般× $1&#x2F;(n-1)$。</p>\n<p><img src=\"/../images/AI/1716194228666.png\" alt=\"1716194228666\"></p>\n<h3 id=\"Bayes-Decision-Rule\"><a href=\"#Bayes-Decision-Rule\" class=\"headerlink\" title=\"Bayes Decision Rule\"></a>Bayes Decision Rule</h3><p><img src=\"/../images/AI/1716194320872.png\" alt=\"1716194320872\"></p>\n<p>对于回归问题，可以采用高斯噪声假设：</p>\n<p><img src=\"/../images/AI/1716194583833.png\" alt=\"1716194583833\"></p>\n<p>这样就得到了最小二乘估计。</p>\n<p>MLE 是先验概率相等的 MAP。</p>\n<p>放在机器学习中，MAP 可以定义为：模型 &#x3D; 数据 + 先验。</p>\n<p><img src=\"/../images/AI/1716194633162.png\" alt=\"1716194633162\"></p>\n<p>先验信息在机器学习中体现为正则化：</p>\n<p>2 范数正则化就是在认为模型参数服从高斯分布的先验假设情况下，利用 MAP 准则来估计参数。</p>\n<p>这也就是为什么正则化倾向于避免过拟合：高斯分布先验希望模型参数足够简单。</p>\n<p><img src=\"/../images/AI/1716194757145.png\" alt=\"1716194757145\"></p>\n<h3 id=\"Bayesian-Model-Averaging\"><a href=\"#Bayesian-Model-Averaging\" class=\"headerlink\" title=\"Bayesian Model Averaging\"></a>Bayesian Model Averaging</h3><p><img src=\"/../images/AI/1716195002371.png\" alt=\"1716195002371\"></p>\n<p>意义：模型集成。</p>\n<h3 id=\"Discriminative-Models\"><a href=\"#Discriminative-Models\" class=\"headerlink\" title=\"Discriminative Models\"></a>Discriminative Models</h3><p>上面的理论足够解释判别式模型的原理了。</p>\n<h3 id=\"Generative-Models\"><a href=\"#Generative-Models\" class=\"headerlink\" title=\"Generative Models\"></a>Generative Models</h3><p><img src=\"/../images/AI/1716195398036.png\" alt=\"1716195398036\"></p>\n<p><img src=\"/../images/AI/1716195442145.png\" alt=\"1716195442145\"></p>\n<h4 id=\"Naive-Bayes-Classifier\"><a href=\"#Naive-Bayes-Classifier\" class=\"headerlink\" title=\"Naive Bayes Classifier\"></a>Naive Bayes Classifier</h4><p>model $Y$ as a bernoulli distribution with parameters $p(y&#x3D;1)$ and $p(y&#x3D;-1)$</p>\n<p>conditional independence: each dimension is independent given label y</p>\n<div>$$\np(X=x|Y=y)=\\prod_{j=1}^dp(x_{\\cdot j}|y)\n$$</div>\n\n<p>Laplacian smoothing for 0 samples:</p>\n<div>$$\np(x_{\\cdot j}=r_j|Y=+1)=\\frac{\\sum_{i=1}^n1\\{x_{\\cdot j}=r_j\\wedge y_i=+1\\}+1}{\\sum_{i=1}^n1\\{y_i=+1\\}+k_j}\n$$</div>\n\n<p>For dataset with all continuous features: descretize it, or use another model based on a different assumption.</p>\n<h4 id=\"Guassian-Discriminant-Analysis\"><a href=\"#Guassian-Discriminant-Analysis\" class=\"headerlink\" title=\"Guassian Discriminant Analysis\"></a>Guassian Discriminant Analysis</h4><p>是一个生成模型！虽然它被用来分类，但是它的建模设计上采用的是生成式。</p>\n<p>For dataset with all continuous features:</p>\n<p>Using parametrice distribution to represent $P(X&#x3D;x|Y&#x3D;y)$</p>\n<p>A common assumption in classification:</p>\n<ul>\n<li>We always assume that data points in a class is a cluster.</li>\n</ul>\n<p>Still model $p(Y&#x3D;y)$ as Bernoulli distribution.</p>\n<div>$$\n\\text{So we can model }p(X=x|Y=y)\\text{ by Gaussian distribution:}\\\\p(X=x|Y=+1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{+})^{T}\\Sigma^{-1}(x-\\mu_{+})\\right)\\\\p(X=x|Y=-1)\\propto\\exp\\left(-\\frac{1}{2}(x-\\mu_{-})^{T}\\Sigma^{-1}(x-\\mu_{-})\\right)\n$$</div>\n\n<p>Note the shared parameters $\\Sigma$ for positive and nagative classes.</p>\n<p>Use MLE to find the best solution:</p>\n<div>$$\n\\ell(\\phi,\\mu_+,\\mu_-,\\Sigma)=\\log\\prod_{i=1}^np(x_i,y_i;\\phi,\\mu_+,\\mu_-,\\Sigma)\\\\=\\log\\prod_{i=1}^np(x_i|y_i;\\mu_+,\\mu_-,\\Sigma)+\\boxed{\\log\\prod_{i=1}^np(y_i|\\phi)}\n$$</div>\n\n<p>Then:</p>\n<div>$$\n\\phi=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}}{n},\\mu_{+}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=+1\\}},\\mu_{-}=\\frac{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}x_{i}}{\\sum_{i=1}^{n}1\\{y_{i}=-1\\}}\\\\\\boldsymbol{\\Sigma}=\\frac{1}{n}\\boldsymbol{\\Sigma}_{i=1}^{n}(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu}_{\\boldsymbol{y}_{i}})^{T}\n$$</div>\n\n<h4 id=\"Discriminative-vs-Generative\"><a href=\"#Discriminative-vs-Generative\" class=\"headerlink\" title=\"Discriminative vs. Generative\"></a>Discriminative vs. Generative</h4><p><img src=\"/../images/AI/1716795753326.png\" alt=\"1716795753326\"></p>\n<h3 id=\"Mixture-Models-and-EM\"><a href=\"#Mixture-Models-and-EM\" class=\"headerlink\" title=\"Mixture Models and EM\"></a>Mixture Models and EM</h3><h4 id=\"Gaussian-Mixture-Model\"><a href=\"#Gaussian-Mixture-Model\" class=\"headerlink\" title=\"Gaussian Mixture Model\"></a>Gaussian Mixture Model</h4><p>A Generative model. More assumption than Logistic Regression.</p>\n<p><img src=\"/../images/AI/1716796053911.png\" alt=\"1716796053911\"></p>\n<p>Sample dataset from GMM:</p>\n<div>$$\np(x)=\\sum_{z=1}^k\\pi_z\\mathcal{N}(x|\\mu_z,\\Sigma_z)\n$$</div>\n\n<p>Compute log-likelihood:</p>\n<div>$$\n\\ell(\\boldsymbol{\\pi},\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})=\\log\\prod_{i=1}^n\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\pi_z\\mathcal{N}(\\boldsymbol{x}_i|\\boldsymbol{\\mu}_z,\\boldsymbol{\\Sigma}_z)\\right]\n$$</div>\n\n<div>$$\n\\ell(\\pi,\\mu,\\Sigma)=\\sum_{i=1}^n\\log\\left[\\sum_{z=1}^k\\frac{\\pi_z}{\\sqrt{|2\\pi\\Sigma_z|}}\\exp(-\\frac12(x_i-\\mu_z)^T\\Sigma^{-1}(x_i-\\mu_z))\\right]\n$$</div>\n\n<p>Intracable! Use EM method to estimate parameters.</p>\n<p>$z$ is latent variable.</p>\n<h4 id=\"Expectation-Maximization\"><a href=\"#Expectation-Maximization\" class=\"headerlink\" title=\"Expectation Maximization\"></a>Expectation Maximization</h4><p><img src=\"/../images/AI/1716797001550.png\" alt=\"1716797001550\"></p>\n<p>Learing Problem:</p>\n<p>find MLE</p>\n<div>$$\n\\widehat{\\theta}=\\underset{\\theta}{\\operatorname*{argmax\\ }}p(\\mathcal{D}|\\theta)\n$$</div>\n\n<p>Inference Promblem:</p>\n<p>Given $x$, find conditional variable of $z$:</p>\n<div>$$\np(z|x,\\theta)\n$$</div>\n\n<p>EM method is for both problems!</p>\n<p>it is hard to maximize the marginal likelihood directly:</p>\n<div>$$\n\\max_\\theta\\log p(x|\\theta)\n$$</div>\n\n<p>but the complete data log-likelihood is easy typically:</p>\n<div>$$\n\\max_\\theta\\log p(x, z|\\theta)\n$$</div>\n\n<p>if we had a distribution $q(z)$ for z:</p>\n<div>$$\n\\max_\\theta\\sum_zq(z)\\log p(x,z|\\theta)\n$$</div>\n\n<p>We have Evidence Lower Bound (ELBO):</p>\n<div>$$\n\\log p(x|\\theta)=\\log\\left[\\sum_zp(x,z|\\theta)\\right] \\ge \\underbrace{\\sum_zq(z)\\log(\\frac{p(x,z|\\theta)}{q(z)})}_{\\mathcal{L}(q,\\theta)}\n$$</div>\n\n<p>Now we optimize the ELBO iteratively:</p>\n<p><img src=\"/../images/AI/1716797936119.png\" alt=\"1716797936119\"></p>\n<p>The math background for ELBO:</p>\n<p><img src=\"/../images/AI/1716798247574.png\" alt=\"1716798247574\"></p>\n<p>We get back an equality for the marginal likelihood:</p>\n<div>$$\n\\log p(x|\\theta)=\\mathcal{L}(q,\\theta)+\\mathrm{KL}[q(z)||p(z|x,\\theta)]\n$$</div>\n\n<p>Evidence &#x3D; ELBO + KL-Divergence</p>\n<p>In E-step, if we want to maximize the ELBO without changing $\\theta$, we have to let KL be zero. Thus $q^*(z)&#x3D;p(z|x,\\theta)$</p>\n<p>For M-step, we find the $\\theta$ to maximize the ELBO.</p>\n<p><img src=\"/../images/AI/1716798687551.png\" alt=\"1716798687551\"></p>\n<p>In MAP case:</p>\n<p><img src=\"/../images/AI/1716798850106.png\" alt=\"1716798850106\"></p>\n<p>For GMM, E-step:</p>\n<p><img src=\"/../images/AI/1716798927981.png\" alt=\"1716798927981\"></p>\n<p>M-step:</p>\n<p><img src=\"/../images/AI/1716799063581.png\" alt=\"1716799063581\"></p>\n<p>Recommended Initialize:</p>\n<div>$$\n\\pi = 1/k\\\\\n\\mu = 0\\\\\n\\Sigma = \\sigma^2 I\n$$</div>\n\n<p>Variational Methods:</p>\n<p><img src=\"/../images/AI/1716799707301.png\" alt=\"1716799707301\"></p>\n<p>注意：E 步计算的是隐变量的后验（如果能计算出来），因为它是使得似然函数及ELBO最大的 $q(z)$。算不出来就用变分方法近似。</p>\n<p>$q(z)$ 既不是先验分布，也不是后验分布，它只是我们对隐变量分布的一种估计。</p>\n<h3 id=\"Probabilistic-Topic-Models\"><a href=\"#Probabilistic-Topic-Models\" class=\"headerlink\" title=\"Probabilistic Topic Models\"></a>Probabilistic Topic Models</h3><h4 id=\"Dirichlet-Multinomial-Model\"><a href=\"#Dirichlet-Multinomial-Model\" class=\"headerlink\" title=\"Dirichlet-Multinomial Model\"></a>Dirichlet-Multinomial Model</h4><p><img src=\"/../images/AI/1717400667281.png\" alt=\"1717400667281\"></p>\n<p>Beta Distribution:</p>\n<div>$$\nf(\\phi|\\alpha,\\beta)=\\frac1{B(\\alpha,\\beta)}\\phi^{\\alpha-1}(1-\\phi)^{\\beta-1}\n$$</div>\n\n<p>Dirichlet Multinomial Model: Multi-dimensional version of Beta Distribution</p>\n<div>$$\n\\boxed{p(\\vec{\\theta}|\\boldsymbol{\\alpha})}=\\frac1{B(\\boldsymbol{\\alpha})}\\prod_{k=1}^K\\theta_k^{\\alpha_k-1}\\quad\\text{Where }B(\\alpha)=\\frac{\\Pi_{k=1}^K\\Gamma(\\alpha_k)}{\\Gamma(\\sum_{k=1}^K\\alpha_k)}\n$$</div>\n\n<p>Conjugate prior:</p>\n<div>$$\n\\sum_{i=1}^K\\theta_i=1\n$$</div>\n\n<p><img src=\"/../images/AI/1717400854837.png\" alt=\"1717400854837\"></p>\n<p>Admixture:</p>\n<p><img src=\"/../images/AI/1717401031002.png\" alt=\"1717401031002\"></p>\n<p>Latent Dirichlet Allocation (LDA):</p>\n<p><img src=\"/../images/AI/1717401124879.png\" alt=\"1717401124879\"></p>\n<p>Probabilistic Graphical Models:</p>\n<p><img src=\"/../images/AI/1717401517265.png\" alt=\"1717401517265\"></p>\n<p><img src=\"/../images/AI/1717401591545.png\" alt=\"1717401591545\"></p>\n<p>Maximum Likelihood Estimation</p>\n<div>$$\n\\log p(\\beta,\\theta,z,w|\\alpha,\\eta)\\\\\n=\\sum_{k=1}^K\\log p(\\vec{\\beta}_k|\\eta)+\\sum_{d=1}^D\\log p(\\vec{\\theta}_d|\\alpha)+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(z_{d,n}|\\vec{\\theta}_d)\\\\\n +\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log p(w_{d,n}|z_{d,n},\\vec{\\boldsymbol{\\beta}}_{1:K})\\\\\n \\begin{aligned}\n&=\\sum_{k=1}^{K}\\left(\\sum_{v=1}^{V}(\\eta_{v}-1)\\log\\beta_{kv}-\\log B(\\eta)\\right)+\\sum_{d=1}^{D}\\sum_{k=1}^{K}(\\alpha_{k}-1)\\log\\theta_{dk}-\\log B(\\alpha) \\\\\n&+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\theta_{d,z_{d,n}}+\\sum_{d=1}^D\\sum_{n=1}^{N_d}\\log\\beta_{z_{d,n}w_{d,n}}\n\\end{aligned}\n$$</div>\n\n<p>To learn the param $\\alpha, \\eta$, use EM method:</p>\n<p>In E-step, calculate </p>\n<div>$$\nq^*(z)=p(z|x,\\theta^{\\mathrm{old}})\n$$</div>\n\n<div>$$\np(\\theta,z,\\beta\\mid w,\\alpha,\\eta)=\\frac{p(\\theta,z,\\beta,w\\mid\\alpha,\\eta)}{p(w\\mid\\alpha,\\eta)}\n$$</div>\n\n<p>However, the denominator is intractable:</p>\n<div>$$\np(\\mathbf{w}|\\alpha,\\eta)=\\int\\int\\sum_\\mathbf{z}p(\\boldsymbol{\\theta},\\mathbf{z},\\boldsymbol{\\beta},\\mathbf{w}|\\boldsymbol{\\alpha},\\boldsymbol{\\eta})d\\boldsymbol{\\theta}d\\boldsymbol{\\beta}\n$$</div>\n\n<p>This problem is for general Bayesian models. We can use Variational Methods or Markov Chain Monte Carlo to solve it.</p>\n<h4 id=\"Variational-Methods\"><a href=\"#Variational-Methods\" class=\"headerlink\" title=\"Variational Methods\"></a>Variational Methods</h4><p><img src=\"/../images/AI/1717403664862.png\" alt=\"1717403664862\"></p>\n<p><img src=\"/../images/AI/1717403702542.png\" alt=\"1717403702542\"></p>\n<p><img src=\"/../images/AI/1717403725888.png\" alt=\"1717403725888\"></p>\n<p><img src=\"/../images/AI/1717404024479.png\" alt=\"1717404024479\"></p>\n<p>Use Mean field assumption in LDA:</p>\n<p><img src=\"/../images/AI/1717404907709.png\" alt=\"1717404907709\"></p>\n<p><img src=\"/../images/AI/1717404790783.png\" alt=\"1717404790783\"></p>\n<h3 id=\"Variational-Autoencoders-VAE\"><a href=\"#Variational-Autoencoders-VAE\" class=\"headerlink\" title=\"Variational Autoencoders (VAE)\"></a>Variational Autoencoders (VAE)</h3><p><img src=\"/../images/AI/1717405465141.png\" alt=\"1717405465141\"></p>\n<p>Reparameterization Trick: </p>\n<p><img src=\"/../images/AI/1717405435705.png\" alt=\"1717405435705\"></p>\n"},{"title":"Principle of Antenna","katex":true,"date":"2024-03-01T06:14:50.000Z","_content":"## Introduction of Antenna\n\nDefinition of Antenna\n\n* Transmitter and receiver of EM wave\n* Signal from current to wave\n* from lumped to distributed\n\nAntenna classifications\n\n* Resonant and non-resonant/leaky/travelling wave\n* Antenna number: element, multiple antennas, array\n* Shape: wire, loop, slot, patch/microstrip, cavity\n* Materials: metallic, dielectric\n* Property: wideband, narrow band\n* Yagi-Uda, Vivaldi, Cassegrain\n* Function: moblie/handset, base station, AiP\n\n## Maxwell equations\n\n$$\n\\nabla \\cdot \\vec D = \\rho \\rightarrow \\nabla \\cdot \\tilde{\\vec D} = \\rho \\\\\n\\nabla \\cdot {\\vec B} = 0 \\rarr \\nabla \\cdot \\tilde{\\vec B} = 0\\\\\n\\nabla \\times {\\vec E} = -\\frac{\\partial \\vec B}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec E} = -j\\omega \\tilde{\\vec B}\\\\\n\\nabla \\times {\\vec H} = \\vec J + \\frac{\\partial \\vec D}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec H} = \\vec J + j\\omega \\tilde{\\vec D}\\\\\n\\vec D = \\varepsilon \\vec E\\\\\n\\vec B = \\mu \\vec H\n$$\n\n$$\n\\nabla^2 \\vec F = \\nabla(\\nabla \\cdot \\vec F) - \\nabla \\times (\\nabla \\times \\vec F)\\\\\n\\nabla \\times (\\nabla f) = 0\\\\\n\\nabla \\cdot (\\nabla \\times \\vec F) = 0\n$$\n\n## Auxiliary Potential Functions\n\nLet\n\n$$\n\\vec B = \\nabla \\times \\vec A\\\\\n\\vec E + j\\omega \\vec A = -\\nabla \\phi\n$$\n\n$$\n\\nabla \\cdot \\vec D = \\varepsilon \\nabla \\cdot(-\\nabla \\phi  - j\\omega \\vec A) = \\rho\\\\\n\\Rightarrow \\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon} - j\\omega(\\nabla \\cdot \\vec A + j\\omega \\mu \\varepsilon \\phi)\n$$\n\n$$\n\\nabla \\times \\vec H = \\frac{1}{\\mu}(\\nabla(\\nabla \\cdot \\vec A) - \\nabla^2\\vec A) = \\vec J + j\\omega \\vec D = \\vec J + j\\omega\\varepsilon(-\\nabla\\phi - j\\omega \\vec A)\\\\\n\\Rightarrow \\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J - \\nabla(\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi)\n$$\n\nUse Lorentz Gauge\n\n$$\n\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi = 0\n$$\n\nThen\n\n$$\n\\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J\\\\\n\\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon}\n$$\n\nSolve ODE:\n\n$$\n\\begin{equation}  \n\\nabla^2\\phi + k^2\\phi = 0(r\\ne 0)\n\\end{equation}\\\\\n\\begin{equation}\n\\nabla^2\\phi + k^2\\phi = -\\frac{\\rho}{\\varepsilon}(r=0)\n\\end{equation}\n$$\n\nFor (1)\n\n$$\nu(r) = \\frac{\\phi(r)}{r}\\\\\n\\frac{\\rm{d}^2}{\\rm{d}r^2}u + k^2u = 0\\\\\nu = C_1e^{-jkr} + C_2e^{jkr}\\\\\n\\phi = C_1\\frac{e^{-jkr}}{r}\n$$\n\nFor (2), in arbitrary volume\n\n$$\n\\iiint_V(\\nabla^2\\phi + k^2\\phi)\\mathrm dv = \\iiint_V(-\\frac{\\rho}{\\varepsilon}\\mathrm dv) = -\\frac{q}{\\varepsilon}\\\\\nr \\rightarrow 0\\\\\n\\iiint_V(k^2\\phi)\\mathrm dv = 0\\\\\n\\iiint_V\\nabla^2\\phi \\mathrm dv = \\oiint_S \\nabla\\phi \\cdot \\mathrm d\\vec s = C_1 \\oiint_S (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})\\mathrm d\\vec s = C_1 (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})4\\pi r^2 = -C_1 4\\pi\n$$\n\nFinally,\n\n$$\n\\phi(r) = \\frac{q}{4\\pi\\varepsilon}\\frac{e^{-jkr}}{r}\n$$\n\n## Radiation Parameters\n\n### Field Zone\n\nNear field: resonant, field;\n\nFar field: propagation, wave;\n\nFresnel region: transition;\n\n![1711090268476](../images/Antenna/1711090268476.png)\n\n### Antenna Parameters\n\n* Radiation patterns\n* Radiation Intensity\n* Power Density\n* Directivity (方向性) and Gain (重要！)\n* Polarization\n* Effective Aperture(等效口面) and Aperture efficienty(口面效率)\n\nE 面：与电场方向平行的面\n\nH 面：与磁场方向平行的面\n\n#### Pattern Parameters\n\n![1711090565574](../images/Antenna/1711090565574.png)\n\nOften use log scale.\n\n#### Power Density\n\nInstantaneous Poynting vector $\\vec S(x, y, z, t)$\n\nRadiation Power Density = Time average Poynting vector $\\vec S_{av}(x, y, z)=\\frac1T\\int_0^T\\vec S(x, y, z, t)\\mathrm dt = \\frac12\\text{Re}[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}]$\n\nTotal Radiation Power $P_{rad} = \\oiint_S[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}] \\cdot \\mathrm d\\vec s$\n\n#### Radiation Intensity\n\n$$\nU(\\theta, \\varphi) = r^2 S(r, \\theta, \\varphi)\n$$\n\nIsotropic 各向同性\n\n$$\nP_{rad} = \\int_{0}^{2\\pi}\\int_{0}^{\\pi}U\\sin\\theta\\mathrm d\\theta\\mathrm d\\varphi\n$$\n\n#### Directivity\n\n$$\nD = \\frac{U_{\\max}}{U_{av}} = \\frac{P_{\\max}}{P_{rad}/4\\pi}\n$$\n\n![1711091202619](../images/Antenna/1711091202619.png)\n\n![1711091212947](../images/Antenna/1711091212947.png)\n\n![1711693683771](../images/Antenna/1711693683771.png)\n\n![1711693701192](../images/Antenna/1711693701192.png)\n\n#### Gain\n\n![1711693749686](../images/Antenna/1711693749686.png)\n\n$$\nG = \\frac{U_{\\max}}{P_{in}/4\\pi}\n$$\n\n#### Polarization\n\n![1711693845822](../images/Antenna/1711693845822.png)\n\nPolarization Mismatch:\n\n![1711693861642](../images/Antenna/1711693861642.png)\n\nCP\n\n![1711693936592](../images/Antenna/1711693936592.png)\n\n#### Effective Aperture and Aperture efficiency\n\n![1711694027177](../images/Antenna/1711694027177.png)\n\n![1711694083583](../images/Antenna/1711694083583.png)\n\n### Circuit Parameters\n\n#### Input impedance\n\nInput impedance definition:\n\n* the impedance presented by an antenna at its terminals\n* the ratio of the voltage to current at its terminals\n* the ratio of the electric to magnetic fields at its terminals\n\n![1711694243897](../images/Antenna/1711694243897.png)\n\n##### Conjugate Matching\n\n$$\nZ_A = Z_g^*\n$$\n\n##### Mismatching\n\n![1711694350257](../images/Antenna/1711694350257.png)\n\n##### Radiation Resistance\n\n$$\nP_{rad} = \\frac12|I_g|^2R_r = \\oiint_S\\vec S_{av} \\cdot \\rm d\\vec s\n$$\n\n![1711694462059](../images/Antenna/1711694462059.png)\n\n#### Scattering Parameters\n\n![1711694619870](../images/Antenna/1711694619870.png)\n\n$$\n\\frac{\\Gamma^2}{Z_1} + \\frac{T^2}{Z_2} = 1\n$$\n\n![1711694639638](../images/Antenna/1711694639638.png)\n\n![1711695738159](../images/Antenna/1711695738159.png)\n\n二端口网络通常用于描述二天线问题。$S_{11}$表示天线1的反射，$S_{21}$表示天线1到天线2的耦合，均不利于信号的传播。我们希望让$1 - S_{11}^2 - S_{21}^2$尽可能大。\n\n## Link Calculation\n\n### Friis's Equation\n\n![1712471419276](../images/Antenna/1712471419276.png)\n\n![1712471436962](../images/Antenna/1712471436962.png)\n\n### EIRP\n\n![1712471499226](../images/Antenna/1712471499226.png)\n\n赫兹偶极子的辐射电阻： $80\\pi^2(\\frac{\\Delta z}{\\lambda})^2$，方向性 $\\frac{2}{3}$。\n\n### Radar Equation\n\n![1712473473687](../images/Antenna/1712473473687.png)\n\nRCS(Radar cross section)\n\nRCS (σ) of a radar target is an effective area that intercepts the transmitted radar power and then\nscatters that power isotropically back to the radar receiver.\n\n$$\n\\sigma=\\lim_{R\\to\\infty}\\frac{W_{o}4\\pi R^2}{W_i}\n$$\n\n* $W_i$, $W_o$ and $R$ are known;\n* $\\sigma$ converges.\n\n## Antenna Theorems\n\n\n$$\n\\boxed{P_r=\\mathrm{P}_t\\mathrm{G}_t\\mathrm{G}_r(\\frac{\\lambda}{4\\pi R})^2}\n$$\n\n$$\nP_{r}=P_{t}\\mathrm{e}_{r}\\mathrm{e}_{t}D_{r}\\mathrm{D}_{t}(1-\\left|\\Gamma_{r}\\right|^{2})(1-\\left|\\Gamma_{t}\\right|^{2})(\\frac{\\lambda}{4\\pi R})^{2}\n$$\n\nIn radar:\n\n$$\nP_{r}=P_{t}\\mathrm{G}_{t}\\mathrm{G}_{r}\\sigma\\frac{1}{4\\pi}(\\frac{\\lambda}{4\\pi R_{1}R_{2}})^{2}\n$$\n\nEquivalent circuit model\n\n\n![1712900712333](../images/Antenna/1712900712333.png)\n\n$R_r$ ：接收天线反射会释放能量。\n\n### Duality Theorem\n\n![1712901375924](../images/Antenna/1712901375924.png)\n\n电 -> 磁，不变号；\n磁 -> 电，变号。\n\n### Image Theorem\n\nPEC：完美电导体\n\nPMC：完美磁导体\n\n定理条件：\n* PEC or PMC\n* Infinite boundary\n\nPEC\n\n$$\n\\begin{aligned}&\\hat{n}\\times\\vec{E}=0\\\\&\\hat{n}\\cdot\\vec{B}=0\\end{aligned}\n$$\n\nPMC\n\n$$\n\\begin{aligned}&\\hat{n}\\times\\vec{H}=0\\\\&\\hat{n}\\cdot\\vec{D}=0\\end{aligned}\n$$\n\n![1712902160882](../images/Antenna/1712902160882.png)\n\nNote:\n- Satisfied with boundary condition;\n- Mirror source instead of PEC or PMC infinite boundary;\n- Array: source and mirror source;\n- Current loop: upper inside, lower outside.\n\n### Reciprocity Theorem\n\nIn radiation pattern,\n\n![1712903308547](../images/Antenna/1712903308547.png)\n\nTransmitting pattern of antenna “a”\n\n$$\nZ_{_{ba}}(\\theta,\\varphi)=\\frac{V_{_b}(\\theta,\\varphi)}{I_{_a}}\n$$\n\nReceiving pattern of ante\n\n$$\nZ_{ab}(\\theta,\\varphi)=\\frac{V_{a}(\\theta,\\varphi)}{I_{b}}\n$$\n\nThen,\n\n$$\nZ_{ab}(\\theta,\\phi)=Z_{ba}(\\theta,\\phi)\n$$\n\nLorentz Reciprocity Theorem\n\n$$\n-\\nabla\\cdot(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})=\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\\\\n-\\oiint_{S}(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})\\cdot ds^{'}=\\iiint_{V}\\left(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\right)dv^{'}\n$$\n\nFar field:\n\n$$\n\\vec{H}_i=\\hat{r}\\times\\vec{E}_i/\\eta;\\quad d\\vec{s}=\\hat{n}ds=\\hat{r}ds\n$$\n\n$$\n(\\vec{E}_1\\times\\vec{H}_2-\\vec{E}_2\\times\\vec{H}_1)\\cdot\\hat{r}=(\\hat{r}\\times\\vec{E}_1)\\cdot\\vec{H}_2-(\\hat{r}\\times\\vec{E}_2)\\cdot\\vec{H}_1=0\n$$\n\n$$\n\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=0\\\\\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=\\iiint_{V}\\Big(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1}\\Big)d\\nu^{'}\n$$\n\nReaction: Reciprocity theorem: $\\langle 1 2\\rangle=\\langle 2,1\\rangle$\n\n$$\n\\left\\langle1,2\\right\\rangle=\\int_{V}(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2})d\\nu\\quad\\left\\langle2,1\\right\\rangle=\\int_{V}(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1})d\\nu \n$$\n\nIf only current-source\n\n$$\n\\iiint_V\\vec{E}_1\\cdot\\vec{J}_2d\\nu=\\iiint_V\\vec{E}_2\\cdot\\vec{J}_1d\\nu\\\\\n\\vec{E}_1\\cdot\\vec{J}_2=\\vec{E_2} \\cdot \\vec{J_1}\n$$\n\nNon-reciprocity\n\nElectron plasma (non-reciprocal media)\n\n$$\n\\varepsilon = \\begin{bmatrix}\\varepsilon_{xx}&+ig&0\\\\-ig&\\varepsilon_{yy}&0\\\\0&0&\\varepsilon_{zz}\\end{bmatrix}\n$$\n\n### Huygen's Principle\n\n![1712905110844](../images/Antenna/1712905110844.png)\n\n![1712905233876](../images/Antenna/1712905233876.png)\n\n![1712905317317](../images/Antenna/1712905317317.png)\n\n## Dipole Antenna\n\n### Hertz Dipole\n\n* Infinite short length;\n* Uniform distribution;\n* Infinite small radius;\n\n$$\nE_\\theta=\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr}}r\\sin\\theta \\\\\nH_\\varphi=\\frac{I\\Delta z}{4\\pi}jk\\frac{e^{-jkr}}r{\\sin\\theta}\\\\\n\\frac{E_\\theta}{H_\\varphi}=\\sqrt{\\frac{\\mu_0}{\\varepsilon_0}}=\\eta \n$$\n\n![1713506228135](../images/Antenna/1713506228135.png)\n\n![1713506258888](../images/Antenna/1713506258888.png)\n\n![1713506275022](../images/Antenna/1713506275022.png)\n\n### Finite Length Dipole\n\n![1713506837120](../images/Antenna/1713506837120.png)\n\n$$\nI=\\begin{cases}I_0\\sin[k(\\dfrac{l}{2}-z')]&0\\leq z'\\leq\\dfrac{l}{2}\\\\\nI_0\\sin[k(\\dfrac{l}{2}+z')]&-\\dfrac{l}{2}\\leq z'\\leq0\\end{cases}\n$$\n\n$$\n\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-j\\kappa\\Lambda}}{4\\pi R}dz’\\\\R=\\sqrt{\\left(x-x’\\right)^2+\\left(y-y’\\right)^2+\\left(z-z’\\right)^2}\n$$\n\n$$\n\\begin{aligned}&\\text{For phase:}&&R\\cong r-z'\\cos\\theta\\\\&\\text{For amplitude:}&&R\\cong r\\end{aligned}\n$$\n\nR is the distance between observer and source, \nr is the distance between observer and origin.\n\n#### Small Dipole\n\n![1713506363705](../images/Antenna/1713506363705.png)\n\n$$\n\\begin{aligned}&I(z’)\\cong I_{in}(1-2|z’|/l)\\\\&\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-jkr}}{4\\pi r}dz’\\end{aligned}\n$$\n\nThen\n\n$$\n\\vec{A}(x,y,z)=\\hat{z}\\mu\\frac{e^{-jkr}}{4\\pi r}\\cdot\\frac12I_{in}l\\\\\n\\vec{A}(\\theta,r)=\\frac12I_{in}l\\mu\\frac{e^{-jkr}}{4\\pi r}(-\\sin\\theta\\hat{\\theta}+\\cos\\theta\\hat{r})\n$$\n\n$$\n\\vec{E}=j\\omega\\mu I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\theta}\\\\\\vec{H}=j\\beta I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\varphi}\n$$\n\nNote: half of the ideal infinitesima(Hertz) dipole\n\n$$\n\\mathrm{Directivity}:\\quad D=\\frac{4\\pi}{\\Omega_A}\\Rightarrow D_{\\underset{dipole}{\\operatorname*{small}}}=1.5\n$$\n\n$$\nR_{rad}=20\\left(\\frac{\\pi\\Delta z}\\lambda\\right)^2=\\frac14R_{rad}^\\textit{Hertz dipole}\n$$\n\n$$\nP_{rad}=\\frac14\\frac{4\\pi}3{\\left(\\frac{I\\Delta z}{4\\pi}\\right)}^2k^2\\eta{=}\\frac12I^2R_{rad}\n$$\n\n#### General Case\n\n$$\nE_{\\theta}=j\\eta\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\\\\H_{\\varphi}=j\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\n$$\n\nBeam width: change with length.\n\n![1713507175699](../images/Antenna/1713507175699.png)\n\n$$\n\\begin{aligned}\n&\\textbf{The time average Poynting vector:}\\\\\n&\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\mathrm{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})}{\\sin\\theta}\\bigg]^{2}\\hat{r}  \\\\\n&P_{rad}=\\oint_{s}\\vec{S}_{a\\nu}\\cdot d\\vec{s}=\\int_{0}^{2\\pi}\\int_{0}^{\\pi}\\vec{S}_{a\\nu}\\cdot\\vec{r}r^{2}\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_{0}\\right|^{2}}{4\\pi}\\int_{0}^{\\pi}\\frac{\\left[\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})\\right]^{2}}{\\sin\\theta}d\\theta  \\\\\n&\\begin{aligned}&\\text{The radiation intensity:}\\\\&&U=r^2S_{av}=\\eta\\frac{\\left|I_0\\right|^2}{8\\pi^2}\\left[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\right]^2\\\\&&=\\frac{\\pi}{2}=\\frac{\\left|I_{0}\\right|^{2}}{2}=\\frac{k_{0}}{2}=\\frac{k_{0}}{2}\\end{aligned}& \\begin{matrix}{l}\\\\\\end{matrix})  \\\\\n&\\Omega_A=\\frac{P_{rad}}{U_{\\max}}\\quad D=4\\pi/\\Omega_A\\quad A_e=\\frac{\\lambda^2}{4\\pi}D\\quad P_{rad}=\\frac12I^2R_{rad}\n\\end{aligned}\n$$\n\n![1713507190746](../images/Antenna/1713507190746.png)\n\n![1713507205996](../images/Antenna/1713507205996.png)\n\n#### Input Impedance\n\nInput resistance $R_r$:\n* calculated by E and H at port; \n* take the real part (lossless).\n\nRadiation resistance $R_{rad}$:\n* calculated by E and H at far-field;\n\n$$\nP_{rad}=\\frac12{\\left|I\\right|}^2R_{rad}\\quad P_{rad}=\\frac12{\\left|I_{in}\\right|}^2R_r\n$$\n\nI is the maximum/peak current.\n\nGeneral Relation:\n\n$$\nR_r=R_{rad}/\\sin^2\\left(\\frac{kl}2\\right)\n$$\n\n### Half-wavelength dipole\n\n![1713508252106](../images/Antenna/1713508252106.png)\n\n$$\nI(z)=I_0\\sin(\\frac\\pi2-k\\left|z\\right|)\n$$\n\n$$\nE_\\theta(r,\\theta,\\varphi)=j\\eta I_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\\\\H_\\varphi(r,\\theta,\\varphi)=jI_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\n$$\n\n$$\n\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\operatorname{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{\\pi}{2}\\cos\\theta)}{\\sin\\theta}\\bigg]^{2}\\hat{r}\\\\\nP_{rad}=\\oint_sS_{a\\nu}\\cdot d\\vec{s}=\\int_0^{2\\pi}\\int_0^\\pi\\vec{S}_{a\\nu}\\cdot\\hat{r}r^2\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_0\\right|^2}{4\\pi}\\int_0^\\pi\\frac{\\cos^2(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}d\\theta \n$$\n\n$$\nD=4\\pi/\\Omega_{A}=1.643=2.15\\mathrm{dBi}\\\\\nA_e=\\frac{\\lambda^2}{4\\pi}D_0\\cong0.13\\lambda^2\n$$\n\nEdge capacitive effect: \n* Terminal (open-end) \ncurrent is not ideal zero;\n* Effective length is longer\n\n$$\nR_r=R_{rad}=\\frac{2P_{rad}}{\\left|I_0\\right|^2}\\cong73\\left(\\Omega\\right)\\\\\nZ_A=73+j43\\left(\\Omega\\right)\n$$\n\n### Applications\n\n#### Wideband Antennas\n\n![1713508669926](../images/Antenna/1713508669926.png)\n\n#### Folded Dipole\n\n![1713508784675](../images/Antenna/1713508784675.png)\n\n$$\nZ_{{folded}}=4Z_A\n$$\n\nIncrease Input Impedance\n\n#### Log-periodic & Yagi-Uda antenna\n\n![1713509120707](../images/Antenna/1713509120707.png)\n\n#### Dipole Antennas in base station\n\n![1713509734724](../images/Antenna/1713509734724.png)\n\n#### Monopole\n\n![1713509771675](../images/Antenna/1713509771675.png)\n\n## Loop Antennas\n\n### Small Loop\n\n![1715324583382](../images/Antenna/1715324583382.png)\n\n![1715324548326](../images/Antenna/1715324548326.png)\n\n![1715324559069](../images/Antenna/1715324559069.png)\n\nInfinite small loop radius;\n\nInfinite small wire radius;\n\nUniform distribution.\n\nResistance $R_r$ too small!\n\n### Finite-length loop antennas\n\n![1715325834911](../images/Antenna/1715325834911.png)\n\n![1715324769403](../images/Antenna/1715324769403.png)\n\n![1715328812089](../images/Antenna/1715328812089.png)\n\n### Modes of Loop antennas\n\n\n![1715924283522](../images/Antenna/1715924283522.png)\n\n![1715924294266](../images/Antenna/1715924294266.png)\n\n### Helix/helical antennas\n\n![1715924314079](../images/Antenna/1715924314079.png)\n\nAxial Mode\n\n![1715924338243](../images/Antenna/1715924338243.png)\n\nNormal Mode:\n\n![1715924364965](../images/Antenna/1715924364965.png)\n\n![1715924463502](../images/Antenna/1715924463502.png)\n\n## Aperture Antenna\n\n### Huygens' Principle\n\n![1715927654495](../images/Antenna/1715927654495.png)\n\n### Rectangular aperture antennas\n\n![1715927982080](../images/Antenna/1715927982080.png)\n\n![1715928380068](../images/Antenna/1715928380068.png)\n\n![1715929046320](../images/Antenna/1715929046320.png)\n\n![1715929138391](../images/Antenna/1715929138391.png)\n\n![1715929169213](../images/Antenna/1715929169213.png)\n\n### Horn Antennas\n\n\n![1715929396692](../images/Antenna/1715929396692.png)\n\n\n![1715929501432](../images/Antenna/1715929501432.png)\n\nThe E-pattern is in shadow.\n\n![1715929523072](../images/Antenna/1715929523072.png)\n\n![1715929531751](../images/Antenna/1715929531751.png)\n\n![1715929546494](../images/Antenna/1715929546494.png)\n\n## Antenna Array\n\n1-D Linear Array\n\n2-D Planar Array\n\n3-D Conformal Array\n\nArray Element\n* Dipoles\n* Loops\n* Slots\n* Microstrip antennas\n\n### Two-Element array\n\n![1717133761533](../images/Antenna/1717133761533.png)\n\n$$\n\\begin{gathered}\n\\vec{E}_1= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_1}}{r_1}\\cos\\theta_1 \\\\\n\\vec{E}_{2}= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_2}}{r_2}\\cos\\theta_2 \n\\end{gathered}\n$$\n\nRemarks:\n* Two element;\n* Towards Y axis;\n* Along Z axis;\n* Space: d;\n* Uniform phase \nand amplitude;\n* Observe in 2D \n(YZ-plane).\n\nFar field Approximation\n\n![1717133876692](../images/Antenna/1717133876692.png)\n\n$$\n\\begin{aligned}&\\vec{E}_{total}=\\vec{E}_1+\\vec{E}_2\\\\&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac1r\\Bigg(e^{-jk(r-\\frac d2\\cos\\theta)}+e^{-jk(r+\\frac d2\\cos\\theta)}\\Bigg)\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n\\vec{E}_{total}& =\\vec{E}_1+\\vec{E}_2=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{1}{r}\\Bigg(e^{-jk(r-\\frac{d}{2}\\cos\\theta)}+e^{-jk(r+\\frac{d}{2}\\cos\\theta)}\\Bigg)  \\\\\n&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}{r}\\Bigg(e^{jk\\frac{d}{2}\\cos\\theta}+e^{-jk\\frac{d}{2}\\cos\\theta}\\Bigg) \\\\\n&=\\hat{\\theta}\\underbrace{\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}r}_{\\text{Element pattern}}\\underbrace{2\\cos\\biggl[\\frac12kd\\cos\\theta\\biggr]}_{\\text{Array Factor (AF)}}\n\\end{aligned}\n$$\n\nRemarks:\n* Uniform phase and amplitude;\n* AF is related to space (d);\n* AF is with no relation with antenna type.\n\n$$\nAF{=}2\\cos\\left[\\frac12kd\\cos\\theta\\right]\\quad kd{=}\\frac{2\\pi}\\lambda d{=}2\\pi\\frac d\\lambda \n$$\n\n![1717134268805](../images/Antenna/1717134268805.png)\n\n![1717134287481](../images/Antenna/1717134287481.png)\n\n### N-Element array\n\n![1717134353772](../images/Antenna/1717134353772.png)\n\n$$\n\\begin{aligned}&AF=1+e^{jkd\\cos\\theta}+e^{j2kd\\cos\\theta}+\\cdots+e^{j(N-1)kd\\cos\\theta}\\\\&=\\sum_{n=1}^Ne^{j(n-1)kd\\cos\\theta}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}\\end{aligned}\n$$\n\n$$\nAF=1+e^{j\\Psi}+e^{j2\\Psi}+\\cdots+e^{j(N-1)\\Psi}=\\frac{e^{jN\\Psi}-1}{e^{j\\Psi}-1}\\\\=\\frac{e^{j\\frac N2\\Psi}\\left(e^{j\\frac N2\\Psi}-e^{-j\\frac N2\\Psi}\\right)}{e^{j\\frac12\\Psi}\\left(e^{j\\frac12\\Psi}-e^{-j\\frac12\\Psi}\\right)}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$\n\nRefenece Point at the end:\n\n$$\nAF=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$\n\nRefenece Point at the center:\n\n$$\nAF=\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$\n\nIn Progreessive Phase Shift:\n\n$$\n\\Psi=kd\\cos\\theta+\\alpha \n$$\n\n$$\nAF=1+e^{j(kd\\cos\\theta+\\alpha)}+e^{j2(kd\\cos\\theta+\\alpha)}+\\cdots+e^{j(N-1)(kd\\cos\\theta+\\alpha)}\\\\=\\sum_{n=1}^Ne^{j(n-1)(kd\\cos\\theta+\\alpha)}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$\n\nNormalized Array Factor:\n\n$$\n\\left|f(\\Psi)\\right|=\\left|\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{N\\sin\\left(\\frac12\\Psi\\right)}\\right|\n$$\n\nGrating Lobe:\n\n$$\n\\begin{aligned}\n\\theta\\in\\begin{bmatrix}0,\\pi\\end{bmatrix}\\text{ or }\\theta\\in\\begin{bmatrix}\\theta_1,\\theta_2\\end{bmatrix}\\text{, visible region} \\\\\n\\text{In the visible region,} \\\\\nifwehaveY= 0\\mathrm{~and~}\\Psi=2\\pi. \n\\end{aligned}\n$$\n\nAvoid grating lobe:\n1. Smaller d;\n2. Smaller phase shift.\n\n$$\n1.\\mathrm{~For~}\\alpha=\\pi\\Rightarrow2kd<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<\\frac12\\\\2.\\mathrm{~For~}\\alpha=0\\mathrm{~}\\Rightarrow\\mathrm{~k}d<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<1\n$$\n\n#### Broadside Array\n\nMaximum @ $\\theta = 90\\degree$\n\n$$\nAF\\boldsymbol{=}N@\\boldsymbol{\\theta}\\boldsymbol{=}\\boldsymbol{\\pi}/2\\quad\\boldsymbol{\\Psi}\\boldsymbol{=}kd\\cos\\boldsymbol{\\theta}\\boldsymbol{+}\\boldsymbol{\\alpha}|_{\\theta=\\pi/2}\\boldsymbol{=}0\n$$\n\n![1717134725130](../images/Antenna/1717134725130.png)\n\n![1717134745100](../images/Antenna/1717134745100.png)\n\n#### End-fire Array\n\n![1717134897852](../images/Antenna/1717134897852.png)\n\n$$\n\\begin{aligned}\n&AF= N@\\theta{=}0  &\\Psi=kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2\\ldots)  \\\\\n&\\text{or} \\\\\n&AF= N@\\theta{=}\\pi   &\\Psi=-kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2...)  \\\\\n&\\Psi=kd\\cos\\theta+\\alpha=2\\pi\\cos\\theta \n\\end{aligned}\n$$\n\nBidirectional:\n\n![1717134942873](../images/Antenna/1717134942873.png)\n\nUnidirectional:\n\n![1717134955235](../images/Antenna/1717134955235.png)\n\n#### Phased Array\n\n![1717135044895](../images/Antenna/1717135044895.png)\n\n#### Non-uniform Array\n\nSide Lobe\n\nUniform array:\n* Universal pattern: N↑, SLL↓ \n* With a limit of -13.3 dB\n* No control of SL\n\nHow to reduce SLL?\n\nNon-uniform excitation\n\n![1717135171215](../images/Antenna/1717135171215.png)\n\n#### Planar Array\n\n![1717135198414](../images/Antenna/1717135198414.png)\n\nCan be viewed as product of two linear array factors:\n\n$$\nAF=\\sum_{i=1}^{M\\times N}I_ie^{jk\\hat{r}\\cdot\\vec{r}_i}\\\\\nAF_n(\\theta,\\phi)=\\left\\{\\frac{\\sin(\\frac M2\\psi_x)}{M\\sin\\frac{\\psi_x}2}\\right\\}\\left\\{\\frac{\\sin(\\frac N2\\psi_y)}{N\\sin\\frac{\\psi_y}2}\\right\\};\\\\\\psi_x=kd_x\\sin\\theta\\cos\\varphi+\\alpha_x\\\\\\psi_y=kd_y\\sin\\theta\\sin\\varphi+\\alpha_y\n$$\n\n### Applications\n\n#### Yagi-Uda Antenna\n\nBasic configuration:\n* One driven element;\n* Two parasitic elements or more\n\n![1717135386351](../images/Antenna/1717135386351.png)\n\nRemarks:\n* Parasitic elements are excited by near-field coupling from the driven element;\n* Proper design of parasitic elements for end fire radiation;\n* In far field, the radiated waves from all the elements are in-phase.\n\n![1717135675789](../images/Antenna/1717135675789.png)\n\n![1717135951201](../images/Antenna/1717135951201.png)\n\n#### Helix Antenna\n\n![1717136046473](../images/Antenna/1717136046473.png)\n\n![1717136115015](../images/Antenna/1717136115015.png)\n\n## Travelling-Wave Antennas\n\n### Travelling wave & standing wave\n\n#### Long wire antennas\n\n![1717137633424](../images/Antenna/1717137633424.png)\n\n![1717137646795](../images/Antenna/1717137646795.png)\n\nNote:\nLong wire antennas: “l” = Several wavelength\n* One end for excitation;\n* The other end for load (open, short, or matching);\n* Transmission line with radiation.\n\n### Log-periodic Antennas\n\nYagi-Uda: High Gain\n\nLog-periodic: Wide Bandwidth\n\n![1717138714524](../images/Antenna/1717138714524.png)\n\nWhy:\n1. Feed from smaller dipole element;\n2. Feed out-of-phase with adjacent elements;\n3. Add a resistor at the end.\n\n\n$$\n\\tau=\\frac{R_{n+1}}{R_{n}}=\\frac{L_{n+1}}{L_{n}}=\\frac{d_{n+1}}{d_{n}}\\\\\\alpha=2\\tan^{-1}\\left(\\frac{1-\\tau}{4\\sigma}\\right)\\\\\\sigma=\\frac{d_{n}}{2L_{n}}\\\\L_{1}\\approx\\frac{\\lambda_{L}}{2}\\quad\\mathrm{and}\\quad L_{N}\\approx\\frac{\\lambda_{U}}{2}\n$$\n\n![1717138873279](../images/Antenna/1717138873279.png)\n\n## Microstrip Antennas  \n\n\n![1717740667735](../images/Antenna/1717740667735.png)\n\n![1717740670364](../images/Antenna/1717740670364.png)\n\n![1717740680573](../images/Antenna/1717740680573.png)\n\n### Basic Mode\n\n* Equivalent magnetic current;\n* Radiating and non-radiating apertures;\n* Operating frequency with different L.\n\n![1717740726098](../images/Antenna/1717740726098.png)\n\n* Magnetic current array;\n* Image theorem from infinite ground;\n* Cavity model with magnetic walls;\n* Different from\n\n![1717740758890](../images/Antenna/1717740758890.png)\n\n![1717740768183](../images/Antenna/1717740768183.png)\n\n### Antenna feeding methods\n\n![1717740786849](../images/Antenna/1717740786849.png)\n\nImpedance Matching:\n\n![1717740801741](../images/Antenna/1717740801741.png)\n\nUsing 50-Ohm port: finding the position with Z_in=50 Ohm\n\n### Analysis Model\n\n![1717742374397](../images/Antenna/1717742374397.png)\n\nKnown:\n* Operating Frequency\n* Dielectric: $\\varepsilon_r$ and $h$\n* Metal: $t$\n\nDesign: \n* Patch: $L$ and $W$\n* Evaluate gain\n\n2 Models:\n\n![1717742413544](../images/Antenna/1717742413544.png)\n\n#### Transmission line model\n\ndetermine W\n\nUniform distribution and  field intensity in dielectric\n\n$$\nW=\\frac{1}{2f_r\\sqrt{\\mu_0\\epsilon_0}}\\sqrt{\\frac{2}{\\epsilon_r+1}}\n$$\n\nEffective permittivity\n\n$$\n\\varepsilon_{eff}=\\frac{\\varepsilon_r+1}2+\\frac{\\varepsilon_r-1}2{\\left[1+12\\frac hW\\right]}^{-1/2}\n$$\n\nFring effect and determine L\n\n$$\n\\frac{\\Delta L}{h}=0.412\\frac{(\\varepsilon_{eff}+0.3)(\\frac Wh+0.264)}{(\\varepsilon_{eff}-0.258)(\\frac Wh+0.8)}\\\\L=\\frac{\\lambda_d}2-2\\Delta L=\\frac{\\lambda_0}{2\\sqrt{\\varepsilon_{eff}}}-2\\Delta L\n$$\n\nimpedance matching\n\n#### Cavity Model\n\n![1717742626807](../images/Antenna/1717742626807.png)\n\n![1717743460723](../images/Antenna/1717743460723.png)\n\n![1717743468657](../images/Antenna/1717743468657.png)\n\n### Circular polarization\n\nDual feed patch\n\n![1717743681072](../images/Antenna/1717743681072.png)\n\n![1717743691321](../images/Antenna/1717743691321.png)\n\n![1717743927411](../images/Antenna/1717743927411.png)\n\n![1718344358151](../images/Antenna/1718344358151.png)\n\nSP-feed 旋转馈电\n\n## Reflector and lens antennas\n\n![1718345601277](../images/Antenna/1718345601277.png)\n\n### Corner Reflectors\n\n![1718345727630](../images/Antenna/1718345727630.png)\n\n![1718345718761](../images/Antenna/1718345718761.png)\n\n### Parabolic Reflectors\n\n![1718346212882](../images/Antenna/1718346212882.png)\n\n![1718346379534](../images/Antenna/1718346379534.png)\n\n![1718346371235](../images/Antenna/1718346371235.png)\n\n![1718346571584](../images/Antenna/1718346571584.png)\n\n### Lens Antennas\n\n![1718346830900](../images/Antenna/1718346830900.png)\n\nLens antennas:\n* High gain: plane wave;\n* Geometrical optics: equal optical distance;\n* Source: spherical wave, illuminate the whole lens;\n* Source is positioned on the focal point for normal \nradiated plane wave;\n* Other incident/radiated angle of plane wave: focus on \nthe focal plane with gain decrease;\n* Spatial Fournier Transformation: (x, y)&k\n\n### Reflected and transmitted array\n\n![1718347859765](../images/Antenna/1718347859765.png)\n\n![1718347869028](../images/Antenna/1718347869028.png)\n\n","source":"_posts/Antenna.md","raw":"---\ntitle: Principle of Antenna\nkatex: true\ndate: 2024-03-01 14:14:50\ntags:\n---\n## Introduction of Antenna\n\nDefinition of Antenna\n\n* Transmitter and receiver of EM wave\n* Signal from current to wave\n* from lumped to distributed\n\nAntenna classifications\n\n* Resonant and non-resonant/leaky/travelling wave\n* Antenna number: element, multiple antennas, array\n* Shape: wire, loop, slot, patch/microstrip, cavity\n* Materials: metallic, dielectric\n* Property: wideband, narrow band\n* Yagi-Uda, Vivaldi, Cassegrain\n* Function: moblie/handset, base station, AiP\n\n## Maxwell equations\n\n$$\n\\nabla \\cdot \\vec D = \\rho \\rightarrow \\nabla \\cdot \\tilde{\\vec D} = \\rho \\\\\n\\nabla \\cdot {\\vec B} = 0 \\rarr \\nabla \\cdot \\tilde{\\vec B} = 0\\\\\n\\nabla \\times {\\vec E} = -\\frac{\\partial \\vec B}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec E} = -j\\omega \\tilde{\\vec B}\\\\\n\\nabla \\times {\\vec H} = \\vec J + \\frac{\\partial \\vec D}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec H} = \\vec J + j\\omega \\tilde{\\vec D}\\\\\n\\vec D = \\varepsilon \\vec E\\\\\n\\vec B = \\mu \\vec H\n$$\n\n$$\n\\nabla^2 \\vec F = \\nabla(\\nabla \\cdot \\vec F) - \\nabla \\times (\\nabla \\times \\vec F)\\\\\n\\nabla \\times (\\nabla f) = 0\\\\\n\\nabla \\cdot (\\nabla \\times \\vec F) = 0\n$$\n\n## Auxiliary Potential Functions\n\nLet\n\n$$\n\\vec B = \\nabla \\times \\vec A\\\\\n\\vec E + j\\omega \\vec A = -\\nabla \\phi\n$$\n\n$$\n\\nabla \\cdot \\vec D = \\varepsilon \\nabla \\cdot(-\\nabla \\phi  - j\\omega \\vec A) = \\rho\\\\\n\\Rightarrow \\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon} - j\\omega(\\nabla \\cdot \\vec A + j\\omega \\mu \\varepsilon \\phi)\n$$\n\n$$\n\\nabla \\times \\vec H = \\frac{1}{\\mu}(\\nabla(\\nabla \\cdot \\vec A) - \\nabla^2\\vec A) = \\vec J + j\\omega \\vec D = \\vec J + j\\omega\\varepsilon(-\\nabla\\phi - j\\omega \\vec A)\\\\\n\\Rightarrow \\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J - \\nabla(\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi)\n$$\n\nUse Lorentz Gauge\n\n$$\n\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi = 0\n$$\n\nThen\n\n$$\n\\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J\\\\\n\\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon}\n$$\n\nSolve ODE:\n\n$$\n\\begin{equation}  \n\\nabla^2\\phi + k^2\\phi = 0(r\\ne 0)\n\\end{equation}\\\\\n\\begin{equation}\n\\nabla^2\\phi + k^2\\phi = -\\frac{\\rho}{\\varepsilon}(r=0)\n\\end{equation}\n$$\n\nFor (1)\n\n$$\nu(r) = \\frac{\\phi(r)}{r}\\\\\n\\frac{\\rm{d}^2}{\\rm{d}r^2}u + k^2u = 0\\\\\nu = C_1e^{-jkr} + C_2e^{jkr}\\\\\n\\phi = C_1\\frac{e^{-jkr}}{r}\n$$\n\nFor (2), in arbitrary volume\n\n$$\n\\iiint_V(\\nabla^2\\phi + k^2\\phi)\\mathrm dv = \\iiint_V(-\\frac{\\rho}{\\varepsilon}\\mathrm dv) = -\\frac{q}{\\varepsilon}\\\\\nr \\rightarrow 0\\\\\n\\iiint_V(k^2\\phi)\\mathrm dv = 0\\\\\n\\iiint_V\\nabla^2\\phi \\mathrm dv = \\oiint_S \\nabla\\phi \\cdot \\mathrm d\\vec s = C_1 \\oiint_S (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})\\mathrm d\\vec s = C_1 (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})4\\pi r^2 = -C_1 4\\pi\n$$\n\nFinally,\n\n$$\n\\phi(r) = \\frac{q}{4\\pi\\varepsilon}\\frac{e^{-jkr}}{r}\n$$\n\n## Radiation Parameters\n\n### Field Zone\n\nNear field: resonant, field;\n\nFar field: propagation, wave;\n\nFresnel region: transition;\n\n![1711090268476](../images/Antenna/1711090268476.png)\n\n### Antenna Parameters\n\n* Radiation patterns\n* Radiation Intensity\n* Power Density\n* Directivity (方向性) and Gain (重要！)\n* Polarization\n* Effective Aperture(等效口面) and Aperture efficienty(口面效率)\n\nE 面：与电场方向平行的面\n\nH 面：与磁场方向平行的面\n\n#### Pattern Parameters\n\n![1711090565574](../images/Antenna/1711090565574.png)\n\nOften use log scale.\n\n#### Power Density\n\nInstantaneous Poynting vector $\\vec S(x, y, z, t)$\n\nRadiation Power Density = Time average Poynting vector $\\vec S_{av}(x, y, z)=\\frac1T\\int_0^T\\vec S(x, y, z, t)\\mathrm dt = \\frac12\\text{Re}[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}]$\n\nTotal Radiation Power $P_{rad} = \\oiint_S[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}] \\cdot \\mathrm d\\vec s$\n\n#### Radiation Intensity\n\n$$\nU(\\theta, \\varphi) = r^2 S(r, \\theta, \\varphi)\n$$\n\nIsotropic 各向同性\n\n$$\nP_{rad} = \\int_{0}^{2\\pi}\\int_{0}^{\\pi}U\\sin\\theta\\mathrm d\\theta\\mathrm d\\varphi\n$$\n\n#### Directivity\n\n$$\nD = \\frac{U_{\\max}}{U_{av}} = \\frac{P_{\\max}}{P_{rad}/4\\pi}\n$$\n\n![1711091202619](../images/Antenna/1711091202619.png)\n\n![1711091212947](../images/Antenna/1711091212947.png)\n\n![1711693683771](../images/Antenna/1711693683771.png)\n\n![1711693701192](../images/Antenna/1711693701192.png)\n\n#### Gain\n\n![1711693749686](../images/Antenna/1711693749686.png)\n\n$$\nG = \\frac{U_{\\max}}{P_{in}/4\\pi}\n$$\n\n#### Polarization\n\n![1711693845822](../images/Antenna/1711693845822.png)\n\nPolarization Mismatch:\n\n![1711693861642](../images/Antenna/1711693861642.png)\n\nCP\n\n![1711693936592](../images/Antenna/1711693936592.png)\n\n#### Effective Aperture and Aperture efficiency\n\n![1711694027177](../images/Antenna/1711694027177.png)\n\n![1711694083583](../images/Antenna/1711694083583.png)\n\n### Circuit Parameters\n\n#### Input impedance\n\nInput impedance definition:\n\n* the impedance presented by an antenna at its terminals\n* the ratio of the voltage to current at its terminals\n* the ratio of the electric to magnetic fields at its terminals\n\n![1711694243897](../images/Antenna/1711694243897.png)\n\n##### Conjugate Matching\n\n$$\nZ_A = Z_g^*\n$$\n\n##### Mismatching\n\n![1711694350257](../images/Antenna/1711694350257.png)\n\n##### Radiation Resistance\n\n$$\nP_{rad} = \\frac12|I_g|^2R_r = \\oiint_S\\vec S_{av} \\cdot \\rm d\\vec s\n$$\n\n![1711694462059](../images/Antenna/1711694462059.png)\n\n#### Scattering Parameters\n\n![1711694619870](../images/Antenna/1711694619870.png)\n\n$$\n\\frac{\\Gamma^2}{Z_1} + \\frac{T^2}{Z_2} = 1\n$$\n\n![1711694639638](../images/Antenna/1711694639638.png)\n\n![1711695738159](../images/Antenna/1711695738159.png)\n\n二端口网络通常用于描述二天线问题。$S_{11}$表示天线1的反射，$S_{21}$表示天线1到天线2的耦合，均不利于信号的传播。我们希望让$1 - S_{11}^2 - S_{21}^2$尽可能大。\n\n## Link Calculation\n\n### Friis's Equation\n\n![1712471419276](../images/Antenna/1712471419276.png)\n\n![1712471436962](../images/Antenna/1712471436962.png)\n\n### EIRP\n\n![1712471499226](../images/Antenna/1712471499226.png)\n\n赫兹偶极子的辐射电阻： $80\\pi^2(\\frac{\\Delta z}{\\lambda})^2$，方向性 $\\frac{2}{3}$。\n\n### Radar Equation\n\n![1712473473687](../images/Antenna/1712473473687.png)\n\nRCS(Radar cross section)\n\nRCS (σ) of a radar target is an effective area that intercepts the transmitted radar power and then\nscatters that power isotropically back to the radar receiver.\n\n$$\n\\sigma=\\lim_{R\\to\\infty}\\frac{W_{o}4\\pi R^2}{W_i}\n$$\n\n* $W_i$, $W_o$ and $R$ are known;\n* $\\sigma$ converges.\n\n## Antenna Theorems\n\n\n$$\n\\boxed{P_r=\\mathrm{P}_t\\mathrm{G}_t\\mathrm{G}_r(\\frac{\\lambda}{4\\pi R})^2}\n$$\n\n$$\nP_{r}=P_{t}\\mathrm{e}_{r}\\mathrm{e}_{t}D_{r}\\mathrm{D}_{t}(1-\\left|\\Gamma_{r}\\right|^{2})(1-\\left|\\Gamma_{t}\\right|^{2})(\\frac{\\lambda}{4\\pi R})^{2}\n$$\n\nIn radar:\n\n$$\nP_{r}=P_{t}\\mathrm{G}_{t}\\mathrm{G}_{r}\\sigma\\frac{1}{4\\pi}(\\frac{\\lambda}{4\\pi R_{1}R_{2}})^{2}\n$$\n\nEquivalent circuit model\n\n\n![1712900712333](../images/Antenna/1712900712333.png)\n\n$R_r$ ：接收天线反射会释放能量。\n\n### Duality Theorem\n\n![1712901375924](../images/Antenna/1712901375924.png)\n\n电 -> 磁，不变号；\n磁 -> 电，变号。\n\n### Image Theorem\n\nPEC：完美电导体\n\nPMC：完美磁导体\n\n定理条件：\n* PEC or PMC\n* Infinite boundary\n\nPEC\n\n$$\n\\begin{aligned}&\\hat{n}\\times\\vec{E}=0\\\\&\\hat{n}\\cdot\\vec{B}=0\\end{aligned}\n$$\n\nPMC\n\n$$\n\\begin{aligned}&\\hat{n}\\times\\vec{H}=0\\\\&\\hat{n}\\cdot\\vec{D}=0\\end{aligned}\n$$\n\n![1712902160882](../images/Antenna/1712902160882.png)\n\nNote:\n- Satisfied with boundary condition;\n- Mirror source instead of PEC or PMC infinite boundary;\n- Array: source and mirror source;\n- Current loop: upper inside, lower outside.\n\n### Reciprocity Theorem\n\nIn radiation pattern,\n\n![1712903308547](../images/Antenna/1712903308547.png)\n\nTransmitting pattern of antenna “a”\n\n$$\nZ_{_{ba}}(\\theta,\\varphi)=\\frac{V_{_b}(\\theta,\\varphi)}{I_{_a}}\n$$\n\nReceiving pattern of ante\n\n$$\nZ_{ab}(\\theta,\\varphi)=\\frac{V_{a}(\\theta,\\varphi)}{I_{b}}\n$$\n\nThen,\n\n$$\nZ_{ab}(\\theta,\\phi)=Z_{ba}(\\theta,\\phi)\n$$\n\nLorentz Reciprocity Theorem\n\n$$\n-\\nabla\\cdot(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})=\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\\\\n-\\oiint_{S}(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})\\cdot ds^{'}=\\iiint_{V}\\left(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\right)dv^{'}\n$$\n\nFar field:\n\n$$\n\\vec{H}_i=\\hat{r}\\times\\vec{E}_i/\\eta;\\quad d\\vec{s}=\\hat{n}ds=\\hat{r}ds\n$$\n\n$$\n(\\vec{E}_1\\times\\vec{H}_2-\\vec{E}_2\\times\\vec{H}_1)\\cdot\\hat{r}=(\\hat{r}\\times\\vec{E}_1)\\cdot\\vec{H}_2-(\\hat{r}\\times\\vec{E}_2)\\cdot\\vec{H}_1=0\n$$\n\n$$\n\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=0\\\\\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=\\iiint_{V}\\Big(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1}\\Big)d\\nu^{'}\n$$\n\nReaction: Reciprocity theorem: $\\langle 1 2\\rangle=\\langle 2,1\\rangle$\n\n$$\n\\left\\langle1,2\\right\\rangle=\\int_{V}(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2})d\\nu\\quad\\left\\langle2,1\\right\\rangle=\\int_{V}(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1})d\\nu \n$$\n\nIf only current-source\n\n$$\n\\iiint_V\\vec{E}_1\\cdot\\vec{J}_2d\\nu=\\iiint_V\\vec{E}_2\\cdot\\vec{J}_1d\\nu\\\\\n\\vec{E}_1\\cdot\\vec{J}_2=\\vec{E_2} \\cdot \\vec{J_1}\n$$\n\nNon-reciprocity\n\nElectron plasma (non-reciprocal media)\n\n$$\n\\varepsilon = \\begin{bmatrix}\\varepsilon_{xx}&+ig&0\\\\-ig&\\varepsilon_{yy}&0\\\\0&0&\\varepsilon_{zz}\\end{bmatrix}\n$$\n\n### Huygen's Principle\n\n![1712905110844](../images/Antenna/1712905110844.png)\n\n![1712905233876](../images/Antenna/1712905233876.png)\n\n![1712905317317](../images/Antenna/1712905317317.png)\n\n## Dipole Antenna\n\n### Hertz Dipole\n\n* Infinite short length;\n* Uniform distribution;\n* Infinite small radius;\n\n$$\nE_\\theta=\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr}}r\\sin\\theta \\\\\nH_\\varphi=\\frac{I\\Delta z}{4\\pi}jk\\frac{e^{-jkr}}r{\\sin\\theta}\\\\\n\\frac{E_\\theta}{H_\\varphi}=\\sqrt{\\frac{\\mu_0}{\\varepsilon_0}}=\\eta \n$$\n\n![1713506228135](../images/Antenna/1713506228135.png)\n\n![1713506258888](../images/Antenna/1713506258888.png)\n\n![1713506275022](../images/Antenna/1713506275022.png)\n\n### Finite Length Dipole\n\n![1713506837120](../images/Antenna/1713506837120.png)\n\n$$\nI=\\begin{cases}I_0\\sin[k(\\dfrac{l}{2}-z')]&0\\leq z'\\leq\\dfrac{l}{2}\\\\\nI_0\\sin[k(\\dfrac{l}{2}+z')]&-\\dfrac{l}{2}\\leq z'\\leq0\\end{cases}\n$$\n\n$$\n\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-j\\kappa\\Lambda}}{4\\pi R}dz’\\\\R=\\sqrt{\\left(x-x’\\right)^2+\\left(y-y’\\right)^2+\\left(z-z’\\right)^2}\n$$\n\n$$\n\\begin{aligned}&\\text{For phase:}&&R\\cong r-z'\\cos\\theta\\\\&\\text{For amplitude:}&&R\\cong r\\end{aligned}\n$$\n\nR is the distance between observer and source, \nr is the distance between observer and origin.\n\n#### Small Dipole\n\n![1713506363705](../images/Antenna/1713506363705.png)\n\n$$\n\\begin{aligned}&I(z’)\\cong I_{in}(1-2|z’|/l)\\\\&\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-jkr}}{4\\pi r}dz’\\end{aligned}\n$$\n\nThen\n\n$$\n\\vec{A}(x,y,z)=\\hat{z}\\mu\\frac{e^{-jkr}}{4\\pi r}\\cdot\\frac12I_{in}l\\\\\n\\vec{A}(\\theta,r)=\\frac12I_{in}l\\mu\\frac{e^{-jkr}}{4\\pi r}(-\\sin\\theta\\hat{\\theta}+\\cos\\theta\\hat{r})\n$$\n\n$$\n\\vec{E}=j\\omega\\mu I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\theta}\\\\\\vec{H}=j\\beta I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\varphi}\n$$\n\nNote: half of the ideal infinitesima(Hertz) dipole\n\n$$\n\\mathrm{Directivity}:\\quad D=\\frac{4\\pi}{\\Omega_A}\\Rightarrow D_{\\underset{dipole}{\\operatorname*{small}}}=1.5\n$$\n\n$$\nR_{rad}=20\\left(\\frac{\\pi\\Delta z}\\lambda\\right)^2=\\frac14R_{rad}^\\textit{Hertz dipole}\n$$\n\n$$\nP_{rad}=\\frac14\\frac{4\\pi}3{\\left(\\frac{I\\Delta z}{4\\pi}\\right)}^2k^2\\eta{=}\\frac12I^2R_{rad}\n$$\n\n#### General Case\n\n$$\nE_{\\theta}=j\\eta\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\\\\H_{\\varphi}=j\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\n$$\n\nBeam width: change with length.\n\n![1713507175699](../images/Antenna/1713507175699.png)\n\n$$\n\\begin{aligned}\n&\\textbf{The time average Poynting vector:}\\\\\n&\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\mathrm{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})}{\\sin\\theta}\\bigg]^{2}\\hat{r}  \\\\\n&P_{rad}=\\oint_{s}\\vec{S}_{a\\nu}\\cdot d\\vec{s}=\\int_{0}^{2\\pi}\\int_{0}^{\\pi}\\vec{S}_{a\\nu}\\cdot\\vec{r}r^{2}\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_{0}\\right|^{2}}{4\\pi}\\int_{0}^{\\pi}\\frac{\\left[\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})\\right]^{2}}{\\sin\\theta}d\\theta  \\\\\n&\\begin{aligned}&\\text{The radiation intensity:}\\\\&&U=r^2S_{av}=\\eta\\frac{\\left|I_0\\right|^2}{8\\pi^2}\\left[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\right]^2\\\\&&=\\frac{\\pi}{2}=\\frac{\\left|I_{0}\\right|^{2}}{2}=\\frac{k_{0}}{2}=\\frac{k_{0}}{2}\\end{aligned}& \\begin{matrix}{l}\\\\\\end{matrix})  \\\\\n&\\Omega_A=\\frac{P_{rad}}{U_{\\max}}\\quad D=4\\pi/\\Omega_A\\quad A_e=\\frac{\\lambda^2}{4\\pi}D\\quad P_{rad}=\\frac12I^2R_{rad}\n\\end{aligned}\n$$\n\n![1713507190746](../images/Antenna/1713507190746.png)\n\n![1713507205996](../images/Antenna/1713507205996.png)\n\n#### Input Impedance\n\nInput resistance $R_r$:\n* calculated by E and H at port; \n* take the real part (lossless).\n\nRadiation resistance $R_{rad}$:\n* calculated by E and H at far-field;\n\n$$\nP_{rad}=\\frac12{\\left|I\\right|}^2R_{rad}\\quad P_{rad}=\\frac12{\\left|I_{in}\\right|}^2R_r\n$$\n\nI is the maximum/peak current.\n\nGeneral Relation:\n\n$$\nR_r=R_{rad}/\\sin^2\\left(\\frac{kl}2\\right)\n$$\n\n### Half-wavelength dipole\n\n![1713508252106](../images/Antenna/1713508252106.png)\n\n$$\nI(z)=I_0\\sin(\\frac\\pi2-k\\left|z\\right|)\n$$\n\n$$\nE_\\theta(r,\\theta,\\varphi)=j\\eta I_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\\\\H_\\varphi(r,\\theta,\\varphi)=jI_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\n$$\n\n$$\n\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\operatorname{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{\\pi}{2}\\cos\\theta)}{\\sin\\theta}\\bigg]^{2}\\hat{r}\\\\\nP_{rad}=\\oint_sS_{a\\nu}\\cdot d\\vec{s}=\\int_0^{2\\pi}\\int_0^\\pi\\vec{S}_{a\\nu}\\cdot\\hat{r}r^2\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_0\\right|^2}{4\\pi}\\int_0^\\pi\\frac{\\cos^2(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}d\\theta \n$$\n\n$$\nD=4\\pi/\\Omega_{A}=1.643=2.15\\mathrm{dBi}\\\\\nA_e=\\frac{\\lambda^2}{4\\pi}D_0\\cong0.13\\lambda^2\n$$\n\nEdge capacitive effect: \n* Terminal (open-end) \ncurrent is not ideal zero;\n* Effective length is longer\n\n$$\nR_r=R_{rad}=\\frac{2P_{rad}}{\\left|I_0\\right|^2}\\cong73\\left(\\Omega\\right)\\\\\nZ_A=73+j43\\left(\\Omega\\right)\n$$\n\n### Applications\n\n#### Wideband Antennas\n\n![1713508669926](../images/Antenna/1713508669926.png)\n\n#### Folded Dipole\n\n![1713508784675](../images/Antenna/1713508784675.png)\n\n$$\nZ_{{folded}}=4Z_A\n$$\n\nIncrease Input Impedance\n\n#### Log-periodic & Yagi-Uda antenna\n\n![1713509120707](../images/Antenna/1713509120707.png)\n\n#### Dipole Antennas in base station\n\n![1713509734724](../images/Antenna/1713509734724.png)\n\n#### Monopole\n\n![1713509771675](../images/Antenna/1713509771675.png)\n\n## Loop Antennas\n\n### Small Loop\n\n![1715324583382](../images/Antenna/1715324583382.png)\n\n![1715324548326](../images/Antenna/1715324548326.png)\n\n![1715324559069](../images/Antenna/1715324559069.png)\n\nInfinite small loop radius;\n\nInfinite small wire radius;\n\nUniform distribution.\n\nResistance $R_r$ too small!\n\n### Finite-length loop antennas\n\n![1715325834911](../images/Antenna/1715325834911.png)\n\n![1715324769403](../images/Antenna/1715324769403.png)\n\n![1715328812089](../images/Antenna/1715328812089.png)\n\n### Modes of Loop antennas\n\n\n![1715924283522](../images/Antenna/1715924283522.png)\n\n![1715924294266](../images/Antenna/1715924294266.png)\n\n### Helix/helical antennas\n\n![1715924314079](../images/Antenna/1715924314079.png)\n\nAxial Mode\n\n![1715924338243](../images/Antenna/1715924338243.png)\n\nNormal Mode:\n\n![1715924364965](../images/Antenna/1715924364965.png)\n\n![1715924463502](../images/Antenna/1715924463502.png)\n\n## Aperture Antenna\n\n### Huygens' Principle\n\n![1715927654495](../images/Antenna/1715927654495.png)\n\n### Rectangular aperture antennas\n\n![1715927982080](../images/Antenna/1715927982080.png)\n\n![1715928380068](../images/Antenna/1715928380068.png)\n\n![1715929046320](../images/Antenna/1715929046320.png)\n\n![1715929138391](../images/Antenna/1715929138391.png)\n\n![1715929169213](../images/Antenna/1715929169213.png)\n\n### Horn Antennas\n\n\n![1715929396692](../images/Antenna/1715929396692.png)\n\n\n![1715929501432](../images/Antenna/1715929501432.png)\n\nThe E-pattern is in shadow.\n\n![1715929523072](../images/Antenna/1715929523072.png)\n\n![1715929531751](../images/Antenna/1715929531751.png)\n\n![1715929546494](../images/Antenna/1715929546494.png)\n\n## Antenna Array\n\n1-D Linear Array\n\n2-D Planar Array\n\n3-D Conformal Array\n\nArray Element\n* Dipoles\n* Loops\n* Slots\n* Microstrip antennas\n\n### Two-Element array\n\n![1717133761533](../images/Antenna/1717133761533.png)\n\n$$\n\\begin{gathered}\n\\vec{E}_1= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_1}}{r_1}\\cos\\theta_1 \\\\\n\\vec{E}_{2}= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_2}}{r_2}\\cos\\theta_2 \n\\end{gathered}\n$$\n\nRemarks:\n* Two element;\n* Towards Y axis;\n* Along Z axis;\n* Space: d;\n* Uniform phase \nand amplitude;\n* Observe in 2D \n(YZ-plane).\n\nFar field Approximation\n\n![1717133876692](../images/Antenna/1717133876692.png)\n\n$$\n\\begin{aligned}&\\vec{E}_{total}=\\vec{E}_1+\\vec{E}_2\\\\&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac1r\\Bigg(e^{-jk(r-\\frac d2\\cos\\theta)}+e^{-jk(r+\\frac d2\\cos\\theta)}\\Bigg)\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n\\vec{E}_{total}& =\\vec{E}_1+\\vec{E}_2=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{1}{r}\\Bigg(e^{-jk(r-\\frac{d}{2}\\cos\\theta)}+e^{-jk(r+\\frac{d}{2}\\cos\\theta)}\\Bigg)  \\\\\n&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}{r}\\Bigg(e^{jk\\frac{d}{2}\\cos\\theta}+e^{-jk\\frac{d}{2}\\cos\\theta}\\Bigg) \\\\\n&=\\hat{\\theta}\\underbrace{\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}r}_{\\text{Element pattern}}\\underbrace{2\\cos\\biggl[\\frac12kd\\cos\\theta\\biggr]}_{\\text{Array Factor (AF)}}\n\\end{aligned}\n$$\n\nRemarks:\n* Uniform phase and amplitude;\n* AF is related to space (d);\n* AF is with no relation with antenna type.\n\n$$\nAF{=}2\\cos\\left[\\frac12kd\\cos\\theta\\right]\\quad kd{=}\\frac{2\\pi}\\lambda d{=}2\\pi\\frac d\\lambda \n$$\n\n![1717134268805](../images/Antenna/1717134268805.png)\n\n![1717134287481](../images/Antenna/1717134287481.png)\n\n### N-Element array\n\n![1717134353772](../images/Antenna/1717134353772.png)\n\n$$\n\\begin{aligned}&AF=1+e^{jkd\\cos\\theta}+e^{j2kd\\cos\\theta}+\\cdots+e^{j(N-1)kd\\cos\\theta}\\\\&=\\sum_{n=1}^Ne^{j(n-1)kd\\cos\\theta}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}\\end{aligned}\n$$\n\n$$\nAF=1+e^{j\\Psi}+e^{j2\\Psi}+\\cdots+e^{j(N-1)\\Psi}=\\frac{e^{jN\\Psi}-1}{e^{j\\Psi}-1}\\\\=\\frac{e^{j\\frac N2\\Psi}\\left(e^{j\\frac N2\\Psi}-e^{-j\\frac N2\\Psi}\\right)}{e^{j\\frac12\\Psi}\\left(e^{j\\frac12\\Psi}-e^{-j\\frac12\\Psi}\\right)}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$\n\nRefenece Point at the end:\n\n$$\nAF=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$\n\nRefenece Point at the center:\n\n$$\nAF=\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$\n\nIn Progreessive Phase Shift:\n\n$$\n\\Psi=kd\\cos\\theta+\\alpha \n$$\n\n$$\nAF=1+e^{j(kd\\cos\\theta+\\alpha)}+e^{j2(kd\\cos\\theta+\\alpha)}+\\cdots+e^{j(N-1)(kd\\cos\\theta+\\alpha)}\\\\=\\sum_{n=1}^Ne^{j(n-1)(kd\\cos\\theta+\\alpha)}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$\n\nNormalized Array Factor:\n\n$$\n\\left|f(\\Psi)\\right|=\\left|\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{N\\sin\\left(\\frac12\\Psi\\right)}\\right|\n$$\n\nGrating Lobe:\n\n$$\n\\begin{aligned}\n\\theta\\in\\begin{bmatrix}0,\\pi\\end{bmatrix}\\text{ or }\\theta\\in\\begin{bmatrix}\\theta_1,\\theta_2\\end{bmatrix}\\text{, visible region} \\\\\n\\text{In the visible region,} \\\\\nifwehaveY= 0\\mathrm{~and~}\\Psi=2\\pi. \n\\end{aligned}\n$$\n\nAvoid grating lobe:\n1. Smaller d;\n2. Smaller phase shift.\n\n$$\n1.\\mathrm{~For~}\\alpha=\\pi\\Rightarrow2kd<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<\\frac12\\\\2.\\mathrm{~For~}\\alpha=0\\mathrm{~}\\Rightarrow\\mathrm{~k}d<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<1\n$$\n\n#### Broadside Array\n\nMaximum @ $\\theta = 90\\degree$\n\n$$\nAF\\boldsymbol{=}N@\\boldsymbol{\\theta}\\boldsymbol{=}\\boldsymbol{\\pi}/2\\quad\\boldsymbol{\\Psi}\\boldsymbol{=}kd\\cos\\boldsymbol{\\theta}\\boldsymbol{+}\\boldsymbol{\\alpha}|_{\\theta=\\pi/2}\\boldsymbol{=}0\n$$\n\n![1717134725130](../images/Antenna/1717134725130.png)\n\n![1717134745100](../images/Antenna/1717134745100.png)\n\n#### End-fire Array\n\n![1717134897852](../images/Antenna/1717134897852.png)\n\n$$\n\\begin{aligned}\n&AF= N@\\theta{=}0  &\\Psi=kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2\\ldots)  \\\\\n&\\text{or} \\\\\n&AF= N@\\theta{=}\\pi   &\\Psi=-kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2...)  \\\\\n&\\Psi=kd\\cos\\theta+\\alpha=2\\pi\\cos\\theta \n\\end{aligned}\n$$\n\nBidirectional:\n\n![1717134942873](../images/Antenna/1717134942873.png)\n\nUnidirectional:\n\n![1717134955235](../images/Antenna/1717134955235.png)\n\n#### Phased Array\n\n![1717135044895](../images/Antenna/1717135044895.png)\n\n#### Non-uniform Array\n\nSide Lobe\n\nUniform array:\n* Universal pattern: N↑, SLL↓ \n* With a limit of -13.3 dB\n* No control of SL\n\nHow to reduce SLL?\n\nNon-uniform excitation\n\n![1717135171215](../images/Antenna/1717135171215.png)\n\n#### Planar Array\n\n![1717135198414](../images/Antenna/1717135198414.png)\n\nCan be viewed as product of two linear array factors:\n\n$$\nAF=\\sum_{i=1}^{M\\times N}I_ie^{jk\\hat{r}\\cdot\\vec{r}_i}\\\\\nAF_n(\\theta,\\phi)=\\left\\{\\frac{\\sin(\\frac M2\\psi_x)}{M\\sin\\frac{\\psi_x}2}\\right\\}\\left\\{\\frac{\\sin(\\frac N2\\psi_y)}{N\\sin\\frac{\\psi_y}2}\\right\\};\\\\\\psi_x=kd_x\\sin\\theta\\cos\\varphi+\\alpha_x\\\\\\psi_y=kd_y\\sin\\theta\\sin\\varphi+\\alpha_y\n$$\n\n### Applications\n\n#### Yagi-Uda Antenna\n\nBasic configuration:\n* One driven element;\n* Two parasitic elements or more\n\n![1717135386351](../images/Antenna/1717135386351.png)\n\nRemarks:\n* Parasitic elements are excited by near-field coupling from the driven element;\n* Proper design of parasitic elements for end fire radiation;\n* In far field, the radiated waves from all the elements are in-phase.\n\n![1717135675789](../images/Antenna/1717135675789.png)\n\n![1717135951201](../images/Antenna/1717135951201.png)\n\n#### Helix Antenna\n\n![1717136046473](../images/Antenna/1717136046473.png)\n\n![1717136115015](../images/Antenna/1717136115015.png)\n\n## Travelling-Wave Antennas\n\n### Travelling wave & standing wave\n\n#### Long wire antennas\n\n![1717137633424](../images/Antenna/1717137633424.png)\n\n![1717137646795](../images/Antenna/1717137646795.png)\n\nNote:\nLong wire antennas: “l” = Several wavelength\n* One end for excitation;\n* The other end for load (open, short, or matching);\n* Transmission line with radiation.\n\n### Log-periodic Antennas\n\nYagi-Uda: High Gain\n\nLog-periodic: Wide Bandwidth\n\n![1717138714524](../images/Antenna/1717138714524.png)\n\nWhy:\n1. Feed from smaller dipole element;\n2. Feed out-of-phase with adjacent elements;\n3. Add a resistor at the end.\n\n\n$$\n\\tau=\\frac{R_{n+1}}{R_{n}}=\\frac{L_{n+1}}{L_{n}}=\\frac{d_{n+1}}{d_{n}}\\\\\\alpha=2\\tan^{-1}\\left(\\frac{1-\\tau}{4\\sigma}\\right)\\\\\\sigma=\\frac{d_{n}}{2L_{n}}\\\\L_{1}\\approx\\frac{\\lambda_{L}}{2}\\quad\\mathrm{and}\\quad L_{N}\\approx\\frac{\\lambda_{U}}{2}\n$$\n\n![1717138873279](../images/Antenna/1717138873279.png)\n\n## Microstrip Antennas  \n\n\n![1717740667735](../images/Antenna/1717740667735.png)\n\n![1717740670364](../images/Antenna/1717740670364.png)\n\n![1717740680573](../images/Antenna/1717740680573.png)\n\n### Basic Mode\n\n* Equivalent magnetic current;\n* Radiating and non-radiating apertures;\n* Operating frequency with different L.\n\n![1717740726098](../images/Antenna/1717740726098.png)\n\n* Magnetic current array;\n* Image theorem from infinite ground;\n* Cavity model with magnetic walls;\n* Different from\n\n![1717740758890](../images/Antenna/1717740758890.png)\n\n![1717740768183](../images/Antenna/1717740768183.png)\n\n### Antenna feeding methods\n\n![1717740786849](../images/Antenna/1717740786849.png)\n\nImpedance Matching:\n\n![1717740801741](../images/Antenna/1717740801741.png)\n\nUsing 50-Ohm port: finding the position with Z_in=50 Ohm\n\n### Analysis Model\n\n![1717742374397](../images/Antenna/1717742374397.png)\n\nKnown:\n* Operating Frequency\n* Dielectric: $\\varepsilon_r$ and $h$\n* Metal: $t$\n\nDesign: \n* Patch: $L$ and $W$\n* Evaluate gain\n\n2 Models:\n\n![1717742413544](../images/Antenna/1717742413544.png)\n\n#### Transmission line model\n\ndetermine W\n\nUniform distribution and  field intensity in dielectric\n\n$$\nW=\\frac{1}{2f_r\\sqrt{\\mu_0\\epsilon_0}}\\sqrt{\\frac{2}{\\epsilon_r+1}}\n$$\n\nEffective permittivity\n\n$$\n\\varepsilon_{eff}=\\frac{\\varepsilon_r+1}2+\\frac{\\varepsilon_r-1}2{\\left[1+12\\frac hW\\right]}^{-1/2}\n$$\n\nFring effect and determine L\n\n$$\n\\frac{\\Delta L}{h}=0.412\\frac{(\\varepsilon_{eff}+0.3)(\\frac Wh+0.264)}{(\\varepsilon_{eff}-0.258)(\\frac Wh+0.8)}\\\\L=\\frac{\\lambda_d}2-2\\Delta L=\\frac{\\lambda_0}{2\\sqrt{\\varepsilon_{eff}}}-2\\Delta L\n$$\n\nimpedance matching\n\n#### Cavity Model\n\n![1717742626807](../images/Antenna/1717742626807.png)\n\n![1717743460723](../images/Antenna/1717743460723.png)\n\n![1717743468657](../images/Antenna/1717743468657.png)\n\n### Circular polarization\n\nDual feed patch\n\n![1717743681072](../images/Antenna/1717743681072.png)\n\n![1717743691321](../images/Antenna/1717743691321.png)\n\n![1717743927411](../images/Antenna/1717743927411.png)\n\n![1718344358151](../images/Antenna/1718344358151.png)\n\nSP-feed 旋转馈电\n\n## Reflector and lens antennas\n\n![1718345601277](../images/Antenna/1718345601277.png)\n\n### Corner Reflectors\n\n![1718345727630](../images/Antenna/1718345727630.png)\n\n![1718345718761](../images/Antenna/1718345718761.png)\n\n### Parabolic Reflectors\n\n![1718346212882](../images/Antenna/1718346212882.png)\n\n![1718346379534](../images/Antenna/1718346379534.png)\n\n![1718346371235](../images/Antenna/1718346371235.png)\n\n![1718346571584](../images/Antenna/1718346571584.png)\n\n### Lens Antennas\n\n![1718346830900](../images/Antenna/1718346830900.png)\n\nLens antennas:\n* High gain: plane wave;\n* Geometrical optics: equal optical distance;\n* Source: spherical wave, illuminate the whole lens;\n* Source is positioned on the focal point for normal \nradiated plane wave;\n* Other incident/radiated angle of plane wave: focus on \nthe focal plane with gain decrease;\n* Spatial Fournier Transformation: (x, y)&k\n\n### Reflected and transmitted array\n\n![1718347859765](../images/Antenna/1718347859765.png)\n\n![1718347869028](../images/Antenna/1718347869028.png)\n\n","slug":"Antenna","published":1,"updated":"2024-06-14T06:51:10.497Z","_id":"clu1gtfho0001rsug0ragehji","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Introduction-of-Antenna\"><a href=\"#Introduction-of-Antenna\" class=\"headerlink\" title=\"Introduction of Antenna\"></a>Introduction of Antenna</h2><p>Definition of Antenna</p>\n<ul>\n<li>Transmitter and receiver of EM wave</li>\n<li>Signal from current to wave</li>\n<li>from lumped to distributed</li>\n</ul>\n<p>Antenna classifications</p>\n<ul>\n<li>Resonant and non-resonant&#x2F;leaky&#x2F;travelling wave</li>\n<li>Antenna number: element, multiple antennas, array</li>\n<li>Shape: wire, loop, slot, patch&#x2F;microstrip, cavity</li>\n<li>Materials: metallic, dielectric</li>\n<li>Property: wideband, narrow band</li>\n<li>Yagi-Uda, Vivaldi, Cassegrain</li>\n<li>Function: moblie&#x2F;handset, base station, AiP</li>\n</ul>\n<h2 id=\"Maxwell-equations\"><a href=\"#Maxwell-equations\" class=\"headerlink\" title=\"Maxwell equations\"></a>Maxwell equations</h2><div>$$\n\\nabla \\cdot \\vec D = \\rho \\rightarrow \\nabla \\cdot \\tilde{\\vec D} = \\rho \\\\\n\\nabla \\cdot {\\vec B} = 0 \\rarr \\nabla \\cdot \\tilde{\\vec B} = 0\\\\\n\\nabla \\times {\\vec E} = -\\frac{\\partial \\vec B}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec E} = -j\\omega \\tilde{\\vec B}\\\\\n\\nabla \\times {\\vec H} = \\vec J + \\frac{\\partial \\vec D}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec H} = \\vec J + j\\omega \\tilde{\\vec D}\\\\\n\\vec D = \\varepsilon \\vec E\\\\\n\\vec B = \\mu \\vec H\n$$</div>\n\n<div>$$\n\\nabla^2 \\vec F = \\nabla(\\nabla \\cdot \\vec F) - \\nabla \\times (\\nabla \\times \\vec F)\\\\\n\\nabla \\times (\\nabla f) = 0\\\\\n\\nabla \\cdot (\\nabla \\times \\vec F) = 0\n$$</div>\n\n<h2 id=\"Auxiliary-Potential-Functions\"><a href=\"#Auxiliary-Potential-Functions\" class=\"headerlink\" title=\"Auxiliary Potential Functions\"></a>Auxiliary Potential Functions</h2><p>Let</p>\n<div>$$\n\\vec B = \\nabla \\times \\vec A\\\\\n\\vec E + j\\omega \\vec A = -\\nabla \\phi\n$$</div>\n\n<div>$$\n\\nabla \\cdot \\vec D = \\varepsilon \\nabla \\cdot(-\\nabla \\phi  - j\\omega \\vec A) = \\rho\\\\\n\\Rightarrow \\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon} - j\\omega(\\nabla \\cdot \\vec A + j\\omega \\mu \\varepsilon \\phi)\n$$</div>\n\n<div>$$\n\\nabla \\times \\vec H = \\frac{1}{\\mu}(\\nabla(\\nabla \\cdot \\vec A) - \\nabla^2\\vec A) = \\vec J + j\\omega \\vec D = \\vec J + j\\omega\\varepsilon(-\\nabla\\phi - j\\omega \\vec A)\\\\\n\\Rightarrow \\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J - \\nabla(\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi)\n$$</div>\n\n<p>Use Lorentz Gauge</p>\n<div>$$\n\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi = 0\n$$</div>\n\n<p>Then</p>\n<div>$$\n\\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J\\\\\n\\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon}\n$$</div>\n\n<p>Solve ODE:</p>\n<div>$$\n\\begin{equation}  \n\\nabla^2\\phi + k^2\\phi = 0(r\\ne 0)\n\\end{equation}\\\\\n\\begin{equation}\n\\nabla^2\\phi + k^2\\phi = -\\frac{\\rho}{\\varepsilon}(r=0)\n\\end{equation}\n$$</div>\n\n<p>For (1)</p>\n<div>$$\nu(r) = \\frac{\\phi(r)}{r}\\\\\n\\frac{\\rm{d}^2}{\\rm{d}r^2}u + k^2u = 0\\\\\nu = C_1e^{-jkr} + C_2e^{jkr}\\\\\n\\phi = C_1\\frac{e^{-jkr}}{r}\n$$</div>\n\n<p>For (2), in arbitrary volume</p>\n<div>$$\n\\iiint_V(\\nabla^2\\phi + k^2\\phi)\\mathrm dv = \\iiint_V(-\\frac{\\rho}{\\varepsilon}\\mathrm dv) = -\\frac{q}{\\varepsilon}\\\\\nr \\rightarrow 0\\\\\n\\iiint_V(k^2\\phi)\\mathrm dv = 0\\\\\n\\iiint_V\\nabla^2\\phi \\mathrm dv = \\oiint_S \\nabla\\phi \\cdot \\mathrm d\\vec s = C_1 \\oiint_S (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})\\mathrm d\\vec s = C_1 (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})4\\pi r^2 = -C_1 4\\pi\n$$</div>\n\n<p>Finally,</p>\n<div>$$\n\\phi(r) = \\frac{q}{4\\pi\\varepsilon}\\frac{e^{-jkr}}{r}\n$$</div>\n\n<h2 id=\"Radiation-Parameters\"><a href=\"#Radiation-Parameters\" class=\"headerlink\" title=\"Radiation Parameters\"></a>Radiation Parameters</h2><h3 id=\"Field-Zone\"><a href=\"#Field-Zone\" class=\"headerlink\" title=\"Field Zone\"></a>Field Zone</h3><p>Near field: resonant, field;</p>\n<p>Far field: propagation, wave;</p>\n<p>Fresnel region: transition;</p>\n<p><img src=\"/../images/Antenna/1711090268476.png\" alt=\"1711090268476\" loading=\"lazy\"></p>\n<h3 id=\"Antenna-Parameters\"><a href=\"#Antenna-Parameters\" class=\"headerlink\" title=\"Antenna Parameters\"></a>Antenna Parameters</h3><ul>\n<li>Radiation patterns</li>\n<li>Radiation Intensity</li>\n<li>Power Density</li>\n<li>Directivity (方向性) and Gain (重要！)</li>\n<li>Polarization</li>\n<li>Effective Aperture(等效口面) and Aperture efficienty(口面效率)</li>\n</ul>\n<p>E 面：与电场方向平行的面</p>\n<p>H 面：与磁场方向平行的面</p>\n<h4 id=\"Pattern-Parameters\"><a href=\"#Pattern-Parameters\" class=\"headerlink\" title=\"Pattern Parameters\"></a>Pattern Parameters</h4><p><img src=\"/../images/Antenna/1711090565574.png\" alt=\"1711090565574\" loading=\"lazy\"></p>\n<p>Often use log scale.</p>\n<h4 id=\"Power-Density\"><a href=\"#Power-Density\" class=\"headerlink\" title=\"Power Density\"></a>Power Density</h4><p>Instantaneous Poynting vector $\\vec S(x, y, z, t)$</p>\n<p>Radiation Power Density &#x3D; Time average Poynting vector $\\vec S_{av}(x, y, z)&#x3D;\\frac1T\\int_0^T\\vec S(x, y, z, t)\\mathrm dt &#x3D; \\frac12\\text{Re}[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}]$</p>\n<p>Total Radiation Power $P_{rad} &#x3D; \\oiint_S[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}] \\cdot \\mathrm d\\vec s$</p>\n<h4 id=\"Radiation-Intensity\"><a href=\"#Radiation-Intensity\" class=\"headerlink\" title=\"Radiation Intensity\"></a>Radiation Intensity</h4><div>$$\nU(\\theta, \\varphi) = r^2 S(r, \\theta, \\varphi)\n$$</div>\n\n<p>Isotropic 各向同性</p>\n<div>$$\nP_{rad} = \\int_{0}^{2\\pi}\\int_{0}^{\\pi}U\\sin\\theta\\mathrm d\\theta\\mathrm d\\varphi\n$$</div>\n\n<h4 id=\"Directivity\"><a href=\"#Directivity\" class=\"headerlink\" title=\"Directivity\"></a>Directivity</h4><div>$$\nD = \\frac{U_{\\max}}{U_{av}} = \\frac{P_{\\max}}{P_{rad}/4\\pi}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1711091202619.png\" alt=\"1711091202619\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1711091212947.png\" alt=\"1711091212947\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1711693683771.png\" alt=\"1711693683771\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1711693701192.png\" alt=\"1711693701192\" loading=\"lazy\"></p>\n<h4 id=\"Gain\"><a href=\"#Gain\" class=\"headerlink\" title=\"Gain\"></a>Gain</h4><p><img src=\"/../images/Antenna/1711693749686.png\" alt=\"1711693749686\" loading=\"lazy\"></p>\n<div>$$\nG = \\frac{U_{\\max}}{P_{in}/4\\pi}\n$$</div>\n\n<h4 id=\"Polarization\"><a href=\"#Polarization\" class=\"headerlink\" title=\"Polarization\"></a>Polarization</h4><p><img src=\"/../images/Antenna/1711693845822.png\" alt=\"1711693845822\" loading=\"lazy\"></p>\n<p>Polarization Mismatch:</p>\n<p><img src=\"/../images/Antenna/1711693861642.png\" alt=\"1711693861642\" loading=\"lazy\"></p>\n<p>CP</p>\n<p><img src=\"/../images/Antenna/1711693936592.png\" alt=\"1711693936592\" loading=\"lazy\"></p>\n<h4 id=\"Effective-Aperture-and-Aperture-efficiency\"><a href=\"#Effective-Aperture-and-Aperture-efficiency\" class=\"headerlink\" title=\"Effective Aperture and Aperture efficiency\"></a>Effective Aperture and Aperture efficiency</h4><p><img src=\"/../images/Antenna/1711694027177.png\" alt=\"1711694027177\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1711694083583.png\" alt=\"1711694083583\" loading=\"lazy\"></p>\n<h3 id=\"Circuit-Parameters\"><a href=\"#Circuit-Parameters\" class=\"headerlink\" title=\"Circuit Parameters\"></a>Circuit Parameters</h3><h4 id=\"Input-impedance\"><a href=\"#Input-impedance\" class=\"headerlink\" title=\"Input impedance\"></a>Input impedance</h4><p>Input impedance definition:</p>\n<ul>\n<li>the impedance presented by an antenna at its terminals</li>\n<li>the ratio of the voltage to current at its terminals</li>\n<li>the ratio of the electric to magnetic fields at its terminals</li>\n</ul>\n<p><img src=\"/../images/Antenna/1711694243897.png\" alt=\"1711694243897\" loading=\"lazy\"></p>\n<h5 id=\"Conjugate-Matching\"><a href=\"#Conjugate-Matching\" class=\"headerlink\" title=\"Conjugate Matching\"></a>Conjugate Matching</h5><div>$$\nZ_A = Z_g^*\n$$</div>\n\n<h5 id=\"Mismatching\"><a href=\"#Mismatching\" class=\"headerlink\" title=\"Mismatching\"></a>Mismatching</h5><p><img src=\"/../images/Antenna/1711694350257.png\" alt=\"1711694350257\" loading=\"lazy\"></p>\n<h5 id=\"Radiation-Resistance\"><a href=\"#Radiation-Resistance\" class=\"headerlink\" title=\"Radiation Resistance\"></a>Radiation Resistance</h5><div>$$\nP_{rad} = \\frac12|I_g|^2R_r = \\oiint_S\\vec S_{av} \\cdot \\rm d\\vec s\n$$</div>\n\n<p><img src=\"/../images/Antenna/1711694462059.png\" alt=\"1711694462059\" loading=\"lazy\"></p>\n<h4 id=\"Scattering-Parameters\"><a href=\"#Scattering-Parameters\" class=\"headerlink\" title=\"Scattering Parameters\"></a>Scattering Parameters</h4><p><img src=\"/../images/Antenna/1711694619870.png\" alt=\"1711694619870\" loading=\"lazy\"></p>\n<div>$$\n\\frac{\\Gamma^2}{Z_1} + \\frac{T^2}{Z_2} = 1\n$$</div>\n\n<p><img src=\"/../images/Antenna/1711694639638.png\" alt=\"1711694639638\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1711695738159.png\" alt=\"1711695738159\" loading=\"lazy\"></p>\n<p>二端口网络通常用于描述二天线问题。$S_{11}$表示天线1的反射，$S_{21}$表示天线1到天线2的耦合，均不利于信号的传播。我们希望让$1 - S_{11}^2 - S_{21}^2$尽可能大。</p>\n<h2 id=\"Link-Calculation\"><a href=\"#Link-Calculation\" class=\"headerlink\" title=\"Link Calculation\"></a>Link Calculation</h2><h3 id=\"Friis’s-Equation\"><a href=\"#Friis’s-Equation\" class=\"headerlink\" title=\"Friis’s Equation\"></a>Friis’s Equation</h3><p><img src=\"/../images/Antenna/1712471419276.png\" alt=\"1712471419276\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1712471436962.png\" alt=\"1712471436962\" loading=\"lazy\"></p>\n<h3 id=\"EIRP\"><a href=\"#EIRP\" class=\"headerlink\" title=\"EIRP\"></a>EIRP</h3><p><img src=\"/../images/Antenna/1712471499226.png\" alt=\"1712471499226\" loading=\"lazy\"></p>\n<p>赫兹偶极子的辐射电阻： $80\\pi^2(\\frac{\\Delta z}{\\lambda})^2$，方向性 $\\frac{2}{3}$。</p>\n<h3 id=\"Radar-Equation\"><a href=\"#Radar-Equation\" class=\"headerlink\" title=\"Radar Equation\"></a>Radar Equation</h3><p><img src=\"/../images/Antenna/1712473473687.png\" alt=\"1712473473687\" loading=\"lazy\"></p>\n<p>RCS(Radar cross section)</p>\n<p>RCS (σ) of a radar target is an effective area that intercepts the transmitted radar power and then<br>scatters that power isotropically back to the radar receiver.</p>\n<div>$$\n\\sigma=\\lim_{R\\to\\infty}\\frac{W_{o}4\\pi R^2}{W_i}\n$$</div>\n\n<ul>\n<li>$W_i$, $W_o$ and $R$ are known;</li>\n<li>$\\sigma$ converges.</li>\n</ul>\n<h2 id=\"Antenna-Theorems\"><a href=\"#Antenna-Theorems\" class=\"headerlink\" title=\"Antenna Theorems\"></a>Antenna Theorems</h2><div>$$\n\\boxed{P_r=\\mathrm{P}_t\\mathrm{G}_t\\mathrm{G}_r(\\frac{\\lambda}{4\\pi R})^2}\n$$</div>\n\n<div>$$\nP_{r}=P_{t}\\mathrm{e}_{r}\\mathrm{e}_{t}D_{r}\\mathrm{D}_{t}(1-\\left|\\Gamma_{r}\\right|^{2})(1-\\left|\\Gamma_{t}\\right|^{2})(\\frac{\\lambda}{4\\pi R})^{2}\n$$</div>\n\n<p>In radar:</p>\n<div>$$\nP_{r}=P_{t}\\mathrm{G}_{t}\\mathrm{G}_{r}\\sigma\\frac{1}{4\\pi}(\\frac{\\lambda}{4\\pi R_{1}R_{2}})^{2}\n$$</div>\n\n<p>Equivalent circuit model</p>\n<p><img src=\"/../images/Antenna/1712900712333.png\" alt=\"1712900712333\" loading=\"lazy\"></p>\n<p>$R_r$ ：接收天线反射会释放能量。</p>\n<h3 id=\"Duality-Theorem\"><a href=\"#Duality-Theorem\" class=\"headerlink\" title=\"Duality Theorem\"></a>Duality Theorem</h3><p><img src=\"/../images/Antenna/1712901375924.png\" alt=\"1712901375924\" loading=\"lazy\"></p>\n<p>电 -&gt; 磁，不变号；<br>磁 -&gt; 电，变号。</p>\n<h3 id=\"Image-Theorem\"><a href=\"#Image-Theorem\" class=\"headerlink\" title=\"Image Theorem\"></a>Image Theorem</h3><p>PEC：完美电导体</p>\n<p>PMC：完美磁导体</p>\n<p>定理条件：</p>\n<ul>\n<li>PEC or PMC</li>\n<li>Infinite boundary</li>\n</ul>\n<p>PEC</p>\n<div>$$\n\\begin{aligned}&\\hat{n}\\times\\vec{E}=0\\\\&\\hat{n}\\cdot\\vec{B}=0\\end{aligned}\n$$</div>\n\n<p>PMC</p>\n<div>$$\n\\begin{aligned}&\\hat{n}\\times\\vec{H}=0\\\\&\\hat{n}\\cdot\\vec{D}=0\\end{aligned}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1712902160882.png\" alt=\"1712902160882\" loading=\"lazy\"></p>\n<p>Note:</p>\n<ul>\n<li>Satisfied with boundary condition;</li>\n<li>Mirror source instead of PEC or PMC infinite boundary;</li>\n<li>Array: source and mirror source;</li>\n<li>Current loop: upper inside, lower outside.</li>\n</ul>\n<h3 id=\"Reciprocity-Theorem\"><a href=\"#Reciprocity-Theorem\" class=\"headerlink\" title=\"Reciprocity Theorem\"></a>Reciprocity Theorem</h3><p>In radiation pattern,</p>\n<p><img src=\"/../images/Antenna/1712903308547.png\" alt=\"1712903308547\" loading=\"lazy\"></p>\n<p>Transmitting pattern of antenna “a”</p>\n<div>$$\nZ_{_{ba}}(\\theta,\\varphi)=\\frac{V_{_b}(\\theta,\\varphi)}{I_{_a}}\n$$</div>\n\n<p>Receiving pattern of ante</p>\n<div>$$\nZ_{ab}(\\theta,\\varphi)=\\frac{V_{a}(\\theta,\\varphi)}{I_{b}}\n$$</div>\n\n<p>Then,</p>\n<div>$$\nZ_{ab}(\\theta,\\phi)=Z_{ba}(\\theta,\\phi)\n$$</div>\n\n<p>Lorentz Reciprocity Theorem</p>\n<div>$$\n-\\nabla\\cdot(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})=\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\\\\n-\\oiint_{S}(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})\\cdot ds^{'}=\\iiint_{V}\\left(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\right)dv^{'}\n$$</div>\n\n<p>Far field:</p>\n<div>$$\n\\vec{H}_i=\\hat{r}\\times\\vec{E}_i/\\eta;\\quad d\\vec{s}=\\hat{n}ds=\\hat{r}ds\n$$</div>\n\n<div>$$\n(\\vec{E}_1\\times\\vec{H}_2-\\vec{E}_2\\times\\vec{H}_1)\\cdot\\hat{r}=(\\hat{r}\\times\\vec{E}_1)\\cdot\\vec{H}_2-(\\hat{r}\\times\\vec{E}_2)\\cdot\\vec{H}_1=0\n$$</div>\n\n<div>$$\n\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=0\\\\\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=\\iiint_{V}\\Big(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1}\\Big)d\\nu^{'}\n$$</div>\n\n<p>Reaction: Reciprocity theorem: $\\langle 1 2\\rangle&#x3D;\\langle 2,1\\rangle$</p>\n<div>$$\n\\left\\langle1,2\\right\\rangle=\\int_{V}(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2})d\\nu\\quad\\left\\langle2,1\\right\\rangle=\\int_{V}(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1})d\\nu \n$$</div>\n\n<p>If only current-source</p>\n<div>$$\n\\iiint_V\\vec{E}_1\\cdot\\vec{J}_2d\\nu=\\iiint_V\\vec{E}_2\\cdot\\vec{J}_1d\\nu\\\\\n\\vec{E}_1\\cdot\\vec{J}_2=\\vec{E_2} \\cdot \\vec{J_1}\n$$</div>\n\n<p>Non-reciprocity</p>\n<p>Electron plasma (non-reciprocal media)</p>\n<div>$$\n\\varepsilon = \\begin{bmatrix}\\varepsilon_{xx}&+ig&0\\\\-ig&\\varepsilon_{yy}&0\\\\0&0&\\varepsilon_{zz}\\end{bmatrix}\n$$</div>\n\n<h3 id=\"Huygen’s-Principle\"><a href=\"#Huygen’s-Principle\" class=\"headerlink\" title=\"Huygen’s Principle\"></a>Huygen’s Principle</h3><p><img src=\"/../images/Antenna/1712905110844.png\" alt=\"1712905110844\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1712905233876.png\" alt=\"1712905233876\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1712905317317.png\" alt=\"1712905317317\" loading=\"lazy\"></p>\n<h2 id=\"Dipole-Antenna\"><a href=\"#Dipole-Antenna\" class=\"headerlink\" title=\"Dipole Antenna\"></a>Dipole Antenna</h2><h3 id=\"Hertz-Dipole\"><a href=\"#Hertz-Dipole\" class=\"headerlink\" title=\"Hertz Dipole\"></a>Hertz Dipole</h3><ul>\n<li>Infinite short length;</li>\n<li>Uniform distribution;</li>\n<li>Infinite small radius;</li>\n</ul>\n<div>$$\nE_\\theta=\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr}}r\\sin\\theta \\\\\nH_\\varphi=\\frac{I\\Delta z}{4\\pi}jk\\frac{e^{-jkr}}r{\\sin\\theta}\\\\\n\\frac{E_\\theta}{H_\\varphi}=\\sqrt{\\frac{\\mu_0}{\\varepsilon_0}}=\\eta \n$$</div>\n\n<p><img src=\"/../images/Antenna/1713506228135.png\" alt=\"1713506228135\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1713506258888.png\" alt=\"1713506258888\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1713506275022.png\" alt=\"1713506275022\" loading=\"lazy\"></p>\n<h3 id=\"Finite-Length-Dipole\"><a href=\"#Finite-Length-Dipole\" class=\"headerlink\" title=\"Finite Length Dipole\"></a>Finite Length Dipole</h3><p><img src=\"/../images/Antenna/1713506837120.png\" alt=\"1713506837120\" loading=\"lazy\"></p>\n<div>$$\nI=\\begin{cases}I_0\\sin[k(\\dfrac{l}{2}-z')]&0\\leq z'\\leq\\dfrac{l}{2}\\\\\nI_0\\sin[k(\\dfrac{l}{2}+z')]&-\\dfrac{l}{2}\\leq z'\\leq0\\end{cases}\n$$</div>\n\n<div>$$\n\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-j\\kappa\\Lambda}}{4\\pi R}dz’\\\\R=\\sqrt{\\left(x-x’\\right)^2+\\left(y-y’\\right)^2+\\left(z-z’\\right)^2}\n$$</div>\n\n<div>$$\n\\begin{aligned}&\\text{For phase:}&&R\\cong r-z'\\cos\\theta\\\\&\\text{For amplitude:}&&R\\cong r\\end{aligned}\n$$</div>\n\n<p>R is the distance between observer and source,<br>r is the distance between observer and origin.</p>\n<h4 id=\"Small-Dipole\"><a href=\"#Small-Dipole\" class=\"headerlink\" title=\"Small Dipole\"></a>Small Dipole</h4><p><img src=\"/../images/Antenna/1713506363705.png\" alt=\"1713506363705\" loading=\"lazy\"></p>\n<div>$$\n\\begin{aligned}&I(z’)\\cong I_{in}(1-2|z’|/l)\\\\&\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-jkr}}{4\\pi r}dz’\\end{aligned}\n$$</div>\n\n<p>Then</p>\n<div>$$\n\\vec{A}(x,y,z)=\\hat{z}\\mu\\frac{e^{-jkr}}{4\\pi r}\\cdot\\frac12I_{in}l\\\\\n\\vec{A}(\\theta,r)=\\frac12I_{in}l\\mu\\frac{e^{-jkr}}{4\\pi r}(-\\sin\\theta\\hat{\\theta}+\\cos\\theta\\hat{r})\n$$</div>\n\n<div>$$\n\\vec{E}=j\\omega\\mu I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\theta}\\\\\\vec{H}=j\\beta I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\varphi}\n$$</div>\n\n<p>Note: half of the ideal infinitesima(Hertz) dipole</p>\n<div>$$\n\\mathrm{Directivity}:\\quad D=\\frac{4\\pi}{\\Omega_A}\\Rightarrow D_{\\underset{dipole}{\\operatorname*{small}}}=1.5\n$$</div>\n\n<div>$$\nR_{rad}=20\\left(\\frac{\\pi\\Delta z}\\lambda\\right)^2=\\frac14R_{rad}^\\textit{Hertz dipole}\n$$</div>\n\n<div>$$\nP_{rad}=\\frac14\\frac{4\\pi}3{\\left(\\frac{I\\Delta z}{4\\pi}\\right)}^2k^2\\eta{=}\\frac12I^2R_{rad}\n$$</div>\n\n<h4 id=\"General-Case\"><a href=\"#General-Case\" class=\"headerlink\" title=\"General Case\"></a>General Case</h4><div>$$\nE_{\\theta}=j\\eta\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\\\\H_{\\varphi}=j\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\n$$</div>\n\n<p>Beam width: change with length.</p>\n<p><img src=\"/../images/Antenna/1713507175699.png\" alt=\"1713507175699\" loading=\"lazy\"></p>\n<div>$$\n\\begin{aligned}\n&\\textbf{The time average Poynting vector:}\\\\\n&\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\mathrm{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})}{\\sin\\theta}\\bigg]^{2}\\hat{r}  \\\\\n&P_{rad}=\\oint_{s}\\vec{S}_{a\\nu}\\cdot d\\vec{s}=\\int_{0}^{2\\pi}\\int_{0}^{\\pi}\\vec{S}_{a\\nu}\\cdot\\vec{r}r^{2}\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_{0}\\right|^{2}}{4\\pi}\\int_{0}^{\\pi}\\frac{\\left[\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})\\right]^{2}}{\\sin\\theta}d\\theta  \\\\\n&\\begin{aligned}&\\text{The radiation intensity:}\\\\&&U=r^2S_{av}=\\eta\\frac{\\left|I_0\\right|^2}{8\\pi^2}\\left[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\right]^2\\\\&&=\\frac{\\pi}{2}=\\frac{\\left|I_{0}\\right|^{2}}{2}=\\frac{k_{0}}{2}=\\frac{k_{0}}{2}\\end{aligned}& \\begin{matrix}{l}\\\\\\end{matrix})  \\\\\n&\\Omega_A=\\frac{P_{rad}}{U_{\\max}}\\quad D=4\\pi/\\Omega_A\\quad A_e=\\frac{\\lambda^2}{4\\pi}D\\quad P_{rad}=\\frac12I^2R_{rad}\n\\end{aligned}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1713507190746.png\" alt=\"1713507190746\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1713507205996.png\" alt=\"1713507205996\" loading=\"lazy\"></p>\n<h4 id=\"Input-Impedance\"><a href=\"#Input-Impedance\" class=\"headerlink\" title=\"Input Impedance\"></a>Input Impedance</h4><p>Input resistance $R_r$:</p>\n<ul>\n<li>calculated by E and H at port; </li>\n<li>take the real part (lossless).</li>\n</ul>\n<p>Radiation resistance $R_{rad}$:</p>\n<ul>\n<li>calculated by E and H at far-field;</li>\n</ul>\n<div>$$\nP_{rad}=\\frac12{\\left|I\\right|}^2R_{rad}\\quad P_{rad}=\\frac12{\\left|I_{in}\\right|}^2R_r\n$$</div>\n\n<p>I is the maximum&#x2F;peak current.</p>\n<p>General Relation:</p>\n<div>$$\nR_r=R_{rad}/\\sin^2\\left(\\frac{kl}2\\right)\n$$</div>\n\n<h3 id=\"Half-wavelength-dipole\"><a href=\"#Half-wavelength-dipole\" class=\"headerlink\" title=\"Half-wavelength dipole\"></a>Half-wavelength dipole</h3><p><img src=\"/../images/Antenna/1713508252106.png\" alt=\"1713508252106\" loading=\"lazy\"></p>\n<div>$$\nI(z)=I_0\\sin(\\frac\\pi2-k\\left|z\\right|)\n$$</div>\n\n<div>$$\nE_\\theta(r,\\theta,\\varphi)=j\\eta I_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\\\\H_\\varphi(r,\\theta,\\varphi)=jI_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\n$$</div>\n\n<div>$$\n\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\operatorname{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{\\pi}{2}\\cos\\theta)}{\\sin\\theta}\\bigg]^{2}\\hat{r}\\\\\nP_{rad}=\\oint_sS_{a\\nu}\\cdot d\\vec{s}=\\int_0^{2\\pi}\\int_0^\\pi\\vec{S}_{a\\nu}\\cdot\\hat{r}r^2\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_0\\right|^2}{4\\pi}\\int_0^\\pi\\frac{\\cos^2(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}d\\theta \n$$</div>\n\n<div>$$\nD=4\\pi/\\Omega_{A}=1.643=2.15\\mathrm{dBi}\\\\\nA_e=\\frac{\\lambda^2}{4\\pi}D_0\\cong0.13\\lambda^2\n$$</div>\n\n<p>Edge capacitive effect: </p>\n<ul>\n<li>Terminal (open-end)<br>current is not ideal zero;</li>\n<li>Effective length is longer</li>\n</ul>\n<div>$$\nR_r=R_{rad}=\\frac{2P_{rad}}{\\left|I_0\\right|^2}\\cong73\\left(\\Omega\\right)\\\\\nZ_A=73+j43\\left(\\Omega\\right)\n$$</div>\n\n<h3 id=\"Applications\"><a href=\"#Applications\" class=\"headerlink\" title=\"Applications\"></a>Applications</h3><h4 id=\"Wideband-Antennas\"><a href=\"#Wideband-Antennas\" class=\"headerlink\" title=\"Wideband Antennas\"></a>Wideband Antennas</h4><p><img src=\"/../images/Antenna/1713508669926.png\" alt=\"1713508669926\" loading=\"lazy\"></p>\n<h4 id=\"Folded-Dipole\"><a href=\"#Folded-Dipole\" class=\"headerlink\" title=\"Folded Dipole\"></a>Folded Dipole</h4><p><img src=\"/../images/Antenna/1713508784675.png\" alt=\"1713508784675\" loading=\"lazy\"></p>\n<div>$$\nZ_=4Z_A\n$$</div>\n\n<p>Increase Input Impedance</p>\n<h4 id=\"Log-periodic-amp-Yagi-Uda-antenna\"><a href=\"#Log-periodic-amp-Yagi-Uda-antenna\" class=\"headerlink\" title=\"Log-periodic &amp; Yagi-Uda antenna\"></a>Log-periodic &amp; Yagi-Uda antenna</h4><p><img src=\"/../images/Antenna/1713509120707.png\" alt=\"1713509120707\" loading=\"lazy\"></p>\n<h4 id=\"Dipole-Antennas-in-base-station\"><a href=\"#Dipole-Antennas-in-base-station\" class=\"headerlink\" title=\"Dipole Antennas in base station\"></a>Dipole Antennas in base station</h4><p><img src=\"/../images/Antenna/1713509734724.png\" alt=\"1713509734724\" loading=\"lazy\"></p>\n<h4 id=\"Monopole\"><a href=\"#Monopole\" class=\"headerlink\" title=\"Monopole\"></a>Monopole</h4><p><img src=\"/../images/Antenna/1713509771675.png\" alt=\"1713509771675\" loading=\"lazy\"></p>\n<h2 id=\"Loop-Antennas\"><a href=\"#Loop-Antennas\" class=\"headerlink\" title=\"Loop Antennas\"></a>Loop Antennas</h2><h3 id=\"Small-Loop\"><a href=\"#Small-Loop\" class=\"headerlink\" title=\"Small Loop\"></a>Small Loop</h3><p><img src=\"/../images/Antenna/1715324583382.png\" alt=\"1715324583382\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715324548326.png\" alt=\"1715324548326\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715324559069.png\" alt=\"1715324559069\" loading=\"lazy\"></p>\n<p>Infinite small loop radius;</p>\n<p>Infinite small wire radius;</p>\n<p>Uniform distribution.</p>\n<p>Resistance $R_r$ too small!</p>\n<h3 id=\"Finite-length-loop-antennas\"><a href=\"#Finite-length-loop-antennas\" class=\"headerlink\" title=\"Finite-length loop antennas\"></a>Finite-length loop antennas</h3><p><img src=\"/../images/Antenna/1715325834911.png\" alt=\"1715325834911\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715324769403.png\" alt=\"1715324769403\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715328812089.png\" alt=\"1715328812089\" loading=\"lazy\"></p>\n<h3 id=\"Modes-of-Loop-antennas\"><a href=\"#Modes-of-Loop-antennas\" class=\"headerlink\" title=\"Modes of Loop antennas\"></a>Modes of Loop antennas</h3><p><img src=\"/../images/Antenna/1715924283522.png\" alt=\"1715924283522\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715924294266.png\" alt=\"1715924294266\" loading=\"lazy\"></p>\n<h3 id=\"Helix-x2F-helical-antennas\"><a href=\"#Helix-x2F-helical-antennas\" class=\"headerlink\" title=\"Helix&#x2F;helical antennas\"></a>Helix&#x2F;helical antennas</h3><p><img src=\"/../images/Antenna/1715924314079.png\" alt=\"1715924314079\" loading=\"lazy\"></p>\n<p>Axial Mode</p>\n<p><img src=\"/../images/Antenna/1715924338243.png\" alt=\"1715924338243\" loading=\"lazy\"></p>\n<p>Normal Mode:</p>\n<p><img src=\"/../images/Antenna/1715924364965.png\" alt=\"1715924364965\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715924463502.png\" alt=\"1715924463502\" loading=\"lazy\"></p>\n<h2 id=\"Aperture-Antenna\"><a href=\"#Aperture-Antenna\" class=\"headerlink\" title=\"Aperture Antenna\"></a>Aperture Antenna</h2><h3 id=\"Huygens’-Principle\"><a href=\"#Huygens’-Principle\" class=\"headerlink\" title=\"Huygens’ Principle\"></a>Huygens’ Principle</h3><p><img src=\"/../images/Antenna/1715927654495.png\" alt=\"1715927654495\" loading=\"lazy\"></p>\n<h3 id=\"Rectangular-aperture-antennas\"><a href=\"#Rectangular-aperture-antennas\" class=\"headerlink\" title=\"Rectangular aperture antennas\"></a>Rectangular aperture antennas</h3><p><img src=\"/../images/Antenna/1715927982080.png\" alt=\"1715927982080\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715928380068.png\" alt=\"1715928380068\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715929046320.png\" alt=\"1715929046320\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715929138391.png\" alt=\"1715929138391\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715929169213.png\" alt=\"1715929169213\" loading=\"lazy\"></p>\n<h3 id=\"Horn-Antennas\"><a href=\"#Horn-Antennas\" class=\"headerlink\" title=\"Horn Antennas\"></a>Horn Antennas</h3><p><img src=\"/../images/Antenna/1715929396692.png\" alt=\"1715929396692\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715929501432.png\" alt=\"1715929501432\" loading=\"lazy\"></p>\n<p>The E-pattern is in shadow.</p>\n<p><img src=\"/../images/Antenna/1715929523072.png\" alt=\"1715929523072\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715929531751.png\" alt=\"1715929531751\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1715929546494.png\" alt=\"1715929546494\" loading=\"lazy\"></p>\n<h2 id=\"Antenna-Array\"><a href=\"#Antenna-Array\" class=\"headerlink\" title=\"Antenna Array\"></a>Antenna Array</h2><p>1-D Linear Array</p>\n<p>2-D Planar Array</p>\n<p>3-D Conformal Array</p>\n<p>Array Element</p>\n<ul>\n<li>Dipoles</li>\n<li>Loops</li>\n<li>Slots</li>\n<li>Microstrip antennas</li>\n</ul>\n<h3 id=\"Two-Element-array\"><a href=\"#Two-Element-array\" class=\"headerlink\" title=\"Two-Element array\"></a>Two-Element array</h3><p><img src=\"/../images/Antenna/1717133761533.png\" alt=\"1717133761533\" loading=\"lazy\"></p>\n<div>$$\n\\begin{gathered}\n\\vec{E}_1= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_1}}{r_1}\\cos\\theta_1 \\\\\n\\vec{E}_{2}= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_2}}{r_2}\\cos\\theta_2 \n\\end{gathered}\n$$</div>\n\n<p>Remarks:</p>\n<ul>\n<li>Two element;</li>\n<li>Towards Y axis;</li>\n<li>Along Z axis;</li>\n<li>Space: d;</li>\n<li>Uniform phase<br>and amplitude;</li>\n<li>Observe in 2D<br>(YZ-plane).</li>\n</ul>\n<p>Far field Approximation</p>\n<p><img src=\"/../images/Antenna/1717133876692.png\" alt=\"1717133876692\" loading=\"lazy\"></p>\n<div>$$\n\\begin{aligned}&\\vec{E}_{total}=\\vec{E}_1+\\vec{E}_2\\\\&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac1r\\Bigg(e^{-jk(r-\\frac d2\\cos\\theta)}+e^{-jk(r+\\frac d2\\cos\\theta)}\\Bigg)\\end{aligned}\n$$</div>\n\n<div>$$\n\\begin{aligned}\n\\vec{E}_{total}& =\\vec{E}_1+\\vec{E}_2=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{1}{r}\\Bigg(e^{-jk(r-\\frac{d}{2}\\cos\\theta)}+e^{-jk(r+\\frac{d}{2}\\cos\\theta)}\\Bigg)  \\\\\n&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}{r}\\Bigg(e^{jk\\frac{d}{2}\\cos\\theta}+e^{-jk\\frac{d}{2}\\cos\\theta}\\Bigg) \\\\\n&=\\hat{\\theta}\\underbrace{\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}r}_{\\text{Element pattern}}\\underbrace{2\\cos\\biggl[\\frac12kd\\cos\\theta\\biggr]}_{\\text{Array Factor (AF)}}\n\\end{aligned}\n$$</div>\n\n<p>Remarks:</p>\n<ul>\n<li>Uniform phase and amplitude;</li>\n<li>AF is related to space (d);</li>\n<li>AF is with no relation with antenna type.</li>\n</ul>\n<div>$$\nAF{=}2\\cos\\left[\\frac12kd\\cos\\theta\\right]\\quad kd{=}\\frac{2\\pi}\\lambda d{=}2\\pi\\frac d\\lambda \n$$</div>\n\n<p><img src=\"/../images/Antenna/1717134268805.png\" alt=\"1717134268805\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717134287481.png\" alt=\"1717134287481\" loading=\"lazy\"></p>\n<h3 id=\"N-Element-array\"><a href=\"#N-Element-array\" class=\"headerlink\" title=\"N-Element array\"></a>N-Element array</h3><p><img src=\"/../images/Antenna/1717134353772.png\" alt=\"1717134353772\" loading=\"lazy\"></p>\n<div>$$\n\\begin{aligned}&AF=1+e^{jkd\\cos\\theta}+e^{j2kd\\cos\\theta}+\\cdots+e^{j(N-1)kd\\cos\\theta}\\\\&=\\sum_{n=1}^Ne^{j(n-1)kd\\cos\\theta}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}\\end{aligned}\n$$</div>\n\n<div>$$\nAF=1+e^{j\\Psi}+e^{j2\\Psi}+\\cdots+e^{j(N-1)\\Psi}=\\frac{e^{jN\\Psi}-1}{e^{j\\Psi}-1}\\\\=\\frac{e^{j\\frac N2\\Psi}\\left(e^{j\\frac N2\\Psi}-e^{-j\\frac N2\\Psi}\\right)}{e^{j\\frac12\\Psi}\\left(e^{j\\frac12\\Psi}-e^{-j\\frac12\\Psi}\\right)}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$</div>\n\n<p>Refenece Point at the end:</p>\n<div>$$\nAF=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$</div>\n\n<p>Refenece Point at the center:</p>\n<div>$$\nAF=\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$</div>\n\n<p>In Progreessive Phase Shift:</p>\n<div>$$\n\\Psi=kd\\cos\\theta+\\alpha \n$$</div>\n\n<div>$$\nAF=1+e^{j(kd\\cos\\theta+\\alpha)}+e^{j2(kd\\cos\\theta+\\alpha)}+\\cdots+e^{j(N-1)(kd\\cos\\theta+\\alpha)}\\\\=\\sum_{n=1}^Ne^{j(n-1)(kd\\cos\\theta+\\alpha)}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$</div>\n\n<p>Normalized Array Factor:</p>\n<div>$$\n\\left|f(\\Psi)\\right|=\\left|\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{N\\sin\\left(\\frac12\\Psi\\right)}\\right|\n$$</div>\n\n<p>Grating Lobe:</p>\n<div>$$\n\\begin{aligned}\n\\theta\\in\\begin{bmatrix}0,\\pi\\end{bmatrix}\\text{ or }\\theta\\in\\begin{bmatrix}\\theta_1,\\theta_2\\end{bmatrix}\\text{, visible region} \\\\\n\\text{In the visible region,} \\\\\nifwehaveY= 0\\mathrm{~and~}\\Psi=2\\pi. \n\\end{aligned}\n$$</div>\n\n<p>Avoid grating lobe:</p>\n<ol>\n<li>Smaller d;</li>\n<li>Smaller phase shift.</li>\n</ol>\n<div>$$\n1.\\mathrm{~For~}\\alpha=\\pi\\Rightarrow2kd<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<\\frac12\\\\2.\\mathrm{~For~}\\alpha=0\\mathrm{~}\\Rightarrow\\mathrm{~k}d<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<1\n$$</div>\n\n<h4 id=\"Broadside-Array\"><a href=\"#Broadside-Array\" class=\"headerlink\" title=\"Broadside Array\"></a>Broadside Array</h4><p>Maximum @ $\\theta &#x3D; 90\\degree$</p>\n<div>$$\nAF\\boldsymbol{=}N@\\boldsymbol{\\theta}\\boldsymbol{=}\\boldsymbol{\\pi}/2\\quad\\boldsymbol{\\Psi}\\boldsymbol{=}kd\\cos\\boldsymbol{\\theta}\\boldsymbol{+}\\boldsymbol{\\alpha}|_{\\theta=\\pi/2}\\boldsymbol{=}0\n$$</div>\n\n<p><img src=\"/../images/Antenna/1717134725130.png\" alt=\"1717134725130\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717134745100.png\" alt=\"1717134745100\" loading=\"lazy\"></p>\n<h4 id=\"End-fire-Array\"><a href=\"#End-fire-Array\" class=\"headerlink\" title=\"End-fire Array\"></a>End-fire Array</h4><p><img src=\"/../images/Antenna/1717134897852.png\" alt=\"1717134897852\" loading=\"lazy\"></p>\n<div>$$\n\\begin{aligned}\n&AF= N@\\theta{=}0  &\\Psi=kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2\\ldots)  \\\\\n&\\text{or} \\\\\n&AF= N@\\theta{=}\\pi   &\\Psi=-kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2...)  \\\\\n&\\Psi=kd\\cos\\theta+\\alpha=2\\pi\\cos\\theta \n\\end{aligned}\n$$</div>\n\n<p>Bidirectional:</p>\n<p><img src=\"/../images/Antenna/1717134942873.png\" alt=\"1717134942873\" loading=\"lazy\"></p>\n<p>Unidirectional:</p>\n<p><img src=\"/../images/Antenna/1717134955235.png\" alt=\"1717134955235\" loading=\"lazy\"></p>\n<h4 id=\"Phased-Array\"><a href=\"#Phased-Array\" class=\"headerlink\" title=\"Phased Array\"></a>Phased Array</h4><p><img src=\"/../images/Antenna/1717135044895.png\" alt=\"1717135044895\" loading=\"lazy\"></p>\n<h4 id=\"Non-uniform-Array\"><a href=\"#Non-uniform-Array\" class=\"headerlink\" title=\"Non-uniform Array\"></a>Non-uniform Array</h4><p>Side Lobe</p>\n<p>Uniform array:</p>\n<ul>\n<li>Universal pattern: N↑, SLL↓ </li>\n<li>With a limit of -13.3 dB</li>\n<li>No control of SL</li>\n</ul>\n<p>How to reduce SLL?</p>\n<p>Non-uniform excitation</p>\n<p><img src=\"/../images/Antenna/1717135171215.png\" alt=\"1717135171215\" loading=\"lazy\"></p>\n<h4 id=\"Planar-Array\"><a href=\"#Planar-Array\" class=\"headerlink\" title=\"Planar Array\"></a>Planar Array</h4><p><img src=\"/../images/Antenna/1717135198414.png\" alt=\"1717135198414\" loading=\"lazy\"></p>\n<p>Can be viewed as product of two linear array factors:</p>\n<div>$$\nAF=\\sum_{i=1}^{M\\times N}I_ie^{jk\\hat{r}\\cdot\\vec{r}_i}\\\\\nAF_n(\\theta,\\phi)=\\left\\lbrace\\frac{\\sin(\\frac M2\\psi_x)}{M\\sin\\frac{\\psi_x}2}\\right\\rbrace\\left\\{\\frac{\\sin(\\frac N2\\psi_y)}{N\\sin\\frac{\\psi_y}2}\\right\\};\\\\\\psi_x=kd_x\\sin\\theta\\cos\\varphi+\\alpha_x\\\\\\psi_y=kd_y\\sin\\theta\\sin\\varphi+\\alpha_y\n$$</div>\n\n<h3 id=\"Applications-1\"><a href=\"#Applications-1\" class=\"headerlink\" title=\"Applications\"></a>Applications</h3><h4 id=\"Yagi-Uda-Antenna\"><a href=\"#Yagi-Uda-Antenna\" class=\"headerlink\" title=\"Yagi-Uda Antenna\"></a>Yagi-Uda Antenna</h4><p>Basic configuration:</p>\n<ul>\n<li>One driven element;</li>\n<li>Two parasitic elements or more</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717135386351.png\" alt=\"1717135386351\" loading=\"lazy\"></p>\n<p>Remarks:</p>\n<ul>\n<li>Parasitic elements are excited by near-field coupling from the driven element;</li>\n<li>Proper design of parasitic elements for end fire radiation;</li>\n<li>In far field, the radiated waves from all the elements are in-phase.</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717135675789.png\" alt=\"1717135675789\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717135951201.png\" alt=\"1717135951201\" loading=\"lazy\"></p>\n<h4 id=\"Helix-Antenna\"><a href=\"#Helix-Antenna\" class=\"headerlink\" title=\"Helix Antenna\"></a>Helix Antenna</h4><p><img src=\"/../images/Antenna/1717136046473.png\" alt=\"1717136046473\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717136115015.png\" alt=\"1717136115015\" loading=\"lazy\"></p>\n<h2 id=\"Travelling-Wave-Antennas\"><a href=\"#Travelling-Wave-Antennas\" class=\"headerlink\" title=\"Travelling-Wave Antennas\"></a>Travelling-Wave Antennas</h2><h3 id=\"Travelling-wave-amp-standing-wave\"><a href=\"#Travelling-wave-amp-standing-wave\" class=\"headerlink\" title=\"Travelling wave &amp; standing wave\"></a>Travelling wave &amp; standing wave</h3><h4 id=\"Long-wire-antennas\"><a href=\"#Long-wire-antennas\" class=\"headerlink\" title=\"Long wire antennas\"></a>Long wire antennas</h4><p><img src=\"/../images/Antenna/1717137633424.png\" alt=\"1717137633424\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717137646795.png\" alt=\"1717137646795\" loading=\"lazy\"></p>\n<p>Note:<br>Long wire antennas: “l” &#x3D; Several wavelength</p>\n<ul>\n<li>One end for excitation;</li>\n<li>The other end for load (open, short, or matching);</li>\n<li>Transmission line with radiation.</li>\n</ul>\n<h3 id=\"Log-periodic-Antennas\"><a href=\"#Log-periodic-Antennas\" class=\"headerlink\" title=\"Log-periodic Antennas\"></a>Log-periodic Antennas</h3><p>Yagi-Uda: High Gain</p>\n<p>Log-periodic: Wide Bandwidth</p>\n<p><img src=\"/../images/Antenna/1717138714524.png\" alt=\"1717138714524\" loading=\"lazy\"></p>\n<p>Why:</p>\n<ol>\n<li>Feed from smaller dipole element;</li>\n<li>Feed out-of-phase with adjacent elements;</li>\n<li>Add a resistor at the end.</li>\n</ol>\n<div>$$\n\\tau=\\frac{R_{n+1}}{R_{n}}=\\frac{L_{n+1}}{L_{n}}=\\frac{d_{n+1}}{d_{n}}\\\\\\alpha=2\\tan^{-1}\\left(\\frac{1-\\tau}{4\\sigma}\\right)\\\\\\sigma=\\frac{d_{n}}{2L_{n}}\\\\L_{1}\\approx\\frac{\\lambda_{L}}{2}\\quad\\mathrm{and}\\quad L_{N}\\approx\\frac{\\lambda_{U}}{2}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1717138873279.png\" alt=\"1717138873279\" loading=\"lazy\"></p>\n<h2 id=\"Microstrip-Antennas\"><a href=\"#Microstrip-Antennas\" class=\"headerlink\" title=\"Microstrip Antennas\"></a>Microstrip Antennas</h2><p><img src=\"/../images/Antenna/1717740667735.png\" alt=\"1717740667735\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717740670364.png\" alt=\"1717740670364\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717740680573.png\" alt=\"1717740680573\" loading=\"lazy\"></p>\n<h3 id=\"Basic-Mode\"><a href=\"#Basic-Mode\" class=\"headerlink\" title=\"Basic Mode\"></a>Basic Mode</h3><ul>\n<li>Equivalent magnetic current;</li>\n<li>Radiating and non-radiating apertures;</li>\n<li>Operating frequency with different L.</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717740726098.png\" alt=\"1717740726098\" loading=\"lazy\"></p>\n<ul>\n<li>Magnetic current array;</li>\n<li>Image theorem from infinite ground;</li>\n<li>Cavity model with magnetic walls;</li>\n<li>Different from</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717740758890.png\" alt=\"1717740758890\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717740768183.png\" alt=\"1717740768183\" loading=\"lazy\"></p>\n<h3 id=\"Antenna-feeding-methods\"><a href=\"#Antenna-feeding-methods\" class=\"headerlink\" title=\"Antenna feeding methods\"></a>Antenna feeding methods</h3><p><img src=\"/../images/Antenna/1717740786849.png\" alt=\"1717740786849\" loading=\"lazy\"></p>\n<p>Impedance Matching:</p>\n<p><img src=\"/../images/Antenna/1717740801741.png\" alt=\"1717740801741\" loading=\"lazy\"></p>\n<p>Using 50-Ohm port: finding the position with Z_in&#x3D;50 Ohm</p>\n<h3 id=\"Analysis-Model\"><a href=\"#Analysis-Model\" class=\"headerlink\" title=\"Analysis Model\"></a>Analysis Model</h3><p><img src=\"/../images/Antenna/1717742374397.png\" alt=\"1717742374397\" loading=\"lazy\"></p>\n<p>Known:</p>\n<ul>\n<li>Operating Frequency</li>\n<li>Dielectric: $\\varepsilon_r$ and $h$</li>\n<li>Metal: $t$</li>\n</ul>\n<p>Design: </p>\n<ul>\n<li>Patch: $L$ and $W$</li>\n<li>Evaluate gain</li>\n</ul>\n<p>2 Models:</p>\n<p><img src=\"/../images/Antenna/1717742413544.png\" alt=\"1717742413544\" loading=\"lazy\"></p>\n<h4 id=\"Transmission-line-model\"><a href=\"#Transmission-line-model\" class=\"headerlink\" title=\"Transmission line model\"></a>Transmission line model</h4><p>determine W</p>\n<p>Uniform distribution and  field intensity in dielectric</p>\n<div>$$\nW=\\frac{1}{2f_r\\sqrt{\\mu_0\\epsilon_0}}\\sqrt{\\frac{2}{\\epsilon_r+1}}\n$$</div>\n\n<p>Effective permittivity</p>\n<div>$$\n\\varepsilon_{eff}=\\frac{\\varepsilon_r+1}2+\\frac{\\varepsilon_r-1}2{\\left[1+12\\frac hW\\right]}^{-1/2}\n$$</div>\n\n<p>Fring effect and determine L</p>\n<div>$$\n\\frac{\\Delta L}{h}=0.412\\frac{(\\varepsilon_{eff}+0.3)(\\frac Wh+0.264)}{(\\varepsilon_{eff}-0.258)(\\frac Wh+0.8)}\\\\L=\\frac{\\lambda_d}2-2\\Delta L=\\frac{\\lambda_0}{2\\sqrt{\\varepsilon_{eff}}}-2\\Delta L\n$$</div>\n\n<p>impedance matching</p>\n<h4 id=\"Cavity-Model\"><a href=\"#Cavity-Model\" class=\"headerlink\" title=\"Cavity Model\"></a>Cavity Model</h4><p><img src=\"/../images/Antenna/1717742626807.png\" alt=\"1717742626807\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717743460723.png\" alt=\"1717743460723\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717743468657.png\" alt=\"1717743468657\" loading=\"lazy\"></p>\n<h3 id=\"Circular-polarization\"><a href=\"#Circular-polarization\" class=\"headerlink\" title=\"Circular polarization\"></a>Circular polarization</h3><p>Dual feed patch</p>\n<p><img src=\"/../images/Antenna/1717743681072.png\" alt=\"1717743681072\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717743691321.png\" alt=\"1717743691321\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1717743927411.png\" alt=\"1717743927411\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1718344358151.png\" alt=\"1718344358151\" loading=\"lazy\"></p>\n<p>SP-feed 旋转馈电</p>\n<h2 id=\"Reflector-and-lens-antennas\"><a href=\"#Reflector-and-lens-antennas\" class=\"headerlink\" title=\"Reflector and lens antennas\"></a>Reflector and lens antennas</h2><p><img src=\"/../images/Antenna/1718345601277.png\" alt=\"1718345601277\" loading=\"lazy\"></p>\n<h3 id=\"Corner-Reflectors\"><a href=\"#Corner-Reflectors\" class=\"headerlink\" title=\"Corner Reflectors\"></a>Corner Reflectors</h3><p><img src=\"/../images/Antenna/1718345727630.png\" alt=\"1718345727630\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1718345718761.png\" alt=\"1718345718761\" loading=\"lazy\"></p>\n<h3 id=\"Parabolic-Reflectors\"><a href=\"#Parabolic-Reflectors\" class=\"headerlink\" title=\"Parabolic Reflectors\"></a>Parabolic Reflectors</h3><p><img src=\"/../images/Antenna/1718346212882.png\" alt=\"1718346212882\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1718346379534.png\" alt=\"1718346379534\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1718346371235.png\" alt=\"1718346371235\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1718346571584.png\" alt=\"1718346571584\" loading=\"lazy\"></p>\n<h3 id=\"Lens-Antennas\"><a href=\"#Lens-Antennas\" class=\"headerlink\" title=\"Lens Antennas\"></a>Lens Antennas</h3><p><img src=\"/../images/Antenna/1718346830900.png\" alt=\"1718346830900\" loading=\"lazy\"></p>\n<p>Lens antennas:</p>\n<ul>\n<li>High gain: plane wave;</li>\n<li>Geometrical optics: equal optical distance;</li>\n<li>Source: spherical wave, illuminate the whole lens;</li>\n<li>Source is positioned on the focal point for normal<br>radiated plane wave;</li>\n<li>Other incident&#x2F;radiated angle of plane wave: focus on<br>the focal plane with gain decrease;</li>\n<li>Spatial Fournier Transformation: (x, y)&amp;k</li>\n</ul>\n<h3 id=\"Reflected-and-transmitted-array\"><a href=\"#Reflected-and-transmitted-array\" class=\"headerlink\" title=\"Reflected and transmitted array\"></a>Reflected and transmitted array</h3><p><img src=\"/../images/Antenna/1718347859765.png\" alt=\"1718347859765\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Antenna/1718347869028.png\" alt=\"1718347869028\" loading=\"lazy\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Introduction-of-Antenna\"><a href=\"#Introduction-of-Antenna\" class=\"headerlink\" title=\"Introduction of Antenna\"></a>Introduction of Antenna</h2><p>Definition of Antenna</p>\n<ul>\n<li>Transmitter and receiver of EM wave</li>\n<li>Signal from current to wave</li>\n<li>from lumped to distributed</li>\n</ul>\n<p>Antenna classifications</p>\n<ul>\n<li>Resonant and non-resonant&#x2F;leaky&#x2F;travelling wave</li>\n<li>Antenna number: element, multiple antennas, array</li>\n<li>Shape: wire, loop, slot, patch&#x2F;microstrip, cavity</li>\n<li>Materials: metallic, dielectric</li>\n<li>Property: wideband, narrow band</li>\n<li>Yagi-Uda, Vivaldi, Cassegrain</li>\n<li>Function: moblie&#x2F;handset, base station, AiP</li>\n</ul>\n<h2 id=\"Maxwell-equations\"><a href=\"#Maxwell-equations\" class=\"headerlink\" title=\"Maxwell equations\"></a>Maxwell equations</h2><div>$$\n\\nabla \\cdot \\vec D = \\rho \\rightarrow \\nabla \\cdot \\tilde{\\vec D} = \\rho \\\\\n\\nabla \\cdot {\\vec B} = 0 \\rarr \\nabla \\cdot \\tilde{\\vec B} = 0\\\\\n\\nabla \\times {\\vec E} = -\\frac{\\partial \\vec B}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec E} = -j\\omega \\tilde{\\vec B}\\\\\n\\nabla \\times {\\vec H} = \\vec J + \\frac{\\partial \\vec D}{\\partial t} \\rarr \\nabla \\times \\tilde{\\vec H} = \\vec J + j\\omega \\tilde{\\vec D}\\\\\n\\vec D = \\varepsilon \\vec E\\\\\n\\vec B = \\mu \\vec H\n$$</div>\n\n<div>$$\n\\nabla^2 \\vec F = \\nabla(\\nabla \\cdot \\vec F) - \\nabla \\times (\\nabla \\times \\vec F)\\\\\n\\nabla \\times (\\nabla f) = 0\\\\\n\\nabla \\cdot (\\nabla \\times \\vec F) = 0\n$$</div>\n\n<h2 id=\"Auxiliary-Potential-Functions\"><a href=\"#Auxiliary-Potential-Functions\" class=\"headerlink\" title=\"Auxiliary Potential Functions\"></a>Auxiliary Potential Functions</h2><p>Let</p>\n<div>$$\n\\vec B = \\nabla \\times \\vec A\\\\\n\\vec E + j\\omega \\vec A = -\\nabla \\phi\n$$</div>\n\n<div>$$\n\\nabla \\cdot \\vec D = \\varepsilon \\nabla \\cdot(-\\nabla \\phi  - j\\omega \\vec A) = \\rho\\\\\n\\Rightarrow \\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon} - j\\omega(\\nabla \\cdot \\vec A + j\\omega \\mu \\varepsilon \\phi)\n$$</div>\n\n<div>$$\n\\nabla \\times \\vec H = \\frac{1}{\\mu}(\\nabla(\\nabla \\cdot \\vec A) - \\nabla^2\\vec A) = \\vec J + j\\omega \\vec D = \\vec J + j\\omega\\varepsilon(-\\nabla\\phi - j\\omega \\vec A)\\\\\n\\Rightarrow \\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J - \\nabla(\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi)\n$$</div>\n\n<p>Use Lorentz Gauge</p>\n<div>$$\n\\nabla \\cdot \\vec A + j\\omega\\mu\\varepsilon\\phi = 0\n$$</div>\n\n<p>Then</p>\n<div>$$\n\\nabla^2\\vec A + \\omega^2\\mu\\varepsilon\\vec A = -\\mu \\vec J\\\\\n\\nabla^2\\phi + \\omega^2\\mu\\varepsilon\\phi = - \\frac{\\rho}{\\varepsilon}\n$$</div>\n\n<p>Solve ODE:</p>\n<div>$$\n\\begin{equation}  \n\\nabla^2\\phi + k^2\\phi = 0(r\\ne 0)\n\\end{equation}\\\\\n\\begin{equation}\n\\nabla^2\\phi + k^2\\phi = -\\frac{\\rho}{\\varepsilon}(r=0)\n\\end{equation}\n$$</div>\n\n<p>For (1)</p>\n<div>$$\nu(r) = \\frac{\\phi(r)}{r}\\\\\n\\frac{\\rm{d}^2}{\\rm{d}r^2}u + k^2u = 0\\\\\nu = C_1e^{-jkr} + C_2e^{jkr}\\\\\n\\phi = C_1\\frac{e^{-jkr}}{r}\n$$</div>\n\n<p>For (2), in arbitrary volume</p>\n<div>$$\n\\iiint_V(\\nabla^2\\phi + k^2\\phi)\\mathrm dv = \\iiint_V(-\\frac{\\rho}{\\varepsilon}\\mathrm dv) = -\\frac{q}{\\varepsilon}\\\\\nr \\rightarrow 0\\\\\n\\iiint_V(k^2\\phi)\\mathrm dv = 0\\\\\n\\iiint_V\\nabla^2\\phi \\mathrm dv = \\oiint_S \\nabla\\phi \\cdot \\mathrm d\\vec s = C_1 \\oiint_S (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})\\mathrm d\\vec s = C_1 (\\frac{-jkre^{-jkr} - e^{-jkr}}{r^2})4\\pi r^2 = -C_1 4\\pi\n$$</div>\n\n<p>Finally,</p>\n<div>$$\n\\phi(r) = \\frac{q}{4\\pi\\varepsilon}\\frac{e^{-jkr}}{r}\n$$</div>\n\n<h2 id=\"Radiation-Parameters\"><a href=\"#Radiation-Parameters\" class=\"headerlink\" title=\"Radiation Parameters\"></a>Radiation Parameters</h2><h3 id=\"Field-Zone\"><a href=\"#Field-Zone\" class=\"headerlink\" title=\"Field Zone\"></a>Field Zone</h3><p>Near field: resonant, field;</p>\n<p>Far field: propagation, wave;</p>\n<p>Fresnel region: transition;</p>\n<p><img src=\"/../images/Antenna/1711090268476.png\" alt=\"1711090268476\"></p>\n<h3 id=\"Antenna-Parameters\"><a href=\"#Antenna-Parameters\" class=\"headerlink\" title=\"Antenna Parameters\"></a>Antenna Parameters</h3><ul>\n<li>Radiation patterns</li>\n<li>Radiation Intensity</li>\n<li>Power Density</li>\n<li>Directivity (方向性) and Gain (重要！)</li>\n<li>Polarization</li>\n<li>Effective Aperture(等效口面) and Aperture efficienty(口面效率)</li>\n</ul>\n<p>E 面：与电场方向平行的面</p>\n<p>H 面：与磁场方向平行的面</p>\n<h4 id=\"Pattern-Parameters\"><a href=\"#Pattern-Parameters\" class=\"headerlink\" title=\"Pattern Parameters\"></a>Pattern Parameters</h4><p><img src=\"/../images/Antenna/1711090565574.png\" alt=\"1711090565574\"></p>\n<p>Often use log scale.</p>\n<h4 id=\"Power-Density\"><a href=\"#Power-Density\" class=\"headerlink\" title=\"Power Density\"></a>Power Density</h4><p>Instantaneous Poynting vector $\\vec S(x, y, z, t)$</p>\n<p>Radiation Power Density &#x3D; Time average Poynting vector $\\vec S_{av}(x, y, z)&#x3D;\\frac1T\\int_0^T\\vec S(x, y, z, t)\\mathrm dt &#x3D; \\frac12\\text{Re}[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}]$</p>\n<p>Total Radiation Power $P_{rad} &#x3D; \\oiint_S[\\tilde{\\vec E} \\times \\tilde{\\vec H^*}] \\cdot \\mathrm d\\vec s$</p>\n<h4 id=\"Radiation-Intensity\"><a href=\"#Radiation-Intensity\" class=\"headerlink\" title=\"Radiation Intensity\"></a>Radiation Intensity</h4><div>$$\nU(\\theta, \\varphi) = r^2 S(r, \\theta, \\varphi)\n$$</div>\n\n<p>Isotropic 各向同性</p>\n<div>$$\nP_{rad} = \\int_{0}^{2\\pi}\\int_{0}^{\\pi}U\\sin\\theta\\mathrm d\\theta\\mathrm d\\varphi\n$$</div>\n\n<h4 id=\"Directivity\"><a href=\"#Directivity\" class=\"headerlink\" title=\"Directivity\"></a>Directivity</h4><div>$$\nD = \\frac{U_{\\max}}{U_{av}} = \\frac{P_{\\max}}{P_{rad}/4\\pi}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1711091202619.png\" alt=\"1711091202619\"></p>\n<p><img src=\"/../images/Antenna/1711091212947.png\" alt=\"1711091212947\"></p>\n<p><img src=\"/../images/Antenna/1711693683771.png\" alt=\"1711693683771\"></p>\n<p><img src=\"/../images/Antenna/1711693701192.png\" alt=\"1711693701192\"></p>\n<h4 id=\"Gain\"><a href=\"#Gain\" class=\"headerlink\" title=\"Gain\"></a>Gain</h4><p><img src=\"/../images/Antenna/1711693749686.png\" alt=\"1711693749686\"></p>\n<div>$$\nG = \\frac{U_{\\max}}{P_{in}/4\\pi}\n$$</div>\n\n<h4 id=\"Polarization\"><a href=\"#Polarization\" class=\"headerlink\" title=\"Polarization\"></a>Polarization</h4><p><img src=\"/../images/Antenna/1711693845822.png\" alt=\"1711693845822\"></p>\n<p>Polarization Mismatch:</p>\n<p><img src=\"/../images/Antenna/1711693861642.png\" alt=\"1711693861642\"></p>\n<p>CP</p>\n<p><img src=\"/../images/Antenna/1711693936592.png\" alt=\"1711693936592\"></p>\n<h4 id=\"Effective-Aperture-and-Aperture-efficiency\"><a href=\"#Effective-Aperture-and-Aperture-efficiency\" class=\"headerlink\" title=\"Effective Aperture and Aperture efficiency\"></a>Effective Aperture and Aperture efficiency</h4><p><img src=\"/../images/Antenna/1711694027177.png\" alt=\"1711694027177\"></p>\n<p><img src=\"/../images/Antenna/1711694083583.png\" alt=\"1711694083583\"></p>\n<h3 id=\"Circuit-Parameters\"><a href=\"#Circuit-Parameters\" class=\"headerlink\" title=\"Circuit Parameters\"></a>Circuit Parameters</h3><h4 id=\"Input-impedance\"><a href=\"#Input-impedance\" class=\"headerlink\" title=\"Input impedance\"></a>Input impedance</h4><p>Input impedance definition:</p>\n<ul>\n<li>the impedance presented by an antenna at its terminals</li>\n<li>the ratio of the voltage to current at its terminals</li>\n<li>the ratio of the electric to magnetic fields at its terminals</li>\n</ul>\n<p><img src=\"/../images/Antenna/1711694243897.png\" alt=\"1711694243897\"></p>\n<h5 id=\"Conjugate-Matching\"><a href=\"#Conjugate-Matching\" class=\"headerlink\" title=\"Conjugate Matching\"></a>Conjugate Matching</h5><div>$$\nZ_A = Z_g^*\n$$</div>\n\n<h5 id=\"Mismatching\"><a href=\"#Mismatching\" class=\"headerlink\" title=\"Mismatching\"></a>Mismatching</h5><p><img src=\"/../images/Antenna/1711694350257.png\" alt=\"1711694350257\"></p>\n<h5 id=\"Radiation-Resistance\"><a href=\"#Radiation-Resistance\" class=\"headerlink\" title=\"Radiation Resistance\"></a>Radiation Resistance</h5><div>$$\nP_{rad} = \\frac12|I_g|^2R_r = \\oiint_S\\vec S_{av} \\cdot \\rm d\\vec s\n$$</div>\n\n<p><img src=\"/../images/Antenna/1711694462059.png\" alt=\"1711694462059\"></p>\n<h4 id=\"Scattering-Parameters\"><a href=\"#Scattering-Parameters\" class=\"headerlink\" title=\"Scattering Parameters\"></a>Scattering Parameters</h4><p><img src=\"/../images/Antenna/1711694619870.png\" alt=\"1711694619870\"></p>\n<div>$$\n\\frac{\\Gamma^2}{Z_1} + \\frac{T^2}{Z_2} = 1\n$$</div>\n\n<p><img src=\"/../images/Antenna/1711694639638.png\" alt=\"1711694639638\"></p>\n<p><img src=\"/../images/Antenna/1711695738159.png\" alt=\"1711695738159\"></p>\n<p>二端口网络通常用于描述二天线问题。$S_{11}$表示天线1的反射，$S_{21}$表示天线1到天线2的耦合，均不利于信号的传播。我们希望让$1 - S_{11}^2 - S_{21}^2$尽可能大。</p>\n<h2 id=\"Link-Calculation\"><a href=\"#Link-Calculation\" class=\"headerlink\" title=\"Link Calculation\"></a>Link Calculation</h2><h3 id=\"Friis’s-Equation\"><a href=\"#Friis’s-Equation\" class=\"headerlink\" title=\"Friis’s Equation\"></a>Friis’s Equation</h3><p><img src=\"/../images/Antenna/1712471419276.png\" alt=\"1712471419276\"></p>\n<p><img src=\"/../images/Antenna/1712471436962.png\" alt=\"1712471436962\"></p>\n<h3 id=\"EIRP\"><a href=\"#EIRP\" class=\"headerlink\" title=\"EIRP\"></a>EIRP</h3><p><img src=\"/../images/Antenna/1712471499226.png\" alt=\"1712471499226\"></p>\n<p>赫兹偶极子的辐射电阻： $80\\pi^2(\\frac{\\Delta z}{\\lambda})^2$，方向性 $\\frac{2}{3}$。</p>\n<h3 id=\"Radar-Equation\"><a href=\"#Radar-Equation\" class=\"headerlink\" title=\"Radar Equation\"></a>Radar Equation</h3><p><img src=\"/../images/Antenna/1712473473687.png\" alt=\"1712473473687\"></p>\n<p>RCS(Radar cross section)</p>\n<p>RCS (σ) of a radar target is an effective area that intercepts the transmitted radar power and then<br>scatters that power isotropically back to the radar receiver.</p>\n<div>$$\n\\sigma=\\lim_{R\\to\\infty}\\frac{W_{o}4\\pi R^2}{W_i}\n$$</div>\n\n<ul>\n<li>$W_i$, $W_o$ and $R$ are known;</li>\n<li>$\\sigma$ converges.</li>\n</ul>\n<h2 id=\"Antenna-Theorems\"><a href=\"#Antenna-Theorems\" class=\"headerlink\" title=\"Antenna Theorems\"></a>Antenna Theorems</h2><div>$$\n\\boxed{P_r=\\mathrm{P}_t\\mathrm{G}_t\\mathrm{G}_r(\\frac{\\lambda}{4\\pi R})^2}\n$$</div>\n\n<div>$$\nP_{r}=P_{t}\\mathrm{e}_{r}\\mathrm{e}_{t}D_{r}\\mathrm{D}_{t}(1-\\left|\\Gamma_{r}\\right|^{2})(1-\\left|\\Gamma_{t}\\right|^{2})(\\frac{\\lambda}{4\\pi R})^{2}\n$$</div>\n\n<p>In radar:</p>\n<div>$$\nP_{r}=P_{t}\\mathrm{G}_{t}\\mathrm{G}_{r}\\sigma\\frac{1}{4\\pi}(\\frac{\\lambda}{4\\pi R_{1}R_{2}})^{2}\n$$</div>\n\n<p>Equivalent circuit model</p>\n<p><img src=\"/../images/Antenna/1712900712333.png\" alt=\"1712900712333\"></p>\n<p>$R_r$ ：接收天线反射会释放能量。</p>\n<h3 id=\"Duality-Theorem\"><a href=\"#Duality-Theorem\" class=\"headerlink\" title=\"Duality Theorem\"></a>Duality Theorem</h3><p><img src=\"/../images/Antenna/1712901375924.png\" alt=\"1712901375924\"></p>\n<p>电 -&gt; 磁，不变号；<br>磁 -&gt; 电，变号。</p>\n<h3 id=\"Image-Theorem\"><a href=\"#Image-Theorem\" class=\"headerlink\" title=\"Image Theorem\"></a>Image Theorem</h3><p>PEC：完美电导体</p>\n<p>PMC：完美磁导体</p>\n<p>定理条件：</p>\n<ul>\n<li>PEC or PMC</li>\n<li>Infinite boundary</li>\n</ul>\n<p>PEC</p>\n<div>$$\n\\begin{aligned}&\\hat{n}\\times\\vec{E}=0\\\\&\\hat{n}\\cdot\\vec{B}=0\\end{aligned}\n$$</div>\n\n<p>PMC</p>\n<div>$$\n\\begin{aligned}&\\hat{n}\\times\\vec{H}=0\\\\&\\hat{n}\\cdot\\vec{D}=0\\end{aligned}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1712902160882.png\" alt=\"1712902160882\"></p>\n<p>Note:</p>\n<ul>\n<li>Satisfied with boundary condition;</li>\n<li>Mirror source instead of PEC or PMC infinite boundary;</li>\n<li>Array: source and mirror source;</li>\n<li>Current loop: upper inside, lower outside.</li>\n</ul>\n<h3 id=\"Reciprocity-Theorem\"><a href=\"#Reciprocity-Theorem\" class=\"headerlink\" title=\"Reciprocity Theorem\"></a>Reciprocity Theorem</h3><p>In radiation pattern,</p>\n<p><img src=\"/../images/Antenna/1712903308547.png\" alt=\"1712903308547\"></p>\n<p>Transmitting pattern of antenna “a”</p>\n<div>$$\nZ_{_{ba}}(\\theta,\\varphi)=\\frac{V_{_b}(\\theta,\\varphi)}{I_{_a}}\n$$</div>\n\n<p>Receiving pattern of ante</p>\n<div>$$\nZ_{ab}(\\theta,\\varphi)=\\frac{V_{a}(\\theta,\\varphi)}{I_{b}}\n$$</div>\n\n<p>Then,</p>\n<div>$$\nZ_{ab}(\\theta,\\phi)=Z_{ba}(\\theta,\\phi)\n$$</div>\n\n<p>Lorentz Reciprocity Theorem</p>\n<div>$$\n-\\nabla\\cdot(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})=\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\\\\n-\\oiint_{S}(\\vec{E}_{1}\\times\\vec{H}_{2}-\\vec{E}_{2}\\times\\vec{H}_{1})\\cdot ds^{'}=\\iiint_{V}\\left(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec H_1 \\cdot \\vec M_2\\right)dv^{'}\n$$</div>\n\n<p>Far field:</p>\n<div>$$\n\\vec{H}_i=\\hat{r}\\times\\vec{E}_i/\\eta;\\quad d\\vec{s}=\\hat{n}ds=\\hat{r}ds\n$$</div>\n\n<div>$$\n(\\vec{E}_1\\times\\vec{H}_2-\\vec{E}_2\\times\\vec{H}_1)\\cdot\\hat{r}=(\\hat{r}\\times\\vec{E}_1)\\cdot\\vec{H}_2-(\\hat{r}\\times\\vec{E}_2)\\cdot\\vec{H}_1=0\n$$</div>\n\n<div>$$\n\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}+\\vec{H}_{2}\\cdot\\vec{M}_{1}-\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=0\\\\\\iiint_{V}\\Big(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2}\\Big)d\\nu^{'}=\\iiint_{V}\\Big(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1}\\Big)d\\nu^{'}\n$$</div>\n\n<p>Reaction: Reciprocity theorem: $\\langle 1 2\\rangle&#x3D;\\langle 2,1\\rangle$</p>\n<div>$$\n\\left\\langle1,2\\right\\rangle=\\int_{V}(\\vec{E}_{1}\\cdot\\vec{J}_{2}-\\vec{H}_{1}\\cdot\\vec{M}_{2})d\\nu\\quad\\left\\langle2,1\\right\\rangle=\\int_{V}(\\vec{E}_{2}\\cdot\\vec{J}_{1}-\\vec{H}_{2}\\cdot\\vec{M}_{1})d\\nu \n$$</div>\n\n<p>If only current-source</p>\n<div>$$\n\\iiint_V\\vec{E}_1\\cdot\\vec{J}_2d\\nu=\\iiint_V\\vec{E}_2\\cdot\\vec{J}_1d\\nu\\\\\n\\vec{E}_1\\cdot\\vec{J}_2=\\vec{E_2} \\cdot \\vec{J_1}\n$$</div>\n\n<p>Non-reciprocity</p>\n<p>Electron plasma (non-reciprocal media)</p>\n<div>$$\n\\varepsilon = \\begin{bmatrix}\\varepsilon_{xx}&+ig&0\\\\-ig&\\varepsilon_{yy}&0\\\\0&0&\\varepsilon_{zz}\\end{bmatrix}\n$$</div>\n\n<h3 id=\"Huygen’s-Principle\"><a href=\"#Huygen’s-Principle\" class=\"headerlink\" title=\"Huygen’s Principle\"></a>Huygen’s Principle</h3><p><img src=\"/../images/Antenna/1712905110844.png\" alt=\"1712905110844\"></p>\n<p><img src=\"/../images/Antenna/1712905233876.png\" alt=\"1712905233876\"></p>\n<p><img src=\"/../images/Antenna/1712905317317.png\" alt=\"1712905317317\"></p>\n<h2 id=\"Dipole-Antenna\"><a href=\"#Dipole-Antenna\" class=\"headerlink\" title=\"Dipole Antenna\"></a>Dipole Antenna</h2><h3 id=\"Hertz-Dipole\"><a href=\"#Hertz-Dipole\" class=\"headerlink\" title=\"Hertz Dipole\"></a>Hertz Dipole</h3><ul>\n<li>Infinite short length;</li>\n<li>Uniform distribution;</li>\n<li>Infinite small radius;</li>\n</ul>\n<div>$$\nE_\\theta=\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr}}r\\sin\\theta \\\\\nH_\\varphi=\\frac{I\\Delta z}{4\\pi}jk\\frac{e^{-jkr}}r{\\sin\\theta}\\\\\n\\frac{E_\\theta}{H_\\varphi}=\\sqrt{\\frac{\\mu_0}{\\varepsilon_0}}=\\eta \n$$</div>\n\n<p><img src=\"/../images/Antenna/1713506228135.png\" alt=\"1713506228135\"></p>\n<p><img src=\"/../images/Antenna/1713506258888.png\" alt=\"1713506258888\"></p>\n<p><img src=\"/../images/Antenna/1713506275022.png\" alt=\"1713506275022\"></p>\n<h3 id=\"Finite-Length-Dipole\"><a href=\"#Finite-Length-Dipole\" class=\"headerlink\" title=\"Finite Length Dipole\"></a>Finite Length Dipole</h3><p><img src=\"/../images/Antenna/1713506837120.png\" alt=\"1713506837120\"></p>\n<div>$$\nI=\\begin{cases}I_0\\sin[k(\\dfrac{l}{2}-z')]&0\\leq z'\\leq\\dfrac{l}{2}\\\\\nI_0\\sin[k(\\dfrac{l}{2}+z')]&-\\dfrac{l}{2}\\leq z'\\leq0\\end{cases}\n$$</div>\n\n<div>$$\n\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-j\\kappa\\Lambda}}{4\\pi R}dz’\\\\R=\\sqrt{\\left(x-x’\\right)^2+\\left(y-y’\\right)^2+\\left(z-z’\\right)^2}\n$$</div>\n\n<div>$$\n\\begin{aligned}&\\text{For phase:}&&R\\cong r-z'\\cos\\theta\\\\&\\text{For amplitude:}&&R\\cong r\\end{aligned}\n$$</div>\n\n<p>R is the distance between observer and source,<br>r is the distance between observer and origin.</p>\n<h4 id=\"Small-Dipole\"><a href=\"#Small-Dipole\" class=\"headerlink\" title=\"Small Dipole\"></a>Small Dipole</h4><p><img src=\"/../images/Antenna/1713506363705.png\" alt=\"1713506363705\"></p>\n<div>$$\n\\begin{aligned}&I(z’)\\cong I_{in}(1-2|z’|/l)\\\\&\\vec{A}(x,y,z)=A_z\\hat{z}=\\hat{z}\\int_{-l/2}^{l/2}\\mu I(z’)\\frac{e^{-jkr}}{4\\pi r}dz’\\end{aligned}\n$$</div>\n\n<p>Then</p>\n<div>$$\n\\vec{A}(x,y,z)=\\hat{z}\\mu\\frac{e^{-jkr}}{4\\pi r}\\cdot\\frac12I_{in}l\\\\\n\\vec{A}(\\theta,r)=\\frac12I_{in}l\\mu\\frac{e^{-jkr}}{4\\pi r}(-\\sin\\theta\\hat{\\theta}+\\cos\\theta\\hat{r})\n$$</div>\n\n<div>$$\n\\vec{E}=j\\omega\\mu I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\theta}\\\\\\vec{H}=j\\beta I_{in}l\\frac{e^{-jkr}}{8\\pi r}\\sin\\theta\\hat{\\varphi}\n$$</div>\n\n<p>Note: half of the ideal infinitesima(Hertz) dipole</p>\n<div>$$\n\\mathrm{Directivity}:\\quad D=\\frac{4\\pi}{\\Omega_A}\\Rightarrow D_{\\underset{dipole}{\\operatorname*{small}}}=1.5\n$$</div>\n\n<div>$$\nR_{rad}=20\\left(\\frac{\\pi\\Delta z}\\lambda\\right)^2=\\frac14R_{rad}^\\textit{Hertz dipole}\n$$</div>\n\n<div>$$\nP_{rad}=\\frac14\\frac{4\\pi}3{\\left(\\frac{I\\Delta z}{4\\pi}\\right)}^2k^2\\eta{=}\\frac12I^2R_{rad}\n$$</div>\n\n<h4 id=\"General-Case\"><a href=\"#General-Case\" class=\"headerlink\" title=\"General Case\"></a>General Case</h4><div>$$\nE_{\\theta}=j\\eta\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\\\\H_{\\varphi}=j\\frac{I_0e^{-jkr}}{2\\pi r}\\Bigg[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\Bigg]\n$$</div>\n\n<p>Beam width: change with length.</p>\n<p><img src=\"/../images/Antenna/1713507175699.png\" alt=\"1713507175699\"></p>\n<div>$$\n\\begin{aligned}\n&\\textbf{The time average Poynting vector:}\\\\\n&\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\mathrm{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})}{\\sin\\theta}\\bigg]^{2}\\hat{r}  \\\\\n&P_{rad}=\\oint_{s}\\vec{S}_{a\\nu}\\cdot d\\vec{s}=\\int_{0}^{2\\pi}\\int_{0}^{\\pi}\\vec{S}_{a\\nu}\\cdot\\vec{r}r^{2}\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_{0}\\right|^{2}}{4\\pi}\\int_{0}^{\\pi}\\frac{\\left[\\cos(\\frac{kl}{2}\\cos\\theta)-\\cos(\\frac{kl}{2})\\right]^{2}}{\\sin\\theta}d\\theta  \\\\\n&\\begin{aligned}&\\text{The radiation intensity:}\\\\&&U=r^2S_{av}=\\eta\\frac{\\left|I_0\\right|^2}{8\\pi^2}\\left[\\frac{\\cos(\\frac{kl}2\\cos\\theta)-\\cos(\\frac{kl}2)}{\\sin\\theta}\\right]^2\\\\&&=\\frac{\\pi}{2}=\\frac{\\left|I_{0}\\right|^{2}}{2}=\\frac{k_{0}}{2}=\\frac{k_{0}}{2}\\end{aligned}& \\begin{matrix}{l}\\\\\\end{matrix})  \\\\\n&\\Omega_A=\\frac{P_{rad}}{U_{\\max}}\\quad D=4\\pi/\\Omega_A\\quad A_e=\\frac{\\lambda^2}{4\\pi}D\\quad P_{rad}=\\frac12I^2R_{rad}\n\\end{aligned}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1713507190746.png\" alt=\"1713507190746\"></p>\n<p><img src=\"/../images/Antenna/1713507205996.png\" alt=\"1713507205996\"></p>\n<h4 id=\"Input-Impedance\"><a href=\"#Input-Impedance\" class=\"headerlink\" title=\"Input Impedance\"></a>Input Impedance</h4><p>Input resistance $R_r$:</p>\n<ul>\n<li>calculated by E and H at port; </li>\n<li>take the real part (lossless).</li>\n</ul>\n<p>Radiation resistance $R_{rad}$:</p>\n<ul>\n<li>calculated by E and H at far-field;</li>\n</ul>\n<div>$$\nP_{rad}=\\frac12{\\left|I\\right|}^2R_{rad}\\quad P_{rad}=\\frac12{\\left|I_{in}\\right|}^2R_r\n$$</div>\n\n<p>I is the maximum&#x2F;peak current.</p>\n<p>General Relation:</p>\n<div>$$\nR_r=R_{rad}/\\sin^2\\left(\\frac{kl}2\\right)\n$$</div>\n\n<h3 id=\"Half-wavelength-dipole\"><a href=\"#Half-wavelength-dipole\" class=\"headerlink\" title=\"Half-wavelength dipole\"></a>Half-wavelength dipole</h3><p><img src=\"/../images/Antenna/1713508252106.png\" alt=\"1713508252106\"></p>\n<div>$$\nI(z)=I_0\\sin(\\frac\\pi2-k\\left|z\\right|)\n$$</div>\n\n<div>$$\nE_\\theta(r,\\theta,\\varphi)=j\\eta I_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\\\\H_\\varphi(r,\\theta,\\varphi)=jI_0\\frac{e^{-jkr}}{2\\pi r}\\frac{\\cos(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}\n$$</div>\n\n<div>$$\n\\vec{S}_{a\\nu}=\\hat{r}S_{a\\nu}=\\frac{1}{2}\\operatorname{Re}\\bigg[\\tilde{\\vec{E}}\\times\\tilde{\\vec{H}}^{*}\\bigg]=\\eta\\frac{\\big|I_{0}\\big|^{2}}{8\\pi^{2}r^{2}}\\bigg[\\frac{\\cos(\\frac{\\pi}{2}\\cos\\theta)}{\\sin\\theta}\\bigg]^{2}\\hat{r}\\\\\nP_{rad}=\\oint_sS_{a\\nu}\\cdot d\\vec{s}=\\int_0^{2\\pi}\\int_0^\\pi\\vec{S}_{a\\nu}\\cdot\\hat{r}r^2\\sin\\theta d\\theta d\\varphi=\\eta\\frac{\\left|I_0\\right|^2}{4\\pi}\\int_0^\\pi\\frac{\\cos^2(\\frac\\pi2\\cos\\theta)}{\\sin\\theta}d\\theta \n$$</div>\n\n<div>$$\nD=4\\pi/\\Omega_{A}=1.643=2.15\\mathrm{dBi}\\\\\nA_e=\\frac{\\lambda^2}{4\\pi}D_0\\cong0.13\\lambda^2\n$$</div>\n\n<p>Edge capacitive effect: </p>\n<ul>\n<li>Terminal (open-end)<br>current is not ideal zero;</li>\n<li>Effective length is longer</li>\n</ul>\n<div>$$\nR_r=R_{rad}=\\frac{2P_{rad}}{\\left|I_0\\right|^2}\\cong73\\left(\\Omega\\right)\\\\\nZ_A=73+j43\\left(\\Omega\\right)\n$$</div>\n\n<h3 id=\"Applications\"><a href=\"#Applications\" class=\"headerlink\" title=\"Applications\"></a>Applications</h3><h4 id=\"Wideband-Antennas\"><a href=\"#Wideband-Antennas\" class=\"headerlink\" title=\"Wideband Antennas\"></a>Wideband Antennas</h4><p><img src=\"/../images/Antenna/1713508669926.png\" alt=\"1713508669926\"></p>\n<h4 id=\"Folded-Dipole\"><a href=\"#Folded-Dipole\" class=\"headerlink\" title=\"Folded Dipole\"></a>Folded Dipole</h4><p><img src=\"/../images/Antenna/1713508784675.png\" alt=\"1713508784675\"></p>\n<div>$$\nZ_=4Z_A\n$$</div>\n\n<p>Increase Input Impedance</p>\n<h4 id=\"Log-periodic-amp-Yagi-Uda-antenna\"><a href=\"#Log-periodic-amp-Yagi-Uda-antenna\" class=\"headerlink\" title=\"Log-periodic &amp; Yagi-Uda antenna\"></a>Log-periodic &amp; Yagi-Uda antenna</h4><p><img src=\"/../images/Antenna/1713509120707.png\" alt=\"1713509120707\"></p>\n<h4 id=\"Dipole-Antennas-in-base-station\"><a href=\"#Dipole-Antennas-in-base-station\" class=\"headerlink\" title=\"Dipole Antennas in base station\"></a>Dipole Antennas in base station</h4><p><img src=\"/../images/Antenna/1713509734724.png\" alt=\"1713509734724\"></p>\n<h4 id=\"Monopole\"><a href=\"#Monopole\" class=\"headerlink\" title=\"Monopole\"></a>Monopole</h4><p><img src=\"/../images/Antenna/1713509771675.png\" alt=\"1713509771675\"></p>\n<h2 id=\"Loop-Antennas\"><a href=\"#Loop-Antennas\" class=\"headerlink\" title=\"Loop Antennas\"></a>Loop Antennas</h2><h3 id=\"Small-Loop\"><a href=\"#Small-Loop\" class=\"headerlink\" title=\"Small Loop\"></a>Small Loop</h3><p><img src=\"/../images/Antenna/1715324583382.png\" alt=\"1715324583382\"></p>\n<p><img src=\"/../images/Antenna/1715324548326.png\" alt=\"1715324548326\"></p>\n<p><img src=\"/../images/Antenna/1715324559069.png\" alt=\"1715324559069\"></p>\n<p>Infinite small loop radius;</p>\n<p>Infinite small wire radius;</p>\n<p>Uniform distribution.</p>\n<p>Resistance $R_r$ too small!</p>\n<h3 id=\"Finite-length-loop-antennas\"><a href=\"#Finite-length-loop-antennas\" class=\"headerlink\" title=\"Finite-length loop antennas\"></a>Finite-length loop antennas</h3><p><img src=\"/../images/Antenna/1715325834911.png\" alt=\"1715325834911\"></p>\n<p><img src=\"/../images/Antenna/1715324769403.png\" alt=\"1715324769403\"></p>\n<p><img src=\"/../images/Antenna/1715328812089.png\" alt=\"1715328812089\"></p>\n<h3 id=\"Modes-of-Loop-antennas\"><a href=\"#Modes-of-Loop-antennas\" class=\"headerlink\" title=\"Modes of Loop antennas\"></a>Modes of Loop antennas</h3><p><img src=\"/../images/Antenna/1715924283522.png\" alt=\"1715924283522\"></p>\n<p><img src=\"/../images/Antenna/1715924294266.png\" alt=\"1715924294266\"></p>\n<h3 id=\"Helix-x2F-helical-antennas\"><a href=\"#Helix-x2F-helical-antennas\" class=\"headerlink\" title=\"Helix&#x2F;helical antennas\"></a>Helix&#x2F;helical antennas</h3><p><img src=\"/../images/Antenna/1715924314079.png\" alt=\"1715924314079\"></p>\n<p>Axial Mode</p>\n<p><img src=\"/../images/Antenna/1715924338243.png\" alt=\"1715924338243\"></p>\n<p>Normal Mode:</p>\n<p><img src=\"/../images/Antenna/1715924364965.png\" alt=\"1715924364965\"></p>\n<p><img src=\"/../images/Antenna/1715924463502.png\" alt=\"1715924463502\"></p>\n<h2 id=\"Aperture-Antenna\"><a href=\"#Aperture-Antenna\" class=\"headerlink\" title=\"Aperture Antenna\"></a>Aperture Antenna</h2><h3 id=\"Huygens’-Principle\"><a href=\"#Huygens’-Principle\" class=\"headerlink\" title=\"Huygens’ Principle\"></a>Huygens’ Principle</h3><p><img src=\"/../images/Antenna/1715927654495.png\" alt=\"1715927654495\"></p>\n<h3 id=\"Rectangular-aperture-antennas\"><a href=\"#Rectangular-aperture-antennas\" class=\"headerlink\" title=\"Rectangular aperture antennas\"></a>Rectangular aperture antennas</h3><p><img src=\"/../images/Antenna/1715927982080.png\" alt=\"1715927982080\"></p>\n<p><img src=\"/../images/Antenna/1715928380068.png\" alt=\"1715928380068\"></p>\n<p><img src=\"/../images/Antenna/1715929046320.png\" alt=\"1715929046320\"></p>\n<p><img src=\"/../images/Antenna/1715929138391.png\" alt=\"1715929138391\"></p>\n<p><img src=\"/../images/Antenna/1715929169213.png\" alt=\"1715929169213\"></p>\n<h3 id=\"Horn-Antennas\"><a href=\"#Horn-Antennas\" class=\"headerlink\" title=\"Horn Antennas\"></a>Horn Antennas</h3><p><img src=\"/../images/Antenna/1715929396692.png\" alt=\"1715929396692\"></p>\n<p><img src=\"/../images/Antenna/1715929501432.png\" alt=\"1715929501432\"></p>\n<p>The E-pattern is in shadow.</p>\n<p><img src=\"/../images/Antenna/1715929523072.png\" alt=\"1715929523072\"></p>\n<p><img src=\"/../images/Antenna/1715929531751.png\" alt=\"1715929531751\"></p>\n<p><img src=\"/../images/Antenna/1715929546494.png\" alt=\"1715929546494\"></p>\n<h2 id=\"Antenna-Array\"><a href=\"#Antenna-Array\" class=\"headerlink\" title=\"Antenna Array\"></a>Antenna Array</h2><p>1-D Linear Array</p>\n<p>2-D Planar Array</p>\n<p>3-D Conformal Array</p>\n<p>Array Element</p>\n<ul>\n<li>Dipoles</li>\n<li>Loops</li>\n<li>Slots</li>\n<li>Microstrip antennas</li>\n</ul>\n<h3 id=\"Two-Element-array\"><a href=\"#Two-Element-array\" class=\"headerlink\" title=\"Two-Element array\"></a>Two-Element array</h3><p><img src=\"/../images/Antenna/1717133761533.png\" alt=\"1717133761533\"></p>\n<div>$$\n\\begin{gathered}\n\\vec{E}_1= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_1}}{r_1}\\cos\\theta_1 \\\\\n\\vec{E}_{2}= \\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\frac{e^{-jkr_2}}{r_2}\\cos\\theta_2 \n\\end{gathered}\n$$</div>\n\n<p>Remarks:</p>\n<ul>\n<li>Two element;</li>\n<li>Towards Y axis;</li>\n<li>Along Z axis;</li>\n<li>Space: d;</li>\n<li>Uniform phase<br>and amplitude;</li>\n<li>Observe in 2D<br>(YZ-plane).</li>\n</ul>\n<p>Far field Approximation</p>\n<p><img src=\"/../images/Antenna/1717133876692.png\" alt=\"1717133876692\"></p>\n<div>$$\n\\begin{aligned}&\\vec{E}_{total}=\\vec{E}_1+\\vec{E}_2\\\\&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac1r\\Bigg(e^{-jk(r-\\frac d2\\cos\\theta)}+e^{-jk(r+\\frac d2\\cos\\theta)}\\Bigg)\\end{aligned}\n$$</div>\n\n<div>$$\n\\begin{aligned}\n\\vec{E}_{total}& =\\vec{E}_1+\\vec{E}_2=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{1}{r}\\Bigg(e^{-jk(r-\\frac{d}{2}\\cos\\theta)}+e^{-jk(r+\\frac{d}{2}\\cos\\theta)}\\Bigg)  \\\\\n&=\\hat{\\theta}\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}{r}\\Bigg(e^{jk\\frac{d}{2}\\cos\\theta}+e^{-jk\\frac{d}{2}\\cos\\theta}\\Bigg) \\\\\n&=\\hat{\\theta}\\underbrace{\\frac{I\\Delta z}{4\\pi}j\\omega\\mu\\cos\\theta\\frac{e^{-jkr}}r}_{\\text{Element pattern}}\\underbrace{2\\cos\\biggl[\\frac12kd\\cos\\theta\\biggr]}_{\\text{Array Factor (AF)}}\n\\end{aligned}\n$$</div>\n\n<p>Remarks:</p>\n<ul>\n<li>Uniform phase and amplitude;</li>\n<li>AF is related to space (d);</li>\n<li>AF is with no relation with antenna type.</li>\n</ul>\n<div>$$\nAF{=}2\\cos\\left[\\frac12kd\\cos\\theta\\right]\\quad kd{=}\\frac{2\\pi}\\lambda d{=}2\\pi\\frac d\\lambda \n$$</div>\n\n<p><img src=\"/../images/Antenna/1717134268805.png\" alt=\"1717134268805\"></p>\n<p><img src=\"/../images/Antenna/1717134287481.png\" alt=\"1717134287481\"></p>\n<h3 id=\"N-Element-array\"><a href=\"#N-Element-array\" class=\"headerlink\" title=\"N-Element array\"></a>N-Element array</h3><p><img src=\"/../images/Antenna/1717134353772.png\" alt=\"1717134353772\"></p>\n<div>$$\n\\begin{aligned}&AF=1+e^{jkd\\cos\\theta}+e^{j2kd\\cos\\theta}+\\cdots+e^{j(N-1)kd\\cos\\theta}\\\\&=\\sum_{n=1}^Ne^{j(n-1)kd\\cos\\theta}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}\\end{aligned}\n$$</div>\n\n<div>$$\nAF=1+e^{j\\Psi}+e^{j2\\Psi}+\\cdots+e^{j(N-1)\\Psi}=\\frac{e^{jN\\Psi}-1}{e^{j\\Psi}-1}\\\\=\\frac{e^{j\\frac N2\\Psi}\\left(e^{j\\frac N2\\Psi}-e^{-j\\frac N2\\Psi}\\right)}{e^{j\\frac12\\Psi}\\left(e^{j\\frac12\\Psi}-e^{-j\\frac12\\Psi}\\right)}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$</div>\n\n<p>Refenece Point at the end:</p>\n<div>$$\nAF=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$</div>\n\n<p>Refenece Point at the center:</p>\n<div>$$\nAF=\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{\\sin\\left(\\frac12\\Psi\\right)},\\Psi=kd\\cos\\theta,\n$$</div>\n\n<p>In Progreessive Phase Shift:</p>\n<div>$$\n\\Psi=kd\\cos\\theta+\\alpha \n$$</div>\n\n<div>$$\nAF=1+e^{j(kd\\cos\\theta+\\alpha)}+e^{j2(kd\\cos\\theta+\\alpha)}+\\cdots+e^{j(N-1)(kd\\cos\\theta+\\alpha)}\\\\=\\sum_{n=1}^Ne^{j(n-1)(kd\\cos\\theta+\\alpha)}=\\sum_{n=1}^Ne^{j(n-1)\\Psi}=\\frac{e^{j\\frac N2\\Psi}\\sin\\left(\\frac N2\\Psi\\right)}{e^{j\\frac12\\Psi}\\sin\\left(\\frac12\\Psi\\right)}\n$$</div>\n\n<p>Normalized Array Factor:</p>\n<div>$$\n\\left|f(\\Psi)\\right|=\\left|\\frac{\\sin\\left(\\frac N2\\Psi\\right)}{N\\sin\\left(\\frac12\\Psi\\right)}\\right|\n$$</div>\n\n<p>Grating Lobe:</p>\n<div>$$\n\\begin{aligned}\n\\theta\\in\\begin{bmatrix}0,\\pi\\end{bmatrix}\\text{ or }\\theta\\in\\begin{bmatrix}\\theta_1,\\theta_2\\end{bmatrix}\\text{, visible region} \\\\\n\\text{In the visible region,} \\\\\nifwehaveY= 0\\mathrm{~and~}\\Psi=2\\pi. \n\\end{aligned}\n$$</div>\n\n<p>Avoid grating lobe:</p>\n<ol>\n<li>Smaller d;</li>\n<li>Smaller phase shift.</li>\n</ol>\n<div>$$\n1.\\mathrm{~For~}\\alpha=\\pi\\Rightarrow2kd<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<\\frac12\\\\2.\\mathrm{~For~}\\alpha=0\\mathrm{~}\\Rightarrow\\mathrm{~k}d<2\\pi\\Rightarrow d\\mathrm{~/~}\\lambda<1\n$$</div>\n\n<h4 id=\"Broadside-Array\"><a href=\"#Broadside-Array\" class=\"headerlink\" title=\"Broadside Array\"></a>Broadside Array</h4><p>Maximum @ $\\theta &#x3D; 90\\degree$</p>\n<div>$$\nAF\\boldsymbol{=}N@\\boldsymbol{\\theta}\\boldsymbol{=}\\boldsymbol{\\pi}/2\\quad\\boldsymbol{\\Psi}\\boldsymbol{=}kd\\cos\\boldsymbol{\\theta}\\boldsymbol{+}\\boldsymbol{\\alpha}|_{\\theta=\\pi/2}\\boldsymbol{=}0\n$$</div>\n\n<p><img src=\"/../images/Antenna/1717134725130.png\" alt=\"1717134725130\"></p>\n<p><img src=\"/../images/Antenna/1717134745100.png\" alt=\"1717134745100\"></p>\n<h4 id=\"End-fire-Array\"><a href=\"#End-fire-Array\" class=\"headerlink\" title=\"End-fire Array\"></a>End-fire Array</h4><p><img src=\"/../images/Antenna/1717134897852.png\" alt=\"1717134897852\"></p>\n<div>$$\n\\begin{aligned}\n&AF= N@\\theta{=}0  &\\Psi=kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2\\ldots)  \\\\\n&\\text{or} \\\\\n&AF= N@\\theta{=}\\pi   &\\Psi=-kd+\\alpha=2n\\pi(n=0,\\pm1,\\pm2...)  \\\\\n&\\Psi=kd\\cos\\theta+\\alpha=2\\pi\\cos\\theta \n\\end{aligned}\n$$</div>\n\n<p>Bidirectional:</p>\n<p><img src=\"/../images/Antenna/1717134942873.png\" alt=\"1717134942873\"></p>\n<p>Unidirectional:</p>\n<p><img src=\"/../images/Antenna/1717134955235.png\" alt=\"1717134955235\"></p>\n<h4 id=\"Phased-Array\"><a href=\"#Phased-Array\" class=\"headerlink\" title=\"Phased Array\"></a>Phased Array</h4><p><img src=\"/../images/Antenna/1717135044895.png\" alt=\"1717135044895\"></p>\n<h4 id=\"Non-uniform-Array\"><a href=\"#Non-uniform-Array\" class=\"headerlink\" title=\"Non-uniform Array\"></a>Non-uniform Array</h4><p>Side Lobe</p>\n<p>Uniform array:</p>\n<ul>\n<li>Universal pattern: N↑, SLL↓ </li>\n<li>With a limit of -13.3 dB</li>\n<li>No control of SL</li>\n</ul>\n<p>How to reduce SLL?</p>\n<p>Non-uniform excitation</p>\n<p><img src=\"/../images/Antenna/1717135171215.png\" alt=\"1717135171215\"></p>\n<h4 id=\"Planar-Array\"><a href=\"#Planar-Array\" class=\"headerlink\" title=\"Planar Array\"></a>Planar Array</h4><p><img src=\"/../images/Antenna/1717135198414.png\" alt=\"1717135198414\"></p>\n<p>Can be viewed as product of two linear array factors:</p>\n<div>$$\nAF=\\sum_{i=1}^{M\\times N}I_ie^{jk\\hat{r}\\cdot\\vec{r}_i}\\\\\nAF_n(\\theta,\\phi)=\\left\\lbrace\\frac{\\sin(\\frac M2\\psi_x)}{M\\sin\\frac{\\psi_x}2}\\right\\rbrace\\left\\{\\frac{\\sin(\\frac N2\\psi_y)}{N\\sin\\frac{\\psi_y}2}\\right\\};\\\\\\psi_x=kd_x\\sin\\theta\\cos\\varphi+\\alpha_x\\\\\\psi_y=kd_y\\sin\\theta\\sin\\varphi+\\alpha_y\n$$</div>\n\n<h3 id=\"Applications-1\"><a href=\"#Applications-1\" class=\"headerlink\" title=\"Applications\"></a>Applications</h3><h4 id=\"Yagi-Uda-Antenna\"><a href=\"#Yagi-Uda-Antenna\" class=\"headerlink\" title=\"Yagi-Uda Antenna\"></a>Yagi-Uda Antenna</h4><p>Basic configuration:</p>\n<ul>\n<li>One driven element;</li>\n<li>Two parasitic elements or more</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717135386351.png\" alt=\"1717135386351\"></p>\n<p>Remarks:</p>\n<ul>\n<li>Parasitic elements are excited by near-field coupling from the driven element;</li>\n<li>Proper design of parasitic elements for end fire radiation;</li>\n<li>In far field, the radiated waves from all the elements are in-phase.</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717135675789.png\" alt=\"1717135675789\"></p>\n<p><img src=\"/../images/Antenna/1717135951201.png\" alt=\"1717135951201\"></p>\n<h4 id=\"Helix-Antenna\"><a href=\"#Helix-Antenna\" class=\"headerlink\" title=\"Helix Antenna\"></a>Helix Antenna</h4><p><img src=\"/../images/Antenna/1717136046473.png\" alt=\"1717136046473\"></p>\n<p><img src=\"/../images/Antenna/1717136115015.png\" alt=\"1717136115015\"></p>\n<h2 id=\"Travelling-Wave-Antennas\"><a href=\"#Travelling-Wave-Antennas\" class=\"headerlink\" title=\"Travelling-Wave Antennas\"></a>Travelling-Wave Antennas</h2><h3 id=\"Travelling-wave-amp-standing-wave\"><a href=\"#Travelling-wave-amp-standing-wave\" class=\"headerlink\" title=\"Travelling wave &amp; standing wave\"></a>Travelling wave &amp; standing wave</h3><h4 id=\"Long-wire-antennas\"><a href=\"#Long-wire-antennas\" class=\"headerlink\" title=\"Long wire antennas\"></a>Long wire antennas</h4><p><img src=\"/../images/Antenna/1717137633424.png\" alt=\"1717137633424\"></p>\n<p><img src=\"/../images/Antenna/1717137646795.png\" alt=\"1717137646795\"></p>\n<p>Note:<br>Long wire antennas: “l” &#x3D; Several wavelength</p>\n<ul>\n<li>One end for excitation;</li>\n<li>The other end for load (open, short, or matching);</li>\n<li>Transmission line with radiation.</li>\n</ul>\n<h3 id=\"Log-periodic-Antennas\"><a href=\"#Log-periodic-Antennas\" class=\"headerlink\" title=\"Log-periodic Antennas\"></a>Log-periodic Antennas</h3><p>Yagi-Uda: High Gain</p>\n<p>Log-periodic: Wide Bandwidth</p>\n<p><img src=\"/../images/Antenna/1717138714524.png\" alt=\"1717138714524\"></p>\n<p>Why:</p>\n<ol>\n<li>Feed from smaller dipole element;</li>\n<li>Feed out-of-phase with adjacent elements;</li>\n<li>Add a resistor at the end.</li>\n</ol>\n<div>$$\n\\tau=\\frac{R_{n+1}}{R_{n}}=\\frac{L_{n+1}}{L_{n}}=\\frac{d_{n+1}}{d_{n}}\\\\\\alpha=2\\tan^{-1}\\left(\\frac{1-\\tau}{4\\sigma}\\right)\\\\\\sigma=\\frac{d_{n}}{2L_{n}}\\\\L_{1}\\approx\\frac{\\lambda_{L}}{2}\\quad\\mathrm{and}\\quad L_{N}\\approx\\frac{\\lambda_{U}}{2}\n$$</div>\n\n<p><img src=\"/../images/Antenna/1717138873279.png\" alt=\"1717138873279\"></p>\n<h2 id=\"Microstrip-Antennas\"><a href=\"#Microstrip-Antennas\" class=\"headerlink\" title=\"Microstrip Antennas\"></a>Microstrip Antennas</h2><p><img src=\"/../images/Antenna/1717740667735.png\" alt=\"1717740667735\"></p>\n<p><img src=\"/../images/Antenna/1717740670364.png\" alt=\"1717740670364\"></p>\n<p><img src=\"/../images/Antenna/1717740680573.png\" alt=\"1717740680573\"></p>\n<h3 id=\"Basic-Mode\"><a href=\"#Basic-Mode\" class=\"headerlink\" title=\"Basic Mode\"></a>Basic Mode</h3><ul>\n<li>Equivalent magnetic current;</li>\n<li>Radiating and non-radiating apertures;</li>\n<li>Operating frequency with different L.</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717740726098.png\" alt=\"1717740726098\"></p>\n<ul>\n<li>Magnetic current array;</li>\n<li>Image theorem from infinite ground;</li>\n<li>Cavity model with magnetic walls;</li>\n<li>Different from</li>\n</ul>\n<p><img src=\"/../images/Antenna/1717740758890.png\" alt=\"1717740758890\"></p>\n<p><img src=\"/../images/Antenna/1717740768183.png\" alt=\"1717740768183\"></p>\n<h3 id=\"Antenna-feeding-methods\"><a href=\"#Antenna-feeding-methods\" class=\"headerlink\" title=\"Antenna feeding methods\"></a>Antenna feeding methods</h3><p><img src=\"/../images/Antenna/1717740786849.png\" alt=\"1717740786849\"></p>\n<p>Impedance Matching:</p>\n<p><img src=\"/../images/Antenna/1717740801741.png\" alt=\"1717740801741\"></p>\n<p>Using 50-Ohm port: finding the position with Z_in&#x3D;50 Ohm</p>\n<h3 id=\"Analysis-Model\"><a href=\"#Analysis-Model\" class=\"headerlink\" title=\"Analysis Model\"></a>Analysis Model</h3><p><img src=\"/../images/Antenna/1717742374397.png\" alt=\"1717742374397\"></p>\n<p>Known:</p>\n<ul>\n<li>Operating Frequency</li>\n<li>Dielectric: $\\varepsilon_r$ and $h$</li>\n<li>Metal: $t$</li>\n</ul>\n<p>Design: </p>\n<ul>\n<li>Patch: $L$ and $W$</li>\n<li>Evaluate gain</li>\n</ul>\n<p>2 Models:</p>\n<p><img src=\"/../images/Antenna/1717742413544.png\" alt=\"1717742413544\"></p>\n<h4 id=\"Transmission-line-model\"><a href=\"#Transmission-line-model\" class=\"headerlink\" title=\"Transmission line model\"></a>Transmission line model</h4><p>determine W</p>\n<p>Uniform distribution and  field intensity in dielectric</p>\n<div>$$\nW=\\frac{1}{2f_r\\sqrt{\\mu_0\\epsilon_0}}\\sqrt{\\frac{2}{\\epsilon_r+1}}\n$$</div>\n\n<p>Effective permittivity</p>\n<div>$$\n\\varepsilon_{eff}=\\frac{\\varepsilon_r+1}2+\\frac{\\varepsilon_r-1}2{\\left[1+12\\frac hW\\right]}^{-1/2}\n$$</div>\n\n<p>Fring effect and determine L</p>\n<div>$$\n\\frac{\\Delta L}{h}=0.412\\frac{(\\varepsilon_{eff}+0.3)(\\frac Wh+0.264)}{(\\varepsilon_{eff}-0.258)(\\frac Wh+0.8)}\\\\L=\\frac{\\lambda_d}2-2\\Delta L=\\frac{\\lambda_0}{2\\sqrt{\\varepsilon_{eff}}}-2\\Delta L\n$$</div>\n\n<p>impedance matching</p>\n<h4 id=\"Cavity-Model\"><a href=\"#Cavity-Model\" class=\"headerlink\" title=\"Cavity Model\"></a>Cavity Model</h4><p><img src=\"/../images/Antenna/1717742626807.png\" alt=\"1717742626807\"></p>\n<p><img src=\"/../images/Antenna/1717743460723.png\" alt=\"1717743460723\"></p>\n<p><img src=\"/../images/Antenna/1717743468657.png\" alt=\"1717743468657\"></p>\n<h3 id=\"Circular-polarization\"><a href=\"#Circular-polarization\" class=\"headerlink\" title=\"Circular polarization\"></a>Circular polarization</h3><p>Dual feed patch</p>\n<p><img src=\"/../images/Antenna/1717743681072.png\" alt=\"1717743681072\"></p>\n<p><img src=\"/../images/Antenna/1717743691321.png\" alt=\"1717743691321\"></p>\n<p><img src=\"/../images/Antenna/1717743927411.png\" alt=\"1717743927411\"></p>\n<p><img src=\"/../images/Antenna/1718344358151.png\" alt=\"1718344358151\"></p>\n<p>SP-feed 旋转馈电</p>\n<h2 id=\"Reflector-and-lens-antennas\"><a href=\"#Reflector-and-lens-antennas\" class=\"headerlink\" title=\"Reflector and lens antennas\"></a>Reflector and lens antennas</h2><p><img src=\"/../images/Antenna/1718345601277.png\" alt=\"1718345601277\"></p>\n<h3 id=\"Corner-Reflectors\"><a href=\"#Corner-Reflectors\" class=\"headerlink\" title=\"Corner Reflectors\"></a>Corner Reflectors</h3><p><img src=\"/../images/Antenna/1718345727630.png\" alt=\"1718345727630\"></p>\n<p><img src=\"/../images/Antenna/1718345718761.png\" alt=\"1718345718761\"></p>\n<h3 id=\"Parabolic-Reflectors\"><a href=\"#Parabolic-Reflectors\" class=\"headerlink\" title=\"Parabolic Reflectors\"></a>Parabolic Reflectors</h3><p><img src=\"/../images/Antenna/1718346212882.png\" alt=\"1718346212882\"></p>\n<p><img src=\"/../images/Antenna/1718346379534.png\" alt=\"1718346379534\"></p>\n<p><img src=\"/../images/Antenna/1718346371235.png\" alt=\"1718346371235\"></p>\n<p><img src=\"/../images/Antenna/1718346571584.png\" alt=\"1718346571584\"></p>\n<h3 id=\"Lens-Antennas\"><a href=\"#Lens-Antennas\" class=\"headerlink\" title=\"Lens Antennas\"></a>Lens Antennas</h3><p><img src=\"/../images/Antenna/1718346830900.png\" alt=\"1718346830900\"></p>\n<p>Lens antennas:</p>\n<ul>\n<li>High gain: plane wave;</li>\n<li>Geometrical optics: equal optical distance;</li>\n<li>Source: spherical wave, illuminate the whole lens;</li>\n<li>Source is positioned on the focal point for normal<br>radiated plane wave;</li>\n<li>Other incident&#x2F;radiated angle of plane wave: focus on<br>the focal plane with gain decrease;</li>\n<li>Spatial Fournier Transformation: (x, y)&amp;k</li>\n</ul>\n<h3 id=\"Reflected-and-transmitted-array\"><a href=\"#Reflected-and-transmitted-array\" class=\"headerlink\" title=\"Reflected and transmitted array\"></a>Reflected and transmitted array</h3><p><img src=\"/../images/Antenna/1718347859765.png\" alt=\"1718347859765\"></p>\n<p><img src=\"/../images/Antenna/1718347869028.png\" alt=\"1718347869028\"></p>\n"},{"title":"CSAPP学习笔记","date":"2023-01-21T03:19:14.000Z","_content":"\n\n### 第三章 \n\nCSAPP第三版使用的GCC版本：4.8.1\n\n[Compiler Explorer](https://godbolt.org/)\n\n#### 为什么p173要执行subq $8, %rsp?\n为了对齐栈指针。x86要求栈指针为16的倍数，而每次调用函数后栈指针模16都会余个8，两次push使栈指针减少16，还是余8.\n\n#### 随笔\n\n结构体字节对齐的结论：对齐要求取决于占据空间最大的元素。可以先安排较大元素，再安排较小元素。\n\n#### 答案纠错\n3.43第4问答案有误。应为```movq %rdi,(%rsi)```。\n![](../images/csapp1.jpg)\n\n","source":"_posts/CSAPP学习笔记.md","raw":"---\ntitle: CSAPP学习笔记\ndate: 2023-01-21 11:19:14\ntags:\n---\n\n\n### 第三章 \n\nCSAPP第三版使用的GCC版本：4.8.1\n\n[Compiler Explorer](https://godbolt.org/)\n\n#### 为什么p173要执行subq $8, %rsp?\n为了对齐栈指针。x86要求栈指针为16的倍数，而每次调用函数后栈指针模16都会余个8，两次push使栈指针减少16，还是余8.\n\n#### 随笔\n\n结构体字节对齐的结论：对齐要求取决于占据空间最大的元素。可以先安排较大元素，再安排较小元素。\n\n#### 答案纠错\n3.43第4问答案有误。应为```movq %rdi,(%rsi)```。\n![](../images/csapp1.jpg)\n\n","slug":"CSAPP学习笔记","published":1,"updated":"2024-03-19T06:01:16.155Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhq0002rsug5c44gq57","content":"<h3 id=\"第三章\"><a href=\"#第三章\" class=\"headerlink\" title=\"第三章\"></a>第三章</h3><p>CSAPP第三版使用的GCC版本：4.8.1</p>\n<p><a href=\"https://godbolt.org/\">Compiler Explorer</a></p>\n<h4 id=\"为什么p173要执行subq-8-rsp\"><a href=\"#为什么p173要执行subq-8-rsp\" class=\"headerlink\" title=\"为什么p173要执行subq $8, %rsp?\"></a>为什么p173要执行subq $8, %rsp?</h4><p>为了对齐栈指针。x86要求栈指针为16的倍数，而每次调用函数后栈指针模16都会余个8，两次push使栈指针减少16，还是余8.</p>\n<h4 id=\"随笔\"><a href=\"#随笔\" class=\"headerlink\" title=\"随笔\"></a>随笔</h4><p>结构体字节对齐的结论：对齐要求取决于占据空间最大的元素。可以先安排较大元素，再安排较小元素。</p>\n<h4 id=\"答案纠错\"><a href=\"#答案纠错\" class=\"headerlink\" title=\"答案纠错\"></a>答案纠错</h4><p>3.43第4问答案有误。应为<code>movq %rdi,(%rsi)</code>。<br><img src=\"/../images/csapp1.jpg\" loading=\"lazy\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"第三章\"><a href=\"#第三章\" class=\"headerlink\" title=\"第三章\"></a>第三章</h3><p>CSAPP第三版使用的GCC版本：4.8.1</p>\n<p><a href=\"https://godbolt.org/\">Compiler Explorer</a></p>\n<h4 id=\"为什么p173要执行subq-8-rsp\"><a href=\"#为什么p173要执行subq-8-rsp\" class=\"headerlink\" title=\"为什么p173要执行subq $8, %rsp?\"></a>为什么p173要执行subq $8, %rsp?</h4><p>为了对齐栈指针。x86要求栈指针为16的倍数，而每次调用函数后栈指针模16都会余个8，两次push使栈指针减少16，还是余8.</p>\n<h4 id=\"随笔\"><a href=\"#随笔\" class=\"headerlink\" title=\"随笔\"></a>随笔</h4><p>结构体字节对齐的结论：对齐要求取决于占据空间最大的元素。可以先安排较大元素，再安排较小元素。</p>\n<h4 id=\"答案纠错\"><a href=\"#答案纠错\" class=\"headerlink\" title=\"答案纠错\"></a>答案纠错</h4><p>3.43第4问答案有误。应为<code>movq %rdi,(%rsi)</code>。<br><img src=\"/../images/csapp1.jpg\"></p>\n"},{"title":"Computer Network","date":"2023-09-18T11:18:41.000Z","katex":true,"_content":"\n## 参考书籍\n\nA.S Tanebaum (著)，严伟，潘爱民(译) 计算机网络(第五版), 2004，清华大学出版社 \n\nA.S Tanebaum，Nick Feamster, David Wetherall (著)，潘爱民(译)， 计算机网络(第六版), 2022, 清华大学出版社（彩色版，非常精美）\n\n\n## 杂项\n\ntoken ring \n\n计算机网络最核心的技术：分组(packet)。\n\ngrid computing\n\n## 计算机网络的历史与进展\n\n网络计算的基本模式\n* C/S or B/W\n* P2P\n\n服务\n* 延迟、带宽、丢失率、可靠性\n* 单播/多播， 实时/非实时\n\n链路：光纤、电缆和卫星\n* 电子、光子等作为传输介质\n* 节点：机械/电/光\n\n协议\n* TCP/IP, ATM, MPLS, SONET, Ethernet, PPP, X.25, FrameRelay, AppleTalk, IPX, SNA\n\n功能\n* 路由，差错控制、拥塞控制、服务质量(QoS)\n\n应用：FTP、HTTP \n\n\n空间距离\n* 局域网 (LAN): 以太网、令牌环、FDDI\n* 城域网 (MAN): DQDB, SMDS ,以太网\n* 广域网 (WAN): X.25, ATM, frame relay, DWDM\n\n信息类型\n* 数据网络 vs. 通信网络\n\n应用类型\n* 专用网络：飞机订票网，银行网，信用卡网\n* 通用网络：Internet\n\n使用权\n* 私有：企业网\n* 公用：电话网、Internet\n协议的所有权\n* 私有: SNA (Systems Network Architecture)\n* 开放: IP\n技术\n* 地面 vs. 卫星\n* 有线 vs. 无线\n协议\n* IP, AppleTalk, SNA\n\n计算机网络的形成\n* 多终端系统\n* 把计算机互联起来\n1970年代的计算机网络\n* X.25 分组交换网：各国的电信部门建设运行\n* 各种专用的网络体系结构：SNA，DECnet\n* Internet 的前身ARPANET进行实验运行\n1980年代的计算机网络\n* 标准化计算机网络体系结构：OSI\n* 局域网络 LAN 技术空前发展\n* 建成NSFNET，Internet 初具规模\n\n迈特卡尔夫定律(联网定律)\n\n网络价值随用户数平方成正比。未联网设备增加 $N$ 倍，效率增加 $N$ 倍。联网设备增加 $N$ 倍，效率增加 $N^2$ 倍\n\nInternet 标准化组织\n\n* Internet Engineering Task Force（IETF）：IETF负责Internet协议的研发和改进。IETF被分为很多个工作组（working groups），他们提交的文档称为RFC（Request For Comments）。\n* IRTF（Internet Research Task Force）：IRTF由一些专注于某个领域长期发展的研究小组组成。\n* Internet Architecture Board（IAB）：IAB负责定义Internet的整体框架，为IETF提供大方向上的指导。\n* The Internet Engineering Steering Group（IESG）：IESG在技术方面管理IETF的活动，负责Internet标准的制定过程。\n\n所有的标准以RFC的形式发布出来，可以从www.ietf.org免费获得，但不是所有的RFC都是Internet标准。标准形成的一般步骤是：\n* Internet Drafts\n* RFCs\n* Proposed Standard\n* Draft Standard（需要两个可以工作的实现）\n* Internet Standard（由IAB发布）\n\nDavid Clark, MIT, 1992: \n*      \"We reject: kings, presidents, and voting. \n*       We believe in: rough consensus and running code.”\n\n**Paul Baran 分组交换网络**\n\n与 Donald Watts Davies 在这个思想的发明上有争议。\n\nBaran 的设计细节：\n\n报文发送\n* 每个交换节点根据自己的路由表判断如何转发报文\n* 每个报文的转发都是独立于其他报文的\n* 交换节点不保存端节点的状态\n  * 可扩展性好\n  * 不是最有效的网络\n  * 发送不是完美的\n    * 端节点必须能容忍发送错误并从中恢复 \n分布式系统\n* 所有交换节点是平等的\n* 避免了单一节点失效问题\n* 部件可以失效，但系统不可以\n* 系统的健壮性来自于\n  * 足够的物理（硬件）冗余\n  * 适应性路由\n\n模拟实验表明：“extremely survivable networks can be built using a moderately low redundancy of connectivity level”—Paul Baran, 1964\n\n\n比较两种可靠系统的实现思路：\n\n电话系统 \n* 笨终端，聪明的网络 \n* 确保每个网络部件都是可靠的 \n  * 系统可靠性＝部件可靠性 \n  * 通过局部冗余实现部件的高可靠性 \n  * 期望每个部件都能正常工作，部件失败的可能性很低 \n* 需要人工配置的，高度控制的网络 \n\nBaran的系统 \n* 建立在简单的、不可靠部件上的可靠系统 \n* 自适应的系统 \n* 聪明的终端，可以修正传输错误 \n\nBaran 设计思想的一种实现：Internet\n\n* 连接异构的子网\n* 提供两种基本功能\n  * 全球唯一的地址\n  * 报文通过动态路由从源节点发送到目的节点\n\nsimple, flexible, scalable, and robust\n\n分组交换的特点：\n\n**简单性**\n\n* 每个报文携带各自的地址信息\n* 一个路由表可以为所有的流量服务\n* 可以适应爆炸性的增长\n  * 越简单越不容易出错 \n  * 越简单越容易增长 \n  * 对基本网络功能的要求少，可以在其上建立多种类型的网络 \n\n**灵活性**\n\nEverything over IP\n\nIP over Everything\n\n**可扩展性**\n\n可扩展的系统必须能对付\n* 端系统的增加\n* 流量的增加\n* 网络规模的增长\n  * 大的路由表\n  * 路由频繁的变化\n\n边缘论：End-to-End Argument\n\n路由器只负责传输，复杂的功能（纠错，重传）都由终端自行解决\n\n**健壮性**\n* 动态路由具有自适应的特性\n  * 动态路由和报文转发相辅相成\n  * 周期性路由更新\n  * 默认: 现有的部件会失效，会有新的部件加入，认为变化是正常的\n* 牺牲一定的带宽的利用率，提高健壮性(报文头开销，更新开销) \n\n\n## 数据通信基本原理\n\n香农定理：\n带宽为 $H$ 赫兹，信噪比为 $S/N$ 的任意信道的最大数据传输率为 $H\\log_2(1 + S/N) (bps)$\n* 此式是利用信息论得出的，具有普遍意义\n* 与信号电平级数、采样速度无关\n* 此式仅是上限，实践中难以达到\n\n曼彻斯特码（Manchester），也称相位编码\n* 原理：每一位中间都有一个跳变，从低跳到高表示“0”，从高跳到低表示“1”。\n* 优点：克服了NRZ码的不足。每位中间的跳变即可作为数据，又可作为时钟，能够自同步。\t\n\n差分曼彻斯特码（Differential Manchester）\n* 原理：每一位中间都有一个跳变，每位开始时有跳变表示“0”，无跳变表示“1”。位中间跳变表示时钟，位前跳变表示数据。\n* 优点：时钟、数据分离，便于提取。\n\n## 网络体系结构\n\n### 计算机网络的构成\n\n**资源子网**\n* 服务器（Server）\n* 客户机（Client）\n\nC/S -> B/W -> P2P\n\n**通信子网**\n* 通信线路（通道）\n* 网络互连设备（路由器、交换机、集线器等）\n\n#### 基本结构\n\n**点到点通道**\n* 一条线路连接两台网络互联设备\n* 一般两台计算机的连接要经过多台互联设备\n* 星形、环形、树形、全连结、交叉环、不规则图\n* 关键技术：路由选择（Routing）\n\n**广播网络**\n* 总线，环\n* 组播网络（Multicast Networks）：把成员分组\n* 单播网络（Unicast Networks）\n  * 点到点连接\n* 关键技术：通道分配\n  * 静态分配：分时间片\n    * 控制简单，通道利用率低\n  * 动态分配各站点动态使用通道\n    * 控制复杂，通道利用度高\n    * 通道分配方法：\n      * 集中式：只有一个仲裁机构\n      * 分布式：各站点均有仲裁机构\n\n* PAN\n* LAN\n* MAN\n* WAN\n* internet，指一种技术(Internet，指实体的网络)\n* Interplanetary Internet\n\n### 计算机网络体系结构\n\n对计算机网络及其部件所完成的功能的比较精确的定义，即从功能的角度描述计算机网络的结构，是层次模型和协议的集合。\n\n注意：计算机网络体系结构仅仅定义了网络及其部件通过协议应完成的功能，不定义协议的实现细节和各层协议之间的接口关系。\n\n协议分层的优点：易于协议的设计、分析、实现和调试\n\n计算机网络的功能：\n* 基本功能：为地理位置不同的计算机用户提供访问通路\n* 具体化为：\n  * 连接源节点和目的节点的物理传输线路，可以经过中间节点\n  * 每条线路两端的结点利用波形进行二进制通信\n  * 无差错的信息传送\n  * 多个用户共享一条物理线路\n  * 按照地址信息，进行路由选择\n  * 信息缓存与流量控制\n  * 会话控制\n  * 满足各种用户、各种应用的访问要求\n\n\n#### 网络协议\n\n层次结构的计算计网络功能中最重要的功能是通信功能，这种通信功能主要涉及同层中通信双方的相互作用，位于不同计算机上进行对话的第N层通信各方可分别看成是一种进程，称为**对等进程（同等进程）**\n\n**协议**\n\n计算机网络同等层次中，通信双方进行信息交换时必须遵守的规则。\n\n**协议栈**\n\n一个特定系统所使用的一组协议统称为协议栈。\n\n**接口**\n\n相邻层之间有一个接口（Interface），它定义了下层向上层提供的原语操作与服务\n\n#### 层、协议和接口\n\n**协议特性**\n\n* 不知道上下层的内部结构\n* 独立完成某种功能\n* 为上层提供服务\n* 使用下层提供的服务\n\n#### 服务分类\n\n* 面向连接的服务\n  * 当使用服务传输数据时，首先建立连接，然后使用该链接传送数据，使用完后，关闭连接。\n  * 特点：顺序性好，类似于电话\n* 面向无连接的服务\n  * 直接使用服务传送数据，每个分组独立进行路由选择。\n  * 特点：顺序性差，类似于邮政\n* 连接与可靠的关系\n  * 连接并不意味着可靠，可靠要通过确认、重传等机制来保证\n  * 面向无连接的可以是可靠的，例如挂号信\n\nTCP(可靠的连接)，UDP(不可靠的)\n\n|服务|例子|\n|--|--|\n面向连接的例子|\n|可靠的报文流|页面序列|\n可靠的字节流|文件下载\n不可靠的连接|IP语音\n无连接的例子|\n不可靠的数据报|垃圾邮件\n有确认的数据报|文本消息\n请求-响应|数据库查询\n\n#### 服务原语(primitives)\n\n服务在形式上是由一组接口原语（或操作）来描述的\n\n四种类型：\n\n* 请求（request）：实体请求服务做一些工作\n* 指示（Indication）：实体被通知事件的发生\n* 响应（Response）：实体对某个事件的响应\n* 确认（Confirm）：对较早请求产生响应的确认\n\n#### 分层\n\n引入中间层，为底层不同的网络技术提供统一的抽象，服务上层业务\n\n### 计算机网络参考模型\n\n#### 计算机网络的标准化\n\n**电信标准**\n\nITU(International Telecommunication Union)\n* ITU-R：无线通信\n* ITU-T：电信标准\n* ITU-D：开发\n\n**国际标准化组织：ISO**\n\n一个国际标准的形成：\n* CD（Committee Draft）\n* DIS(Draft International Standard)\n* IS(International Standard)\n\n**其他标准化组织**\n\n* ANSI\n* NIST\n* IEEE\n* OIF\n\n**互联网标准化组织**\n\n互联网标准是自发，而非政府干预的，标准文本称为 RFC(Request For Comments)\n\n#### OSI 参考模型\n\n![alt](../images/计网/3_1.jpg)\n\n![alt](../images/计网/3_3.jpg)\n\n#### TCP/IP 参考模型\n\n* 物理层\n  * 在物理线路上传输原始的二进制位\n* 数据链路层\n  * 在有差错的物理线路上提供无差错的数据传输\n  * 第一层和第二层合称为：Host-to-Network\n* Internet 层（网络层）\n  * 控制通信子网提供源点到目的点的IP分组传送\n* 运输层\n  * 提供端到端的数据传送服务，包括 TCP 和 UDP\n* 应用层\n  * 提供各种管理和应用服务功能\n\n![alt](../images/计网/3_2.jpg)\n\n#### 其他参考模型\n\nNovell NetWare 参考模型\n\n![alt](../images/计网/3_5.jpg)\n\nATM 参考模型（B-ISDN）\n\n![alt](../images/计网/3_6.jpg)\n\n**排队与统计复用**\n\n若分组的到达速率超过链路的传输速率：\n\n* 分组在端口中排队，等待链路发送\n* 当排队等待的分组超过分配给端口队列的缓存大小，缓存溢出，导致新到达的分组被丢弃\n* 端口队列将随即到达的分组进行一定程度的整形，实现了关联端口链路的统计复用\n\n**分组延时的组成**\n\n$$\nD = d_{proc} + d_{queue} + d_{trans} + d_{drop}\n$$\n\n$d_{trans}$：传输延时：\n* L: 分组长度\n* R：链路速率\n* $d_{trans} = L / R$\n\n$d_{prop}$ 传播延时：\n* $d$：链路长度\n* $s$：传播速度\n* $d_{prop}$：$d/s$\n\n**吞吐量**\n\n单位时间内发送者可以给接收者传送的比特数\n* 瞬时吞吐量：给定时刻的速率\n* 平均吞吐量：一段时间内的平均速率\n\n瓶颈链路：端到端路径(Path)上约束端到端平均吞吐量的链路(Link)\n\n\n![alt](../images/计网/3_7.jpg)\n\n**几个概念**\n\n* 报文：传输层协议的传输单位。报文由传输协议的头和应用层协议数据组成。就互联网而言，报文就是 TCP 报文段，报文段一定要封装在 IP 数据报(Datagram)中。\n* 报文段： TCP 协议端到端传输的单位。\n* IP 数据报分组：IP 协议的端到端传输单位，由 IP 头和传输层协议数据组成。\n* 分组：穿越网络层和链路层之间接口的数据单位。可以是完整的 IP 数据报或者 IP 数据报的分片(fragment)\n* 帧：链路层协议传输单元\n\n## 物理层\n\n物理层提供机械的、电气的、功能的和规程的特性，目的是启动、维护和关闭数据链路实体之间进行比特传输的物理连接。这种连接可能通过中继系统，中继系统内的传输也是在物理层。\n\n物理层的网络互联设备：中继器\n\n物理层的基本功能：在两个网络设备之间提供透明的比特流传输。\n\n物理层操作：物理连接的启动与关闭，正常数据的传输，以及维护管理。\n\n* 连接方式  （点到点，点到多点）\n* 通信方式  （单工，半双工，全双工）\n* 位传输方式（串行，并行）\n\n物理层的四个重要特性：\n* 机械特性\n* 电气特性\n* 功能特性\n* 规程特性\n\n**机械特性**\n\n主要定义物理连接的边界点，即接插装置；规定物理连接时所采用的规格、引脚的数量和排列情况\n\n**电气特性**\n\n规定传输二进制位时，线路上信号的电压高低、阻抗匹配、传输速率和距离限制。\n\n**功能特性**\n\n主要定义各条物理线路的功能。\n\n线路的功能分为四大类：\n- 数据\n- 控制\n- 定时\n- 接地\n\n\n**规程特性**\n\n主要定义各条物理线路的工作规程和时序关系。\n\n**传输介质**\n\n有导向介质\n* 铜线、光纤\n\n磁介质\n\n双绞线\n\n同轴电缆\n\n光纤\n\n无导向介质\n* 无线电波、激光、红外等\n\n**扩频技术**\n\n* 窄带通信\n  * 窄带的接受效果更加\n  * 利于提高单位 Hz 的能量\n* 扩频通信\n  * 调频扩频\n  * 直接序列扩频\n  * 超宽带(UWB)\n\n无线电传输\n\n低频率、大波长的无线电容易穿过障碍物。全方向发射。\n\n微波传输\n\n- f >100Mhz，波长在厘米级\n- 微波沿直线传播\n- 无法穿越障碍物,容易被雨水吸收\n- 多径衰落(Multipath fading)\n- 造价低\n\n红外线和毫米波\n\n- 波长在毫米级\n- 很难穿越障碍物\n- 短程通信（无需授权）\n- 遥控器等\n- 室内无线LAN\n\n光波传输\n\n- 自由空间光通信\n- 无法穿透雨或浓雾\n- 受环境影响较大\n\n**典型传输网络**\n\n* 电话网络\n  * SONET/SDH\n  * 采用TDM技术，是同步系统，由主时钟控制，时钟精度10e-9。\n  *  路径（path），链路（line），段（section）\n\n基本结构\n* 一帧包含 810 字节，每 125 us 产生一帧\n* 基本 SONET 信道称为 STS-1\n\n蜂窝无线电（Cellular Radio）\n* 单方向的寻呼系统\n* 打电话给寻呼公司，输入寻呼机号码；\n* 寻呼公司的计算机收到请求，通过线路传到高处（山顶）的天线；\n* 天线直接广播信号（本地寻呼），或传递给卫星（异地寻呼），卫星再广播。\n* 需要很小的带宽\n\n模拟蜂窝电话\n* 使用小的蜂窝\n* 在附近（不相邻）的蜂窝中重用传输频率\n* 发射功率小，设备小而便宜\n\n数字蜂窝网络\n* 第一代：模拟蜂窝电话\n* 第二代：数字蜂窝电话\n* 第三代：3G\n\n有线接入网络\n\n通信卫星\n\n电力线通信\n\n## 数据链路层\n\n### 定义和功能\n\n数据链路层协议定义了一条链路的两个结点间交换数据的单元格式，以结点发送和接收数据单元的动作。\n\n概念：\n\n结点(node)：网络中的主机(host)和路由器(router)称为结点\n\n链路(link)：   通信路径上连接相邻结点的信道称为链路\n\n点到点(point to point)：一条链路的两个相邻结点间的通信称为点到点通信, 也称为通信路径(path)的一跳(hop)\n\n端到端(end to end)\n\n从源结点(source node)到目的结点(destination node)的通信称为端到端通信，通信路径可能由多个链路组成。\n\n与端到端(end to end，E2E)相对应的概念是逐调(hop by hop，HBH) \n\n虚拟数据通路\n\n实际数据通路\n\n功能：\n\n数据链路层协议应提供的最基本功能\n- 向网络层提供服务\n- 定界与同步\n- 差错控制\n- 顺序控制\n- 流量控制\n\n提供三种服务\n* 不可靠无连接服务\n* 可靠无连接服务\n* 可靠面向连接服务\n\n#### 成帧\n\nFraming: 将比特流分成离散的帧，并计算每个帧的校验和。\n\n字符计数法\n* 在帧头中用一个域来表示整个帧的字符个数\n* 缺点：若计数出错，对本帧和后面的帧有影响\n\n带字符填充的首尾字符定界法\n* 起始字符 DLE STX，结束字符DLE ETX\n  * DLE:Data Link Escape\n  * STX:Start of Text\n  * ETX:End of Text\n* 字符填充\n* 局限于 8 位字符和 ASCII 字符传送\n\n\n带位填充的首尾标记定界法\n* 帧的起始和结束都用一个特殊的位串“01111110”，称为标记(flag)\n* “0”比特插入删除技术\n\n物理层编码违例法\n\n只适用于物理层编码有冗余的网络\n* 802 LAN：曼彻斯特编码中\n  * 高-低 / 低-高 分别表示1/0，\n  * 高-高 / 低-低  不表示数据，可以用来做定界符。\n\n#### 差错控制\n\n一般方法：接收方给发送方一个反馈（响应）\n\n出错情况\n* 帧出错，包括发送帧和相应帧\n* 帧丢失，包括发送帧和相应帧\n\n一般方案\n* 通过计时器和序号保证每帧最终交给目的网络层仅一次\n\n#### 流量控制\n\n防止发送过快，淹没接收端\n* 例如，接收端缓存溢出\n\n### 错误检测和纠正\n\n 差错出现特点\n* 随机、偶发、孤立\n* 连续突发(burst）\n 处理差错的两种基本策略\n* 使用纠错码\n* 发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，并能纠正错误。\n  * 例：前向纠错FEC (Forward Error Correcting):\n* 使用检错码\n* 发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，但不能判断哪里有错。\n\n**奇偶校验**\n最简单的例子是奇偶校验，在数据后填加一个奇偶位\n\n奇偶校验可以用来检查奇数个错误\n\n#### 纠错码\n码字(codeword）\n* 一个帧包括m个数据位，r个校验位，n = m + r，\n* 则此n比特单元称为n位码字\n海明距离（Hamming distance）\n* 两个码字之间不同的比特位数目。\n* 例如：0000000000 与0000011111的海明距离为5\n\n结论\n* 如果两个码字的海明距离为d，则需要d个单比特错就可以把一个码字转换成另一个码字；\n* 为了检查出d个错，需要使用海明距离为 d + 1 的编码；\n* 为了纠正d个错，需要使用海明距离为 2d + 1 的编码。\n\nm个信息位，r个校验位，纠正单比特错 (n=r+m)\n\n对 $2^m$ 个任何有效信息中的任何一个，有 $n$ 个与其距离为 1 的无效码字，因此有\n\n$$\n(n + 1)2^m \\le 2^n\n$$\n\n利用 $n = m + r$，得到 $m + r + 1 \\le 2^r$，给定 m，利用上式得到校正单比特误码的校验位数目下界\n\n* 码位从左边开始编号，从“1”开始；\n* 位号为2的幂的位是校验位，其余是信息位；\n* 每个校验位使得包括自己在内的一些位的奇偶值为偶数（或奇数）\n* 为看清数据位k对哪些校验位有影响，将k写成2的幂的和。\n\n汉明码的工作过程：\n* 每个码字到来前，接收方计数器清零；\n* 接收方检查每个校验位k (k = 1, 2, 4 …)的奇偶值是否正确；\n* 若第 k 位奇偶值不对，计数器加 k；\n* 所有校验位检查完后，若计数器值为0，则码字有效；若计数器值为m，则第m位出错。例：若校验位1、2、8出错，则第11位变反。\n\n#### 检错码\n\n使用纠错码传数据，效率低。适用于不可重传的场合。\n\n大多情况采用的检测码加重传。\n\n二进制多项式\n\n二进制码串表示成二进制多项式\n\n循环冗余码（CRC）\n\n* 发送方与接收方事前商定。\n* 生成多项式的高位和低位必须为1\n* 生成多项式必须比传输信息对应的多项式短\n\nCRC 的基本思想\n校验和(checksum)加载帧尾，使带校验和的帧的多项式能被 $G(x)$ 除尽，接收方接受时，用 $G(x)$ 去除它，若有余数，则传输出错。\n\n校验和计算算法\n\n设 $G(x)$ 为 $r$ 阶，在帧的末尾加 $r$ 个0，使得帧为 $m + r$ 位，相应多项式为 $x^rM(x)$。\n\n按照模 2 除法用对应$G(x)$ 的位串去除对应于 $x^rM(x)$减去余数，结果就是要传送的带检验和的多项式 $T(x)$。\n\nCRC 的检错能力：\n\n发送方发送 $T(x)$，接收方接受的$T(x) + E(x)$，$E(x) \\ne 0$。\n\n$(T(x) + E(x)) / G(x) = 0 + (E(x) / G(x))$\n\n如果$(E(x) / G(x))$的余数为0，则差错不能发现；否则可以发现。\n\n![alt](../images/计网/5_1.jpg)\n\n![alt](../images/计网/5_2.jpg)\n\n### 数据链路层协议\n#### 无约束单工协议\n\n* 工作在理想情况\n* 单工传输\n* 发送方无休止工作（要发送的信息无限多）\n* 接收方无休止工作（缓冲区无限大）\n* 通信线路（信道）不损坏或丢失信息帧\n\n工作过程\n\n* 发送程序: 取数据，构成帧，发送帧；\n* 接收程序: 等待，接收帧，送数据给高层\n\n#### 单工停等协议\n\n协议描述\n* 增加约束条件：接收方不能无休止接收。\n解决方案\n* 接收方每收到一个帧后，给发送方回送一个响应。\n工作过程\n* 发送程序：取数据，成帧，发送帧，等待响应帧\n* 接收程序：等待，接收帧，送数据给高层，回送响应帧。\n\n\n#### 有噪声信道的单工协议\n\n协议描述\n* 增加约束条件：信道（线路）有差错，信息帧可能损坏或丢失。\n\n解决方案\n* 出错重传\n  * 带来的问题\n    * 响应帧重复?发送帧头中放入序号\n* 重传触发:\n    * 超时重传 \n    * 什么时候重传?定时器\nARQ/PAR\n  * PAR (Positive Acknowledgement with Retransmission）\n  * ARQ (Automatic Repeat reQuest）\n\n### 流量控制\n\n#### 滑动窗口协议\n\n捎带确认（piggybacking）\n\n**一位滑窗协议**\n* 窗口大小：N = 1，发送序号和接收序号的取值范围：0，1；\n* 可进行数据双向传输，信息帧中可含有确认信息（piggybacking）；\n* 信息帧中包括两个序号域：发送序号和接收序号\n  （已经正确收到的帧的序号）\n存在问题\n* 能保证无差错传输，但是基于停等方式；\n* 若双方同时开始发送，则会有一半重复帧；\n* 效率低，传输时间长。\n\n\n#### 退后n帧协议\n#### 选择重传协议\n","source":"_posts/Computer-Network.md","raw":"---\ntitle: Computer Network\ndate: 2023-09-18 19:18:41\ntags: note\nkatex: true\n---\n\n## 参考书籍\n\nA.S Tanebaum (著)，严伟，潘爱民(译) 计算机网络(第五版), 2004，清华大学出版社 \n\nA.S Tanebaum，Nick Feamster, David Wetherall (著)，潘爱民(译)， 计算机网络(第六版), 2022, 清华大学出版社（彩色版，非常精美）\n\n\n## 杂项\n\ntoken ring \n\n计算机网络最核心的技术：分组(packet)。\n\ngrid computing\n\n## 计算机网络的历史与进展\n\n网络计算的基本模式\n* C/S or B/W\n* P2P\n\n服务\n* 延迟、带宽、丢失率、可靠性\n* 单播/多播， 实时/非实时\n\n链路：光纤、电缆和卫星\n* 电子、光子等作为传输介质\n* 节点：机械/电/光\n\n协议\n* TCP/IP, ATM, MPLS, SONET, Ethernet, PPP, X.25, FrameRelay, AppleTalk, IPX, SNA\n\n功能\n* 路由，差错控制、拥塞控制、服务质量(QoS)\n\n应用：FTP、HTTP \n\n\n空间距离\n* 局域网 (LAN): 以太网、令牌环、FDDI\n* 城域网 (MAN): DQDB, SMDS ,以太网\n* 广域网 (WAN): X.25, ATM, frame relay, DWDM\n\n信息类型\n* 数据网络 vs. 通信网络\n\n应用类型\n* 专用网络：飞机订票网，银行网，信用卡网\n* 通用网络：Internet\n\n使用权\n* 私有：企业网\n* 公用：电话网、Internet\n协议的所有权\n* 私有: SNA (Systems Network Architecture)\n* 开放: IP\n技术\n* 地面 vs. 卫星\n* 有线 vs. 无线\n协议\n* IP, AppleTalk, SNA\n\n计算机网络的形成\n* 多终端系统\n* 把计算机互联起来\n1970年代的计算机网络\n* X.25 分组交换网：各国的电信部门建设运行\n* 各种专用的网络体系结构：SNA，DECnet\n* Internet 的前身ARPANET进行实验运行\n1980年代的计算机网络\n* 标准化计算机网络体系结构：OSI\n* 局域网络 LAN 技术空前发展\n* 建成NSFNET，Internet 初具规模\n\n迈特卡尔夫定律(联网定律)\n\n网络价值随用户数平方成正比。未联网设备增加 $N$ 倍，效率增加 $N$ 倍。联网设备增加 $N$ 倍，效率增加 $N^2$ 倍\n\nInternet 标准化组织\n\n* Internet Engineering Task Force（IETF）：IETF负责Internet协议的研发和改进。IETF被分为很多个工作组（working groups），他们提交的文档称为RFC（Request For Comments）。\n* IRTF（Internet Research Task Force）：IRTF由一些专注于某个领域长期发展的研究小组组成。\n* Internet Architecture Board（IAB）：IAB负责定义Internet的整体框架，为IETF提供大方向上的指导。\n* The Internet Engineering Steering Group（IESG）：IESG在技术方面管理IETF的活动，负责Internet标准的制定过程。\n\n所有的标准以RFC的形式发布出来，可以从www.ietf.org免费获得，但不是所有的RFC都是Internet标准。标准形成的一般步骤是：\n* Internet Drafts\n* RFCs\n* Proposed Standard\n* Draft Standard（需要两个可以工作的实现）\n* Internet Standard（由IAB发布）\n\nDavid Clark, MIT, 1992: \n*      \"We reject: kings, presidents, and voting. \n*       We believe in: rough consensus and running code.”\n\n**Paul Baran 分组交换网络**\n\n与 Donald Watts Davies 在这个思想的发明上有争议。\n\nBaran 的设计细节：\n\n报文发送\n* 每个交换节点根据自己的路由表判断如何转发报文\n* 每个报文的转发都是独立于其他报文的\n* 交换节点不保存端节点的状态\n  * 可扩展性好\n  * 不是最有效的网络\n  * 发送不是完美的\n    * 端节点必须能容忍发送错误并从中恢复 \n分布式系统\n* 所有交换节点是平等的\n* 避免了单一节点失效问题\n* 部件可以失效，但系统不可以\n* 系统的健壮性来自于\n  * 足够的物理（硬件）冗余\n  * 适应性路由\n\n模拟实验表明：“extremely survivable networks can be built using a moderately low redundancy of connectivity level”—Paul Baran, 1964\n\n\n比较两种可靠系统的实现思路：\n\n电话系统 \n* 笨终端，聪明的网络 \n* 确保每个网络部件都是可靠的 \n  * 系统可靠性＝部件可靠性 \n  * 通过局部冗余实现部件的高可靠性 \n  * 期望每个部件都能正常工作，部件失败的可能性很低 \n* 需要人工配置的，高度控制的网络 \n\nBaran的系统 \n* 建立在简单的、不可靠部件上的可靠系统 \n* 自适应的系统 \n* 聪明的终端，可以修正传输错误 \n\nBaran 设计思想的一种实现：Internet\n\n* 连接异构的子网\n* 提供两种基本功能\n  * 全球唯一的地址\n  * 报文通过动态路由从源节点发送到目的节点\n\nsimple, flexible, scalable, and robust\n\n分组交换的特点：\n\n**简单性**\n\n* 每个报文携带各自的地址信息\n* 一个路由表可以为所有的流量服务\n* 可以适应爆炸性的增长\n  * 越简单越不容易出错 \n  * 越简单越容易增长 \n  * 对基本网络功能的要求少，可以在其上建立多种类型的网络 \n\n**灵活性**\n\nEverything over IP\n\nIP over Everything\n\n**可扩展性**\n\n可扩展的系统必须能对付\n* 端系统的增加\n* 流量的增加\n* 网络规模的增长\n  * 大的路由表\n  * 路由频繁的变化\n\n边缘论：End-to-End Argument\n\n路由器只负责传输，复杂的功能（纠错，重传）都由终端自行解决\n\n**健壮性**\n* 动态路由具有自适应的特性\n  * 动态路由和报文转发相辅相成\n  * 周期性路由更新\n  * 默认: 现有的部件会失效，会有新的部件加入，认为变化是正常的\n* 牺牲一定的带宽的利用率，提高健壮性(报文头开销，更新开销) \n\n\n## 数据通信基本原理\n\n香农定理：\n带宽为 $H$ 赫兹，信噪比为 $S/N$ 的任意信道的最大数据传输率为 $H\\log_2(1 + S/N) (bps)$\n* 此式是利用信息论得出的，具有普遍意义\n* 与信号电平级数、采样速度无关\n* 此式仅是上限，实践中难以达到\n\n曼彻斯特码（Manchester），也称相位编码\n* 原理：每一位中间都有一个跳变，从低跳到高表示“0”，从高跳到低表示“1”。\n* 优点：克服了NRZ码的不足。每位中间的跳变即可作为数据，又可作为时钟，能够自同步。\t\n\n差分曼彻斯特码（Differential Manchester）\n* 原理：每一位中间都有一个跳变，每位开始时有跳变表示“0”，无跳变表示“1”。位中间跳变表示时钟，位前跳变表示数据。\n* 优点：时钟、数据分离，便于提取。\n\n## 网络体系结构\n\n### 计算机网络的构成\n\n**资源子网**\n* 服务器（Server）\n* 客户机（Client）\n\nC/S -> B/W -> P2P\n\n**通信子网**\n* 通信线路（通道）\n* 网络互连设备（路由器、交换机、集线器等）\n\n#### 基本结构\n\n**点到点通道**\n* 一条线路连接两台网络互联设备\n* 一般两台计算机的连接要经过多台互联设备\n* 星形、环形、树形、全连结、交叉环、不规则图\n* 关键技术：路由选择（Routing）\n\n**广播网络**\n* 总线，环\n* 组播网络（Multicast Networks）：把成员分组\n* 单播网络（Unicast Networks）\n  * 点到点连接\n* 关键技术：通道分配\n  * 静态分配：分时间片\n    * 控制简单，通道利用率低\n  * 动态分配各站点动态使用通道\n    * 控制复杂，通道利用度高\n    * 通道分配方法：\n      * 集中式：只有一个仲裁机构\n      * 分布式：各站点均有仲裁机构\n\n* PAN\n* LAN\n* MAN\n* WAN\n* internet，指一种技术(Internet，指实体的网络)\n* Interplanetary Internet\n\n### 计算机网络体系结构\n\n对计算机网络及其部件所完成的功能的比较精确的定义，即从功能的角度描述计算机网络的结构，是层次模型和协议的集合。\n\n注意：计算机网络体系结构仅仅定义了网络及其部件通过协议应完成的功能，不定义协议的实现细节和各层协议之间的接口关系。\n\n协议分层的优点：易于协议的设计、分析、实现和调试\n\n计算机网络的功能：\n* 基本功能：为地理位置不同的计算机用户提供访问通路\n* 具体化为：\n  * 连接源节点和目的节点的物理传输线路，可以经过中间节点\n  * 每条线路两端的结点利用波形进行二进制通信\n  * 无差错的信息传送\n  * 多个用户共享一条物理线路\n  * 按照地址信息，进行路由选择\n  * 信息缓存与流量控制\n  * 会话控制\n  * 满足各种用户、各种应用的访问要求\n\n\n#### 网络协议\n\n层次结构的计算计网络功能中最重要的功能是通信功能，这种通信功能主要涉及同层中通信双方的相互作用，位于不同计算机上进行对话的第N层通信各方可分别看成是一种进程，称为**对等进程（同等进程）**\n\n**协议**\n\n计算机网络同等层次中，通信双方进行信息交换时必须遵守的规则。\n\n**协议栈**\n\n一个特定系统所使用的一组协议统称为协议栈。\n\n**接口**\n\n相邻层之间有一个接口（Interface），它定义了下层向上层提供的原语操作与服务\n\n#### 层、协议和接口\n\n**协议特性**\n\n* 不知道上下层的内部结构\n* 独立完成某种功能\n* 为上层提供服务\n* 使用下层提供的服务\n\n#### 服务分类\n\n* 面向连接的服务\n  * 当使用服务传输数据时，首先建立连接，然后使用该链接传送数据，使用完后，关闭连接。\n  * 特点：顺序性好，类似于电话\n* 面向无连接的服务\n  * 直接使用服务传送数据，每个分组独立进行路由选择。\n  * 特点：顺序性差，类似于邮政\n* 连接与可靠的关系\n  * 连接并不意味着可靠，可靠要通过确认、重传等机制来保证\n  * 面向无连接的可以是可靠的，例如挂号信\n\nTCP(可靠的连接)，UDP(不可靠的)\n\n|服务|例子|\n|--|--|\n面向连接的例子|\n|可靠的报文流|页面序列|\n可靠的字节流|文件下载\n不可靠的连接|IP语音\n无连接的例子|\n不可靠的数据报|垃圾邮件\n有确认的数据报|文本消息\n请求-响应|数据库查询\n\n#### 服务原语(primitives)\n\n服务在形式上是由一组接口原语（或操作）来描述的\n\n四种类型：\n\n* 请求（request）：实体请求服务做一些工作\n* 指示（Indication）：实体被通知事件的发生\n* 响应（Response）：实体对某个事件的响应\n* 确认（Confirm）：对较早请求产生响应的确认\n\n#### 分层\n\n引入中间层，为底层不同的网络技术提供统一的抽象，服务上层业务\n\n### 计算机网络参考模型\n\n#### 计算机网络的标准化\n\n**电信标准**\n\nITU(International Telecommunication Union)\n* ITU-R：无线通信\n* ITU-T：电信标准\n* ITU-D：开发\n\n**国际标准化组织：ISO**\n\n一个国际标准的形成：\n* CD（Committee Draft）\n* DIS(Draft International Standard)\n* IS(International Standard)\n\n**其他标准化组织**\n\n* ANSI\n* NIST\n* IEEE\n* OIF\n\n**互联网标准化组织**\n\n互联网标准是自发，而非政府干预的，标准文本称为 RFC(Request For Comments)\n\n#### OSI 参考模型\n\n![alt](../images/计网/3_1.jpg)\n\n![alt](../images/计网/3_3.jpg)\n\n#### TCP/IP 参考模型\n\n* 物理层\n  * 在物理线路上传输原始的二进制位\n* 数据链路层\n  * 在有差错的物理线路上提供无差错的数据传输\n  * 第一层和第二层合称为：Host-to-Network\n* Internet 层（网络层）\n  * 控制通信子网提供源点到目的点的IP分组传送\n* 运输层\n  * 提供端到端的数据传送服务，包括 TCP 和 UDP\n* 应用层\n  * 提供各种管理和应用服务功能\n\n![alt](../images/计网/3_2.jpg)\n\n#### 其他参考模型\n\nNovell NetWare 参考模型\n\n![alt](../images/计网/3_5.jpg)\n\nATM 参考模型（B-ISDN）\n\n![alt](../images/计网/3_6.jpg)\n\n**排队与统计复用**\n\n若分组的到达速率超过链路的传输速率：\n\n* 分组在端口中排队，等待链路发送\n* 当排队等待的分组超过分配给端口队列的缓存大小，缓存溢出，导致新到达的分组被丢弃\n* 端口队列将随即到达的分组进行一定程度的整形，实现了关联端口链路的统计复用\n\n**分组延时的组成**\n\n$$\nD = d_{proc} + d_{queue} + d_{trans} + d_{drop}\n$$\n\n$d_{trans}$：传输延时：\n* L: 分组长度\n* R：链路速率\n* $d_{trans} = L / R$\n\n$d_{prop}$ 传播延时：\n* $d$：链路长度\n* $s$：传播速度\n* $d_{prop}$：$d/s$\n\n**吞吐量**\n\n单位时间内发送者可以给接收者传送的比特数\n* 瞬时吞吐量：给定时刻的速率\n* 平均吞吐量：一段时间内的平均速率\n\n瓶颈链路：端到端路径(Path)上约束端到端平均吞吐量的链路(Link)\n\n\n![alt](../images/计网/3_7.jpg)\n\n**几个概念**\n\n* 报文：传输层协议的传输单位。报文由传输协议的头和应用层协议数据组成。就互联网而言，报文就是 TCP 报文段，报文段一定要封装在 IP 数据报(Datagram)中。\n* 报文段： TCP 协议端到端传输的单位。\n* IP 数据报分组：IP 协议的端到端传输单位，由 IP 头和传输层协议数据组成。\n* 分组：穿越网络层和链路层之间接口的数据单位。可以是完整的 IP 数据报或者 IP 数据报的分片(fragment)\n* 帧：链路层协议传输单元\n\n## 物理层\n\n物理层提供机械的、电气的、功能的和规程的特性，目的是启动、维护和关闭数据链路实体之间进行比特传输的物理连接。这种连接可能通过中继系统，中继系统内的传输也是在物理层。\n\n物理层的网络互联设备：中继器\n\n物理层的基本功能：在两个网络设备之间提供透明的比特流传输。\n\n物理层操作：物理连接的启动与关闭，正常数据的传输，以及维护管理。\n\n* 连接方式  （点到点，点到多点）\n* 通信方式  （单工，半双工，全双工）\n* 位传输方式（串行，并行）\n\n物理层的四个重要特性：\n* 机械特性\n* 电气特性\n* 功能特性\n* 规程特性\n\n**机械特性**\n\n主要定义物理连接的边界点，即接插装置；规定物理连接时所采用的规格、引脚的数量和排列情况\n\n**电气特性**\n\n规定传输二进制位时，线路上信号的电压高低、阻抗匹配、传输速率和距离限制。\n\n**功能特性**\n\n主要定义各条物理线路的功能。\n\n线路的功能分为四大类：\n- 数据\n- 控制\n- 定时\n- 接地\n\n\n**规程特性**\n\n主要定义各条物理线路的工作规程和时序关系。\n\n**传输介质**\n\n有导向介质\n* 铜线、光纤\n\n磁介质\n\n双绞线\n\n同轴电缆\n\n光纤\n\n无导向介质\n* 无线电波、激光、红外等\n\n**扩频技术**\n\n* 窄带通信\n  * 窄带的接受效果更加\n  * 利于提高单位 Hz 的能量\n* 扩频通信\n  * 调频扩频\n  * 直接序列扩频\n  * 超宽带(UWB)\n\n无线电传输\n\n低频率、大波长的无线电容易穿过障碍物。全方向发射。\n\n微波传输\n\n- f >100Mhz，波长在厘米级\n- 微波沿直线传播\n- 无法穿越障碍物,容易被雨水吸收\n- 多径衰落(Multipath fading)\n- 造价低\n\n红外线和毫米波\n\n- 波长在毫米级\n- 很难穿越障碍物\n- 短程通信（无需授权）\n- 遥控器等\n- 室内无线LAN\n\n光波传输\n\n- 自由空间光通信\n- 无法穿透雨或浓雾\n- 受环境影响较大\n\n**典型传输网络**\n\n* 电话网络\n  * SONET/SDH\n  * 采用TDM技术，是同步系统，由主时钟控制，时钟精度10e-9。\n  *  路径（path），链路（line），段（section）\n\n基本结构\n* 一帧包含 810 字节，每 125 us 产生一帧\n* 基本 SONET 信道称为 STS-1\n\n蜂窝无线电（Cellular Radio）\n* 单方向的寻呼系统\n* 打电话给寻呼公司，输入寻呼机号码；\n* 寻呼公司的计算机收到请求，通过线路传到高处（山顶）的天线；\n* 天线直接广播信号（本地寻呼），或传递给卫星（异地寻呼），卫星再广播。\n* 需要很小的带宽\n\n模拟蜂窝电话\n* 使用小的蜂窝\n* 在附近（不相邻）的蜂窝中重用传输频率\n* 发射功率小，设备小而便宜\n\n数字蜂窝网络\n* 第一代：模拟蜂窝电话\n* 第二代：数字蜂窝电话\n* 第三代：3G\n\n有线接入网络\n\n通信卫星\n\n电力线通信\n\n## 数据链路层\n\n### 定义和功能\n\n数据链路层协议定义了一条链路的两个结点间交换数据的单元格式，以结点发送和接收数据单元的动作。\n\n概念：\n\n结点(node)：网络中的主机(host)和路由器(router)称为结点\n\n链路(link)：   通信路径上连接相邻结点的信道称为链路\n\n点到点(point to point)：一条链路的两个相邻结点间的通信称为点到点通信, 也称为通信路径(path)的一跳(hop)\n\n端到端(end to end)\n\n从源结点(source node)到目的结点(destination node)的通信称为端到端通信，通信路径可能由多个链路组成。\n\n与端到端(end to end，E2E)相对应的概念是逐调(hop by hop，HBH) \n\n虚拟数据通路\n\n实际数据通路\n\n功能：\n\n数据链路层协议应提供的最基本功能\n- 向网络层提供服务\n- 定界与同步\n- 差错控制\n- 顺序控制\n- 流量控制\n\n提供三种服务\n* 不可靠无连接服务\n* 可靠无连接服务\n* 可靠面向连接服务\n\n#### 成帧\n\nFraming: 将比特流分成离散的帧，并计算每个帧的校验和。\n\n字符计数法\n* 在帧头中用一个域来表示整个帧的字符个数\n* 缺点：若计数出错，对本帧和后面的帧有影响\n\n带字符填充的首尾字符定界法\n* 起始字符 DLE STX，结束字符DLE ETX\n  * DLE:Data Link Escape\n  * STX:Start of Text\n  * ETX:End of Text\n* 字符填充\n* 局限于 8 位字符和 ASCII 字符传送\n\n\n带位填充的首尾标记定界法\n* 帧的起始和结束都用一个特殊的位串“01111110”，称为标记(flag)\n* “0”比特插入删除技术\n\n物理层编码违例法\n\n只适用于物理层编码有冗余的网络\n* 802 LAN：曼彻斯特编码中\n  * 高-低 / 低-高 分别表示1/0，\n  * 高-高 / 低-低  不表示数据，可以用来做定界符。\n\n#### 差错控制\n\n一般方法：接收方给发送方一个反馈（响应）\n\n出错情况\n* 帧出错，包括发送帧和相应帧\n* 帧丢失，包括发送帧和相应帧\n\n一般方案\n* 通过计时器和序号保证每帧最终交给目的网络层仅一次\n\n#### 流量控制\n\n防止发送过快，淹没接收端\n* 例如，接收端缓存溢出\n\n### 错误检测和纠正\n\n 差错出现特点\n* 随机、偶发、孤立\n* 连续突发(burst）\n 处理差错的两种基本策略\n* 使用纠错码\n* 发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，并能纠正错误。\n  * 例：前向纠错FEC (Forward Error Correcting):\n* 使用检错码\n* 发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，但不能判断哪里有错。\n\n**奇偶校验**\n最简单的例子是奇偶校验，在数据后填加一个奇偶位\n\n奇偶校验可以用来检查奇数个错误\n\n#### 纠错码\n码字(codeword）\n* 一个帧包括m个数据位，r个校验位，n = m + r，\n* 则此n比特单元称为n位码字\n海明距离（Hamming distance）\n* 两个码字之间不同的比特位数目。\n* 例如：0000000000 与0000011111的海明距离为5\n\n结论\n* 如果两个码字的海明距离为d，则需要d个单比特错就可以把一个码字转换成另一个码字；\n* 为了检查出d个错，需要使用海明距离为 d + 1 的编码；\n* 为了纠正d个错，需要使用海明距离为 2d + 1 的编码。\n\nm个信息位，r个校验位，纠正单比特错 (n=r+m)\n\n对 $2^m$ 个任何有效信息中的任何一个，有 $n$ 个与其距离为 1 的无效码字，因此有\n\n$$\n(n + 1)2^m \\le 2^n\n$$\n\n利用 $n = m + r$，得到 $m + r + 1 \\le 2^r$，给定 m，利用上式得到校正单比特误码的校验位数目下界\n\n* 码位从左边开始编号，从“1”开始；\n* 位号为2的幂的位是校验位，其余是信息位；\n* 每个校验位使得包括自己在内的一些位的奇偶值为偶数（或奇数）\n* 为看清数据位k对哪些校验位有影响，将k写成2的幂的和。\n\n汉明码的工作过程：\n* 每个码字到来前，接收方计数器清零；\n* 接收方检查每个校验位k (k = 1, 2, 4 …)的奇偶值是否正确；\n* 若第 k 位奇偶值不对，计数器加 k；\n* 所有校验位检查完后，若计数器值为0，则码字有效；若计数器值为m，则第m位出错。例：若校验位1、2、8出错，则第11位变反。\n\n#### 检错码\n\n使用纠错码传数据，效率低。适用于不可重传的场合。\n\n大多情况采用的检测码加重传。\n\n二进制多项式\n\n二进制码串表示成二进制多项式\n\n循环冗余码（CRC）\n\n* 发送方与接收方事前商定。\n* 生成多项式的高位和低位必须为1\n* 生成多项式必须比传输信息对应的多项式短\n\nCRC 的基本思想\n校验和(checksum)加载帧尾，使带校验和的帧的多项式能被 $G(x)$ 除尽，接收方接受时，用 $G(x)$ 去除它，若有余数，则传输出错。\n\n校验和计算算法\n\n设 $G(x)$ 为 $r$ 阶，在帧的末尾加 $r$ 个0，使得帧为 $m + r$ 位，相应多项式为 $x^rM(x)$。\n\n按照模 2 除法用对应$G(x)$ 的位串去除对应于 $x^rM(x)$减去余数，结果就是要传送的带检验和的多项式 $T(x)$。\n\nCRC 的检错能力：\n\n发送方发送 $T(x)$，接收方接受的$T(x) + E(x)$，$E(x) \\ne 0$。\n\n$(T(x) + E(x)) / G(x) = 0 + (E(x) / G(x))$\n\n如果$(E(x) / G(x))$的余数为0，则差错不能发现；否则可以发现。\n\n![alt](../images/计网/5_1.jpg)\n\n![alt](../images/计网/5_2.jpg)\n\n### 数据链路层协议\n#### 无约束单工协议\n\n* 工作在理想情况\n* 单工传输\n* 发送方无休止工作（要发送的信息无限多）\n* 接收方无休止工作（缓冲区无限大）\n* 通信线路（信道）不损坏或丢失信息帧\n\n工作过程\n\n* 发送程序: 取数据，构成帧，发送帧；\n* 接收程序: 等待，接收帧，送数据给高层\n\n#### 单工停等协议\n\n协议描述\n* 增加约束条件：接收方不能无休止接收。\n解决方案\n* 接收方每收到一个帧后，给发送方回送一个响应。\n工作过程\n* 发送程序：取数据，成帧，发送帧，等待响应帧\n* 接收程序：等待，接收帧，送数据给高层，回送响应帧。\n\n\n#### 有噪声信道的单工协议\n\n协议描述\n* 增加约束条件：信道（线路）有差错，信息帧可能损坏或丢失。\n\n解决方案\n* 出错重传\n  * 带来的问题\n    * 响应帧重复?发送帧头中放入序号\n* 重传触发:\n    * 超时重传 \n    * 什么时候重传?定时器\nARQ/PAR\n  * PAR (Positive Acknowledgement with Retransmission）\n  * ARQ (Automatic Repeat reQuest）\n\n### 流量控制\n\n#### 滑动窗口协议\n\n捎带确认（piggybacking）\n\n**一位滑窗协议**\n* 窗口大小：N = 1，发送序号和接收序号的取值范围：0，1；\n* 可进行数据双向传输，信息帧中可含有确认信息（piggybacking）；\n* 信息帧中包括两个序号域：发送序号和接收序号\n  （已经正确收到的帧的序号）\n存在问题\n* 能保证无差错传输，但是基于停等方式；\n* 若双方同时开始发送，则会有一半重复帧；\n* 效率低，传输时间长。\n\n\n#### 退后n帧协议\n#### 选择重传协议\n","slug":"Computer-Network","published":1,"updated":"2024-03-19T06:01:16.156Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhr0003rsug8v0ha8dw","content":"<h2 id=\"参考书籍\"><a href=\"#参考书籍\" class=\"headerlink\" title=\"参考书籍\"></a>参考书籍</h2><p>A.S Tanebaum (著)，严伟，潘爱民(译) 计算机网络(第五版), 2004，清华大学出版社 </p>\n<p>A.S Tanebaum，Nick Feamster, David Wetherall (著)，潘爱民(译)， 计算机网络(第六版), 2022, 清华大学出版社（彩色版，非常精美）</p>\n<h2 id=\"杂项\"><a href=\"#杂项\" class=\"headerlink\" title=\"杂项\"></a>杂项</h2><p>token ring </p>\n<p>计算机网络最核心的技术：分组(packet)。</p>\n<p>grid computing</p>\n<h2 id=\"计算机网络的历史与进展\"><a href=\"#计算机网络的历史与进展\" class=\"headerlink\" title=\"计算机网络的历史与进展\"></a>计算机网络的历史与进展</h2><p>网络计算的基本模式</p>\n<ul>\n<li>C&#x2F;S or B&#x2F;W</li>\n<li>P2P</li>\n</ul>\n<p>服务</p>\n<ul>\n<li>延迟、带宽、丢失率、可靠性</li>\n<li>单播&#x2F;多播， 实时&#x2F;非实时</li>\n</ul>\n<p>链路：光纤、电缆和卫星</p>\n<ul>\n<li>电子、光子等作为传输介质</li>\n<li>节点：机械&#x2F;电&#x2F;光</li>\n</ul>\n<p>协议</p>\n<ul>\n<li>TCP&#x2F;IP, ATM, MPLS, SONET, Ethernet, PPP, X.25, FrameRelay, AppleTalk, IPX, SNA</li>\n</ul>\n<p>功能</p>\n<ul>\n<li>路由，差错控制、拥塞控制、服务质量(QoS)</li>\n</ul>\n<p>应用：FTP、HTTP </p>\n<p>空间距离</p>\n<ul>\n<li>局域网 (LAN): 以太网、令牌环、FDDI</li>\n<li>城域网 (MAN): DQDB, SMDS ,以太网</li>\n<li>广域网 (WAN): X.25, ATM, frame relay, DWDM</li>\n</ul>\n<p>信息类型</p>\n<ul>\n<li>数据网络 vs. 通信网络</li>\n</ul>\n<p>应用类型</p>\n<ul>\n<li>专用网络：飞机订票网，银行网，信用卡网</li>\n<li>通用网络：Internet</li>\n</ul>\n<p>使用权</p>\n<ul>\n<li>私有：企业网</li>\n<li>公用：电话网、Internet<br>协议的所有权</li>\n<li>私有: SNA (Systems Network Architecture)</li>\n<li>开放: IP<br>技术</li>\n<li>地面 vs. 卫星</li>\n<li>有线 vs. 无线<br>协议</li>\n<li>IP, AppleTalk, SNA</li>\n</ul>\n<p>计算机网络的形成</p>\n<ul>\n<li>多终端系统</li>\n<li>把计算机互联起来<br>1970年代的计算机网络</li>\n<li>X.25 分组交换网：各国的电信部门建设运行</li>\n<li>各种专用的网络体系结构：SNA，DECnet</li>\n<li>Internet 的前身ARPANET进行实验运行<br>1980年代的计算机网络</li>\n<li>标准化计算机网络体系结构：OSI</li>\n<li>局域网络 LAN 技术空前发展</li>\n<li>建成NSFNET，Internet 初具规模</li>\n</ul>\n<p>迈特卡尔夫定律(联网定律)</p>\n<p>网络价值随用户数平方成正比。未联网设备增加 $N$ 倍，效率增加 $N$ 倍。联网设备增加 $N$ 倍，效率增加 $N^2$ 倍</p>\n<p>Internet 标准化组织</p>\n<ul>\n<li>Internet Engineering Task Force（IETF）：IETF负责Internet协议的研发和改进。IETF被分为很多个工作组（working groups），他们提交的文档称为RFC（Request For Comments）。</li>\n<li>IRTF（Internet Research Task Force）：IRTF由一些专注于某个领域长期发展的研究小组组成。</li>\n<li>Internet Architecture Board（IAB）：IAB负责定义Internet的整体框架，为IETF提供大方向上的指导。</li>\n<li>The Internet Engineering Steering Group（IESG）：IESG在技术方面管理IETF的活动，负责Internet标准的制定过程。</li>\n</ul>\n<p>所有的标准以RFC的形式发布出来，可以从<a href=\"http://www.ietf.org免费获得，但不是所有的RFC都是Internet标准。标准形成的一般步骤是：\">www.ietf.org免费获得，但不是所有的RFC都是Internet标准。标准形成的一般步骤是：</a></p>\n<ul>\n<li>Internet Drafts</li>\n<li>RFCs</li>\n<li>Proposed Standard</li>\n<li>Draft Standard（需要两个可以工作的实现）</li>\n<li>Internet Standard（由IAB发布）</li>\n</ul>\n<p>David Clark, MIT, 1992: </p>\n<ul>\n<li><pre><code> &quot;We reject: kings, presidents, and voting. \n</code></pre>\n</li>\n<li><pre><code>  We believe in: rough consensus and running code.”\n</code></pre>\n</li>\n</ul>\n<p><strong>Paul Baran 分组交换网络</strong></p>\n<p>与 Donald Watts Davies 在这个思想的发明上有争议。</p>\n<p>Baran 的设计细节：</p>\n<p>报文发送</p>\n<ul>\n<li>每个交换节点根据自己的路由表判断如何转发报文</li>\n<li>每个报文的转发都是独立于其他报文的</li>\n<li>交换节点不保存端节点的状态<ul>\n<li>可扩展性好</li>\n<li>不是最有效的网络</li>\n<li>发送不是完美的<ul>\n<li>端节点必须能容忍发送错误并从中恢复<br>分布式系统</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>所有交换节点是平等的</li>\n<li>避免了单一节点失效问题</li>\n<li>部件可以失效，但系统不可以</li>\n<li>系统的健壮性来自于<ul>\n<li>足够的物理（硬件）冗余</li>\n<li>适应性路由</li>\n</ul>\n</li>\n</ul>\n<p>模拟实验表明：“extremely survivable networks can be built using a moderately low redundancy of connectivity level”—Paul Baran, 1964</p>\n<p>比较两种可靠系统的实现思路：</p>\n<p>电话系统 </p>\n<ul>\n<li>笨终端，聪明的网络 </li>\n<li>确保每个网络部件都是可靠的 <ul>\n<li>系统可靠性＝部件可靠性 </li>\n<li>通过局部冗余实现部件的高可靠性 </li>\n<li>期望每个部件都能正常工作，部件失败的可能性很低</li>\n</ul>\n</li>\n<li>需要人工配置的，高度控制的网络</li>\n</ul>\n<p>Baran的系统 </p>\n<ul>\n<li>建立在简单的、不可靠部件上的可靠系统 </li>\n<li>自适应的系统 </li>\n<li>聪明的终端，可以修正传输错误</li>\n</ul>\n<p>Baran 设计思想的一种实现：Internet</p>\n<ul>\n<li>连接异构的子网</li>\n<li>提供两种基本功能<ul>\n<li>全球唯一的地址</li>\n<li>报文通过动态路由从源节点发送到目的节点</li>\n</ul>\n</li>\n</ul>\n<p>simple, flexible, scalable, and robust</p>\n<p>分组交换的特点：</p>\n<p><strong>简单性</strong></p>\n<ul>\n<li>每个报文携带各自的地址信息</li>\n<li>一个路由表可以为所有的流量服务</li>\n<li>可以适应爆炸性的增长<ul>\n<li>越简单越不容易出错 </li>\n<li>越简单越容易增长 </li>\n<li>对基本网络功能的要求少，可以在其上建立多种类型的网络</li>\n</ul>\n</li>\n</ul>\n<p><strong>灵活性</strong></p>\n<p>Everything over IP</p>\n<p>IP over Everything</p>\n<p><strong>可扩展性</strong></p>\n<p>可扩展的系统必须能对付</p>\n<ul>\n<li>端系统的增加</li>\n<li>流量的增加</li>\n<li>网络规模的增长<ul>\n<li>大的路由表</li>\n<li>路由频繁的变化</li>\n</ul>\n</li>\n</ul>\n<p>边缘论：End-to-End Argument</p>\n<p>路由器只负责传输，复杂的功能（纠错，重传）都由终端自行解决</p>\n<p><strong>健壮性</strong></p>\n<ul>\n<li>动态路由具有自适应的特性<ul>\n<li>动态路由和报文转发相辅相成</li>\n<li>周期性路由更新</li>\n<li>默认: 现有的部件会失效，会有新的部件加入，认为变化是正常的</li>\n</ul>\n</li>\n<li>牺牲一定的带宽的利用率，提高健壮性(报文头开销，更新开销)</li>\n</ul>\n<h2 id=\"数据通信基本原理\"><a href=\"#数据通信基本原理\" class=\"headerlink\" title=\"数据通信基本原理\"></a>数据通信基本原理</h2><p>香农定理：<br>带宽为 $H$ 赫兹，信噪比为 $S&#x2F;N$ 的任意信道的最大数据传输率为 $H\\log_2(1 + S&#x2F;N) (bps)$</p>\n<ul>\n<li>此式是利用信息论得出的，具有普遍意义</li>\n<li>与信号电平级数、采样速度无关</li>\n<li>此式仅是上限，实践中难以达到</li>\n</ul>\n<p>曼彻斯特码（Manchester），也称相位编码</p>\n<ul>\n<li>原理：每一位中间都有一个跳变，从低跳到高表示“0”，从高跳到低表示“1”。</li>\n<li>优点：克服了NRZ码的不足。每位中间的跳变即可作为数据，又可作为时钟，能够自同步。</li>\n</ul>\n<p>\t</p>\n<p>差分曼彻斯特码（Differential Manchester）</p>\n<ul>\n<li>原理：每一位中间都有一个跳变，每位开始时有跳变表示“0”，无跳变表示“1”。位中间跳变表示时钟，位前跳变表示数据。</li>\n<li>优点：时钟、数据分离，便于提取。</li>\n</ul>\n<h2 id=\"网络体系结构\"><a href=\"#网络体系结构\" class=\"headerlink\" title=\"网络体系结构\"></a>网络体系结构</h2><h3 id=\"计算机网络的构成\"><a href=\"#计算机网络的构成\" class=\"headerlink\" title=\"计算机网络的构成\"></a>计算机网络的构成</h3><p><strong>资源子网</strong></p>\n<ul>\n<li>服务器（Server）</li>\n<li>客户机（Client）</li>\n</ul>\n<p>C&#x2F;S -&gt; B&#x2F;W -&gt; P2P</p>\n<p><strong>通信子网</strong></p>\n<ul>\n<li>通信线路（通道）</li>\n<li>网络互连设备（路由器、交换机、集线器等）</li>\n</ul>\n<h4 id=\"基本结构\"><a href=\"#基本结构\" class=\"headerlink\" title=\"基本结构\"></a>基本结构</h4><p><strong>点到点通道</strong></p>\n<ul>\n<li>一条线路连接两台网络互联设备</li>\n<li>一般两台计算机的连接要经过多台互联设备</li>\n<li>星形、环形、树形、全连结、交叉环、不规则图</li>\n<li>关键技术：路由选择（Routing）</li>\n</ul>\n<p><strong>广播网络</strong></p>\n<ul>\n<li><p>总线，环</p>\n</li>\n<li><p>组播网络（Multicast Networks）：把成员分组</p>\n</li>\n<li><p>单播网络（Unicast Networks）</p>\n<ul>\n<li>点到点连接</li>\n</ul>\n</li>\n<li><p>关键技术：通道分配</p>\n<ul>\n<li>静态分配：分时间片<ul>\n<li>控制简单，通道利用率低</li>\n</ul>\n</li>\n<li>动态分配各站点动态使用通道<ul>\n<li>控制复杂，通道利用度高</li>\n<li>通道分配方法：<ul>\n<li>集中式：只有一个仲裁机构</li>\n<li>分布式：各站点均有仲裁机构</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>PAN</p>\n</li>\n<li><p>LAN</p>\n</li>\n<li><p>MAN</p>\n</li>\n<li><p>WAN</p>\n</li>\n<li><p>internet，指一种技术(Internet，指实体的网络)</p>\n</li>\n<li><p>Interplanetary Internet</p>\n</li>\n</ul>\n<h3 id=\"计算机网络体系结构\"><a href=\"#计算机网络体系结构\" class=\"headerlink\" title=\"计算机网络体系结构\"></a>计算机网络体系结构</h3><p>对计算机网络及其部件所完成的功能的比较精确的定义，即从功能的角度描述计算机网络的结构，是层次模型和协议的集合。</p>\n<p>注意：计算机网络体系结构仅仅定义了网络及其部件通过协议应完成的功能，不定义协议的实现细节和各层协议之间的接口关系。</p>\n<p>协议分层的优点：易于协议的设计、分析、实现和调试</p>\n<p>计算机网络的功能：</p>\n<ul>\n<li>基本功能：为地理位置不同的计算机用户提供访问通路</li>\n<li>具体化为：<ul>\n<li>连接源节点和目的节点的物理传输线路，可以经过中间节点</li>\n<li>每条线路两端的结点利用波形进行二进制通信</li>\n<li>无差错的信息传送</li>\n<li>多个用户共享一条物理线路</li>\n<li>按照地址信息，进行路由选择</li>\n<li>信息缓存与流量控制</li>\n<li>会话控制</li>\n<li>满足各种用户、各种应用的访问要求</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"网络协议\"><a href=\"#网络协议\" class=\"headerlink\" title=\"网络协议\"></a>网络协议</h4><p>层次结构的计算计网络功能中最重要的功能是通信功能，这种通信功能主要涉及同层中通信双方的相互作用，位于不同计算机上进行对话的第N层通信各方可分别看成是一种进程，称为<strong>对等进程（同等进程）</strong></p>\n<p><strong>协议</strong></p>\n<p>计算机网络同等层次中，通信双方进行信息交换时必须遵守的规则。</p>\n<p><strong>协议栈</strong></p>\n<p>一个特定系统所使用的一组协议统称为协议栈。</p>\n<p><strong>接口</strong></p>\n<p>相邻层之间有一个接口（Interface），它定义了下层向上层提供的原语操作与服务</p>\n<h4 id=\"层、协议和接口\"><a href=\"#层、协议和接口\" class=\"headerlink\" title=\"层、协议和接口\"></a>层、协议和接口</h4><p><strong>协议特性</strong></p>\n<ul>\n<li>不知道上下层的内部结构</li>\n<li>独立完成某种功能</li>\n<li>为上层提供服务</li>\n<li>使用下层提供的服务</li>\n</ul>\n<h4 id=\"服务分类\"><a href=\"#服务分类\" class=\"headerlink\" title=\"服务分类\"></a>服务分类</h4><ul>\n<li>面向连接的服务<ul>\n<li>当使用服务传输数据时，首先建立连接，然后使用该链接传送数据，使用完后，关闭连接。</li>\n<li>特点：顺序性好，类似于电话</li>\n</ul>\n</li>\n<li>面向无连接的服务<ul>\n<li>直接使用服务传送数据，每个分组独立进行路由选择。</li>\n<li>特点：顺序性差，类似于邮政</li>\n</ul>\n</li>\n<li>连接与可靠的关系<ul>\n<li>连接并不意味着可靠，可靠要通过确认、重传等机制来保证</li>\n<li>面向无连接的可以是可靠的，例如挂号信</li>\n</ul>\n</li>\n</ul>\n<p>TCP(可靠的连接)，UDP(不可靠的)</p>\n<table>\n<thead>\n<tr>\n<th>服务</th>\n<th>例子</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>面向连接的例子</td>\n<td></td>\n</tr>\n<tr>\n<td>可靠的报文流</td>\n<td>页面序列</td>\n</tr>\n<tr>\n<td>可靠的字节流</td>\n<td>文件下载</td>\n</tr>\n<tr>\n<td>不可靠的连接</td>\n<td>IP语音</td>\n</tr>\n<tr>\n<td>无连接的例子</td>\n<td></td>\n</tr>\n<tr>\n<td>不可靠的数据报</td>\n<td>垃圾邮件</td>\n</tr>\n<tr>\n<td>有确认的数据报</td>\n<td>文本消息</td>\n</tr>\n<tr>\n<td>请求-响应</td>\n<td>数据库查询</td>\n</tr>\n</tbody></table>\n<h4 id=\"服务原语-primitives\"><a href=\"#服务原语-primitives\" class=\"headerlink\" title=\"服务原语(primitives)\"></a>服务原语(primitives)</h4><p>服务在形式上是由一组接口原语（或操作）来描述的</p>\n<p>四种类型：</p>\n<ul>\n<li>请求（request）：实体请求服务做一些工作</li>\n<li>指示（Indication）：实体被通知事件的发生</li>\n<li>响应（Response）：实体对某个事件的响应</li>\n<li>确认（Confirm）：对较早请求产生响应的确认</li>\n</ul>\n<h4 id=\"分层\"><a href=\"#分层\" class=\"headerlink\" title=\"分层\"></a>分层</h4><p>引入中间层，为底层不同的网络技术提供统一的抽象，服务上层业务</p>\n<h3 id=\"计算机网络参考模型\"><a href=\"#计算机网络参考模型\" class=\"headerlink\" title=\"计算机网络参考模型\"></a>计算机网络参考模型</h3><h4 id=\"计算机网络的标准化\"><a href=\"#计算机网络的标准化\" class=\"headerlink\" title=\"计算机网络的标准化\"></a>计算机网络的标准化</h4><p><strong>电信标准</strong></p>\n<p>ITU(International Telecommunication Union)</p>\n<ul>\n<li>ITU-R：无线通信</li>\n<li>ITU-T：电信标准</li>\n<li>ITU-D：开发</li>\n</ul>\n<p><strong>国际标准化组织：ISO</strong></p>\n<p>一个国际标准的形成：</p>\n<ul>\n<li>CD（Committee Draft）</li>\n<li>DIS(Draft International Standard)</li>\n<li>IS(International Standard)</li>\n</ul>\n<p><strong>其他标准化组织</strong></p>\n<ul>\n<li>ANSI</li>\n<li>NIST</li>\n<li>IEEE</li>\n<li>OIF</li>\n</ul>\n<p><strong>互联网标准化组织</strong></p>\n<p>互联网标准是自发，而非政府干预的，标准文本称为 RFC(Request For Comments)</p>\n<h4 id=\"OSI-参考模型\"><a href=\"#OSI-参考模型\" class=\"headerlink\" title=\"OSI 参考模型\"></a>OSI 参考模型</h4><p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_3.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"TCP-x2F-IP-参考模型\"><a href=\"#TCP-x2F-IP-参考模型\" class=\"headerlink\" title=\"TCP&#x2F;IP 参考模型\"></a>TCP&#x2F;IP 参考模型</h4><ul>\n<li>物理层<ul>\n<li>在物理线路上传输原始的二进制位</li>\n</ul>\n</li>\n<li>数据链路层<ul>\n<li>在有差错的物理线路上提供无差错的数据传输</li>\n<li>第一层和第二层合称为：Host-to-Network</li>\n</ul>\n</li>\n<li>Internet 层（网络层）<ul>\n<li>控制通信子网提供源点到目的点的IP分组传送</li>\n</ul>\n</li>\n<li>运输层<ul>\n<li>提供端到端的数据传送服务，包括 TCP 和 UDP</li>\n</ul>\n</li>\n<li>应用层<ul>\n<li>提供各种管理和应用服务功能</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"其他参考模型\"><a href=\"#其他参考模型\" class=\"headerlink\" title=\"其他参考模型\"></a>其他参考模型</h4><p>Novell NetWare 参考模型</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_5.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>ATM 参考模型（B-ISDN）</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_6.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><strong>排队与统计复用</strong></p>\n<p>若分组的到达速率超过链路的传输速率：</p>\n<ul>\n<li>分组在端口中排队，等待链路发送</li>\n<li>当排队等待的分组超过分配给端口队列的缓存大小，缓存溢出，导致新到达的分组被丢弃</li>\n<li>端口队列将随即到达的分组进行一定程度的整形，实现了关联端口链路的统计复用</li>\n</ul>\n<p><strong>分组延时的组成</strong></p>\n<div>$$\nD = d_{proc} + d_{queue} + d_{trans} + d_{drop}\n$$</div>\n\n<p>$d_{trans}$：传输延时：</p>\n<ul>\n<li>L: 分组长度</li>\n<li>R：链路速率</li>\n<li>$d_{trans} &#x3D; L &#x2F; R$</li>\n</ul>\n<p>$d_{prop}$ 传播延时：</p>\n<ul>\n<li>$d$：链路长度</li>\n<li>$s$：传播速度</li>\n<li>$d_{prop}$：$d&#x2F;s$</li>\n</ul>\n<p><strong>吞吐量</strong></p>\n<p>单位时间内发送者可以给接收者传送的比特数</p>\n<ul>\n<li>瞬时吞吐量：给定时刻的速率</li>\n<li>平均吞吐量：一段时间内的平均速率</li>\n</ul>\n<p>瓶颈链路：端到端路径(Path)上约束端到端平均吞吐量的链路(Link)</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_7.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><strong>几个概念</strong></p>\n<ul>\n<li>报文：传输层协议的传输单位。报文由传输协议的头和应用层协议数据组成。就互联网而言，报文就是 TCP 报文段，报文段一定要封装在 IP 数据报(Datagram)中。</li>\n<li>报文段： TCP 协议端到端传输的单位。</li>\n<li>IP 数据报分组：IP 协议的端到端传输单位，由 IP 头和传输层协议数据组成。</li>\n<li>分组：穿越网络层和链路层之间接口的数据单位。可以是完整的 IP 数据报或者 IP 数据报的分片(fragment)</li>\n<li>帧：链路层协议传输单元</li>\n</ul>\n<h2 id=\"物理层\"><a href=\"#物理层\" class=\"headerlink\" title=\"物理层\"></a>物理层</h2><p>物理层提供机械的、电气的、功能的和规程的特性，目的是启动、维护和关闭数据链路实体之间进行比特传输的物理连接。这种连接可能通过中继系统，中继系统内的传输也是在物理层。</p>\n<p>物理层的网络互联设备：中继器</p>\n<p>物理层的基本功能：在两个网络设备之间提供透明的比特流传输。</p>\n<p>物理层操作：物理连接的启动与关闭，正常数据的传输，以及维护管理。</p>\n<ul>\n<li>连接方式  （点到点，点到多点）</li>\n<li>通信方式  （单工，半双工，全双工）</li>\n<li>位传输方式（串行，并行）</li>\n</ul>\n<p>物理层的四个重要特性：</p>\n<ul>\n<li>机械特性</li>\n<li>电气特性</li>\n<li>功能特性</li>\n<li>规程特性</li>\n</ul>\n<p><strong>机械特性</strong></p>\n<p>主要定义物理连接的边界点，即接插装置；规定物理连接时所采用的规格、引脚的数量和排列情况</p>\n<p><strong>电气特性</strong></p>\n<p>规定传输二进制位时，线路上信号的电压高低、阻抗匹配、传输速率和距离限制。</p>\n<p><strong>功能特性</strong></p>\n<p>主要定义各条物理线路的功能。</p>\n<p>线路的功能分为四大类：</p>\n<ul>\n<li>数据</li>\n<li>控制</li>\n<li>定时</li>\n<li>接地</li>\n</ul>\n<p><strong>规程特性</strong></p>\n<p>主要定义各条物理线路的工作规程和时序关系。</p>\n<p><strong>传输介质</strong></p>\n<p>有导向介质</p>\n<ul>\n<li>铜线、光纤</li>\n</ul>\n<p>磁介质</p>\n<p>双绞线</p>\n<p>同轴电缆</p>\n<p>光纤</p>\n<p>无导向介质</p>\n<ul>\n<li>无线电波、激光、红外等</li>\n</ul>\n<p><strong>扩频技术</strong></p>\n<ul>\n<li>窄带通信<ul>\n<li>窄带的接受效果更加</li>\n<li>利于提高单位 Hz 的能量</li>\n</ul>\n</li>\n<li>扩频通信<ul>\n<li>调频扩频</li>\n<li>直接序列扩频</li>\n<li>超宽带(UWB)</li>\n</ul>\n</li>\n</ul>\n<p>无线电传输</p>\n<p>低频率、大波长的无线电容易穿过障碍物。全方向发射。</p>\n<p>微波传输</p>\n<ul>\n<li>f &gt;100Mhz，波长在厘米级</li>\n<li>微波沿直线传播</li>\n<li>无法穿越障碍物,容易被雨水吸收</li>\n<li>多径衰落(Multipath fading)</li>\n<li>造价低</li>\n</ul>\n<p>红外线和毫米波</p>\n<ul>\n<li>波长在毫米级</li>\n<li>很难穿越障碍物</li>\n<li>短程通信（无需授权）</li>\n<li>遥控器等</li>\n<li>室内无线LAN</li>\n</ul>\n<p>光波传输</p>\n<ul>\n<li>自由空间光通信</li>\n<li>无法穿透雨或浓雾</li>\n<li>受环境影响较大</li>\n</ul>\n<p><strong>典型传输网络</strong></p>\n<ul>\n<li>电话网络<ul>\n<li>SONET&#x2F;SDH</li>\n<li>采用TDM技术，是同步系统，由主时钟控制，时钟精度10e-9。</li>\n<li>路径（path），链路（line），段（section）</li>\n</ul>\n</li>\n</ul>\n<p>基本结构</p>\n<ul>\n<li>一帧包含 810 字节，每 125 us 产生一帧</li>\n<li>基本 SONET 信道称为 STS-1</li>\n</ul>\n<p>蜂窝无线电（Cellular Radio）</p>\n<ul>\n<li>单方向的寻呼系统</li>\n<li>打电话给寻呼公司，输入寻呼机号码；</li>\n<li>寻呼公司的计算机收到请求，通过线路传到高处（山顶）的天线；</li>\n<li>天线直接广播信号（本地寻呼），或传递给卫星（异地寻呼），卫星再广播。</li>\n<li>需要很小的带宽</li>\n</ul>\n<p>模拟蜂窝电话</p>\n<ul>\n<li>使用小的蜂窝</li>\n<li>在附近（不相邻）的蜂窝中重用传输频率</li>\n<li>发射功率小，设备小而便宜</li>\n</ul>\n<p>数字蜂窝网络</p>\n<ul>\n<li>第一代：模拟蜂窝电话</li>\n<li>第二代：数字蜂窝电话</li>\n<li>第三代：3G</li>\n</ul>\n<p>有线接入网络</p>\n<p>通信卫星</p>\n<p>电力线通信</p>\n<h2 id=\"数据链路层\"><a href=\"#数据链路层\" class=\"headerlink\" title=\"数据链路层\"></a>数据链路层</h2><h3 id=\"定义和功能\"><a href=\"#定义和功能\" class=\"headerlink\" title=\"定义和功能\"></a>定义和功能</h3><p>数据链路层协议定义了一条链路的两个结点间交换数据的单元格式，以结点发送和接收数据单元的动作。</p>\n<p>概念：</p>\n<p>结点(node)：网络中的主机(host)和路由器(router)称为结点</p>\n<p>链路(link)：   通信路径上连接相邻结点的信道称为链路</p>\n<p>点到点(point to point)：一条链路的两个相邻结点间的通信称为点到点通信, 也称为通信路径(path)的一跳(hop)</p>\n<p>端到端(end to end)</p>\n<p>从源结点(source node)到目的结点(destination node)的通信称为端到端通信，通信路径可能由多个链路组成。</p>\n<p>与端到端(end to end，E2E)相对应的概念是逐调(hop by hop，HBH) </p>\n<p>虚拟数据通路</p>\n<p>实际数据通路</p>\n<p>功能：</p>\n<p>数据链路层协议应提供的最基本功能</p>\n<ul>\n<li>向网络层提供服务</li>\n<li>定界与同步</li>\n<li>差错控制</li>\n<li>顺序控制</li>\n<li>流量控制</li>\n</ul>\n<p>提供三种服务</p>\n<ul>\n<li>不可靠无连接服务</li>\n<li>可靠无连接服务</li>\n<li>可靠面向连接服务</li>\n</ul>\n<h4 id=\"成帧\"><a href=\"#成帧\" class=\"headerlink\" title=\"成帧\"></a>成帧</h4><p>Framing: 将比特流分成离散的帧，并计算每个帧的校验和。</p>\n<p>字符计数法</p>\n<ul>\n<li>在帧头中用一个域来表示整个帧的字符个数</li>\n<li>缺点：若计数出错，对本帧和后面的帧有影响</li>\n</ul>\n<p>带字符填充的首尾字符定界法</p>\n<ul>\n<li>起始字符 DLE STX，结束字符DLE ETX<ul>\n<li>DLE:Data Link Escape</li>\n<li>STX:Start of Text</li>\n<li>ETX:End of Text</li>\n</ul>\n</li>\n<li>字符填充</li>\n<li>局限于 8 位字符和 ASCII 字符传送</li>\n</ul>\n<p>带位填充的首尾标记定界法</p>\n<ul>\n<li>帧的起始和结束都用一个特殊的位串“01111110”，称为标记(flag)</li>\n<li>“0”比特插入删除技术</li>\n</ul>\n<p>物理层编码违例法</p>\n<p>只适用于物理层编码有冗余的网络</p>\n<ul>\n<li>802 LAN：曼彻斯特编码中<ul>\n<li>高-低 &#x2F; 低-高 分别表示1&#x2F;0，</li>\n<li>高-高 &#x2F; 低-低  不表示数据，可以用来做定界符。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"差错控制\"><a href=\"#差错控制\" class=\"headerlink\" title=\"差错控制\"></a>差错控制</h4><p>一般方法：接收方给发送方一个反馈（响应）</p>\n<p>出错情况</p>\n<ul>\n<li>帧出错，包括发送帧和相应帧</li>\n<li>帧丢失，包括发送帧和相应帧</li>\n</ul>\n<p>一般方案</p>\n<ul>\n<li>通过计时器和序号保证每帧最终交给目的网络层仅一次</li>\n</ul>\n<h4 id=\"流量控制\"><a href=\"#流量控制\" class=\"headerlink\" title=\"流量控制\"></a>流量控制</h4><p>防止发送过快，淹没接收端</p>\n<ul>\n<li>例如，接收端缓存溢出</li>\n</ul>\n<h3 id=\"错误检测和纠正\"><a href=\"#错误检测和纠正\" class=\"headerlink\" title=\"错误检测和纠正\"></a>错误检测和纠正</h3><p> 差错出现特点</p>\n<ul>\n<li>随机、偶发、孤立</li>\n<li>连续突发(burst）<br> 处理差错的两种基本策略</li>\n<li>使用纠错码</li>\n<li>发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，并能纠正错误。<ul>\n<li>例：前向纠错FEC (Forward Error Correcting):</li>\n</ul>\n</li>\n<li>使用检错码</li>\n<li>发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，但不能判断哪里有错。</li>\n</ul>\n<p><strong>奇偶校验</strong><br>最简单的例子是奇偶校验，在数据后填加一个奇偶位</p>\n<p>奇偶校验可以用来检查奇数个错误</p>\n<h4 id=\"纠错码\"><a href=\"#纠错码\" class=\"headerlink\" title=\"纠错码\"></a>纠错码</h4><p>码字(codeword）</p>\n<ul>\n<li>一个帧包括m个数据位，r个校验位，n &#x3D; m + r，</li>\n<li>则此n比特单元称为n位码字<br>海明距离（Hamming distance）</li>\n<li>两个码字之间不同的比特位数目。</li>\n<li>例如：0000000000 与0000011111的海明距离为5</li>\n</ul>\n<p>结论</p>\n<ul>\n<li>如果两个码字的海明距离为d，则需要d个单比特错就可以把一个码字转换成另一个码字；</li>\n<li>为了检查出d个错，需要使用海明距离为 d + 1 的编码；</li>\n<li>为了纠正d个错，需要使用海明距离为 2d + 1 的编码。</li>\n</ul>\n<p>m个信息位，r个校验位，纠正单比特错 (n&#x3D;r+m)</p>\n<p>对 $2^m$ 个任何有效信息中的任何一个，有 $n$ 个与其距离为 1 的无效码字，因此有</p>\n<div>$$\n(n + 1)2^m \\le 2^n\n$$</div>\n\n<p>利用 $n &#x3D; m + r$，得到 $m + r + 1 \\le 2^r$，给定 m，利用上式得到校正单比特误码的校验位数目下界</p>\n<ul>\n<li>码位从左边开始编号，从“1”开始；</li>\n<li>位号为2的幂的位是校验位，其余是信息位；</li>\n<li>每个校验位使得包括自己在内的一些位的奇偶值为偶数（或奇数）</li>\n<li>为看清数据位k对哪些校验位有影响，将k写成2的幂的和。</li>\n</ul>\n<p>汉明码的工作过程：</p>\n<ul>\n<li>每个码字到来前，接收方计数器清零；</li>\n<li>接收方检查每个校验位k (k &#x3D; 1, 2, 4 …)的奇偶值是否正确；</li>\n<li>若第 k 位奇偶值不对，计数器加 k；</li>\n<li>所有校验位检查完后，若计数器值为0，则码字有效；若计数器值为m，则第m位出错。例：若校验位1、2、8出错，则第11位变反。</li>\n</ul>\n<h4 id=\"检错码\"><a href=\"#检错码\" class=\"headerlink\" title=\"检错码\"></a>检错码</h4><p>使用纠错码传数据，效率低。适用于不可重传的场合。</p>\n<p>大多情况采用的检测码加重传。</p>\n<p>二进制多项式</p>\n<p>二进制码串表示成二进制多项式</p>\n<p>循环冗余码（CRC）</p>\n<ul>\n<li>发送方与接收方事前商定。</li>\n<li>生成多项式的高位和低位必须为1</li>\n<li>生成多项式必须比传输信息对应的多项式短</li>\n</ul>\n<p>CRC 的基本思想<br>校验和(checksum)加载帧尾，使带校验和的帧的多项式能被 $G(x)$ 除尽，接收方接受时，用 $G(x)$ 去除它，若有余数，则传输出错。</p>\n<p>校验和计算算法</p>\n<p>设 $G(x)$ 为 $r$ 阶，在帧的末尾加 $r$ 个0，使得帧为 $m + r$ 位，相应多项式为 $x^rM(x)$。</p>\n<p>按照模 2 除法用对应$G(x)$ 的位串去除对应于 $x^rM(x)$减去余数，结果就是要传送的带检验和的多项式 $T(x)$。</p>\n<p>CRC 的检错能力：</p>\n<p>发送方发送 $T(x)$，接收方接受的$T(x) + E(x)$，$E(x) \\ne 0$。</p>\n<p>$(T(x) + E(x)) &#x2F; G(x) &#x3D; 0 + (E(x) &#x2F; G(x))$</p>\n<p>如果$(E(x) &#x2F; G(x))$的余数为0，则差错不能发现；否则可以发现。</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/5_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/5_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h3 id=\"数据链路层协议\"><a href=\"#数据链路层协议\" class=\"headerlink\" title=\"数据链路层协议\"></a>数据链路层协议</h3><h4 id=\"无约束单工协议\"><a href=\"#无约束单工协议\" class=\"headerlink\" title=\"无约束单工协议\"></a>无约束单工协议</h4><ul>\n<li>工作在理想情况</li>\n<li>单工传输</li>\n<li>发送方无休止工作（要发送的信息无限多）</li>\n<li>接收方无休止工作（缓冲区无限大）</li>\n<li>通信线路（信道）不损坏或丢失信息帧</li>\n</ul>\n<p>工作过程</p>\n<ul>\n<li>发送程序: 取数据，构成帧，发送帧；</li>\n<li>接收程序: 等待，接收帧，送数据给高层</li>\n</ul>\n<h4 id=\"单工停等协议\"><a href=\"#单工停等协议\" class=\"headerlink\" title=\"单工停等协议\"></a>单工停等协议</h4><p>协议描述</p>\n<ul>\n<li>增加约束条件：接收方不能无休止接收。<br>解决方案</li>\n<li>接收方每收到一个帧后，给发送方回送一个响应。<br>工作过程</li>\n<li>发送程序：取数据，成帧，发送帧，等待响应帧</li>\n<li>接收程序：等待，接收帧，送数据给高层，回送响应帧。</li>\n</ul>\n<h4 id=\"有噪声信道的单工协议\"><a href=\"#有噪声信道的单工协议\" class=\"headerlink\" title=\"有噪声信道的单工协议\"></a>有噪声信道的单工协议</h4><p>协议描述</p>\n<ul>\n<li>增加约束条件：信道（线路）有差错，信息帧可能损坏或丢失。</li>\n</ul>\n<p>解决方案</p>\n<ul>\n<li>出错重传<ul>\n<li>带来的问题<ul>\n<li>响应帧重复?发送帧头中放入序号</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>重传触发:<ul>\n<li>超时重传 </li>\n<li>什么时候重传?定时器<br>ARQ&#x2F;PAR</li>\n<li>PAR (Positive Acknowledgement with Retransmission）</li>\n<li>ARQ (Automatic Repeat reQuest）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"流量控制-1\"><a href=\"#流量控制-1\" class=\"headerlink\" title=\"流量控制\"></a>流量控制</h3><h4 id=\"滑动窗口协议\"><a href=\"#滑动窗口协议\" class=\"headerlink\" title=\"滑动窗口协议\"></a>滑动窗口协议</h4><p>捎带确认（piggybacking）</p>\n<p><strong>一位滑窗协议</strong></p>\n<ul>\n<li>窗口大小：N &#x3D; 1，发送序号和接收序号的取值范围：0，1；</li>\n<li>可进行数据双向传输，信息帧中可含有确认信息（piggybacking）；</li>\n<li>信息帧中包括两个序号域：发送序号和接收序号<br>（已经正确收到的帧的序号）<br>存在问题</li>\n<li>能保证无差错传输，但是基于停等方式；</li>\n<li>若双方同时开始发送，则会有一半重复帧；</li>\n<li>效率低，传输时间长。</li>\n</ul>\n<h4 id=\"退后n帧协议\"><a href=\"#退后n帧协议\" class=\"headerlink\" title=\"退后n帧协议\"></a>退后n帧协议</h4><h4 id=\"选择重传协议\"><a href=\"#选择重传协议\" class=\"headerlink\" title=\"选择重传协议\"></a>选择重传协议</h4>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"参考书籍\"><a href=\"#参考书籍\" class=\"headerlink\" title=\"参考书籍\"></a>参考书籍</h2><p>A.S Tanebaum (著)，严伟，潘爱民(译) 计算机网络(第五版), 2004，清华大学出版社 </p>\n<p>A.S Tanebaum，Nick Feamster, David Wetherall (著)，潘爱民(译)， 计算机网络(第六版), 2022, 清华大学出版社（彩色版，非常精美）</p>\n<h2 id=\"杂项\"><a href=\"#杂项\" class=\"headerlink\" title=\"杂项\"></a>杂项</h2><p>token ring </p>\n<p>计算机网络最核心的技术：分组(packet)。</p>\n<p>grid computing</p>\n<h2 id=\"计算机网络的历史与进展\"><a href=\"#计算机网络的历史与进展\" class=\"headerlink\" title=\"计算机网络的历史与进展\"></a>计算机网络的历史与进展</h2><p>网络计算的基本模式</p>\n<ul>\n<li>C&#x2F;S or B&#x2F;W</li>\n<li>P2P</li>\n</ul>\n<p>服务</p>\n<ul>\n<li>延迟、带宽、丢失率、可靠性</li>\n<li>单播&#x2F;多播， 实时&#x2F;非实时</li>\n</ul>\n<p>链路：光纤、电缆和卫星</p>\n<ul>\n<li>电子、光子等作为传输介质</li>\n<li>节点：机械&#x2F;电&#x2F;光</li>\n</ul>\n<p>协议</p>\n<ul>\n<li>TCP&#x2F;IP, ATM, MPLS, SONET, Ethernet, PPP, X.25, FrameRelay, AppleTalk, IPX, SNA</li>\n</ul>\n<p>功能</p>\n<ul>\n<li>路由，差错控制、拥塞控制、服务质量(QoS)</li>\n</ul>\n<p>应用：FTP、HTTP </p>\n<p>空间距离</p>\n<ul>\n<li>局域网 (LAN): 以太网、令牌环、FDDI</li>\n<li>城域网 (MAN): DQDB, SMDS ,以太网</li>\n<li>广域网 (WAN): X.25, ATM, frame relay, DWDM</li>\n</ul>\n<p>信息类型</p>\n<ul>\n<li>数据网络 vs. 通信网络</li>\n</ul>\n<p>应用类型</p>\n<ul>\n<li>专用网络：飞机订票网，银行网，信用卡网</li>\n<li>通用网络：Internet</li>\n</ul>\n<p>使用权</p>\n<ul>\n<li>私有：企业网</li>\n<li>公用：电话网、Internet<br>协议的所有权</li>\n<li>私有: SNA (Systems Network Architecture)</li>\n<li>开放: IP<br>技术</li>\n<li>地面 vs. 卫星</li>\n<li>有线 vs. 无线<br>协议</li>\n<li>IP, AppleTalk, SNA</li>\n</ul>\n<p>计算机网络的形成</p>\n<ul>\n<li>多终端系统</li>\n<li>把计算机互联起来<br>1970年代的计算机网络</li>\n<li>X.25 分组交换网：各国的电信部门建设运行</li>\n<li>各种专用的网络体系结构：SNA，DECnet</li>\n<li>Internet 的前身ARPANET进行实验运行<br>1980年代的计算机网络</li>\n<li>标准化计算机网络体系结构：OSI</li>\n<li>局域网络 LAN 技术空前发展</li>\n<li>建成NSFNET，Internet 初具规模</li>\n</ul>\n<p>迈特卡尔夫定律(联网定律)</p>\n<p>网络价值随用户数平方成正比。未联网设备增加 $N$ 倍，效率增加 $N$ 倍。联网设备增加 $N$ 倍，效率增加 $N^2$ 倍</p>\n<p>Internet 标准化组织</p>\n<ul>\n<li>Internet Engineering Task Force（IETF）：IETF负责Internet协议的研发和改进。IETF被分为很多个工作组（working groups），他们提交的文档称为RFC（Request For Comments）。</li>\n<li>IRTF（Internet Research Task Force）：IRTF由一些专注于某个领域长期发展的研究小组组成。</li>\n<li>Internet Architecture Board（IAB）：IAB负责定义Internet的整体框架，为IETF提供大方向上的指导。</li>\n<li>The Internet Engineering Steering Group（IESG）：IESG在技术方面管理IETF的活动，负责Internet标准的制定过程。</li>\n</ul>\n<p>所有的标准以RFC的形式发布出来，可以从<a href=\"http://www.ietf.org免费获得，但不是所有的RFC都是Internet标准。标准形成的一般步骤是：\">www.ietf.org免费获得，但不是所有的RFC都是Internet标准。标准形成的一般步骤是：</a></p>\n<ul>\n<li>Internet Drafts</li>\n<li>RFCs</li>\n<li>Proposed Standard</li>\n<li>Draft Standard（需要两个可以工作的实现）</li>\n<li>Internet Standard（由IAB发布）</li>\n</ul>\n<p>David Clark, MIT, 1992: </p>\n<ul>\n<li><pre><code> &quot;We reject: kings, presidents, and voting. \n</code></pre>\n</li>\n<li><pre><code>  We believe in: rough consensus and running code.”\n</code></pre>\n</li>\n</ul>\n<p><strong>Paul Baran 分组交换网络</strong></p>\n<p>与 Donald Watts Davies 在这个思想的发明上有争议。</p>\n<p>Baran 的设计细节：</p>\n<p>报文发送</p>\n<ul>\n<li>每个交换节点根据自己的路由表判断如何转发报文</li>\n<li>每个报文的转发都是独立于其他报文的</li>\n<li>交换节点不保存端节点的状态<ul>\n<li>可扩展性好</li>\n<li>不是最有效的网络</li>\n<li>发送不是完美的<ul>\n<li>端节点必须能容忍发送错误并从中恢复<br>分布式系统</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>所有交换节点是平等的</li>\n<li>避免了单一节点失效问题</li>\n<li>部件可以失效，但系统不可以</li>\n<li>系统的健壮性来自于<ul>\n<li>足够的物理（硬件）冗余</li>\n<li>适应性路由</li>\n</ul>\n</li>\n</ul>\n<p>模拟实验表明：“extremely survivable networks can be built using a moderately low redundancy of connectivity level”—Paul Baran, 1964</p>\n<p>比较两种可靠系统的实现思路：</p>\n<p>电话系统 </p>\n<ul>\n<li>笨终端，聪明的网络 </li>\n<li>确保每个网络部件都是可靠的 <ul>\n<li>系统可靠性＝部件可靠性 </li>\n<li>通过局部冗余实现部件的高可靠性 </li>\n<li>期望每个部件都能正常工作，部件失败的可能性很低</li>\n</ul>\n</li>\n<li>需要人工配置的，高度控制的网络</li>\n</ul>\n<p>Baran的系统 </p>\n<ul>\n<li>建立在简单的、不可靠部件上的可靠系统 </li>\n<li>自适应的系统 </li>\n<li>聪明的终端，可以修正传输错误</li>\n</ul>\n<p>Baran 设计思想的一种实现：Internet</p>\n<ul>\n<li>连接异构的子网</li>\n<li>提供两种基本功能<ul>\n<li>全球唯一的地址</li>\n<li>报文通过动态路由从源节点发送到目的节点</li>\n</ul>\n</li>\n</ul>\n<p>simple, flexible, scalable, and robust</p>\n<p>分组交换的特点：</p>\n<p><strong>简单性</strong></p>\n<ul>\n<li>每个报文携带各自的地址信息</li>\n<li>一个路由表可以为所有的流量服务</li>\n<li>可以适应爆炸性的增长<ul>\n<li>越简单越不容易出错 </li>\n<li>越简单越容易增长 </li>\n<li>对基本网络功能的要求少，可以在其上建立多种类型的网络</li>\n</ul>\n</li>\n</ul>\n<p><strong>灵活性</strong></p>\n<p>Everything over IP</p>\n<p>IP over Everything</p>\n<p><strong>可扩展性</strong></p>\n<p>可扩展的系统必须能对付</p>\n<ul>\n<li>端系统的增加</li>\n<li>流量的增加</li>\n<li>网络规模的增长<ul>\n<li>大的路由表</li>\n<li>路由频繁的变化</li>\n</ul>\n</li>\n</ul>\n<p>边缘论：End-to-End Argument</p>\n<p>路由器只负责传输，复杂的功能（纠错，重传）都由终端自行解决</p>\n<p><strong>健壮性</strong></p>\n<ul>\n<li>动态路由具有自适应的特性<ul>\n<li>动态路由和报文转发相辅相成</li>\n<li>周期性路由更新</li>\n<li>默认: 现有的部件会失效，会有新的部件加入，认为变化是正常的</li>\n</ul>\n</li>\n<li>牺牲一定的带宽的利用率，提高健壮性(报文头开销，更新开销)</li>\n</ul>\n<h2 id=\"数据通信基本原理\"><a href=\"#数据通信基本原理\" class=\"headerlink\" title=\"数据通信基本原理\"></a>数据通信基本原理</h2><p>香农定理：<br>带宽为 $H$ 赫兹，信噪比为 $S&#x2F;N$ 的任意信道的最大数据传输率为 $H\\log_2(1 + S&#x2F;N) (bps)$</p>\n<ul>\n<li>此式是利用信息论得出的，具有普遍意义</li>\n<li>与信号电平级数、采样速度无关</li>\n<li>此式仅是上限，实践中难以达到</li>\n</ul>\n<p>曼彻斯特码（Manchester），也称相位编码</p>\n<ul>\n<li>原理：每一位中间都有一个跳变，从低跳到高表示“0”，从高跳到低表示“1”。</li>\n<li>优点：克服了NRZ码的不足。每位中间的跳变即可作为数据，又可作为时钟，能够自同步。</li>\n</ul>\n<p>\t</p>\n<p>差分曼彻斯特码（Differential Manchester）</p>\n<ul>\n<li>原理：每一位中间都有一个跳变，每位开始时有跳变表示“0”，无跳变表示“1”。位中间跳变表示时钟，位前跳变表示数据。</li>\n<li>优点：时钟、数据分离，便于提取。</li>\n</ul>\n<h2 id=\"网络体系结构\"><a href=\"#网络体系结构\" class=\"headerlink\" title=\"网络体系结构\"></a>网络体系结构</h2><h3 id=\"计算机网络的构成\"><a href=\"#计算机网络的构成\" class=\"headerlink\" title=\"计算机网络的构成\"></a>计算机网络的构成</h3><p><strong>资源子网</strong></p>\n<ul>\n<li>服务器（Server）</li>\n<li>客户机（Client）</li>\n</ul>\n<p>C&#x2F;S -&gt; B&#x2F;W -&gt; P2P</p>\n<p><strong>通信子网</strong></p>\n<ul>\n<li>通信线路（通道）</li>\n<li>网络互连设备（路由器、交换机、集线器等）</li>\n</ul>\n<h4 id=\"基本结构\"><a href=\"#基本结构\" class=\"headerlink\" title=\"基本结构\"></a>基本结构</h4><p><strong>点到点通道</strong></p>\n<ul>\n<li>一条线路连接两台网络互联设备</li>\n<li>一般两台计算机的连接要经过多台互联设备</li>\n<li>星形、环形、树形、全连结、交叉环、不规则图</li>\n<li>关键技术：路由选择（Routing）</li>\n</ul>\n<p><strong>广播网络</strong></p>\n<ul>\n<li><p>总线，环</p>\n</li>\n<li><p>组播网络（Multicast Networks）：把成员分组</p>\n</li>\n<li><p>单播网络（Unicast Networks）</p>\n<ul>\n<li>点到点连接</li>\n</ul>\n</li>\n<li><p>关键技术：通道分配</p>\n<ul>\n<li>静态分配：分时间片<ul>\n<li>控制简单，通道利用率低</li>\n</ul>\n</li>\n<li>动态分配各站点动态使用通道<ul>\n<li>控制复杂，通道利用度高</li>\n<li>通道分配方法：<ul>\n<li>集中式：只有一个仲裁机构</li>\n<li>分布式：各站点均有仲裁机构</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>PAN</p>\n</li>\n<li><p>LAN</p>\n</li>\n<li><p>MAN</p>\n</li>\n<li><p>WAN</p>\n</li>\n<li><p>internet，指一种技术(Internet，指实体的网络)</p>\n</li>\n<li><p>Interplanetary Internet</p>\n</li>\n</ul>\n<h3 id=\"计算机网络体系结构\"><a href=\"#计算机网络体系结构\" class=\"headerlink\" title=\"计算机网络体系结构\"></a>计算机网络体系结构</h3><p>对计算机网络及其部件所完成的功能的比较精确的定义，即从功能的角度描述计算机网络的结构，是层次模型和协议的集合。</p>\n<p>注意：计算机网络体系结构仅仅定义了网络及其部件通过协议应完成的功能，不定义协议的实现细节和各层协议之间的接口关系。</p>\n<p>协议分层的优点：易于协议的设计、分析、实现和调试</p>\n<p>计算机网络的功能：</p>\n<ul>\n<li>基本功能：为地理位置不同的计算机用户提供访问通路</li>\n<li>具体化为：<ul>\n<li>连接源节点和目的节点的物理传输线路，可以经过中间节点</li>\n<li>每条线路两端的结点利用波形进行二进制通信</li>\n<li>无差错的信息传送</li>\n<li>多个用户共享一条物理线路</li>\n<li>按照地址信息，进行路由选择</li>\n<li>信息缓存与流量控制</li>\n<li>会话控制</li>\n<li>满足各种用户、各种应用的访问要求</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"网络协议\"><a href=\"#网络协议\" class=\"headerlink\" title=\"网络协议\"></a>网络协议</h4><p>层次结构的计算计网络功能中最重要的功能是通信功能，这种通信功能主要涉及同层中通信双方的相互作用，位于不同计算机上进行对话的第N层通信各方可分别看成是一种进程，称为<strong>对等进程（同等进程）</strong></p>\n<p><strong>协议</strong></p>\n<p>计算机网络同等层次中，通信双方进行信息交换时必须遵守的规则。</p>\n<p><strong>协议栈</strong></p>\n<p>一个特定系统所使用的一组协议统称为协议栈。</p>\n<p><strong>接口</strong></p>\n<p>相邻层之间有一个接口（Interface），它定义了下层向上层提供的原语操作与服务</p>\n<h4 id=\"层、协议和接口\"><a href=\"#层、协议和接口\" class=\"headerlink\" title=\"层、协议和接口\"></a>层、协议和接口</h4><p><strong>协议特性</strong></p>\n<ul>\n<li>不知道上下层的内部结构</li>\n<li>独立完成某种功能</li>\n<li>为上层提供服务</li>\n<li>使用下层提供的服务</li>\n</ul>\n<h4 id=\"服务分类\"><a href=\"#服务分类\" class=\"headerlink\" title=\"服务分类\"></a>服务分类</h4><ul>\n<li>面向连接的服务<ul>\n<li>当使用服务传输数据时，首先建立连接，然后使用该链接传送数据，使用完后，关闭连接。</li>\n<li>特点：顺序性好，类似于电话</li>\n</ul>\n</li>\n<li>面向无连接的服务<ul>\n<li>直接使用服务传送数据，每个分组独立进行路由选择。</li>\n<li>特点：顺序性差，类似于邮政</li>\n</ul>\n</li>\n<li>连接与可靠的关系<ul>\n<li>连接并不意味着可靠，可靠要通过确认、重传等机制来保证</li>\n<li>面向无连接的可以是可靠的，例如挂号信</li>\n</ul>\n</li>\n</ul>\n<p>TCP(可靠的连接)，UDP(不可靠的)</p>\n<table>\n<thead>\n<tr>\n<th>服务</th>\n<th>例子</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>面向连接的例子</td>\n<td></td>\n</tr>\n<tr>\n<td>可靠的报文流</td>\n<td>页面序列</td>\n</tr>\n<tr>\n<td>可靠的字节流</td>\n<td>文件下载</td>\n</tr>\n<tr>\n<td>不可靠的连接</td>\n<td>IP语音</td>\n</tr>\n<tr>\n<td>无连接的例子</td>\n<td></td>\n</tr>\n<tr>\n<td>不可靠的数据报</td>\n<td>垃圾邮件</td>\n</tr>\n<tr>\n<td>有确认的数据报</td>\n<td>文本消息</td>\n</tr>\n<tr>\n<td>请求-响应</td>\n<td>数据库查询</td>\n</tr>\n</tbody></table>\n<h4 id=\"服务原语-primitives\"><a href=\"#服务原语-primitives\" class=\"headerlink\" title=\"服务原语(primitives)\"></a>服务原语(primitives)</h4><p>服务在形式上是由一组接口原语（或操作）来描述的</p>\n<p>四种类型：</p>\n<ul>\n<li>请求（request）：实体请求服务做一些工作</li>\n<li>指示（Indication）：实体被通知事件的发生</li>\n<li>响应（Response）：实体对某个事件的响应</li>\n<li>确认（Confirm）：对较早请求产生响应的确认</li>\n</ul>\n<h4 id=\"分层\"><a href=\"#分层\" class=\"headerlink\" title=\"分层\"></a>分层</h4><p>引入中间层，为底层不同的网络技术提供统一的抽象，服务上层业务</p>\n<h3 id=\"计算机网络参考模型\"><a href=\"#计算机网络参考模型\" class=\"headerlink\" title=\"计算机网络参考模型\"></a>计算机网络参考模型</h3><h4 id=\"计算机网络的标准化\"><a href=\"#计算机网络的标准化\" class=\"headerlink\" title=\"计算机网络的标准化\"></a>计算机网络的标准化</h4><p><strong>电信标准</strong></p>\n<p>ITU(International Telecommunication Union)</p>\n<ul>\n<li>ITU-R：无线通信</li>\n<li>ITU-T：电信标准</li>\n<li>ITU-D：开发</li>\n</ul>\n<p><strong>国际标准化组织：ISO</strong></p>\n<p>一个国际标准的形成：</p>\n<ul>\n<li>CD（Committee Draft）</li>\n<li>DIS(Draft International Standard)</li>\n<li>IS(International Standard)</li>\n</ul>\n<p><strong>其他标准化组织</strong></p>\n<ul>\n<li>ANSI</li>\n<li>NIST</li>\n<li>IEEE</li>\n<li>OIF</li>\n</ul>\n<p><strong>互联网标准化组织</strong></p>\n<p>互联网标准是自发，而非政府干预的，标准文本称为 RFC(Request For Comments)</p>\n<h4 id=\"OSI-参考模型\"><a href=\"#OSI-参考模型\" class=\"headerlink\" title=\"OSI 参考模型\"></a>OSI 参考模型</h4><p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_1.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_3.jpg\" alt=\"alt\"></p>\n<h4 id=\"TCP-x2F-IP-参考模型\"><a href=\"#TCP-x2F-IP-参考模型\" class=\"headerlink\" title=\"TCP&#x2F;IP 参考模型\"></a>TCP&#x2F;IP 参考模型</h4><ul>\n<li>物理层<ul>\n<li>在物理线路上传输原始的二进制位</li>\n</ul>\n</li>\n<li>数据链路层<ul>\n<li>在有差错的物理线路上提供无差错的数据传输</li>\n<li>第一层和第二层合称为：Host-to-Network</li>\n</ul>\n</li>\n<li>Internet 层（网络层）<ul>\n<li>控制通信子网提供源点到目的点的IP分组传送</li>\n</ul>\n</li>\n<li>运输层<ul>\n<li>提供端到端的数据传送服务，包括 TCP 和 UDP</li>\n</ul>\n</li>\n<li>应用层<ul>\n<li>提供各种管理和应用服务功能</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_2.jpg\" alt=\"alt\"></p>\n<h4 id=\"其他参考模型\"><a href=\"#其他参考模型\" class=\"headerlink\" title=\"其他参考模型\"></a>其他参考模型</h4><p>Novell NetWare 参考模型</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_5.jpg\" alt=\"alt\"></p>\n<p>ATM 参考模型（B-ISDN）</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_6.jpg\" alt=\"alt\"></p>\n<p><strong>排队与统计复用</strong></p>\n<p>若分组的到达速率超过链路的传输速率：</p>\n<ul>\n<li>分组在端口中排队，等待链路发送</li>\n<li>当排队等待的分组超过分配给端口队列的缓存大小，缓存溢出，导致新到达的分组被丢弃</li>\n<li>端口队列将随即到达的分组进行一定程度的整形，实现了关联端口链路的统计复用</li>\n</ul>\n<p><strong>分组延时的组成</strong></p>\n<div>$$\nD = d_{proc} + d_{queue} + d_{trans} + d_{drop}\n$$</div>\n\n<p>$d_{trans}$：传输延时：</p>\n<ul>\n<li>L: 分组长度</li>\n<li>R：链路速率</li>\n<li>$d_{trans} &#x3D; L &#x2F; R$</li>\n</ul>\n<p>$d_{prop}$ 传播延时：</p>\n<ul>\n<li>$d$：链路长度</li>\n<li>$s$：传播速度</li>\n<li>$d_{prop}$：$d&#x2F;s$</li>\n</ul>\n<p><strong>吞吐量</strong></p>\n<p>单位时间内发送者可以给接收者传送的比特数</p>\n<ul>\n<li>瞬时吞吐量：给定时刻的速率</li>\n<li>平均吞吐量：一段时间内的平均速率</li>\n</ul>\n<p>瓶颈链路：端到端路径(Path)上约束端到端平均吞吐量的链路(Link)</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/3_7.jpg\" alt=\"alt\"></p>\n<p><strong>几个概念</strong></p>\n<ul>\n<li>报文：传输层协议的传输单位。报文由传输协议的头和应用层协议数据组成。就互联网而言，报文就是 TCP 报文段，报文段一定要封装在 IP 数据报(Datagram)中。</li>\n<li>报文段： TCP 协议端到端传输的单位。</li>\n<li>IP 数据报分组：IP 协议的端到端传输单位，由 IP 头和传输层协议数据组成。</li>\n<li>分组：穿越网络层和链路层之间接口的数据单位。可以是完整的 IP 数据报或者 IP 数据报的分片(fragment)</li>\n<li>帧：链路层协议传输单元</li>\n</ul>\n<h2 id=\"物理层\"><a href=\"#物理层\" class=\"headerlink\" title=\"物理层\"></a>物理层</h2><p>物理层提供机械的、电气的、功能的和规程的特性，目的是启动、维护和关闭数据链路实体之间进行比特传输的物理连接。这种连接可能通过中继系统，中继系统内的传输也是在物理层。</p>\n<p>物理层的网络互联设备：中继器</p>\n<p>物理层的基本功能：在两个网络设备之间提供透明的比特流传输。</p>\n<p>物理层操作：物理连接的启动与关闭，正常数据的传输，以及维护管理。</p>\n<ul>\n<li>连接方式  （点到点，点到多点）</li>\n<li>通信方式  （单工，半双工，全双工）</li>\n<li>位传输方式（串行，并行）</li>\n</ul>\n<p>物理层的四个重要特性：</p>\n<ul>\n<li>机械特性</li>\n<li>电气特性</li>\n<li>功能特性</li>\n<li>规程特性</li>\n</ul>\n<p><strong>机械特性</strong></p>\n<p>主要定义物理连接的边界点，即接插装置；规定物理连接时所采用的规格、引脚的数量和排列情况</p>\n<p><strong>电气特性</strong></p>\n<p>规定传输二进制位时，线路上信号的电压高低、阻抗匹配、传输速率和距离限制。</p>\n<p><strong>功能特性</strong></p>\n<p>主要定义各条物理线路的功能。</p>\n<p>线路的功能分为四大类：</p>\n<ul>\n<li>数据</li>\n<li>控制</li>\n<li>定时</li>\n<li>接地</li>\n</ul>\n<p><strong>规程特性</strong></p>\n<p>主要定义各条物理线路的工作规程和时序关系。</p>\n<p><strong>传输介质</strong></p>\n<p>有导向介质</p>\n<ul>\n<li>铜线、光纤</li>\n</ul>\n<p>磁介质</p>\n<p>双绞线</p>\n<p>同轴电缆</p>\n<p>光纤</p>\n<p>无导向介质</p>\n<ul>\n<li>无线电波、激光、红外等</li>\n</ul>\n<p><strong>扩频技术</strong></p>\n<ul>\n<li>窄带通信<ul>\n<li>窄带的接受效果更加</li>\n<li>利于提高单位 Hz 的能量</li>\n</ul>\n</li>\n<li>扩频通信<ul>\n<li>调频扩频</li>\n<li>直接序列扩频</li>\n<li>超宽带(UWB)</li>\n</ul>\n</li>\n</ul>\n<p>无线电传输</p>\n<p>低频率、大波长的无线电容易穿过障碍物。全方向发射。</p>\n<p>微波传输</p>\n<ul>\n<li>f &gt;100Mhz，波长在厘米级</li>\n<li>微波沿直线传播</li>\n<li>无法穿越障碍物,容易被雨水吸收</li>\n<li>多径衰落(Multipath fading)</li>\n<li>造价低</li>\n</ul>\n<p>红外线和毫米波</p>\n<ul>\n<li>波长在毫米级</li>\n<li>很难穿越障碍物</li>\n<li>短程通信（无需授权）</li>\n<li>遥控器等</li>\n<li>室内无线LAN</li>\n</ul>\n<p>光波传输</p>\n<ul>\n<li>自由空间光通信</li>\n<li>无法穿透雨或浓雾</li>\n<li>受环境影响较大</li>\n</ul>\n<p><strong>典型传输网络</strong></p>\n<ul>\n<li>电话网络<ul>\n<li>SONET&#x2F;SDH</li>\n<li>采用TDM技术，是同步系统，由主时钟控制，时钟精度10e-9。</li>\n<li>路径（path），链路（line），段（section）</li>\n</ul>\n</li>\n</ul>\n<p>基本结构</p>\n<ul>\n<li>一帧包含 810 字节，每 125 us 产生一帧</li>\n<li>基本 SONET 信道称为 STS-1</li>\n</ul>\n<p>蜂窝无线电（Cellular Radio）</p>\n<ul>\n<li>单方向的寻呼系统</li>\n<li>打电话给寻呼公司，输入寻呼机号码；</li>\n<li>寻呼公司的计算机收到请求，通过线路传到高处（山顶）的天线；</li>\n<li>天线直接广播信号（本地寻呼），或传递给卫星（异地寻呼），卫星再广播。</li>\n<li>需要很小的带宽</li>\n</ul>\n<p>模拟蜂窝电话</p>\n<ul>\n<li>使用小的蜂窝</li>\n<li>在附近（不相邻）的蜂窝中重用传输频率</li>\n<li>发射功率小，设备小而便宜</li>\n</ul>\n<p>数字蜂窝网络</p>\n<ul>\n<li>第一代：模拟蜂窝电话</li>\n<li>第二代：数字蜂窝电话</li>\n<li>第三代：3G</li>\n</ul>\n<p>有线接入网络</p>\n<p>通信卫星</p>\n<p>电力线通信</p>\n<h2 id=\"数据链路层\"><a href=\"#数据链路层\" class=\"headerlink\" title=\"数据链路层\"></a>数据链路层</h2><h3 id=\"定义和功能\"><a href=\"#定义和功能\" class=\"headerlink\" title=\"定义和功能\"></a>定义和功能</h3><p>数据链路层协议定义了一条链路的两个结点间交换数据的单元格式，以结点发送和接收数据单元的动作。</p>\n<p>概念：</p>\n<p>结点(node)：网络中的主机(host)和路由器(router)称为结点</p>\n<p>链路(link)：   通信路径上连接相邻结点的信道称为链路</p>\n<p>点到点(point to point)：一条链路的两个相邻结点间的通信称为点到点通信, 也称为通信路径(path)的一跳(hop)</p>\n<p>端到端(end to end)</p>\n<p>从源结点(source node)到目的结点(destination node)的通信称为端到端通信，通信路径可能由多个链路组成。</p>\n<p>与端到端(end to end，E2E)相对应的概念是逐调(hop by hop，HBH) </p>\n<p>虚拟数据通路</p>\n<p>实际数据通路</p>\n<p>功能：</p>\n<p>数据链路层协议应提供的最基本功能</p>\n<ul>\n<li>向网络层提供服务</li>\n<li>定界与同步</li>\n<li>差错控制</li>\n<li>顺序控制</li>\n<li>流量控制</li>\n</ul>\n<p>提供三种服务</p>\n<ul>\n<li>不可靠无连接服务</li>\n<li>可靠无连接服务</li>\n<li>可靠面向连接服务</li>\n</ul>\n<h4 id=\"成帧\"><a href=\"#成帧\" class=\"headerlink\" title=\"成帧\"></a>成帧</h4><p>Framing: 将比特流分成离散的帧，并计算每个帧的校验和。</p>\n<p>字符计数法</p>\n<ul>\n<li>在帧头中用一个域来表示整个帧的字符个数</li>\n<li>缺点：若计数出错，对本帧和后面的帧有影响</li>\n</ul>\n<p>带字符填充的首尾字符定界法</p>\n<ul>\n<li>起始字符 DLE STX，结束字符DLE ETX<ul>\n<li>DLE:Data Link Escape</li>\n<li>STX:Start of Text</li>\n<li>ETX:End of Text</li>\n</ul>\n</li>\n<li>字符填充</li>\n<li>局限于 8 位字符和 ASCII 字符传送</li>\n</ul>\n<p>带位填充的首尾标记定界法</p>\n<ul>\n<li>帧的起始和结束都用一个特殊的位串“01111110”，称为标记(flag)</li>\n<li>“0”比特插入删除技术</li>\n</ul>\n<p>物理层编码违例法</p>\n<p>只适用于物理层编码有冗余的网络</p>\n<ul>\n<li>802 LAN：曼彻斯特编码中<ul>\n<li>高-低 &#x2F; 低-高 分别表示1&#x2F;0，</li>\n<li>高-高 &#x2F; 低-低  不表示数据，可以用来做定界符。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"差错控制\"><a href=\"#差错控制\" class=\"headerlink\" title=\"差错控制\"></a>差错控制</h4><p>一般方法：接收方给发送方一个反馈（响应）</p>\n<p>出错情况</p>\n<ul>\n<li>帧出错，包括发送帧和相应帧</li>\n<li>帧丢失，包括发送帧和相应帧</li>\n</ul>\n<p>一般方案</p>\n<ul>\n<li>通过计时器和序号保证每帧最终交给目的网络层仅一次</li>\n</ul>\n<h4 id=\"流量控制\"><a href=\"#流量控制\" class=\"headerlink\" title=\"流量控制\"></a>流量控制</h4><p>防止发送过快，淹没接收端</p>\n<ul>\n<li>例如，接收端缓存溢出</li>\n</ul>\n<h3 id=\"错误检测和纠正\"><a href=\"#错误检测和纠正\" class=\"headerlink\" title=\"错误检测和纠正\"></a>错误检测和纠正</h3><p> 差错出现特点</p>\n<ul>\n<li>随机、偶发、孤立</li>\n<li>连续突发(burst）<br> 处理差错的两种基本策略</li>\n<li>使用纠错码</li>\n<li>发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，并能纠正错误。<ul>\n<li>例：前向纠错FEC (Forward Error Correcting):</li>\n</ul>\n</li>\n<li>使用检错码</li>\n<li>发送方在每个数据块中加入足够的冗余信息，使得接收方能够判断接收到的数据是否有错，但不能判断哪里有错。</li>\n</ul>\n<p><strong>奇偶校验</strong><br>最简单的例子是奇偶校验，在数据后填加一个奇偶位</p>\n<p>奇偶校验可以用来检查奇数个错误</p>\n<h4 id=\"纠错码\"><a href=\"#纠错码\" class=\"headerlink\" title=\"纠错码\"></a>纠错码</h4><p>码字(codeword）</p>\n<ul>\n<li>一个帧包括m个数据位，r个校验位，n &#x3D; m + r，</li>\n<li>则此n比特单元称为n位码字<br>海明距离（Hamming distance）</li>\n<li>两个码字之间不同的比特位数目。</li>\n<li>例如：0000000000 与0000011111的海明距离为5</li>\n</ul>\n<p>结论</p>\n<ul>\n<li>如果两个码字的海明距离为d，则需要d个单比特错就可以把一个码字转换成另一个码字；</li>\n<li>为了检查出d个错，需要使用海明距离为 d + 1 的编码；</li>\n<li>为了纠正d个错，需要使用海明距离为 2d + 1 的编码。</li>\n</ul>\n<p>m个信息位，r个校验位，纠正单比特错 (n&#x3D;r+m)</p>\n<p>对 $2^m$ 个任何有效信息中的任何一个，有 $n$ 个与其距离为 1 的无效码字，因此有</p>\n<div>$$\n(n + 1)2^m \\le 2^n\n$$</div>\n\n<p>利用 $n &#x3D; m + r$，得到 $m + r + 1 \\le 2^r$，给定 m，利用上式得到校正单比特误码的校验位数目下界</p>\n<ul>\n<li>码位从左边开始编号，从“1”开始；</li>\n<li>位号为2的幂的位是校验位，其余是信息位；</li>\n<li>每个校验位使得包括自己在内的一些位的奇偶值为偶数（或奇数）</li>\n<li>为看清数据位k对哪些校验位有影响，将k写成2的幂的和。</li>\n</ul>\n<p>汉明码的工作过程：</p>\n<ul>\n<li>每个码字到来前，接收方计数器清零；</li>\n<li>接收方检查每个校验位k (k &#x3D; 1, 2, 4 …)的奇偶值是否正确；</li>\n<li>若第 k 位奇偶值不对，计数器加 k；</li>\n<li>所有校验位检查完后，若计数器值为0，则码字有效；若计数器值为m，则第m位出错。例：若校验位1、2、8出错，则第11位变反。</li>\n</ul>\n<h4 id=\"检错码\"><a href=\"#检错码\" class=\"headerlink\" title=\"检错码\"></a>检错码</h4><p>使用纠错码传数据，效率低。适用于不可重传的场合。</p>\n<p>大多情况采用的检测码加重传。</p>\n<p>二进制多项式</p>\n<p>二进制码串表示成二进制多项式</p>\n<p>循环冗余码（CRC）</p>\n<ul>\n<li>发送方与接收方事前商定。</li>\n<li>生成多项式的高位和低位必须为1</li>\n<li>生成多项式必须比传输信息对应的多项式短</li>\n</ul>\n<p>CRC 的基本思想<br>校验和(checksum)加载帧尾，使带校验和的帧的多项式能被 $G(x)$ 除尽，接收方接受时，用 $G(x)$ 去除它，若有余数，则传输出错。</p>\n<p>校验和计算算法</p>\n<p>设 $G(x)$ 为 $r$ 阶，在帧的末尾加 $r$ 个0，使得帧为 $m + r$ 位，相应多项式为 $x^rM(x)$。</p>\n<p>按照模 2 除法用对应$G(x)$ 的位串去除对应于 $x^rM(x)$减去余数，结果就是要传送的带检验和的多项式 $T(x)$。</p>\n<p>CRC 的检错能力：</p>\n<p>发送方发送 $T(x)$，接收方接受的$T(x) + E(x)$，$E(x) \\ne 0$。</p>\n<p>$(T(x) + E(x)) &#x2F; G(x) &#x3D; 0 + (E(x) &#x2F; G(x))$</p>\n<p>如果$(E(x) &#x2F; G(x))$的余数为0，则差错不能发现；否则可以发现。</p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/5_1.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E8%AE%A1%E7%BD%91/5_2.jpg\" alt=\"alt\"></p>\n<h3 id=\"数据链路层协议\"><a href=\"#数据链路层协议\" class=\"headerlink\" title=\"数据链路层协议\"></a>数据链路层协议</h3><h4 id=\"无约束单工协议\"><a href=\"#无约束单工协议\" class=\"headerlink\" title=\"无约束单工协议\"></a>无约束单工协议</h4><ul>\n<li>工作在理想情况</li>\n<li>单工传输</li>\n<li>发送方无休止工作（要发送的信息无限多）</li>\n<li>接收方无休止工作（缓冲区无限大）</li>\n<li>通信线路（信道）不损坏或丢失信息帧</li>\n</ul>\n<p>工作过程</p>\n<ul>\n<li>发送程序: 取数据，构成帧，发送帧；</li>\n<li>接收程序: 等待，接收帧，送数据给高层</li>\n</ul>\n<h4 id=\"单工停等协议\"><a href=\"#单工停等协议\" class=\"headerlink\" title=\"单工停等协议\"></a>单工停等协议</h4><p>协议描述</p>\n<ul>\n<li>增加约束条件：接收方不能无休止接收。<br>解决方案</li>\n<li>接收方每收到一个帧后，给发送方回送一个响应。<br>工作过程</li>\n<li>发送程序：取数据，成帧，发送帧，等待响应帧</li>\n<li>接收程序：等待，接收帧，送数据给高层，回送响应帧。</li>\n</ul>\n<h4 id=\"有噪声信道的单工协议\"><a href=\"#有噪声信道的单工协议\" class=\"headerlink\" title=\"有噪声信道的单工协议\"></a>有噪声信道的单工协议</h4><p>协议描述</p>\n<ul>\n<li>增加约束条件：信道（线路）有差错，信息帧可能损坏或丢失。</li>\n</ul>\n<p>解决方案</p>\n<ul>\n<li>出错重传<ul>\n<li>带来的问题<ul>\n<li>响应帧重复?发送帧头中放入序号</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>重传触发:<ul>\n<li>超时重传 </li>\n<li>什么时候重传?定时器<br>ARQ&#x2F;PAR</li>\n<li>PAR (Positive Acknowledgement with Retransmission）</li>\n<li>ARQ (Automatic Repeat reQuest）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"流量控制-1\"><a href=\"#流量控制-1\" class=\"headerlink\" title=\"流量控制\"></a>流量控制</h3><h4 id=\"滑动窗口协议\"><a href=\"#滑动窗口协议\" class=\"headerlink\" title=\"滑动窗口协议\"></a>滑动窗口协议</h4><p>捎带确认（piggybacking）</p>\n<p><strong>一位滑窗协议</strong></p>\n<ul>\n<li>窗口大小：N &#x3D; 1，发送序号和接收序号的取值范围：0，1；</li>\n<li>可进行数据双向传输，信息帧中可含有确认信息（piggybacking）；</li>\n<li>信息帧中包括两个序号域：发送序号和接收序号<br>（已经正确收到的帧的序号）<br>存在问题</li>\n<li>能保证无差错传输，但是基于停等方式；</li>\n<li>若双方同时开始发送，则会有一半重复帧；</li>\n<li>效率低，传输时间长。</li>\n</ul>\n<h4 id=\"退后n帧协议\"><a href=\"#退后n帧协议\" class=\"headerlink\" title=\"退后n帧协议\"></a>退后n帧协议</h4><h4 id=\"选择重传协议\"><a href=\"#选择重传协议\" class=\"headerlink\" title=\"选择重传协议\"></a>选择重传协议</h4>"},{"title":"笔记-数据与算法","date":"2022-09-13T02:01:08.000Z","katex":true,"_content":"\n# 相关资源\n\n[Princeton _Algorithm 4th Edition_](https://algs4.cs.princeton.edu/home/)\n\n# 课程说明\n\n## 课程内容\n\n数据处理，数学模型，算法分析\n\n非数值问题：\n\n数据结构：线性表，栈，队列，串，树，图\n\n非数值算法：查找，排序\n\n数值问题：\n\n误差分析\n\n线性方程组\n\n非线性方程\n\n拟合与插值\n\n最优化初步\n\n算法设计：蛮力，分治、减治、贪心、动态规划、搜索算法\n\n# 绪论\n\n## 数据与算法\n\n## 数学模型\n\n对于现实世界的某一特定对象，为特定目的而得到的一个抽象的简化的数学结构。\n\n### 算法\n\n算法是问题的程序化解决方案。\n\n算法强调精确定义的求解过程，并不是问题的答案。\n\n设计实现算法，并没有得到答案，但是给出了一般的解决方案。\n\n一个算法能够解决很多看似好无关系的问题，只要这些问题可以抽象为某种相同的算法。\n\n### 数据\n\n数据是客观世界的描述。\n\n数据是信息的载体，是算法处理的对象。\n\n算法是处理数据的系统。\n\n人的因素也被纳入了数学模型的和算法。\n\nIBM Watson\n\n## 算法分析和算法设计\n\n### 算法及其特性\n\n算法的五个重要特性：\n\n有穷性：一个算法必须可以在有穷步之后结束，且每一步可以在有穷时间内完成\n\n确定性：算法的描述无歧义，算法的执行结果是确定的且精确地符合要求或期望\n\n可行性：算法中描述的操作都可以通过已经实现的基本操作运算的有限次执行来实现\n\n输入：一个算法有零个或多个输入，这些输入取自某个特定的对象集\n\n输出：一个算法有一个或多个输出，输出量是算法计算的结果\n\n### 算法的评价\n\n#### 正确性\n\n不含语法错误\n\n几组一般的输入数据\n\n精心选择的、典型、苛刻且带有刁难性的输入数据（衡量标准）\n\n一切合法的输入数据\n\n#### 健壮性\n\n输入的数据非法\n\n#### 可读性\n\n描述清楚，便于理解\n\n#### 高效率\n\n占用的空间和时间资源\n\n### 算法效率的衡量方法\n\n和算法执行时间相关的因素有很多。\n\n一个特定算法运行工作量的大小，是问题规模的函数。\n\n#### 渐进时间复杂度\n\n算法的渐进时间复杂度(Time Complexity): $T(n) = O[f(n)]$\n\nBig-O 记号的形式化定义\n\n- 若 f(n)是正整数 n 的一个函数，则$x_n = O[f(n)]$表示存在正的常数$M$和$n_0$， 使得当$n > n_0$时，都满足$|x_n| \\le M|f(n)|$\n- 标记的是算法效率的上限\n\n##### 算法效率估算方法\n\n- 算法执行的时间 = Σ 操作的执行次数 × 操作的执行时间\n- 算法操作包括**控制操作**和**原操作**<br>一般来说，相比于循环体，控制操作本身的复杂度可被忽略。而在原操作中，我们又可以寻找其中执行次数最多的一种或几种操作，这些操作被称为基本操作。\n- 选取算法中的**基本操作**\n- 算法的执行时间与**基本操作执行次数之和**成正比\n\n##### 描述指标\n\n- 最好情况(best-case)：对于任何一个输入的运行时间下限\n- 最坏情况(worst-case)：对于任何一个输入的运行时间下限\n- 平均(average-complexity): 根据各种操作出现概率的分布进行加权平均\n- 分摊(amortized complexity): 连续实施足够多次操作，总成本摊至单次操作\n\n最重要的是平均情况下的性能\n\n##### 引入大 O 表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\n\n##### 迅速找到会被多次反复执行的基本操作\n\n##### 感兴趣的复杂度形式非常有限\n\n##### 按照对数坐标画图\n\n#### 空间复杂度\n\n##### 算法空间\n\n- 指令空间(instruction space): 用来存储程序指令所需的空间\n- 数据空间(data space): 存储运行过程中常量和变量所需的空间\n- 环境空间: 系统为程序运行，特别是函数调用提供的空间\n\n##### 算法的渐进空间复杂度: $S(n) = O[f(n)]$\n\n##### 输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\n\n### 数据结构\n\n#### 数据元素和数据项\n\n数据元素(Data Element): 数据的最小单位\n\n数据项：(Data Item): 数据结构中讨论的最小单位\n\n#### 数据结构是带结构的数据元素的集合\n\n逻辑结构：集合，线性结构，树结构，图结构\n\n存储结构：顺序存储，链式存储\n\n#### 二元关系\n\n##### 定义\n\n定义：设有几何$M, N$, 其笛卡尔积$M \\times N$的任意一个子集$R \\in M \\times N$\n\n二元关系表示了集合$M$和集合$N$中元素之间的某种相关性。\n\n若$(a, b) \\in R$, 则称$a$为$R$的前件，$b$称为$R$的后件。\n\n若$M = N$, 则称$R \\sub M \\times M$为 M 上的二元关系。\n\n##### 二元关系的性质\n\n设$R$为集合$M$上的一个二元关系：\n\n(1) 自反性：对于每个$a \\in M$, 有 $(a, a) \\in R$;\n\n反自反性： 对于所有$a \\in M$, 有$(a, a) \\notin R$;\n\n(2) 对称性：当$(a, b) \\in R$时，则$a = b$;\n\n反对称性：当$(a, b) \\in R$且$(b, a) \\in R$时，必有$a = b$;\n\n(3) 传递性： 当$(a, b) \\in R$且$(b, c) \\in R$ 时， 必有$(a, c) \\in R$。\n\n##### 常见的二元关系\n\n等价关系：满足自反性、对称性、传递性\n\n偏序关系：满足自反性、反对称性、传递性\n\n全序关系：若$M$中的任意两个元素$a$和$b$是可比的，也就是说或者有$aRb$成立，或者有$bRa$成立，则称$R$是集合$M$上的全序关系(Totala Order Relation)\n\n#### 数据类型(Data Type)\n\n##### C 语言中的类型定义\n\n五种基本数据类型：字符型，整型，浮点型，双精度浮点型和无值类型\n\n程序中任何变量，常量都必须先定义类型。\n\n整数类型 int 及定义在其上的操作：+, -, \\*, /, %, ++, --\n\n双精度浮点型 double 及定义在其上的操作：+, -, \\*, /, ++, --\n\n###### 数据类型用来刻画(程序)操作对象的特性\n\n数据类型是一个元素的集合和定义在此集合上的一组操作的总称。\n\n数据类型实现了信息的隐藏，把一切用户无需了解的细节封装在类型中。\n\n高级语言中的数据类型分为原子类型和结构类型。\n\n#### 抽象数据类型(Abstract Data Type, ADT)\n\n是指一个数学模型以及定义在此数学模型上的一组操作。\n\n数据抽象：描述的是实体的本质特征、功能以及外部用户接口\n\n数据封装：将实体的外部特性和内在实现细节发呢里，对外部用户隐藏内部实现细节，使得应用和实现分离\n\nADT 的优点：\n\n- 程序结构清晰，易于扩展易于维护而不失其效率\n- 提高程序的数据安全性\n- 大大增加了软件的复用程度\n\n#### 抽象数据类型的描述\n\n```\nADT 抽象数据类型名{\n    数据对象: <数据对象的定义>\n    数据关系: <数据关系的定义>\n    基本操作: <基本操作的定义>\n    基本操作名(参数表)\n        初始条件: <初始条件描述>\n        操作结果: <操作结果描述>\n}ADT 抽象数据类型名\n```\n\n基本操作参数:\n\n- 赋值参数提供输入值\n- 引用参数以&打头，用于返回操作结果\n\n# 数据结构\n\n## 线性表\n\n线性表的元素可以是各种各样的，但是同一线性表的元素必然具有相同特性-同质\n\n线性表中的相邻元素之间存在有序关系-位序\n\n线性表是一种“有序结果”，即在数据元素的非空有限集合中\n\n- 存在唯一的一个被称为“第一个”的数据元素，无前驱；\n- 存在唯一的一个被称为的“最后一个”的数据元素，无后继；\n- 除第一个之外，每一个数据元素均只有一个直接前驱；\n- 除最后一个之外，每个数据元素均只有一个直接后继\n\n线性表中元素个数定义为线性表的长度\n\n$$(a_0, a_1, \\dots, a_{i-1}, a_i, a_{i+1}, \\dots, a_{n-1})$$\n\n若线性表为空，则其长度为 0，称为空表\n\n在非空表中，每个数据元素都有一个确定的位置\n\n- $a_0$是第 0 个数据元素，$a_{n-1}$是第$n-1$个数据元素\n- $a_i$是第 i 个数据元素\n- 称 i 为数据元素$a_i$在线性表中的位序\n\n## 线性表 ADT\n\n```Java\nADT List{\n    数据对象:\n    数据关系:\n    基本操作：\n    InitList(&L);\n        操作结果：构造一个空的线性表L。\n    DestroyList(&L);\n        初始条件：线性表已存在。\n        操作结果：销毁线性表L。\n    IsEmpty(L);\n        初始条件：线性表已存在。\n        操作结果：若L为空表，则返回TRUE，否则返回FALSE。\n    ListLength(L);\n        初始条件：线性表L已存在。\n        操作结果：用e返回L中第i个数据元素的值\n    GetElem(L, i, &e);\n        初始条件：线性表L已存在。\n        操作结果；用e返回L中第i个数据元素的值。\n    LocateElem(L, e, compare());\n        初始条件：线性表L已存在，compare()是数据元素判定函数。\n        操作结果：返回L中第1个与e满足关系compare()的数据元素的位序。若这样的元素不存在，则返回-1。\n    PriorElem(L, cur_e, &pre_e);\n        初始条件：线性表L已存在。\n        操作结果：若cur_e是L的数据元素，且不是最后一个，则用next_e返回它的后继，否则操作失败，next_e无定义。\n    ClearList(&L);\n        初始条件：线性表L已存在；\n        操作结果：将L重置为空表。\n    ListInsert(&L, i, e);\n        初始条件：线性表L已存在, 0 <=i <= ListLength(L)。\n        操作结果：在L中第i个位置插入新的数据元素e，L的长度加1。\n    ListDelete(&L, i, &e)\n        初始条件：线性表L已存在，0 <= i <= ListLength(L) - 1。\n        操作结果：删除L的第i个数据元素，用e返回其值，L的长度减1。\n    ListTraverse(L, visit());\n        初始条件：线性表L已存在。\n        操作结果：依次对L的每个数据元素调用函数 visit()。\n\n```\n\n线性表的合并：$O(m+n)$\n\n线性表的保序归并：$O(m+n)$\n\n线性表的顺序存储：顺序表\n\n- 用一组地址连续的存储单元依次存储线性表的数据元素\n\n顺序表的主要操作：\n\n插入操作：在顺序表的第 i 个位置插入一个新元素，使顺序表的长度增加到$n+1$\n\n复杂度分析：\n\n- 在顺序表的第$i$个位置插入一个新元素，需要移动$n - i$个元素；\n- 假设从顺序表的第$i$个位置插入元素的先验概率为$p_i$\n- 插入操作移动元素次数的期望为$E_{insert} = \\sum_{i = 0}^n(n - i) \\times p_i$\n\n删除操作：把顺序表的第$i$个位置的元素从表中删除，使长度为$n$的顺序表的长度变为$n - 1$\n\n复杂度分析：\n\n- 把顺序表的第$i$个位置上的元素删除，需要移动$n - i -1$个元素\n- 假设从顺序表的第$i$个位置删除元素的先验概率为$q_i$\n- 删除操作移动元素次数的期望为: $E_{delete} = \\sum_{i = 0}^{n - 1}(n - i - 1) \\times q_i$\n\n不失一般性，我们假设插入或删除元素出现在任何位置的概率都是相等的，因此有$p_i = p = 1/(n+1), q_i = q = 1/n$。\n\n推导得到：\n$$E_{insert} = \\frac1{n+1}\\sum_{i = 0}^n(n-i) = \\frac n2\\newline E_{delete} = \\frac1n\\sum_{i = 0}^{n - 1}(n - i - 1) = \\frac{n - 1}2$$\n\n## 单向链表\n\n最简单的链表结构：链表节点(node)由两个域组成。\n\n数据域：存储数据元素，\n\n指针域：指向直接后继节点\n\n单向链表的 C++实现：\n\n```C++\nclass LinkList {\nprivate:\n    NODE *head;\npublic:\n    LinkList() {head = NULL;}\n    ~LinkList();\n    bool clearSqList();\n    bool IsEmpty(){return head ==  NULL;}\n    bool GetElem(int i, int *e);\n    int LocateElem(int e);\n    bool PriorElem(int cur_e, int *next_e);\n    bool NextElem(int cur_e, int* pre_e);\n    bool Insert(int i, int e);\n    bool Delete(int i, int *e);\n    bool Traverse(bool (*visit)(int e));//遍历所有节点\n}\n\n```\n\n单向链表的不足：\n\n* 单链表的表长是一个隐含的值，遍历链表才能得到\n* 在单链表中插入或者删除元素时，需要在链表中依序寻找操作位置\n* 在链表中，元素的“位序”概念淡化，结点的“位置”概念强化\n* 如何得到某个元素的前驱？\n\n改进链表的设置：\n\n* 增加“表长”、“表尾指针”和“当前位置指针”三个数据域\n\n* 将基本操作中的“位序i”改为“指针p”\n\n## 双向链表\n\n由数据，前驱和后继构成。\n\n方便寻找前驱，但是增加了维护成本。\n\n## 顺序表和链表的比较：\n\n顺序表\n\n用一组地址连续的存储单元依次存储线性表中的数据元素\n\n优点：可以随机存取\n\n缺点：插入，删除操作需要移动表中的数据元素，事先确定规模，空间效率不高。\n\n链表：\n\n用一组“任意”的存储单元（附加指针）存储表中的数据元素\n\n优点：插入，删除操作无需移动表中的数据元素，空间利用率高\n\n缺点：不能随机存取\n\n## 栈\n\n栈是LIFO(Last In First Out，先进后出)的线性表。\n\n允许插入和删除的一段称为栈顶(top), 另一端称为栈底(bottom)\n\n### 栈的ADT\n\n~~~C++\n{\n    Push(&s, e);\n    Pop(&s, &e);\n    ClearStack(&s);\n} ADT Stack;\n~~~\n\n### 栈的表示和实现\n\n栈的顺序表示\n\ntop指向最后一个元素可以，指向空也可以，但是实现时要自洽。\n\n栈的链式表示\n\n有头插入和尾插入两个方式\n\n总体来看，头插入比尾插入的优势要更大。首先，插入时虽然头插入要修改的指针更多，但是时间复杂度小，头插入$O(1)$，尾插入$O(n)$。其次，如果以尾部为栈顶，删除时会很麻烦。\n\n**静态分配**\n\n```C++\n#define STACK_MAX_SIZE 100\n```\n**动态分配**\n\n程序隐含设定\n\n```C++\n#define STACK_INT_SIZE 100\n#define STACKINCREMENT 10\n```\n\n用户给定\n\n### 复杂度分析\n\n顺序栈的效率分析\n\n时间复杂度\n\n* 进栈、出栈:$O(1)$\n* 栈的溢出处理\n* 如果栈元素时简单数据类型，则构造和销毁函数也是$O(1)$的\n\n空间复杂度\n\n* 顺序栈的长度构造时确定\n* 空间利用效率低\n\n链式栈的效率分析\n\n时间复杂度\n\n* 链式栈的入栈出栈是$O(1)$时间的\n* 建立和销毁是$O(n)$时间的\n\n空间复杂度\n\n* 一般不会产生溢出\n* 空间利用率高\n\n### 栈的一些应用\n\n显式应用：括号匹配，表达式求值，迷宫求解\n\n隐式应用：函数调用，递归\n\n系统栈\n\n## 递归\n\n栈与递归具有相似性。\n\nFibonacci的递归次数：$C(n) = O(t^n)$\n\n(证明思路：归纳法证明$C(n) = 2F(n) - 1$, 根据F(n)通项可以判断。)\n\n使用递推法的时间复杂度：$O(n)$.\n\n经常需要进行递归的消除。消除方法：递推，循环等，没有统一的解决方案。可以借用显式栈实现非递归过程。\n\n递归的评价：\n\n* 简洁，便于理解，便于叙述和设计\n* 运行效率低，无法控制递归堆栈的规模\n\n## 队列\n\n队列是FIFO(First In First Out, 先进先出)的线性表。\n\n### 队列的表示和实现\n\n队列的顺序表示法\n\n入队: rear = rear + 1\n\n出队: front = front + 1\n\n需要判定队满和队空。\n\n顺序队列的问题：被出队的空间不会再次被使用了。\n\n循环队列：\n\n队尾指针指向maxSize - 1时， 入列则指向0；\n\n队头指针指向maxSize - 1，出列也指向0。\n\n可以使用模运算实现。\n\n缺点：无法区分队空和队满的状态。\n\n区分方法：\n\n设置一个空位；设置标志；设置队列长度变量\n\n队列的链式表示法\n\n入队不会出现队满的问题，出队可能回有队空的问题，队空的条件为front = NULL.\n\n## 串\n\n串是有线长度的字符序列。\n\n串的长度是字符个数。\n\n字符在串中的位置。\n\n两个串相等的条件。\n\n子串和主串，子串在主串中的位置。\n\n### 匹配算法\n\nBrute-Force算法：一个一个比。复杂度最高O(m * n)。\n\nKMP算法：尽可能跳过更多不必要的匹配。复杂度最多O(m + n)。\n\nHorspool算法：启发式算法。复杂度低则O(m/n)，高则O(m * n + s)，s为字符表规模\n\nBoyer-Moore算法：最坏O(n)。KMP和Horspool的综合（或者说Horspool是BM算法的简化版本。）\n\n## 树与二叉树\n\n### 树\n\n空树，子树。\n\n结点（node）是树的基本单位。\n\n结点的度(degree)：结点的子树个数。\n\n树的度：结点度的最大值。\n\nk叉树：树的度为k\n\nchild, parent, cousin, ancestor, descendant\n\ndepth/height\n\n树的性质：\n\n1. 树中结点数等于所有结点度数和加一\n2. k叉树第i层至多$k^{i - 1}个结点$\n3. 深度为h的k叉树至多有$(k^h - 1)/(k - 1)$个结点\n4. 具有n个结点的k叉树的最小深度为$[\\log_k(n(k - 1) + 1)]$\n\n### 二叉树\n\n二叉树是结点的一个有限集合，该集合或者为空，或者是由一个根节点加上两棵分别称为左子树和右子树的、互不相交的二叉树组成。\n\n二叉树的性质：\n\n1. 叶子结点数 = 度为二的结点数 + 1\n2. 第i层至多$2^{i - 1}$个结点\n3. 深度为h，则最多有$(2^h - 1)$个结点\n4. 具有n个结点的完全二叉树的深度为$\\lceil\\log_2(n + 1)\\rceil$\n5. 对于完全二叉树（最后一层从右向左缺若干结点），从左向右，从上到下编号，则$\\lfloor(i - 1)/2\\rfloor$为编号i的parent结点，$2i + 1$为其左子树，$2i + 2$为其右子树。\n\n二叉树的顺序表示\n\n完全二叉树按照编号存储。不完全二叉树按照它对应的完全二叉树存储，但是缺少的部分留空。\n\n不完全二叉树结点越少，空间效率越低。\n\n二叉树的链式表示\n\n空间效率很高。\n\n二叉树的遍历：\n\n记根节点为V，遍历左子树为L，遍历右子树记为R\n\n先序遍历：V - L - R\n\n中序遍历：L - V - R\n\n后序遍历：L - R - V\n\n遍历可以通过递归实现，但是递归可能会对效率产生影响。可以利用栈的特性实现遍历。\n\n层序遍历：从上到下优先遍历同一层的结点。\n\n遍历实现了树的线索化过程。\n\n### 霍夫曼树\n\n霍夫曼树：寻找加权路径长度(WPL)的最小树。\n\n用途：实现性能最好的变长二进制编码。\n\n霍夫曼编码不是唯一的，但是所有霍夫曼树的WPL都相等。\n\n不足：\n\n没有错误保护功能\n\n### 二叉树的建立\n\n只知道二叉树的先序序列，不能确定这棵二叉树。\n\n但是如果同时知道先序序列和中序序列，则可以确定这棵二叉树。\n\n## 图\n\n### 概念\n\n图的定义\n\n顶点，边，弧\n\n邻接顶点\n\n有向图，无向图\n\n有向完全图，无向完全图\n\n子图\n\n握手定理，度\n\n权，网络\n边上的数叫做权。有权的图叫网络。\n\n连通\n\n连通图\n\n连通分量\n无向图的极大连通子图为连通分量。（所谓极大，就是再加入一个点都会导致它不连通）\n\n强连通图\n有向图中存在vi到vj且存在vj到vi的图。\n\n强连通分量\n有向图的极大强连通子图为强连通分量。\n\nEuler路径和Euler回路\n\n图的存储和表示\n\n邻接矩阵表示\n如果v和w之间有边，则元素为1，否则为0.\n\n邻接表表示\n采用链表数组表示图。同一个顶点发出的边在同一个链表中。\n\n### 图的遍历\n\n深度优先遍历和广度优先遍历\n\n图的遍历：从已给连通图的某一顶点出发，沿着一些边访问所有顶点，且每个顶点只访问一次，则叫做图的遍历。\n\n邻接矩阵的遍历：$O(v^2)$\n\n邻接表的遍历：$O(v + e)$\n\n### 生成树\n\n连通图的生成树，包含图中全部n个顶点，但只有n-1条边。\n\n深度优先和广度优先遍历分别会得到一个搜索树。\n\n最小生成树：权值之和最小的生成树。\n\n求最小生成树的算法：贪心算法思想。Kruskal算法和Prim算法。\n\nPrim算法\n\n![](../images/DSA/Prim.jpg)\n\nPrim算法的时间复杂度为$O(n^2)$。对稠密图而言是线性的。对于稠密图而言，Prim的邻接矩阵实现是首选方法。\n\nKruskal算法\n![](../images/DSA/Kruskal.jpg)\n\nKruskal的时间复杂度为$O(E\\log E)$。\n\nKruskal算法对于稀疏图是好的选择。\n\n### 最短路径树\n\n从根到其他顶点的最短路径\n\n源点-汇点最短路径：给定一个起始顶点s和一个结束顶点 ，在图中找出从s到t的一条路径。起始顶点称为“源点”，结束顶点称为“汇点”\n\n单源最短路径：给定一个起始顶点s，找出从s到图中其它各顶点的最短路径\n\n全源最短路径：找出连接图中各对顶点的最短路径\n\n#### 单源最短路径\n\nDijkstra算法\n\n![](../images/DSA/Dijkstra.jpg)\n\nDijkstra算法通过构造加权有向图图的最短路径树SPT，来实现单源最短路径算法。\n\n时间复杂度为$O(v^2)$，和Prim算法很相似。\n\n#### 全源最短路径\n\n可以对每个顶点用Dijkstra算法。\n\nFloyd算法\n\n时间复杂度：$O(v^3)$。可以计算出一个网络中所有的最短路径。\n\nFloyd算法允许图中带有负权值的边，但不允许有包含带负权值的边组成回路。\n\n# 算法\n\n## 非数值算法\n\n### 查找\n\n查找算法的复杂性：关键字/数据规模\n\n查找算法的分类：\n* 内部/外部\n* 静态/动态\n\n#### 查找表\n\n查找表（Search Table）是由同一类型数据元素构成的集合。\n\n按关键字查找\n1. 查询某元素是否存在\n2. 检索某数据元素的各种属性\n3. 在查找表中插入一个数据元素\n4. 从查找表中删除一个数据元素\n\n查找表的种类\n1. 静态查找表-仅可执行1,2\n2. 可执行1,2,3,4\n\n平均查找长度：在查找过程中，为确定目标在查找表中的位置，需要进行关键字比较次数的期望值\n\n$$\nASL = \\sum_{0}^{n - 1}P_i C_i\n$$\n\n$P_i$为第i条记录的查找概率，$C_i$为第i条记录的查找长度。\n\n有时我们会假设查找概率相等或不等，有时要考虑查找失败的比较次数。\n\nASL越小，查找性能越好。\n\n顺序查找：又称线性查找，是从线性\n表的一端开始，依次把每个元素的\n关键字同给定值进行比较\n\n假设每个元素的查找概率相等，则平均查找长度为：$ASL = \\sum_0^{n - 1}\\frac{i + 1}{n} = \\frac{n + 1}{2}$。\n\n更多考虑：查找概率不等；查找失败需要N次比较；越界判断\n\n折半查找：如果顺序表有序，我们可以采用高效率的折半查找\n\n折半查找可以用一个二叉树结构来表述。比较次数不会超过$\\lfloor\\log_2 N + 1\\rfloor$。\n\n索引查找：将线性表划分为若干子表，再建立指向这若干子表的一个索引表。相同性质的数据归类到一个子表中。\n\n索引表：顺序表或链表\n\n子表：顺序表或链表\n\n因而可以有四种不同的索引存储方式。\n\n索引表的特点：表不大， 表中元素不常变动。因而适合用顺序表来表示索引表。\n\n分块查找：也称索引顺序查找，是顺序查找的改进。子表之间有序；块内元素无序。索引表包括关键字项，指针项，子表长度。\n\n索引文件：单关键字，多关键字。\n\n稠密索引：索引表的索引项和主文件的各记录一一对应，称为稠密索引。\n\n稀疏索引（非稠密索引）：索引项对应主文件的一部分记录。\n\n索引文件的好处：减少访问外存的次数，提高查找速度。\n\n倒排文件：不同之处是辅索引表包含物理地址序列。（为什么要倒排？）\n\n#### 二叉搜索树（BST）\n\n或者是一棵空树，或者是具有下列性质\n的二叉树：每个结点有一个关键字(key)，\n并且:\n1. 任意结点关键字大于等于该结点左\n子树中所有结点含有的关键字\n2. 同时该结点的关键字小于等于右子\n树中所有结点含有的关键字\n\nBST是一种重要的动态搜索结构。它的中序遍历是确定的。 \n\nBST的插入操作和查找操作同样简单。\n\n\n删除操作比较复杂。叶子结点的删除比较简单；如果结点只有一棵子树，也比较简单；如果左右子树都不空，可以用中序后继替换。\n\nBST的性能：越“平衡”越好。\n\n二叉搜索树的路径长度和高度直接关系到BST中搜索的开销，对于一棵\n含有N个关键字的BST\n* 最好情况下，所有搜索都可以保证对数运行时间\n* 最坏情况下，进行一次搜索需要 次比较\n* 平均情况下搜索需要 次比较操作\n\nBST的旋转操作：结点和一个子孙交换角色。分为左旋转和右旋转。右旋转涉及到结点和右孩子。（右旋转和左旋转是以结点自己作为参考系而言。）\n\nBST通过不断的旋转来保证自己的平衡性。\n\nAVL树：\n一棵AVL树或者是空树，或者是具有下列性质的二叉搜索树:\n1. 左子树和右子树都是AVL树\n1. 且左子树和右子树的高度之差的绝对\n值不超过1\n\nAVL的高度为$O(\\log_2 n)$，平均查找长度也为$O(\\log_2 n)$。\n\nAVL具有良好的搜索性能，能够避免一般BST性能恶化的问题。但是AVL的维护比较复杂，在进行插入和删除操作后，都必须通过大量的旋转操作保证AVL的平衡性。\n\n寻找其他方法，以提高BST的平衡程度，保证BST的性能。\n\n* 实用的平衡二叉搜索树-红黑树\n\n* 多路平衡的动态查找结构-B-树\n\n#### 散列\n\n散列的关键是散列函数和冲突处理。\n\n散列函数应是简单的，能在较短的时间内计算出结果\n\n散列函数的定义域必须包括需要存储的全部关键码，如果散列表允许有m\n个地址，其值域必须在0到m-1之间\n\n理想的散列函数应近似为随机的，对每一个输入，相应的输出在值域上是\n等概的。\n\n冲突处理：\n\n* 链地址法：把散列到同一个地址的关键字存进链表中。（表长小于元素数目）\n* 开放定址法：放在表中空的位置。查找时采用“探测”的方法。如果探测下一个位置，称为线性探测。（表长大于元素数目，稀疏表，一般不允许表达到半满状态）\n* 双重散列法：用第二个散列函数表达散列的增量。时间复杂度略大，但是性能比线性探测好很多。\n\n散列的其他应用：字符串的匹配；搜索引擎对URL的散列；信息安全中的内容鉴别技术（MD5, sha）。\n\n散列提供常数时间的查找性能，实现简单；但是好的散列函数不易找到，删除操作和空间性能不好，最坏情况下性能不好，忽略了数据间的逻辑关系。\n\n### 排序\n\n排序算法的稳定性：如果两个对象的排序码相等，排序前后的顺序不变，则是稳定的；否则是不稳定的。\n\n内排序：数据对象存放在内存。\n\n外排序：数据对象在内、外存之间移动。\n\n冒泡排序：复杂度为$O(n^2)$。添加排序标记，最好情况下只需要$n - 1$次比较和0次交换。\n\n插入排序：有直接插入，折半插入，希尔排序\n\n直接插入：$O(n^2)$\n\n折半插入：查找插入位置的时候可以采用折半查找，因为表中可以插入的部分已经排好序了。复杂度没有变化，依然是$O(n^2)$\n\n希尔排序：如果序列中，间距为h的元素都有序，称这个序列为h-排序的。希尔排序就是不断缩小h，直到h=1。\n\n选择特定的步长序列$h_n$，取出序列中增量为$h_n$的子列进行插入排序。然后取$h_{n-1}$，直至取$h_1=1$。\n\n它在h比较大的时候排序，由于间距短，速度快；而h小的时候，由于有序性强，速度快。总体速度依赖于步长序列的选择，时间复杂度比直接插入好一些。\n\n选择排序：比较次数$O(n^2)$，移动次数$O(n)$，移动次数少一些。\n\n冒泡排序和插入排序都是稳定的，而选择排序是不稳定的。\n\n**快速排序**：一种交换类排序。具有很好的性能。\n\n将待排序序列分为两个部分，满足：\n1. a[i]位于它在序列中的正确位置\n2. 前面的元素比a[i]小\n3. 后面的元素比a[i]大\n然后对两个部分继续划分，每次划分都将一个元素划分到它的正确位置。\n\n如何划分：\n\n选择划分元素v。从序列左边扫描，找到一个比v大的元素，从右边扫描，找到一个比v小的元素，交换两个元素。反复交换，直到左右扫描指针相遇，则划分完成。\n\n快速排序的递归树是一颗二叉搜索树，因为每次递归都是对比自己大和比自己小的两个部分递归。\n\n时间复杂度：理想情况下$O(N\\log_2N)$，如果递归树是平衡的。平均情况下为$O(N\\log N)$，而最坏情况下退化为$O(N^2)$。\n\n快速排序是不稳定的排序算法。\n\n改进：\n\n划分元素是最大或者最小的元素时是最坏情况。为了避免最坏情况，采用中间元素法：取序列的左端元素，右端元素和中间元素，选择关键字处于中间的元素作为划分元素。\n\n快速排序中，子序列非常小时仍然要递归调用，可以采用插入排序代替，提高效率。\n\n归并排序：合并有序表。两个表的归并，叫二路归并。利用二路归并可以实现归并排序。\n\n自底向上归并：将文件分割成长度为m的子序列，每次m翻倍。\n\n自顶向下归并：将文件分割为两个部分，分别进行递归的归并排序后再合起来进行归并排序。\n\n归并排序是稳定的，时间最好情况是$O(N\\log N)$，最坏是$O(N^2)$.\n\n堆：堆是满足堆性质的完全二叉树。\n\n最大堆：任意节点的值小于父节点的值。\n\n最小堆；任意节点的值小于父节点的值。\n\n因为是完全二叉树，适合用顺序存储方式。\n\n堆：顺序存储在一维数组中。\n\n堆的操作，例如插入，删除或者修改结点会破坏堆的性质，因此修复堆是重要的操作。\n\n对于最大堆，如果某结点的关键值小于其子节点的关键值，可以采用自顶向下堆化(Heapify-down)的算法进行修复。\n\n对于最大堆，若结点的关键值大于父节点的关键值，采用自底向上堆化(Heapify-up的算法进行修复)\n\n向堆中插入结点：在新节点插入堆尾，调用自底向上算法调整堆。这种构造堆方法称为自顶向下的堆构造。\n\n自顶向下的堆构造：$O(N\\log N)$\n\n自底向上的堆构造：时间复杂度$O(N)$\n\n自底向上构造复杂度小的原因：离根远的复杂度小，离根近的复杂度大。而自顶向下是离根远的复杂度大，离根近的复杂度小。离根远的数量多，而离根近的数量少，因此自底向上的整体的复杂度更小。\n\n优先级队列可以用堆实现，性能非常好。\n\n堆排序：节约空间，比较次数和移动次数都是$O(N\\log N)$。堆排序是不稳定的排序方法。\n\n从小到大排序的方法：自底向上构造最大堆。将堆首与堆尾交换，堆序列长度-1，调整堆，再次交换，重复上述过程，直到堆空。\n\n>堆排序大概可以理解成优先队列的出队过程。\n\n采用决策树的方法可以求得比较次数的下界为$O(N\\log N)$\n\n## 数值算法\n\n### 基础\n\n一个数值问题是适定的(well posed)，需要满足：\n* 解存在\n* 解唯一\n* 连续地依赖于问题数据\n\n不满足条件的问题被称为不适定的(ill-posed)。\n\n适定的问题，如果解对输入数据非常敏感，则称之为病态的(ill-conditioned)。\n\n针对适定和良态(well-conditioned)问题，数值分析可以得到具有一定精度的近似解。\n\n数值分析重视误差。误差=计算误差+传播误差，算法影响的是计算误差。误差有模型误差、测量误差、截断误差、舍入误差。\n\n前向误差反映了输出的误差，后向误差反映了输入的误差。相对前向误差与相对后向误差的比值叫做条件数(condition number)。$cond \\le 1$说明问题是良态的；否则是病态的。\n\n实际问题中我们通常求解条件数的估计值或者上限。进而求得前向误差。\n\n相对条件数:$\\left|\\frac{xf^\\prime (x)}{f(x)}\\right|$。绝对条件数：$\\left|f(x)\\right|$\n\n算法的稳定性：如果一个算法对于计算过程中的微小扰动不敏感，则算法是稳定的。\n\n问题的病态性针对输入数据的微小扰动，而算法的稳定性针对的是计算过程中的误差。\n\n最近舍入法：与x最相近的浮点数，如果相等，取最后一个存储位为偶数。\n\n若是偶数，则区间是闭区间；若是奇数，则对应的区间为开区间。\n\n浮点数的下溢限主要由尾数决定，机器精度由尾数决定。\n\n浮点数的表示法:\n\n$$\nx = \\pm \\left(d_0 + \\frac{d_1} \\beta + \\frac{d_2} {\\beta^{2}}+ \\dots + \\frac{d_{p-1}} {\\beta^{p-1} } \\right)\\beta^E\n$$\n\n在正规化浮点数系统中：\n$$\n\\text{UFL}=\\beta_L\\\\\n\\text{OFL}=\\beta^{U+1}(1 - \\beta^{1-p})\\\\\n$$\n\n机器精度：舍入造成的相对误差上限：\n$$\n\\left|\\frac{fl(x) - x}{x}\\right| \\le \\epsilon_{mach}\n$$\n\n最近舍入方式下：\n$$\n\\epsilon_{mach} = \\beta^{1-p} / 2\n$$\n\n### 线性方程求解\n\n解矩阵方程$A\\mathbb x = \\mathbb b$。\n\n误差分析：\n\n条件数：$\\text{cond}(A) = ||A||||A^{-1}||$\n\n直观理解：两条线接近平行的时候，两条线截距的轻微扰动会造成解很大的不确定性。\n\n解方程：\n\n直接求解法\n\n高斯消元法：复杂度$O(n^3)$。通常采用列选主元的方法提高算法的稳定性。\n\nLU分解：如果$b$变化而$A$不变，可以较快地多次求解。\n\n解的精度分析：条件数大，即使残差很小，也会得出极大的计算误差。是因为问题本身非常敏感。\n\n高斯-约当法：把A变换为对角阵。\n\n乔列斯基分解：A是对称正定阵，则A=LL'。\n* 算法是良态的\n* 不需要选主元就有稳定性\n* 只需要存储下三角部分即可\n* 分解的乘法和加法次数都约为$n^3/6$\n\n线性方程的迭代解法：\n\n不动点迭代法：\n\n$$\nAx = b \\Rightarrow x = Gx + C\n$$\n\n不动点迭代的收敛核心在于G。\n\n对于矩阵M，定义谱半径$\\rho(M)$为M的特征值绝对值的最大值。\n\n如果$\\rho(G)< 1$，则不动点迭代收敛。\n\n分裂$A = M - N$，则\n\n$$\n(M - N)x = b\\Rightarrow\\\\\nx = M^{-1}Nx + M^{-1}b\n$$\n\n当$\\rho(M^{-1}N) < 1$时，不动点迭代收敛。\n\nJacobi（雅克比）方法：$A = D + L + U$, $M = D$, $N = - (L + U)$, $x^{k+1} = D^{-1}[b - (L+U)x^k]$。\n\n高斯-赛德方法：\n$A = D + L + U$, $M = D + L$, $N = -U$, $x^{k+1} = (D+L)^{-1}(b - Ux^k)$。\n\n这两种迭代都不一定收敛，但是实际中一般都可以。高斯赛德方法速度比雅克比快一倍。\n\n### 非线性方程求解\n\n误差分析：\n\n非线性方程$f(x) = 0$，真解为$x^*$，近似解为$\\hat x$。\n\n残差：$||f(\\hat x)||$\n\n前向误差：$||\\hat x - x^*||$，能更准确地描述解的精确程度。\n\n绝对条件数：$1/|f^\\prime(x^*)|$\n\n可见，如果f(x)在$x^*$处接近水平，则问题是病态的。\n\n具有重根的问题也是病态的。\n\n解法：\n\n二分法：定义误差$e_k = x_k - x^*$，定义迭代法的收敛速度定义：$\\lim_{k\\rightarrow \\infty}\\frac{||e_{k + 1}||}{||e_k||^r} = C$，则收敛速度为$r$。r=1称为线性的，r>1称为超线性的，r=2称为平方的。二分法的迭代次数与函数的具体形式无关。\n\n不动点迭代法：\n\n收敛性：\n\n$$\n\\lim_{k\\rightarrow \\infty}\\frac{||e_{k+1}||}{||e_k||} \\\\=\\lim_{k\\rightarrow \\infty}\\frac{g(x_k) - x^*}{x_k - x^*} \\\\\n= \\lim_{k\\rightarrow \\infty} g^\\prime (\\xi_k) = g^\\prime(x^*) \n$$\n\n绝对条件数为$g^\\prime(x^*)$。如果$|g^\\prime(x^*)|$非零，则收敛是线性的，如果为0，则是超线性的。\n\n牛顿迭代法：\n\n$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}\n$$\n\n由于$g^\\prime(x^*)=0$，收敛是超线性的。进一步分析得到$\\lim_{k\\rightarrow \\infty}\\frac{x_{k+1} - x^*}{(x_k - x^*)^2} = \\frac{f^{\\prime\\prime}(x^*)}{2f^\\prime(x)}$，因此牛顿法是平方收敛的。\n\n牛顿法的特点：\n* 初值的选取很重要\n* $f^\\prime(x)\\ne 0$\n* 速度快，但是可能出现振荡的情况\n* 对多重根的收敛速度退化为线性\n* 涉及到求导，有时候比较困难\n\n准牛顿法：免去了求导\n\n$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{g_k}\n$$\n\n割线法：准牛顿法的一种\n\n$$\ng_k = \\frac{f(x_k) - f(x_{k - 1})}{x_k - x_{k - 1}}\n$$\n\n反插：割线法是用两次的迭代值确定一条直线，取直线与x轴的交点。可以采用反二次插值：用前三次迭代值确定抛物线$x = p(y)$，取它与x轴的交点。\n\n二分法较安全，但速度慢；迭代法速度快，但不安全。可以在区间较大时采用二分法缩小区间，等区间较小时再采用迭代法。\n\n### 拟合与插值\n\n#### 拟合\n\n如果方程的数目多于未知数的数目，则是超定方程。\n\n如果方程的数目少于未知数的数目，则是欠定方程。\n\n超定方程在线性最小二乘的意义下得到一个近似解。\n\n转而求解$A^TAx = A^Tb$。如果矩阵A是列满秩的，则解唯一。\n\n若$A^TA$是正定的，则有$A = LL^T$。\n\n可以采用QR分解将长方阵A简化：\n\n$$\nA = Q\\begin{bmatrix}\nR\\\\\n0\n\\end{bmatrix}\n$$\n\n进一步，如果$Q = \\begin{bmatrix}Q_1\\\\Q_2\\end{bmatrix}$，则$Rx = Q_1^Tb$。\n\n利用household变换进行QR分解。\n\n正规方程方法的复杂度：$mn^2/2  + n^3/6$\n\nhousehold变换的复杂度：$mn^2 - n^3 / 3$\n\n如果m和n相当，则两种变换的复杂度相当，而m远大于n时，QR分解的复杂度是正规方程方法的两倍。\n\nQR分解的适用性更宽。\n\n#### 插值\n\n插值使得函数精确地通过给定数据点。\n\n单项式基底：$\\phi_j(x) = x^{j - 1}$。给定点数越多的插值问题，病态性越高，插值多项式的系数不稳定。\n\n霍纳法则：$t_1 + x(t_2+x(t_3+(\\dotsb)))$，减少乘法次数。\n\n拉格朗日插值：\n\n$$\nl_j(x) = \\frac{\\prod_{k = 1, k \\ne j}^{n}(x - x_k)}{\\prod_{k = 1, k\\ne j}^{n}(x_j - x_k)}\n$$\n\n* 确定形式容易\n* 计算值困难\n* 微分，积分不方便\n\n牛顿插值：基底取$\\prod_{k = 1}^{j - 1}(t - t_k)$。\n\n* 容易确定，系数较容易求解\n* 计算可以通过类似霍纳法则的方法求得，时间复杂度低\n* 在确定和求值之间形成了较好的平衡。\n\n### 优化问题\n\n分为连续优化问题和离散优化问题。\n\n可行点，约束集合。\n\n#### 连续优化问题\n\n有线性规划和非线性规划问题。\n\n线性规划：不细讲。\n\n非线性规划：\n\n（严格/非严格）全局最小值，局部最小值。全局最小值的求解，甚至验证都很困难。\n\n闭集：闭集是补集为开集的集合。如果一个集合中所有的极限点都是这个集合中的点，则这个集合是闭集。\n\n有界闭集上的连续函数有全局最小值。如果不是闭的或者无界，就可能没有最小值。\n\n$\\lim_{||x||\\rightarrow \\infty} f(x) = \\infty$，称$f(x)$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的。\n\n如果连续函数$f$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的，则$f$在$S$上存在全局最小值。\n\n集合是凸的：任意两点的连线属于这个集合。\n\n函数是凸的：区间内函数值不超过端点连线上的函数值。\n\n如果集合和函数都是凸的，称为凸优化问题。\n\n我们有如下结论：\n* 如果$f$是凸集$S\\sube \\mathbb{R^n}$上的凸函数，则在 $S\\sube \\mathbb{R^n}$的任意内点上连续\n* 凸函数$f$在凸集$S\\sube \\mathbb{R^n}$上的任意局部最小值，都是$f$在$S\\sube \\mathbb{R^n}$上的全局最小值\n* 严格凸函数$f$在凸集 $S\\sube \\mathbb{R^n}$上的局部最小值，是$f$在$S\\sube \\mathbb{R^n}$上的唯一全局最小值\n* 如果$f$在有界闭集$S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一的全局最小值\n* 如果$f$在无界闭集 $S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一全局最小值的充要\n条件是$f$在$S\\sube \\mathbb{R^n}$上是强制的\n\n下面考虑无约束优化：\n\n梯度为0的点是临界点。\n\n临界点可能是局部最大值/最小值/鞍点。\n\n如果函数是凸的，临界点就是全局最小值点。\n\n海森矩阵正定，则f是凸的。\n\n如果$x^*$是函数$f$的最小值，\n则$\\nabla f(x^*) = 0$，$\\nabla^2f(x^*)$非负定。\n\n如果$\\nabla f(x^*) = 0$且$\\nabla^2f(x^*)$正定，则$x^*$是严格局部最小值。\n\n如果是凸优化，则$\\nabla f(x^*) = 0\\Leftrightarrow f(x^*)$为严格局部最小值\n\n矩阵的正定性：\n* 特征值全正\n* Cholesky分解唯一\n* 顺序主子式的行列式全正\n\n拉格朗日乘数法：\n\n$$\n\\mathcal{L}(x, \\lambda) = f(x) + \\lambda^Tg(x)\n$$\n\n海森矩阵：\n\n$$\nH_{\\mathcal{L}}(x, \\lambda) = \\begin{bmatrix}\n    B(x, \\lambda) && J_g^T(x)\\\\\n    J_g(x) && 0\n\\end{bmatrix}\\\\\nB(x,\\lambda) = H_f(x) + \\sum_{i = 1}^m\\lambda_iH_{g_i}(x)\n$$\n\n只要$B(x^*, \\lambda^*)$正定，则$x^*$是极小值点。\n\n敏感性和病态性：依赖于海森矩阵\n* 海森矩阵奇异，则极值问题病态\n* 海森矩阵接近奇异，则极值问题敏感\n\n下面考虑一维优化问题：\n\n单峰函数:最小值左侧递减，最小值右侧递增。\n\n类似于二分法，可以用黄金分割搜索求单峰函数的极小值。\n\n好处：每次迭代只需要更新一个点；安全性好；收敛速度线性；\n\n坏处：收敛速度还可以提高。\n\n方法二：逐次抛物插值。用两个端点和一个近似极值点拟合一条抛物线，取抛物线的最小值点作为新的近似极值点，反复直到收敛。\n\n当初始点接近极值点时能够收敛；收敛是超线性的。\n\n牛顿迭代法：\n$$\nx_{k + 1} = x_k - \\frac{f'(x_k)}{f''(x_k)}\n$$\n\n实际上采用黄金分割搜索和逐次抛物插值混合方案，避免求函数的导数。\n\n多维优化问题：\n\n最速下降法：\n$$\nx_{k + 1} = x_k - \\alpha_k\\nabla f(x_k)\n$$\n\n确定$\\alpha_k$：$\\min_{\\alpha_k} f(x_k - \\alpha_k \\nabla f(x_k))$\n\n非常可靠，只要梯度不为0；速度可能不快，呈之字形；收敛速度线性；初值的选择很重要。\n\n牛顿法：\n$$\nx_{k + 1} = x_k - H_f^{-1}(x_k)\\nabla f(x_k)\n$$\n\n平方收敛，速度快于梯度下降；需要距离最优解很近；不需要搜索参数；如果目标具有连续的二阶偏导数，则海森矩阵对称。\n\n拟牛顿法\n\n$$\nx_{k + 1} = x_k - \\alpha_kB_k^{-1}\\nabla f(x_k)\n$$\n\n## 算法设计思想\n\n### 贪心算法\n\n* 可行性\n* 局部最优\n* 不可取消\n\n不是所有优化问题都能通过贪心算法求解，即使可以使用贪心算法，也不一定能够得到最优解。\n\n如果一个优化问题可以通过局部最优选择得到全局最优解，则说这个问题满足贪心选择性质，此时可以简单高效地求得问题的最优解。\n\n贪心策略可以有很多种。不同的算法有不同的性能。不一定得到全局最优解。\n\n### 动态规划\n\n多阶段动态过程的优化问题\n\n阶段：把问题分成几个相互联系的有顺序的几个环节，这些环节被称\n为阶段\n\n状态：某一阶段的出发位置称为状态。通俗的说状态是对问题在某一\n时刻的进展情况的数学描述\n\n决策：从某阶段的一个状态演变到下一个阶段某状态的选择\n\n条件：最优化原理；无后效性\n\n动态规划用空间换时间，有大量重叠子问题时才能体现它的优势。\n\n例：Floyd算法，Viterbi译码\n\n### 蛮力法\n\n### 分治法\n\n快速排序\n\n分治法：分成若干个小的同类问题\n\n减治法：变成一个更小的同类问题\n\n变治法：变成若干个更简单的问题\n\n### 搜索算法\n\n组合优化问题的解空间指的是搜索答案的过程中搜索过的可行解。\n\n回溯法：没有希望的解就不去搜索。\n\n分支界限法：一边搜索一边给出当前部分解的下界。对于下界比搜索到的可行解还大的分支，不去搜索。下界的估计方法很重要。\n\n回溯法和分支界限法都不能保证求解的效率。\n\n### 随机算法\n\nSherwood算法\n\n快速排序在某些序列下会发生时间复杂度的退化。随机划分元素，可以使得达到最坏复杂度的概率降到很低。\n\n一般地，若确定型算法在最坏情况下的时间复杂度和它在平均情况下的时间复杂度有较大的差异，通过随机性可以消除这种差别。并不是避免这种最坏的情况发生，而是切除这种最坏情况和特定实例之间的联系。\n\nLas Vegas算法\n\n* 随机化决策\n* 减少算法运行的时间\n* 有概率会失败\n* 多尝试几次以提高成功率\n\nMonte Carlo算法\n\n* 概率为基础的统计模拟方法\n* 不保证得到正确的解\n* 设计合理，大量重复可以大概率得到高精度的解\n\n随机投点求面积\n\n一个蒙特卡洛方法得到正确判定的概率不小于p，则算法是p正确的。\n\n如果同一实例不会给出不同的解，称算法是一致的。\n\n对于判定问题，如果能够保证返回true时是正确的，称为偏真的；保证返回false时是正确的，则算法是偏假的。\n\nSherwood:一定得到正确解，一般不会遇到最坏情况\n\nLas Vegas:不一定得到正确解，但如果得到了一定是正确的\n\nMonte Carlo:不一定得到正确解，即使得到了也不一定是正确的\n\n### 算法优化技术\n\n输入增强技术\n\n* 字符串匹配算法\n\n* 计数排序\n\n预构造技术\n\n* 并查集\n\n* 二叉查找树\n\n* 倒排索引\n\n* 堆和堆排序\n\n时空平衡\n\n* 比特逆序\n* 散列\n\n","source":"_posts/DataAndAlgorithms.md","raw":"---\ntitle: 笔记-数据与算法\ndate: 2022-09-13 10:01:08\ntags: note\nkatex: true\n---\n\n# 相关资源\n\n[Princeton _Algorithm 4th Edition_](https://algs4.cs.princeton.edu/home/)\n\n# 课程说明\n\n## 课程内容\n\n数据处理，数学模型，算法分析\n\n非数值问题：\n\n数据结构：线性表，栈，队列，串，树，图\n\n非数值算法：查找，排序\n\n数值问题：\n\n误差分析\n\n线性方程组\n\n非线性方程\n\n拟合与插值\n\n最优化初步\n\n算法设计：蛮力，分治、减治、贪心、动态规划、搜索算法\n\n# 绪论\n\n## 数据与算法\n\n## 数学模型\n\n对于现实世界的某一特定对象，为特定目的而得到的一个抽象的简化的数学结构。\n\n### 算法\n\n算法是问题的程序化解决方案。\n\n算法强调精确定义的求解过程，并不是问题的答案。\n\n设计实现算法，并没有得到答案，但是给出了一般的解决方案。\n\n一个算法能够解决很多看似好无关系的问题，只要这些问题可以抽象为某种相同的算法。\n\n### 数据\n\n数据是客观世界的描述。\n\n数据是信息的载体，是算法处理的对象。\n\n算法是处理数据的系统。\n\n人的因素也被纳入了数学模型的和算法。\n\nIBM Watson\n\n## 算法分析和算法设计\n\n### 算法及其特性\n\n算法的五个重要特性：\n\n有穷性：一个算法必须可以在有穷步之后结束，且每一步可以在有穷时间内完成\n\n确定性：算法的描述无歧义，算法的执行结果是确定的且精确地符合要求或期望\n\n可行性：算法中描述的操作都可以通过已经实现的基本操作运算的有限次执行来实现\n\n输入：一个算法有零个或多个输入，这些输入取自某个特定的对象集\n\n输出：一个算法有一个或多个输出，输出量是算法计算的结果\n\n### 算法的评价\n\n#### 正确性\n\n不含语法错误\n\n几组一般的输入数据\n\n精心选择的、典型、苛刻且带有刁难性的输入数据（衡量标准）\n\n一切合法的输入数据\n\n#### 健壮性\n\n输入的数据非法\n\n#### 可读性\n\n描述清楚，便于理解\n\n#### 高效率\n\n占用的空间和时间资源\n\n### 算法效率的衡量方法\n\n和算法执行时间相关的因素有很多。\n\n一个特定算法运行工作量的大小，是问题规模的函数。\n\n#### 渐进时间复杂度\n\n算法的渐进时间复杂度(Time Complexity): $T(n) = O[f(n)]$\n\nBig-O 记号的形式化定义\n\n- 若 f(n)是正整数 n 的一个函数，则$x_n = O[f(n)]$表示存在正的常数$M$和$n_0$， 使得当$n > n_0$时，都满足$|x_n| \\le M|f(n)|$\n- 标记的是算法效率的上限\n\n##### 算法效率估算方法\n\n- 算法执行的时间 = Σ 操作的执行次数 × 操作的执行时间\n- 算法操作包括**控制操作**和**原操作**<br>一般来说，相比于循环体，控制操作本身的复杂度可被忽略。而在原操作中，我们又可以寻找其中执行次数最多的一种或几种操作，这些操作被称为基本操作。\n- 选取算法中的**基本操作**\n- 算法的执行时间与**基本操作执行次数之和**成正比\n\n##### 描述指标\n\n- 最好情况(best-case)：对于任何一个输入的运行时间下限\n- 最坏情况(worst-case)：对于任何一个输入的运行时间下限\n- 平均(average-complexity): 根据各种操作出现概率的分布进行加权平均\n- 分摊(amortized complexity): 连续实施足够多次操作，总成本摊至单次操作\n\n最重要的是平均情况下的性能\n\n##### 引入大 O 表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\n\n##### 迅速找到会被多次反复执行的基本操作\n\n##### 感兴趣的复杂度形式非常有限\n\n##### 按照对数坐标画图\n\n#### 空间复杂度\n\n##### 算法空间\n\n- 指令空间(instruction space): 用来存储程序指令所需的空间\n- 数据空间(data space): 存储运行过程中常量和变量所需的空间\n- 环境空间: 系统为程序运行，特别是函数调用提供的空间\n\n##### 算法的渐进空间复杂度: $S(n) = O[f(n)]$\n\n##### 输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\n\n### 数据结构\n\n#### 数据元素和数据项\n\n数据元素(Data Element): 数据的最小单位\n\n数据项：(Data Item): 数据结构中讨论的最小单位\n\n#### 数据结构是带结构的数据元素的集合\n\n逻辑结构：集合，线性结构，树结构，图结构\n\n存储结构：顺序存储，链式存储\n\n#### 二元关系\n\n##### 定义\n\n定义：设有几何$M, N$, 其笛卡尔积$M \\times N$的任意一个子集$R \\in M \\times N$\n\n二元关系表示了集合$M$和集合$N$中元素之间的某种相关性。\n\n若$(a, b) \\in R$, 则称$a$为$R$的前件，$b$称为$R$的后件。\n\n若$M = N$, 则称$R \\sub M \\times M$为 M 上的二元关系。\n\n##### 二元关系的性质\n\n设$R$为集合$M$上的一个二元关系：\n\n(1) 自反性：对于每个$a \\in M$, 有 $(a, a) \\in R$;\n\n反自反性： 对于所有$a \\in M$, 有$(a, a) \\notin R$;\n\n(2) 对称性：当$(a, b) \\in R$时，则$a = b$;\n\n反对称性：当$(a, b) \\in R$且$(b, a) \\in R$时，必有$a = b$;\n\n(3) 传递性： 当$(a, b) \\in R$且$(b, c) \\in R$ 时， 必有$(a, c) \\in R$。\n\n##### 常见的二元关系\n\n等价关系：满足自反性、对称性、传递性\n\n偏序关系：满足自反性、反对称性、传递性\n\n全序关系：若$M$中的任意两个元素$a$和$b$是可比的，也就是说或者有$aRb$成立，或者有$bRa$成立，则称$R$是集合$M$上的全序关系(Totala Order Relation)\n\n#### 数据类型(Data Type)\n\n##### C 语言中的类型定义\n\n五种基本数据类型：字符型，整型，浮点型，双精度浮点型和无值类型\n\n程序中任何变量，常量都必须先定义类型。\n\n整数类型 int 及定义在其上的操作：+, -, \\*, /, %, ++, --\n\n双精度浮点型 double 及定义在其上的操作：+, -, \\*, /, ++, --\n\n###### 数据类型用来刻画(程序)操作对象的特性\n\n数据类型是一个元素的集合和定义在此集合上的一组操作的总称。\n\n数据类型实现了信息的隐藏，把一切用户无需了解的细节封装在类型中。\n\n高级语言中的数据类型分为原子类型和结构类型。\n\n#### 抽象数据类型(Abstract Data Type, ADT)\n\n是指一个数学模型以及定义在此数学模型上的一组操作。\n\n数据抽象：描述的是实体的本质特征、功能以及外部用户接口\n\n数据封装：将实体的外部特性和内在实现细节发呢里，对外部用户隐藏内部实现细节，使得应用和实现分离\n\nADT 的优点：\n\n- 程序结构清晰，易于扩展易于维护而不失其效率\n- 提高程序的数据安全性\n- 大大增加了软件的复用程度\n\n#### 抽象数据类型的描述\n\n```\nADT 抽象数据类型名{\n    数据对象: <数据对象的定义>\n    数据关系: <数据关系的定义>\n    基本操作: <基本操作的定义>\n    基本操作名(参数表)\n        初始条件: <初始条件描述>\n        操作结果: <操作结果描述>\n}ADT 抽象数据类型名\n```\n\n基本操作参数:\n\n- 赋值参数提供输入值\n- 引用参数以&打头，用于返回操作结果\n\n# 数据结构\n\n## 线性表\n\n线性表的元素可以是各种各样的，但是同一线性表的元素必然具有相同特性-同质\n\n线性表中的相邻元素之间存在有序关系-位序\n\n线性表是一种“有序结果”，即在数据元素的非空有限集合中\n\n- 存在唯一的一个被称为“第一个”的数据元素，无前驱；\n- 存在唯一的一个被称为的“最后一个”的数据元素，无后继；\n- 除第一个之外，每一个数据元素均只有一个直接前驱；\n- 除最后一个之外，每个数据元素均只有一个直接后继\n\n线性表中元素个数定义为线性表的长度\n\n$$(a_0, a_1, \\dots, a_{i-1}, a_i, a_{i+1}, \\dots, a_{n-1})$$\n\n若线性表为空，则其长度为 0，称为空表\n\n在非空表中，每个数据元素都有一个确定的位置\n\n- $a_0$是第 0 个数据元素，$a_{n-1}$是第$n-1$个数据元素\n- $a_i$是第 i 个数据元素\n- 称 i 为数据元素$a_i$在线性表中的位序\n\n## 线性表 ADT\n\n```Java\nADT List{\n    数据对象:\n    数据关系:\n    基本操作：\n    InitList(&L);\n        操作结果：构造一个空的线性表L。\n    DestroyList(&L);\n        初始条件：线性表已存在。\n        操作结果：销毁线性表L。\n    IsEmpty(L);\n        初始条件：线性表已存在。\n        操作结果：若L为空表，则返回TRUE，否则返回FALSE。\n    ListLength(L);\n        初始条件：线性表L已存在。\n        操作结果：用e返回L中第i个数据元素的值\n    GetElem(L, i, &e);\n        初始条件：线性表L已存在。\n        操作结果；用e返回L中第i个数据元素的值。\n    LocateElem(L, e, compare());\n        初始条件：线性表L已存在，compare()是数据元素判定函数。\n        操作结果：返回L中第1个与e满足关系compare()的数据元素的位序。若这样的元素不存在，则返回-1。\n    PriorElem(L, cur_e, &pre_e);\n        初始条件：线性表L已存在。\n        操作结果：若cur_e是L的数据元素，且不是最后一个，则用next_e返回它的后继，否则操作失败，next_e无定义。\n    ClearList(&L);\n        初始条件：线性表L已存在；\n        操作结果：将L重置为空表。\n    ListInsert(&L, i, e);\n        初始条件：线性表L已存在, 0 <=i <= ListLength(L)。\n        操作结果：在L中第i个位置插入新的数据元素e，L的长度加1。\n    ListDelete(&L, i, &e)\n        初始条件：线性表L已存在，0 <= i <= ListLength(L) - 1。\n        操作结果：删除L的第i个数据元素，用e返回其值，L的长度减1。\n    ListTraverse(L, visit());\n        初始条件：线性表L已存在。\n        操作结果：依次对L的每个数据元素调用函数 visit()。\n\n```\n\n线性表的合并：$O(m+n)$\n\n线性表的保序归并：$O(m+n)$\n\n线性表的顺序存储：顺序表\n\n- 用一组地址连续的存储单元依次存储线性表的数据元素\n\n顺序表的主要操作：\n\n插入操作：在顺序表的第 i 个位置插入一个新元素，使顺序表的长度增加到$n+1$\n\n复杂度分析：\n\n- 在顺序表的第$i$个位置插入一个新元素，需要移动$n - i$个元素；\n- 假设从顺序表的第$i$个位置插入元素的先验概率为$p_i$\n- 插入操作移动元素次数的期望为$E_{insert} = \\sum_{i = 0}^n(n - i) \\times p_i$\n\n删除操作：把顺序表的第$i$个位置的元素从表中删除，使长度为$n$的顺序表的长度变为$n - 1$\n\n复杂度分析：\n\n- 把顺序表的第$i$个位置上的元素删除，需要移动$n - i -1$个元素\n- 假设从顺序表的第$i$个位置删除元素的先验概率为$q_i$\n- 删除操作移动元素次数的期望为: $E_{delete} = \\sum_{i = 0}^{n - 1}(n - i - 1) \\times q_i$\n\n不失一般性，我们假设插入或删除元素出现在任何位置的概率都是相等的，因此有$p_i = p = 1/(n+1), q_i = q = 1/n$。\n\n推导得到：\n$$E_{insert} = \\frac1{n+1}\\sum_{i = 0}^n(n-i) = \\frac n2\\newline E_{delete} = \\frac1n\\sum_{i = 0}^{n - 1}(n - i - 1) = \\frac{n - 1}2$$\n\n## 单向链表\n\n最简单的链表结构：链表节点(node)由两个域组成。\n\n数据域：存储数据元素，\n\n指针域：指向直接后继节点\n\n单向链表的 C++实现：\n\n```C++\nclass LinkList {\nprivate:\n    NODE *head;\npublic:\n    LinkList() {head = NULL;}\n    ~LinkList();\n    bool clearSqList();\n    bool IsEmpty(){return head ==  NULL;}\n    bool GetElem(int i, int *e);\n    int LocateElem(int e);\n    bool PriorElem(int cur_e, int *next_e);\n    bool NextElem(int cur_e, int* pre_e);\n    bool Insert(int i, int e);\n    bool Delete(int i, int *e);\n    bool Traverse(bool (*visit)(int e));//遍历所有节点\n}\n\n```\n\n单向链表的不足：\n\n* 单链表的表长是一个隐含的值，遍历链表才能得到\n* 在单链表中插入或者删除元素时，需要在链表中依序寻找操作位置\n* 在链表中，元素的“位序”概念淡化，结点的“位置”概念强化\n* 如何得到某个元素的前驱？\n\n改进链表的设置：\n\n* 增加“表长”、“表尾指针”和“当前位置指针”三个数据域\n\n* 将基本操作中的“位序i”改为“指针p”\n\n## 双向链表\n\n由数据，前驱和后继构成。\n\n方便寻找前驱，但是增加了维护成本。\n\n## 顺序表和链表的比较：\n\n顺序表\n\n用一组地址连续的存储单元依次存储线性表中的数据元素\n\n优点：可以随机存取\n\n缺点：插入，删除操作需要移动表中的数据元素，事先确定规模，空间效率不高。\n\n链表：\n\n用一组“任意”的存储单元（附加指针）存储表中的数据元素\n\n优点：插入，删除操作无需移动表中的数据元素，空间利用率高\n\n缺点：不能随机存取\n\n## 栈\n\n栈是LIFO(Last In First Out，先进后出)的线性表。\n\n允许插入和删除的一段称为栈顶(top), 另一端称为栈底(bottom)\n\n### 栈的ADT\n\n~~~C++\n{\n    Push(&s, e);\n    Pop(&s, &e);\n    ClearStack(&s);\n} ADT Stack;\n~~~\n\n### 栈的表示和实现\n\n栈的顺序表示\n\ntop指向最后一个元素可以，指向空也可以，但是实现时要自洽。\n\n栈的链式表示\n\n有头插入和尾插入两个方式\n\n总体来看，头插入比尾插入的优势要更大。首先，插入时虽然头插入要修改的指针更多，但是时间复杂度小，头插入$O(1)$，尾插入$O(n)$。其次，如果以尾部为栈顶，删除时会很麻烦。\n\n**静态分配**\n\n```C++\n#define STACK_MAX_SIZE 100\n```\n**动态分配**\n\n程序隐含设定\n\n```C++\n#define STACK_INT_SIZE 100\n#define STACKINCREMENT 10\n```\n\n用户给定\n\n### 复杂度分析\n\n顺序栈的效率分析\n\n时间复杂度\n\n* 进栈、出栈:$O(1)$\n* 栈的溢出处理\n* 如果栈元素时简单数据类型，则构造和销毁函数也是$O(1)$的\n\n空间复杂度\n\n* 顺序栈的长度构造时确定\n* 空间利用效率低\n\n链式栈的效率分析\n\n时间复杂度\n\n* 链式栈的入栈出栈是$O(1)$时间的\n* 建立和销毁是$O(n)$时间的\n\n空间复杂度\n\n* 一般不会产生溢出\n* 空间利用率高\n\n### 栈的一些应用\n\n显式应用：括号匹配，表达式求值，迷宫求解\n\n隐式应用：函数调用，递归\n\n系统栈\n\n## 递归\n\n栈与递归具有相似性。\n\nFibonacci的递归次数：$C(n) = O(t^n)$\n\n(证明思路：归纳法证明$C(n) = 2F(n) - 1$, 根据F(n)通项可以判断。)\n\n使用递推法的时间复杂度：$O(n)$.\n\n经常需要进行递归的消除。消除方法：递推，循环等，没有统一的解决方案。可以借用显式栈实现非递归过程。\n\n递归的评价：\n\n* 简洁，便于理解，便于叙述和设计\n* 运行效率低，无法控制递归堆栈的规模\n\n## 队列\n\n队列是FIFO(First In First Out, 先进先出)的线性表。\n\n### 队列的表示和实现\n\n队列的顺序表示法\n\n入队: rear = rear + 1\n\n出队: front = front + 1\n\n需要判定队满和队空。\n\n顺序队列的问题：被出队的空间不会再次被使用了。\n\n循环队列：\n\n队尾指针指向maxSize - 1时， 入列则指向0；\n\n队头指针指向maxSize - 1，出列也指向0。\n\n可以使用模运算实现。\n\n缺点：无法区分队空和队满的状态。\n\n区分方法：\n\n设置一个空位；设置标志；设置队列长度变量\n\n队列的链式表示法\n\n入队不会出现队满的问题，出队可能回有队空的问题，队空的条件为front = NULL.\n\n## 串\n\n串是有线长度的字符序列。\n\n串的长度是字符个数。\n\n字符在串中的位置。\n\n两个串相等的条件。\n\n子串和主串，子串在主串中的位置。\n\n### 匹配算法\n\nBrute-Force算法：一个一个比。复杂度最高O(m * n)。\n\nKMP算法：尽可能跳过更多不必要的匹配。复杂度最多O(m + n)。\n\nHorspool算法：启发式算法。复杂度低则O(m/n)，高则O(m * n + s)，s为字符表规模\n\nBoyer-Moore算法：最坏O(n)。KMP和Horspool的综合（或者说Horspool是BM算法的简化版本。）\n\n## 树与二叉树\n\n### 树\n\n空树，子树。\n\n结点（node）是树的基本单位。\n\n结点的度(degree)：结点的子树个数。\n\n树的度：结点度的最大值。\n\nk叉树：树的度为k\n\nchild, parent, cousin, ancestor, descendant\n\ndepth/height\n\n树的性质：\n\n1. 树中结点数等于所有结点度数和加一\n2. k叉树第i层至多$k^{i - 1}个结点$\n3. 深度为h的k叉树至多有$(k^h - 1)/(k - 1)$个结点\n4. 具有n个结点的k叉树的最小深度为$[\\log_k(n(k - 1) + 1)]$\n\n### 二叉树\n\n二叉树是结点的一个有限集合，该集合或者为空，或者是由一个根节点加上两棵分别称为左子树和右子树的、互不相交的二叉树组成。\n\n二叉树的性质：\n\n1. 叶子结点数 = 度为二的结点数 + 1\n2. 第i层至多$2^{i - 1}$个结点\n3. 深度为h，则最多有$(2^h - 1)$个结点\n4. 具有n个结点的完全二叉树的深度为$\\lceil\\log_2(n + 1)\\rceil$\n5. 对于完全二叉树（最后一层从右向左缺若干结点），从左向右，从上到下编号，则$\\lfloor(i - 1)/2\\rfloor$为编号i的parent结点，$2i + 1$为其左子树，$2i + 2$为其右子树。\n\n二叉树的顺序表示\n\n完全二叉树按照编号存储。不完全二叉树按照它对应的完全二叉树存储，但是缺少的部分留空。\n\n不完全二叉树结点越少，空间效率越低。\n\n二叉树的链式表示\n\n空间效率很高。\n\n二叉树的遍历：\n\n记根节点为V，遍历左子树为L，遍历右子树记为R\n\n先序遍历：V - L - R\n\n中序遍历：L - V - R\n\n后序遍历：L - R - V\n\n遍历可以通过递归实现，但是递归可能会对效率产生影响。可以利用栈的特性实现遍历。\n\n层序遍历：从上到下优先遍历同一层的结点。\n\n遍历实现了树的线索化过程。\n\n### 霍夫曼树\n\n霍夫曼树：寻找加权路径长度(WPL)的最小树。\n\n用途：实现性能最好的变长二进制编码。\n\n霍夫曼编码不是唯一的，但是所有霍夫曼树的WPL都相等。\n\n不足：\n\n没有错误保护功能\n\n### 二叉树的建立\n\n只知道二叉树的先序序列，不能确定这棵二叉树。\n\n但是如果同时知道先序序列和中序序列，则可以确定这棵二叉树。\n\n## 图\n\n### 概念\n\n图的定义\n\n顶点，边，弧\n\n邻接顶点\n\n有向图，无向图\n\n有向完全图，无向完全图\n\n子图\n\n握手定理，度\n\n权，网络\n边上的数叫做权。有权的图叫网络。\n\n连通\n\n连通图\n\n连通分量\n无向图的极大连通子图为连通分量。（所谓极大，就是再加入一个点都会导致它不连通）\n\n强连通图\n有向图中存在vi到vj且存在vj到vi的图。\n\n强连通分量\n有向图的极大强连通子图为强连通分量。\n\nEuler路径和Euler回路\n\n图的存储和表示\n\n邻接矩阵表示\n如果v和w之间有边，则元素为1，否则为0.\n\n邻接表表示\n采用链表数组表示图。同一个顶点发出的边在同一个链表中。\n\n### 图的遍历\n\n深度优先遍历和广度优先遍历\n\n图的遍历：从已给连通图的某一顶点出发，沿着一些边访问所有顶点，且每个顶点只访问一次，则叫做图的遍历。\n\n邻接矩阵的遍历：$O(v^2)$\n\n邻接表的遍历：$O(v + e)$\n\n### 生成树\n\n连通图的生成树，包含图中全部n个顶点，但只有n-1条边。\n\n深度优先和广度优先遍历分别会得到一个搜索树。\n\n最小生成树：权值之和最小的生成树。\n\n求最小生成树的算法：贪心算法思想。Kruskal算法和Prim算法。\n\nPrim算法\n\n![](../images/DSA/Prim.jpg)\n\nPrim算法的时间复杂度为$O(n^2)$。对稠密图而言是线性的。对于稠密图而言，Prim的邻接矩阵实现是首选方法。\n\nKruskal算法\n![](../images/DSA/Kruskal.jpg)\n\nKruskal的时间复杂度为$O(E\\log E)$。\n\nKruskal算法对于稀疏图是好的选择。\n\n### 最短路径树\n\n从根到其他顶点的最短路径\n\n源点-汇点最短路径：给定一个起始顶点s和一个结束顶点 ，在图中找出从s到t的一条路径。起始顶点称为“源点”，结束顶点称为“汇点”\n\n单源最短路径：给定一个起始顶点s，找出从s到图中其它各顶点的最短路径\n\n全源最短路径：找出连接图中各对顶点的最短路径\n\n#### 单源最短路径\n\nDijkstra算法\n\n![](../images/DSA/Dijkstra.jpg)\n\nDijkstra算法通过构造加权有向图图的最短路径树SPT，来实现单源最短路径算法。\n\n时间复杂度为$O(v^2)$，和Prim算法很相似。\n\n#### 全源最短路径\n\n可以对每个顶点用Dijkstra算法。\n\nFloyd算法\n\n时间复杂度：$O(v^3)$。可以计算出一个网络中所有的最短路径。\n\nFloyd算法允许图中带有负权值的边，但不允许有包含带负权值的边组成回路。\n\n# 算法\n\n## 非数值算法\n\n### 查找\n\n查找算法的复杂性：关键字/数据规模\n\n查找算法的分类：\n* 内部/外部\n* 静态/动态\n\n#### 查找表\n\n查找表（Search Table）是由同一类型数据元素构成的集合。\n\n按关键字查找\n1. 查询某元素是否存在\n2. 检索某数据元素的各种属性\n3. 在查找表中插入一个数据元素\n4. 从查找表中删除一个数据元素\n\n查找表的种类\n1. 静态查找表-仅可执行1,2\n2. 可执行1,2,3,4\n\n平均查找长度：在查找过程中，为确定目标在查找表中的位置，需要进行关键字比较次数的期望值\n\n$$\nASL = \\sum_{0}^{n - 1}P_i C_i\n$$\n\n$P_i$为第i条记录的查找概率，$C_i$为第i条记录的查找长度。\n\n有时我们会假设查找概率相等或不等，有时要考虑查找失败的比较次数。\n\nASL越小，查找性能越好。\n\n顺序查找：又称线性查找，是从线性\n表的一端开始，依次把每个元素的\n关键字同给定值进行比较\n\n假设每个元素的查找概率相等，则平均查找长度为：$ASL = \\sum_0^{n - 1}\\frac{i + 1}{n} = \\frac{n + 1}{2}$。\n\n更多考虑：查找概率不等；查找失败需要N次比较；越界判断\n\n折半查找：如果顺序表有序，我们可以采用高效率的折半查找\n\n折半查找可以用一个二叉树结构来表述。比较次数不会超过$\\lfloor\\log_2 N + 1\\rfloor$。\n\n索引查找：将线性表划分为若干子表，再建立指向这若干子表的一个索引表。相同性质的数据归类到一个子表中。\n\n索引表：顺序表或链表\n\n子表：顺序表或链表\n\n因而可以有四种不同的索引存储方式。\n\n索引表的特点：表不大， 表中元素不常变动。因而适合用顺序表来表示索引表。\n\n分块查找：也称索引顺序查找，是顺序查找的改进。子表之间有序；块内元素无序。索引表包括关键字项，指针项，子表长度。\n\n索引文件：单关键字，多关键字。\n\n稠密索引：索引表的索引项和主文件的各记录一一对应，称为稠密索引。\n\n稀疏索引（非稠密索引）：索引项对应主文件的一部分记录。\n\n索引文件的好处：减少访问外存的次数，提高查找速度。\n\n倒排文件：不同之处是辅索引表包含物理地址序列。（为什么要倒排？）\n\n#### 二叉搜索树（BST）\n\n或者是一棵空树，或者是具有下列性质\n的二叉树：每个结点有一个关键字(key)，\n并且:\n1. 任意结点关键字大于等于该结点左\n子树中所有结点含有的关键字\n2. 同时该结点的关键字小于等于右子\n树中所有结点含有的关键字\n\nBST是一种重要的动态搜索结构。它的中序遍历是确定的。 \n\nBST的插入操作和查找操作同样简单。\n\n\n删除操作比较复杂。叶子结点的删除比较简单；如果结点只有一棵子树，也比较简单；如果左右子树都不空，可以用中序后继替换。\n\nBST的性能：越“平衡”越好。\n\n二叉搜索树的路径长度和高度直接关系到BST中搜索的开销，对于一棵\n含有N个关键字的BST\n* 最好情况下，所有搜索都可以保证对数运行时间\n* 最坏情况下，进行一次搜索需要 次比较\n* 平均情况下搜索需要 次比较操作\n\nBST的旋转操作：结点和一个子孙交换角色。分为左旋转和右旋转。右旋转涉及到结点和右孩子。（右旋转和左旋转是以结点自己作为参考系而言。）\n\nBST通过不断的旋转来保证自己的平衡性。\n\nAVL树：\n一棵AVL树或者是空树，或者是具有下列性质的二叉搜索树:\n1. 左子树和右子树都是AVL树\n1. 且左子树和右子树的高度之差的绝对\n值不超过1\n\nAVL的高度为$O(\\log_2 n)$，平均查找长度也为$O(\\log_2 n)$。\n\nAVL具有良好的搜索性能，能够避免一般BST性能恶化的问题。但是AVL的维护比较复杂，在进行插入和删除操作后，都必须通过大量的旋转操作保证AVL的平衡性。\n\n寻找其他方法，以提高BST的平衡程度，保证BST的性能。\n\n* 实用的平衡二叉搜索树-红黑树\n\n* 多路平衡的动态查找结构-B-树\n\n#### 散列\n\n散列的关键是散列函数和冲突处理。\n\n散列函数应是简单的，能在较短的时间内计算出结果\n\n散列函数的定义域必须包括需要存储的全部关键码，如果散列表允许有m\n个地址，其值域必须在0到m-1之间\n\n理想的散列函数应近似为随机的，对每一个输入，相应的输出在值域上是\n等概的。\n\n冲突处理：\n\n* 链地址法：把散列到同一个地址的关键字存进链表中。（表长小于元素数目）\n* 开放定址法：放在表中空的位置。查找时采用“探测”的方法。如果探测下一个位置，称为线性探测。（表长大于元素数目，稀疏表，一般不允许表达到半满状态）\n* 双重散列法：用第二个散列函数表达散列的增量。时间复杂度略大，但是性能比线性探测好很多。\n\n散列的其他应用：字符串的匹配；搜索引擎对URL的散列；信息安全中的内容鉴别技术（MD5, sha）。\n\n散列提供常数时间的查找性能，实现简单；但是好的散列函数不易找到，删除操作和空间性能不好，最坏情况下性能不好，忽略了数据间的逻辑关系。\n\n### 排序\n\n排序算法的稳定性：如果两个对象的排序码相等，排序前后的顺序不变，则是稳定的；否则是不稳定的。\n\n内排序：数据对象存放在内存。\n\n外排序：数据对象在内、外存之间移动。\n\n冒泡排序：复杂度为$O(n^2)$。添加排序标记，最好情况下只需要$n - 1$次比较和0次交换。\n\n插入排序：有直接插入，折半插入，希尔排序\n\n直接插入：$O(n^2)$\n\n折半插入：查找插入位置的时候可以采用折半查找，因为表中可以插入的部分已经排好序了。复杂度没有变化，依然是$O(n^2)$\n\n希尔排序：如果序列中，间距为h的元素都有序，称这个序列为h-排序的。希尔排序就是不断缩小h，直到h=1。\n\n选择特定的步长序列$h_n$，取出序列中增量为$h_n$的子列进行插入排序。然后取$h_{n-1}$，直至取$h_1=1$。\n\n它在h比较大的时候排序，由于间距短，速度快；而h小的时候，由于有序性强，速度快。总体速度依赖于步长序列的选择，时间复杂度比直接插入好一些。\n\n选择排序：比较次数$O(n^2)$，移动次数$O(n)$，移动次数少一些。\n\n冒泡排序和插入排序都是稳定的，而选择排序是不稳定的。\n\n**快速排序**：一种交换类排序。具有很好的性能。\n\n将待排序序列分为两个部分，满足：\n1. a[i]位于它在序列中的正确位置\n2. 前面的元素比a[i]小\n3. 后面的元素比a[i]大\n然后对两个部分继续划分，每次划分都将一个元素划分到它的正确位置。\n\n如何划分：\n\n选择划分元素v。从序列左边扫描，找到一个比v大的元素，从右边扫描，找到一个比v小的元素，交换两个元素。反复交换，直到左右扫描指针相遇，则划分完成。\n\n快速排序的递归树是一颗二叉搜索树，因为每次递归都是对比自己大和比自己小的两个部分递归。\n\n时间复杂度：理想情况下$O(N\\log_2N)$，如果递归树是平衡的。平均情况下为$O(N\\log N)$，而最坏情况下退化为$O(N^2)$。\n\n快速排序是不稳定的排序算法。\n\n改进：\n\n划分元素是最大或者最小的元素时是最坏情况。为了避免最坏情况，采用中间元素法：取序列的左端元素，右端元素和中间元素，选择关键字处于中间的元素作为划分元素。\n\n快速排序中，子序列非常小时仍然要递归调用，可以采用插入排序代替，提高效率。\n\n归并排序：合并有序表。两个表的归并，叫二路归并。利用二路归并可以实现归并排序。\n\n自底向上归并：将文件分割成长度为m的子序列，每次m翻倍。\n\n自顶向下归并：将文件分割为两个部分，分别进行递归的归并排序后再合起来进行归并排序。\n\n归并排序是稳定的，时间最好情况是$O(N\\log N)$，最坏是$O(N^2)$.\n\n堆：堆是满足堆性质的完全二叉树。\n\n最大堆：任意节点的值小于父节点的值。\n\n最小堆；任意节点的值小于父节点的值。\n\n因为是完全二叉树，适合用顺序存储方式。\n\n堆：顺序存储在一维数组中。\n\n堆的操作，例如插入，删除或者修改结点会破坏堆的性质，因此修复堆是重要的操作。\n\n对于最大堆，如果某结点的关键值小于其子节点的关键值，可以采用自顶向下堆化(Heapify-down)的算法进行修复。\n\n对于最大堆，若结点的关键值大于父节点的关键值，采用自底向上堆化(Heapify-up的算法进行修复)\n\n向堆中插入结点：在新节点插入堆尾，调用自底向上算法调整堆。这种构造堆方法称为自顶向下的堆构造。\n\n自顶向下的堆构造：$O(N\\log N)$\n\n自底向上的堆构造：时间复杂度$O(N)$\n\n自底向上构造复杂度小的原因：离根远的复杂度小，离根近的复杂度大。而自顶向下是离根远的复杂度大，离根近的复杂度小。离根远的数量多，而离根近的数量少，因此自底向上的整体的复杂度更小。\n\n优先级队列可以用堆实现，性能非常好。\n\n堆排序：节约空间，比较次数和移动次数都是$O(N\\log N)$。堆排序是不稳定的排序方法。\n\n从小到大排序的方法：自底向上构造最大堆。将堆首与堆尾交换，堆序列长度-1，调整堆，再次交换，重复上述过程，直到堆空。\n\n>堆排序大概可以理解成优先队列的出队过程。\n\n采用决策树的方法可以求得比较次数的下界为$O(N\\log N)$\n\n## 数值算法\n\n### 基础\n\n一个数值问题是适定的(well posed)，需要满足：\n* 解存在\n* 解唯一\n* 连续地依赖于问题数据\n\n不满足条件的问题被称为不适定的(ill-posed)。\n\n适定的问题，如果解对输入数据非常敏感，则称之为病态的(ill-conditioned)。\n\n针对适定和良态(well-conditioned)问题，数值分析可以得到具有一定精度的近似解。\n\n数值分析重视误差。误差=计算误差+传播误差，算法影响的是计算误差。误差有模型误差、测量误差、截断误差、舍入误差。\n\n前向误差反映了输出的误差，后向误差反映了输入的误差。相对前向误差与相对后向误差的比值叫做条件数(condition number)。$cond \\le 1$说明问题是良态的；否则是病态的。\n\n实际问题中我们通常求解条件数的估计值或者上限。进而求得前向误差。\n\n相对条件数:$\\left|\\frac{xf^\\prime (x)}{f(x)}\\right|$。绝对条件数：$\\left|f(x)\\right|$\n\n算法的稳定性：如果一个算法对于计算过程中的微小扰动不敏感，则算法是稳定的。\n\n问题的病态性针对输入数据的微小扰动，而算法的稳定性针对的是计算过程中的误差。\n\n最近舍入法：与x最相近的浮点数，如果相等，取最后一个存储位为偶数。\n\n若是偶数，则区间是闭区间；若是奇数，则对应的区间为开区间。\n\n浮点数的下溢限主要由尾数决定，机器精度由尾数决定。\n\n浮点数的表示法:\n\n$$\nx = \\pm \\left(d_0 + \\frac{d_1} \\beta + \\frac{d_2} {\\beta^{2}}+ \\dots + \\frac{d_{p-1}} {\\beta^{p-1} } \\right)\\beta^E\n$$\n\n在正规化浮点数系统中：\n$$\n\\text{UFL}=\\beta_L\\\\\n\\text{OFL}=\\beta^{U+1}(1 - \\beta^{1-p})\\\\\n$$\n\n机器精度：舍入造成的相对误差上限：\n$$\n\\left|\\frac{fl(x) - x}{x}\\right| \\le \\epsilon_{mach}\n$$\n\n最近舍入方式下：\n$$\n\\epsilon_{mach} = \\beta^{1-p} / 2\n$$\n\n### 线性方程求解\n\n解矩阵方程$A\\mathbb x = \\mathbb b$。\n\n误差分析：\n\n条件数：$\\text{cond}(A) = ||A||||A^{-1}||$\n\n直观理解：两条线接近平行的时候，两条线截距的轻微扰动会造成解很大的不确定性。\n\n解方程：\n\n直接求解法\n\n高斯消元法：复杂度$O(n^3)$。通常采用列选主元的方法提高算法的稳定性。\n\nLU分解：如果$b$变化而$A$不变，可以较快地多次求解。\n\n解的精度分析：条件数大，即使残差很小，也会得出极大的计算误差。是因为问题本身非常敏感。\n\n高斯-约当法：把A变换为对角阵。\n\n乔列斯基分解：A是对称正定阵，则A=LL'。\n* 算法是良态的\n* 不需要选主元就有稳定性\n* 只需要存储下三角部分即可\n* 分解的乘法和加法次数都约为$n^3/6$\n\n线性方程的迭代解法：\n\n不动点迭代法：\n\n$$\nAx = b \\Rightarrow x = Gx + C\n$$\n\n不动点迭代的收敛核心在于G。\n\n对于矩阵M，定义谱半径$\\rho(M)$为M的特征值绝对值的最大值。\n\n如果$\\rho(G)< 1$，则不动点迭代收敛。\n\n分裂$A = M - N$，则\n\n$$\n(M - N)x = b\\Rightarrow\\\\\nx = M^{-1}Nx + M^{-1}b\n$$\n\n当$\\rho(M^{-1}N) < 1$时，不动点迭代收敛。\n\nJacobi（雅克比）方法：$A = D + L + U$, $M = D$, $N = - (L + U)$, $x^{k+1} = D^{-1}[b - (L+U)x^k]$。\n\n高斯-赛德方法：\n$A = D + L + U$, $M = D + L$, $N = -U$, $x^{k+1} = (D+L)^{-1}(b - Ux^k)$。\n\n这两种迭代都不一定收敛，但是实际中一般都可以。高斯赛德方法速度比雅克比快一倍。\n\n### 非线性方程求解\n\n误差分析：\n\n非线性方程$f(x) = 0$，真解为$x^*$，近似解为$\\hat x$。\n\n残差：$||f(\\hat x)||$\n\n前向误差：$||\\hat x - x^*||$，能更准确地描述解的精确程度。\n\n绝对条件数：$1/|f^\\prime(x^*)|$\n\n可见，如果f(x)在$x^*$处接近水平，则问题是病态的。\n\n具有重根的问题也是病态的。\n\n解法：\n\n二分法：定义误差$e_k = x_k - x^*$，定义迭代法的收敛速度定义：$\\lim_{k\\rightarrow \\infty}\\frac{||e_{k + 1}||}{||e_k||^r} = C$，则收敛速度为$r$。r=1称为线性的，r>1称为超线性的，r=2称为平方的。二分法的迭代次数与函数的具体形式无关。\n\n不动点迭代法：\n\n收敛性：\n\n$$\n\\lim_{k\\rightarrow \\infty}\\frac{||e_{k+1}||}{||e_k||} \\\\=\\lim_{k\\rightarrow \\infty}\\frac{g(x_k) - x^*}{x_k - x^*} \\\\\n= \\lim_{k\\rightarrow \\infty} g^\\prime (\\xi_k) = g^\\prime(x^*) \n$$\n\n绝对条件数为$g^\\prime(x^*)$。如果$|g^\\prime(x^*)|$非零，则收敛是线性的，如果为0，则是超线性的。\n\n牛顿迭代法：\n\n$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}\n$$\n\n由于$g^\\prime(x^*)=0$，收敛是超线性的。进一步分析得到$\\lim_{k\\rightarrow \\infty}\\frac{x_{k+1} - x^*}{(x_k - x^*)^2} = \\frac{f^{\\prime\\prime}(x^*)}{2f^\\prime(x)}$，因此牛顿法是平方收敛的。\n\n牛顿法的特点：\n* 初值的选取很重要\n* $f^\\prime(x)\\ne 0$\n* 速度快，但是可能出现振荡的情况\n* 对多重根的收敛速度退化为线性\n* 涉及到求导，有时候比较困难\n\n准牛顿法：免去了求导\n\n$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{g_k}\n$$\n\n割线法：准牛顿法的一种\n\n$$\ng_k = \\frac{f(x_k) - f(x_{k - 1})}{x_k - x_{k - 1}}\n$$\n\n反插：割线法是用两次的迭代值确定一条直线，取直线与x轴的交点。可以采用反二次插值：用前三次迭代值确定抛物线$x = p(y)$，取它与x轴的交点。\n\n二分法较安全，但速度慢；迭代法速度快，但不安全。可以在区间较大时采用二分法缩小区间，等区间较小时再采用迭代法。\n\n### 拟合与插值\n\n#### 拟合\n\n如果方程的数目多于未知数的数目，则是超定方程。\n\n如果方程的数目少于未知数的数目，则是欠定方程。\n\n超定方程在线性最小二乘的意义下得到一个近似解。\n\n转而求解$A^TAx = A^Tb$。如果矩阵A是列满秩的，则解唯一。\n\n若$A^TA$是正定的，则有$A = LL^T$。\n\n可以采用QR分解将长方阵A简化：\n\n$$\nA = Q\\begin{bmatrix}\nR\\\\\n0\n\\end{bmatrix}\n$$\n\n进一步，如果$Q = \\begin{bmatrix}Q_1\\\\Q_2\\end{bmatrix}$，则$Rx = Q_1^Tb$。\n\n利用household变换进行QR分解。\n\n正规方程方法的复杂度：$mn^2/2  + n^3/6$\n\nhousehold变换的复杂度：$mn^2 - n^3 / 3$\n\n如果m和n相当，则两种变换的复杂度相当，而m远大于n时，QR分解的复杂度是正规方程方法的两倍。\n\nQR分解的适用性更宽。\n\n#### 插值\n\n插值使得函数精确地通过给定数据点。\n\n单项式基底：$\\phi_j(x) = x^{j - 1}$。给定点数越多的插值问题，病态性越高，插值多项式的系数不稳定。\n\n霍纳法则：$t_1 + x(t_2+x(t_3+(\\dotsb)))$，减少乘法次数。\n\n拉格朗日插值：\n\n$$\nl_j(x) = \\frac{\\prod_{k = 1, k \\ne j}^{n}(x - x_k)}{\\prod_{k = 1, k\\ne j}^{n}(x_j - x_k)}\n$$\n\n* 确定形式容易\n* 计算值困难\n* 微分，积分不方便\n\n牛顿插值：基底取$\\prod_{k = 1}^{j - 1}(t - t_k)$。\n\n* 容易确定，系数较容易求解\n* 计算可以通过类似霍纳法则的方法求得，时间复杂度低\n* 在确定和求值之间形成了较好的平衡。\n\n### 优化问题\n\n分为连续优化问题和离散优化问题。\n\n可行点，约束集合。\n\n#### 连续优化问题\n\n有线性规划和非线性规划问题。\n\n线性规划：不细讲。\n\n非线性规划：\n\n（严格/非严格）全局最小值，局部最小值。全局最小值的求解，甚至验证都很困难。\n\n闭集：闭集是补集为开集的集合。如果一个集合中所有的极限点都是这个集合中的点，则这个集合是闭集。\n\n有界闭集上的连续函数有全局最小值。如果不是闭的或者无界，就可能没有最小值。\n\n$\\lim_{||x||\\rightarrow \\infty} f(x) = \\infty$，称$f(x)$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的。\n\n如果连续函数$f$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的，则$f$在$S$上存在全局最小值。\n\n集合是凸的：任意两点的连线属于这个集合。\n\n函数是凸的：区间内函数值不超过端点连线上的函数值。\n\n如果集合和函数都是凸的，称为凸优化问题。\n\n我们有如下结论：\n* 如果$f$是凸集$S\\sube \\mathbb{R^n}$上的凸函数，则在 $S\\sube \\mathbb{R^n}$的任意内点上连续\n* 凸函数$f$在凸集$S\\sube \\mathbb{R^n}$上的任意局部最小值，都是$f$在$S\\sube \\mathbb{R^n}$上的全局最小值\n* 严格凸函数$f$在凸集 $S\\sube \\mathbb{R^n}$上的局部最小值，是$f$在$S\\sube \\mathbb{R^n}$上的唯一全局最小值\n* 如果$f$在有界闭集$S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一的全局最小值\n* 如果$f$在无界闭集 $S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一全局最小值的充要\n条件是$f$在$S\\sube \\mathbb{R^n}$上是强制的\n\n下面考虑无约束优化：\n\n梯度为0的点是临界点。\n\n临界点可能是局部最大值/最小值/鞍点。\n\n如果函数是凸的，临界点就是全局最小值点。\n\n海森矩阵正定，则f是凸的。\n\n如果$x^*$是函数$f$的最小值，\n则$\\nabla f(x^*) = 0$，$\\nabla^2f(x^*)$非负定。\n\n如果$\\nabla f(x^*) = 0$且$\\nabla^2f(x^*)$正定，则$x^*$是严格局部最小值。\n\n如果是凸优化，则$\\nabla f(x^*) = 0\\Leftrightarrow f(x^*)$为严格局部最小值\n\n矩阵的正定性：\n* 特征值全正\n* Cholesky分解唯一\n* 顺序主子式的行列式全正\n\n拉格朗日乘数法：\n\n$$\n\\mathcal{L}(x, \\lambda) = f(x) + \\lambda^Tg(x)\n$$\n\n海森矩阵：\n\n$$\nH_{\\mathcal{L}}(x, \\lambda) = \\begin{bmatrix}\n    B(x, \\lambda) && J_g^T(x)\\\\\n    J_g(x) && 0\n\\end{bmatrix}\\\\\nB(x,\\lambda) = H_f(x) + \\sum_{i = 1}^m\\lambda_iH_{g_i}(x)\n$$\n\n只要$B(x^*, \\lambda^*)$正定，则$x^*$是极小值点。\n\n敏感性和病态性：依赖于海森矩阵\n* 海森矩阵奇异，则极值问题病态\n* 海森矩阵接近奇异，则极值问题敏感\n\n下面考虑一维优化问题：\n\n单峰函数:最小值左侧递减，最小值右侧递增。\n\n类似于二分法，可以用黄金分割搜索求单峰函数的极小值。\n\n好处：每次迭代只需要更新一个点；安全性好；收敛速度线性；\n\n坏处：收敛速度还可以提高。\n\n方法二：逐次抛物插值。用两个端点和一个近似极值点拟合一条抛物线，取抛物线的最小值点作为新的近似极值点，反复直到收敛。\n\n当初始点接近极值点时能够收敛；收敛是超线性的。\n\n牛顿迭代法：\n$$\nx_{k + 1} = x_k - \\frac{f'(x_k)}{f''(x_k)}\n$$\n\n实际上采用黄金分割搜索和逐次抛物插值混合方案，避免求函数的导数。\n\n多维优化问题：\n\n最速下降法：\n$$\nx_{k + 1} = x_k - \\alpha_k\\nabla f(x_k)\n$$\n\n确定$\\alpha_k$：$\\min_{\\alpha_k} f(x_k - \\alpha_k \\nabla f(x_k))$\n\n非常可靠，只要梯度不为0；速度可能不快，呈之字形；收敛速度线性；初值的选择很重要。\n\n牛顿法：\n$$\nx_{k + 1} = x_k - H_f^{-1}(x_k)\\nabla f(x_k)\n$$\n\n平方收敛，速度快于梯度下降；需要距离最优解很近；不需要搜索参数；如果目标具有连续的二阶偏导数，则海森矩阵对称。\n\n拟牛顿法\n\n$$\nx_{k + 1} = x_k - \\alpha_kB_k^{-1}\\nabla f(x_k)\n$$\n\n## 算法设计思想\n\n### 贪心算法\n\n* 可行性\n* 局部最优\n* 不可取消\n\n不是所有优化问题都能通过贪心算法求解，即使可以使用贪心算法，也不一定能够得到最优解。\n\n如果一个优化问题可以通过局部最优选择得到全局最优解，则说这个问题满足贪心选择性质，此时可以简单高效地求得问题的最优解。\n\n贪心策略可以有很多种。不同的算法有不同的性能。不一定得到全局最优解。\n\n### 动态规划\n\n多阶段动态过程的优化问题\n\n阶段：把问题分成几个相互联系的有顺序的几个环节，这些环节被称\n为阶段\n\n状态：某一阶段的出发位置称为状态。通俗的说状态是对问题在某一\n时刻的进展情况的数学描述\n\n决策：从某阶段的一个状态演变到下一个阶段某状态的选择\n\n条件：最优化原理；无后效性\n\n动态规划用空间换时间，有大量重叠子问题时才能体现它的优势。\n\n例：Floyd算法，Viterbi译码\n\n### 蛮力法\n\n### 分治法\n\n快速排序\n\n分治法：分成若干个小的同类问题\n\n减治法：变成一个更小的同类问题\n\n变治法：变成若干个更简单的问题\n\n### 搜索算法\n\n组合优化问题的解空间指的是搜索答案的过程中搜索过的可行解。\n\n回溯法：没有希望的解就不去搜索。\n\n分支界限法：一边搜索一边给出当前部分解的下界。对于下界比搜索到的可行解还大的分支，不去搜索。下界的估计方法很重要。\n\n回溯法和分支界限法都不能保证求解的效率。\n\n### 随机算法\n\nSherwood算法\n\n快速排序在某些序列下会发生时间复杂度的退化。随机划分元素，可以使得达到最坏复杂度的概率降到很低。\n\n一般地，若确定型算法在最坏情况下的时间复杂度和它在平均情况下的时间复杂度有较大的差异，通过随机性可以消除这种差别。并不是避免这种最坏的情况发生，而是切除这种最坏情况和特定实例之间的联系。\n\nLas Vegas算法\n\n* 随机化决策\n* 减少算法运行的时间\n* 有概率会失败\n* 多尝试几次以提高成功率\n\nMonte Carlo算法\n\n* 概率为基础的统计模拟方法\n* 不保证得到正确的解\n* 设计合理，大量重复可以大概率得到高精度的解\n\n随机投点求面积\n\n一个蒙特卡洛方法得到正确判定的概率不小于p，则算法是p正确的。\n\n如果同一实例不会给出不同的解，称算法是一致的。\n\n对于判定问题，如果能够保证返回true时是正确的，称为偏真的；保证返回false时是正确的，则算法是偏假的。\n\nSherwood:一定得到正确解，一般不会遇到最坏情况\n\nLas Vegas:不一定得到正确解，但如果得到了一定是正确的\n\nMonte Carlo:不一定得到正确解，即使得到了也不一定是正确的\n\n### 算法优化技术\n\n输入增强技术\n\n* 字符串匹配算法\n\n* 计数排序\n\n预构造技术\n\n* 并查集\n\n* 二叉查找树\n\n* 倒排索引\n\n* 堆和堆排序\n\n时空平衡\n\n* 比特逆序\n* 散列\n\n","slug":"DataAndAlgorithms","published":1,"updated":"2024-03-19T06:01:16.157Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhr0004rsug72ka1b2s","content":"<h1 id=\"相关资源\"><a href=\"#相关资源\" class=\"headerlink\" title=\"相关资源\"></a>相关资源</h1><p><a href=\"https://algs4.cs.princeton.edu/home/\">Princeton <em>Algorithm 4th Edition</em></a></p>\n<h1 id=\"课程说明\"><a href=\"#课程说明\" class=\"headerlink\" title=\"课程说明\"></a>课程说明</h1><h2 id=\"课程内容\"><a href=\"#课程内容\" class=\"headerlink\" title=\"课程内容\"></a>课程内容</h2><p>数据处理，数学模型，算法分析</p>\n<p>非数值问题：</p>\n<p>数据结构：线性表，栈，队列，串，树，图</p>\n<p>非数值算法：查找，排序</p>\n<p>数值问题：</p>\n<p>误差分析</p>\n<p>线性方程组</p>\n<p>非线性方程</p>\n<p>拟合与插值</p>\n<p>最优化初步</p>\n<p>算法设计：蛮力，分治、减治、贪心、动态规划、搜索算法</p>\n<h1 id=\"绪论\"><a href=\"#绪论\" class=\"headerlink\" title=\"绪论\"></a>绪论</h1><h2 id=\"数据与算法\"><a href=\"#数据与算法\" class=\"headerlink\" title=\"数据与算法\"></a>数据与算法</h2><h2 id=\"数学模型\"><a href=\"#数学模型\" class=\"headerlink\" title=\"数学模型\"></a>数学模型</h2><p>对于现实世界的某一特定对象，为特定目的而得到的一个抽象的简化的数学结构。</p>\n<h3 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h3><p>算法是问题的程序化解决方案。</p>\n<p>算法强调精确定义的求解过程，并不是问题的答案。</p>\n<p>设计实现算法，并没有得到答案，但是给出了一般的解决方案。</p>\n<p>一个算法能够解决很多看似好无关系的问题，只要这些问题可以抽象为某种相同的算法。</p>\n<h3 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h3><p>数据是客观世界的描述。</p>\n<p>数据是信息的载体，是算法处理的对象。</p>\n<p>算法是处理数据的系统。</p>\n<p>人的因素也被纳入了数学模型的和算法。</p>\n<p>IBM Watson</p>\n<h2 id=\"算法分析和算法设计\"><a href=\"#算法分析和算法设计\" class=\"headerlink\" title=\"算法分析和算法设计\"></a>算法分析和算法设计</h2><h3 id=\"算法及其特性\"><a href=\"#算法及其特性\" class=\"headerlink\" title=\"算法及其特性\"></a>算法及其特性</h3><p>算法的五个重要特性：</p>\n<p>有穷性：一个算法必须可以在有穷步之后结束，且每一步可以在有穷时间内完成</p>\n<p>确定性：算法的描述无歧义，算法的执行结果是确定的且精确地符合要求或期望</p>\n<p>可行性：算法中描述的操作都可以通过已经实现的基本操作运算的有限次执行来实现</p>\n<p>输入：一个算法有零个或多个输入，这些输入取自某个特定的对象集</p>\n<p>输出：一个算法有一个或多个输出，输出量是算法计算的结果</p>\n<h3 id=\"算法的评价\"><a href=\"#算法的评价\" class=\"headerlink\" title=\"算法的评价\"></a>算法的评价</h3><h4 id=\"正确性\"><a href=\"#正确性\" class=\"headerlink\" title=\"正确性\"></a>正确性</h4><p>不含语法错误</p>\n<p>几组一般的输入数据</p>\n<p>精心选择的、典型、苛刻且带有刁难性的输入数据（衡量标准）</p>\n<p>一切合法的输入数据</p>\n<h4 id=\"健壮性\"><a href=\"#健壮性\" class=\"headerlink\" title=\"健壮性\"></a>健壮性</h4><p>输入的数据非法</p>\n<h4 id=\"可读性\"><a href=\"#可读性\" class=\"headerlink\" title=\"可读性\"></a>可读性</h4><p>描述清楚，便于理解</p>\n<h4 id=\"高效率\"><a href=\"#高效率\" class=\"headerlink\" title=\"高效率\"></a>高效率</h4><p>占用的空间和时间资源</p>\n<h3 id=\"算法效率的衡量方法\"><a href=\"#算法效率的衡量方法\" class=\"headerlink\" title=\"算法效率的衡量方法\"></a>算法效率的衡量方法</h3><p>和算法执行时间相关的因素有很多。</p>\n<p>一个特定算法运行工作量的大小，是问题规模的函数。</p>\n<h4 id=\"渐进时间复杂度\"><a href=\"#渐进时间复杂度\" class=\"headerlink\" title=\"渐进时间复杂度\"></a>渐进时间复杂度</h4><p>算法的渐进时间复杂度(Time Complexity): $T(n) &#x3D; O[f(n)]$</p>\n<p>Big-O 记号的形式化定义</p>\n<ul>\n<li>若 f(n)是正整数 n 的一个函数，则$x_n &#x3D; O[f(n)]$表示存在正的常数$M$和$n_0$， 使得当$n &gt; n_0$时，都满足$|x_n| \\le M|f(n)|$</li>\n<li>标记的是算法效率的上限</li>\n</ul>\n<h5 id=\"算法效率估算方法\"><a href=\"#算法效率估算方法\" class=\"headerlink\" title=\"算法效率估算方法\"></a>算法效率估算方法</h5><ul>\n<li>算法执行的时间 &#x3D; Σ 操作的执行次数 × 操作的执行时间</li>\n<li>算法操作包括<strong>控制操作</strong>和<strong>原操作</strong><br>一般来说，相比于循环体，控制操作本身的复杂度可被忽略。而在原操作中，我们又可以寻找其中执行次数最多的一种或几种操作，这些操作被称为基本操作。</li>\n<li>选取算法中的<strong>基本操作</strong></li>\n<li>算法的执行时间与<strong>基本操作执行次数之和</strong>成正比</li>\n</ul>\n<h5 id=\"描述指标\"><a href=\"#描述指标\" class=\"headerlink\" title=\"描述指标\"></a>描述指标</h5><ul>\n<li>最好情况(best-case)：对于任何一个输入的运行时间下限</li>\n<li>最坏情况(worst-case)：对于任何一个输入的运行时间下限</li>\n<li>平均(average-complexity): 根据各种操作出现概率的分布进行加权平均</li>\n<li>分摊(amortized complexity): 连续实施足够多次操作，总成本摊至单次操作</li>\n</ul>\n<p>最重要的是平均情况下的性能</p>\n<h5 id=\"引入大-O-表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\"><a href=\"#引入大-O-表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\" class=\"headerlink\" title=\"引入大 O 表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\"></a>引入大 O 表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型</h5><h5 id=\"迅速找到会被多次反复执行的基本操作\"><a href=\"#迅速找到会被多次反复执行的基本操作\" class=\"headerlink\" title=\"迅速找到会被多次反复执行的基本操作\"></a>迅速找到会被多次反复执行的基本操作</h5><h5 id=\"感兴趣的复杂度形式非常有限\"><a href=\"#感兴趣的复杂度形式非常有限\" class=\"headerlink\" title=\"感兴趣的复杂度形式非常有限\"></a>感兴趣的复杂度形式非常有限</h5><h5 id=\"按照对数坐标画图\"><a href=\"#按照对数坐标画图\" class=\"headerlink\" title=\"按照对数坐标画图\"></a>按照对数坐标画图</h5><h4 id=\"空间复杂度\"><a href=\"#空间复杂度\" class=\"headerlink\" title=\"空间复杂度\"></a>空间复杂度</h4><h5 id=\"算法空间\"><a href=\"#算法空间\" class=\"headerlink\" title=\"算法空间\"></a>算法空间</h5><ul>\n<li>指令空间(instruction space): 用来存储程序指令所需的空间</li>\n<li>数据空间(data space): 存储运行过程中常量和变量所需的空间</li>\n<li>环境空间: 系统为程序运行，特别是函数调用提供的空间</li>\n</ul>\n<h5 id=\"算法的渐进空间复杂度-S-n-x3D-O-f-n\"><a href=\"#算法的渐进空间复杂度-S-n-x3D-O-f-n\" class=\"headerlink\" title=\"算法的渐进空间复杂度: $S(n) &#x3D; O[f(n)]$\"></a>算法的渐进空间复杂度: $S(n) &#x3D; O[f(n)]$</h5><h5 id=\"输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\"><a href=\"#输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\" class=\"headerlink\" title=\"输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\"></a>输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间</h5><h3 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><h4 id=\"数据元素和数据项\"><a href=\"#数据元素和数据项\" class=\"headerlink\" title=\"数据元素和数据项\"></a>数据元素和数据项</h4><p>数据元素(Data Element): 数据的最小单位</p>\n<p>数据项：(Data Item): 数据结构中讨论的最小单位</p>\n<h4 id=\"数据结构是带结构的数据元素的集合\"><a href=\"#数据结构是带结构的数据元素的集合\" class=\"headerlink\" title=\"数据结构是带结构的数据元素的集合\"></a>数据结构是带结构的数据元素的集合</h4><p>逻辑结构：集合，线性结构，树结构，图结构</p>\n<p>存储结构：顺序存储，链式存储</p>\n<h4 id=\"二元关系\"><a href=\"#二元关系\" class=\"headerlink\" title=\"二元关系\"></a>二元关系</h4><h5 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h5><p>定义：设有几何$M, N$, 其笛卡尔积$M \\times N$的任意一个子集$R \\in M \\times N$</p>\n<p>二元关系表示了集合$M$和集合$N$中元素之间的某种相关性。</p>\n<p>若$(a, b) \\in R$, 则称$a$为$R$的前件，$b$称为$R$的后件。</p>\n<p>若$M &#x3D; N$, 则称$R \\sub M \\times M$为 M 上的二元关系。</p>\n<h5 id=\"二元关系的性质\"><a href=\"#二元关系的性质\" class=\"headerlink\" title=\"二元关系的性质\"></a>二元关系的性质</h5><p>设$R$为集合$M$上的一个二元关系：</p>\n<p>(1) 自反性：对于每个$a \\in M$, 有 $(a, a) \\in R$;</p>\n<p>反自反性： 对于所有$a \\in M$, 有$(a, a) \\notin R$;</p>\n<p>(2) 对称性：当$(a, b) \\in R$时，则$a &#x3D; b$;</p>\n<p>反对称性：当$(a, b) \\in R$且$(b, a) \\in R$时，必有$a &#x3D; b$;</p>\n<p>(3) 传递性： 当$(a, b) \\in R$且$(b, c) \\in R$ 时， 必有$(a, c) \\in R$。</p>\n<h5 id=\"常见的二元关系\"><a href=\"#常见的二元关系\" class=\"headerlink\" title=\"常见的二元关系\"></a>常见的二元关系</h5><p>等价关系：满足自反性、对称性、传递性</p>\n<p>偏序关系：满足自反性、反对称性、传递性</p>\n<p>全序关系：若$M$中的任意两个元素$a$和$b$是可比的，也就是说或者有$aRb$成立，或者有$bRa$成立，则称$R$是集合$M$上的全序关系(Totala Order Relation)</p>\n<h4 id=\"数据类型-Data-Type\"><a href=\"#数据类型-Data-Type\" class=\"headerlink\" title=\"数据类型(Data Type)\"></a>数据类型(Data Type)</h4><h5 id=\"C-语言中的类型定义\"><a href=\"#C-语言中的类型定义\" class=\"headerlink\" title=\"C 语言中的类型定义\"></a>C 语言中的类型定义</h5><p>五种基本数据类型：字符型，整型，浮点型，双精度浮点型和无值类型</p>\n<p>程序中任何变量，常量都必须先定义类型。</p>\n<p>整数类型 int 及定义在其上的操作：+, -, *, &#x2F;, %, ++, –</p>\n<p>双精度浮点型 double 及定义在其上的操作：+, -, *, &#x2F;, ++, –</p>\n<h6 id=\"数据类型用来刻画-程序-操作对象的特性\"><a href=\"#数据类型用来刻画-程序-操作对象的特性\" class=\"headerlink\" title=\"数据类型用来刻画(程序)操作对象的特性\"></a>数据类型用来刻画(程序)操作对象的特性</h6><p>数据类型是一个元素的集合和定义在此集合上的一组操作的总称。</p>\n<p>数据类型实现了信息的隐藏，把一切用户无需了解的细节封装在类型中。</p>\n<p>高级语言中的数据类型分为原子类型和结构类型。</p>\n<h4 id=\"抽象数据类型-Abstract-Data-Type-ADT\"><a href=\"#抽象数据类型-Abstract-Data-Type-ADT\" class=\"headerlink\" title=\"抽象数据类型(Abstract Data Type, ADT)\"></a>抽象数据类型(Abstract Data Type, ADT)</h4><p>是指一个数学模型以及定义在此数学模型上的一组操作。</p>\n<p>数据抽象：描述的是实体的本质特征、功能以及外部用户接口</p>\n<p>数据封装：将实体的外部特性和内在实现细节发呢里，对外部用户隐藏内部实现细节，使得应用和实现分离</p>\n<p>ADT 的优点：</p>\n<ul>\n<li>程序结构清晰，易于扩展易于维护而不失其效率</li>\n<li>提高程序的数据安全性</li>\n<li>大大增加了软件的复用程度</li>\n</ul>\n<h4 id=\"抽象数据类型的描述\"><a href=\"#抽象数据类型的描述\" class=\"headerlink\" title=\"抽象数据类型的描述\"></a>抽象数据类型的描述</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 抽象数据类型名&#123;</span><br><span class=\"line\">    数据对象: &lt;数据对象的定义&gt;</span><br><span class=\"line\">    数据关系: &lt;数据关系的定义&gt;</span><br><span class=\"line\">    基本操作: &lt;基本操作的定义&gt;</span><br><span class=\"line\">    基本操作名(参数表)</span><br><span class=\"line\">        初始条件: &lt;初始条件描述&gt;</span><br><span class=\"line\">        操作结果: &lt;操作结果描述&gt;</span><br><span class=\"line\">&#125;ADT 抽象数据类型名</span><br></pre></td></tr></table></figure>\n\n<p>基本操作参数:</p>\n<ul>\n<li>赋值参数提供输入值</li>\n<li>引用参数以&amp;打头，用于返回操作结果</li>\n</ul>\n<h1 id=\"数据结构-1\"><a href=\"#数据结构-1\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h1><h2 id=\"线性表\"><a href=\"#线性表\" class=\"headerlink\" title=\"线性表\"></a>线性表</h2><p>线性表的元素可以是各种各样的，但是同一线性表的元素必然具有相同特性-同质</p>\n<p>线性表中的相邻元素之间存在有序关系-位序</p>\n<p>线性表是一种“有序结果”，即在数据元素的非空有限集合中</p>\n<ul>\n<li>存在唯一的一个被称为“第一个”的数据元素，无前驱；</li>\n<li>存在唯一的一个被称为的“最后一个”的数据元素，无后继；</li>\n<li>除第一个之外，每一个数据元素均只有一个直接前驱；</li>\n<li>除最后一个之外，每个数据元素均只有一个直接后继</li>\n</ul>\n<p>线性表中元素个数定义为线性表的长度</p>\n<div>$$(a_0, a_1, \\dots, a_{i-1}, a_i, a_{i+1}, \\dots, a_{n-1})$$</div>\n\n<p>若线性表为空，则其长度为 0，称为空表</p>\n<p>在非空表中，每个数据元素都有一个确定的位置</p>\n<ul>\n<li>$a_0$是第 0 个数据元素，$a_{n-1}$是第$n-1$个数据元素</li>\n<li>$a_i$是第 i 个数据元素</li>\n<li>称 i 为数据元素$a_i$在线性表中的位序</li>\n</ul>\n<h2 id=\"线性表-ADT\"><a href=\"#线性表-ADT\" class=\"headerlink\" title=\"线性表 ADT\"></a>线性表 ADT</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT List&#123;</span><br><span class=\"line\">    数据对象:</span><br><span class=\"line\">    数据关系:</span><br><span class=\"line\">    基本操作：</span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">        操作结果：构造一个空的线性表L。</span><br><span class=\"line\">    DestroyList(&amp;L);</span><br><span class=\"line\">        初始条件：线性表已存在。</span><br><span class=\"line\">        操作结果：销毁线性表L。</span><br><span class=\"line\">    IsEmpty(L);</span><br><span class=\"line\">        初始条件：线性表已存在。</span><br><span class=\"line\">        操作结果：若L为空表，则返回TRUE，否则返回FALSE。</span><br><span class=\"line\">    ListLength(L);</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果：用e返回L中第i个数据元素的值</span><br><span class=\"line\">    GetElem(L, i, &amp;e);</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果；用e返回L中第i个数据元素的值。</span><br><span class=\"line\">    LocateElem(L, e, compare());</span><br><span class=\"line\">        初始条件：线性表L已存在，compare()是数据元素判定函数。</span><br><span class=\"line\">        操作结果：返回L中第<span class=\"number\">1</span>个与e满足关系compare()的数据元素的位序。若这样的元素不存在，则返回-<span class=\"number\">1</span>。</span><br><span class=\"line\">    PriorElem(L, cur_e, &amp;pre_e);</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果：若cur_e是L的数据元素，且不是最后一个，则用next_e返回它的后继，否则操作失败，next_e无定义。</span><br><span class=\"line\">    ClearList(&amp;L);</span><br><span class=\"line\">        初始条件：线性表L已存在；</span><br><span class=\"line\">        操作结果：将L重置为空表。</span><br><span class=\"line\">    ListInsert(&amp;L, i, e);</span><br><span class=\"line\">        初始条件：线性表L已存在, <span class=\"number\">0</span> &lt;=i &lt;= ListLength(L)。</span><br><span class=\"line\">        操作结果：在L中第i个位置插入新的数据元素e，L的长度加<span class=\"number\">1</span>。</span><br><span class=\"line\">    ListDelete(&amp;L, i, &amp;e)</span><br><span class=\"line\">        初始条件：线性表L已存在，<span class=\"number\">0</span> &lt;= i &lt;= ListLength(L) - <span class=\"number\">1</span>。</span><br><span class=\"line\">        操作结果：删除L的第i个数据元素，用e返回其值，L的长度减<span class=\"number\">1</span>。</span><br><span class=\"line\">    ListTraverse(L, visit());</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果：依次对L的每个数据元素调用函数 visit()。</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>线性表的合并：$O(m+n)$</p>\n<p>线性表的保序归并：$O(m+n)$</p>\n<p>线性表的顺序存储：顺序表</p>\n<ul>\n<li>用一组地址连续的存储单元依次存储线性表的数据元素</li>\n</ul>\n<p>顺序表的主要操作：</p>\n<p>插入操作：在顺序表的第 i 个位置插入一个新元素，使顺序表的长度增加到$n+1$</p>\n<p>复杂度分析：</p>\n<ul>\n<li>在顺序表的第$i$个位置插入一个新元素，需要移动$n - i$个元素；</li>\n<li>假设从顺序表的第$i$个位置插入元素的先验概率为$p_i$</li>\n<li>插入操作移动元素次数的期望为$E_{insert} &#x3D; \\sum_{i &#x3D; 0}^n(n - i) \\times p_i$</li>\n</ul>\n<p>删除操作：把顺序表的第$i$个位置的元素从表中删除，使长度为$n$的顺序表的长度变为$n - 1$</p>\n<p>复杂度分析：</p>\n<ul>\n<li>把顺序表的第$i$个位置上的元素删除，需要移动$n - i -1$个元素</li>\n<li>假设从顺序表的第$i$个位置删除元素的先验概率为$q_i$</li>\n<li>删除操作移动元素次数的期望为: $E_{delete} &#x3D; \\sum_{i &#x3D; 0}^{n - 1}(n - i - 1) \\times q_i$</li>\n</ul>\n<p>不失一般性，我们假设插入或删除元素出现在任何位置的概率都是相等的，因此有$p_i &#x3D; p &#x3D; 1&#x2F;(n+1), q_i &#x3D; q &#x3D; 1&#x2F;n$。</p>\n<p>推导得到：</p>\n<div>$$E_{insert} = \\frac1{n+1}\\sum_{i = 0}^n(n-i) = \\frac n2\\newline E_{delete} = \\frac1n\\sum_{i = 0}^{n - 1}(n - i - 1) = \\frac{n - 1}2$$</div>\n\n<h2 id=\"单向链表\"><a href=\"#单向链表\" class=\"headerlink\" title=\"单向链表\"></a>单向链表</h2><p>最简单的链表结构：链表节点(node)由两个域组成。</p>\n<p>数据域：存储数据元素，</p>\n<p>指针域：指向直接后继节点</p>\n<p>单向链表的 C++实现：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LinkList</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    NODE *head;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">LinkList</span>() &#123;head = <span class=\"literal\">NULL</span>;&#125;</span><br><span class=\"line\">    ~<span class=\"built_in\">LinkList</span>();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">clearSqList</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">IsEmpty</span><span class=\"params\">()</span></span>&#123;<span class=\"keyword\">return</span> head ==  <span class=\"literal\">NULL</span>;&#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">GetElem</span><span class=\"params\">(<span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">LocateElem</span><span class=\"params\">(<span class=\"type\">int</span> e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">PriorElem</span><span class=\"params\">(<span class=\"type\">int</span> cur_e, <span class=\"type\">int</span> *next_e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">NextElem</span><span class=\"params\">(<span class=\"type\">int</span> cur_e, <span class=\"type\">int</span>* pre_e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">Insert</span><span class=\"params\">(<span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">Delete</span><span class=\"params\">(<span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">Traverse</span><span class=\"params\">(<span class=\"type\">bool</span> (*visit)(<span class=\"type\">int</span> e))</span></span>;<span class=\"comment\">//遍历所有节点</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>单向链表的不足：</p>\n<ul>\n<li>单链表的表长是一个隐含的值，遍历链表才能得到</li>\n<li>在单链表中插入或者删除元素时，需要在链表中依序寻找操作位置</li>\n<li>在链表中，元素的“位序”概念淡化，结点的“位置”概念强化</li>\n<li>如何得到某个元素的前驱？</li>\n</ul>\n<p>改进链表的设置：</p>\n<ul>\n<li><p>增加“表长”、“表尾指针”和“当前位置指针”三个数据域</p>\n</li>\n<li><p>将基本操作中的“位序i”改为“指针p”</p>\n</li>\n</ul>\n<h2 id=\"双向链表\"><a href=\"#双向链表\" class=\"headerlink\" title=\"双向链表\"></a>双向链表</h2><p>由数据，前驱和后继构成。</p>\n<p>方便寻找前驱，但是增加了维护成本。</p>\n<h2 id=\"顺序表和链表的比较：\"><a href=\"#顺序表和链表的比较：\" class=\"headerlink\" title=\"顺序表和链表的比较：\"></a>顺序表和链表的比较：</h2><p>顺序表</p>\n<p>用一组地址连续的存储单元依次存储线性表中的数据元素</p>\n<p>优点：可以随机存取</p>\n<p>缺点：插入，删除操作需要移动表中的数据元素，事先确定规模，空间效率不高。</p>\n<p>链表：</p>\n<p>用一组“任意”的存储单元（附加指针）存储表中的数据元素</p>\n<p>优点：插入，删除操作无需移动表中的数据元素，空间利用率高</p>\n<p>缺点：不能随机存取</p>\n<h2 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h2><p>栈是LIFO(Last In First Out，先进后出)的线性表。</p>\n<p>允许插入和删除的一段称为栈顶(top), 另一端称为栈底(bottom)</p>\n<h3 id=\"栈的ADT\"><a href=\"#栈的ADT\" class=\"headerlink\" title=\"栈的ADT\"></a>栈的ADT</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">Push</span>(&amp;s, e);</span><br><span class=\"line\">    <span class=\"built_in\">Pop</span>(&amp;s, &amp;e);</span><br><span class=\"line\">    <span class=\"built_in\">ClearStack</span>(&amp;s);</span><br><span class=\"line\">&#125; ADT Stack;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"栈的表示和实现\"><a href=\"#栈的表示和实现\" class=\"headerlink\" title=\"栈的表示和实现\"></a>栈的表示和实现</h3><p>栈的顺序表示</p>\n<p>top指向最后一个元素可以，指向空也可以，但是实现时要自洽。</p>\n<p>栈的链式表示</p>\n<p>有头插入和尾插入两个方式</p>\n<p>总体来看，头插入比尾插入的优势要更大。首先，插入时虽然头插入要修改的指针更多，但是时间复杂度小，头插入$O(1)$，尾插入$O(n)$。其次，如果以尾部为栈顶，删除时会很麻烦。</p>\n<p><strong>静态分配</strong></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> STACK_MAX_SIZE 100</span></span><br></pre></td></tr></table></figure>\n<p><strong>动态分配</strong></p>\n<p>程序隐含设定</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> STACK_INT_SIZE 100</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> STACKINCREMENT 10</span></span><br></pre></td></tr></table></figure>\n\n<p>用户给定</p>\n<h3 id=\"复杂度分析\"><a href=\"#复杂度分析\" class=\"headerlink\" title=\"复杂度分析\"></a>复杂度分析</h3><p>顺序栈的效率分析</p>\n<p>时间复杂度</p>\n<ul>\n<li>进栈、出栈:$O(1)$</li>\n<li>栈的溢出处理</li>\n<li>如果栈元素时简单数据类型，则构造和销毁函数也是$O(1)$的</li>\n</ul>\n<p>空间复杂度</p>\n<ul>\n<li>顺序栈的长度构造时确定</li>\n<li>空间利用效率低</li>\n</ul>\n<p>链式栈的效率分析</p>\n<p>时间复杂度</p>\n<ul>\n<li>链式栈的入栈出栈是$O(1)$时间的</li>\n<li>建立和销毁是$O(n)$时间的</li>\n</ul>\n<p>空间复杂度</p>\n<ul>\n<li>一般不会产生溢出</li>\n<li>空间利用率高</li>\n</ul>\n<h3 id=\"栈的一些应用\"><a href=\"#栈的一些应用\" class=\"headerlink\" title=\"栈的一些应用\"></a>栈的一些应用</h3><p>显式应用：括号匹配，表达式求值，迷宫求解</p>\n<p>隐式应用：函数调用，递归</p>\n<p>系统栈</p>\n<h2 id=\"递归\"><a href=\"#递归\" class=\"headerlink\" title=\"递归\"></a>递归</h2><p>栈与递归具有相似性。</p>\n<p>Fibonacci的递归次数：$C(n) &#x3D; O(t^n)$</p>\n<p>(证明思路：归纳法证明$C(n) &#x3D; 2F(n) - 1$, 根据F(n)通项可以判断。)</p>\n<p>使用递推法的时间复杂度：$O(n)$.</p>\n<p>经常需要进行递归的消除。消除方法：递推，循环等，没有统一的解决方案。可以借用显式栈实现非递归过程。</p>\n<p>递归的评价：</p>\n<ul>\n<li>简洁，便于理解，便于叙述和设计</li>\n<li>运行效率低，无法控制递归堆栈的规模</li>\n</ul>\n<h2 id=\"队列\"><a href=\"#队列\" class=\"headerlink\" title=\"队列\"></a>队列</h2><p>队列是FIFO(First In First Out, 先进先出)的线性表。</p>\n<h3 id=\"队列的表示和实现\"><a href=\"#队列的表示和实现\" class=\"headerlink\" title=\"队列的表示和实现\"></a>队列的表示和实现</h3><p>队列的顺序表示法</p>\n<p>入队: rear &#x3D; rear + 1</p>\n<p>出队: front &#x3D; front + 1</p>\n<p>需要判定队满和队空。</p>\n<p>顺序队列的问题：被出队的空间不会再次被使用了。</p>\n<p>循环队列：</p>\n<p>队尾指针指向maxSize - 1时， 入列则指向0；</p>\n<p>队头指针指向maxSize - 1，出列也指向0。</p>\n<p>可以使用模运算实现。</p>\n<p>缺点：无法区分队空和队满的状态。</p>\n<p>区分方法：</p>\n<p>设置一个空位；设置标志；设置队列长度变量</p>\n<p>队列的链式表示法</p>\n<p>入队不会出现队满的问题，出队可能回有队空的问题，队空的条件为front &#x3D; NULL.</p>\n<h2 id=\"串\"><a href=\"#串\" class=\"headerlink\" title=\"串\"></a>串</h2><p>串是有线长度的字符序列。</p>\n<p>串的长度是字符个数。</p>\n<p>字符在串中的位置。</p>\n<p>两个串相等的条件。</p>\n<p>子串和主串，子串在主串中的位置。</p>\n<h3 id=\"匹配算法\"><a href=\"#匹配算法\" class=\"headerlink\" title=\"匹配算法\"></a>匹配算法</h3><p>Brute-Force算法：一个一个比。复杂度最高O(m * n)。</p>\n<p>KMP算法：尽可能跳过更多不必要的匹配。复杂度最多O(m + n)。</p>\n<p>Horspool算法：启发式算法。复杂度低则O(m&#x2F;n)，高则O(m * n + s)，s为字符表规模</p>\n<p>Boyer-Moore算法：最坏O(n)。KMP和Horspool的综合（或者说Horspool是BM算法的简化版本。）</p>\n<h2 id=\"树与二叉树\"><a href=\"#树与二叉树\" class=\"headerlink\" title=\"树与二叉树\"></a>树与二叉树</h2><h3 id=\"树\"><a href=\"#树\" class=\"headerlink\" title=\"树\"></a>树</h3><p>空树，子树。</p>\n<p>结点（node）是树的基本单位。</p>\n<p>结点的度(degree)：结点的子树个数。</p>\n<p>树的度：结点度的最大值。</p>\n<p>k叉树：树的度为k</p>\n<p>child, parent, cousin, ancestor, descendant</p>\n<p>depth&#x2F;height</p>\n<p>树的性质：</p>\n<ol>\n<li>树中结点数等于所有结点度数和加一</li>\n<li>k叉树第i层至多$k^{i - 1}个结点$</li>\n<li>深度为h的k叉树至多有$(k^h - 1)&#x2F;(k - 1)$个结点</li>\n<li>具有n个结点的k叉树的最小深度为$[\\log_k(n(k - 1) + 1)]$</li>\n</ol>\n<h3 id=\"二叉树\"><a href=\"#二叉树\" class=\"headerlink\" title=\"二叉树\"></a>二叉树</h3><p>二叉树是结点的一个有限集合，该集合或者为空，或者是由一个根节点加上两棵分别称为左子树和右子树的、互不相交的二叉树组成。</p>\n<p>二叉树的性质：</p>\n<ol>\n<li>叶子结点数 &#x3D; 度为二的结点数 + 1</li>\n<li>第i层至多$2^{i - 1}$个结点</li>\n<li>深度为h，则最多有$(2^h - 1)$个结点</li>\n<li>具有n个结点的完全二叉树的深度为$\\lceil\\log_2(n + 1)\\rceil$</li>\n<li>对于完全二叉树（最后一层从右向左缺若干结点），从左向右，从上到下编号，则$\\lfloor(i - 1)&#x2F;2\\rfloor$为编号i的parent结点，$2i + 1$为其左子树，$2i + 2$为其右子树。</li>\n</ol>\n<p>二叉树的顺序表示</p>\n<p>完全二叉树按照编号存储。不完全二叉树按照它对应的完全二叉树存储，但是缺少的部分留空。</p>\n<p>不完全二叉树结点越少，空间效率越低。</p>\n<p>二叉树的链式表示</p>\n<p>空间效率很高。</p>\n<p>二叉树的遍历：</p>\n<p>记根节点为V，遍历左子树为L，遍历右子树记为R</p>\n<p>先序遍历：V - L - R</p>\n<p>中序遍历：L - V - R</p>\n<p>后序遍历：L - R - V</p>\n<p>遍历可以通过递归实现，但是递归可能会对效率产生影响。可以利用栈的特性实现遍历。</p>\n<p>层序遍历：从上到下优先遍历同一层的结点。</p>\n<p>遍历实现了树的线索化过程。</p>\n<h3 id=\"霍夫曼树\"><a href=\"#霍夫曼树\" class=\"headerlink\" title=\"霍夫曼树\"></a>霍夫曼树</h3><p>霍夫曼树：寻找加权路径长度(WPL)的最小树。</p>\n<p>用途：实现性能最好的变长二进制编码。</p>\n<p>霍夫曼编码不是唯一的，但是所有霍夫曼树的WPL都相等。</p>\n<p>不足：</p>\n<p>没有错误保护功能</p>\n<h3 id=\"二叉树的建立\"><a href=\"#二叉树的建立\" class=\"headerlink\" title=\"二叉树的建立\"></a>二叉树的建立</h3><p>只知道二叉树的先序序列，不能确定这棵二叉树。</p>\n<p>但是如果同时知道先序序列和中序序列，则可以确定这棵二叉树。</p>\n<h2 id=\"图\"><a href=\"#图\" class=\"headerlink\" title=\"图\"></a>图</h2><h3 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h3><p>图的定义</p>\n<p>顶点，边，弧</p>\n<p>邻接顶点</p>\n<p>有向图，无向图</p>\n<p>有向完全图，无向完全图</p>\n<p>子图</p>\n<p>握手定理，度</p>\n<p>权，网络<br>边上的数叫做权。有权的图叫网络。</p>\n<p>连通</p>\n<p>连通图</p>\n<p>连通分量<br>无向图的极大连通子图为连通分量。（所谓极大，就是再加入一个点都会导致它不连通）</p>\n<p>强连通图<br>有向图中存在vi到vj且存在vj到vi的图。</p>\n<p>强连通分量<br>有向图的极大强连通子图为强连通分量。</p>\n<p>Euler路径和Euler回路</p>\n<p>图的存储和表示</p>\n<p>邻接矩阵表示<br>如果v和w之间有边，则元素为1，否则为0.</p>\n<p>邻接表表示<br>采用链表数组表示图。同一个顶点发出的边在同一个链表中。</p>\n<h3 id=\"图的遍历\"><a href=\"#图的遍历\" class=\"headerlink\" title=\"图的遍历\"></a>图的遍历</h3><p>深度优先遍历和广度优先遍历</p>\n<p>图的遍历：从已给连通图的某一顶点出发，沿着一些边访问所有顶点，且每个顶点只访问一次，则叫做图的遍历。</p>\n<p>邻接矩阵的遍历：$O(v^2)$</p>\n<p>邻接表的遍历：$O(v + e)$</p>\n<h3 id=\"生成树\"><a href=\"#生成树\" class=\"headerlink\" title=\"生成树\"></a>生成树</h3><p>连通图的生成树，包含图中全部n个顶点，但只有n-1条边。</p>\n<p>深度优先和广度优先遍历分别会得到一个搜索树。</p>\n<p>最小生成树：权值之和最小的生成树。</p>\n<p>求最小生成树的算法：贪心算法思想。Kruskal算法和Prim算法。</p>\n<p>Prim算法</p>\n<p><img src=\"/../images/DSA/Prim.jpg\" loading=\"lazy\"></p>\n<p>Prim算法的时间复杂度为$O(n^2)$。对稠密图而言是线性的。对于稠密图而言，Prim的邻接矩阵实现是首选方法。</p>\n<p>Kruskal算法<br><img src=\"/../images/DSA/Kruskal.jpg\" loading=\"lazy\"></p>\n<p>Kruskal的时间复杂度为$O(E\\log E)$。</p>\n<p>Kruskal算法对于稀疏图是好的选择。</p>\n<h3 id=\"最短路径树\"><a href=\"#最短路径树\" class=\"headerlink\" title=\"最短路径树\"></a>最短路径树</h3><p>从根到其他顶点的最短路径</p>\n<p>源点-汇点最短路径：给定一个起始顶点s和一个结束顶点 ，在图中找出从s到t的一条路径。起始顶点称为“源点”，结束顶点称为“汇点”</p>\n<p>单源最短路径：给定一个起始顶点s，找出从s到图中其它各顶点的最短路径</p>\n<p>全源最短路径：找出连接图中各对顶点的最短路径</p>\n<h4 id=\"单源最短路径\"><a href=\"#单源最短路径\" class=\"headerlink\" title=\"单源最短路径\"></a>单源最短路径</h4><p>Dijkstra算法</p>\n<p><img src=\"/../images/DSA/Dijkstra.jpg\" loading=\"lazy\"></p>\n<p>Dijkstra算法通过构造加权有向图图的最短路径树SPT，来实现单源最短路径算法。</p>\n<p>时间复杂度为$O(v^2)$，和Prim算法很相似。</p>\n<h4 id=\"全源最短路径\"><a href=\"#全源最短路径\" class=\"headerlink\" title=\"全源最短路径\"></a>全源最短路径</h4><p>可以对每个顶点用Dijkstra算法。</p>\n<p>Floyd算法</p>\n<p>时间复杂度：$O(v^3)$。可以计算出一个网络中所有的最短路径。</p>\n<p>Floyd算法允许图中带有负权值的边，但不允许有包含带负权值的边组成回路。</p>\n<h1 id=\"算法-1\"><a href=\"#算法-1\" class=\"headerlink\" title=\"算法\"></a>算法</h1><h2 id=\"非数值算法\"><a href=\"#非数值算法\" class=\"headerlink\" title=\"非数值算法\"></a>非数值算法</h2><h3 id=\"查找\"><a href=\"#查找\" class=\"headerlink\" title=\"查找\"></a>查找</h3><p>查找算法的复杂性：关键字&#x2F;数据规模</p>\n<p>查找算法的分类：</p>\n<ul>\n<li>内部&#x2F;外部</li>\n<li>静态&#x2F;动态</li>\n</ul>\n<h4 id=\"查找表\"><a href=\"#查找表\" class=\"headerlink\" title=\"查找表\"></a>查找表</h4><p>查找表（Search Table）是由同一类型数据元素构成的集合。</p>\n<p>按关键字查找</p>\n<ol>\n<li>查询某元素是否存在</li>\n<li>检索某数据元素的各种属性</li>\n<li>在查找表中插入一个数据元素</li>\n<li>从查找表中删除一个数据元素</li>\n</ol>\n<p>查找表的种类</p>\n<ol>\n<li>静态查找表-仅可执行1,2</li>\n<li>可执行1,2,3,4</li>\n</ol>\n<p>平均查找长度：在查找过程中，为确定目标在查找表中的位置，需要进行关键字比较次数的期望值</p>\n<div>$$\nASL = \\sum_{0}^{n - 1}P_i C_i\n$$</div>\n\n<p>$P_i$为第i条记录的查找概率，$C_i$为第i条记录的查找长度。</p>\n<p>有时我们会假设查找概率相等或不等，有时要考虑查找失败的比较次数。</p>\n<p>ASL越小，查找性能越好。</p>\n<p>顺序查找：又称线性查找，是从线性<br>表的一端开始，依次把每个元素的<br>关键字同给定值进行比较</p>\n<p>假设每个元素的查找概率相等，则平均查找长度为：$ASL &#x3D; \\sum_0^{n - 1}\\frac{i + 1}{n} &#x3D; \\frac{n + 1}{2}$。</p>\n<p>更多考虑：查找概率不等；查找失败需要N次比较；越界判断</p>\n<p>折半查找：如果顺序表有序，我们可以采用高效率的折半查找</p>\n<p>折半查找可以用一个二叉树结构来表述。比较次数不会超过$\\lfloor\\log_2 N + 1\\rfloor$。</p>\n<p>索引查找：将线性表划分为若干子表，再建立指向这若干子表的一个索引表。相同性质的数据归类到一个子表中。</p>\n<p>索引表：顺序表或链表</p>\n<p>子表：顺序表或链表</p>\n<p>因而可以有四种不同的索引存储方式。</p>\n<p>索引表的特点：表不大， 表中元素不常变动。因而适合用顺序表来表示索引表。</p>\n<p>分块查找：也称索引顺序查找，是顺序查找的改进。子表之间有序；块内元素无序。索引表包括关键字项，指针项，子表长度。</p>\n<p>索引文件：单关键字，多关键字。</p>\n<p>稠密索引：索引表的索引项和主文件的各记录一一对应，称为稠密索引。</p>\n<p>稀疏索引（非稠密索引）：索引项对应主文件的一部分记录。</p>\n<p>索引文件的好处：减少访问外存的次数，提高查找速度。</p>\n<p>倒排文件：不同之处是辅索引表包含物理地址序列。（为什么要倒排？）</p>\n<h4 id=\"二叉搜索树（BST）\"><a href=\"#二叉搜索树（BST）\" class=\"headerlink\" title=\"二叉搜索树（BST）\"></a>二叉搜索树（BST）</h4><p>或者是一棵空树，或者是具有下列性质<br>的二叉树：每个结点有一个关键字(key)，<br>并且:</p>\n<ol>\n<li>任意结点关键字大于等于该结点左<br>子树中所有结点含有的关键字</li>\n<li>同时该结点的关键字小于等于右子<br>树中所有结点含有的关键字</li>\n</ol>\n<p>BST是一种重要的动态搜索结构。它的中序遍历是确定的。 </p>\n<p>BST的插入操作和查找操作同样简单。</p>\n<p>删除操作比较复杂。叶子结点的删除比较简单；如果结点只有一棵子树，也比较简单；如果左右子树都不空，可以用中序后继替换。</p>\n<p>BST的性能：越“平衡”越好。</p>\n<p>二叉搜索树的路径长度和高度直接关系到BST中搜索的开销，对于一棵<br>含有N个关键字的BST</p>\n<ul>\n<li>最好情况下，所有搜索都可以保证对数运行时间</li>\n<li>最坏情况下，进行一次搜索需要 次比较</li>\n<li>平均情况下搜索需要 次比较操作</li>\n</ul>\n<p>BST的旋转操作：结点和一个子孙交换角色。分为左旋转和右旋转。右旋转涉及到结点和右孩子。（右旋转和左旋转是以结点自己作为参考系而言。）</p>\n<p>BST通过不断的旋转来保证自己的平衡性。</p>\n<p>AVL树：<br>一棵AVL树或者是空树，或者是具有下列性质的二叉搜索树:</p>\n<ol>\n<li>左子树和右子树都是AVL树</li>\n<li>且左子树和右子树的高度之差的绝对<br>值不超过1</li>\n</ol>\n<p>AVL的高度为$O(\\log_2 n)$，平均查找长度也为$O(\\log_2 n)$。</p>\n<p>AVL具有良好的搜索性能，能够避免一般BST性能恶化的问题。但是AVL的维护比较复杂，在进行插入和删除操作后，都必须通过大量的旋转操作保证AVL的平衡性。</p>\n<p>寻找其他方法，以提高BST的平衡程度，保证BST的性能。</p>\n<ul>\n<li><p>实用的平衡二叉搜索树-红黑树</p>\n</li>\n<li><p>多路平衡的动态查找结构-B-树</p>\n</li>\n</ul>\n<h4 id=\"散列\"><a href=\"#散列\" class=\"headerlink\" title=\"散列\"></a>散列</h4><p>散列的关键是散列函数和冲突处理。</p>\n<p>散列函数应是简单的，能在较短的时间内计算出结果</p>\n<p>散列函数的定义域必须包括需要存储的全部关键码，如果散列表允许有m<br>个地址，其值域必须在0到m-1之间</p>\n<p>理想的散列函数应近似为随机的，对每一个输入，相应的输出在值域上是<br>等概的。</p>\n<p>冲突处理：</p>\n<ul>\n<li>链地址法：把散列到同一个地址的关键字存进链表中。（表长小于元素数目）</li>\n<li>开放定址法：放在表中空的位置。查找时采用“探测”的方法。如果探测下一个位置，称为线性探测。（表长大于元素数目，稀疏表，一般不允许表达到半满状态）</li>\n<li>双重散列法：用第二个散列函数表达散列的增量。时间复杂度略大，但是性能比线性探测好很多。</li>\n</ul>\n<p>散列的其他应用：字符串的匹配；搜索引擎对URL的散列；信息安全中的内容鉴别技术（MD5, sha）。</p>\n<p>散列提供常数时间的查找性能，实现简单；但是好的散列函数不易找到，删除操作和空间性能不好，最坏情况下性能不好，忽略了数据间的逻辑关系。</p>\n<h3 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h3><p>排序算法的稳定性：如果两个对象的排序码相等，排序前后的顺序不变，则是稳定的；否则是不稳定的。</p>\n<p>内排序：数据对象存放在内存。</p>\n<p>外排序：数据对象在内、外存之间移动。</p>\n<p>冒泡排序：复杂度为$O(n^2)$。添加排序标记，最好情况下只需要$n - 1$次比较和0次交换。</p>\n<p>插入排序：有直接插入，折半插入，希尔排序</p>\n<p>直接插入：$O(n^2)$</p>\n<p>折半插入：查找插入位置的时候可以采用折半查找，因为表中可以插入的部分已经排好序了。复杂度没有变化，依然是$O(n^2)$</p>\n<p>希尔排序：如果序列中，间距为h的元素都有序，称这个序列为h-排序的。希尔排序就是不断缩小h，直到h&#x3D;1。</p>\n<p>选择特定的步长序列$h_n$，取出序列中增量为$h_n$的子列进行插入排序。然后取$h_{n-1}$，直至取$h_1&#x3D;1$。</p>\n<p>它在h比较大的时候排序，由于间距短，速度快；而h小的时候，由于有序性强，速度快。总体速度依赖于步长序列的选择，时间复杂度比直接插入好一些。</p>\n<p>选择排序：比较次数$O(n^2)$，移动次数$O(n)$，移动次数少一些。</p>\n<p>冒泡排序和插入排序都是稳定的，而选择排序是不稳定的。</p>\n<p><strong>快速排序</strong>：一种交换类排序。具有很好的性能。</p>\n<p>将待排序序列分为两个部分，满足：</p>\n<ol>\n<li>a[i]位于它在序列中的正确位置</li>\n<li>前面的元素比a[i]小</li>\n<li>后面的元素比a[i]大<br>然后对两个部分继续划分，每次划分都将一个元素划分到它的正确位置。</li>\n</ol>\n<p>如何划分：</p>\n<p>选择划分元素v。从序列左边扫描，找到一个比v大的元素，从右边扫描，找到一个比v小的元素，交换两个元素。反复交换，直到左右扫描指针相遇，则划分完成。</p>\n<p>快速排序的递归树是一颗二叉搜索树，因为每次递归都是对比自己大和比自己小的两个部分递归。</p>\n<p>时间复杂度：理想情况下$O(N\\log_2N)$，如果递归树是平衡的。平均情况下为$O(N\\log N)$，而最坏情况下退化为$O(N^2)$。</p>\n<p>快速排序是不稳定的排序算法。</p>\n<p>改进：</p>\n<p>划分元素是最大或者最小的元素时是最坏情况。为了避免最坏情况，采用中间元素法：取序列的左端元素，右端元素和中间元素，选择关键字处于中间的元素作为划分元素。</p>\n<p>快速排序中，子序列非常小时仍然要递归调用，可以采用插入排序代替，提高效率。</p>\n<p>归并排序：合并有序表。两个表的归并，叫二路归并。利用二路归并可以实现归并排序。</p>\n<p>自底向上归并：将文件分割成长度为m的子序列，每次m翻倍。</p>\n<p>自顶向下归并：将文件分割为两个部分，分别进行递归的归并排序后再合起来进行归并排序。</p>\n<p>归并排序是稳定的，时间最好情况是$O(N\\log N)$，最坏是$O(N^2)$.</p>\n<p>堆：堆是满足堆性质的完全二叉树。</p>\n<p>最大堆：任意节点的值小于父节点的值。</p>\n<p>最小堆；任意节点的值小于父节点的值。</p>\n<p>因为是完全二叉树，适合用顺序存储方式。</p>\n<p>堆：顺序存储在一维数组中。</p>\n<p>堆的操作，例如插入，删除或者修改结点会破坏堆的性质，因此修复堆是重要的操作。</p>\n<p>对于最大堆，如果某结点的关键值小于其子节点的关键值，可以采用自顶向下堆化(Heapify-down)的算法进行修复。</p>\n<p>对于最大堆，若结点的关键值大于父节点的关键值，采用自底向上堆化(Heapify-up的算法进行修复)</p>\n<p>向堆中插入结点：在新节点插入堆尾，调用自底向上算法调整堆。这种构造堆方法称为自顶向下的堆构造。</p>\n<p>自顶向下的堆构造：$O(N\\log N)$</p>\n<p>自底向上的堆构造：时间复杂度$O(N)$</p>\n<p>自底向上构造复杂度小的原因：离根远的复杂度小，离根近的复杂度大。而自顶向下是离根远的复杂度大，离根近的复杂度小。离根远的数量多，而离根近的数量少，因此自底向上的整体的复杂度更小。</p>\n<p>优先级队列可以用堆实现，性能非常好。</p>\n<p>堆排序：节约空间，比较次数和移动次数都是$O(N\\log N)$。堆排序是不稳定的排序方法。</p>\n<p>从小到大排序的方法：自底向上构造最大堆。将堆首与堆尾交换，堆序列长度-1，调整堆，再次交换，重复上述过程，直到堆空。</p>\n<blockquote>\n<p>堆排序大概可以理解成优先队列的出队过程。</p>\n</blockquote>\n<p>采用决策树的方法可以求得比较次数的下界为$O(N\\log N)$</p>\n<h2 id=\"数值算法\"><a href=\"#数值算法\" class=\"headerlink\" title=\"数值算法\"></a>数值算法</h2><h3 id=\"基础\"><a href=\"#基础\" class=\"headerlink\" title=\"基础\"></a>基础</h3><p>一个数值问题是适定的(well posed)，需要满足：</p>\n<ul>\n<li>解存在</li>\n<li>解唯一</li>\n<li>连续地依赖于问题数据</li>\n</ul>\n<p>不满足条件的问题被称为不适定的(ill-posed)。</p>\n<p>适定的问题，如果解对输入数据非常敏感，则称之为病态的(ill-conditioned)。</p>\n<p>针对适定和良态(well-conditioned)问题，数值分析可以得到具有一定精度的近似解。</p>\n<p>数值分析重视误差。误差&#x3D;计算误差+传播误差，算法影响的是计算误差。误差有模型误差、测量误差、截断误差、舍入误差。</p>\n<p>前向误差反映了输出的误差，后向误差反映了输入的误差。相对前向误差与相对后向误差的比值叫做条件数(condition number)。$cond \\le 1$说明问题是良态的；否则是病态的。</p>\n<p>实际问题中我们通常求解条件数的估计值或者上限。进而求得前向误差。</p>\n<p>相对条件数:$\\left|\\frac{xf^\\prime (x)}{f(x)}\\right|$。绝对条件数：$\\left|f(x)\\right|$</p>\n<p>算法的稳定性：如果一个算法对于计算过程中的微小扰动不敏感，则算法是稳定的。</p>\n<p>问题的病态性针对输入数据的微小扰动，而算法的稳定性针对的是计算过程中的误差。</p>\n<p>最近舍入法：与x最相近的浮点数，如果相等，取最后一个存储位为偶数。</p>\n<p>若是偶数，则区间是闭区间；若是奇数，则对应的区间为开区间。</p>\n<p>浮点数的下溢限主要由尾数决定，机器精度由尾数决定。</p>\n<p>浮点数的表示法:</p>\n<div>$$\nx = \\pm \\left(d_0 + \\frac{d_1} \\beta + \\frac{d_2} {\\beta^{2}}+ \\dots + \\frac{d_{p-1}} {\\beta^{p-1} } \\right)\\beta^E\n$$</div>\n\n<p>在正规化浮点数系统中：</p>\n<div>$$\n\\text{UFL}=\\beta_L\\\\\n\\text{OFL}=\\beta^{U+1}(1 - \\beta^{1-p})\\\\\n$$</div>\n\n<p>机器精度：舍入造成的相对误差上限：</p>\n<div>$$\n\\left|\\frac{fl(x) - x}{x}\\right| \\le \\epsilon_{mach}\n$$</div>\n\n<p>最近舍入方式下：</p>\n<div>$$\n\\epsilon_{mach} = \\beta^{1-p} / 2\n$$</div>\n\n<h3 id=\"线性方程求解\"><a href=\"#线性方程求解\" class=\"headerlink\" title=\"线性方程求解\"></a>线性方程求解</h3><p>解矩阵方程$A\\mathbb x &#x3D; \\mathbb b$。</p>\n<p>误差分析：</p>\n<p>条件数：$\\text{cond}(A) &#x3D; ||A||||A^{-1}||$</p>\n<p>直观理解：两条线接近平行的时候，两条线截距的轻微扰动会造成解很大的不确定性。</p>\n<p>解方程：</p>\n<p>直接求解法</p>\n<p>高斯消元法：复杂度$O(n^3)$。通常采用列选主元的方法提高算法的稳定性。</p>\n<p>LU分解：如果$b$变化而$A$不变，可以较快地多次求解。</p>\n<p>解的精度分析：条件数大，即使残差很小，也会得出极大的计算误差。是因为问题本身非常敏感。</p>\n<p>高斯-约当法：把A变换为对角阵。</p>\n<p>乔列斯基分解：A是对称正定阵，则A&#x3D;LL’。</p>\n<ul>\n<li>算法是良态的</li>\n<li>不需要选主元就有稳定性</li>\n<li>只需要存储下三角部分即可</li>\n<li>分解的乘法和加法次数都约为$n^3&#x2F;6$</li>\n</ul>\n<p>线性方程的迭代解法：</p>\n<p>不动点迭代法：</p>\n<div>$$\nAx = b \\Rightarrow x = Gx + C\n$$</div>\n\n<p>不动点迭代的收敛核心在于G。</p>\n<p>对于矩阵M，定义谱半径$\\rho(M)$为M的特征值绝对值的最大值。</p>\n<p>如果$\\rho(G)&lt; 1$，则不动点迭代收敛。</p>\n<p>分裂$A &#x3D; M - N$，则</p>\n<div>$$\n(M - N)x = b\\Rightarrow\\\\\nx = M^{-1}Nx + M^{-1}b\n$$</div>\n\n<p>当$\\rho(M^{-1}N) &lt; 1$时，不动点迭代收敛。</p>\n<p>Jacobi（雅克比）方法：$A &#x3D; D + L + U$, $M &#x3D; D$, $N &#x3D; - (L + U)$, $x^{k+1} &#x3D; D^{-1}[b - (L+U)x^k]$。</p>\n<p>高斯-赛德方法：<br>$A &#x3D; D + L + U$, $M &#x3D; D + L$, $N &#x3D; -U$, $x^{k+1} &#x3D; (D+L)^{-1}(b - Ux^k)$。</p>\n<p>这两种迭代都不一定收敛，但是实际中一般都可以。高斯赛德方法速度比雅克比快一倍。</p>\n<h3 id=\"非线性方程求解\"><a href=\"#非线性方程求解\" class=\"headerlink\" title=\"非线性方程求解\"></a>非线性方程求解</h3><p>误差分析：</p>\n<p>非线性方程$f(x) &#x3D; 0$，真解为$x^*$，近似解为$\\hat x$。</p>\n<p>残差：$||f(\\hat x)||$</p>\n<p>前向误差：$||\\hat x - x^*||$，能更准确地描述解的精确程度。</p>\n<p>绝对条件数：$1&#x2F;|f^\\prime(x^*)|$</p>\n<p>可见，如果f(x)在$x^*$处接近水平，则问题是病态的。</p>\n<p>具有重根的问题也是病态的。</p>\n<p>解法：</p>\n<p>二分法：定义误差$e_k &#x3D; x_k - x^*$，定义迭代法的收敛速度定义：$\\lim_{k\\rightarrow \\infty}\\frac{||e_{k + 1}||}{||e_k||^r} &#x3D; C$，则收敛速度为$r$。r&#x3D;1称为线性的，r&gt;1称为超线性的，r&#x3D;2称为平方的。二分法的迭代次数与函数的具体形式无关。</p>\n<p>不动点迭代法：</p>\n<p>收敛性：</p>\n<div>$$\n\\lim_{k\\rightarrow \\infty}\\frac{||e_{k+1}||}{||e_k||} \\\\=\\lim_{k\\rightarrow \\infty}\\frac{g(x_k) - x^*}{x_k - x^*} \\\\\n= \\lim_{k\\rightarrow \\infty} g^\\prime (\\xi_k) = g^\\prime(x^*) \n$$</div>\n\n<p>绝对条件数为$g^\\prime(x^*)$。如果$|g^\\prime(x^*)|$非零，则收敛是线性的，如果为0，则是超线性的。</p>\n<p>牛顿迭代法：</p>\n<div>$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}\n$$</div>\n\n<p>由于$g^\\prime(x^*)&#x3D;0$，收敛是超线性的。进一步分析得到$\\lim_{k\\rightarrow \\infty}\\frac{x_{k+1} - x^*}{(x_k - x^*)^2} &#x3D; \\frac{f^{\\prime\\prime}(x^*)}{2f^\\prime(x)}$，因此牛顿法是平方收敛的。</p>\n<p>牛顿法的特点：</p>\n<ul>\n<li>初值的选取很重要</li>\n<li>$f^\\prime(x)\\ne 0$</li>\n<li>速度快，但是可能出现振荡的情况</li>\n<li>对多重根的收敛速度退化为线性</li>\n<li>涉及到求导，有时候比较困难</li>\n</ul>\n<p>准牛顿法：免去了求导</p>\n<div>$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{g_k}\n$$</div>\n\n<p>割线法：准牛顿法的一种</p>\n<div>$$\ng_k = \\frac{f(x_k) - f(x_{k - 1})}{x_k - x_{k - 1}}\n$$</div>\n\n<p>反插：割线法是用两次的迭代值确定一条直线，取直线与x轴的交点。可以采用反二次插值：用前三次迭代值确定抛物线$x &#x3D; p(y)$，取它与x轴的交点。</p>\n<p>二分法较安全，但速度慢；迭代法速度快，但不安全。可以在区间较大时采用二分法缩小区间，等区间较小时再采用迭代法。</p>\n<h3 id=\"拟合与插值\"><a href=\"#拟合与插值\" class=\"headerlink\" title=\"拟合与插值\"></a>拟合与插值</h3><h4 id=\"拟合\"><a href=\"#拟合\" class=\"headerlink\" title=\"拟合\"></a>拟合</h4><p>如果方程的数目多于未知数的数目，则是超定方程。</p>\n<p>如果方程的数目少于未知数的数目，则是欠定方程。</p>\n<p>超定方程在线性最小二乘的意义下得到一个近似解。</p>\n<p>转而求解$A^TAx &#x3D; A^Tb$。如果矩阵A是列满秩的，则解唯一。</p>\n<p>若$A^TA$是正定的，则有$A &#x3D; LL^T$。</p>\n<p>可以采用QR分解将长方阵A简化：</p>\n<div>$$\nA = Q\\begin{bmatrix}\nR\\\\\n0\n\\end{bmatrix}\n$$</div>\n\n<p>进一步，如果$Q &#x3D; \\begin{bmatrix}Q_1\\Q_2\\end{bmatrix}$，则$Rx &#x3D; Q_1^Tb$。</p>\n<p>利用household变换进行QR分解。</p>\n<p>正规方程方法的复杂度：$mn^2&#x2F;2  + n^3&#x2F;6$</p>\n<p>household变换的复杂度：$mn^2 - n^3 &#x2F; 3$</p>\n<p>如果m和n相当，则两种变换的复杂度相当，而m远大于n时，QR分解的复杂度是正规方程方法的两倍。</p>\n<p>QR分解的适用性更宽。</p>\n<h4 id=\"插值\"><a href=\"#插值\" class=\"headerlink\" title=\"插值\"></a>插值</h4><p>插值使得函数精确地通过给定数据点。</p>\n<p>单项式基底：$\\phi_j(x) &#x3D; x^{j - 1}$。给定点数越多的插值问题，病态性越高，插值多项式的系数不稳定。</p>\n<p>霍纳法则：$t_1 + x(t_2+x(t_3+(\\dotsb)))$，减少乘法次数。</p>\n<p>拉格朗日插值：</p>\n<div>$$\nl_j(x) = \\frac{\\prod_{k = 1, k \\ne j}^{n}(x - x_k)}{\\prod_{k = 1, k\\ne j}^{n}(x_j - x_k)}\n$$</div>\n\n<ul>\n<li>确定形式容易</li>\n<li>计算值困难</li>\n<li>微分，积分不方便</li>\n</ul>\n<p>牛顿插值：基底取$\\prod_{k &#x3D; 1}^{j - 1}(t - t_k)$。</p>\n<ul>\n<li>容易确定，系数较容易求解</li>\n<li>计算可以通过类似霍纳法则的方法求得，时间复杂度低</li>\n<li>在确定和求值之间形成了较好的平衡。</li>\n</ul>\n<h3 id=\"优化问题\"><a href=\"#优化问题\" class=\"headerlink\" title=\"优化问题\"></a>优化问题</h3><p>分为连续优化问题和离散优化问题。</p>\n<p>可行点，约束集合。</p>\n<h4 id=\"连续优化问题\"><a href=\"#连续优化问题\" class=\"headerlink\" title=\"连续优化问题\"></a>连续优化问题</h4><p>有线性规划和非线性规划问题。</p>\n<p>线性规划：不细讲。</p>\n<p>非线性规划：</p>\n<p>（严格&#x2F;非严格）全局最小值，局部最小值。全局最小值的求解，甚至验证都很困难。</p>\n<p>闭集：闭集是补集为开集的集合。如果一个集合中所有的极限点都是这个集合中的点，则这个集合是闭集。</p>\n<p>有界闭集上的连续函数有全局最小值。如果不是闭的或者无界，就可能没有最小值。</p>\n<p>$\\lim_{||x||\\rightarrow \\infty} f(x) &#x3D; \\infty$，称$f(x)$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的。</p>\n<p>如果连续函数$f$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的，则$f$在$S$上存在全局最小值。</p>\n<p>集合是凸的：任意两点的连线属于这个集合。</p>\n<p>函数是凸的：区间内函数值不超过端点连线上的函数值。</p>\n<p>如果集合和函数都是凸的，称为凸优化问题。</p>\n<p>我们有如下结论：</p>\n<ul>\n<li>如果$f$是凸集$S\\sube \\mathbb{R^n}$上的凸函数，则在 $S\\sube \\mathbb{R^n}$的任意内点上连续</li>\n<li>凸函数$f$在凸集$S\\sube \\mathbb{R^n}$上的任意局部最小值，都是$f$在$S\\sube \\mathbb{R^n}$上的全局最小值</li>\n<li>严格凸函数$f$在凸集 $S\\sube \\mathbb{R^n}$上的局部最小值，是$f$在$S\\sube \\mathbb{R^n}$上的唯一全局最小值</li>\n<li>如果$f$在有界闭集$S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一的全局最小值</li>\n<li>如果$f$在无界闭集 $S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一全局最小值的充要<br>条件是$f$在$S\\sube \\mathbb{R^n}$上是强制的</li>\n</ul>\n<p>下面考虑无约束优化：</p>\n<p>梯度为0的点是临界点。</p>\n<p>临界点可能是局部最大值&#x2F;最小值&#x2F;鞍点。</p>\n<p>如果函数是凸的，临界点就是全局最小值点。</p>\n<p>海森矩阵正定，则f是凸的。</p>\n<p>如果$x^*$是函数$f$的最小值，<br>则$\\nabla f(x^*) &#x3D; 0$，$\\nabla^2f(x^*)$非负定。</p>\n<p>如果$\\nabla f(x^*) &#x3D; 0$且$\\nabla^2f(x^*)$正定，则$x^*$是严格局部最小值。</p>\n<p>如果是凸优化，则$\\nabla f(x^*) &#x3D; 0\\Leftrightarrow f(x^*)$为严格局部最小值</p>\n<p>矩阵的正定性：</p>\n<ul>\n<li>特征值全正</li>\n<li>Cholesky分解唯一</li>\n<li>顺序主子式的行列式全正</li>\n</ul>\n<p>拉格朗日乘数法：</p>\n<div>$$\n\\mathcal{L}(x, \\lambda) = f(x) + \\lambda^Tg(x)\n$$</div>\n\n<p>海森矩阵：</p>\n<div>$$\nH_{\\mathcal{L}}(x, \\lambda) = \\begin{bmatrix}\n    B(x, \\lambda) && J_g^T(x)\\\\\n    J_g(x) && 0\n\\end{bmatrix}\\\\\nB(x,\\lambda) = H_f(x) + \\sum_{i = 1}^m\\lambda_iH_{g_i}(x)\n$$</div>\n\n<p>只要$B(x^*, \\lambda^*)$正定，则$x^*$是极小值点。</p>\n<p>敏感性和病态性：依赖于海森矩阵</p>\n<ul>\n<li>海森矩阵奇异，则极值问题病态</li>\n<li>海森矩阵接近奇异，则极值问题敏感</li>\n</ul>\n<p>下面考虑一维优化问题：</p>\n<p>单峰函数:最小值左侧递减，最小值右侧递增。</p>\n<p>类似于二分法，可以用黄金分割搜索求单峰函数的极小值。</p>\n<p>好处：每次迭代只需要更新一个点；安全性好；收敛速度线性；</p>\n<p>坏处：收敛速度还可以提高。</p>\n<p>方法二：逐次抛物插值。用两个端点和一个近似极值点拟合一条抛物线，取抛物线的最小值点作为新的近似极值点，反复直到收敛。</p>\n<p>当初始点接近极值点时能够收敛；收敛是超线性的。</p>\n<p>牛顿迭代法：</p>\n<div>$$\nx_{k + 1} = x_k - \\frac{f'(x_k)}{f''(x_k)}\n$$</div>\n\n<p>实际上采用黄金分割搜索和逐次抛物插值混合方案，避免求函数的导数。</p>\n<p>多维优化问题：</p>\n<p>最速下降法：</p>\n<div>$$\nx_{k + 1} = x_k - \\alpha_k\\nabla f(x_k)\n$$</div>\n\n<p>确定$\\alpha_k$：$\\min_{\\alpha_k} f(x_k - \\alpha_k \\nabla f(x_k))$</p>\n<p>非常可靠，只要梯度不为0；速度可能不快，呈之字形；收敛速度线性；初值的选择很重要。</p>\n<p>牛顿法：</p>\n<div>$$\nx_{k + 1} = x_k - H_f^{-1}(x_k)\\nabla f(x_k)\n$$</div>\n\n<p>平方收敛，速度快于梯度下降；需要距离最优解很近；不需要搜索参数；如果目标具有连续的二阶偏导数，则海森矩阵对称。</p>\n<p>拟牛顿法</p>\n<div>$$\nx_{k + 1} = x_k - \\alpha_kB_k^{-1}\\nabla f(x_k)\n$$</div>\n\n<h2 id=\"算法设计思想\"><a href=\"#算法设计思想\" class=\"headerlink\" title=\"算法设计思想\"></a>算法设计思想</h2><h3 id=\"贪心算法\"><a href=\"#贪心算法\" class=\"headerlink\" title=\"贪心算法\"></a>贪心算法</h3><ul>\n<li>可行性</li>\n<li>局部最优</li>\n<li>不可取消</li>\n</ul>\n<p>不是所有优化问题都能通过贪心算法求解，即使可以使用贪心算法，也不一定能够得到最优解。</p>\n<p>如果一个优化问题可以通过局部最优选择得到全局最优解，则说这个问题满足贪心选择性质，此时可以简单高效地求得问题的最优解。</p>\n<p>贪心策略可以有很多种。不同的算法有不同的性能。不一定得到全局最优解。</p>\n<h3 id=\"动态规划\"><a href=\"#动态规划\" class=\"headerlink\" title=\"动态规划\"></a>动态规划</h3><p>多阶段动态过程的优化问题</p>\n<p>阶段：把问题分成几个相互联系的有顺序的几个环节，这些环节被称<br>为阶段</p>\n<p>状态：某一阶段的出发位置称为状态。通俗的说状态是对问题在某一<br>时刻的进展情况的数学描述</p>\n<p>决策：从某阶段的一个状态演变到下一个阶段某状态的选择</p>\n<p>条件：最优化原理；无后效性</p>\n<p>动态规划用空间换时间，有大量重叠子问题时才能体现它的优势。</p>\n<p>例：Floyd算法，Viterbi译码</p>\n<h3 id=\"蛮力法\"><a href=\"#蛮力法\" class=\"headerlink\" title=\"蛮力法\"></a>蛮力法</h3><h3 id=\"分治法\"><a href=\"#分治法\" class=\"headerlink\" title=\"分治法\"></a>分治法</h3><p>快速排序</p>\n<p>分治法：分成若干个小的同类问题</p>\n<p>减治法：变成一个更小的同类问题</p>\n<p>变治法：变成若干个更简单的问题</p>\n<h3 id=\"搜索算法\"><a href=\"#搜索算法\" class=\"headerlink\" title=\"搜索算法\"></a>搜索算法</h3><p>组合优化问题的解空间指的是搜索答案的过程中搜索过的可行解。</p>\n<p>回溯法：没有希望的解就不去搜索。</p>\n<p>分支界限法：一边搜索一边给出当前部分解的下界。对于下界比搜索到的可行解还大的分支，不去搜索。下界的估计方法很重要。</p>\n<p>回溯法和分支界限法都不能保证求解的效率。</p>\n<h3 id=\"随机算法\"><a href=\"#随机算法\" class=\"headerlink\" title=\"随机算法\"></a>随机算法</h3><p>Sherwood算法</p>\n<p>快速排序在某些序列下会发生时间复杂度的退化。随机划分元素，可以使得达到最坏复杂度的概率降到很低。</p>\n<p>一般地，若确定型算法在最坏情况下的时间复杂度和它在平均情况下的时间复杂度有较大的差异，通过随机性可以消除这种差别。并不是避免这种最坏的情况发生，而是切除这种最坏情况和特定实例之间的联系。</p>\n<p>Las Vegas算法</p>\n<ul>\n<li>随机化决策</li>\n<li>减少算法运行的时间</li>\n<li>有概率会失败</li>\n<li>多尝试几次以提高成功率</li>\n</ul>\n<p>Monte Carlo算法</p>\n<ul>\n<li>概率为基础的统计模拟方法</li>\n<li>不保证得到正确的解</li>\n<li>设计合理，大量重复可以大概率得到高精度的解</li>\n</ul>\n<p>随机投点求面积</p>\n<p>一个蒙特卡洛方法得到正确判定的概率不小于p，则算法是p正确的。</p>\n<p>如果同一实例不会给出不同的解，称算法是一致的。</p>\n<p>对于判定问题，如果能够保证返回true时是正确的，称为偏真的；保证返回false时是正确的，则算法是偏假的。</p>\n<p>Sherwood:一定得到正确解，一般不会遇到最坏情况</p>\n<p>Las Vegas:不一定得到正确解，但如果得到了一定是正确的</p>\n<p>Monte Carlo:不一定得到正确解，即使得到了也不一定是正确的</p>\n<h3 id=\"算法优化技术\"><a href=\"#算法优化技术\" class=\"headerlink\" title=\"算法优化技术\"></a>算法优化技术</h3><p>输入增强技术</p>\n<ul>\n<li><p>字符串匹配算法</p>\n</li>\n<li><p>计数排序</p>\n</li>\n</ul>\n<p>预构造技术</p>\n<ul>\n<li><p>并查集</p>\n</li>\n<li><p>二叉查找树</p>\n</li>\n<li><p>倒排索引</p>\n</li>\n<li><p>堆和堆排序</p>\n</li>\n</ul>\n<p>时空平衡</p>\n<ul>\n<li>比特逆序</li>\n<li>散列</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"相关资源\"><a href=\"#相关资源\" class=\"headerlink\" title=\"相关资源\"></a>相关资源</h1><p><a href=\"https://algs4.cs.princeton.edu/home/\">Princeton <em>Algorithm 4th Edition</em></a></p>\n<h1 id=\"课程说明\"><a href=\"#课程说明\" class=\"headerlink\" title=\"课程说明\"></a>课程说明</h1><h2 id=\"课程内容\"><a href=\"#课程内容\" class=\"headerlink\" title=\"课程内容\"></a>课程内容</h2><p>数据处理，数学模型，算法分析</p>\n<p>非数值问题：</p>\n<p>数据结构：线性表，栈，队列，串，树，图</p>\n<p>非数值算法：查找，排序</p>\n<p>数值问题：</p>\n<p>误差分析</p>\n<p>线性方程组</p>\n<p>非线性方程</p>\n<p>拟合与插值</p>\n<p>最优化初步</p>\n<p>算法设计：蛮力，分治、减治、贪心、动态规划、搜索算法</p>\n<h1 id=\"绪论\"><a href=\"#绪论\" class=\"headerlink\" title=\"绪论\"></a>绪论</h1><h2 id=\"数据与算法\"><a href=\"#数据与算法\" class=\"headerlink\" title=\"数据与算法\"></a>数据与算法</h2><h2 id=\"数学模型\"><a href=\"#数学模型\" class=\"headerlink\" title=\"数学模型\"></a>数学模型</h2><p>对于现实世界的某一特定对象，为特定目的而得到的一个抽象的简化的数学结构。</p>\n<h3 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h3><p>算法是问题的程序化解决方案。</p>\n<p>算法强调精确定义的求解过程，并不是问题的答案。</p>\n<p>设计实现算法，并没有得到答案，但是给出了一般的解决方案。</p>\n<p>一个算法能够解决很多看似好无关系的问题，只要这些问题可以抽象为某种相同的算法。</p>\n<h3 id=\"数据\"><a href=\"#数据\" class=\"headerlink\" title=\"数据\"></a>数据</h3><p>数据是客观世界的描述。</p>\n<p>数据是信息的载体，是算法处理的对象。</p>\n<p>算法是处理数据的系统。</p>\n<p>人的因素也被纳入了数学模型的和算法。</p>\n<p>IBM Watson</p>\n<h2 id=\"算法分析和算法设计\"><a href=\"#算法分析和算法设计\" class=\"headerlink\" title=\"算法分析和算法设计\"></a>算法分析和算法设计</h2><h3 id=\"算法及其特性\"><a href=\"#算法及其特性\" class=\"headerlink\" title=\"算法及其特性\"></a>算法及其特性</h3><p>算法的五个重要特性：</p>\n<p>有穷性：一个算法必须可以在有穷步之后结束，且每一步可以在有穷时间内完成</p>\n<p>确定性：算法的描述无歧义，算法的执行结果是确定的且精确地符合要求或期望</p>\n<p>可行性：算法中描述的操作都可以通过已经实现的基本操作运算的有限次执行来实现</p>\n<p>输入：一个算法有零个或多个输入，这些输入取自某个特定的对象集</p>\n<p>输出：一个算法有一个或多个输出，输出量是算法计算的结果</p>\n<h3 id=\"算法的评价\"><a href=\"#算法的评价\" class=\"headerlink\" title=\"算法的评价\"></a>算法的评价</h3><h4 id=\"正确性\"><a href=\"#正确性\" class=\"headerlink\" title=\"正确性\"></a>正确性</h4><p>不含语法错误</p>\n<p>几组一般的输入数据</p>\n<p>精心选择的、典型、苛刻且带有刁难性的输入数据（衡量标准）</p>\n<p>一切合法的输入数据</p>\n<h4 id=\"健壮性\"><a href=\"#健壮性\" class=\"headerlink\" title=\"健壮性\"></a>健壮性</h4><p>输入的数据非法</p>\n<h4 id=\"可读性\"><a href=\"#可读性\" class=\"headerlink\" title=\"可读性\"></a>可读性</h4><p>描述清楚，便于理解</p>\n<h4 id=\"高效率\"><a href=\"#高效率\" class=\"headerlink\" title=\"高效率\"></a>高效率</h4><p>占用的空间和时间资源</p>\n<h3 id=\"算法效率的衡量方法\"><a href=\"#算法效率的衡量方法\" class=\"headerlink\" title=\"算法效率的衡量方法\"></a>算法效率的衡量方法</h3><p>和算法执行时间相关的因素有很多。</p>\n<p>一个特定算法运行工作量的大小，是问题规模的函数。</p>\n<h4 id=\"渐进时间复杂度\"><a href=\"#渐进时间复杂度\" class=\"headerlink\" title=\"渐进时间复杂度\"></a>渐进时间复杂度</h4><p>算法的渐进时间复杂度(Time Complexity): $T(n) &#x3D; O[f(n)]$</p>\n<p>Big-O 记号的形式化定义</p>\n<ul>\n<li>若 f(n)是正整数 n 的一个函数，则$x_n &#x3D; O[f(n)]$表示存在正的常数$M$和$n_0$， 使得当$n &gt; n_0$时，都满足$|x_n| \\le M|f(n)|$</li>\n<li>标记的是算法效率的上限</li>\n</ul>\n<h5 id=\"算法效率估算方法\"><a href=\"#算法效率估算方法\" class=\"headerlink\" title=\"算法效率估算方法\"></a>算法效率估算方法</h5><ul>\n<li>算法执行的时间 &#x3D; Σ 操作的执行次数 × 操作的执行时间</li>\n<li>算法操作包括<strong>控制操作</strong>和<strong>原操作</strong><br>一般来说，相比于循环体，控制操作本身的复杂度可被忽略。而在原操作中，我们又可以寻找其中执行次数最多的一种或几种操作，这些操作被称为基本操作。</li>\n<li>选取算法中的<strong>基本操作</strong></li>\n<li>算法的执行时间与<strong>基本操作执行次数之和</strong>成正比</li>\n</ul>\n<h5 id=\"描述指标\"><a href=\"#描述指标\" class=\"headerlink\" title=\"描述指标\"></a>描述指标</h5><ul>\n<li>最好情况(best-case)：对于任何一个输入的运行时间下限</li>\n<li>最坏情况(worst-case)：对于任何一个输入的运行时间下限</li>\n<li>平均(average-complexity): 根据各种操作出现概率的分布进行加权平均</li>\n<li>分摊(amortized complexity): 连续实施足够多次操作，总成本摊至单次操作</li>\n</ul>\n<p>最重要的是平均情况下的性能</p>\n<h5 id=\"引入大-O-表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\"><a href=\"#引入大-O-表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\" class=\"headerlink\" title=\"引入大 O 表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型\"></a>引入大 O 表示的渐进时间复杂度和空间复杂度实际上是建立了算法效率分析的数学模型</h5><h5 id=\"迅速找到会被多次反复执行的基本操作\"><a href=\"#迅速找到会被多次反复执行的基本操作\" class=\"headerlink\" title=\"迅速找到会被多次反复执行的基本操作\"></a>迅速找到会被多次反复执行的基本操作</h5><h5 id=\"感兴趣的复杂度形式非常有限\"><a href=\"#感兴趣的复杂度形式非常有限\" class=\"headerlink\" title=\"感兴趣的复杂度形式非常有限\"></a>感兴趣的复杂度形式非常有限</h5><h5 id=\"按照对数坐标画图\"><a href=\"#按照对数坐标画图\" class=\"headerlink\" title=\"按照对数坐标画图\"></a>按照对数坐标画图</h5><h4 id=\"空间复杂度\"><a href=\"#空间复杂度\" class=\"headerlink\" title=\"空间复杂度\"></a>空间复杂度</h4><h5 id=\"算法空间\"><a href=\"#算法空间\" class=\"headerlink\" title=\"算法空间\"></a>算法空间</h5><ul>\n<li>指令空间(instruction space): 用来存储程序指令所需的空间</li>\n<li>数据空间(data space): 存储运行过程中常量和变量所需的空间</li>\n<li>环境空间: 系统为程序运行，特别是函数调用提供的空间</li>\n</ul>\n<h5 id=\"算法的渐进空间复杂度-S-n-x3D-O-f-n\"><a href=\"#算法的渐进空间复杂度-S-n-x3D-O-f-n\" class=\"headerlink\" title=\"算法的渐进空间复杂度: $S(n) &#x3D; O[f(n)]$\"></a>算法的渐进空间复杂度: $S(n) &#x3D; O[f(n)]$</h5><h5 id=\"输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\"><a href=\"#输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\" class=\"headerlink\" title=\"输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间\"></a>输入数据所占空间只取决于问题本身，和算法无关，则只需要分析输入和程序之外的额外空间</h5><h3 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><h4 id=\"数据元素和数据项\"><a href=\"#数据元素和数据项\" class=\"headerlink\" title=\"数据元素和数据项\"></a>数据元素和数据项</h4><p>数据元素(Data Element): 数据的最小单位</p>\n<p>数据项：(Data Item): 数据结构中讨论的最小单位</p>\n<h4 id=\"数据结构是带结构的数据元素的集合\"><a href=\"#数据结构是带结构的数据元素的集合\" class=\"headerlink\" title=\"数据结构是带结构的数据元素的集合\"></a>数据结构是带结构的数据元素的集合</h4><p>逻辑结构：集合，线性结构，树结构，图结构</p>\n<p>存储结构：顺序存储，链式存储</p>\n<h4 id=\"二元关系\"><a href=\"#二元关系\" class=\"headerlink\" title=\"二元关系\"></a>二元关系</h4><h5 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h5><p>定义：设有几何$M, N$, 其笛卡尔积$M \\times N$的任意一个子集$R \\in M \\times N$</p>\n<p>二元关系表示了集合$M$和集合$N$中元素之间的某种相关性。</p>\n<p>若$(a, b) \\in R$, 则称$a$为$R$的前件，$b$称为$R$的后件。</p>\n<p>若$M &#x3D; N$, 则称$R \\sub M \\times M$为 M 上的二元关系。</p>\n<h5 id=\"二元关系的性质\"><a href=\"#二元关系的性质\" class=\"headerlink\" title=\"二元关系的性质\"></a>二元关系的性质</h5><p>设$R$为集合$M$上的一个二元关系：</p>\n<p>(1) 自反性：对于每个$a \\in M$, 有 $(a, a) \\in R$;</p>\n<p>反自反性： 对于所有$a \\in M$, 有$(a, a) \\notin R$;</p>\n<p>(2) 对称性：当$(a, b) \\in R$时，则$a &#x3D; b$;</p>\n<p>反对称性：当$(a, b) \\in R$且$(b, a) \\in R$时，必有$a &#x3D; b$;</p>\n<p>(3) 传递性： 当$(a, b) \\in R$且$(b, c) \\in R$ 时， 必有$(a, c) \\in R$。</p>\n<h5 id=\"常见的二元关系\"><a href=\"#常见的二元关系\" class=\"headerlink\" title=\"常见的二元关系\"></a>常见的二元关系</h5><p>等价关系：满足自反性、对称性、传递性</p>\n<p>偏序关系：满足自反性、反对称性、传递性</p>\n<p>全序关系：若$M$中的任意两个元素$a$和$b$是可比的，也就是说或者有$aRb$成立，或者有$bRa$成立，则称$R$是集合$M$上的全序关系(Totala Order Relation)</p>\n<h4 id=\"数据类型-Data-Type\"><a href=\"#数据类型-Data-Type\" class=\"headerlink\" title=\"数据类型(Data Type)\"></a>数据类型(Data Type)</h4><h5 id=\"C-语言中的类型定义\"><a href=\"#C-语言中的类型定义\" class=\"headerlink\" title=\"C 语言中的类型定义\"></a>C 语言中的类型定义</h5><p>五种基本数据类型：字符型，整型，浮点型，双精度浮点型和无值类型</p>\n<p>程序中任何变量，常量都必须先定义类型。</p>\n<p>整数类型 int 及定义在其上的操作：+, -, *, &#x2F;, %, ++, –</p>\n<p>双精度浮点型 double 及定义在其上的操作：+, -, *, &#x2F;, ++, –</p>\n<h6 id=\"数据类型用来刻画-程序-操作对象的特性\"><a href=\"#数据类型用来刻画-程序-操作对象的特性\" class=\"headerlink\" title=\"数据类型用来刻画(程序)操作对象的特性\"></a>数据类型用来刻画(程序)操作对象的特性</h6><p>数据类型是一个元素的集合和定义在此集合上的一组操作的总称。</p>\n<p>数据类型实现了信息的隐藏，把一切用户无需了解的细节封装在类型中。</p>\n<p>高级语言中的数据类型分为原子类型和结构类型。</p>\n<h4 id=\"抽象数据类型-Abstract-Data-Type-ADT\"><a href=\"#抽象数据类型-Abstract-Data-Type-ADT\" class=\"headerlink\" title=\"抽象数据类型(Abstract Data Type, ADT)\"></a>抽象数据类型(Abstract Data Type, ADT)</h4><p>是指一个数学模型以及定义在此数学模型上的一组操作。</p>\n<p>数据抽象：描述的是实体的本质特征、功能以及外部用户接口</p>\n<p>数据封装：将实体的外部特性和内在实现细节发呢里，对外部用户隐藏内部实现细节，使得应用和实现分离</p>\n<p>ADT 的优点：</p>\n<ul>\n<li>程序结构清晰，易于扩展易于维护而不失其效率</li>\n<li>提高程序的数据安全性</li>\n<li>大大增加了软件的复用程度</li>\n</ul>\n<h4 id=\"抽象数据类型的描述\"><a href=\"#抽象数据类型的描述\" class=\"headerlink\" title=\"抽象数据类型的描述\"></a>抽象数据类型的描述</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT 抽象数据类型名&#123;</span><br><span class=\"line\">    数据对象: &lt;数据对象的定义&gt;</span><br><span class=\"line\">    数据关系: &lt;数据关系的定义&gt;</span><br><span class=\"line\">    基本操作: &lt;基本操作的定义&gt;</span><br><span class=\"line\">    基本操作名(参数表)</span><br><span class=\"line\">        初始条件: &lt;初始条件描述&gt;</span><br><span class=\"line\">        操作结果: &lt;操作结果描述&gt;</span><br><span class=\"line\">&#125;ADT 抽象数据类型名</span><br></pre></td></tr></table></figure>\n\n<p>基本操作参数:</p>\n<ul>\n<li>赋值参数提供输入值</li>\n<li>引用参数以&amp;打头，用于返回操作结果</li>\n</ul>\n<h1 id=\"数据结构-1\"><a href=\"#数据结构-1\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h1><h2 id=\"线性表\"><a href=\"#线性表\" class=\"headerlink\" title=\"线性表\"></a>线性表</h2><p>线性表的元素可以是各种各样的，但是同一线性表的元素必然具有相同特性-同质</p>\n<p>线性表中的相邻元素之间存在有序关系-位序</p>\n<p>线性表是一种“有序结果”，即在数据元素的非空有限集合中</p>\n<ul>\n<li>存在唯一的一个被称为“第一个”的数据元素，无前驱；</li>\n<li>存在唯一的一个被称为的“最后一个”的数据元素，无后继；</li>\n<li>除第一个之外，每一个数据元素均只有一个直接前驱；</li>\n<li>除最后一个之外，每个数据元素均只有一个直接后继</li>\n</ul>\n<p>线性表中元素个数定义为线性表的长度</p>\n<div>$$(a_0, a_1, \\dots, a_{i-1}, a_i, a_{i+1}, \\dots, a_{n-1})$$</div>\n\n<p>若线性表为空，则其长度为 0，称为空表</p>\n<p>在非空表中，每个数据元素都有一个确定的位置</p>\n<ul>\n<li>$a_0$是第 0 个数据元素，$a_{n-1}$是第$n-1$个数据元素</li>\n<li>$a_i$是第 i 个数据元素</li>\n<li>称 i 为数据元素$a_i$在线性表中的位序</li>\n</ul>\n<h2 id=\"线性表-ADT\"><a href=\"#线性表-ADT\" class=\"headerlink\" title=\"线性表 ADT\"></a>线性表 ADT</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADT List&#123;</span><br><span class=\"line\">    数据对象:</span><br><span class=\"line\">    数据关系:</span><br><span class=\"line\">    基本操作：</span><br><span class=\"line\">    InitList(&amp;L);</span><br><span class=\"line\">        操作结果：构造一个空的线性表L。</span><br><span class=\"line\">    DestroyList(&amp;L);</span><br><span class=\"line\">        初始条件：线性表已存在。</span><br><span class=\"line\">        操作结果：销毁线性表L。</span><br><span class=\"line\">    IsEmpty(L);</span><br><span class=\"line\">        初始条件：线性表已存在。</span><br><span class=\"line\">        操作结果：若L为空表，则返回TRUE，否则返回FALSE。</span><br><span class=\"line\">    ListLength(L);</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果：用e返回L中第i个数据元素的值</span><br><span class=\"line\">    GetElem(L, i, &amp;e);</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果；用e返回L中第i个数据元素的值。</span><br><span class=\"line\">    LocateElem(L, e, compare());</span><br><span class=\"line\">        初始条件：线性表L已存在，compare()是数据元素判定函数。</span><br><span class=\"line\">        操作结果：返回L中第<span class=\"number\">1</span>个与e满足关系compare()的数据元素的位序。若这样的元素不存在，则返回-<span class=\"number\">1</span>。</span><br><span class=\"line\">    PriorElem(L, cur_e, &amp;pre_e);</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果：若cur_e是L的数据元素，且不是最后一个，则用next_e返回它的后继，否则操作失败，next_e无定义。</span><br><span class=\"line\">    ClearList(&amp;L);</span><br><span class=\"line\">        初始条件：线性表L已存在；</span><br><span class=\"line\">        操作结果：将L重置为空表。</span><br><span class=\"line\">    ListInsert(&amp;L, i, e);</span><br><span class=\"line\">        初始条件：线性表L已存在, <span class=\"number\">0</span> &lt;=i &lt;= ListLength(L)。</span><br><span class=\"line\">        操作结果：在L中第i个位置插入新的数据元素e，L的长度加<span class=\"number\">1</span>。</span><br><span class=\"line\">    ListDelete(&amp;L, i, &amp;e)</span><br><span class=\"line\">        初始条件：线性表L已存在，<span class=\"number\">0</span> &lt;= i &lt;= ListLength(L) - <span class=\"number\">1</span>。</span><br><span class=\"line\">        操作结果：删除L的第i个数据元素，用e返回其值，L的长度减<span class=\"number\">1</span>。</span><br><span class=\"line\">    ListTraverse(L, visit());</span><br><span class=\"line\">        初始条件：线性表L已存在。</span><br><span class=\"line\">        操作结果：依次对L的每个数据元素调用函数 visit()。</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>线性表的合并：$O(m+n)$</p>\n<p>线性表的保序归并：$O(m+n)$</p>\n<p>线性表的顺序存储：顺序表</p>\n<ul>\n<li>用一组地址连续的存储单元依次存储线性表的数据元素</li>\n</ul>\n<p>顺序表的主要操作：</p>\n<p>插入操作：在顺序表的第 i 个位置插入一个新元素，使顺序表的长度增加到$n+1$</p>\n<p>复杂度分析：</p>\n<ul>\n<li>在顺序表的第$i$个位置插入一个新元素，需要移动$n - i$个元素；</li>\n<li>假设从顺序表的第$i$个位置插入元素的先验概率为$p_i$</li>\n<li>插入操作移动元素次数的期望为$E_{insert} &#x3D; \\sum_{i &#x3D; 0}^n(n - i) \\times p_i$</li>\n</ul>\n<p>删除操作：把顺序表的第$i$个位置的元素从表中删除，使长度为$n$的顺序表的长度变为$n - 1$</p>\n<p>复杂度分析：</p>\n<ul>\n<li>把顺序表的第$i$个位置上的元素删除，需要移动$n - i -1$个元素</li>\n<li>假设从顺序表的第$i$个位置删除元素的先验概率为$q_i$</li>\n<li>删除操作移动元素次数的期望为: $E_{delete} &#x3D; \\sum_{i &#x3D; 0}^{n - 1}(n - i - 1) \\times q_i$</li>\n</ul>\n<p>不失一般性，我们假设插入或删除元素出现在任何位置的概率都是相等的，因此有$p_i &#x3D; p &#x3D; 1&#x2F;(n+1), q_i &#x3D; q &#x3D; 1&#x2F;n$。</p>\n<p>推导得到：</p>\n<div>$$E_{insert} = \\frac1{n+1}\\sum_{i = 0}^n(n-i) = \\frac n2\\newline E_{delete} = \\frac1n\\sum_{i = 0}^{n - 1}(n - i - 1) = \\frac{n - 1}2$$</div>\n\n<h2 id=\"单向链表\"><a href=\"#单向链表\" class=\"headerlink\" title=\"单向链表\"></a>单向链表</h2><p>最简单的链表结构：链表节点(node)由两个域组成。</p>\n<p>数据域：存储数据元素，</p>\n<p>指针域：指向直接后继节点</p>\n<p>单向链表的 C++实现：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LinkList</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    NODE *head;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"built_in\">LinkList</span>() &#123;head = <span class=\"literal\">NULL</span>;&#125;</span><br><span class=\"line\">    ~<span class=\"built_in\">LinkList</span>();</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">clearSqList</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">IsEmpty</span><span class=\"params\">()</span></span>&#123;<span class=\"keyword\">return</span> head ==  <span class=\"literal\">NULL</span>;&#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">GetElem</span><span class=\"params\">(<span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">LocateElem</span><span class=\"params\">(<span class=\"type\">int</span> e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">PriorElem</span><span class=\"params\">(<span class=\"type\">int</span> cur_e, <span class=\"type\">int</span> *next_e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">NextElem</span><span class=\"params\">(<span class=\"type\">int</span> cur_e, <span class=\"type\">int</span>* pre_e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">Insert</span><span class=\"params\">(<span class=\"type\">int</span> i, <span class=\"type\">int</span> e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">Delete</span><span class=\"params\">(<span class=\"type\">int</span> i, <span class=\"type\">int</span> *e)</span></span>;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">Traverse</span><span class=\"params\">(<span class=\"type\">bool</span> (*visit)(<span class=\"type\">int</span> e))</span></span>;<span class=\"comment\">//遍历所有节点</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>单向链表的不足：</p>\n<ul>\n<li>单链表的表长是一个隐含的值，遍历链表才能得到</li>\n<li>在单链表中插入或者删除元素时，需要在链表中依序寻找操作位置</li>\n<li>在链表中，元素的“位序”概念淡化，结点的“位置”概念强化</li>\n<li>如何得到某个元素的前驱？</li>\n</ul>\n<p>改进链表的设置：</p>\n<ul>\n<li><p>增加“表长”、“表尾指针”和“当前位置指针”三个数据域</p>\n</li>\n<li><p>将基本操作中的“位序i”改为“指针p”</p>\n</li>\n</ul>\n<h2 id=\"双向链表\"><a href=\"#双向链表\" class=\"headerlink\" title=\"双向链表\"></a>双向链表</h2><p>由数据，前驱和后继构成。</p>\n<p>方便寻找前驱，但是增加了维护成本。</p>\n<h2 id=\"顺序表和链表的比较：\"><a href=\"#顺序表和链表的比较：\" class=\"headerlink\" title=\"顺序表和链表的比较：\"></a>顺序表和链表的比较：</h2><p>顺序表</p>\n<p>用一组地址连续的存储单元依次存储线性表中的数据元素</p>\n<p>优点：可以随机存取</p>\n<p>缺点：插入，删除操作需要移动表中的数据元素，事先确定规模，空间效率不高。</p>\n<p>链表：</p>\n<p>用一组“任意”的存储单元（附加指针）存储表中的数据元素</p>\n<p>优点：插入，删除操作无需移动表中的数据元素，空间利用率高</p>\n<p>缺点：不能随机存取</p>\n<h2 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h2><p>栈是LIFO(Last In First Out，先进后出)的线性表。</p>\n<p>允许插入和删除的一段称为栈顶(top), 另一端称为栈底(bottom)</p>\n<h3 id=\"栈的ADT\"><a href=\"#栈的ADT\" class=\"headerlink\" title=\"栈的ADT\"></a>栈的ADT</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">Push</span>(&amp;s, e);</span><br><span class=\"line\">    <span class=\"built_in\">Pop</span>(&amp;s, &amp;e);</span><br><span class=\"line\">    <span class=\"built_in\">ClearStack</span>(&amp;s);</span><br><span class=\"line\">&#125; ADT Stack;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"栈的表示和实现\"><a href=\"#栈的表示和实现\" class=\"headerlink\" title=\"栈的表示和实现\"></a>栈的表示和实现</h3><p>栈的顺序表示</p>\n<p>top指向最后一个元素可以，指向空也可以，但是实现时要自洽。</p>\n<p>栈的链式表示</p>\n<p>有头插入和尾插入两个方式</p>\n<p>总体来看，头插入比尾插入的优势要更大。首先，插入时虽然头插入要修改的指针更多，但是时间复杂度小，头插入$O(1)$，尾插入$O(n)$。其次，如果以尾部为栈顶，删除时会很麻烦。</p>\n<p><strong>静态分配</strong></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> STACK_MAX_SIZE 100</span></span><br></pre></td></tr></table></figure>\n<p><strong>动态分配</strong></p>\n<p>程序隐含设定</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> STACK_INT_SIZE 100</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> STACKINCREMENT 10</span></span><br></pre></td></tr></table></figure>\n\n<p>用户给定</p>\n<h3 id=\"复杂度分析\"><a href=\"#复杂度分析\" class=\"headerlink\" title=\"复杂度分析\"></a>复杂度分析</h3><p>顺序栈的效率分析</p>\n<p>时间复杂度</p>\n<ul>\n<li>进栈、出栈:$O(1)$</li>\n<li>栈的溢出处理</li>\n<li>如果栈元素时简单数据类型，则构造和销毁函数也是$O(1)$的</li>\n</ul>\n<p>空间复杂度</p>\n<ul>\n<li>顺序栈的长度构造时确定</li>\n<li>空间利用效率低</li>\n</ul>\n<p>链式栈的效率分析</p>\n<p>时间复杂度</p>\n<ul>\n<li>链式栈的入栈出栈是$O(1)$时间的</li>\n<li>建立和销毁是$O(n)$时间的</li>\n</ul>\n<p>空间复杂度</p>\n<ul>\n<li>一般不会产生溢出</li>\n<li>空间利用率高</li>\n</ul>\n<h3 id=\"栈的一些应用\"><a href=\"#栈的一些应用\" class=\"headerlink\" title=\"栈的一些应用\"></a>栈的一些应用</h3><p>显式应用：括号匹配，表达式求值，迷宫求解</p>\n<p>隐式应用：函数调用，递归</p>\n<p>系统栈</p>\n<h2 id=\"递归\"><a href=\"#递归\" class=\"headerlink\" title=\"递归\"></a>递归</h2><p>栈与递归具有相似性。</p>\n<p>Fibonacci的递归次数：$C(n) &#x3D; O(t^n)$</p>\n<p>(证明思路：归纳法证明$C(n) &#x3D; 2F(n) - 1$, 根据F(n)通项可以判断。)</p>\n<p>使用递推法的时间复杂度：$O(n)$.</p>\n<p>经常需要进行递归的消除。消除方法：递推，循环等，没有统一的解决方案。可以借用显式栈实现非递归过程。</p>\n<p>递归的评价：</p>\n<ul>\n<li>简洁，便于理解，便于叙述和设计</li>\n<li>运行效率低，无法控制递归堆栈的规模</li>\n</ul>\n<h2 id=\"队列\"><a href=\"#队列\" class=\"headerlink\" title=\"队列\"></a>队列</h2><p>队列是FIFO(First In First Out, 先进先出)的线性表。</p>\n<h3 id=\"队列的表示和实现\"><a href=\"#队列的表示和实现\" class=\"headerlink\" title=\"队列的表示和实现\"></a>队列的表示和实现</h3><p>队列的顺序表示法</p>\n<p>入队: rear &#x3D; rear + 1</p>\n<p>出队: front &#x3D; front + 1</p>\n<p>需要判定队满和队空。</p>\n<p>顺序队列的问题：被出队的空间不会再次被使用了。</p>\n<p>循环队列：</p>\n<p>队尾指针指向maxSize - 1时， 入列则指向0；</p>\n<p>队头指针指向maxSize - 1，出列也指向0。</p>\n<p>可以使用模运算实现。</p>\n<p>缺点：无法区分队空和队满的状态。</p>\n<p>区分方法：</p>\n<p>设置一个空位；设置标志；设置队列长度变量</p>\n<p>队列的链式表示法</p>\n<p>入队不会出现队满的问题，出队可能回有队空的问题，队空的条件为front &#x3D; NULL.</p>\n<h2 id=\"串\"><a href=\"#串\" class=\"headerlink\" title=\"串\"></a>串</h2><p>串是有线长度的字符序列。</p>\n<p>串的长度是字符个数。</p>\n<p>字符在串中的位置。</p>\n<p>两个串相等的条件。</p>\n<p>子串和主串，子串在主串中的位置。</p>\n<h3 id=\"匹配算法\"><a href=\"#匹配算法\" class=\"headerlink\" title=\"匹配算法\"></a>匹配算法</h3><p>Brute-Force算法：一个一个比。复杂度最高O(m * n)。</p>\n<p>KMP算法：尽可能跳过更多不必要的匹配。复杂度最多O(m + n)。</p>\n<p>Horspool算法：启发式算法。复杂度低则O(m&#x2F;n)，高则O(m * n + s)，s为字符表规模</p>\n<p>Boyer-Moore算法：最坏O(n)。KMP和Horspool的综合（或者说Horspool是BM算法的简化版本。）</p>\n<h2 id=\"树与二叉树\"><a href=\"#树与二叉树\" class=\"headerlink\" title=\"树与二叉树\"></a>树与二叉树</h2><h3 id=\"树\"><a href=\"#树\" class=\"headerlink\" title=\"树\"></a>树</h3><p>空树，子树。</p>\n<p>结点（node）是树的基本单位。</p>\n<p>结点的度(degree)：结点的子树个数。</p>\n<p>树的度：结点度的最大值。</p>\n<p>k叉树：树的度为k</p>\n<p>child, parent, cousin, ancestor, descendant</p>\n<p>depth&#x2F;height</p>\n<p>树的性质：</p>\n<ol>\n<li>树中结点数等于所有结点度数和加一</li>\n<li>k叉树第i层至多$k^{i - 1}个结点$</li>\n<li>深度为h的k叉树至多有$(k^h - 1)&#x2F;(k - 1)$个结点</li>\n<li>具有n个结点的k叉树的最小深度为$[\\log_k(n(k - 1) + 1)]$</li>\n</ol>\n<h3 id=\"二叉树\"><a href=\"#二叉树\" class=\"headerlink\" title=\"二叉树\"></a>二叉树</h3><p>二叉树是结点的一个有限集合，该集合或者为空，或者是由一个根节点加上两棵分别称为左子树和右子树的、互不相交的二叉树组成。</p>\n<p>二叉树的性质：</p>\n<ol>\n<li>叶子结点数 &#x3D; 度为二的结点数 + 1</li>\n<li>第i层至多$2^{i - 1}$个结点</li>\n<li>深度为h，则最多有$(2^h - 1)$个结点</li>\n<li>具有n个结点的完全二叉树的深度为$\\lceil\\log_2(n + 1)\\rceil$</li>\n<li>对于完全二叉树（最后一层从右向左缺若干结点），从左向右，从上到下编号，则$\\lfloor(i - 1)&#x2F;2\\rfloor$为编号i的parent结点，$2i + 1$为其左子树，$2i + 2$为其右子树。</li>\n</ol>\n<p>二叉树的顺序表示</p>\n<p>完全二叉树按照编号存储。不完全二叉树按照它对应的完全二叉树存储，但是缺少的部分留空。</p>\n<p>不完全二叉树结点越少，空间效率越低。</p>\n<p>二叉树的链式表示</p>\n<p>空间效率很高。</p>\n<p>二叉树的遍历：</p>\n<p>记根节点为V，遍历左子树为L，遍历右子树记为R</p>\n<p>先序遍历：V - L - R</p>\n<p>中序遍历：L - V - R</p>\n<p>后序遍历：L - R - V</p>\n<p>遍历可以通过递归实现，但是递归可能会对效率产生影响。可以利用栈的特性实现遍历。</p>\n<p>层序遍历：从上到下优先遍历同一层的结点。</p>\n<p>遍历实现了树的线索化过程。</p>\n<h3 id=\"霍夫曼树\"><a href=\"#霍夫曼树\" class=\"headerlink\" title=\"霍夫曼树\"></a>霍夫曼树</h3><p>霍夫曼树：寻找加权路径长度(WPL)的最小树。</p>\n<p>用途：实现性能最好的变长二进制编码。</p>\n<p>霍夫曼编码不是唯一的，但是所有霍夫曼树的WPL都相等。</p>\n<p>不足：</p>\n<p>没有错误保护功能</p>\n<h3 id=\"二叉树的建立\"><a href=\"#二叉树的建立\" class=\"headerlink\" title=\"二叉树的建立\"></a>二叉树的建立</h3><p>只知道二叉树的先序序列，不能确定这棵二叉树。</p>\n<p>但是如果同时知道先序序列和中序序列，则可以确定这棵二叉树。</p>\n<h2 id=\"图\"><a href=\"#图\" class=\"headerlink\" title=\"图\"></a>图</h2><h3 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h3><p>图的定义</p>\n<p>顶点，边，弧</p>\n<p>邻接顶点</p>\n<p>有向图，无向图</p>\n<p>有向完全图，无向完全图</p>\n<p>子图</p>\n<p>握手定理，度</p>\n<p>权，网络<br>边上的数叫做权。有权的图叫网络。</p>\n<p>连通</p>\n<p>连通图</p>\n<p>连通分量<br>无向图的极大连通子图为连通分量。（所谓极大，就是再加入一个点都会导致它不连通）</p>\n<p>强连通图<br>有向图中存在vi到vj且存在vj到vi的图。</p>\n<p>强连通分量<br>有向图的极大强连通子图为强连通分量。</p>\n<p>Euler路径和Euler回路</p>\n<p>图的存储和表示</p>\n<p>邻接矩阵表示<br>如果v和w之间有边，则元素为1，否则为0.</p>\n<p>邻接表表示<br>采用链表数组表示图。同一个顶点发出的边在同一个链表中。</p>\n<h3 id=\"图的遍历\"><a href=\"#图的遍历\" class=\"headerlink\" title=\"图的遍历\"></a>图的遍历</h3><p>深度优先遍历和广度优先遍历</p>\n<p>图的遍历：从已给连通图的某一顶点出发，沿着一些边访问所有顶点，且每个顶点只访问一次，则叫做图的遍历。</p>\n<p>邻接矩阵的遍历：$O(v^2)$</p>\n<p>邻接表的遍历：$O(v + e)$</p>\n<h3 id=\"生成树\"><a href=\"#生成树\" class=\"headerlink\" title=\"生成树\"></a>生成树</h3><p>连通图的生成树，包含图中全部n个顶点，但只有n-1条边。</p>\n<p>深度优先和广度优先遍历分别会得到一个搜索树。</p>\n<p>最小生成树：权值之和最小的生成树。</p>\n<p>求最小生成树的算法：贪心算法思想。Kruskal算法和Prim算法。</p>\n<p>Prim算法</p>\n<p><img src=\"/../images/DSA/Prim.jpg\"></p>\n<p>Prim算法的时间复杂度为$O(n^2)$。对稠密图而言是线性的。对于稠密图而言，Prim的邻接矩阵实现是首选方法。</p>\n<p>Kruskal算法<br><img src=\"/../images/DSA/Kruskal.jpg\"></p>\n<p>Kruskal的时间复杂度为$O(E\\log E)$。</p>\n<p>Kruskal算法对于稀疏图是好的选择。</p>\n<h3 id=\"最短路径树\"><a href=\"#最短路径树\" class=\"headerlink\" title=\"最短路径树\"></a>最短路径树</h3><p>从根到其他顶点的最短路径</p>\n<p>源点-汇点最短路径：给定一个起始顶点s和一个结束顶点 ，在图中找出从s到t的一条路径。起始顶点称为“源点”，结束顶点称为“汇点”</p>\n<p>单源最短路径：给定一个起始顶点s，找出从s到图中其它各顶点的最短路径</p>\n<p>全源最短路径：找出连接图中各对顶点的最短路径</p>\n<h4 id=\"单源最短路径\"><a href=\"#单源最短路径\" class=\"headerlink\" title=\"单源最短路径\"></a>单源最短路径</h4><p>Dijkstra算法</p>\n<p><img src=\"/../images/DSA/Dijkstra.jpg\"></p>\n<p>Dijkstra算法通过构造加权有向图图的最短路径树SPT，来实现单源最短路径算法。</p>\n<p>时间复杂度为$O(v^2)$，和Prim算法很相似。</p>\n<h4 id=\"全源最短路径\"><a href=\"#全源最短路径\" class=\"headerlink\" title=\"全源最短路径\"></a>全源最短路径</h4><p>可以对每个顶点用Dijkstra算法。</p>\n<p>Floyd算法</p>\n<p>时间复杂度：$O(v^3)$。可以计算出一个网络中所有的最短路径。</p>\n<p>Floyd算法允许图中带有负权值的边，但不允许有包含带负权值的边组成回路。</p>\n<h1 id=\"算法-1\"><a href=\"#算法-1\" class=\"headerlink\" title=\"算法\"></a>算法</h1><h2 id=\"非数值算法\"><a href=\"#非数值算法\" class=\"headerlink\" title=\"非数值算法\"></a>非数值算法</h2><h3 id=\"查找\"><a href=\"#查找\" class=\"headerlink\" title=\"查找\"></a>查找</h3><p>查找算法的复杂性：关键字&#x2F;数据规模</p>\n<p>查找算法的分类：</p>\n<ul>\n<li>内部&#x2F;外部</li>\n<li>静态&#x2F;动态</li>\n</ul>\n<h4 id=\"查找表\"><a href=\"#查找表\" class=\"headerlink\" title=\"查找表\"></a>查找表</h4><p>查找表（Search Table）是由同一类型数据元素构成的集合。</p>\n<p>按关键字查找</p>\n<ol>\n<li>查询某元素是否存在</li>\n<li>检索某数据元素的各种属性</li>\n<li>在查找表中插入一个数据元素</li>\n<li>从查找表中删除一个数据元素</li>\n</ol>\n<p>查找表的种类</p>\n<ol>\n<li>静态查找表-仅可执行1,2</li>\n<li>可执行1,2,3,4</li>\n</ol>\n<p>平均查找长度：在查找过程中，为确定目标在查找表中的位置，需要进行关键字比较次数的期望值</p>\n<div>$$\nASL = \\sum_{0}^{n - 1}P_i C_i\n$$</div>\n\n<p>$P_i$为第i条记录的查找概率，$C_i$为第i条记录的查找长度。</p>\n<p>有时我们会假设查找概率相等或不等，有时要考虑查找失败的比较次数。</p>\n<p>ASL越小，查找性能越好。</p>\n<p>顺序查找：又称线性查找，是从线性<br>表的一端开始，依次把每个元素的<br>关键字同给定值进行比较</p>\n<p>假设每个元素的查找概率相等，则平均查找长度为：$ASL &#x3D; \\sum_0^{n - 1}\\frac{i + 1}{n} &#x3D; \\frac{n + 1}{2}$。</p>\n<p>更多考虑：查找概率不等；查找失败需要N次比较；越界判断</p>\n<p>折半查找：如果顺序表有序，我们可以采用高效率的折半查找</p>\n<p>折半查找可以用一个二叉树结构来表述。比较次数不会超过$\\lfloor\\log_2 N + 1\\rfloor$。</p>\n<p>索引查找：将线性表划分为若干子表，再建立指向这若干子表的一个索引表。相同性质的数据归类到一个子表中。</p>\n<p>索引表：顺序表或链表</p>\n<p>子表：顺序表或链表</p>\n<p>因而可以有四种不同的索引存储方式。</p>\n<p>索引表的特点：表不大， 表中元素不常变动。因而适合用顺序表来表示索引表。</p>\n<p>分块查找：也称索引顺序查找，是顺序查找的改进。子表之间有序；块内元素无序。索引表包括关键字项，指针项，子表长度。</p>\n<p>索引文件：单关键字，多关键字。</p>\n<p>稠密索引：索引表的索引项和主文件的各记录一一对应，称为稠密索引。</p>\n<p>稀疏索引（非稠密索引）：索引项对应主文件的一部分记录。</p>\n<p>索引文件的好处：减少访问外存的次数，提高查找速度。</p>\n<p>倒排文件：不同之处是辅索引表包含物理地址序列。（为什么要倒排？）</p>\n<h4 id=\"二叉搜索树（BST）\"><a href=\"#二叉搜索树（BST）\" class=\"headerlink\" title=\"二叉搜索树（BST）\"></a>二叉搜索树（BST）</h4><p>或者是一棵空树，或者是具有下列性质<br>的二叉树：每个结点有一个关键字(key)，<br>并且:</p>\n<ol>\n<li>任意结点关键字大于等于该结点左<br>子树中所有结点含有的关键字</li>\n<li>同时该结点的关键字小于等于右子<br>树中所有结点含有的关键字</li>\n</ol>\n<p>BST是一种重要的动态搜索结构。它的中序遍历是确定的。 </p>\n<p>BST的插入操作和查找操作同样简单。</p>\n<p>删除操作比较复杂。叶子结点的删除比较简单；如果结点只有一棵子树，也比较简单；如果左右子树都不空，可以用中序后继替换。</p>\n<p>BST的性能：越“平衡”越好。</p>\n<p>二叉搜索树的路径长度和高度直接关系到BST中搜索的开销，对于一棵<br>含有N个关键字的BST</p>\n<ul>\n<li>最好情况下，所有搜索都可以保证对数运行时间</li>\n<li>最坏情况下，进行一次搜索需要 次比较</li>\n<li>平均情况下搜索需要 次比较操作</li>\n</ul>\n<p>BST的旋转操作：结点和一个子孙交换角色。分为左旋转和右旋转。右旋转涉及到结点和右孩子。（右旋转和左旋转是以结点自己作为参考系而言。）</p>\n<p>BST通过不断的旋转来保证自己的平衡性。</p>\n<p>AVL树：<br>一棵AVL树或者是空树，或者是具有下列性质的二叉搜索树:</p>\n<ol>\n<li>左子树和右子树都是AVL树</li>\n<li>且左子树和右子树的高度之差的绝对<br>值不超过1</li>\n</ol>\n<p>AVL的高度为$O(\\log_2 n)$，平均查找长度也为$O(\\log_2 n)$。</p>\n<p>AVL具有良好的搜索性能，能够避免一般BST性能恶化的问题。但是AVL的维护比较复杂，在进行插入和删除操作后，都必须通过大量的旋转操作保证AVL的平衡性。</p>\n<p>寻找其他方法，以提高BST的平衡程度，保证BST的性能。</p>\n<ul>\n<li><p>实用的平衡二叉搜索树-红黑树</p>\n</li>\n<li><p>多路平衡的动态查找结构-B-树</p>\n</li>\n</ul>\n<h4 id=\"散列\"><a href=\"#散列\" class=\"headerlink\" title=\"散列\"></a>散列</h4><p>散列的关键是散列函数和冲突处理。</p>\n<p>散列函数应是简单的，能在较短的时间内计算出结果</p>\n<p>散列函数的定义域必须包括需要存储的全部关键码，如果散列表允许有m<br>个地址，其值域必须在0到m-1之间</p>\n<p>理想的散列函数应近似为随机的，对每一个输入，相应的输出在值域上是<br>等概的。</p>\n<p>冲突处理：</p>\n<ul>\n<li>链地址法：把散列到同一个地址的关键字存进链表中。（表长小于元素数目）</li>\n<li>开放定址法：放在表中空的位置。查找时采用“探测”的方法。如果探测下一个位置，称为线性探测。（表长大于元素数目，稀疏表，一般不允许表达到半满状态）</li>\n<li>双重散列法：用第二个散列函数表达散列的增量。时间复杂度略大，但是性能比线性探测好很多。</li>\n</ul>\n<p>散列的其他应用：字符串的匹配；搜索引擎对URL的散列；信息安全中的内容鉴别技术（MD5, sha）。</p>\n<p>散列提供常数时间的查找性能，实现简单；但是好的散列函数不易找到，删除操作和空间性能不好，最坏情况下性能不好，忽略了数据间的逻辑关系。</p>\n<h3 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h3><p>排序算法的稳定性：如果两个对象的排序码相等，排序前后的顺序不变，则是稳定的；否则是不稳定的。</p>\n<p>内排序：数据对象存放在内存。</p>\n<p>外排序：数据对象在内、外存之间移动。</p>\n<p>冒泡排序：复杂度为$O(n^2)$。添加排序标记，最好情况下只需要$n - 1$次比较和0次交换。</p>\n<p>插入排序：有直接插入，折半插入，希尔排序</p>\n<p>直接插入：$O(n^2)$</p>\n<p>折半插入：查找插入位置的时候可以采用折半查找，因为表中可以插入的部分已经排好序了。复杂度没有变化，依然是$O(n^2)$</p>\n<p>希尔排序：如果序列中，间距为h的元素都有序，称这个序列为h-排序的。希尔排序就是不断缩小h，直到h&#x3D;1。</p>\n<p>选择特定的步长序列$h_n$，取出序列中增量为$h_n$的子列进行插入排序。然后取$h_{n-1}$，直至取$h_1&#x3D;1$。</p>\n<p>它在h比较大的时候排序，由于间距短，速度快；而h小的时候，由于有序性强，速度快。总体速度依赖于步长序列的选择，时间复杂度比直接插入好一些。</p>\n<p>选择排序：比较次数$O(n^2)$，移动次数$O(n)$，移动次数少一些。</p>\n<p>冒泡排序和插入排序都是稳定的，而选择排序是不稳定的。</p>\n<p><strong>快速排序</strong>：一种交换类排序。具有很好的性能。</p>\n<p>将待排序序列分为两个部分，满足：</p>\n<ol>\n<li>a[i]位于它在序列中的正确位置</li>\n<li>前面的元素比a[i]小</li>\n<li>后面的元素比a[i]大<br>然后对两个部分继续划分，每次划分都将一个元素划分到它的正确位置。</li>\n</ol>\n<p>如何划分：</p>\n<p>选择划分元素v。从序列左边扫描，找到一个比v大的元素，从右边扫描，找到一个比v小的元素，交换两个元素。反复交换，直到左右扫描指针相遇，则划分完成。</p>\n<p>快速排序的递归树是一颗二叉搜索树，因为每次递归都是对比自己大和比自己小的两个部分递归。</p>\n<p>时间复杂度：理想情况下$O(N\\log_2N)$，如果递归树是平衡的。平均情况下为$O(N\\log N)$，而最坏情况下退化为$O(N^2)$。</p>\n<p>快速排序是不稳定的排序算法。</p>\n<p>改进：</p>\n<p>划分元素是最大或者最小的元素时是最坏情况。为了避免最坏情况，采用中间元素法：取序列的左端元素，右端元素和中间元素，选择关键字处于中间的元素作为划分元素。</p>\n<p>快速排序中，子序列非常小时仍然要递归调用，可以采用插入排序代替，提高效率。</p>\n<p>归并排序：合并有序表。两个表的归并，叫二路归并。利用二路归并可以实现归并排序。</p>\n<p>自底向上归并：将文件分割成长度为m的子序列，每次m翻倍。</p>\n<p>自顶向下归并：将文件分割为两个部分，分别进行递归的归并排序后再合起来进行归并排序。</p>\n<p>归并排序是稳定的，时间最好情况是$O(N\\log N)$，最坏是$O(N^2)$.</p>\n<p>堆：堆是满足堆性质的完全二叉树。</p>\n<p>最大堆：任意节点的值小于父节点的值。</p>\n<p>最小堆；任意节点的值小于父节点的值。</p>\n<p>因为是完全二叉树，适合用顺序存储方式。</p>\n<p>堆：顺序存储在一维数组中。</p>\n<p>堆的操作，例如插入，删除或者修改结点会破坏堆的性质，因此修复堆是重要的操作。</p>\n<p>对于最大堆，如果某结点的关键值小于其子节点的关键值，可以采用自顶向下堆化(Heapify-down)的算法进行修复。</p>\n<p>对于最大堆，若结点的关键值大于父节点的关键值，采用自底向上堆化(Heapify-up的算法进行修复)</p>\n<p>向堆中插入结点：在新节点插入堆尾，调用自底向上算法调整堆。这种构造堆方法称为自顶向下的堆构造。</p>\n<p>自顶向下的堆构造：$O(N\\log N)$</p>\n<p>自底向上的堆构造：时间复杂度$O(N)$</p>\n<p>自底向上构造复杂度小的原因：离根远的复杂度小，离根近的复杂度大。而自顶向下是离根远的复杂度大，离根近的复杂度小。离根远的数量多，而离根近的数量少，因此自底向上的整体的复杂度更小。</p>\n<p>优先级队列可以用堆实现，性能非常好。</p>\n<p>堆排序：节约空间，比较次数和移动次数都是$O(N\\log N)$。堆排序是不稳定的排序方法。</p>\n<p>从小到大排序的方法：自底向上构造最大堆。将堆首与堆尾交换，堆序列长度-1，调整堆，再次交换，重复上述过程，直到堆空。</p>\n<blockquote>\n<p>堆排序大概可以理解成优先队列的出队过程。</p>\n</blockquote>\n<p>采用决策树的方法可以求得比较次数的下界为$O(N\\log N)$</p>\n<h2 id=\"数值算法\"><a href=\"#数值算法\" class=\"headerlink\" title=\"数值算法\"></a>数值算法</h2><h3 id=\"基础\"><a href=\"#基础\" class=\"headerlink\" title=\"基础\"></a>基础</h3><p>一个数值问题是适定的(well posed)，需要满足：</p>\n<ul>\n<li>解存在</li>\n<li>解唯一</li>\n<li>连续地依赖于问题数据</li>\n</ul>\n<p>不满足条件的问题被称为不适定的(ill-posed)。</p>\n<p>适定的问题，如果解对输入数据非常敏感，则称之为病态的(ill-conditioned)。</p>\n<p>针对适定和良态(well-conditioned)问题，数值分析可以得到具有一定精度的近似解。</p>\n<p>数值分析重视误差。误差&#x3D;计算误差+传播误差，算法影响的是计算误差。误差有模型误差、测量误差、截断误差、舍入误差。</p>\n<p>前向误差反映了输出的误差，后向误差反映了输入的误差。相对前向误差与相对后向误差的比值叫做条件数(condition number)。$cond \\le 1$说明问题是良态的；否则是病态的。</p>\n<p>实际问题中我们通常求解条件数的估计值或者上限。进而求得前向误差。</p>\n<p>相对条件数:$\\left|\\frac{xf^\\prime (x)}{f(x)}\\right|$。绝对条件数：$\\left|f(x)\\right|$</p>\n<p>算法的稳定性：如果一个算法对于计算过程中的微小扰动不敏感，则算法是稳定的。</p>\n<p>问题的病态性针对输入数据的微小扰动，而算法的稳定性针对的是计算过程中的误差。</p>\n<p>最近舍入法：与x最相近的浮点数，如果相等，取最后一个存储位为偶数。</p>\n<p>若是偶数，则区间是闭区间；若是奇数，则对应的区间为开区间。</p>\n<p>浮点数的下溢限主要由尾数决定，机器精度由尾数决定。</p>\n<p>浮点数的表示法:</p>\n<div>$$\nx = \\pm \\left(d_0 + \\frac{d_1} \\beta + \\frac{d_2} {\\beta^{2}}+ \\dots + \\frac{d_{p-1}} {\\beta^{p-1} } \\right)\\beta^E\n$$</div>\n\n<p>在正规化浮点数系统中：</p>\n<div>$$\n\\text{UFL}=\\beta_L\\\\\n\\text{OFL}=\\beta^{U+1}(1 - \\beta^{1-p})\\\\\n$$</div>\n\n<p>机器精度：舍入造成的相对误差上限：</p>\n<div>$$\n\\left|\\frac{fl(x) - x}{x}\\right| \\le \\epsilon_{mach}\n$$</div>\n\n<p>最近舍入方式下：</p>\n<div>$$\n\\epsilon_{mach} = \\beta^{1-p} / 2\n$$</div>\n\n<h3 id=\"线性方程求解\"><a href=\"#线性方程求解\" class=\"headerlink\" title=\"线性方程求解\"></a>线性方程求解</h3><p>解矩阵方程$A\\mathbb x &#x3D; \\mathbb b$。</p>\n<p>误差分析：</p>\n<p>条件数：$\\text{cond}(A) &#x3D; ||A||||A^{-1}||$</p>\n<p>直观理解：两条线接近平行的时候，两条线截距的轻微扰动会造成解很大的不确定性。</p>\n<p>解方程：</p>\n<p>直接求解法</p>\n<p>高斯消元法：复杂度$O(n^3)$。通常采用列选主元的方法提高算法的稳定性。</p>\n<p>LU分解：如果$b$变化而$A$不变，可以较快地多次求解。</p>\n<p>解的精度分析：条件数大，即使残差很小，也会得出极大的计算误差。是因为问题本身非常敏感。</p>\n<p>高斯-约当法：把A变换为对角阵。</p>\n<p>乔列斯基分解：A是对称正定阵，则A&#x3D;LL’。</p>\n<ul>\n<li>算法是良态的</li>\n<li>不需要选主元就有稳定性</li>\n<li>只需要存储下三角部分即可</li>\n<li>分解的乘法和加法次数都约为$n^3&#x2F;6$</li>\n</ul>\n<p>线性方程的迭代解法：</p>\n<p>不动点迭代法：</p>\n<div>$$\nAx = b \\Rightarrow x = Gx + C\n$$</div>\n\n<p>不动点迭代的收敛核心在于G。</p>\n<p>对于矩阵M，定义谱半径$\\rho(M)$为M的特征值绝对值的最大值。</p>\n<p>如果$\\rho(G)&lt; 1$，则不动点迭代收敛。</p>\n<p>分裂$A &#x3D; M - N$，则</p>\n<div>$$\n(M - N)x = b\\Rightarrow\\\\\nx = M^{-1}Nx + M^{-1}b\n$$</div>\n\n<p>当$\\rho(M^{-1}N) &lt; 1$时，不动点迭代收敛。</p>\n<p>Jacobi（雅克比）方法：$A &#x3D; D + L + U$, $M &#x3D; D$, $N &#x3D; - (L + U)$, $x^{k+1} &#x3D; D^{-1}[b - (L+U)x^k]$。</p>\n<p>高斯-赛德方法：<br>$A &#x3D; D + L + U$, $M &#x3D; D + L$, $N &#x3D; -U$, $x^{k+1} &#x3D; (D+L)^{-1}(b - Ux^k)$。</p>\n<p>这两种迭代都不一定收敛，但是实际中一般都可以。高斯赛德方法速度比雅克比快一倍。</p>\n<h3 id=\"非线性方程求解\"><a href=\"#非线性方程求解\" class=\"headerlink\" title=\"非线性方程求解\"></a>非线性方程求解</h3><p>误差分析：</p>\n<p>非线性方程$f(x) &#x3D; 0$，真解为$x^*$，近似解为$\\hat x$。</p>\n<p>残差：$||f(\\hat x)||$</p>\n<p>前向误差：$||\\hat x - x^*||$，能更准确地描述解的精确程度。</p>\n<p>绝对条件数：$1&#x2F;|f^\\prime(x^*)|$</p>\n<p>可见，如果f(x)在$x^*$处接近水平，则问题是病态的。</p>\n<p>具有重根的问题也是病态的。</p>\n<p>解法：</p>\n<p>二分法：定义误差$e_k &#x3D; x_k - x^*$，定义迭代法的收敛速度定义：$\\lim_{k\\rightarrow \\infty}\\frac{||e_{k + 1}||}{||e_k||^r} &#x3D; C$，则收敛速度为$r$。r&#x3D;1称为线性的，r&gt;1称为超线性的，r&#x3D;2称为平方的。二分法的迭代次数与函数的具体形式无关。</p>\n<p>不动点迭代法：</p>\n<p>收敛性：</p>\n<div>$$\n\\lim_{k\\rightarrow \\infty}\\frac{||e_{k+1}||}{||e_k||} \\\\=\\lim_{k\\rightarrow \\infty}\\frac{g(x_k) - x^*}{x_k - x^*} \\\\\n= \\lim_{k\\rightarrow \\infty} g^\\prime (\\xi_k) = g^\\prime(x^*) \n$$</div>\n\n<p>绝对条件数为$g^\\prime(x^*)$。如果$|g^\\prime(x^*)|$非零，则收敛是线性的，如果为0，则是超线性的。</p>\n<p>牛顿迭代法：</p>\n<div>$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{f^\\prime(x_k)}\n$$</div>\n\n<p>由于$g^\\prime(x^*)&#x3D;0$，收敛是超线性的。进一步分析得到$\\lim_{k\\rightarrow \\infty}\\frac{x_{k+1} - x^*}{(x_k - x^*)^2} &#x3D; \\frac{f^{\\prime\\prime}(x^*)}{2f^\\prime(x)}$，因此牛顿法是平方收敛的。</p>\n<p>牛顿法的特点：</p>\n<ul>\n<li>初值的选取很重要</li>\n<li>$f^\\prime(x)\\ne 0$</li>\n<li>速度快，但是可能出现振荡的情况</li>\n<li>对多重根的收敛速度退化为线性</li>\n<li>涉及到求导，有时候比较困难</li>\n</ul>\n<p>准牛顿法：免去了求导</p>\n<div>$$\nx_{k + 1} = x_k - \\frac{f(x_k)}{g_k}\n$$</div>\n\n<p>割线法：准牛顿法的一种</p>\n<div>$$\ng_k = \\frac{f(x_k) - f(x_{k - 1})}{x_k - x_{k - 1}}\n$$</div>\n\n<p>反插：割线法是用两次的迭代值确定一条直线，取直线与x轴的交点。可以采用反二次插值：用前三次迭代值确定抛物线$x &#x3D; p(y)$，取它与x轴的交点。</p>\n<p>二分法较安全，但速度慢；迭代法速度快，但不安全。可以在区间较大时采用二分法缩小区间，等区间较小时再采用迭代法。</p>\n<h3 id=\"拟合与插值\"><a href=\"#拟合与插值\" class=\"headerlink\" title=\"拟合与插值\"></a>拟合与插值</h3><h4 id=\"拟合\"><a href=\"#拟合\" class=\"headerlink\" title=\"拟合\"></a>拟合</h4><p>如果方程的数目多于未知数的数目，则是超定方程。</p>\n<p>如果方程的数目少于未知数的数目，则是欠定方程。</p>\n<p>超定方程在线性最小二乘的意义下得到一个近似解。</p>\n<p>转而求解$A^TAx &#x3D; A^Tb$。如果矩阵A是列满秩的，则解唯一。</p>\n<p>若$A^TA$是正定的，则有$A &#x3D; LL^T$。</p>\n<p>可以采用QR分解将长方阵A简化：</p>\n<div>$$\nA = Q\\begin{bmatrix}\nR\\\\\n0\n\\end{bmatrix}\n$$</div>\n\n<p>进一步，如果$Q &#x3D; \\begin{bmatrix}Q_1\\Q_2\\end{bmatrix}$，则$Rx &#x3D; Q_1^Tb$。</p>\n<p>利用household变换进行QR分解。</p>\n<p>正规方程方法的复杂度：$mn^2&#x2F;2  + n^3&#x2F;6$</p>\n<p>household变换的复杂度：$mn^2 - n^3 &#x2F; 3$</p>\n<p>如果m和n相当，则两种变换的复杂度相当，而m远大于n时，QR分解的复杂度是正规方程方法的两倍。</p>\n<p>QR分解的适用性更宽。</p>\n<h4 id=\"插值\"><a href=\"#插值\" class=\"headerlink\" title=\"插值\"></a>插值</h4><p>插值使得函数精确地通过给定数据点。</p>\n<p>单项式基底：$\\phi_j(x) &#x3D; x^{j - 1}$。给定点数越多的插值问题，病态性越高，插值多项式的系数不稳定。</p>\n<p>霍纳法则：$t_1 + x(t_2+x(t_3+(\\dotsb)))$，减少乘法次数。</p>\n<p>拉格朗日插值：</p>\n<div>$$\nl_j(x) = \\frac{\\prod_{k = 1, k \\ne j}^{n}(x - x_k)}{\\prod_{k = 1, k\\ne j}^{n}(x_j - x_k)}\n$$</div>\n\n<ul>\n<li>确定形式容易</li>\n<li>计算值困难</li>\n<li>微分，积分不方便</li>\n</ul>\n<p>牛顿插值：基底取$\\prod_{k &#x3D; 1}^{j - 1}(t - t_k)$。</p>\n<ul>\n<li>容易确定，系数较容易求解</li>\n<li>计算可以通过类似霍纳法则的方法求得，时间复杂度低</li>\n<li>在确定和求值之间形成了较好的平衡。</li>\n</ul>\n<h3 id=\"优化问题\"><a href=\"#优化问题\" class=\"headerlink\" title=\"优化问题\"></a>优化问题</h3><p>分为连续优化问题和离散优化问题。</p>\n<p>可行点，约束集合。</p>\n<h4 id=\"连续优化问题\"><a href=\"#连续优化问题\" class=\"headerlink\" title=\"连续优化问题\"></a>连续优化问题</h4><p>有线性规划和非线性规划问题。</p>\n<p>线性规划：不细讲。</p>\n<p>非线性规划：</p>\n<p>（严格&#x2F;非严格）全局最小值，局部最小值。全局最小值的求解，甚至验证都很困难。</p>\n<p>闭集：闭集是补集为开集的集合。如果一个集合中所有的极限点都是这个集合中的点，则这个集合是闭集。</p>\n<p>有界闭集上的连续函数有全局最小值。如果不是闭的或者无界，就可能没有最小值。</p>\n<p>$\\lim_{||x||\\rightarrow \\infty} f(x) &#x3D; \\infty$，称$f(x)$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的。</p>\n<p>如果连续函数$f$在无界闭集$S\\sube \\mathbb{R^n}$上是强制的，则$f$在$S$上存在全局最小值。</p>\n<p>集合是凸的：任意两点的连线属于这个集合。</p>\n<p>函数是凸的：区间内函数值不超过端点连线上的函数值。</p>\n<p>如果集合和函数都是凸的，称为凸优化问题。</p>\n<p>我们有如下结论：</p>\n<ul>\n<li>如果$f$是凸集$S\\sube \\mathbb{R^n}$上的凸函数，则在 $S\\sube \\mathbb{R^n}$的任意内点上连续</li>\n<li>凸函数$f$在凸集$S\\sube \\mathbb{R^n}$上的任意局部最小值，都是$f$在$S\\sube \\mathbb{R^n}$上的全局最小值</li>\n<li>严格凸函数$f$在凸集 $S\\sube \\mathbb{R^n}$上的局部最小值，是$f$在$S\\sube \\mathbb{R^n}$上的唯一全局最小值</li>\n<li>如果$f$在有界闭集$S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一的全局最小值</li>\n<li>如果$f$在无界闭集 $S\\sube \\mathbb{R^n}$上严格凸，则$f$在$S\\sube \\mathbb{R^n}$上存在唯一全局最小值的充要<br>条件是$f$在$S\\sube \\mathbb{R^n}$上是强制的</li>\n</ul>\n<p>下面考虑无约束优化：</p>\n<p>梯度为0的点是临界点。</p>\n<p>临界点可能是局部最大值&#x2F;最小值&#x2F;鞍点。</p>\n<p>如果函数是凸的，临界点就是全局最小值点。</p>\n<p>海森矩阵正定，则f是凸的。</p>\n<p>如果$x^*$是函数$f$的最小值，<br>则$\\nabla f(x^*) &#x3D; 0$，$\\nabla^2f(x^*)$非负定。</p>\n<p>如果$\\nabla f(x^*) &#x3D; 0$且$\\nabla^2f(x^*)$正定，则$x^*$是严格局部最小值。</p>\n<p>如果是凸优化，则$\\nabla f(x^*) &#x3D; 0\\Leftrightarrow f(x^*)$为严格局部最小值</p>\n<p>矩阵的正定性：</p>\n<ul>\n<li>特征值全正</li>\n<li>Cholesky分解唯一</li>\n<li>顺序主子式的行列式全正</li>\n</ul>\n<p>拉格朗日乘数法：</p>\n<div>$$\n\\mathcal{L}(x, \\lambda) = f(x) + \\lambda^Tg(x)\n$$</div>\n\n<p>海森矩阵：</p>\n<div>$$\nH_{\\mathcal{L}}(x, \\lambda) = \\begin{bmatrix}\n    B(x, \\lambda) && J_g^T(x)\\\\\n    J_g(x) && 0\n\\end{bmatrix}\\\\\nB(x,\\lambda) = H_f(x) + \\sum_{i = 1}^m\\lambda_iH_{g_i}(x)\n$$</div>\n\n<p>只要$B(x^*, \\lambda^*)$正定，则$x^*$是极小值点。</p>\n<p>敏感性和病态性：依赖于海森矩阵</p>\n<ul>\n<li>海森矩阵奇异，则极值问题病态</li>\n<li>海森矩阵接近奇异，则极值问题敏感</li>\n</ul>\n<p>下面考虑一维优化问题：</p>\n<p>单峰函数:最小值左侧递减，最小值右侧递增。</p>\n<p>类似于二分法，可以用黄金分割搜索求单峰函数的极小值。</p>\n<p>好处：每次迭代只需要更新一个点；安全性好；收敛速度线性；</p>\n<p>坏处：收敛速度还可以提高。</p>\n<p>方法二：逐次抛物插值。用两个端点和一个近似极值点拟合一条抛物线，取抛物线的最小值点作为新的近似极值点，反复直到收敛。</p>\n<p>当初始点接近极值点时能够收敛；收敛是超线性的。</p>\n<p>牛顿迭代法：</p>\n<div>$$\nx_{k + 1} = x_k - \\frac{f'(x_k)}{f''(x_k)}\n$$</div>\n\n<p>实际上采用黄金分割搜索和逐次抛物插值混合方案，避免求函数的导数。</p>\n<p>多维优化问题：</p>\n<p>最速下降法：</p>\n<div>$$\nx_{k + 1} = x_k - \\alpha_k\\nabla f(x_k)\n$$</div>\n\n<p>确定$\\alpha_k$：$\\min_{\\alpha_k} f(x_k - \\alpha_k \\nabla f(x_k))$</p>\n<p>非常可靠，只要梯度不为0；速度可能不快，呈之字形；收敛速度线性；初值的选择很重要。</p>\n<p>牛顿法：</p>\n<div>$$\nx_{k + 1} = x_k - H_f^{-1}(x_k)\\nabla f(x_k)\n$$</div>\n\n<p>平方收敛，速度快于梯度下降；需要距离最优解很近；不需要搜索参数；如果目标具有连续的二阶偏导数，则海森矩阵对称。</p>\n<p>拟牛顿法</p>\n<div>$$\nx_{k + 1} = x_k - \\alpha_kB_k^{-1}\\nabla f(x_k)\n$$</div>\n\n<h2 id=\"算法设计思想\"><a href=\"#算法设计思想\" class=\"headerlink\" title=\"算法设计思想\"></a>算法设计思想</h2><h3 id=\"贪心算法\"><a href=\"#贪心算法\" class=\"headerlink\" title=\"贪心算法\"></a>贪心算法</h3><ul>\n<li>可行性</li>\n<li>局部最优</li>\n<li>不可取消</li>\n</ul>\n<p>不是所有优化问题都能通过贪心算法求解，即使可以使用贪心算法，也不一定能够得到最优解。</p>\n<p>如果一个优化问题可以通过局部最优选择得到全局最优解，则说这个问题满足贪心选择性质，此时可以简单高效地求得问题的最优解。</p>\n<p>贪心策略可以有很多种。不同的算法有不同的性能。不一定得到全局最优解。</p>\n<h3 id=\"动态规划\"><a href=\"#动态规划\" class=\"headerlink\" title=\"动态规划\"></a>动态规划</h3><p>多阶段动态过程的优化问题</p>\n<p>阶段：把问题分成几个相互联系的有顺序的几个环节，这些环节被称<br>为阶段</p>\n<p>状态：某一阶段的出发位置称为状态。通俗的说状态是对问题在某一<br>时刻的进展情况的数学描述</p>\n<p>决策：从某阶段的一个状态演变到下一个阶段某状态的选择</p>\n<p>条件：最优化原理；无后效性</p>\n<p>动态规划用空间换时间，有大量重叠子问题时才能体现它的优势。</p>\n<p>例：Floyd算法，Viterbi译码</p>\n<h3 id=\"蛮力法\"><a href=\"#蛮力法\" class=\"headerlink\" title=\"蛮力法\"></a>蛮力法</h3><h3 id=\"分治法\"><a href=\"#分治法\" class=\"headerlink\" title=\"分治法\"></a>分治法</h3><p>快速排序</p>\n<p>分治法：分成若干个小的同类问题</p>\n<p>减治法：变成一个更小的同类问题</p>\n<p>变治法：变成若干个更简单的问题</p>\n<h3 id=\"搜索算法\"><a href=\"#搜索算法\" class=\"headerlink\" title=\"搜索算法\"></a>搜索算法</h3><p>组合优化问题的解空间指的是搜索答案的过程中搜索过的可行解。</p>\n<p>回溯法：没有希望的解就不去搜索。</p>\n<p>分支界限法：一边搜索一边给出当前部分解的下界。对于下界比搜索到的可行解还大的分支，不去搜索。下界的估计方法很重要。</p>\n<p>回溯法和分支界限法都不能保证求解的效率。</p>\n<h3 id=\"随机算法\"><a href=\"#随机算法\" class=\"headerlink\" title=\"随机算法\"></a>随机算法</h3><p>Sherwood算法</p>\n<p>快速排序在某些序列下会发生时间复杂度的退化。随机划分元素，可以使得达到最坏复杂度的概率降到很低。</p>\n<p>一般地，若确定型算法在最坏情况下的时间复杂度和它在平均情况下的时间复杂度有较大的差异，通过随机性可以消除这种差别。并不是避免这种最坏的情况发生，而是切除这种最坏情况和特定实例之间的联系。</p>\n<p>Las Vegas算法</p>\n<ul>\n<li>随机化决策</li>\n<li>减少算法运行的时间</li>\n<li>有概率会失败</li>\n<li>多尝试几次以提高成功率</li>\n</ul>\n<p>Monte Carlo算法</p>\n<ul>\n<li>概率为基础的统计模拟方法</li>\n<li>不保证得到正确的解</li>\n<li>设计合理，大量重复可以大概率得到高精度的解</li>\n</ul>\n<p>随机投点求面积</p>\n<p>一个蒙特卡洛方法得到正确判定的概率不小于p，则算法是p正确的。</p>\n<p>如果同一实例不会给出不同的解，称算法是一致的。</p>\n<p>对于判定问题，如果能够保证返回true时是正确的，称为偏真的；保证返回false时是正确的，则算法是偏假的。</p>\n<p>Sherwood:一定得到正确解，一般不会遇到最坏情况</p>\n<p>Las Vegas:不一定得到正确解，但如果得到了一定是正确的</p>\n<p>Monte Carlo:不一定得到正确解，即使得到了也不一定是正确的</p>\n<h3 id=\"算法优化技术\"><a href=\"#算法优化技术\" class=\"headerlink\" title=\"算法优化技术\"></a>算法优化技术</h3><p>输入增强技术</p>\n<ul>\n<li><p>字符串匹配算法</p>\n</li>\n<li><p>计数排序</p>\n</li>\n</ul>\n<p>预构造技术</p>\n<ul>\n<li><p>并查集</p>\n</li>\n<li><p>二叉查找树</p>\n</li>\n<li><p>倒排索引</p>\n</li>\n<li><p>堆和堆排序</p>\n</li>\n</ul>\n<p>时空平衡</p>\n<ul>\n<li>比特逆序</li>\n<li>散列</li>\n</ul>\n"},{"title":"Digital Signal Processing","date":"2023-09-20T01:51:58.000Z","katex":true,"_content":"\n\n## 绪论\n\n### 信号\n\n信号是某种随时间或/和空间变化的物理量，其包含有从信源到信宿的某种信息。\n\n信号可以根据时间和幅度的取值方式分类\n- 连续时间信号\n- - 在时间和幅度上均可以连续取值的信号\n- 离散时间信号\n- - 仅在离散时间点上取值，但可在幅度上连续取值的\n信号\n- 数字信号\n- - 仅在离散时间点上取值，且在幅度上只能离散取值\n的信号\n\n### 系统\n\n- 由若干相互作用和相互依赖的事物组合而成的具有特\n定功能的整体\n- 具有它自身的结构、行为和性质，通过输入和输出与\n其所处的环境进行交互，通常实现一定的功能\n- 可通过分析给定输入下输出的性质，来研究其行为和\n性质\n\n信号处理系统\n- 对信号进行某种操作的单元或模块\n- 从数学上看，可视为作用于函数上的算子\n\n通常根据信号处理单元而非输入输出信号性质分类\n- 连续（模拟）信号处理系统\n- - 由电阻、电容、电感和放大器等组成的模拟电路完成信号处\n理功能\n- - 直接处理连续信号\n- 离散信号处理系统\n- - 由CCD、电容和放大器等组成的离散电路完成信号处理功能\n- - 处理由连续信号采样而来的离散时间信号\n- 数字信号处理系统\n- - 信号处理功能由数字逻辑电路或通用计算机来完成\n- - 处理数字信号（例如来源于对连续信号的采样和量化）\n\n模拟 -> 采样量化 -> 数字信号处理系统 -> 模拟重建 -> 模拟输出信号\n\n### 数字信号处理的局限\n- ADC和DAC器件的处理能力\n- - 是否能够准确提取出原连续信号中的信息首先决定于\nADC：采样率、量化位数、时钟抖动、线性度等\n- 精度受量化和舍入误差影响\n- - 有限字长效应：数字系统中数字表示和计算精度受字\n长限制\n- 适合于数字处理的信号带宽受处理能力的限制\n- - 例如，信号带宽10MHz、采样率20MHz、FIR滤波器阶\n数为500，则所需计算量为每秒10G次的乘累加\n- - 如果带宽为1GHz呢?\n\n### 数字信号处理的发展\n- 20世纪初至50年代有许多前期的研究工作，从采样\n定理的建立到声码器的数字仿真实验等，奠定了理论\n基础\n- 1965年FFT的提出，是DSP发展的里程碑 （但其源头\n可追溯到高斯时代）\n- 离散变换的进展：65年FFT，70年代余弦变换，80年\n代中后期小波变换\n- 滤波器设计技术：IIR、FIR数字滤波器，多采样处理\n和滤波器组理论，专用滤波器设计，小波滤波\n- 统计和自适应信号处理，阵列处理等，从统计学引入\n信号处理发展的另一条主线——现代信号处理\n- 器件和系统的发展对数字信号处理有积极推动\n\n### 从模拟到数字\n\n模拟信号的数字化：ADC\n\n采样：本课程主要考虑均匀采样。\n\n$$\nx[n] = x_a(nT) -\\infty \\lt n \\lt \\infty\\\\ \nf_s = 1/T\\\\\n\\Omega_s = 2\\pi f_s\n$$\n\n采样的实现：采样保持电路\n\n采样周期：与被采样信号的频带参数一起决定了采样过程是否会发生混叠。\n\n采样过程的模糊性：采样过程可看作一种由连续信号空间到离散信号空间的多对一映射；对于给定的采样周期，仍存在无穷多个连续信号与同一离散信号对应。需要施加某种约束条件。\n\n 采样过程的基本问题：\n- 采样过程是否会引起被采样信号的信息丢失？\n- 被采样的连续信号是否能从采样样本中完全恢复？\n- 采样过程的频域分析可获得上述问题的答案\n- - 推导得到采样后离散信号和采样前连续信号频谱间的数学关系\n- - 确定可以消除采样过程模糊性的条件\n- - 为实际数字信号处理系统设计中采样频率的选择、抗混叠前置滤波器的设计提供指导\n\n采样的数学表示：\n\n$$\ns(t) = \\sum_{n = -\\infty}^{\\infty}\\delta(t - nT)\\\\\nx_s(t) = x_a(t) \\cdot s(t)\\\\\nx[n] = x_a(nT)\n$$\n\n对连续信号进行采样，其频谱是原始信号的周期延拓，延拓周期为采样频率\n\n$$\n\\begin{align*}\n\\text{时域} & \\quad \\quad \\text{频域} \\\\\nx_a(t) & \\quad \\quad X_a(j\\Omega)\\\\\ns(t) & \\quad \\quad S(j\\Omega) = \\frac{2\\pi}{T} \\sum_{k=-\\infty}^{+\\infty} \\delta(\\Omega - k\\Omega_s)\\\\\nx_a(t) \\cdot s(t) & \\quad \\quad X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a\\bigg(j(\\Omega - k\\Omega_s)\\bigg)\n\\end{align*}\n$$\n\n带限信号和带通信号：\n* 带限信号：$X_a(j\\Omega) = 0, |\\Omega| \\ge \\Omega_H$\n* 带通信号：$X_a(j\\Omega) = 0, |\\Omega| \\ge \\Omega_H\\text{ or }|\\Omega| \\le \\Omega_L$\n\n带限信号的采样：\n\n<!-- int, sum, frac partial -->\n\n$$\nX_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)], \\Omega_s \\ge 2\\Omega_H\n$$\n\n对应的离散时间序列：\n\n$$\nX(e^{j\\Omega T}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)]\\\\\n\\Rightarrow X(e^{j\\omega}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\omega - 2\\pi k)/T]\\\\\n$$\n\n带通采样让时间以$T \\rightarrow 1$的形式进行归一化，频率以$\\Omega_s \\rightarrow 2\\pi$的形式进行归一化。\n\nNyquist 采样定理：\n\n$$\nX_a(j\\Omega) = 0, \\forall |\\Omega| \\ge \\Omega_H\\\\\n\\Omega_s = 2\\pi / T \\gt 2\\Omega_H\n$$\n\n或者归一化频率\n\n$$\n\\omega_H = \\Omega_H T < \\pi\n$$\n\nRemark：\n- $𝑥_𝑎(𝑡)$ 是基带、带限信号\n- Nyquist是充分条件，即对被采样信号无其他假设\n- 在仅知道连续信号最高频率时，Nyquist采样定理给出\n了由采样信号唯一确定（或恢复）原信号的条件\n- - 已知连续信号最高频率，可用于确定最低采样频率\n- - 已知采样频率，可确定无混叠连续信号的最高频率\n\n带通信号的采样：\n\n$$\n\\frac{2f_H}{m+1} \\le f_s \\le \\frac{2f_L}{m}, m\\in \\N ,m \\le f_L/B\n$$\n\n带限连续信号的重建：\n- 由离散序列𝑥[𝑛]和采样周期𝑇，恢复原连续信号$𝑥_𝑟(𝑡)$\n- 由序列到冲激串转换和重建滤波两个步骤构成\n- 重建后的信号表示为\n\n$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]h_r(t - nT)\n$$\n\n如选择截止频率$\\Omega_c = \\pi/T$的理想低通滤波器：\n\n$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]\\frac{\\sin[\\pi(t - nT)/T]}{\\pi(t - nT)/T}\n$$\n理想低通滤波器通过对冲激串信号的内插重建了原来的连续信号\n\n**Summary**\n\n原信号：\n\n$$\nx_c(t) \\leftrightarrow X_c(j\\Omega)\n$$\n\n采样后的信号：\n\n$$\n\\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) = \\sum\\limits_{n=-\\infty}^{\\infty}x_c(t)\\delta(t - nT_s) \\leftrightarrow \\frac{1}{T_s}X(e^{j\\Omega T_s}) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}X_c(j(\\Omega - n\\Omega_s))\n$$\n\n数字域：\n\n$$\nx[n] \\leftrightarrow X(e^{j\\omega}) = \\frac{1}{T_s} X_c(j\\omega /T_s)\n$$\n\n恢复信号：\n$$\nh_r(t) \\leftrightarrow H_r(j\\Omega) = \\begin{cases}\n    T_s, &|\\Omega| \\le \\pi / T_s, \\\\\n    0,   &|\\Omega| \\gt \\pi / T_s\n\\end{cases}\\\\\n\\begin{align*}\n    x_r(t)  &= \\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) * h_r(t)\\\\\n            &= \\sum\\limits_{n=-\\infty}^{\\infty} x_c(nT_s)h_r(t - nT_s)\\\\\n            &= x_c(t)\n\\end{align*}\\ \\leftrightarrow\\ \\begin{align*}\n    X_r(j\\Omega) &= T_s X(e^{j\\Omega T_s})H_r(j\\Omega)\\\\\n    &= X_c(j\\Omega)\n\\end{align*}\n$$\n\n数字时域和模拟时域之间的关系：\n$$\nn = \\frac{t}{T_s} = tf_s\n$$\n\n数字频域和模拟频域之间的关系：\n$$\n\\omega = \\Omega T_s = \\frac{2\\pi f}{f_s}\n$$\n\n## 信号的表示\n\n### 离散信号的时域表示\n* 时域表示方法\n    * 数学表达式：可表示基本信号，但大多数实际信号无解析表达式\n    * 图形表示：直观、易理解，但不适用于刻画复杂信号\n    * 数据表示：离散信号最一般的表示方法\n\n### 离散信号的变换域表示\n* 定义：假设离散时间信号为𝑥[𝑛] ，定义映射𝑇{·}，那么信号的变换域表示可以写作𝑋 = 𝑇{𝑥[𝑛]}\n    * 𝑇{·}是从函数空间到函数空间的映射\n    * 𝑋并不要求一定定义在整数域上\n* 常用情形：级数表示\n    * 将信号分解成有限项或无穷多项基本信号加权和的形式，由和式中每个基本信号的加权值组成的序列形成了原信号的变换域表示\n    * 傅里叶级数展开 $x[n] = \\sum_k a_k e^{j2\\pi kn /T}$\n\n### 离散信号的正交函数表示\n\n- 使用信号空间的完备正交基来表示离散信号，\n$$\n\\lbrace\\ldots ,\\varphi_0[n] ,\\varphi_1[n] ,\\varphi_2[n] , \\ldots\\rbrace\n$$\n- 正交性：\n$$\n\\sum_{n} \\varphi_k^*[n] \\varphi_l[n] = \\delta_{kl}\n$$\n其中，$k \\neq l$。\n* 完备性\n    * 任何一个信号都可由这组基函数通过线性叠加而构成\n* 加权系数的计算\n    * 对基函数的投影：\n\n$$\nc_k = \\frac{\\langle x[n], \\phi_k[n]\\rangle}{||\\phi_k[n]||^2}\n$$\n\nDFT 的定义如下：\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n]e^{-j2\\pi kn/N}\n$$\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\nDCT 的定义如下：\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n]\\cos\\left(\\frac{\\pi}{N}(n + 0.5)k\\right)\n$$\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\n### 离散信号的特征域（量）表示\n* 特征量表示指由信号的时域或频域表示来计算用\n于表征信号的特征量\n    * 例如能量、功率、均值、相关函数、功率谱\n    * 特征量表示通常是单向性的，由特征量表示一般不能完整地恢复原信号的所有取值\n    * 实践中，经常用特征量来表示随机信号\n\n### 离散信号的单位抽样信号表示：\n单位抽样信号的移位作为基信号：\n$$\n\\varphi_k[n] = \\delta[n - k], \\quad k \\in (-\\infty, \\ldots, -1, 0, 1, \\ldots, \\infty)\n$$\n\n• 正交性验证：\n$$\n\\langle\\varphi_k[n],\\varphi_l[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} \\delta[n - k] \\delta[n - l] = \\delta[k - l]\n$$\n\n• 系数计算：\n$$\nc_k = \\frac{\\langle x[n],\\varphi_k[n]\\rangle}{\\varphi_k[n]^2} = x[k]\n$$\n\n• 离散信号的单位抽样表示为：\n$$\nx[n] = \\sum_{k=-\\infty}^{\\infty} c_k\\varphi_k[n] = \\sum_{k=-\\infty}^{\\infty} x[k] \\delta[n - k]\n$$\n\n离散信号的复指数信号表示如下：\n\n• 复指数信号作为基信号：\n$$\n\\varphi_\\omega[n] = e^{j\\omega n}, \\quad 0 \\leq \\omega < 2\\pi\n$$\n\n• 正交性验证：\n$$\n\\langle\\varphi_{\\omega_1}[n],\\varphi_{\\omega_2}[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} e^{j\\omega_1 n} e^{-j\\omega_2 n} = \\begin{cases} \n0, & \\omega_1 \\neq \\omega_2 \\\\\n\\infty, & \\omega_1 = \\omega_2 \n\\end{cases}\n$$\n\n• 系数计算：\n$$\nX(e^{j\\omega}) = \\langle x[n], e^{j\\omega n} \\rangle = x[n] e^{-j\\omega n}\n$$\n\n• 离散信号的复指数信号表示为：\n$$\nx[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(e^{j\\omega}) e^{j\\omega n} d\\omega\n$$\n\n### 有限长离散信号的正交函数表示\n\n• 对于长度为$N$的有限长离散序列，选择以下$N$个序列作为基信号：\n$$\n\\varphi_k[n] = e^{j\\frac{2\\pi}{N}kn}R_N[n], \\quad k = 0,1,2,\\ldots,N-1\n$$\n\n• 正交性验证：\n$$\n\\langle \\varphi_k[n],\\varphi_l[n] \\rangle = \\sum_{n=0}^{N-1} e^{j\\frac{2\\pi}{N}(k-l)n} = \\begin{cases} \nN, & k = l \\\\\n0, & k \\neq l \n\\end{cases}\n$$\n\n• 系数计算：\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n] e^{-j\\frac{2\\pi}{N}kn}, \\quad k = 0,1,2,\\ldots,N-1\n$$\n\n• 有限长离散序列可以表示为：\n$$\nx[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} X[k] e^{j\\frac{2\\pi}{N}kn}, \\quad n = 0,1,2,\\ldots,N-1\n$$\n\n* 离散信号的因果性:\n    * 𝑥[𝑛] = 0，for 𝑛 < 0\n\n因果连续信号抽样后一定是因果离散信号。\n\n* 离散信号的对称性：\n\n• 共轭对称性：\n  - 正对称：$x[n] = x^*[-n]$\n  - 反对称：$x[n] = -x^*[-n]$\n\n• 任意信号都可以表示为奇分量和偶分量的和：\n  $x[n] = x_o[n] + x_e[n]$\n  其中，$x_o[n] = \\frac{1}{2}(x[n] - x^*[-n])$为奇分量，$x_e[n] = \\frac{1}{2}(x[n] + x^*[-n])$为偶分量。\n\n• 若信号具有实因果性，可以通过奇分量或偶分量来恢复原信号：\n\n$$\nx[n] = \\begin{cases}\n0, & n < 0 \\\\\nx_e[n], & n = 0 \\\\\n2x_e[n], & n > 0\n\\end{cases}\n$$\n\n* 离散信号的周期性：\n    * $𝑥[n] = 𝑥[𝑛 + N]$\n\n周期连续信号均匀采样后**不**一定是周期离散信号。\n\n$$\n\\omega_0 = \\Omega_0T = 2\\pi\\frac{T}{T_0}\n$$\n\n离散余弦信号的数字角频率 $\\omega_0$ 由采样周期和连续信号周期的比值决定。该比值决定了采样后的信号是否具有周期性。\n\n\n### 离散系统的表示\n\n离散系统的表示可以使用以下公式来描述：\n\n$$y[n] = \\sum_{k=-\\infty}^{\\infty} h[k]x[n-k]$$\n\n其中，$y[n]$表示系统的输出，$x[n]$表示系统的输入，$h[k]$表示系统的单位冲激响应。这个公式是卷积的离散形式，也称为离散卷积。\n\n对于因果性，一个离散系统被称为因果性系统，如果它对任何$n < 0$的输入信号$x[n]$都产生$y[n] = 0$的输出。这意味着输出只依赖于当前和过去的输入。\n\n对于稳定性，一个离散系统被称为稳定系统，如果对于有界的输入信号$x[n]$，输出$y[n]$仍然是有界的。\n\nLTI（线性时不变）系统是指具有线性性质和时不变性质的系统。线性性质意味着系统满足叠加原理，即对于输入信号$x_1[n]$和$x_2[n]$，系统的输出满足$y_1[n] + y_2[n]$。时不变性质意味着系统的单位冲激响应$h[k]$与输入信号$x[n]$的延迟无关。\n\n单位冲激响应是指当输入信号为单位冲激函数$\\delta[n]$时，系统的输出。单位冲激响应通常用$h[n]$表示。\n\nLTI系统可完全由单位冲激响应来表征。\n\n因果性判据：单位冲激响应是一个因果信号。\n稳定性判据：$S = \\sum_{k = -\\infty}^\\infty |h[k]| \\lt +\\infty$\n\n**特征函数与特征值**\n\n$$\nT\\lbrace s[n]\\rbrace = \\lambda s[n]\n$$\n\n**LTI系统的特征函数与特征值**\n\n$$\nT\\lbrace e^{j\\omega n}\\rbrace =\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{j\\omega (n - k)} = \\underbrace{e^{j\\omega n}}_{特征函数}\\cdot\\underbrace{\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{-j\\omega k}}_{特征值}\n$$\n\n$y[n]$ 可看作 $x[n]$ 经过特征信号分解、加权、求和的结果：\n\n$$\ny[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^\\pi H(e^{j\\omega})X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$\n\n* 频率响应函数：单位冲激响应的DTFT\n\n$$\nH(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]e^{-j\\omega n}\n$$\n\n* 系统函数\n\n$$\nH(z) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]z^{-n}\n$$\n\n* 系统差分方程\n\n$$\n\\sum\\limits_{k=0}^{N} a_ky[n - k] =\\sum\\limits_{k=0}^{M} b_kx[n - k]\n$$\n\n* 系统状态空间\n\n$$\n\\lambda[n + 1] = A\\lambda[n] + Bx[n]\\\\\ny[n] = C\\lambda[n] + Dx[n]\n$$\n\n## DTFT 与 DFT\n\n### DTFT\n\n$$\n\\begin{cases}\n    X(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\omega n}\\\\\n    x[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi}X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n\\end{cases}\n$$\n\n与连续频谱的关系：\n\n$$\nX(e^{j\\omega}) = \\frac{1}{T}\\sum\\limits_{k=-\\infty}^{\\infty}X_a\\left[j\\left(\\frac{\\omega}{T} - k\\frac{2\\pi}{T}\\right)\\right]\\\\\n\\omega = \\Omega T\n$$\n\n基本性质：\n\n* 周期性\n\n$$\nX(e^{j\\omega}) = X(e^{j\\omega + 2k\\pi}), k\\in \\Z\n$$\n\n* 线性\n\n$$\nax[n] + by[n] \\lrarr aX(e^{j\\omega}) + bY(e^{j\\omega})\n$$\n\n* 频域求导\n\n$$\nnx[n] \\lrarr j\\frac{\\mathrm dX(e^{j\\omega})}{\\mathrm d\\omega}\n$$\n\n* Parseval 定理：\n\n$$\n\\sum\\limits_{n=-\\infty}^{\\infty}||x[n]||^2 = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}||X(e^{j\\omega})||^2\\mathrm d\\omega\n$$\n\n* 序列的调制\n\n$$\nx[n]e^{j\\omega_0 n} \\lrarr X(e^{j(\\omega - \\omega_0)})\n$$\n\n实现数字变频：\n\n$$\nx_B[n] = x[n]e^{-j\\frac{\\pi}{2}n}\n$$\n\n* 序列的平移\n\n$$\nx[n - n_0] \\lrarr e^{-j\\omega n_0}X(e^{j\\omega})\n$$\n\n* 共轭对称性\n\n$$\nx_e[n] \\lrarr \\text{Re}\\lbrace X(e^{j\\omega}) \\rbrace\n$$\n\n$$\nx_o[n] \\lrarr \\text{Im}\\lbrace X(e^{j\\omega}) \\rbrace\n$$\n\n下面是修正后的表格：\n\n| 序列 $x[n]$   | DTFT $X(e^{j\\omega})$ |\n|:------------:|:------------------:|\n| $x[n]$       | $X(e^{j\\omega})$   |\n| $x^*[n]$     | $X^*(e^{-j\\omega})$ |\n| $x^*[-n]$    | $X^*(e^{j\\omega})$  |\n| $x_R[n]$     | $X_e(e^{j\\omega})$  |\n| $jx_I[n]$    | $X_o(e^{j\\omega})$  |\n| $x_e[n]$     | $X_R(e^{j\\omega})$  |\n| $x_o[n]$     | $jX_I(e^{j\\omega})$ |\n| 以下为实信号| | \n| $x[n] = x^*[n]$        | ，$X(e^{j\\omega}) = X^*(e^{-j\\omega})$ |\n| $x_e[n] = \\frac{1}{2}(x[n] + x[-n])$    | $X_R(e^{j\\omega})$ 实、偶函数|\n|$x_o[n] = \\frac{1}{2}(x[n] - x[-n])$| $jX_I(e^{j\\omega})$  虚、奇函数    |\n\n* 卷积与相关性质\n    * 时域卷积： $x[n] * y[n] \\lrarr X(e^{j\\omega})\\cdot Y(e^{j\\omega})$\n    * 频域卷积：$x[n] \\cdot y[n] \\lrarr \\frac{1}{2\\pi}X(e^{j\\omega}) * Y(e^{j\\omega})$\n    * 时域相关：\n        * 互相关：$r_{xy}[k] =\\sum\\limits_{k=-\\infty}^{\\infty}x[n]y^*[n - k]$\n        * 自相关：$r_{xx}[k] =\\sum\\limits_{k=-\\infty}^{\\infty}x[n]x^*[n - k]$\n        * $R_{xy}(e^{j\\omega}) = X(e^{j\\omega}) \\cdot Y^*(e^{j\\omega})$\n        * $R_{xx}(e^{j\\omega}) = X(e^{j\\omega}) \\cdot X^*(e^{j\\omega})$\n\n**DTFT的存在条件：**\n\n取决于 $\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\omega n}$ 的收敛性\n\n有限和序列 $X_N(e^{j\\omega}) =\\sum\\limits_{n=-N}^{N}x[n]e^{-j\\omega n}$\n\n* 若 $x[n]$ 绝对可和，则 DTFT 存在，且一致收敛\n* 若序列满足平方可和，则 DTFT 满足均方收敛性\n    * 截断误差的能量趋于0，但是某些点的误差的绝对值不一定趋于0（例如理想低通滤波器，有吉布斯现象，在截止频率附近存在一个独立于 $N$ 的震荡，即使 $N$ 趋于无穷，在某些频率点上还是存在9%左右的误差）\n\n**特殊信号的 DTFT**\n\n* 符号序列\n\n$$\n\\text{sgn}[n] = \\begin{cases}\n    1, &n\\gt 0,\\\\\n    0, &n = 0\\\\\n    -1, &n \\lt 0\n\\end{cases} \\lrarr \\text{SGN}(e^{j\\omega}) = \\frac{1}{j} \\cot \\left(\\frac{\\omega}{2}\\right)\n$$\n\n* 阶跃序列\n\n$$\nu[n] = \\frac{1}{2}(\\text{sgn}[n] + 1) + \\frac{1}{2} \\delta[n] \\lrarr U(e^{j\\omega}) = \\frac{1}{1 - e^{-j\\omega} + \\pi} + \\pi\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - 2\\pi k)\n$$\n\n* 离散周期单位冲激串\n\n$$\nx[n] =\\sum\\limits_{k=-\\infty}^{\\infty}\\delta[n - kN]\\lrarr X(e^{j\\omega}) =\\sum\\limits_{k=-\\infty}^{\\infty}e^{-j\\omega k N} = \\frac{2\\pi}{N}\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - \\frac{2k\\pi}{N})\n$$\n\n离散时限信号与周期单位冲激串的卷积，在频域上表现为对 DTFT 的采样，这正是从 DTFT 到 DFT 的过渡。\n\n### DFT\n\nDTFT给出了离散信号频域的全部信息，但在实际应用中存在如下困难：\n* 实际信号往往没有解析表达式，无法计算其DTFT\n* 实际物理装置只能采集有限长度的数据\n* DTFT给出的频谱是连续的，无法用数字设备记录和存储全部的值\n\n#### DFT 的定义\n\n$$\n\\begin{cases}\n    X[k] =\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n    x[n] =\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{-nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n\\end{cases}\n$$\n\n其中，\n$$\nW_N = e^{-j\\frac{2\\pi}{N}}\n$$\n\n#### 理解 DFT\n\nDFT 是 DTFT 的频域采样\n\n$$\nX(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{j\\omega n}\\\\\nX[k] = X(e^{j\\omega})\\big |_{\\omega_k = \\frac{2\\pi}{N}k} =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\frac{2\\pi}{N}kn}\n$$\n\n* 频域乘积等价于时域卷积，因此对离散序列在频域上以2𝜋/𝑁为周期进行采样，等效于离散信号在时域上进行周期延拓，延拓周期为𝑁\n\n* 为保证离散序列频域采样对应的时域序列不发生混叠，要求原离散序列为有限长且长度不超过𝑁。\n\n#### DFT 的频域重构\n\n* 首先需要 $N \\ge L$\n\n$$\n\\begin{align*}\n    X(e^{j\\omega}) &=\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\omega n} =\\sum\\limits_{n=0}^{N - 1}\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}X[k]e^{j\\frac{2k\\pi}{N}n}\\bigg]e^{-j\\omega n}\\\\\n    &=\\sum\\limits_{k=0}^{N - 1}X[k]\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}e^{-j(\\omega - \\frac{2k\\pi}{N}n)}\\bigg]\\\\\n    &=\\sum\\limits_{k=0}^{N - 1} X[k]P\\bigg(\\omega - \\frac{2k\\pi}{N}\\bigg)\n\\end{align*}\n$$\n\n其中，内插函数\n\n$$\nP(\\omega) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1} e^{-j\\omega n} = \\frac{1}{N}\\frac{\\sin (\\omega N / 2)}{\\sin (\\omega / 2)}e^{-j \\frac{N - 1}{2}\\omega}\n$$\n\n#### 理解 DFT II\n\n离散正交变换的定义：\n\n* 定义变换矩阵 $A$， 若 $A$ 满足 $A^HA = cI$，其中$c$为常数，则称 $X = Ax$ 为离散正交变换。若 $c = 1$，则称变换是归一化的。\n* 归一化的离散正交变换满足 Parseval 定理：$||X||^2 = X^HX = x^HA^HAx = x^Hx = ||x||^2$\n\nDFT 是对离散时间信号的加权求和，其向量形式\n\n* $X[k] = w_k^Hx$, $w_k = [e^{j\\frac{2\\pi0k}{N}}, e^{j\\frac{2\\pi1k}{N}}, \\dots, e^{j\\frac{2\\pi(N - 1)k}{N}}]^T$\n* $X = [X[0], X[1], \\dots, X[N - 1]]^T$，则有$X = [w_0, w_1, \\dots, w_{N - 1}]^Hx = W_Nx$\n\n$$\nX = W_Nx\\\\\nx = \\frac{1}{N} W_N^HX\n$$\n\n#### DFT 的周期延拓\n\n• DFT本意是用有限个离散频域样本来表示有限长离散序列\n\n– 时域采样对应着频域周期延拓，频域采样对应着时域周期延拓\n\n• 由于周期延拓，DFT总是面对着周期序列\n\n– 在DFT计算和应用中，总是选择时域和频域的主值区间\n\n– DFT这种隐含的周期性决定了其与DTFT具有不同的性质\n\n**周期延拓的数学表示**\n\n$$\n\\big((n)\\big)_N\n$$\n\n周期延拓可以表示为：\n\n$$\n\\tilde X[k] = X\\bigg[\\big((k)\\big)_N\\bigg]\n\\tilde x[n] = X\\bigg[\\big((n)\\big)_N\\bigg]\n$$\n\n也可表示为卷积和：\n\n$$\n\\tilde{X}[k] = X[k] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[k - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}X[k - mN]\\\\\\tilde{x}[n] = x[n] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[n - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}x[n - mN]\n$$\n\n#### DFT 性质\n\n* 线性性\n    * 前提：变换长度 $N$ 相同\n    * 如果不相同，补零到长度 $N \\ge \\max(N_1, N_2)$\n* 反转性质：若时域循环反转，则频域循环反转\n    * $\\text{DFT} \\Bigg\\lbrace x\\big[\\big((-n)\\big)_N\\bigg] R_N[n]\\Bigg\\rbrace = X\\bigg[\\big((-k)\\big)_N\\bigg] R_N[k]$\n    * 0 时刻不变，其余前后反转\n* 共轭性质：若时域共轭，则频域共轭且循环反转\n    * $\\text{DFT}\\lbrace x^*[n]\\rbrace = X^*[N - k]$\n* 对偶性质：序列的DFT的DFT\n    * $\\text{DFT}\\lbrace X[n]\\rbrace = NX^*[N - k]$\n* 周期序列的共轭对称性：\n    * 共轭对称：$x_{ep}[n] = x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$\n    * 共轭反对称：$x_{ep}[n] = -x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$\n    * 任意有限长序列的周期延拓总可以分解为周期共轭对称和反对称的分量和的形式\n        * $x[n] = x_{ep}[n] + x_{op}[n]$\n        * $x_{ep}[n] = \\frac12 (x[n] + x^*\\bigg[\\big((-n)\\big)_N\\bigg])$\n        * $x_{op}[n] = \\frac12 (x[n] - x^*\\bigg[\\big((-n)\\big)_N\\bigg])$\n    * 实序列的DFT是周期共轭对称序列\n    * 虚序列的DFT是周期共轭反对称序列\n    * 周期共轭对称序列的DFT是实的\n    * 周期共轭反对称序列的DFT是虚的\n* 循环卷积性质：\n    * 有限长循环移位的 DFT 可以由原序列 DFT 乘上一个线性的相位因子得到：$\\text{DFT}\\Bigg \\lbrace\\bigg[x\\big((n - m)\\big)_N\\bigg]\\Bigg \\rbrace = X[k]e^{-j\\frac{2\\pi k}{N}m}$\n    * 在 DTFT 中：$x[n] * y[n] = \\text{IDTFT}\\lbrace X(e^{j\\omega}) \\cdot Y(e^{j\\omega})\\rbrace$\n    * DFT 中：$x[n] \\circledast y[n] =\\sum\\limits_{m=0}^{N - 1}x[m]y\\bigg[\\big((n - m)\\big)_N\\bigg] =\\sum\\limits_{m=0}^{N - 1}x\\bigg[\\big((n - m)\\big)_N\\bigg]y[m]$\n* Parseval 定理：\n    * $\\sum\\limits_{n=0}^{N - 1}|x[n]|^2 = \\frac{1}{N}\\sum\\limits_{k=0}^{N - 1}|X[k]|^2$\n\n## FFT\n\nFFT 算法是一大类 DFT 快速算法的总称。\n* 基 2 FFT 算法：$N = 2^m$\n* 基 4 FFT 算法：$N = 4^m$\n* 分裂基算法：基本蝶形是倒 L 型，$N = 2^m$\n* 组合数 FFT 算法：变换点数为组合数，即$N = N_1N_2$\n\n根据处理基本蝶形的结构特点，可以分为：\n* DIT (Decimation-In-Time)\n* DIF (Decimation-In-Frequency)\n\n### 基 2 DIT-FFT 算法\n\n按照奇偶时间拆分成两个短序列。\n\n长序列的 DFT 可以由两个短序列的 DFT 组合得到。\n\n$$\nX[k] = \\sum\\limits_{m=0}^{N/2 - 1}x[2m]W_N^{2mk} + \\sum\\limits_{m=0}^{N/2 - 1} x[2m + 1]W_N^{(2m + 1)k}\\\\\nf_1[n] = x[2n], f_2[n] = x[2n + 1]\\\\\nX[k] = F_1[k] + W_N^kF_2[k]\\\\\nX[k + N/2] = F_1[k] - W_N^kF_2[k]\n$$\n\n反复抽取，变成2点 DFT：\n\n$$\n\\begin{bmatrix}\n    X[0]\\\\\n    X[1]\n\\end{bmatrix} = \\begin{bmatrix}\n    x[0] + x[1]\\\\\n    x[0] - x[1]\n\\end{bmatrix}\n$$\n\n![alt](../images/DSP/4_2.jpg)\n\n计算复杂度：\n* 乘法次数为$\\frac{N}{2}\\log_2N$，$m_a = Nm = N\\log_2 N$\n\n输入和输出序列的顺序关系：二进制下的倒序关系。\n* 每次均分时，输入序列按照奇偶性划分，输出序列按照是否过半划分\n* 输入序列的奇偶性等价于最低位为1还是0，输出序列是否过半等价于最高位为1还是0\n* 因此输入映射到输出序列是低位映射到高位的关系。\n\n## 数字频谱分析\n\n### DFT 谱分析的基本概念\n\n频谱：信号经过傅里叶变换转换到频域后，其频域表示的幅度和相位随频率变化的关系分别称为信号的幅度谱和相位谱\n\n基于 DFT 的数字频谱分析\n\n\n利用离散信号 DFT 结果 $X[k]$ 与原连续信号频谱 $X_a(j\\Omega)$ 之间存在对应关系来获得连续信号的频谱。\n\n$$\nX[k] = X(e^{j\\omega})|_{\\omega = \\frac{2\\pi}{N}k}\n$$\n\n$$\nX(e^{j\\omega}) = \\frac{1}{T_s}X_a(j\\Omega)|_{\\Omega = \\frac{\\omega}{T_s}}\n$$\n\n$$\n X_a(j\\Omega_k)= T_s X[k]\n$$\n\n利用 DFT 结果获得连续信号的频谱：\n\n$$\nX_a(j\\Omega_k) = X_a \\left ( j\\frac{2\\pi k}{NT_s} \\right) = \\begin{cases}\n    T_sX[k], 0 \\le k \\le \\lceil \\frac{N}{2} \\rceil, \\\\\n    T_sX[k + N], - \\lceil \\frac{N - 1}{2} \\rceil\\le k \\lt 0\n\\end{cases}\n$$\n\n基于DFT的频谱分析方法存在的问题\n\n- 理论上连续正弦信号的频谱应为冲激函数，但DFT结果为有限值\n- DFT结果在连续正弦信号频谱幅度为0的位置却不为零\n\n### DFT 谱分析的一般过程\n\n#### 抗混叠滤波\n\n![alt](../images/DSP/5_1.jpg)\n\n#### 采样\n\n提高采样率\n- 优点：能够无混叠分析的信号带宽增大\n- 缺点：数据率提高，系统复杂度增加，成本上升\n\n#### 加窗\n\n由于DFT只能处理有限长序列，需要对输入信号\n通过加窗进行截断\n- 窗长可根据频率分辨率、实时性和设备存储能力的要\n求来权衡\n- 窗函数的形式也可根据主瓣宽度和旁瓣电平进行选择\n\n$$\nw_R[n] = \\begin{cases}\n    1, 0 \\le n \\lt M\\\\\n    0, \\text{others}\n\\end{cases}\n$$\n\n$$\nx_w[n] = x[n]w_R[n]\n$$\n\n#### DFT计算、插值及频谱输出\n\nDFT计算\n- 可能需要补零，以获得更密集的频域采样，以及使变换点数𝑁满足FFT算法的要求（基2-FFT、基4-FFT）\n\n插值\n- 由DFT结果获得DTFT的估计值\n- 插值方法：\n  - 精确插值： $X(e^{j\\omega}) =\\sum\\limits_{k=0}^{N - 1} X[k] P \\left ( \\omega - \\frac{2\\pi k}{N} \\right)$, $P(\\omega) = \\frac{\\sin(\\omega N/2)}{\\sin(\\omega/2)}e^{-j\\frac{N-1}{2}\\omega}$\n  - 近似插值：线性插值，二次插值\n\n连续信号频谱输出\n– 通过坐标变换得到连续信号频谱 $X_a(j\\Omega) = T_sX(e^{j\\Omega T_s})$\n\n### DFT 谱分析问题\n\n#### 谱分析滤波器\n\n$$\ns(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega t}\\mathrm d\\Omega\\\\\ns(nT_s) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega nT_s}\\mathrm d\\Omega\\\\\nx[n] = \\begin{cases}\n    s(nT_s), n = 0, 1, \\dots, M - 1,\\\\\n    0, M, M + 1, \\dots, N - 1\n\\end{cases}\\\\\nX[k] =\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\frac{2\\pi nk}{N}} = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n}\\mathrm d\\Omega\n$$\n\n令 $\\theta = T_s(\\Omega - \\Omega_k)$，\n\n$$\n\\varphi_k(M, \\theta) = \\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n} = \\frac{\\sin(M\\theta / 2)}{\\sin(\\theta/2)} e^{j\\frac{M - 1}{2}\\theta}\n$$\n\n梳状滤波特性\n\n![alt](../images/DSP/5_2.jpg)\n\n周期内存在多个过零点，把滤波器响应分割成多个区间\n* 主瓣：谱分析滤波器频率响应最大的那个区间\n* 主峰：主瓣中最大频率响应点 $Ω = \\frac{2\\pi k}{NT_s}$处，高度为𝑀\n* 主瓣宽度：主瓣两边过零点之间的距离4𝜋⁄𝑀𝑇𝑠\n* 旁瓣：除响应最大的那个区间外的其它区间\n\nDFT频谱分析方法能否反映连续信号的频谱？\n- DFT的结果主要给出了连续信号落在相应谱分析滤波器主瓣内的那部分信号的频域信息\n- 由于相邻谱分析滤波器主瓣间有交叠，同一个信号可能会在相邻两个谱分析滤波器都有响应\n- 谱分析滤波器的旁瓣会在其他谱分析滤波器的主瓣位置出现，其对应的DFT结果不可避免的包含了其他滤波器主瓣位置处的信号成分\n\nDFT 可用于连续信号的频谱分析，但由于其谱分析滤波器频率分割不理想的本质，必须对其输出结果进行小心的解释\n\nDFT谱估计得到的是对加窗后序列DTFT的采样\n\n$$\nx_w[n] = x[n]w_R[n]\\\\\nX_w(e^{j\\omega}) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}X(e^{j\\omega})W_R(e^{j(\\omega - \\theta)})\\mathrm d\\theta\n$$\n\n对于矩形窗：\n\n$$\nW_R(e^{j\\omega}) = \\text{DTFT}(w_R[n]) = \\frac{\\sin(M\\omega / 2)}{\\sin(\\omega/2)} e^{-j\\frac{M - 1}{2}\\omega}\n$$\n\n频率分辨力的定义：两个等幅单频信号能够被区分开的最小频率间隔\n\n矩形窗的主瓣宽度为 $4\\pi/MT_s$\n\n实际工程中，采用 3dB带宽并加上适当余量作为频率分辨力\n\n* 矩形窗的数字角频率分辨力为 $\\Delta \\omega = 2\\pi / M$\n* 连续信号的分辨力为 $\\Delta f = f_s/M$\n\n分辨力仅决定于信号时长 $MT_s$。\n\n混叠效应\n\n混叠效应本质上由采样过程引起\n- 混叠效应带来的问题\n- 如果采样过程带来了混叠，DFT结果无法将已混叠的频\n率分量分开\n- 采样之前作抗混叠滤波，把带外频率成分滤除\n- 增大采样频率（减小采样周期）\n– 无法仅从DFT结果中判读原连续信号的模拟频率\n- 需要原连续信号频率分布或抗混叠滤波通带的先验\n知识\n\n栅栏效应\n* DFT 无法精确表示不在离散采样点的频率值\n* 频率估计的最大误差为 $\\pi / N$\n* 可以通过加窗补零（增大 $N$）的方法改善\n* 通过局部插值的方法获得更精确的频率估计：精确插值，线性插值，二次插值\n\n## DFT 的应用\n\n### 线性卷积的计算\n\n假设有限长因果序列 $h[n]$ 和 $x[n]$，长度分别为 $P$ 和 $L$，均扩展到 $N$ 个点进行卷积\n\n* 当 $N \\ge P + L - 1$ 时，两种卷积的结果相等\n* 当 $N \\lt P + L - 1$ 时，循环卷积出现混叠\n\n基于 DFT 的 FIR 滤波器实现\n\nFIR 滤波器需要计算有限长序列和无限长序列的线性卷积\n* $h[n]$ 有限\n* $x[n]$ 无限\n\n方法1：重叠相加法\n\n$$\nx[n] =\\sum\\limits_{r=0}^{\\infty}x_r[n - rL]\\\\\ny[n] = h[n] * \\sum\\limits_{r=0}^{\\infty}x_r[n - rL] = \\sum\\limits_{r=0}^{\\infty}h[n] * x_r[n - rL]\\\\\n$$\n\n整个序列的线性卷积等于各段线性卷积后的移位加和\n\nIDFT 后，需要一个专门的加法器进行重叠部分的相加运算\n\n方法二：重叠保留法\n\n取 $L$ 点 $x[n]$ 与扩展的 $P$ 点 $h[n]$ 做循环卷积，取结果的后 $L - P + 1$ 个点作为结果。\n\n两种方法、直接计算线性相关的计算量对比？\n\n### 线性调频 z 变换\n\nCZT 的定义\n\n$$\nX_{cz}(z)|_{z = z_k} =\\sum\\limits_{n=0}^{N - 1}x[n]z_k^{-n}\\\\\nz_k = AW^{-k} = (A_0e^{j\\theta_0})(W_0e^{-j\\varphi_0})^{-k}\n$$\n\n一种广义的 DFT，在复平面螺旋线上的采样。\n\nCZT 的计算\n* 利用定义直接计算\n* 利用卷积计算，而卷积可以利用 FFT 计算\n\n$$\nX_{cz}(z_k) = W^{\\frac{k^2}{2}}\\sum\\limits_{n=0}^{N - 1}f[n]h[k - n]\\\\\nf[n] = x[n]A^{-n}W^{\\frac{n^2}{2}}\\\\\nh[n] = W^{-\\frac{n^2}{2}}\n$$\n\n### 短时傅里叶变换\n\n问题：基于傅里叶的频谱分析可以指导信号观测窗内的频率成分，但是无法得知这些频率成分何时出现，何时消失，持续多久\n\n定义\n\n$$\n\\text{STFT}(t^\\prime, \\Omega) = \\int_{-\\infty}^{\\infty}x(\\tau)g^*(\\tau - t^\\prime)e^{-j\\Omega\\tau}\\mathrm d\\tau\n$$\n\n* 窗的长度\n  * 窗长需要足够短，确保落入窗的信号近似平稳\n  * 窗越长，频率分辨率越高，窗越短，时间分辨率越高\n    * 窗无限长，退化成 FT\n    * 无限短，退化成 $s(t^\\prime)e^{-j\\Omega t^\\prime}$\n* 窗的类型\n  * 矩形窗，汉明窗，布莱克曼窗\n  * 主瓣宽度与旁瓣电平之间的权衡\n\n不确定性原理\n\n$$\n\\Delta t \\cdot \\Delta \\Omega \\ge \\frac{1}{2}\n$$\n\n\n## LTI 系统\n\n### LTI 系统的时域分析——冲激响应\n\n根据冲激响应长度不同：\n* FIR:用 $h[n]$ 表示系统\n* IIR：用系统函数或者差分方程表示\n\n### LTI 系统的时域分析——冲激响应\n\n复指数序列是 LTI 系统的特征函数\n\n$$\nT \\lbrace e^{j\\omega n} \\rbrace = H(e^{j\\omega})e^{j\\omega n}\n$$\n\n频率响应函数的表示方式\n* $H(e^{j\\omega}) = H_R(e^{j\\omega}) + jH_I(e^{j\\omega})$\n* $H(e^{j\\omega}) = |H(e^{j\\omega})|e^{j\\angle H(e^{j\\omega})}$\n* 幅频特性：\n  * $|H(e^{j\\omega})|$\n  * $20\\log |H(e^{j\\omega})|$，单位 dB\n* 相频特性\n  * $arg(H(e^{j\\omega}))$：连续相位\n  * $Arg(H(e^{j\\omega}))$：主值相位\n  * 无卷绕相位：$\\angle H(e^{j\\omega}) = \\tan^{-1}\\frac{H_I(e^{j\\omega})}{H_R(e^{j\\omega})}$\n  * 定义主值区间 $arg(H(e^{j\\omega})) = ARG[H(e^{j\\omega})] + 2\\pi r(\\omega)$，$r(\\omega)$是补偿函数，仅取整数\n\n相位延迟\n\n群延迟\n\n$$\n-\\frac{\\mathrm d}{\\mathrm d\\omega}\\text{arg}[H_{id}(e^{j\\omega})]\n$$\n\n可以表征窄带信号的相位失真（或者延迟）\n\n$$\nx[n] = a[n]e^{j\\omega_c n}\\\\\na[n] = c_1e^{j\\omega_1n}\\\\\ny[n] \\approx |H(e^{j\\omega_c})|c_1e^{j(\\omega_1 + \\omega_c)n + j\\varphi(\\omega_1 + \\omega_c)} \\approx |H(e^{j\\omega_c})|\\underbrace{a[n - \\tau_g(\\omega_c)]}_{群延迟给出了包络延迟}\\underbrace{e^{j\\omega_c[n - \\tau_p(\\omega_c)]}}_{相位延迟\\tau_p(\\omega_c) = \\varphi(\\omega_c)}\n$$\n\n### LTI 系统的零极点分析\n\n$$\n\\sum\\limits_{k=0}^{N}a_ky[n - k] =\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH[z] = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{\\sum\\limits_{k=0}^{N}a_kz^{-k}} = \\left ( \\frac{b_0}{a_0} \\right)\\frac{\\prod_{k = 1}^M(1 - c_kz^{-1})}{\\prod_{k = 1}^N(1 - d_kz^{-1})}\n$$\n\n$z = 0, z = \\infty$ 也可能是零点！求解的时候不要忘了。\n\n系统稳定性的条件：绝对可和。或者说 $H(z)$ 的极点在单位圆内。\n\n可逆性的条件：$h[n] * h_i[n] = \\delta[n]$， $H(8z)H_i(z) = 1$\n* 逆系统的极点和零点就是原系统的零点和极点\n* 逆系统和原系统必须有重叠的 ROC，因此可以确定逆系统的 ROC\n\n频率响应\n\n\n群延迟\n\n$$\n\\text{grd}[] =\\sum\\limits_{k=1}^{N}\\frac{|d_k|^2 - \\Re{d_ke^{-j\\omega}}}{1 + |d_k|^2 - 2\\Re{d_ke^{-j\\omega}}} - \\sum\\limits_{k=1}^{M}\\frac{|c_k|^2 - \\Re{c_ke^{-j\\omega}}}{1 + |c_k|^2 - 2\\Re{c_ke^{-j\\omega}}}\n$$\n\n### IIR滤波器\n\n$$\ny[n] =\\sum\\limits_{k=1}^{N}a_ky[n - k] +\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH(z) = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{1 -\\sum\\limits_{k=1}^{N}a_kz^{-k}}\n$$\n\n直接 I 型\n\n直接 II 型：交换次序，合并延迟单元\n\n级联形式：\n\n$$\nH(z) = K \\prod_{k = 1}^{N_s} \\frac{b_{0k} + b_{1k}z^{-1} + b_{2k}z^{-2}}{1 - a_{1k}z^{-1} - a_{2k}z^{-2}}\n$$\n\n考虑到有限字长效应，级联形式可以以更加灵活的方式减小有限字长的影响。可以控制零点和极点的位置。\n\n级联形式也可以用直接 I, II 型实现。\n\n多径衰落就是一个 FIR 滤波器，因此具有频率选择特性。\n\n\n并联形式\n\n$$\nH(z) =\\sum\\limits_{k=0}^{N_p}C_kz^{-k} +\\sum\\limits_{k=1}^{N_2}\\frac{e_{0k}+e_{1k}z^{-1}}{1 - a_{1k} - a_{2k}z^{-2}}\n$$\n\n各子系统的计算误差互不影响，防止误差传递和放大，可控极点位置\n\n流图转置定理：支路方向取反，系数不变，输入和输出交换位置\n\n### FIR 滤波器\n\n$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n}\n$$\n\n抽头延迟线 or 横向滤波器结构\n\n具有转置形式\n\n级联形式\n\n$$\nH(z) = \\prod_{k = 1}^{M_1}(f_{0k} - f_{1k}z^{-1}\\prod_{k = 1}^{M_2}(b_{0k} + b_{1k} z^{-1} + b_{2k}z^{-2})\n$$\n\n线性相位特性\n\n$$\nH(e^{j\\omega}) = A(e^{j\\omega})e^{-j\\omega\\alpha}\n$$\n\n$$\nh[n] = h[M - n] (I, II)\\\\\nh[n] = - h[M - n] (III,IV)\n$$\n\n线性相位 FIR 滤波器的直接形式\n\n偶数\n\n$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] + x[n - M + k]) + h[M/2]x[n - M/2], &I type\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] - x[n - M + k]), &III type\n\\end{cases}\n$$\n\n奇数\n\n\n$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] + x[n - M + k]), &II type\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] - x[n - M + k]), &IV type\n\\end{cases}\n$$\n\n级联形式\n\n对应四种零点分布情况，有四种网络结构\n\n$$\nH(z) = 1 \\pm z^{-1}\\\\\nH(z) = 1 - 2\\cos(\\theta)z^{-1} + z^{-2}\\\\\nH(z) = (1 - rz^{-1})(1 - r^{-1}z^{-1})\\\\\nH(z) = 1 + bz^{-1} + cz^{-2} + bz^{-3} + z^{-4}\n$$\n\n### FIR 滤波器的频率取样结构\n\n$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n} = \\frac{1}{N}(1 - z^{-N})\\sum\\limits_{k=0}^{N - 1}\\frac{H(k)}{1 - W_N^{-j}z^{-1}}\n$$\n\n$H(k)$ 是 FFT 变换。\n\n若冲激响应是实序列，可以用共轭对称性将成对的一阶子系统合称为二阶子系统\n\n$$\nH_k(z) + H_{-k}(z) = 2|H(k)| \\frac{\\cos\\theta(k) - (\\cos(\\theta(k) - \\frac{2\\pi}{N}k))z^{-1}}{1 - 2\\cos(\\frac{2\\pi}{N}k)z^{-1} + z^{-2}}\n$$\n\n其中 $\\theta(k)$ 是 $H(k)$ 的相位\n\n不成对的子系统？\n\n$$\nH_0(z) = \\frac{H(0)}{1 - z^{-1}}\\\\\nH_{N/2}(z) = \\frac{H(0)}{1 + z^{-1}}\n$$\n\nFIR 滤波器的时分复用结构\n\n\n## 离散希尔伯特变换\n\n$$\nh[n] = \\begin{cases}\n    \\frac{1 - \\cos(n\\pi)}{n\\pi}, n \\ne 0\\\\\n    0, n = 0\n\\end{cases}\n$$\n\n## 典型数字信号处理系统及其误差源\n\n* 引起有限字长的误差源\n  * AD 变换引入的误差\n  * 有限精度引起的误差\n  * 限制乘法运算位数的误差\n  * 防止加法溢出压缩信号电平的误差\n\n### 量化误差的统计分析模型\n\n$$\nQ_B \\lbrace x[n] \\rbrace = x[n] + e[n]\\\\\n$$\n\n$e[n]$ 是各态历经的平稳随机序列，与 $x[n]$ 相互统计独立，具有白噪声的性质，不同时刻的取值相互独立，是均匀分布的。","source":"_posts/Digital-Signal-Processing.md","raw":"---\ntitle: Digital Signal Processing\ndate: 2023-09-20 09:51:58\ntags: note\nkatex: true\n---\n\n\n## 绪论\n\n### 信号\n\n信号是某种随时间或/和空间变化的物理量，其包含有从信源到信宿的某种信息。\n\n信号可以根据时间和幅度的取值方式分类\n- 连续时间信号\n- - 在时间和幅度上均可以连续取值的信号\n- 离散时间信号\n- - 仅在离散时间点上取值，但可在幅度上连续取值的\n信号\n- 数字信号\n- - 仅在离散时间点上取值，且在幅度上只能离散取值\n的信号\n\n### 系统\n\n- 由若干相互作用和相互依赖的事物组合而成的具有特\n定功能的整体\n- 具有它自身的结构、行为和性质，通过输入和输出与\n其所处的环境进行交互，通常实现一定的功能\n- 可通过分析给定输入下输出的性质，来研究其行为和\n性质\n\n信号处理系统\n- 对信号进行某种操作的单元或模块\n- 从数学上看，可视为作用于函数上的算子\n\n通常根据信号处理单元而非输入输出信号性质分类\n- 连续（模拟）信号处理系统\n- - 由电阻、电容、电感和放大器等组成的模拟电路完成信号处\n理功能\n- - 直接处理连续信号\n- 离散信号处理系统\n- - 由CCD、电容和放大器等组成的离散电路完成信号处理功能\n- - 处理由连续信号采样而来的离散时间信号\n- 数字信号处理系统\n- - 信号处理功能由数字逻辑电路或通用计算机来完成\n- - 处理数字信号（例如来源于对连续信号的采样和量化）\n\n模拟 -> 采样量化 -> 数字信号处理系统 -> 模拟重建 -> 模拟输出信号\n\n### 数字信号处理的局限\n- ADC和DAC器件的处理能力\n- - 是否能够准确提取出原连续信号中的信息首先决定于\nADC：采样率、量化位数、时钟抖动、线性度等\n- 精度受量化和舍入误差影响\n- - 有限字长效应：数字系统中数字表示和计算精度受字\n长限制\n- 适合于数字处理的信号带宽受处理能力的限制\n- - 例如，信号带宽10MHz、采样率20MHz、FIR滤波器阶\n数为500，则所需计算量为每秒10G次的乘累加\n- - 如果带宽为1GHz呢?\n\n### 数字信号处理的发展\n- 20世纪初至50年代有许多前期的研究工作，从采样\n定理的建立到声码器的数字仿真实验等，奠定了理论\n基础\n- 1965年FFT的提出，是DSP发展的里程碑 （但其源头\n可追溯到高斯时代）\n- 离散变换的进展：65年FFT，70年代余弦变换，80年\n代中后期小波变换\n- 滤波器设计技术：IIR、FIR数字滤波器，多采样处理\n和滤波器组理论，专用滤波器设计，小波滤波\n- 统计和自适应信号处理，阵列处理等，从统计学引入\n信号处理发展的另一条主线——现代信号处理\n- 器件和系统的发展对数字信号处理有积极推动\n\n### 从模拟到数字\n\n模拟信号的数字化：ADC\n\n采样：本课程主要考虑均匀采样。\n\n$$\nx[n] = x_a(nT) -\\infty \\lt n \\lt \\infty\\\\ \nf_s = 1/T\\\\\n\\Omega_s = 2\\pi f_s\n$$\n\n采样的实现：采样保持电路\n\n采样周期：与被采样信号的频带参数一起决定了采样过程是否会发生混叠。\n\n采样过程的模糊性：采样过程可看作一种由连续信号空间到离散信号空间的多对一映射；对于给定的采样周期，仍存在无穷多个连续信号与同一离散信号对应。需要施加某种约束条件。\n\n 采样过程的基本问题：\n- 采样过程是否会引起被采样信号的信息丢失？\n- 被采样的连续信号是否能从采样样本中完全恢复？\n- 采样过程的频域分析可获得上述问题的答案\n- - 推导得到采样后离散信号和采样前连续信号频谱间的数学关系\n- - 确定可以消除采样过程模糊性的条件\n- - 为实际数字信号处理系统设计中采样频率的选择、抗混叠前置滤波器的设计提供指导\n\n采样的数学表示：\n\n$$\ns(t) = \\sum_{n = -\\infty}^{\\infty}\\delta(t - nT)\\\\\nx_s(t) = x_a(t) \\cdot s(t)\\\\\nx[n] = x_a(nT)\n$$\n\n对连续信号进行采样，其频谱是原始信号的周期延拓，延拓周期为采样频率\n\n$$\n\\begin{align*}\n\\text{时域} & \\quad \\quad \\text{频域} \\\\\nx_a(t) & \\quad \\quad X_a(j\\Omega)\\\\\ns(t) & \\quad \\quad S(j\\Omega) = \\frac{2\\pi}{T} \\sum_{k=-\\infty}^{+\\infty} \\delta(\\Omega - k\\Omega_s)\\\\\nx_a(t) \\cdot s(t) & \\quad \\quad X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a\\bigg(j(\\Omega - k\\Omega_s)\\bigg)\n\\end{align*}\n$$\n\n带限信号和带通信号：\n* 带限信号：$X_a(j\\Omega) = 0, |\\Omega| \\ge \\Omega_H$\n* 带通信号：$X_a(j\\Omega) = 0, |\\Omega| \\ge \\Omega_H\\text{ or }|\\Omega| \\le \\Omega_L$\n\n带限信号的采样：\n\n<!-- int, sum, frac partial -->\n\n$$\nX_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)], \\Omega_s \\ge 2\\Omega_H\n$$\n\n对应的离散时间序列：\n\n$$\nX(e^{j\\Omega T}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)]\\\\\n\\Rightarrow X(e^{j\\omega}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\omega - 2\\pi k)/T]\\\\\n$$\n\n带通采样让时间以$T \\rightarrow 1$的形式进行归一化，频率以$\\Omega_s \\rightarrow 2\\pi$的形式进行归一化。\n\nNyquist 采样定理：\n\n$$\nX_a(j\\Omega) = 0, \\forall |\\Omega| \\ge \\Omega_H\\\\\n\\Omega_s = 2\\pi / T \\gt 2\\Omega_H\n$$\n\n或者归一化频率\n\n$$\n\\omega_H = \\Omega_H T < \\pi\n$$\n\nRemark：\n- $𝑥_𝑎(𝑡)$ 是基带、带限信号\n- Nyquist是充分条件，即对被采样信号无其他假设\n- 在仅知道连续信号最高频率时，Nyquist采样定理给出\n了由采样信号唯一确定（或恢复）原信号的条件\n- - 已知连续信号最高频率，可用于确定最低采样频率\n- - 已知采样频率，可确定无混叠连续信号的最高频率\n\n带通信号的采样：\n\n$$\n\\frac{2f_H}{m+1} \\le f_s \\le \\frac{2f_L}{m}, m\\in \\N ,m \\le f_L/B\n$$\n\n带限连续信号的重建：\n- 由离散序列𝑥[𝑛]和采样周期𝑇，恢复原连续信号$𝑥_𝑟(𝑡)$\n- 由序列到冲激串转换和重建滤波两个步骤构成\n- 重建后的信号表示为\n\n$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]h_r(t - nT)\n$$\n\n如选择截止频率$\\Omega_c = \\pi/T$的理想低通滤波器：\n\n$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]\\frac{\\sin[\\pi(t - nT)/T]}{\\pi(t - nT)/T}\n$$\n理想低通滤波器通过对冲激串信号的内插重建了原来的连续信号\n\n**Summary**\n\n原信号：\n\n$$\nx_c(t) \\leftrightarrow X_c(j\\Omega)\n$$\n\n采样后的信号：\n\n$$\n\\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) = \\sum\\limits_{n=-\\infty}^{\\infty}x_c(t)\\delta(t - nT_s) \\leftrightarrow \\frac{1}{T_s}X(e^{j\\Omega T_s}) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}X_c(j(\\Omega - n\\Omega_s))\n$$\n\n数字域：\n\n$$\nx[n] \\leftrightarrow X(e^{j\\omega}) = \\frac{1}{T_s} X_c(j\\omega /T_s)\n$$\n\n恢复信号：\n$$\nh_r(t) \\leftrightarrow H_r(j\\Omega) = \\begin{cases}\n    T_s, &|\\Omega| \\le \\pi / T_s, \\\\\n    0,   &|\\Omega| \\gt \\pi / T_s\n\\end{cases}\\\\\n\\begin{align*}\n    x_r(t)  &= \\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) * h_r(t)\\\\\n            &= \\sum\\limits_{n=-\\infty}^{\\infty} x_c(nT_s)h_r(t - nT_s)\\\\\n            &= x_c(t)\n\\end{align*}\\ \\leftrightarrow\\ \\begin{align*}\n    X_r(j\\Omega) &= T_s X(e^{j\\Omega T_s})H_r(j\\Omega)\\\\\n    &= X_c(j\\Omega)\n\\end{align*}\n$$\n\n数字时域和模拟时域之间的关系：\n$$\nn = \\frac{t}{T_s} = tf_s\n$$\n\n数字频域和模拟频域之间的关系：\n$$\n\\omega = \\Omega T_s = \\frac{2\\pi f}{f_s}\n$$\n\n## 信号的表示\n\n### 离散信号的时域表示\n* 时域表示方法\n    * 数学表达式：可表示基本信号，但大多数实际信号无解析表达式\n    * 图形表示：直观、易理解，但不适用于刻画复杂信号\n    * 数据表示：离散信号最一般的表示方法\n\n### 离散信号的变换域表示\n* 定义：假设离散时间信号为𝑥[𝑛] ，定义映射𝑇{·}，那么信号的变换域表示可以写作𝑋 = 𝑇{𝑥[𝑛]}\n    * 𝑇{·}是从函数空间到函数空间的映射\n    * 𝑋并不要求一定定义在整数域上\n* 常用情形：级数表示\n    * 将信号分解成有限项或无穷多项基本信号加权和的形式，由和式中每个基本信号的加权值组成的序列形成了原信号的变换域表示\n    * 傅里叶级数展开 $x[n] = \\sum_k a_k e^{j2\\pi kn /T}$\n\n### 离散信号的正交函数表示\n\n- 使用信号空间的完备正交基来表示离散信号，\n$$\n\\lbrace\\ldots ,\\varphi_0[n] ,\\varphi_1[n] ,\\varphi_2[n] , \\ldots\\rbrace\n$$\n- 正交性：\n$$\n\\sum_{n} \\varphi_k^*[n] \\varphi_l[n] = \\delta_{kl}\n$$\n其中，$k \\neq l$。\n* 完备性\n    * 任何一个信号都可由这组基函数通过线性叠加而构成\n* 加权系数的计算\n    * 对基函数的投影：\n\n$$\nc_k = \\frac{\\langle x[n], \\phi_k[n]\\rangle}{||\\phi_k[n]||^2}\n$$\n\nDFT 的定义如下：\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n]e^{-j2\\pi kn/N}\n$$\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\nDCT 的定义如下：\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n]\\cos\\left(\\frac{\\pi}{N}(n + 0.5)k\\right)\n$$\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\n### 离散信号的特征域（量）表示\n* 特征量表示指由信号的时域或频域表示来计算用\n于表征信号的特征量\n    * 例如能量、功率、均值、相关函数、功率谱\n    * 特征量表示通常是单向性的，由特征量表示一般不能完整地恢复原信号的所有取值\n    * 实践中，经常用特征量来表示随机信号\n\n### 离散信号的单位抽样信号表示：\n单位抽样信号的移位作为基信号：\n$$\n\\varphi_k[n] = \\delta[n - k], \\quad k \\in (-\\infty, \\ldots, -1, 0, 1, \\ldots, \\infty)\n$$\n\n• 正交性验证：\n$$\n\\langle\\varphi_k[n],\\varphi_l[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} \\delta[n - k] \\delta[n - l] = \\delta[k - l]\n$$\n\n• 系数计算：\n$$\nc_k = \\frac{\\langle x[n],\\varphi_k[n]\\rangle}{\\varphi_k[n]^2} = x[k]\n$$\n\n• 离散信号的单位抽样表示为：\n$$\nx[n] = \\sum_{k=-\\infty}^{\\infty} c_k\\varphi_k[n] = \\sum_{k=-\\infty}^{\\infty} x[k] \\delta[n - k]\n$$\n\n离散信号的复指数信号表示如下：\n\n• 复指数信号作为基信号：\n$$\n\\varphi_\\omega[n] = e^{j\\omega n}, \\quad 0 \\leq \\omega < 2\\pi\n$$\n\n• 正交性验证：\n$$\n\\langle\\varphi_{\\omega_1}[n],\\varphi_{\\omega_2}[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} e^{j\\omega_1 n} e^{-j\\omega_2 n} = \\begin{cases} \n0, & \\omega_1 \\neq \\omega_2 \\\\\n\\infty, & \\omega_1 = \\omega_2 \n\\end{cases}\n$$\n\n• 系数计算：\n$$\nX(e^{j\\omega}) = \\langle x[n], e^{j\\omega n} \\rangle = x[n] e^{-j\\omega n}\n$$\n\n• 离散信号的复指数信号表示为：\n$$\nx[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(e^{j\\omega}) e^{j\\omega n} d\\omega\n$$\n\n### 有限长离散信号的正交函数表示\n\n• 对于长度为$N$的有限长离散序列，选择以下$N$个序列作为基信号：\n$$\n\\varphi_k[n] = e^{j\\frac{2\\pi}{N}kn}R_N[n], \\quad k = 0,1,2,\\ldots,N-1\n$$\n\n• 正交性验证：\n$$\n\\langle \\varphi_k[n],\\varphi_l[n] \\rangle = \\sum_{n=0}^{N-1} e^{j\\frac{2\\pi}{N}(k-l)n} = \\begin{cases} \nN, & k = l \\\\\n0, & k \\neq l \n\\end{cases}\n$$\n\n• 系数计算：\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n] e^{-j\\frac{2\\pi}{N}kn}, \\quad k = 0,1,2,\\ldots,N-1\n$$\n\n• 有限长离散序列可以表示为：\n$$\nx[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} X[k] e^{j\\frac{2\\pi}{N}kn}, \\quad n = 0,1,2,\\ldots,N-1\n$$\n\n* 离散信号的因果性:\n    * 𝑥[𝑛] = 0，for 𝑛 < 0\n\n因果连续信号抽样后一定是因果离散信号。\n\n* 离散信号的对称性：\n\n• 共轭对称性：\n  - 正对称：$x[n] = x^*[-n]$\n  - 反对称：$x[n] = -x^*[-n]$\n\n• 任意信号都可以表示为奇分量和偶分量的和：\n  $x[n] = x_o[n] + x_e[n]$\n  其中，$x_o[n] = \\frac{1}{2}(x[n] - x^*[-n])$为奇分量，$x_e[n] = \\frac{1}{2}(x[n] + x^*[-n])$为偶分量。\n\n• 若信号具有实因果性，可以通过奇分量或偶分量来恢复原信号：\n\n$$\nx[n] = \\begin{cases}\n0, & n < 0 \\\\\nx_e[n], & n = 0 \\\\\n2x_e[n], & n > 0\n\\end{cases}\n$$\n\n* 离散信号的周期性：\n    * $𝑥[n] = 𝑥[𝑛 + N]$\n\n周期连续信号均匀采样后**不**一定是周期离散信号。\n\n$$\n\\omega_0 = \\Omega_0T = 2\\pi\\frac{T}{T_0}\n$$\n\n离散余弦信号的数字角频率 $\\omega_0$ 由采样周期和连续信号周期的比值决定。该比值决定了采样后的信号是否具有周期性。\n\n\n### 离散系统的表示\n\n离散系统的表示可以使用以下公式来描述：\n\n$$y[n] = \\sum_{k=-\\infty}^{\\infty} h[k]x[n-k]$$\n\n其中，$y[n]$表示系统的输出，$x[n]$表示系统的输入，$h[k]$表示系统的单位冲激响应。这个公式是卷积的离散形式，也称为离散卷积。\n\n对于因果性，一个离散系统被称为因果性系统，如果它对任何$n < 0$的输入信号$x[n]$都产生$y[n] = 0$的输出。这意味着输出只依赖于当前和过去的输入。\n\n对于稳定性，一个离散系统被称为稳定系统，如果对于有界的输入信号$x[n]$，输出$y[n]$仍然是有界的。\n\nLTI（线性时不变）系统是指具有线性性质和时不变性质的系统。线性性质意味着系统满足叠加原理，即对于输入信号$x_1[n]$和$x_2[n]$，系统的输出满足$y_1[n] + y_2[n]$。时不变性质意味着系统的单位冲激响应$h[k]$与输入信号$x[n]$的延迟无关。\n\n单位冲激响应是指当输入信号为单位冲激函数$\\delta[n]$时，系统的输出。单位冲激响应通常用$h[n]$表示。\n\nLTI系统可完全由单位冲激响应来表征。\n\n因果性判据：单位冲激响应是一个因果信号。\n稳定性判据：$S = \\sum_{k = -\\infty}^\\infty |h[k]| \\lt +\\infty$\n\n**特征函数与特征值**\n\n$$\nT\\lbrace s[n]\\rbrace = \\lambda s[n]\n$$\n\n**LTI系统的特征函数与特征值**\n\n$$\nT\\lbrace e^{j\\omega n}\\rbrace =\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{j\\omega (n - k)} = \\underbrace{e^{j\\omega n}}_{特征函数}\\cdot\\underbrace{\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{-j\\omega k}}_{特征值}\n$$\n\n$y[n]$ 可看作 $x[n]$ 经过特征信号分解、加权、求和的结果：\n\n$$\ny[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^\\pi H(e^{j\\omega})X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$\n\n* 频率响应函数：单位冲激响应的DTFT\n\n$$\nH(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]e^{-j\\omega n}\n$$\n\n* 系统函数\n\n$$\nH(z) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]z^{-n}\n$$\n\n* 系统差分方程\n\n$$\n\\sum\\limits_{k=0}^{N} a_ky[n - k] =\\sum\\limits_{k=0}^{M} b_kx[n - k]\n$$\n\n* 系统状态空间\n\n$$\n\\lambda[n + 1] = A\\lambda[n] + Bx[n]\\\\\ny[n] = C\\lambda[n] + Dx[n]\n$$\n\n## DTFT 与 DFT\n\n### DTFT\n\n$$\n\\begin{cases}\n    X(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\omega n}\\\\\n    x[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi}X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n\\end{cases}\n$$\n\n与连续频谱的关系：\n\n$$\nX(e^{j\\omega}) = \\frac{1}{T}\\sum\\limits_{k=-\\infty}^{\\infty}X_a\\left[j\\left(\\frac{\\omega}{T} - k\\frac{2\\pi}{T}\\right)\\right]\\\\\n\\omega = \\Omega T\n$$\n\n基本性质：\n\n* 周期性\n\n$$\nX(e^{j\\omega}) = X(e^{j\\omega + 2k\\pi}), k\\in \\Z\n$$\n\n* 线性\n\n$$\nax[n] + by[n] \\lrarr aX(e^{j\\omega}) + bY(e^{j\\omega})\n$$\n\n* 频域求导\n\n$$\nnx[n] \\lrarr j\\frac{\\mathrm dX(e^{j\\omega})}{\\mathrm d\\omega}\n$$\n\n* Parseval 定理：\n\n$$\n\\sum\\limits_{n=-\\infty}^{\\infty}||x[n]||^2 = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}||X(e^{j\\omega})||^2\\mathrm d\\omega\n$$\n\n* 序列的调制\n\n$$\nx[n]e^{j\\omega_0 n} \\lrarr X(e^{j(\\omega - \\omega_0)})\n$$\n\n实现数字变频：\n\n$$\nx_B[n] = x[n]e^{-j\\frac{\\pi}{2}n}\n$$\n\n* 序列的平移\n\n$$\nx[n - n_0] \\lrarr e^{-j\\omega n_0}X(e^{j\\omega})\n$$\n\n* 共轭对称性\n\n$$\nx_e[n] \\lrarr \\text{Re}\\lbrace X(e^{j\\omega}) \\rbrace\n$$\n\n$$\nx_o[n] \\lrarr \\text{Im}\\lbrace X(e^{j\\omega}) \\rbrace\n$$\n\n下面是修正后的表格：\n\n| 序列 $x[n]$   | DTFT $X(e^{j\\omega})$ |\n|:------------:|:------------------:|\n| $x[n]$       | $X(e^{j\\omega})$   |\n| $x^*[n]$     | $X^*(e^{-j\\omega})$ |\n| $x^*[-n]$    | $X^*(e^{j\\omega})$  |\n| $x_R[n]$     | $X_e(e^{j\\omega})$  |\n| $jx_I[n]$    | $X_o(e^{j\\omega})$  |\n| $x_e[n]$     | $X_R(e^{j\\omega})$  |\n| $x_o[n]$     | $jX_I(e^{j\\omega})$ |\n| 以下为实信号| | \n| $x[n] = x^*[n]$        | ，$X(e^{j\\omega}) = X^*(e^{-j\\omega})$ |\n| $x_e[n] = \\frac{1}{2}(x[n] + x[-n])$    | $X_R(e^{j\\omega})$ 实、偶函数|\n|$x_o[n] = \\frac{1}{2}(x[n] - x[-n])$| $jX_I(e^{j\\omega})$  虚、奇函数    |\n\n* 卷积与相关性质\n    * 时域卷积： $x[n] * y[n] \\lrarr X(e^{j\\omega})\\cdot Y(e^{j\\omega})$\n    * 频域卷积：$x[n] \\cdot y[n] \\lrarr \\frac{1}{2\\pi}X(e^{j\\omega}) * Y(e^{j\\omega})$\n    * 时域相关：\n        * 互相关：$r_{xy}[k] =\\sum\\limits_{k=-\\infty}^{\\infty}x[n]y^*[n - k]$\n        * 自相关：$r_{xx}[k] =\\sum\\limits_{k=-\\infty}^{\\infty}x[n]x^*[n - k]$\n        * $R_{xy}(e^{j\\omega}) = X(e^{j\\omega}) \\cdot Y^*(e^{j\\omega})$\n        * $R_{xx}(e^{j\\omega}) = X(e^{j\\omega}) \\cdot X^*(e^{j\\omega})$\n\n**DTFT的存在条件：**\n\n取决于 $\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\omega n}$ 的收敛性\n\n有限和序列 $X_N(e^{j\\omega}) =\\sum\\limits_{n=-N}^{N}x[n]e^{-j\\omega n}$\n\n* 若 $x[n]$ 绝对可和，则 DTFT 存在，且一致收敛\n* 若序列满足平方可和，则 DTFT 满足均方收敛性\n    * 截断误差的能量趋于0，但是某些点的误差的绝对值不一定趋于0（例如理想低通滤波器，有吉布斯现象，在截止频率附近存在一个独立于 $N$ 的震荡，即使 $N$ 趋于无穷，在某些频率点上还是存在9%左右的误差）\n\n**特殊信号的 DTFT**\n\n* 符号序列\n\n$$\n\\text{sgn}[n] = \\begin{cases}\n    1, &n\\gt 0,\\\\\n    0, &n = 0\\\\\n    -1, &n \\lt 0\n\\end{cases} \\lrarr \\text{SGN}(e^{j\\omega}) = \\frac{1}{j} \\cot \\left(\\frac{\\omega}{2}\\right)\n$$\n\n* 阶跃序列\n\n$$\nu[n] = \\frac{1}{2}(\\text{sgn}[n] + 1) + \\frac{1}{2} \\delta[n] \\lrarr U(e^{j\\omega}) = \\frac{1}{1 - e^{-j\\omega} + \\pi} + \\pi\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - 2\\pi k)\n$$\n\n* 离散周期单位冲激串\n\n$$\nx[n] =\\sum\\limits_{k=-\\infty}^{\\infty}\\delta[n - kN]\\lrarr X(e^{j\\omega}) =\\sum\\limits_{k=-\\infty}^{\\infty}e^{-j\\omega k N} = \\frac{2\\pi}{N}\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - \\frac{2k\\pi}{N})\n$$\n\n离散时限信号与周期单位冲激串的卷积，在频域上表现为对 DTFT 的采样，这正是从 DTFT 到 DFT 的过渡。\n\n### DFT\n\nDTFT给出了离散信号频域的全部信息，但在实际应用中存在如下困难：\n* 实际信号往往没有解析表达式，无法计算其DTFT\n* 实际物理装置只能采集有限长度的数据\n* DTFT给出的频谱是连续的，无法用数字设备记录和存储全部的值\n\n#### DFT 的定义\n\n$$\n\\begin{cases}\n    X[k] =\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n    x[n] =\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{-nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n\\end{cases}\n$$\n\n其中，\n$$\nW_N = e^{-j\\frac{2\\pi}{N}}\n$$\n\n#### 理解 DFT\n\nDFT 是 DTFT 的频域采样\n\n$$\nX(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{j\\omega n}\\\\\nX[k] = X(e^{j\\omega})\\big |_{\\omega_k = \\frac{2\\pi}{N}k} =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\frac{2\\pi}{N}kn}\n$$\n\n* 频域乘积等价于时域卷积，因此对离散序列在频域上以2𝜋/𝑁为周期进行采样，等效于离散信号在时域上进行周期延拓，延拓周期为𝑁\n\n* 为保证离散序列频域采样对应的时域序列不发生混叠，要求原离散序列为有限长且长度不超过𝑁。\n\n#### DFT 的频域重构\n\n* 首先需要 $N \\ge L$\n\n$$\n\\begin{align*}\n    X(e^{j\\omega}) &=\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\omega n} =\\sum\\limits_{n=0}^{N - 1}\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}X[k]e^{j\\frac{2k\\pi}{N}n}\\bigg]e^{-j\\omega n}\\\\\n    &=\\sum\\limits_{k=0}^{N - 1}X[k]\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}e^{-j(\\omega - \\frac{2k\\pi}{N}n)}\\bigg]\\\\\n    &=\\sum\\limits_{k=0}^{N - 1} X[k]P\\bigg(\\omega - \\frac{2k\\pi}{N}\\bigg)\n\\end{align*}\n$$\n\n其中，内插函数\n\n$$\nP(\\omega) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1} e^{-j\\omega n} = \\frac{1}{N}\\frac{\\sin (\\omega N / 2)}{\\sin (\\omega / 2)}e^{-j \\frac{N - 1}{2}\\omega}\n$$\n\n#### 理解 DFT II\n\n离散正交变换的定义：\n\n* 定义变换矩阵 $A$， 若 $A$ 满足 $A^HA = cI$，其中$c$为常数，则称 $X = Ax$ 为离散正交变换。若 $c = 1$，则称变换是归一化的。\n* 归一化的离散正交变换满足 Parseval 定理：$||X||^2 = X^HX = x^HA^HAx = x^Hx = ||x||^2$\n\nDFT 是对离散时间信号的加权求和，其向量形式\n\n* $X[k] = w_k^Hx$, $w_k = [e^{j\\frac{2\\pi0k}{N}}, e^{j\\frac{2\\pi1k}{N}}, \\dots, e^{j\\frac{2\\pi(N - 1)k}{N}}]^T$\n* $X = [X[0], X[1], \\dots, X[N - 1]]^T$，则有$X = [w_0, w_1, \\dots, w_{N - 1}]^Hx = W_Nx$\n\n$$\nX = W_Nx\\\\\nx = \\frac{1}{N} W_N^HX\n$$\n\n#### DFT 的周期延拓\n\n• DFT本意是用有限个离散频域样本来表示有限长离散序列\n\n– 时域采样对应着频域周期延拓，频域采样对应着时域周期延拓\n\n• 由于周期延拓，DFT总是面对着周期序列\n\n– 在DFT计算和应用中，总是选择时域和频域的主值区间\n\n– DFT这种隐含的周期性决定了其与DTFT具有不同的性质\n\n**周期延拓的数学表示**\n\n$$\n\\big((n)\\big)_N\n$$\n\n周期延拓可以表示为：\n\n$$\n\\tilde X[k] = X\\bigg[\\big((k)\\big)_N\\bigg]\n\\tilde x[n] = X\\bigg[\\big((n)\\big)_N\\bigg]\n$$\n\n也可表示为卷积和：\n\n$$\n\\tilde{X}[k] = X[k] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[k - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}X[k - mN]\\\\\\tilde{x}[n] = x[n] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[n - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}x[n - mN]\n$$\n\n#### DFT 性质\n\n* 线性性\n    * 前提：变换长度 $N$ 相同\n    * 如果不相同，补零到长度 $N \\ge \\max(N_1, N_2)$\n* 反转性质：若时域循环反转，则频域循环反转\n    * $\\text{DFT} \\Bigg\\lbrace x\\big[\\big((-n)\\big)_N\\bigg] R_N[n]\\Bigg\\rbrace = X\\bigg[\\big((-k)\\big)_N\\bigg] R_N[k]$\n    * 0 时刻不变，其余前后反转\n* 共轭性质：若时域共轭，则频域共轭且循环反转\n    * $\\text{DFT}\\lbrace x^*[n]\\rbrace = X^*[N - k]$\n* 对偶性质：序列的DFT的DFT\n    * $\\text{DFT}\\lbrace X[n]\\rbrace = NX^*[N - k]$\n* 周期序列的共轭对称性：\n    * 共轭对称：$x_{ep}[n] = x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$\n    * 共轭反对称：$x_{ep}[n] = -x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$\n    * 任意有限长序列的周期延拓总可以分解为周期共轭对称和反对称的分量和的形式\n        * $x[n] = x_{ep}[n] + x_{op}[n]$\n        * $x_{ep}[n] = \\frac12 (x[n] + x^*\\bigg[\\big((-n)\\big)_N\\bigg])$\n        * $x_{op}[n] = \\frac12 (x[n] - x^*\\bigg[\\big((-n)\\big)_N\\bigg])$\n    * 实序列的DFT是周期共轭对称序列\n    * 虚序列的DFT是周期共轭反对称序列\n    * 周期共轭对称序列的DFT是实的\n    * 周期共轭反对称序列的DFT是虚的\n* 循环卷积性质：\n    * 有限长循环移位的 DFT 可以由原序列 DFT 乘上一个线性的相位因子得到：$\\text{DFT}\\Bigg \\lbrace\\bigg[x\\big((n - m)\\big)_N\\bigg]\\Bigg \\rbrace = X[k]e^{-j\\frac{2\\pi k}{N}m}$\n    * 在 DTFT 中：$x[n] * y[n] = \\text{IDTFT}\\lbrace X(e^{j\\omega}) \\cdot Y(e^{j\\omega})\\rbrace$\n    * DFT 中：$x[n] \\circledast y[n] =\\sum\\limits_{m=0}^{N - 1}x[m]y\\bigg[\\big((n - m)\\big)_N\\bigg] =\\sum\\limits_{m=0}^{N - 1}x\\bigg[\\big((n - m)\\big)_N\\bigg]y[m]$\n* Parseval 定理：\n    * $\\sum\\limits_{n=0}^{N - 1}|x[n]|^2 = \\frac{1}{N}\\sum\\limits_{k=0}^{N - 1}|X[k]|^2$\n\n## FFT\n\nFFT 算法是一大类 DFT 快速算法的总称。\n* 基 2 FFT 算法：$N = 2^m$\n* 基 4 FFT 算法：$N = 4^m$\n* 分裂基算法：基本蝶形是倒 L 型，$N = 2^m$\n* 组合数 FFT 算法：变换点数为组合数，即$N = N_1N_2$\n\n根据处理基本蝶形的结构特点，可以分为：\n* DIT (Decimation-In-Time)\n* DIF (Decimation-In-Frequency)\n\n### 基 2 DIT-FFT 算法\n\n按照奇偶时间拆分成两个短序列。\n\n长序列的 DFT 可以由两个短序列的 DFT 组合得到。\n\n$$\nX[k] = \\sum\\limits_{m=0}^{N/2 - 1}x[2m]W_N^{2mk} + \\sum\\limits_{m=0}^{N/2 - 1} x[2m + 1]W_N^{(2m + 1)k}\\\\\nf_1[n] = x[2n], f_2[n] = x[2n + 1]\\\\\nX[k] = F_1[k] + W_N^kF_2[k]\\\\\nX[k + N/2] = F_1[k] - W_N^kF_2[k]\n$$\n\n反复抽取，变成2点 DFT：\n\n$$\n\\begin{bmatrix}\n    X[0]\\\\\n    X[1]\n\\end{bmatrix} = \\begin{bmatrix}\n    x[0] + x[1]\\\\\n    x[0] - x[1]\n\\end{bmatrix}\n$$\n\n![alt](../images/DSP/4_2.jpg)\n\n计算复杂度：\n* 乘法次数为$\\frac{N}{2}\\log_2N$，$m_a = Nm = N\\log_2 N$\n\n输入和输出序列的顺序关系：二进制下的倒序关系。\n* 每次均分时，输入序列按照奇偶性划分，输出序列按照是否过半划分\n* 输入序列的奇偶性等价于最低位为1还是0，输出序列是否过半等价于最高位为1还是0\n* 因此输入映射到输出序列是低位映射到高位的关系。\n\n## 数字频谱分析\n\n### DFT 谱分析的基本概念\n\n频谱：信号经过傅里叶变换转换到频域后，其频域表示的幅度和相位随频率变化的关系分别称为信号的幅度谱和相位谱\n\n基于 DFT 的数字频谱分析\n\n\n利用离散信号 DFT 结果 $X[k]$ 与原连续信号频谱 $X_a(j\\Omega)$ 之间存在对应关系来获得连续信号的频谱。\n\n$$\nX[k] = X(e^{j\\omega})|_{\\omega = \\frac{2\\pi}{N}k}\n$$\n\n$$\nX(e^{j\\omega}) = \\frac{1}{T_s}X_a(j\\Omega)|_{\\Omega = \\frac{\\omega}{T_s}}\n$$\n\n$$\n X_a(j\\Omega_k)= T_s X[k]\n$$\n\n利用 DFT 结果获得连续信号的频谱：\n\n$$\nX_a(j\\Omega_k) = X_a \\left ( j\\frac{2\\pi k}{NT_s} \\right) = \\begin{cases}\n    T_sX[k], 0 \\le k \\le \\lceil \\frac{N}{2} \\rceil, \\\\\n    T_sX[k + N], - \\lceil \\frac{N - 1}{2} \\rceil\\le k \\lt 0\n\\end{cases}\n$$\n\n基于DFT的频谱分析方法存在的问题\n\n- 理论上连续正弦信号的频谱应为冲激函数，但DFT结果为有限值\n- DFT结果在连续正弦信号频谱幅度为0的位置却不为零\n\n### DFT 谱分析的一般过程\n\n#### 抗混叠滤波\n\n![alt](../images/DSP/5_1.jpg)\n\n#### 采样\n\n提高采样率\n- 优点：能够无混叠分析的信号带宽增大\n- 缺点：数据率提高，系统复杂度增加，成本上升\n\n#### 加窗\n\n由于DFT只能处理有限长序列，需要对输入信号\n通过加窗进行截断\n- 窗长可根据频率分辨率、实时性和设备存储能力的要\n求来权衡\n- 窗函数的形式也可根据主瓣宽度和旁瓣电平进行选择\n\n$$\nw_R[n] = \\begin{cases}\n    1, 0 \\le n \\lt M\\\\\n    0, \\text{others}\n\\end{cases}\n$$\n\n$$\nx_w[n] = x[n]w_R[n]\n$$\n\n#### DFT计算、插值及频谱输出\n\nDFT计算\n- 可能需要补零，以获得更密集的频域采样，以及使变换点数𝑁满足FFT算法的要求（基2-FFT、基4-FFT）\n\n插值\n- 由DFT结果获得DTFT的估计值\n- 插值方法：\n  - 精确插值： $X(e^{j\\omega}) =\\sum\\limits_{k=0}^{N - 1} X[k] P \\left ( \\omega - \\frac{2\\pi k}{N} \\right)$, $P(\\omega) = \\frac{\\sin(\\omega N/2)}{\\sin(\\omega/2)}e^{-j\\frac{N-1}{2}\\omega}$\n  - 近似插值：线性插值，二次插值\n\n连续信号频谱输出\n– 通过坐标变换得到连续信号频谱 $X_a(j\\Omega) = T_sX(e^{j\\Omega T_s})$\n\n### DFT 谱分析问题\n\n#### 谱分析滤波器\n\n$$\ns(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega t}\\mathrm d\\Omega\\\\\ns(nT_s) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega nT_s}\\mathrm d\\Omega\\\\\nx[n] = \\begin{cases}\n    s(nT_s), n = 0, 1, \\dots, M - 1,\\\\\n    0, M, M + 1, \\dots, N - 1\n\\end{cases}\\\\\nX[k] =\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\frac{2\\pi nk}{N}} = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n}\\mathrm d\\Omega\n$$\n\n令 $\\theta = T_s(\\Omega - \\Omega_k)$，\n\n$$\n\\varphi_k(M, \\theta) = \\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n} = \\frac{\\sin(M\\theta / 2)}{\\sin(\\theta/2)} e^{j\\frac{M - 1}{2}\\theta}\n$$\n\n梳状滤波特性\n\n![alt](../images/DSP/5_2.jpg)\n\n周期内存在多个过零点，把滤波器响应分割成多个区间\n* 主瓣：谱分析滤波器频率响应最大的那个区间\n* 主峰：主瓣中最大频率响应点 $Ω = \\frac{2\\pi k}{NT_s}$处，高度为𝑀\n* 主瓣宽度：主瓣两边过零点之间的距离4𝜋⁄𝑀𝑇𝑠\n* 旁瓣：除响应最大的那个区间外的其它区间\n\nDFT频谱分析方法能否反映连续信号的频谱？\n- DFT的结果主要给出了连续信号落在相应谱分析滤波器主瓣内的那部分信号的频域信息\n- 由于相邻谱分析滤波器主瓣间有交叠，同一个信号可能会在相邻两个谱分析滤波器都有响应\n- 谱分析滤波器的旁瓣会在其他谱分析滤波器的主瓣位置出现，其对应的DFT结果不可避免的包含了其他滤波器主瓣位置处的信号成分\n\nDFT 可用于连续信号的频谱分析，但由于其谱分析滤波器频率分割不理想的本质，必须对其输出结果进行小心的解释\n\nDFT谱估计得到的是对加窗后序列DTFT的采样\n\n$$\nx_w[n] = x[n]w_R[n]\\\\\nX_w(e^{j\\omega}) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}X(e^{j\\omega})W_R(e^{j(\\omega - \\theta)})\\mathrm d\\theta\n$$\n\n对于矩形窗：\n\n$$\nW_R(e^{j\\omega}) = \\text{DTFT}(w_R[n]) = \\frac{\\sin(M\\omega / 2)}{\\sin(\\omega/2)} e^{-j\\frac{M - 1}{2}\\omega}\n$$\n\n频率分辨力的定义：两个等幅单频信号能够被区分开的最小频率间隔\n\n矩形窗的主瓣宽度为 $4\\pi/MT_s$\n\n实际工程中，采用 3dB带宽并加上适当余量作为频率分辨力\n\n* 矩形窗的数字角频率分辨力为 $\\Delta \\omega = 2\\pi / M$\n* 连续信号的分辨力为 $\\Delta f = f_s/M$\n\n分辨力仅决定于信号时长 $MT_s$。\n\n混叠效应\n\n混叠效应本质上由采样过程引起\n- 混叠效应带来的问题\n- 如果采样过程带来了混叠，DFT结果无法将已混叠的频\n率分量分开\n- 采样之前作抗混叠滤波，把带外频率成分滤除\n- 增大采样频率（减小采样周期）\n– 无法仅从DFT结果中判读原连续信号的模拟频率\n- 需要原连续信号频率分布或抗混叠滤波通带的先验\n知识\n\n栅栏效应\n* DFT 无法精确表示不在离散采样点的频率值\n* 频率估计的最大误差为 $\\pi / N$\n* 可以通过加窗补零（增大 $N$）的方法改善\n* 通过局部插值的方法获得更精确的频率估计：精确插值，线性插值，二次插值\n\n## DFT 的应用\n\n### 线性卷积的计算\n\n假设有限长因果序列 $h[n]$ 和 $x[n]$，长度分别为 $P$ 和 $L$，均扩展到 $N$ 个点进行卷积\n\n* 当 $N \\ge P + L - 1$ 时，两种卷积的结果相等\n* 当 $N \\lt P + L - 1$ 时，循环卷积出现混叠\n\n基于 DFT 的 FIR 滤波器实现\n\nFIR 滤波器需要计算有限长序列和无限长序列的线性卷积\n* $h[n]$ 有限\n* $x[n]$ 无限\n\n方法1：重叠相加法\n\n$$\nx[n] =\\sum\\limits_{r=0}^{\\infty}x_r[n - rL]\\\\\ny[n] = h[n] * \\sum\\limits_{r=0}^{\\infty}x_r[n - rL] = \\sum\\limits_{r=0}^{\\infty}h[n] * x_r[n - rL]\\\\\n$$\n\n整个序列的线性卷积等于各段线性卷积后的移位加和\n\nIDFT 后，需要一个专门的加法器进行重叠部分的相加运算\n\n方法二：重叠保留法\n\n取 $L$ 点 $x[n]$ 与扩展的 $P$ 点 $h[n]$ 做循环卷积，取结果的后 $L - P + 1$ 个点作为结果。\n\n两种方法、直接计算线性相关的计算量对比？\n\n### 线性调频 z 变换\n\nCZT 的定义\n\n$$\nX_{cz}(z)|_{z = z_k} =\\sum\\limits_{n=0}^{N - 1}x[n]z_k^{-n}\\\\\nz_k = AW^{-k} = (A_0e^{j\\theta_0})(W_0e^{-j\\varphi_0})^{-k}\n$$\n\n一种广义的 DFT，在复平面螺旋线上的采样。\n\nCZT 的计算\n* 利用定义直接计算\n* 利用卷积计算，而卷积可以利用 FFT 计算\n\n$$\nX_{cz}(z_k) = W^{\\frac{k^2}{2}}\\sum\\limits_{n=0}^{N - 1}f[n]h[k - n]\\\\\nf[n] = x[n]A^{-n}W^{\\frac{n^2}{2}}\\\\\nh[n] = W^{-\\frac{n^2}{2}}\n$$\n\n### 短时傅里叶变换\n\n问题：基于傅里叶的频谱分析可以指导信号观测窗内的频率成分，但是无法得知这些频率成分何时出现，何时消失，持续多久\n\n定义\n\n$$\n\\text{STFT}(t^\\prime, \\Omega) = \\int_{-\\infty}^{\\infty}x(\\tau)g^*(\\tau - t^\\prime)e^{-j\\Omega\\tau}\\mathrm d\\tau\n$$\n\n* 窗的长度\n  * 窗长需要足够短，确保落入窗的信号近似平稳\n  * 窗越长，频率分辨率越高，窗越短，时间分辨率越高\n    * 窗无限长，退化成 FT\n    * 无限短，退化成 $s(t^\\prime)e^{-j\\Omega t^\\prime}$\n* 窗的类型\n  * 矩形窗，汉明窗，布莱克曼窗\n  * 主瓣宽度与旁瓣电平之间的权衡\n\n不确定性原理\n\n$$\n\\Delta t \\cdot \\Delta \\Omega \\ge \\frac{1}{2}\n$$\n\n\n## LTI 系统\n\n### LTI 系统的时域分析——冲激响应\n\n根据冲激响应长度不同：\n* FIR:用 $h[n]$ 表示系统\n* IIR：用系统函数或者差分方程表示\n\n### LTI 系统的时域分析——冲激响应\n\n复指数序列是 LTI 系统的特征函数\n\n$$\nT \\lbrace e^{j\\omega n} \\rbrace = H(e^{j\\omega})e^{j\\omega n}\n$$\n\n频率响应函数的表示方式\n* $H(e^{j\\omega}) = H_R(e^{j\\omega}) + jH_I(e^{j\\omega})$\n* $H(e^{j\\omega}) = |H(e^{j\\omega})|e^{j\\angle H(e^{j\\omega})}$\n* 幅频特性：\n  * $|H(e^{j\\omega})|$\n  * $20\\log |H(e^{j\\omega})|$，单位 dB\n* 相频特性\n  * $arg(H(e^{j\\omega}))$：连续相位\n  * $Arg(H(e^{j\\omega}))$：主值相位\n  * 无卷绕相位：$\\angle H(e^{j\\omega}) = \\tan^{-1}\\frac{H_I(e^{j\\omega})}{H_R(e^{j\\omega})}$\n  * 定义主值区间 $arg(H(e^{j\\omega})) = ARG[H(e^{j\\omega})] + 2\\pi r(\\omega)$，$r(\\omega)$是补偿函数，仅取整数\n\n相位延迟\n\n群延迟\n\n$$\n-\\frac{\\mathrm d}{\\mathrm d\\omega}\\text{arg}[H_{id}(e^{j\\omega})]\n$$\n\n可以表征窄带信号的相位失真（或者延迟）\n\n$$\nx[n] = a[n]e^{j\\omega_c n}\\\\\na[n] = c_1e^{j\\omega_1n}\\\\\ny[n] \\approx |H(e^{j\\omega_c})|c_1e^{j(\\omega_1 + \\omega_c)n + j\\varphi(\\omega_1 + \\omega_c)} \\approx |H(e^{j\\omega_c})|\\underbrace{a[n - \\tau_g(\\omega_c)]}_{群延迟给出了包络延迟}\\underbrace{e^{j\\omega_c[n - \\tau_p(\\omega_c)]}}_{相位延迟\\tau_p(\\omega_c) = \\varphi(\\omega_c)}\n$$\n\n### LTI 系统的零极点分析\n\n$$\n\\sum\\limits_{k=0}^{N}a_ky[n - k] =\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH[z] = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{\\sum\\limits_{k=0}^{N}a_kz^{-k}} = \\left ( \\frac{b_0}{a_0} \\right)\\frac{\\prod_{k = 1}^M(1 - c_kz^{-1})}{\\prod_{k = 1}^N(1 - d_kz^{-1})}\n$$\n\n$z = 0, z = \\infty$ 也可能是零点！求解的时候不要忘了。\n\n系统稳定性的条件：绝对可和。或者说 $H(z)$ 的极点在单位圆内。\n\n可逆性的条件：$h[n] * h_i[n] = \\delta[n]$， $H(8z)H_i(z) = 1$\n* 逆系统的极点和零点就是原系统的零点和极点\n* 逆系统和原系统必须有重叠的 ROC，因此可以确定逆系统的 ROC\n\n频率响应\n\n\n群延迟\n\n$$\n\\text{grd}[] =\\sum\\limits_{k=1}^{N}\\frac{|d_k|^2 - \\Re{d_ke^{-j\\omega}}}{1 + |d_k|^2 - 2\\Re{d_ke^{-j\\omega}}} - \\sum\\limits_{k=1}^{M}\\frac{|c_k|^2 - \\Re{c_ke^{-j\\omega}}}{1 + |c_k|^2 - 2\\Re{c_ke^{-j\\omega}}}\n$$\n\n### IIR滤波器\n\n$$\ny[n] =\\sum\\limits_{k=1}^{N}a_ky[n - k] +\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH(z) = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{1 -\\sum\\limits_{k=1}^{N}a_kz^{-k}}\n$$\n\n直接 I 型\n\n直接 II 型：交换次序，合并延迟单元\n\n级联形式：\n\n$$\nH(z) = K \\prod_{k = 1}^{N_s} \\frac{b_{0k} + b_{1k}z^{-1} + b_{2k}z^{-2}}{1 - a_{1k}z^{-1} - a_{2k}z^{-2}}\n$$\n\n考虑到有限字长效应，级联形式可以以更加灵活的方式减小有限字长的影响。可以控制零点和极点的位置。\n\n级联形式也可以用直接 I, II 型实现。\n\n多径衰落就是一个 FIR 滤波器，因此具有频率选择特性。\n\n\n并联形式\n\n$$\nH(z) =\\sum\\limits_{k=0}^{N_p}C_kz^{-k} +\\sum\\limits_{k=1}^{N_2}\\frac{e_{0k}+e_{1k}z^{-1}}{1 - a_{1k} - a_{2k}z^{-2}}\n$$\n\n各子系统的计算误差互不影响，防止误差传递和放大，可控极点位置\n\n流图转置定理：支路方向取反，系数不变，输入和输出交换位置\n\n### FIR 滤波器\n\n$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n}\n$$\n\n抽头延迟线 or 横向滤波器结构\n\n具有转置形式\n\n级联形式\n\n$$\nH(z) = \\prod_{k = 1}^{M_1}(f_{0k} - f_{1k}z^{-1}\\prod_{k = 1}^{M_2}(b_{0k} + b_{1k} z^{-1} + b_{2k}z^{-2})\n$$\n\n线性相位特性\n\n$$\nH(e^{j\\omega}) = A(e^{j\\omega})e^{-j\\omega\\alpha}\n$$\n\n$$\nh[n] = h[M - n] (I, II)\\\\\nh[n] = - h[M - n] (III,IV)\n$$\n\n线性相位 FIR 滤波器的直接形式\n\n偶数\n\n$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] + x[n - M + k]) + h[M/2]x[n - M/2], &I type\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] - x[n - M + k]), &III type\n\\end{cases}\n$$\n\n奇数\n\n\n$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] + x[n - M + k]), &II type\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] - x[n - M + k]), &IV type\n\\end{cases}\n$$\n\n级联形式\n\n对应四种零点分布情况，有四种网络结构\n\n$$\nH(z) = 1 \\pm z^{-1}\\\\\nH(z) = 1 - 2\\cos(\\theta)z^{-1} + z^{-2}\\\\\nH(z) = (1 - rz^{-1})(1 - r^{-1}z^{-1})\\\\\nH(z) = 1 + bz^{-1} + cz^{-2} + bz^{-3} + z^{-4}\n$$\n\n### FIR 滤波器的频率取样结构\n\n$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n} = \\frac{1}{N}(1 - z^{-N})\\sum\\limits_{k=0}^{N - 1}\\frac{H(k)}{1 - W_N^{-j}z^{-1}}\n$$\n\n$H(k)$ 是 FFT 变换。\n\n若冲激响应是实序列，可以用共轭对称性将成对的一阶子系统合称为二阶子系统\n\n$$\nH_k(z) + H_{-k}(z) = 2|H(k)| \\frac{\\cos\\theta(k) - (\\cos(\\theta(k) - \\frac{2\\pi}{N}k))z^{-1}}{1 - 2\\cos(\\frac{2\\pi}{N}k)z^{-1} + z^{-2}}\n$$\n\n其中 $\\theta(k)$ 是 $H(k)$ 的相位\n\n不成对的子系统？\n\n$$\nH_0(z) = \\frac{H(0)}{1 - z^{-1}}\\\\\nH_{N/2}(z) = \\frac{H(0)}{1 + z^{-1}}\n$$\n\nFIR 滤波器的时分复用结构\n\n\n## 离散希尔伯特变换\n\n$$\nh[n] = \\begin{cases}\n    \\frac{1 - \\cos(n\\pi)}{n\\pi}, n \\ne 0\\\\\n    0, n = 0\n\\end{cases}\n$$\n\n## 典型数字信号处理系统及其误差源\n\n* 引起有限字长的误差源\n  * AD 变换引入的误差\n  * 有限精度引起的误差\n  * 限制乘法运算位数的误差\n  * 防止加法溢出压缩信号电平的误差\n\n### 量化误差的统计分析模型\n\n$$\nQ_B \\lbrace x[n] \\rbrace = x[n] + e[n]\\\\\n$$\n\n$e[n]$ 是各态历经的平稳随机序列，与 $x[n]$ 相互统计独立，具有白噪声的性质，不同时刻的取值相互独立，是均匀分布的。","slug":"Digital-Signal-Processing","published":1,"updated":"2024-03-19T06:01:16.158Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfht0006rsug8hc34xd4","content":"<h2 id=\"绪论\"><a href=\"#绪论\" class=\"headerlink\" title=\"绪论\"></a>绪论</h2><h3 id=\"信号\"><a href=\"#信号\" class=\"headerlink\" title=\"信号\"></a>信号</h3><p>信号是某种随时间或&#x2F;和空间变化的物理量，其包含有从信源到信宿的某种信息。</p>\n<p>信号可以根据时间和幅度的取值方式分类</p>\n<ul>\n<li>连续时间信号</li>\n<li><ul>\n<li>在时间和幅度上均可以连续取值的信号</li>\n</ul>\n</li>\n<li>离散时间信号</li>\n<li><ul>\n<li>仅在离散时间点上取值，但可在幅度上连续取值的<br>信号</li>\n</ul>\n</li>\n<li>数字信号</li>\n<li><ul>\n<li>仅在离散时间点上取值，且在幅度上只能离散取值<br>的信号</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"系统\"><a href=\"#系统\" class=\"headerlink\" title=\"系统\"></a>系统</h3><ul>\n<li>由若干相互作用和相互依赖的事物组合而成的具有特<br>定功能的整体</li>\n<li>具有它自身的结构、行为和性质，通过输入和输出与<br>其所处的环境进行交互，通常实现一定的功能</li>\n<li>可通过分析给定输入下输出的性质，来研究其行为和<br>性质</li>\n</ul>\n<p>信号处理系统</p>\n<ul>\n<li>对信号进行某种操作的单元或模块</li>\n<li>从数学上看，可视为作用于函数上的算子</li>\n</ul>\n<p>通常根据信号处理单元而非输入输出信号性质分类</p>\n<ul>\n<li>连续（模拟）信号处理系统</li>\n<li><ul>\n<li>由电阻、电容、电感和放大器等组成的模拟电路完成信号处<br>理功能</li>\n</ul>\n</li>\n<li><ul>\n<li>直接处理连续信号</li>\n</ul>\n</li>\n<li>离散信号处理系统</li>\n<li><ul>\n<li>由CCD、电容和放大器等组成的离散电路完成信号处理功能</li>\n</ul>\n</li>\n<li><ul>\n<li>处理由连续信号采样而来的离散时间信号</li>\n</ul>\n</li>\n<li>数字信号处理系统</li>\n<li><ul>\n<li>信号处理功能由数字逻辑电路或通用计算机来完成</li>\n</ul>\n</li>\n<li><ul>\n<li>处理数字信号（例如来源于对连续信号的采样和量化）</li>\n</ul>\n</li>\n</ul>\n<p>模拟 -&gt; 采样量化 -&gt; 数字信号处理系统 -&gt; 模拟重建 -&gt; 模拟输出信号</p>\n<h3 id=\"数字信号处理的局限\"><a href=\"#数字信号处理的局限\" class=\"headerlink\" title=\"数字信号处理的局限\"></a>数字信号处理的局限</h3><ul>\n<li>ADC和DAC器件的处理能力</li>\n<li><ul>\n<li>是否能够准确提取出原连续信号中的信息首先决定于<br>ADC：采样率、量化位数、时钟抖动、线性度等</li>\n</ul>\n</li>\n<li>精度受量化和舍入误差影响</li>\n<li><ul>\n<li>有限字长效应：数字系统中数字表示和计算精度受字<br>长限制</li>\n</ul>\n</li>\n<li>适合于数字处理的信号带宽受处理能力的限制</li>\n<li><ul>\n<li>例如，信号带宽10MHz、采样率20MHz、FIR滤波器阶<br>数为500，则所需计算量为每秒10G次的乘累加</li>\n</ul>\n</li>\n<li><ul>\n<li>如果带宽为1GHz呢?</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"数字信号处理的发展\"><a href=\"#数字信号处理的发展\" class=\"headerlink\" title=\"数字信号处理的发展\"></a>数字信号处理的发展</h3><ul>\n<li>20世纪初至50年代有许多前期的研究工作，从采样<br>定理的建立到声码器的数字仿真实验等，奠定了理论<br>基础</li>\n<li>1965年FFT的提出，是DSP发展的里程碑 （但其源头<br>可追溯到高斯时代）</li>\n<li>离散变换的进展：65年FFT，70年代余弦变换，80年<br>代中后期小波变换</li>\n<li>滤波器设计技术：IIR、FIR数字滤波器，多采样处理<br>和滤波器组理论，专用滤波器设计，小波滤波</li>\n<li>统计和自适应信号处理，阵列处理等，从统计学引入<br>信号处理发展的另一条主线——现代信号处理</li>\n<li>器件和系统的发展对数字信号处理有积极推动</li>\n</ul>\n<h3 id=\"从模拟到数字\"><a href=\"#从模拟到数字\" class=\"headerlink\" title=\"从模拟到数字\"></a>从模拟到数字</h3><p>模拟信号的数字化：ADC</p>\n<p>采样：本课程主要考虑均匀采样。</p>\n<div>$$\nx[n] = x_a(nT) -\\infty \\lt n \\lt \\infty\\\\ \nf_s = 1/T\\\\\n\\Omega_s = 2\\pi f_s\n$$</div>\n\n<p>采样的实现：采样保持电路</p>\n<p>采样周期：与被采样信号的频带参数一起决定了采样过程是否会发生混叠。</p>\n<p>采样过程的模糊性：采样过程可看作一种由连续信号空间到离散信号空间的多对一映射；对于给定的采样周期，仍存在无穷多个连续信号与同一离散信号对应。需要施加某种约束条件。</p>\n<p> 采样过程的基本问题：</p>\n<ul>\n<li>采样过程是否会引起被采样信号的信息丢失？</li>\n<li>被采样的连续信号是否能从采样样本中完全恢复？</li>\n<li>采样过程的频域分析可获得上述问题的答案</li>\n<li><ul>\n<li>推导得到采样后离散信号和采样前连续信号频谱间的数学关系</li>\n</ul>\n</li>\n<li><ul>\n<li>确定可以消除采样过程模糊性的条件</li>\n</ul>\n</li>\n<li><ul>\n<li>为实际数字信号处理系统设计中采样频率的选择、抗混叠前置滤波器的设计提供指导</li>\n</ul>\n</li>\n</ul>\n<p>采样的数学表示：</p>\n<div>$$\ns(t) = \\sum_{n = -\\infty}^{\\infty}\\delta(t - nT)\\\\\nx_s(t) = x_a(t) \\cdot s(t)\\\\\nx[n] = x_a(nT)\n$$</div>\n\n<p>对连续信号进行采样，其频谱是原始信号的周期延拓，延拓周期为采样频率</p>\n<div>$$\n\\begin{align*}\n\\text{时域} & \\quad \\quad \\text{频域} \\\\\nx_a(t) & \\quad \\quad X_a(j\\Omega)\\\\\ns(t) & \\quad \\quad S(j\\Omega) = \\frac{2\\pi}{T} \\sum_{k=-\\infty}^{+\\infty} \\delta(\\Omega - k\\Omega_s)\\\\\nx_a(t) \\cdot s(t) & \\quad \\quad X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a\\bigg(j(\\Omega - k\\Omega_s)\\bigg)\n\\end{align*}\n$$</div>\n\n<p>带限信号和带通信号：</p>\n<ul>\n<li>带限信号：$X_a(j\\Omega) &#x3D; 0, |\\Omega| \\ge \\Omega_H$</li>\n<li>带通信号：$X_a(j\\Omega) &#x3D; 0, |\\Omega| \\ge \\Omega_H\\text{ or }|\\Omega| \\le \\Omega_L$</li>\n</ul>\n<p>带限信号的采样：</p>\n<!-- int, sum, frac partial -->\n\n<div>$$\nX_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)], \\Omega_s \\ge 2\\Omega_H\n$$</div>\n\n<p>对应的离散时间序列：</p>\n<div>$$\nX(e^{j\\Omega T}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)]\\\\\n\\Rightarrow X(e^{j\\omega}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\omega - 2\\pi k)/T]\\\\\n$$</div>\n\n<p>带通采样让时间以$T \\rightarrow 1$的形式进行归一化，频率以$\\Omega_s \\rightarrow 2\\pi$的形式进行归一化。</p>\n<p>Nyquist 采样定理：</p>\n<div>$$\nX_a(j\\Omega) = 0, \\forall |\\Omega| \\ge \\Omega_H\\\\\n\\Omega_s = 2\\pi / T \\gt 2\\Omega_H\n$$</div>\n\n<p>或者归一化频率</p>\n<div>$$\n\\omega_H = \\Omega_H T < \\pi\n$$</div>\n\n<p>Remark：</p>\n<ul>\n<li>$𝑥_𝑎(𝑡)$ 是基带、带限信号</li>\n<li>Nyquist是充分条件，即对被采样信号无其他假设</li>\n<li>在仅知道连续信号最高频率时，Nyquist采样定理给出<br>了由采样信号唯一确定（或恢复）原信号的条件</li>\n<li><ul>\n<li>已知连续信号最高频率，可用于确定最低采样频率</li>\n</ul>\n</li>\n<li><ul>\n<li>已知采样频率，可确定无混叠连续信号的最高频率</li>\n</ul>\n</li>\n</ul>\n<p>带通信号的采样：</p>\n<div>$$\n\\frac{2f_H}{m+1} \\le f_s \\le \\frac{2f_L}{m}, m\\in \\N ,m \\le f_L/B\n$$</div>\n\n<p>带限连续信号的重建：</p>\n<ul>\n<li>由离散序列𝑥[𝑛]和采样周期𝑇，恢复原连续信号$𝑥_𝑟(𝑡)$</li>\n<li>由序列到冲激串转换和重建滤波两个步骤构成</li>\n<li>重建后的信号表示为</li>\n</ul>\n<div>$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]h_r(t - nT)\n$$</div>\n\n<p>如选择截止频率$\\Omega_c &#x3D; \\pi&#x2F;T$的理想低通滤波器：</p>\n<div>$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]\\frac{\\sin[\\pi(t - nT)/T]}{\\pi(t - nT)/T}\n$$</div>\n理想低通滤波器通过对冲激串信号的内插重建了原来的连续信号\n\n<p><strong>Summary</strong></p>\n<p>原信号：</p>\n<div>$$\nx_c(t) \\leftrightarrow X_c(j\\Omega)\n$$</div>\n\n<p>采样后的信号：</p>\n<div>$$\n\\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) = \\sum\\limits_{n=-\\infty}^{\\infty}x_c(t)\\delta(t - nT_s) \\leftrightarrow \\frac{1}{T_s}X(e^{j\\Omega T_s}) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}X_c(j(\\Omega - n\\Omega_s))\n$$</div>\n\n<p>数字域：</p>\n<div>$$\nx[n] \\leftrightarrow X(e^{j\\omega}) = \\frac{1}{T_s} X_c(j\\omega /T_s)\n$$</div>\n\n<p>恢复信号：</p>\n<div>$$\nh_r(t) \\leftrightarrow H_r(j\\Omega) = \\begin{cases}\n    T_s, &|\\Omega| \\le \\pi / T_s, \\\\\n    0,   &|\\Omega| \\gt \\pi / T_s\n\\end{cases}\\\\\n\\begin{align*}\n    x_r(t)  &= \\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) * h_r(t)\\\\\n            &= \\sum\\limits_{n=-\\infty}^{\\infty} x_c(nT_s)h_r(t - nT_s)\\\\\n            &= x_c(t)\n\\end{align*}\\ \\leftrightarrow\\ \\begin{align*}\n    X_r(j\\Omega) &= T_s X(e^{j\\Omega T_s})H_r(j\\Omega)\\\\\n    &= X_c(j\\Omega)\n\\end{align*}\n$$</div>\n\n<p>数字时域和模拟时域之间的关系：</p>\n<div>$$\nn = \\frac{t}{T_s} = tf_s\n$$</div>\n\n<p>数字频域和模拟频域之间的关系：</p>\n<div>$$\n\\omega = \\Omega T_s = \\frac{2\\pi f}{f_s}\n$$</div>\n\n<h2 id=\"信号的表示\"><a href=\"#信号的表示\" class=\"headerlink\" title=\"信号的表示\"></a>信号的表示</h2><h3 id=\"离散信号的时域表示\"><a href=\"#离散信号的时域表示\" class=\"headerlink\" title=\"离散信号的时域表示\"></a>离散信号的时域表示</h3><ul>\n<li>时域表示方法<ul>\n<li>数学表达式：可表示基本信号，但大多数实际信号无解析表达式</li>\n<li>图形表示：直观、易理解，但不适用于刻画复杂信号</li>\n<li>数据表示：离散信号最一般的表示方法</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"离散信号的变换域表示\"><a href=\"#离散信号的变换域表示\" class=\"headerlink\" title=\"离散信号的变换域表示\"></a>离散信号的变换域表示</h3><ul>\n<li>定义：假设离散时间信号为𝑥[𝑛] ，定义映射𝑇{·}，那么信号的变换域表示可以写作𝑋 &#x3D; 𝑇{𝑥[𝑛]}<ul>\n<li>𝑇{·}是从函数空间到函数空间的映射</li>\n<li>𝑋并不要求一定定义在整数域上</li>\n</ul>\n</li>\n<li>常用情形：级数表示<ul>\n<li>将信号分解成有限项或无穷多项基本信号加权和的形式，由和式中每个基本信号的加权值组成的序列形成了原信号的变换域表示</li>\n<li>傅里叶级数展开 $x[n] &#x3D; \\sum_k a_k e^{j2\\pi kn &#x2F;T}$</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"离散信号的正交函数表示\"><a href=\"#离散信号的正交函数表示\" class=\"headerlink\" title=\"离散信号的正交函数表示\"></a>离散信号的正交函数表示</h3><ul>\n<li>使用信号空间的完备正交基来表示离散信号，<div>$$\n\\lbrace\\ldots ,\\varphi_0[n] ,\\varphi_1[n] ,\\varphi_2[n] , \\ldots\\rbrace\n$$</div></li>\n<li>正交性：<div>$$\n\\sum_{n} \\varphi_k^*[n] \\varphi_l[n] = \\delta_{kl}\n$$</div>\n其中，$k \\neq l$。</li>\n</ul>\n<ul>\n<li>完备性<ul>\n<li>任何一个信号都可由这组基函数通过线性叠加而构成</li>\n</ul>\n</li>\n<li>加权系数的计算<ul>\n<li>对基函数的投影：</li>\n</ul>\n</li>\n</ul>\n<div>$$\nc_k = \\frac{\\langle x[n], \\phi_k[n]\\rangle}{||\\phi_k[n]||^2}\n$$</div>\n\n<p>DFT 的定义如下：</p>\n<div>$$\nX[k] = \\sum_{n=0}^{N-1} x[n]e^{-j2\\pi kn/N}\n$$</div>\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\n<p>DCT 的定义如下：</p>\n<div>$$\nX[k] = \\sum_{n=0}^{N-1} x[n]\\cos\\left(\\frac{\\pi}{N}(n + 0.5)k\\right)\n$$</div>\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\n<h3 id=\"离散信号的特征域（量）表示\"><a href=\"#离散信号的特征域（量）表示\" class=\"headerlink\" title=\"离散信号的特征域（量）表示\"></a>离散信号的特征域（量）表示</h3><ul>\n<li>特征量表示指由信号的时域或频域表示来计算用<br>于表征信号的特征量<ul>\n<li>例如能量、功率、均值、相关函数、功率谱</li>\n<li>特征量表示通常是单向性的，由特征量表示一般不能完整地恢复原信号的所有取值</li>\n<li>实践中，经常用特征量来表示随机信号</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"离散信号的单位抽样信号表示：\"><a href=\"#离散信号的单位抽样信号表示：\" class=\"headerlink\" title=\"离散信号的单位抽样信号表示：\"></a>离散信号的单位抽样信号表示：</h3><p>单位抽样信号的移位作为基信号：</p>\n<div>$$\n\\varphi_k[n] = \\delta[n - k], \\quad k \\in (-\\infty, \\ldots, -1, 0, 1, \\ldots, \\infty)\n$$</div>\n\n<p>• 正交性验证：</p>\n<div>$$\n\\langle\\varphi_k[n],\\varphi_l[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} \\delta[n - k] \\delta[n - l] = \\delta[k - l]\n$$</div>\n\n<p>• 系数计算：</p>\n<div>$$\nc_k = \\frac{\\langle x[n],\\varphi_k[n]\\rangle}{\\varphi_k[n]^2} = x[k]\n$$</div>\n\n<p>• 离散信号的单位抽样表示为：</p>\n<div>$$\nx[n] = \\sum_{k=-\\infty}^{\\infty} c_k\\varphi_k[n] = \\sum_{k=-\\infty}^{\\infty} x[k] \\delta[n - k]\n$$</div>\n\n<p>离散信号的复指数信号表示如下：</p>\n<p>• 复指数信号作为基信号：</p>\n<div>$$\n\\varphi_\\omega[n] = e^{j\\omega n}, \\quad 0 \\leq \\omega < 2\\pi\n$$</div>\n\n<p>• 正交性验证：</p>\n<div>$$\n\\langle\\varphi_{\\omega_1}[n],\\varphi_{\\omega_2}[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} e^{j\\omega_1 n} e^{-j\\omega_2 n} = \\begin{cases} \n0, & \\omega_1 \\neq \\omega_2 \\\\\n\\infty, & \\omega_1 = \\omega_2 \n\\end{cases}\n$$</div>\n\n<p>• 系数计算：</p>\n<div>$$\nX(e^{j\\omega}) = \\langle x[n], e^{j\\omega n} \\rangle = x[n] e^{-j\\omega n}\n$$</div>\n\n<p>• 离散信号的复指数信号表示为：</p>\n<div>$$\nx[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(e^{j\\omega}) e^{j\\omega n} d\\omega\n$$</div>\n\n<h3 id=\"有限长离散信号的正交函数表示\"><a href=\"#有限长离散信号的正交函数表示\" class=\"headerlink\" title=\"有限长离散信号的正交函数表示\"></a>有限长离散信号的正交函数表示</h3><p>• 对于长度为$N$的有限长离散序列，选择以下$N$个序列作为基信号：</p>\n<div>$$\n\\varphi_k[n] = e^{j\\frac{2\\pi}{N}kn}R_N[n], \\quad k = 0,1,2,\\ldots,N-1\n$$</div>\n\n<p>• 正交性验证：</p>\n<div>$$\n\\langle \\varphi_k[n],\\varphi_l[n] \\rangle = \\sum_{n=0}^{N-1} e^{j\\frac{2\\pi}{N}(k-l)n} = \\begin{cases} \nN, & k = l \\\\\n0, & k \\neq l \n\\end{cases}\n$$</div>\n\n<p>• 系数计算：</p>\n<div>$$\nX[k] = \\sum_{n=0}^{N-1} x[n] e^{-j\\frac{2\\pi}{N}kn}, \\quad k = 0,1,2,\\ldots,N-1\n$$</div>\n\n<p>• 有限长离散序列可以表示为：</p>\n<div>$$\nx[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} X[k] e^{j\\frac{2\\pi}{N}kn}, \\quad n = 0,1,2,\\ldots,N-1\n$$</div>\n\n<ul>\n<li>离散信号的因果性:<ul>\n<li>𝑥[𝑛] &#x3D; 0，for 𝑛 &lt; 0</li>\n</ul>\n</li>\n</ul>\n<p>因果连续信号抽样后一定是因果离散信号。</p>\n<ul>\n<li>离散信号的对称性：</li>\n</ul>\n<p>• 共轭对称性：</p>\n<ul>\n<li>正对称：$x[n] &#x3D; x^*[-n]$</li>\n<li>反对称：$x[n] &#x3D; -x^*[-n]$</li>\n</ul>\n<p>• 任意信号都可以表示为奇分量和偶分量的和：<br>  $x[n] &#x3D; x_o[n] + x_e[n]$<br>  其中，$x_o[n] &#x3D; \\frac{1}{2}(x[n] - x^*[-n])$为奇分量，$x_e[n] &#x3D; \\frac{1}{2}(x[n] + x^*[-n])$为偶分量。</p>\n<p>• 若信号具有实因果性，可以通过奇分量或偶分量来恢复原信号：</p>\n<div>$$\nx[n] = \\begin{cases}\n0, & n < 0 \\\\\nx_e[n], & n = 0 \\\\\n2x_e[n], & n > 0\n\\end{cases}\n$$</div>\n\n<ul>\n<li>离散信号的周期性：<ul>\n<li>$𝑥[n] &#x3D; 𝑥[𝑛 + N]$</li>\n</ul>\n</li>\n</ul>\n<p>周期连续信号均匀采样后<strong>不</strong>一定是周期离散信号。</p>\n<div>$$\n\\omega_0 = \\Omega_0T = 2\\pi\\frac{T}{T_0}\n$$</div>\n\n<p>离散余弦信号的数字角频率 $\\omega_0$ 由采样周期和连续信号周期的比值决定。该比值决定了采样后的信号是否具有周期性。</p>\n<h3 id=\"离散系统的表示\"><a href=\"#离散系统的表示\" class=\"headerlink\" title=\"离散系统的表示\"></a>离散系统的表示</h3><p>离散系统的表示可以使用以下公式来描述：</p>\n<div>$$y[n] = \\sum_{k=-\\infty}^{\\infty} h[k]x[n-k]$$</div>\n\n<p>其中，$y[n]$表示系统的输出，$x[n]$表示系统的输入，$h[k]$表示系统的单位冲激响应。这个公式是卷积的离散形式，也称为离散卷积。</p>\n<p>对于因果性，一个离散系统被称为因果性系统，如果它对任何$n &lt; 0$的输入信号$x[n]$都产生$y[n] &#x3D; 0$的输出。这意味着输出只依赖于当前和过去的输入。</p>\n<p>对于稳定性，一个离散系统被称为稳定系统，如果对于有界的输入信号$x[n]$，输出$y[n]$仍然是有界的。</p>\n<p>LTI（线性时不变）系统是指具有线性性质和时不变性质的系统。线性性质意味着系统满足叠加原理，即对于输入信号$x_1[n]$和$x_2[n]$，系统的输出满足$y_1[n] + y_2[n]$。时不变性质意味着系统的单位冲激响应$h[k]$与输入信号$x[n]$的延迟无关。</p>\n<p>单位冲激响应是指当输入信号为单位冲激函数$\\delta[n]$时，系统的输出。单位冲激响应通常用$h[n]$表示。</p>\n<p>LTI系统可完全由单位冲激响应来表征。</p>\n<p>因果性判据：单位冲激响应是一个因果信号。<br>稳定性判据：$S &#x3D; \\sum_{k &#x3D; -\\infty}^\\infty |h[k]| \\lt +\\infty$</p>\n<p><strong>特征函数与特征值</strong></p>\n<div>$$\nT\\lbrace s[n]\\rbrace = \\lambda s[n]\n$$</div>\n\n<p><strong>LTI系统的特征函数与特征值</strong></p>\n<div>$$\nT\\lbrace e^{j\\omega n}\\rbrace =\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{j\\omega (n - k)} = \\underbrace{e^{j\\omega n}}_{特征函数}\\cdot\\underbrace{\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{-j\\omega k}}_{特征值}\n$$</div>\n\n<p>$y[n]$ 可看作 $x[n]$ 经过特征信号分解、加权、求和的结果：</p>\n<div>$$\ny[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^\\pi H(e^{j\\omega})X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$</div>\n\n<ul>\n<li>频率响应函数：单位冲激响应的DTFT</li>\n</ul>\n<div>$$\nH(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]e^{-j\\omega n}\n$$</div>\n\n<ul>\n<li>系统函数</li>\n</ul>\n<div>$$\nH(z) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]z^{-n}\n$$</div>\n\n<ul>\n<li>系统差分方程</li>\n</ul>\n<div>$$\n\\sum\\limits_{k=0}^{N} a_ky[n - k] =\\sum\\limits_{k=0}^{M} b_kx[n - k]\n$$</div>\n\n<ul>\n<li>系统状态空间</li>\n</ul>\n<div>$$\n\\lambda[n + 1] = A\\lambda[n] + Bx[n]\\\\\ny[n] = C\\lambda[n] + Dx[n]\n$$</div>\n\n<h2 id=\"DTFT-与-DFT\"><a href=\"#DTFT-与-DFT\" class=\"headerlink\" title=\"DTFT 与 DFT\"></a>DTFT 与 DFT</h2><h3 id=\"DTFT\"><a href=\"#DTFT\" class=\"headerlink\" title=\"DTFT\"></a>DTFT</h3><div>$$\n\\begin{cases}\n    X(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\omega n}\\\\\n    x[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi}X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n\\end{cases}\n$$</div>\n\n<p>与连续频谱的关系：</p>\n<div>$$\nX(e^{j\\omega}) = \\frac{1}{T}\\sum\\limits_{k=-\\infty}^{\\infty}X_a\\left[j\\left(\\frac{\\omega}{T} - k\\frac{2\\pi}{T}\\right)\\right]\\\\\n\\omega = \\Omega T\n$$</div>\n\n<p>基本性质：</p>\n<ul>\n<li>周期性</li>\n</ul>\n<div>$$\nX(e^{j\\omega}) = X(e^{j\\omega + 2k\\pi}), k\\in \\Z\n$$</div>\n\n<ul>\n<li>线性</li>\n</ul>\n<div>$$\nax[n] + by[n] \\lrarr aX(e^{j\\omega}) + bY(e^{j\\omega})\n$$</div>\n\n<ul>\n<li>频域求导</li>\n</ul>\n<div>$$\nnx[n] \\lrarr j\\frac{\\mathrm dX(e^{j\\omega})}{\\mathrm d\\omega}\n$$</div>\n\n<ul>\n<li>Parseval 定理：</li>\n</ul>\n<div>$$\n\\sum\\limits_{n=-\\infty}^{\\infty}||x[n]||^2 = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}||X(e^{j\\omega})||^2\\mathrm d\\omega\n$$</div>\n\n<ul>\n<li>序列的调制</li>\n</ul>\n<div>$$\nx[n]e^{j\\omega_0 n} \\lrarr X(e^{j(\\omega - \\omega_0)})\n$$</div>\n\n<p>实现数字变频：</p>\n<div>$$\nx_B[n] = x[n]e^{-j\\frac{\\pi}{2}n}\n$$</div>\n\n<ul>\n<li>序列的平移</li>\n</ul>\n<div>$$\nx[n - n_0] \\lrarr e^{-j\\omega n_0}X(e^{j\\omega})\n$$</div>\n\n<ul>\n<li>共轭对称性</li>\n</ul>\n<div>$$\nx_e[n] \\lrarr \\text{Re}\\lbrace X(e^{j\\omega}) \\rbrace\n$$</div>\n\n<div>$$\nx_o[n] \\lrarr \\text{Im}\\lbrace X(e^{j\\omega}) \\rbrace\n$$</div>\n\n<p>下面是修正后的表格：</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">序列 $x[n]$</th>\n<th align=\"center\">DTFT $X(e^{j\\omega})$</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$x[n]$</td>\n<td align=\"center\">$X(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x^*[n]$</td>\n<td align=\"center\">$X^*(e^{-j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x^*[-n]$</td>\n<td align=\"center\">$X^*(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_R[n]$</td>\n<td align=\"center\">$X_e(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$jx_I[n]$</td>\n<td align=\"center\">$X_o(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_e[n]$</td>\n<td align=\"center\">$X_R(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_o[n]$</td>\n<td align=\"center\">$jX_I(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">以下为实信号</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\">$x[n] &#x3D; x^*[n]$</td>\n<td align=\"center\">，$X(e^{j\\omega}) &#x3D; X^*(e^{-j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_e[n] &#x3D; \\frac{1}{2}(x[n] + x[-n])$</td>\n<td align=\"center\">$X_R(e^{j\\omega})$ 实、偶函数</td>\n</tr>\n<tr>\n<td align=\"center\">$x_o[n] &#x3D; \\frac{1}{2}(x[n] - x[-n])$</td>\n<td align=\"center\">$jX_I(e^{j\\omega})$  虚、奇函数</td>\n</tr>\n</tbody></table>\n<ul>\n<li>卷积与相关性质<ul>\n<li>时域卷积： $x[n] * y[n] \\lrarr X(e^{j\\omega})\\cdot Y(e^{j\\omega})$</li>\n<li>频域卷积：$x[n] \\cdot y[n] \\lrarr \\frac{1}{2\\pi}X(e^{j\\omega}) * Y(e^{j\\omega})$</li>\n<li>时域相关：<ul>\n<li>互相关：$r_{xy}[k] &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}x[n]y^*[n - k]$</li>\n<li>自相关：$r_{xx}[k] &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}x[n]x^*[n - k]$</li>\n<li>$R_{xy}(e^{j\\omega}) &#x3D; X(e^{j\\omega}) \\cdot Y^*(e^{j\\omega})$</li>\n<li>$R_{xx}(e^{j\\omega}) &#x3D; X(e^{j\\omega}) \\cdot X^*(e^{j\\omega})$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>DTFT的存在条件：</strong></p>\n<p>取决于 $\\sum\\limits_{n&#x3D;-\\infty}^{\\infty}x[n]e^{-j\\omega n}$ 的收敛性</p>\n<p>有限和序列 $X_N(e^{j\\omega}) &#x3D;\\sum\\limits_{n&#x3D;-N}^{N}x[n]e^{-j\\omega n}$</p>\n<ul>\n<li>若 $x[n]$ 绝对可和，则 DTFT 存在，且一致收敛</li>\n<li>若序列满足平方可和，则 DTFT 满足均方收敛性<ul>\n<li>截断误差的能量趋于0，但是某些点的误差的绝对值不一定趋于0（例如理想低通滤波器，有吉布斯现象，在截止频率附近存在一个独立于 $N$ 的震荡，即使 $N$ 趋于无穷，在某些频率点上还是存在9%左右的误差）</li>\n</ul>\n</li>\n</ul>\n<p><strong>特殊信号的 DTFT</strong></p>\n<ul>\n<li>符号序列</li>\n</ul>\n<div>$$\n\\text{sgn}[n] = \\begin{cases}\n    1, &n\\gt 0,\\\\\n    0, &n = 0\\\\\n    -1, &n \\lt 0\n\\end{cases} \\lrarr \\text{SGN}(e^{j\\omega}) = \\frac{1}{j} \\cot \\left(\\frac{\\omega}{2}\\right)\n$$</div>\n\n<ul>\n<li>阶跃序列</li>\n</ul>\n<div>$$\nu[n] = \\frac{1}{2}(\\text{sgn}[n] + 1) + \\frac{1}{2} \\delta[n] \\lrarr U(e^{j\\omega}) = \\frac{1}{1 - e^{-j\\omega} + \\pi} + \\pi\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - 2\\pi k)\n$$</div>\n\n<ul>\n<li>离散周期单位冲激串</li>\n</ul>\n<div>$$\nx[n] =\\sum\\limits_{k=-\\infty}^{\\infty}\\delta[n - kN]\\lrarr X(e^{j\\omega}) =\\sum\\limits_{k=-\\infty}^{\\infty}e^{-j\\omega k N} = \\frac{2\\pi}{N}\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - \\frac{2k\\pi}{N})\n$$</div>\n\n<p>离散时限信号与周期单位冲激串的卷积，在频域上表现为对 DTFT 的采样，这正是从 DTFT 到 DFT 的过渡。</p>\n<h3 id=\"DFT\"><a href=\"#DFT\" class=\"headerlink\" title=\"DFT\"></a>DFT</h3><p>DTFT给出了离散信号频域的全部信息，但在实际应用中存在如下困难：</p>\n<ul>\n<li>实际信号往往没有解析表达式，无法计算其DTFT</li>\n<li>实际物理装置只能采集有限长度的数据</li>\n<li>DTFT给出的频谱是连续的，无法用数字设备记录和存储全部的值</li>\n</ul>\n<h4 id=\"DFT-的定义\"><a href=\"#DFT-的定义\" class=\"headerlink\" title=\"DFT 的定义\"></a>DFT 的定义</h4><div>$$\n\\begin{cases}\n    X[k] =\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n    x[n] =\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{-nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n\\end{cases}\n$$</div>\n\n<p>其中，</p>\n<div>$$\nW_N = e^{-j\\frac{2\\pi}{N}}\n$$</div>\n\n<h4 id=\"理解-DFT\"><a href=\"#理解-DFT\" class=\"headerlink\" title=\"理解 DFT\"></a>理解 DFT</h4><p>DFT 是 DTFT 的频域采样</p>\n<div>$$\nX(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{j\\omega n}\\\\\nX[k] = X(e^{j\\omega})\\big |_{\\omega_k = \\frac{2\\pi}{N}k} =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\frac{2\\pi}{N}kn}\n$$</div>\n\n<ul>\n<li><p>频域乘积等价于时域卷积，因此对离散序列在频域上以2𝜋&#x2F;𝑁为周期进行采样，等效于离散信号在时域上进行周期延拓，延拓周期为𝑁</p>\n</li>\n<li><p>为保证离散序列频域采样对应的时域序列不发生混叠，要求原离散序列为有限长且长度不超过𝑁。</p>\n</li>\n</ul>\n<h4 id=\"DFT-的频域重构\"><a href=\"#DFT-的频域重构\" class=\"headerlink\" title=\"DFT 的频域重构\"></a>DFT 的频域重构</h4><ul>\n<li>首先需要 $N \\ge L$</li>\n</ul>\n<div>$$\n\\begin{align*}\n    X(e^{j\\omega}) &=\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\omega n} =\\sum\\limits_{n=0}^{N - 1}\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}X[k]e^{j\\frac{2k\\pi}{N}n}\\bigg]e^{-j\\omega n}\\\\\n    &=\\sum\\limits_{k=0}^{N - 1}X[k]\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}e^{-j(\\omega - \\frac{2k\\pi}{N}n)}\\bigg]\\\\\n    &=\\sum\\limits_{k=0}^{N - 1} X[k]P\\bigg(\\omega - \\frac{2k\\pi}{N}\\bigg)\n\\end{align*}\n$$</div>\n\n<p>其中，内插函数</p>\n<div>$$\nP(\\omega) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1} e^{-j\\omega n} = \\frac{1}{N}\\frac{\\sin (\\omega N / 2)}{\\sin (\\omega / 2)}e^{-j \\frac{N - 1}{2}\\omega}\n$$</div>\n\n<h4 id=\"理解-DFT-II\"><a href=\"#理解-DFT-II\" class=\"headerlink\" title=\"理解 DFT II\"></a>理解 DFT II</h4><p>离散正交变换的定义：</p>\n<ul>\n<li>定义变换矩阵 $A$， 若 $A$ 满足 $A^HA &#x3D; cI$，其中$c$为常数，则称 $X &#x3D; Ax$ 为离散正交变换。若 $c &#x3D; 1$，则称变换是归一化的。</li>\n<li>归一化的离散正交变换满足 Parseval 定理：$||X||^2 &#x3D; X^HX &#x3D; x^HA^HAx &#x3D; x^Hx &#x3D; ||x||^2$</li>\n</ul>\n<p>DFT 是对离散时间信号的加权求和，其向量形式</p>\n<ul>\n<li>$X[k] &#x3D; w_k^Hx$, $w_k &#x3D; [e^{j\\frac{2\\pi0k}{N}}, e^{j\\frac{2\\pi1k}{N}}, \\dots, e^{j\\frac{2\\pi(N - 1)k}{N}}]^T$</li>\n<li>$X &#x3D; [X[0], X[1], \\dots, X[N - 1]]^T$，则有$X &#x3D; [w_0, w_1, \\dots, w_{N - 1}]^Hx &#x3D; W_Nx$</li>\n</ul>\n<div>$$\nX = W_Nx\\\\\nx = \\frac{1}{N} W_N^HX\n$$</div>\n\n<h4 id=\"DFT-的周期延拓\"><a href=\"#DFT-的周期延拓\" class=\"headerlink\" title=\"DFT 的周期延拓\"></a>DFT 的周期延拓</h4><p>• DFT本意是用有限个离散频域样本来表示有限长离散序列</p>\n<p>– 时域采样对应着频域周期延拓，频域采样对应着时域周期延拓</p>\n<p>• 由于周期延拓，DFT总是面对着周期序列</p>\n<p>– 在DFT计算和应用中，总是选择时域和频域的主值区间</p>\n<p>– DFT这种隐含的周期性决定了其与DTFT具有不同的性质</p>\n<p><strong>周期延拓的数学表示</strong></p>\n<div>$$\n\\big((n)\\big)_N\n$$</div>\n\n<p>周期延拓可以表示为：</p>\n<div>$$\n\\tilde X[k] = X\\bigg[\\big((k)\\big)_N\\bigg]\n\\tilde x[n] = X\\bigg[\\big((n)\\big)_N\\bigg]\n$$</div>\n\n<p>也可表示为卷积和：</p>\n<div>$$\n\\tilde{X}[k] = X[k] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[k - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}X[k - mN]\\\\\\tilde{x}[n] = x[n] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[n - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}x[n - mN]\n$$</div>\n\n<h4 id=\"DFT-性质\"><a href=\"#DFT-性质\" class=\"headerlink\" title=\"DFT 性质\"></a>DFT 性质</h4><ul>\n<li>线性性<ul>\n<li>前提：变换长度 $N$ 相同</li>\n<li>如果不相同，补零到长度 $N \\ge \\max(N_1, N_2)$</li>\n</ul>\n</li>\n<li>反转性质：若时域循环反转，则频域循环反转<ul>\n<li>$\\text{DFT} \\Bigg\\lbrace x\\big[\\big((-n)\\big)_N\\bigg] R_N[n]\\Bigg\\rbrace &#x3D; X\\bigg[\\big((-k)\\big)_N\\bigg] R_N[k]$</li>\n<li>0 时刻不变，其余前后反转</li>\n</ul>\n</li>\n<li>共轭性质：若时域共轭，则频域共轭且循环反转<ul>\n<li>$\\text{DFT}\\lbrace x^*[n]\\rbrace &#x3D; X^*[N - k]$</li>\n</ul>\n</li>\n<li>对偶性质：序列的DFT的DFT<ul>\n<li>$\\text{DFT}\\lbrace X[n]\\rbrace &#x3D; NX^*[N - k]$</li>\n</ul>\n</li>\n<li>周期序列的共轭对称性：<ul>\n<li>共轭对称：$x_{ep}[n] &#x3D; x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$</li>\n<li>共轭反对称：$x_{ep}[n] &#x3D; -x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$</li>\n<li>任意有限长序列的周期延拓总可以分解为周期共轭对称和反对称的分量和的形式<ul>\n<li>$x[n] &#x3D; x_{ep}[n] + x_{op}[n]$</li>\n<li>$x_{ep}[n] &#x3D; \\frac12 (x[n] + x^*\\bigg[\\big((-n)\\big)_N\\bigg])$</li>\n<li>$x_{op}[n] &#x3D; \\frac12 (x[n] - x^*\\bigg[\\big((-n)\\big)_N\\bigg])$</li>\n</ul>\n</li>\n<li>实序列的DFT是周期共轭对称序列</li>\n<li>虚序列的DFT是周期共轭反对称序列</li>\n<li>周期共轭对称序列的DFT是实的</li>\n<li>周期共轭反对称序列的DFT是虚的</li>\n</ul>\n</li>\n<li>循环卷积性质：<ul>\n<li>有限长循环移位的 DFT 可以由原序列 DFT 乘上一个线性的相位因子得到：$\\text{DFT}\\Bigg \\lbrace\\bigg[x\\big((n - m)\\big)_N\\bigg]\\Bigg \\rbrace &#x3D; X[k]e^{-j\\frac{2\\pi k}{N}m}$</li>\n<li>在 DTFT 中：$x[n] * y[n] &#x3D; \\text{IDTFT}\\lbrace X(e^{j\\omega}) \\cdot Y(e^{j\\omega})\\rbrace$</li>\n<li>DFT 中：$x[n] \\circledast y[n] &#x3D;\\sum\\limits_{m&#x3D;0}^{N - 1}x[m]y\\bigg[\\big((n - m)\\big)<em>N\\bigg] &#x3D;\\sum\\limits</em>{m&#x3D;0}^{N - 1}x\\bigg[\\big((n - m)\\big)_N\\bigg]y[m]$</li>\n</ul>\n</li>\n<li>Parseval 定理：<ul>\n<li>$\\sum\\limits_{n&#x3D;0}^{N - 1}|x[n]|^2 &#x3D; \\frac{1}{N}\\sum\\limits_{k&#x3D;0}^{N - 1}|X[k]|^2$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"FFT\"><a href=\"#FFT\" class=\"headerlink\" title=\"FFT\"></a>FFT</h2><p>FFT 算法是一大类 DFT 快速算法的总称。</p>\n<ul>\n<li>基 2 FFT 算法：$N &#x3D; 2^m$</li>\n<li>基 4 FFT 算法：$N &#x3D; 4^m$</li>\n<li>分裂基算法：基本蝶形是倒 L 型，$N &#x3D; 2^m$</li>\n<li>组合数 FFT 算法：变换点数为组合数，即$N &#x3D; N_1N_2$</li>\n</ul>\n<p>根据处理基本蝶形的结构特点，可以分为：</p>\n<ul>\n<li>DIT (Decimation-In-Time)</li>\n<li>DIF (Decimation-In-Frequency)</li>\n</ul>\n<h3 id=\"基-2-DIT-FFT-算法\"><a href=\"#基-2-DIT-FFT-算法\" class=\"headerlink\" title=\"基 2 DIT-FFT 算法\"></a>基 2 DIT-FFT 算法</h3><p>按照奇偶时间拆分成两个短序列。</p>\n<p>长序列的 DFT 可以由两个短序列的 DFT 组合得到。</p>\n<div>$$\nX[k] = \\sum\\limits_{m=0}^{N/2 - 1}x[2m]W_N^{2mk} + \\sum\\limits_{m=0}^{N/2 - 1} x[2m + 1]W_N^{(2m + 1)k}\\\\\nf_1[n] = x[2n], f_2[n] = x[2n + 1]\\\\\nX[k] = F_1[k] + W_N^kF_2[k]\\\\\nX[k + N/2] = F_1[k] - W_N^kF_2[k]\n$$</div>\n\n<p>反复抽取，变成2点 DFT：</p>\n<div>$$\n\\begin{bmatrix}\n    X[0]\\\\\n    X[1]\n\\end{bmatrix} = \\begin{bmatrix}\n    x[0] + x[1]\\\\\n    x[0] - x[1]\n\\end{bmatrix}\n$$</div>\n\n<p><img src=\"/../images/DSP/4_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>计算复杂度：</p>\n<ul>\n<li>乘法次数为$\\frac{N}{2}\\log_2N$，$m_a &#x3D; Nm &#x3D; N\\log_2 N$</li>\n</ul>\n<p>输入和输出序列的顺序关系：二进制下的倒序关系。</p>\n<ul>\n<li>每次均分时，输入序列按照奇偶性划分，输出序列按照是否过半划分</li>\n<li>输入序列的奇偶性等价于最低位为1还是0，输出序列是否过半等价于最高位为1还是0</li>\n<li>因此输入映射到输出序列是低位映射到高位的关系。</li>\n</ul>\n<h2 id=\"数字频谱分析\"><a href=\"#数字频谱分析\" class=\"headerlink\" title=\"数字频谱分析\"></a>数字频谱分析</h2><h3 id=\"DFT-谱分析的基本概念\"><a href=\"#DFT-谱分析的基本概念\" class=\"headerlink\" title=\"DFT 谱分析的基本概念\"></a>DFT 谱分析的基本概念</h3><p>频谱：信号经过傅里叶变换转换到频域后，其频域表示的幅度和相位随频率变化的关系分别称为信号的幅度谱和相位谱</p>\n<p>基于 DFT 的数字频谱分析</p>\n<p>利用离散信号 DFT 结果 $X[k]$ 与原连续信号频谱 $X_a(j\\Omega)$ 之间存在对应关系来获得连续信号的频谱。</p>\n<div>$$\nX[k] = X(e^{j\\omega})|_{\\omega = \\frac{2\\pi}{N}k}\n$$</div>\n\n<div>$$\nX(e^{j\\omega}) = \\frac{1}{T_s}X_a(j\\Omega)|_{\\Omega = \\frac{\\omega}{T_s}}\n$$</div>\n\n<div>$$\n X_a(j\\Omega_k)= T_s X[k]\n$$</div>\n\n<p>利用 DFT 结果获得连续信号的频谱：</p>\n<div>$$\nX_a(j\\Omega_k) = X_a \\left ( j\\frac{2\\pi k}{NT_s} \\right) = \\begin{cases}\n    T_sX[k], 0 \\le k \\le \\lceil \\frac{N}{2} \\rceil, \\\\\n    T_sX[k + N], - \\lceil \\frac{N - 1}{2} \\rceil\\le k \\lt 0\n\\end{cases}\n$$</div>\n\n<p>基于DFT的频谱分析方法存在的问题</p>\n<ul>\n<li>理论上连续正弦信号的频谱应为冲激函数，但DFT结果为有限值</li>\n<li>DFT结果在连续正弦信号频谱幅度为0的位置却不为零</li>\n</ul>\n<h3 id=\"DFT-谱分析的一般过程\"><a href=\"#DFT-谱分析的一般过程\" class=\"headerlink\" title=\"DFT 谱分析的一般过程\"></a>DFT 谱分析的一般过程</h3><h4 id=\"抗混叠滤波\"><a href=\"#抗混叠滤波\" class=\"headerlink\" title=\"抗混叠滤波\"></a>抗混叠滤波</h4><p><img src=\"/../images/DSP/5_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"采样\"><a href=\"#采样\" class=\"headerlink\" title=\"采样\"></a>采样</h4><p>提高采样率</p>\n<ul>\n<li>优点：能够无混叠分析的信号带宽增大</li>\n<li>缺点：数据率提高，系统复杂度增加，成本上升</li>\n</ul>\n<h4 id=\"加窗\"><a href=\"#加窗\" class=\"headerlink\" title=\"加窗\"></a>加窗</h4><p>由于DFT只能处理有限长序列，需要对输入信号<br>通过加窗进行截断</p>\n<ul>\n<li>窗长可根据频率分辨率、实时性和设备存储能力的要<br>求来权衡</li>\n<li>窗函数的形式也可根据主瓣宽度和旁瓣电平进行选择</li>\n</ul>\n<div>$$\nw_R[n] = \\begin{cases}\n    1, 0 \\le n \\lt M\\\\\n    0, \\text{others}\n\\end{cases}\n$$</div>\n\n<div>$$\nx_w[n] = x[n]w_R[n]\n$$</div>\n\n<h4 id=\"DFT计算、插值及频谱输出\"><a href=\"#DFT计算、插值及频谱输出\" class=\"headerlink\" title=\"DFT计算、插值及频谱输出\"></a>DFT计算、插值及频谱输出</h4><p>DFT计算</p>\n<ul>\n<li>可能需要补零，以获得更密集的频域采样，以及使变换点数𝑁满足FFT算法的要求（基2-FFT、基4-FFT）</li>\n</ul>\n<p>插值</p>\n<ul>\n<li>由DFT结果获得DTFT的估计值</li>\n<li>插值方法：<ul>\n<li>精确插值： $X(e^{j\\omega}) &#x3D;\\sum\\limits_{k&#x3D;0}^{N - 1} X[k] P \\left ( \\omega - \\frac{2\\pi k}{N} \\right)$, $P(\\omega) &#x3D; \\frac{\\sin(\\omega N&#x2F;2)}{\\sin(\\omega&#x2F;2)}e^{-j\\frac{N-1}{2}\\omega}$</li>\n<li>近似插值：线性插值，二次插值</li>\n</ul>\n</li>\n</ul>\n<p>连续信号频谱输出<br>– 通过坐标变换得到连续信号频谱 $X_a(j\\Omega) &#x3D; T_sX(e^{j\\Omega T_s})$</p>\n<h3 id=\"DFT-谱分析问题\"><a href=\"#DFT-谱分析问题\" class=\"headerlink\" title=\"DFT 谱分析问题\"></a>DFT 谱分析问题</h3><h4 id=\"谱分析滤波器\"><a href=\"#谱分析滤波器\" class=\"headerlink\" title=\"谱分析滤波器\"></a>谱分析滤波器</h4><div>$$\ns(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega t}\\mathrm d\\Omega\\\\\ns(nT_s) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega nT_s}\\mathrm d\\Omega\\\\\nx[n] = \\begin{cases}\n    s(nT_s), n = 0, 1, \\dots, M - 1,\\\\\n    0, M, M + 1, \\dots, N - 1\n\\end{cases}\\\\\nX[k] =\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\frac{2\\pi nk}{N}} = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n}\\mathrm d\\Omega\n$$</div>\n\n<p>令 $\\theta &#x3D; T_s(\\Omega - \\Omega_k)$，</p>\n<div>$$\n\\varphi_k(M, \\theta) = \\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n} = \\frac{\\sin(M\\theta / 2)}{\\sin(\\theta/2)} e^{j\\frac{M - 1}{2}\\theta}\n$$</div>\n\n<p>梳状滤波特性</p>\n<p><img src=\"/../images/DSP/5_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>周期内存在多个过零点，把滤波器响应分割成多个区间</p>\n<ul>\n<li>主瓣：谱分析滤波器频率响应最大的那个区间</li>\n<li>主峰：主瓣中最大频率响应点 $Ω &#x3D; \\frac{2\\pi k}{NT_s}$处，高度为𝑀</li>\n<li>主瓣宽度：主瓣两边过零点之间的距离4𝜋⁄𝑀𝑇𝑠</li>\n<li>旁瓣：除响应最大的那个区间外的其它区间</li>\n</ul>\n<p>DFT频谱分析方法能否反映连续信号的频谱？</p>\n<ul>\n<li>DFT的结果主要给出了连续信号落在相应谱分析滤波器主瓣内的那部分信号的频域信息</li>\n<li>由于相邻谱分析滤波器主瓣间有交叠，同一个信号可能会在相邻两个谱分析滤波器都有响应</li>\n<li>谱分析滤波器的旁瓣会在其他谱分析滤波器的主瓣位置出现，其对应的DFT结果不可避免的包含了其他滤波器主瓣位置处的信号成分</li>\n</ul>\n<p>DFT 可用于连续信号的频谱分析，但由于其谱分析滤波器频率分割不理想的本质，必须对其输出结果进行小心的解释</p>\n<p>DFT谱估计得到的是对加窗后序列DTFT的采样</p>\n<div>$$\nx_w[n] = x[n]w_R[n]\\\\\nX_w(e^{j\\omega}) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}X(e^{j\\omega})W_R(e^{j(\\omega - \\theta)})\\mathrm d\\theta\n$$</div>\n\n<p>对于矩形窗：</p>\n<div>$$\nW_R(e^{j\\omega}) = \\text{DTFT}(w_R[n]) = \\frac{\\sin(M\\omega / 2)}{\\sin(\\omega/2)} e^{-j\\frac{M - 1}{2}\\omega}\n$$</div>\n\n<p>频率分辨力的定义：两个等幅单频信号能够被区分开的最小频率间隔</p>\n<p>矩形窗的主瓣宽度为 $4\\pi&#x2F;MT_s$</p>\n<p>实际工程中，采用 3dB带宽并加上适当余量作为频率分辨力</p>\n<ul>\n<li>矩形窗的数字角频率分辨力为 $\\Delta \\omega &#x3D; 2\\pi &#x2F; M$</li>\n<li>连续信号的分辨力为 $\\Delta f &#x3D; f_s&#x2F;M$</li>\n</ul>\n<p>分辨力仅决定于信号时长 $MT_s$。</p>\n<p>混叠效应</p>\n<p>混叠效应本质上由采样过程引起</p>\n<ul>\n<li>混叠效应带来的问题</li>\n<li>如果采样过程带来了混叠，DFT结果无法将已混叠的频<br>率分量分开</li>\n<li>采样之前作抗混叠滤波，把带外频率成分滤除</li>\n<li>增大采样频率（减小采样周期）<br>– 无法仅从DFT结果中判读原连续信号的模拟频率</li>\n<li>需要原连续信号频率分布或抗混叠滤波通带的先验<br>知识</li>\n</ul>\n<p>栅栏效应</p>\n<ul>\n<li>DFT 无法精确表示不在离散采样点的频率值</li>\n<li>频率估计的最大误差为 $\\pi &#x2F; N$</li>\n<li>可以通过加窗补零（增大 $N$）的方法改善</li>\n<li>通过局部插值的方法获得更精确的频率估计：精确插值，线性插值，二次插值</li>\n</ul>\n<h2 id=\"DFT-的应用\"><a href=\"#DFT-的应用\" class=\"headerlink\" title=\"DFT 的应用\"></a>DFT 的应用</h2><h3 id=\"线性卷积的计算\"><a href=\"#线性卷积的计算\" class=\"headerlink\" title=\"线性卷积的计算\"></a>线性卷积的计算</h3><p>假设有限长因果序列 $h[n]$ 和 $x[n]$，长度分别为 $P$ 和 $L$，均扩展到 $N$ 个点进行卷积</p>\n<ul>\n<li>当 $N \\ge P + L - 1$ 时，两种卷积的结果相等</li>\n<li>当 $N \\lt P + L - 1$ 时，循环卷积出现混叠</li>\n</ul>\n<p>基于 DFT 的 FIR 滤波器实现</p>\n<p>FIR 滤波器需要计算有限长序列和无限长序列的线性卷积</p>\n<ul>\n<li>$h[n]$ 有限</li>\n<li>$x[n]$ 无限</li>\n</ul>\n<p>方法1：重叠相加法</p>\n<div>$$\nx[n] =\\sum\\limits_{r=0}^{\\infty}x_r[n - rL]\\\\\ny[n] = h[n] * \\sum\\limits_{r=0}^{\\infty}x_r[n - rL] = \\sum\\limits_{r=0}^{\\infty}h[n] * x_r[n - rL]\\\\\n$$</div>\n\n<p>整个序列的线性卷积等于各段线性卷积后的移位加和</p>\n<p>IDFT 后，需要一个专门的加法器进行重叠部分的相加运算</p>\n<p>方法二：重叠保留法</p>\n<p>取 $L$ 点 $x[n]$ 与扩展的 $P$ 点 $h[n]$ 做循环卷积，取结果的后 $L - P + 1$ 个点作为结果。</p>\n<p>两种方法、直接计算线性相关的计算量对比？</p>\n<h3 id=\"线性调频-z-变换\"><a href=\"#线性调频-z-变换\" class=\"headerlink\" title=\"线性调频 z 变换\"></a>线性调频 z 变换</h3><p>CZT 的定义</p>\n<div>$$\nX_{cz}(z)|_{z = z_k} =\\sum\\limits_{n=0}^{N - 1}x[n]z_k^{-n}\\\\\nz_k = AW^{-k} = (A_0e^{j\\theta_0})(W_0e^{-j\\varphi_0})^{-k}\n$$</div>\n\n<p>一种广义的 DFT，在复平面螺旋线上的采样。</p>\n<p>CZT 的计算</p>\n<ul>\n<li>利用定义直接计算</li>\n<li>利用卷积计算，而卷积可以利用 FFT 计算</li>\n</ul>\n<div>$$\nX_{cz}(z_k) = W^{\\frac{k^2}{2}}\\sum\\limits_{n=0}^{N - 1}f[n]h[k - n]\\\\\nf[n] = x[n]A^{-n}W^{\\frac{n^2}{2}}\\\\\nh[n] = W^{-\\frac{n^2}{2}}\n$$</div>\n\n<h3 id=\"短时傅里叶变换\"><a href=\"#短时傅里叶变换\" class=\"headerlink\" title=\"短时傅里叶变换\"></a>短时傅里叶变换</h3><p>问题：基于傅里叶的频谱分析可以指导信号观测窗内的频率成分，但是无法得知这些频率成分何时出现，何时消失，持续多久</p>\n<p>定义</p>\n<div>$$\n\\text{STFT}(t^\\prime, \\Omega) = \\int_{-\\infty}^{\\infty}x(\\tau)g^*(\\tau - t^\\prime)e^{-j\\Omega\\tau}\\mathrm d\\tau\n$$</div>\n\n<ul>\n<li>窗的长度<ul>\n<li>窗长需要足够短，确保落入窗的信号近似平稳</li>\n<li>窗越长，频率分辨率越高，窗越短，时间分辨率越高<ul>\n<li>窗无限长，退化成 FT</li>\n<li>无限短，退化成 $s(t^\\prime)e^{-j\\Omega t^\\prime}$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>窗的类型<ul>\n<li>矩形窗，汉明窗，布莱克曼窗</li>\n<li>主瓣宽度与旁瓣电平之间的权衡</li>\n</ul>\n</li>\n</ul>\n<p>不确定性原理</p>\n<div>$$\n\\Delta t \\cdot \\Delta \\Omega \\ge \\frac{1}{2}\n$$</div>\n\n\n<h2 id=\"LTI-系统\"><a href=\"#LTI-系统\" class=\"headerlink\" title=\"LTI 系统\"></a>LTI 系统</h2><h3 id=\"LTI-系统的时域分析——冲激响应\"><a href=\"#LTI-系统的时域分析——冲激响应\" class=\"headerlink\" title=\"LTI 系统的时域分析——冲激响应\"></a>LTI 系统的时域分析——冲激响应</h3><p>根据冲激响应长度不同：</p>\n<ul>\n<li>FIR:用 $h[n]$ 表示系统</li>\n<li>IIR：用系统函数或者差分方程表示</li>\n</ul>\n<h3 id=\"LTI-系统的时域分析——冲激响应-1\"><a href=\"#LTI-系统的时域分析——冲激响应-1\" class=\"headerlink\" title=\"LTI 系统的时域分析——冲激响应\"></a>LTI 系统的时域分析——冲激响应</h3><p>复指数序列是 LTI 系统的特征函数</p>\n<div>$$\nT \\lbrace e^{j\\omega n} \\rbrace = H(e^{j\\omega})e^{j\\omega n}\n$$</div>\n\n<p>频率响应函数的表示方式</p>\n<ul>\n<li>$H(e^{j\\omega}) &#x3D; H_R(e^{j\\omega}) + jH_I(e^{j\\omega})$</li>\n<li>$H(e^{j\\omega}) &#x3D; |H(e^{j\\omega})|e^{j\\angle H(e^{j\\omega})}$</li>\n<li>幅频特性：<ul>\n<li>$|H(e^{j\\omega})|$</li>\n<li>$20\\log |H(e^{j\\omega})|$，单位 dB</li>\n</ul>\n</li>\n<li>相频特性<ul>\n<li>$arg(H(e^{j\\omega}))$：连续相位</li>\n<li>$Arg(H(e^{j\\omega}))$：主值相位</li>\n<li>无卷绕相位：$\\angle H(e^{j\\omega}) &#x3D; \\tan^{-1}\\frac{H_I(e^{j\\omega})}{H_R(e^{j\\omega})}$</li>\n<li>定义主值区间 $arg(H(e^{j\\omega})) &#x3D; ARG[H(e^{j\\omega})] + 2\\pi r(\\omega)$，$r(\\omega)$是补偿函数，仅取整数</li>\n</ul>\n</li>\n</ul>\n<p>相位延迟</p>\n<p>群延迟</p>\n<div>$$\n-\\frac{\\mathrm d}{\\mathrm d\\omega}\\text{arg}[H_{id}(e^{j\\omega})]\n$$</div>\n\n<p>可以表征窄带信号的相位失真（或者延迟）</p>\n<div>$$\nx[n] = a[n]e^{j\\omega_c n}\\\\\na[n] = c_1e^{j\\omega_1n}\\\\\ny[n] \\approx |H(e^{j\\omega_c})|c_1e^{j(\\omega_1 + \\omega_c)n + j\\varphi(\\omega_1 + \\omega_c)} \\approx |H(e^{j\\omega_c})|\\underbrace{a[n - \\tau_g(\\omega_c)]}_{群延迟给出了包络延迟}\\underbrace{e^{j\\omega_c[n - \\tau_p(\\omega_c)]}}_{相位延迟\\tau_p(\\omega_c) = \\varphi(\\omega_c)}\n$$</div>\n\n<h3 id=\"LTI-系统的零极点分析\"><a href=\"#LTI-系统的零极点分析\" class=\"headerlink\" title=\"LTI 系统的零极点分析\"></a>LTI 系统的零极点分析</h3><div>$$\n\\sum\\limits_{k=0}^{N}a_ky[n - k] =\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH[z] = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{\\sum\\limits_{k=0}^{N}a_kz^{-k}} = \\left ( \\frac{b_0}{a_0} \\right)\\frac{\\prod_{k = 1}^M(1 - c_kz^{-1})}{\\prod_{k = 1}^N(1 - d_kz^{-1})}\n$$</div>\n\n<p>$z &#x3D; 0, z &#x3D; \\infty$ 也可能是零点！求解的时候不要忘了。</p>\n<p>系统稳定性的条件：绝对可和。或者说 $H(z)$ 的极点在单位圆内。</p>\n<p>可逆性的条件：$h[n] * h_i[n] &#x3D; \\delta[n]$， $H(8z)H_i(z) &#x3D; 1$</p>\n<ul>\n<li>逆系统的极点和零点就是原系统的零点和极点</li>\n<li>逆系统和原系统必须有重叠的 ROC，因此可以确定逆系统的 ROC</li>\n</ul>\n<p>频率响应</p>\n<p>群延迟</p>\n<div>$$\n\\text{grd}[] =\\sum\\limits_{k=1}^{N}\\frac{|d_k|^2 - \\Re{d_ke^{-j\\omega}}}{1 + |d_k|^2 - 2\\Re{d_ke^{-j\\omega}}} - \\sum\\limits_{k=1}^{M}\\frac{|c_k|^2 - \\Re{c_ke^{-j\\omega}}}{1 + |c_k|^2 - 2\\Re{c_ke^{-j\\omega}}}\n$$</div>\n\n<h3 id=\"IIR滤波器\"><a href=\"#IIR滤波器\" class=\"headerlink\" title=\"IIR滤波器\"></a>IIR滤波器</h3><div>$$\ny[n] =\\sum\\limits_{k=1}^{N}a_ky[n - k] +\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH(z) = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{1 -\\sum\\limits_{k=1}^{N}a_kz^{-k}}\n$$</div>\n\n<p>直接 I 型</p>\n<p>直接 II 型：交换次序，合并延迟单元</p>\n<p>级联形式：</p>\n<div>$$\nH(z) = K \\prod_{k = 1}^{N_s} \\frac{b_{0k} + b_{1k}z^{-1} + b_{2k}z^{-2}}{1 - a_{1k}z^{-1} - a_{2k}z^{-2}}\n$$</div>\n\n<p>考虑到有限字长效应，级联形式可以以更加灵活的方式减小有限字长的影响。可以控制零点和极点的位置。</p>\n<p>级联形式也可以用直接 I, II 型实现。</p>\n<p>多径衰落就是一个 FIR 滤波器，因此具有频率选择特性。</p>\n<p>并联形式</p>\n<div>$$\nH(z) =\\sum\\limits_{k=0}^{N_p}C_kz^{-k} +\\sum\\limits_{k=1}^{N_2}\\frac{e_{0k}+e_{1k}z^{-1}}{1 - a_{1k} - a_{2k}z^{-2}}\n$$</div>\n\n<p>各子系统的计算误差互不影响，防止误差传递和放大，可控极点位置</p>\n<p>流图转置定理：支路方向取反，系数不变，输入和输出交换位置</p>\n<h3 id=\"FIR-滤波器\"><a href=\"#FIR-滤波器\" class=\"headerlink\" title=\"FIR 滤波器\"></a>FIR 滤波器</h3><div>$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n}\n$$</div>\n\n<p>抽头延迟线 or 横向滤波器结构</p>\n<p>具有转置形式</p>\n<p>级联形式</p>\n<div>$$\nH(z) = \\prod_{k = 1}^{M_1}(f_{0k} - f_{1k}z^{-1}\\prod_{k = 1}^{M_2}(b_{0k} + b_{1k} z^{-1} + b_{2k}z^{-2})\n$$</div>\n\n<p>线性相位特性</p>\n<div>$$\nH(e^{j\\omega}) = A(e^{j\\omega})e^{-j\\omega\\alpha}\n$$</div>\n\n<div>$$\nh[n] = h[M - n] (I, II)\\\\\nh[n] = - h[M - n] (III,IV)\n$$</div>\n\n<p>线性相位 FIR 滤波器的直接形式</p>\n<p>偶数</p>\n<div>$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] + x[n - M + k]) + h[M/2]x[n - M/2], &I type\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] - x[n - M + k]), &III type\n\\end{cases}\n$$</div>\n\n<p>奇数</p>\n<div>$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] + x[n - M + k]), &II type\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] - x[n - M + k]), &IV type\n\\end{cases}\n$$</div>\n\n<p>级联形式</p>\n<p>对应四种零点分布情况，有四种网络结构</p>\n<div>$$\nH(z) = 1 \\pm z^{-1}\\\\\nH(z) = 1 - 2\\cos(\\theta)z^{-1} + z^{-2}\\\\\nH(z) = (1 - rz^{-1})(1 - r^{-1}z^{-1})\\\\\nH(z) = 1 + bz^{-1} + cz^{-2} + bz^{-3} + z^{-4}\n$$</div>\n\n<h3 id=\"FIR-滤波器的频率取样结构\"><a href=\"#FIR-滤波器的频率取样结构\" class=\"headerlink\" title=\"FIR 滤波器的频率取样结构\"></a>FIR 滤波器的频率取样结构</h3><div>$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n} = \\frac{1}{N}(1 - z^{-N})\\sum\\limits_{k=0}^{N - 1}\\frac{H(k)}{1 - W_N^{-j}z^{-1}}\n$$</div>\n\n<p>$H(k)$ 是 FFT 变换。</p>\n<p>若冲激响应是实序列，可以用共轭对称性将成对的一阶子系统合称为二阶子系统</p>\n<div>$$\nH_k(z) + H_{-k}(z) = 2|H(k)| \\frac{\\cos\\theta(k) - (\\cos(\\theta(k) - \\frac{2\\pi}{N}k))z^{-1}}{1 - 2\\cos(\\frac{2\\pi}{N}k)z^{-1} + z^{-2}}\n$$</div>\n\n<p>其中 $\\theta(k)$ 是 $H(k)$ 的相位</p>\n<p>不成对的子系统？</p>\n<div>$$\nH_0(z) = \\frac{H(0)}{1 - z^{-1}}\\\\\nH_{N/2}(z) = \\frac{H(0)}{1 + z^{-1}}\n$$</div>\n\n<p>FIR 滤波器的时分复用结构</p>\n<h2 id=\"离散希尔伯特变换\"><a href=\"#离散希尔伯特变换\" class=\"headerlink\" title=\"离散希尔伯特变换\"></a>离散希尔伯特变换</h2><div>$$\nh[n] = \\begin{cases}\n    \\frac{1 - \\cos(n\\pi)}{n\\pi}, n \\ne 0\\\\\n    0, n = 0\n\\end{cases}\n$$</div>\n\n<h2 id=\"典型数字信号处理系统及其误差源\"><a href=\"#典型数字信号处理系统及其误差源\" class=\"headerlink\" title=\"典型数字信号处理系统及其误差源\"></a>典型数字信号处理系统及其误差源</h2><ul>\n<li>引起有限字长的误差源<ul>\n<li>AD 变换引入的误差</li>\n<li>有限精度引起的误差</li>\n<li>限制乘法运算位数的误差</li>\n<li>防止加法溢出压缩信号电平的误差</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"量化误差的统计分析模型\"><a href=\"#量化误差的统计分析模型\" class=\"headerlink\" title=\"量化误差的统计分析模型\"></a>量化误差的统计分析模型</h3><div>$$\nQ_B \\lbrace x[n] \\rbrace = x[n] + e[n]\\\\\n$$</div>\n\n<p>$e[n]$ 是各态历经的平稳随机序列，与 $x[n]$ 相互统计独立，具有白噪声的性质，不同时刻的取值相互独立，是均匀分布的。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"绪论\"><a href=\"#绪论\" class=\"headerlink\" title=\"绪论\"></a>绪论</h2><h3 id=\"信号\"><a href=\"#信号\" class=\"headerlink\" title=\"信号\"></a>信号</h3><p>信号是某种随时间或&#x2F;和空间变化的物理量，其包含有从信源到信宿的某种信息。</p>\n<p>信号可以根据时间和幅度的取值方式分类</p>\n<ul>\n<li>连续时间信号</li>\n<li><ul>\n<li>在时间和幅度上均可以连续取值的信号</li>\n</ul>\n</li>\n<li>离散时间信号</li>\n<li><ul>\n<li>仅在离散时间点上取值，但可在幅度上连续取值的<br>信号</li>\n</ul>\n</li>\n<li>数字信号</li>\n<li><ul>\n<li>仅在离散时间点上取值，且在幅度上只能离散取值<br>的信号</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"系统\"><a href=\"#系统\" class=\"headerlink\" title=\"系统\"></a>系统</h3><ul>\n<li>由若干相互作用和相互依赖的事物组合而成的具有特<br>定功能的整体</li>\n<li>具有它自身的结构、行为和性质，通过输入和输出与<br>其所处的环境进行交互，通常实现一定的功能</li>\n<li>可通过分析给定输入下输出的性质，来研究其行为和<br>性质</li>\n</ul>\n<p>信号处理系统</p>\n<ul>\n<li>对信号进行某种操作的单元或模块</li>\n<li>从数学上看，可视为作用于函数上的算子</li>\n</ul>\n<p>通常根据信号处理单元而非输入输出信号性质分类</p>\n<ul>\n<li>连续（模拟）信号处理系统</li>\n<li><ul>\n<li>由电阻、电容、电感和放大器等组成的模拟电路完成信号处<br>理功能</li>\n</ul>\n</li>\n<li><ul>\n<li>直接处理连续信号</li>\n</ul>\n</li>\n<li>离散信号处理系统</li>\n<li><ul>\n<li>由CCD、电容和放大器等组成的离散电路完成信号处理功能</li>\n</ul>\n</li>\n<li><ul>\n<li>处理由连续信号采样而来的离散时间信号</li>\n</ul>\n</li>\n<li>数字信号处理系统</li>\n<li><ul>\n<li>信号处理功能由数字逻辑电路或通用计算机来完成</li>\n</ul>\n</li>\n<li><ul>\n<li>处理数字信号（例如来源于对连续信号的采样和量化）</li>\n</ul>\n</li>\n</ul>\n<p>模拟 -&gt; 采样量化 -&gt; 数字信号处理系统 -&gt; 模拟重建 -&gt; 模拟输出信号</p>\n<h3 id=\"数字信号处理的局限\"><a href=\"#数字信号处理的局限\" class=\"headerlink\" title=\"数字信号处理的局限\"></a>数字信号处理的局限</h3><ul>\n<li>ADC和DAC器件的处理能力</li>\n<li><ul>\n<li>是否能够准确提取出原连续信号中的信息首先决定于<br>ADC：采样率、量化位数、时钟抖动、线性度等</li>\n</ul>\n</li>\n<li>精度受量化和舍入误差影响</li>\n<li><ul>\n<li>有限字长效应：数字系统中数字表示和计算精度受字<br>长限制</li>\n</ul>\n</li>\n<li>适合于数字处理的信号带宽受处理能力的限制</li>\n<li><ul>\n<li>例如，信号带宽10MHz、采样率20MHz、FIR滤波器阶<br>数为500，则所需计算量为每秒10G次的乘累加</li>\n</ul>\n</li>\n<li><ul>\n<li>如果带宽为1GHz呢?</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"数字信号处理的发展\"><a href=\"#数字信号处理的发展\" class=\"headerlink\" title=\"数字信号处理的发展\"></a>数字信号处理的发展</h3><ul>\n<li>20世纪初至50年代有许多前期的研究工作，从采样<br>定理的建立到声码器的数字仿真实验等，奠定了理论<br>基础</li>\n<li>1965年FFT的提出，是DSP发展的里程碑 （但其源头<br>可追溯到高斯时代）</li>\n<li>离散变换的进展：65年FFT，70年代余弦变换，80年<br>代中后期小波变换</li>\n<li>滤波器设计技术：IIR、FIR数字滤波器，多采样处理<br>和滤波器组理论，专用滤波器设计，小波滤波</li>\n<li>统计和自适应信号处理，阵列处理等，从统计学引入<br>信号处理发展的另一条主线——现代信号处理</li>\n<li>器件和系统的发展对数字信号处理有积极推动</li>\n</ul>\n<h3 id=\"从模拟到数字\"><a href=\"#从模拟到数字\" class=\"headerlink\" title=\"从模拟到数字\"></a>从模拟到数字</h3><p>模拟信号的数字化：ADC</p>\n<p>采样：本课程主要考虑均匀采样。</p>\n<div>$$\nx[n] = x_a(nT) -\\infty \\lt n \\lt \\infty\\\\ \nf_s = 1/T\\\\\n\\Omega_s = 2\\pi f_s\n$$</div>\n\n<p>采样的实现：采样保持电路</p>\n<p>采样周期：与被采样信号的频带参数一起决定了采样过程是否会发生混叠。</p>\n<p>采样过程的模糊性：采样过程可看作一种由连续信号空间到离散信号空间的多对一映射；对于给定的采样周期，仍存在无穷多个连续信号与同一离散信号对应。需要施加某种约束条件。</p>\n<p> 采样过程的基本问题：</p>\n<ul>\n<li>采样过程是否会引起被采样信号的信息丢失？</li>\n<li>被采样的连续信号是否能从采样样本中完全恢复？</li>\n<li>采样过程的频域分析可获得上述问题的答案</li>\n<li><ul>\n<li>推导得到采样后离散信号和采样前连续信号频谱间的数学关系</li>\n</ul>\n</li>\n<li><ul>\n<li>确定可以消除采样过程模糊性的条件</li>\n</ul>\n</li>\n<li><ul>\n<li>为实际数字信号处理系统设计中采样频率的选择、抗混叠前置滤波器的设计提供指导</li>\n</ul>\n</li>\n</ul>\n<p>采样的数学表示：</p>\n<div>$$\ns(t) = \\sum_{n = -\\infty}^{\\infty}\\delta(t - nT)\\\\\nx_s(t) = x_a(t) \\cdot s(t)\\\\\nx[n] = x_a(nT)\n$$</div>\n\n<p>对连续信号进行采样，其频谱是原始信号的周期延拓，延拓周期为采样频率</p>\n<div>$$\n\\begin{align*}\n\\text{时域} & \\quad \\quad \\text{频域} \\\\\nx_a(t) & \\quad \\quad X_a(j\\Omega)\\\\\ns(t) & \\quad \\quad S(j\\Omega) = \\frac{2\\pi}{T} \\sum_{k=-\\infty}^{+\\infty} \\delta(\\Omega - k\\Omega_s)\\\\\nx_a(t) \\cdot s(t) & \\quad \\quad X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a\\bigg(j(\\Omega - k\\Omega_s)\\bigg)\n\\end{align*}\n$$</div>\n\n<p>带限信号和带通信号：</p>\n<ul>\n<li>带限信号：$X_a(j\\Omega) &#x3D; 0, |\\Omega| \\ge \\Omega_H$</li>\n<li>带通信号：$X_a(j\\Omega) &#x3D; 0, |\\Omega| \\ge \\Omega_H\\text{ or }|\\Omega| \\le \\Omega_L$</li>\n</ul>\n<p>带限信号的采样：</p>\n<!-- int, sum, frac partial -->\n\n<div>$$\nX_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)], \\Omega_s \\ge 2\\Omega_H\n$$</div>\n\n<p>对应的离散时间序列：</p>\n<div>$$\nX(e^{j\\Omega T}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\Omega - k\\Omega_S)]\\\\\n\\Rightarrow X(e^{j\\omega}) = X_S(j\\Omega) = \\frac{1}{T} \\sum_{k=-\\infty}^{+\\infty} X_a[j(\\omega - 2\\pi k)/T]\\\\\n$$</div>\n\n<p>带通采样让时间以$T \\rightarrow 1$的形式进行归一化，频率以$\\Omega_s \\rightarrow 2\\pi$的形式进行归一化。</p>\n<p>Nyquist 采样定理：</p>\n<div>$$\nX_a(j\\Omega) = 0, \\forall |\\Omega| \\ge \\Omega_H\\\\\n\\Omega_s = 2\\pi / T \\gt 2\\Omega_H\n$$</div>\n\n<p>或者归一化频率</p>\n<div>$$\n\\omega_H = \\Omega_H T < \\pi\n$$</div>\n\n<p>Remark：</p>\n<ul>\n<li>$𝑥_𝑎(𝑡)$ 是基带、带限信号</li>\n<li>Nyquist是充分条件，即对被采样信号无其他假设</li>\n<li>在仅知道连续信号最高频率时，Nyquist采样定理给出<br>了由采样信号唯一确定（或恢复）原信号的条件</li>\n<li><ul>\n<li>已知连续信号最高频率，可用于确定最低采样频率</li>\n</ul>\n</li>\n<li><ul>\n<li>已知采样频率，可确定无混叠连续信号的最高频率</li>\n</ul>\n</li>\n</ul>\n<p>带通信号的采样：</p>\n<div>$$\n\\frac{2f_H}{m+1} \\le f_s \\le \\frac{2f_L}{m}, m\\in \\N ,m \\le f_L/B\n$$</div>\n\n<p>带限连续信号的重建：</p>\n<ul>\n<li>由离散序列𝑥[𝑛]和采样周期𝑇，恢复原连续信号$𝑥_𝑟(𝑡)$</li>\n<li>由序列到冲激串转换和重建滤波两个步骤构成</li>\n<li>重建后的信号表示为</li>\n</ul>\n<div>$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]h_r(t - nT)\n$$</div>\n\n<p>如选择截止频率$\\Omega_c &#x3D; \\pi&#x2F;T$的理想低通滤波器：</p>\n<div>$$\nx_r(t) = \\sum_{x = -\\infty}^{\\infty}x[n]\\frac{\\sin[\\pi(t - nT)/T]}{\\pi(t - nT)/T}\n$$</div>\n理想低通滤波器通过对冲激串信号的内插重建了原来的连续信号\n\n<p><strong>Summary</strong></p>\n<p>原信号：</p>\n<div>$$\nx_c(t) \\leftrightarrow X_c(j\\Omega)\n$$</div>\n\n<p>采样后的信号：</p>\n<div>$$\n\\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) = \\sum\\limits_{n=-\\infty}^{\\infty}x_c(t)\\delta(t - nT_s) \\leftrightarrow \\frac{1}{T_s}X(e^{j\\Omega T_s}) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}X_c(j(\\Omega - n\\Omega_s))\n$$</div>\n\n<p>数字域：</p>\n<div>$$\nx[n] \\leftrightarrow X(e^{j\\omega}) = \\frac{1}{T_s} X_c(j\\omega /T_s)\n$$</div>\n\n<p>恢复信号：</p>\n<div>$$\nh_r(t) \\leftrightarrow H_r(j\\Omega) = \\begin{cases}\n    T_s, &|\\Omega| \\le \\pi / T_s, \\\\\n    0,   &|\\Omega| \\gt \\pi / T_s\n\\end{cases}\\\\\n\\begin{align*}\n    x_r(t)  &= \\sum\\limits_{n=-\\infty}^{\\infty}x[n]\\delta(t - nT_s) * h_r(t)\\\\\n            &= \\sum\\limits_{n=-\\infty}^{\\infty} x_c(nT_s)h_r(t - nT_s)\\\\\n            &= x_c(t)\n\\end{align*}\\ \\leftrightarrow\\ \\begin{align*}\n    X_r(j\\Omega) &= T_s X(e^{j\\Omega T_s})H_r(j\\Omega)\\\\\n    &= X_c(j\\Omega)\n\\end{align*}\n$$</div>\n\n<p>数字时域和模拟时域之间的关系：</p>\n<div>$$\nn = \\frac{t}{T_s} = tf_s\n$$</div>\n\n<p>数字频域和模拟频域之间的关系：</p>\n<div>$$\n\\omega = \\Omega T_s = \\frac{2\\pi f}{f_s}\n$$</div>\n\n<h2 id=\"信号的表示\"><a href=\"#信号的表示\" class=\"headerlink\" title=\"信号的表示\"></a>信号的表示</h2><h3 id=\"离散信号的时域表示\"><a href=\"#离散信号的时域表示\" class=\"headerlink\" title=\"离散信号的时域表示\"></a>离散信号的时域表示</h3><ul>\n<li>时域表示方法<ul>\n<li>数学表达式：可表示基本信号，但大多数实际信号无解析表达式</li>\n<li>图形表示：直观、易理解，但不适用于刻画复杂信号</li>\n<li>数据表示：离散信号最一般的表示方法</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"离散信号的变换域表示\"><a href=\"#离散信号的变换域表示\" class=\"headerlink\" title=\"离散信号的变换域表示\"></a>离散信号的变换域表示</h3><ul>\n<li>定义：假设离散时间信号为𝑥[𝑛] ，定义映射𝑇{·}，那么信号的变换域表示可以写作𝑋 &#x3D; 𝑇{𝑥[𝑛]}<ul>\n<li>𝑇{·}是从函数空间到函数空间的映射</li>\n<li>𝑋并不要求一定定义在整数域上</li>\n</ul>\n</li>\n<li>常用情形：级数表示<ul>\n<li>将信号分解成有限项或无穷多项基本信号加权和的形式，由和式中每个基本信号的加权值组成的序列形成了原信号的变换域表示</li>\n<li>傅里叶级数展开 $x[n] &#x3D; \\sum_k a_k e^{j2\\pi kn &#x2F;T}$</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"离散信号的正交函数表示\"><a href=\"#离散信号的正交函数表示\" class=\"headerlink\" title=\"离散信号的正交函数表示\"></a>离散信号的正交函数表示</h3><ul>\n<li>使用信号空间的完备正交基来表示离散信号，<div>$$\n\\lbrace\\ldots ,\\varphi_0[n] ,\\varphi_1[n] ,\\varphi_2[n] , \\ldots\\rbrace\n$$</div></li>\n<li>正交性：<div>$$\n\\sum_{n} \\varphi_k^*[n] \\varphi_l[n] = \\delta_{kl}\n$$</div>\n其中，$k \\neq l$。</li>\n</ul>\n<ul>\n<li>完备性<ul>\n<li>任何一个信号都可由这组基函数通过线性叠加而构成</li>\n</ul>\n</li>\n<li>加权系数的计算<ul>\n<li>对基函数的投影：</li>\n</ul>\n</li>\n</ul>\n<div>$$\nc_k = \\frac{\\langle x[n], \\phi_k[n]\\rangle}{||\\phi_k[n]||^2}\n$$</div>\n\n<p>DFT 的定义如下：</p>\n<div>$$\nX[k] = \\sum_{n=0}^{N-1} x[n]e^{-j2\\pi kn/N}\n$$</div>\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\n<p>DCT 的定义如下：</p>\n<div>$$\nX[k] = \\sum_{n=0}^{N-1} x[n]\\cos\\left(\\frac{\\pi}{N}(n + 0.5)k\\right)\n$$</div>\n其中，$x[n]$为输入信号的离散样本，$N$为采样点数，$X[k]$为输出的频域样本。\n\n<h3 id=\"离散信号的特征域（量）表示\"><a href=\"#离散信号的特征域（量）表示\" class=\"headerlink\" title=\"离散信号的特征域（量）表示\"></a>离散信号的特征域（量）表示</h3><ul>\n<li>特征量表示指由信号的时域或频域表示来计算用<br>于表征信号的特征量<ul>\n<li>例如能量、功率、均值、相关函数、功率谱</li>\n<li>特征量表示通常是单向性的，由特征量表示一般不能完整地恢复原信号的所有取值</li>\n<li>实践中，经常用特征量来表示随机信号</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"离散信号的单位抽样信号表示：\"><a href=\"#离散信号的单位抽样信号表示：\" class=\"headerlink\" title=\"离散信号的单位抽样信号表示：\"></a>离散信号的单位抽样信号表示：</h3><p>单位抽样信号的移位作为基信号：</p>\n<div>$$\n\\varphi_k[n] = \\delta[n - k], \\quad k \\in (-\\infty, \\ldots, -1, 0, 1, \\ldots, \\infty)\n$$</div>\n\n<p>• 正交性验证：</p>\n<div>$$\n\\langle\\varphi_k[n],\\varphi_l[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} \\delta[n - k] \\delta[n - l] = \\delta[k - l]\n$$</div>\n\n<p>• 系数计算：</p>\n<div>$$\nc_k = \\frac{\\langle x[n],\\varphi_k[n]\\rangle}{\\varphi_k[n]^2} = x[k]\n$$</div>\n\n<p>• 离散信号的单位抽样表示为：</p>\n<div>$$\nx[n] = \\sum_{k=-\\infty}^{\\infty} c_k\\varphi_k[n] = \\sum_{k=-\\infty}^{\\infty} x[k] \\delta[n - k]\n$$</div>\n\n<p>离散信号的复指数信号表示如下：</p>\n<p>• 复指数信号作为基信号：</p>\n<div>$$\n\\varphi_\\omega[n] = e^{j\\omega n}, \\quad 0 \\leq \\omega < 2\\pi\n$$</div>\n\n<p>• 正交性验证：</p>\n<div>$$\n\\langle\\varphi_{\\omega_1}[n],\\varphi_{\\omega_2}[n]\\rangle = \\sum_{n=-\\infty}^{\\infty} e^{j\\omega_1 n} e^{-j\\omega_2 n} = \\begin{cases} \n0, & \\omega_1 \\neq \\omega_2 \\\\\n\\infty, & \\omega_1 = \\omega_2 \n\\end{cases}\n$$</div>\n\n<p>• 系数计算：</p>\n<div>$$\nX(e^{j\\omega}) = \\langle x[n], e^{j\\omega n} \\rangle = x[n] e^{-j\\omega n}\n$$</div>\n\n<p>• 离散信号的复指数信号表示为：</p>\n<div>$$\nx[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(e^{j\\omega}) e^{j\\omega n} d\\omega\n$$</div>\n\n<h3 id=\"有限长离散信号的正交函数表示\"><a href=\"#有限长离散信号的正交函数表示\" class=\"headerlink\" title=\"有限长离散信号的正交函数表示\"></a>有限长离散信号的正交函数表示</h3><p>• 对于长度为$N$的有限长离散序列，选择以下$N$个序列作为基信号：</p>\n<div>$$\n\\varphi_k[n] = e^{j\\frac{2\\pi}{N}kn}R_N[n], \\quad k = 0,1,2,\\ldots,N-1\n$$</div>\n\n<p>• 正交性验证：</p>\n<div>$$\n\\langle \\varphi_k[n],\\varphi_l[n] \\rangle = \\sum_{n=0}^{N-1} e^{j\\frac{2\\pi}{N}(k-l)n} = \\begin{cases} \nN, & k = l \\\\\n0, & k \\neq l \n\\end{cases}\n$$</div>\n\n<p>• 系数计算：</p>\n<div>$$\nX[k] = \\sum_{n=0}^{N-1} x[n] e^{-j\\frac{2\\pi}{N}kn}, \\quad k = 0,1,2,\\ldots,N-1\n$$</div>\n\n<p>• 有限长离散序列可以表示为：</p>\n<div>$$\nx[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} X[k] e^{j\\frac{2\\pi}{N}kn}, \\quad n = 0,1,2,\\ldots,N-1\n$$</div>\n\n<ul>\n<li>离散信号的因果性:<ul>\n<li>𝑥[𝑛] &#x3D; 0，for 𝑛 &lt; 0</li>\n</ul>\n</li>\n</ul>\n<p>因果连续信号抽样后一定是因果离散信号。</p>\n<ul>\n<li>离散信号的对称性：</li>\n</ul>\n<p>• 共轭对称性：</p>\n<ul>\n<li>正对称：$x[n] &#x3D; x^*[-n]$</li>\n<li>反对称：$x[n] &#x3D; -x^*[-n]$</li>\n</ul>\n<p>• 任意信号都可以表示为奇分量和偶分量的和：<br>  $x[n] &#x3D; x_o[n] + x_e[n]$<br>  其中，$x_o[n] &#x3D; \\frac{1}{2}(x[n] - x^*[-n])$为奇分量，$x_e[n] &#x3D; \\frac{1}{2}(x[n] + x^*[-n])$为偶分量。</p>\n<p>• 若信号具有实因果性，可以通过奇分量或偶分量来恢复原信号：</p>\n<div>$$\nx[n] = \\begin{cases}\n0, & n < 0 \\\\\nx_e[n], & n = 0 \\\\\n2x_e[n], & n > 0\n\\end{cases}\n$$</div>\n\n<ul>\n<li>离散信号的周期性：<ul>\n<li>$𝑥[n] &#x3D; 𝑥[𝑛 + N]$</li>\n</ul>\n</li>\n</ul>\n<p>周期连续信号均匀采样后<strong>不</strong>一定是周期离散信号。</p>\n<div>$$\n\\omega_0 = \\Omega_0T = 2\\pi\\frac{T}{T_0}\n$$</div>\n\n<p>离散余弦信号的数字角频率 $\\omega_0$ 由采样周期和连续信号周期的比值决定。该比值决定了采样后的信号是否具有周期性。</p>\n<h3 id=\"离散系统的表示\"><a href=\"#离散系统的表示\" class=\"headerlink\" title=\"离散系统的表示\"></a>离散系统的表示</h3><p>离散系统的表示可以使用以下公式来描述：</p>\n<div>$$y[n] = \\sum_{k=-\\infty}^{\\infty} h[k]x[n-k]$$</div>\n\n<p>其中，$y[n]$表示系统的输出，$x[n]$表示系统的输入，$h[k]$表示系统的单位冲激响应。这个公式是卷积的离散形式，也称为离散卷积。</p>\n<p>对于因果性，一个离散系统被称为因果性系统，如果它对任何$n &lt; 0$的输入信号$x[n]$都产生$y[n] &#x3D; 0$的输出。这意味着输出只依赖于当前和过去的输入。</p>\n<p>对于稳定性，一个离散系统被称为稳定系统，如果对于有界的输入信号$x[n]$，输出$y[n]$仍然是有界的。</p>\n<p>LTI（线性时不变）系统是指具有线性性质和时不变性质的系统。线性性质意味着系统满足叠加原理，即对于输入信号$x_1[n]$和$x_2[n]$，系统的输出满足$y_1[n] + y_2[n]$。时不变性质意味着系统的单位冲激响应$h[k]$与输入信号$x[n]$的延迟无关。</p>\n<p>单位冲激响应是指当输入信号为单位冲激函数$\\delta[n]$时，系统的输出。单位冲激响应通常用$h[n]$表示。</p>\n<p>LTI系统可完全由单位冲激响应来表征。</p>\n<p>因果性判据：单位冲激响应是一个因果信号。<br>稳定性判据：$S &#x3D; \\sum_{k &#x3D; -\\infty}^\\infty |h[k]| \\lt +\\infty$</p>\n<p><strong>特征函数与特征值</strong></p>\n<div>$$\nT\\lbrace s[n]\\rbrace = \\lambda s[n]\n$$</div>\n\n<p><strong>LTI系统的特征函数与特征值</strong></p>\n<div>$$\nT\\lbrace e^{j\\omega n}\\rbrace =\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{j\\omega (n - k)} = \\underbrace{e^{j\\omega n}}_{特征函数}\\cdot\\underbrace{\\sum\\limits_{k=-\\infty}^{\\infty}h[k]e^{-j\\omega k}}_{特征值}\n$$</div>\n\n<p>$y[n]$ 可看作 $x[n]$ 经过特征信号分解、加权、求和的结果：</p>\n<div>$$\ny[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^\\pi H(e^{j\\omega})X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$</div>\n\n<ul>\n<li>频率响应函数：单位冲激响应的DTFT</li>\n</ul>\n<div>$$\nH(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]e^{-j\\omega n}\n$$</div>\n\n<ul>\n<li>系统函数</li>\n</ul>\n<div>$$\nH(z) =\\sum\\limits_{n=-\\infty}^{\\infty}h[n]z^{-n}\n$$</div>\n\n<ul>\n<li>系统差分方程</li>\n</ul>\n<div>$$\n\\sum\\limits_{k=0}^{N} a_ky[n - k] =\\sum\\limits_{k=0}^{M} b_kx[n - k]\n$$</div>\n\n<ul>\n<li>系统状态空间</li>\n</ul>\n<div>$$\n\\lambda[n + 1] = A\\lambda[n] + Bx[n]\\\\\ny[n] = C\\lambda[n] + Dx[n]\n$$</div>\n\n<h2 id=\"DTFT-与-DFT\"><a href=\"#DTFT-与-DFT\" class=\"headerlink\" title=\"DTFT 与 DFT\"></a>DTFT 与 DFT</h2><h3 id=\"DTFT\"><a href=\"#DTFT\" class=\"headerlink\" title=\"DTFT\"></a>DTFT</h3><div>$$\n\\begin{cases}\n    X(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\omega n}\\\\\n    x[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi}X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n\\end{cases}\n$$</div>\n\n<p>与连续频谱的关系：</p>\n<div>$$\nX(e^{j\\omega}) = \\frac{1}{T}\\sum\\limits_{k=-\\infty}^{\\infty}X_a\\left[j\\left(\\frac{\\omega}{T} - k\\frac{2\\pi}{T}\\right)\\right]\\\\\n\\omega = \\Omega T\n$$</div>\n\n<p>基本性质：</p>\n<ul>\n<li>周期性</li>\n</ul>\n<div>$$\nX(e^{j\\omega}) = X(e^{j\\omega + 2k\\pi}), k\\in \\Z\n$$</div>\n\n<ul>\n<li>线性</li>\n</ul>\n<div>$$\nax[n] + by[n] \\lrarr aX(e^{j\\omega}) + bY(e^{j\\omega})\n$$</div>\n\n<ul>\n<li>频域求导</li>\n</ul>\n<div>$$\nnx[n] \\lrarr j\\frac{\\mathrm dX(e^{j\\omega})}{\\mathrm d\\omega}\n$$</div>\n\n<ul>\n<li>Parseval 定理：</li>\n</ul>\n<div>$$\n\\sum\\limits_{n=-\\infty}^{\\infty}||x[n]||^2 = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}||X(e^{j\\omega})||^2\\mathrm d\\omega\n$$</div>\n\n<ul>\n<li>序列的调制</li>\n</ul>\n<div>$$\nx[n]e^{j\\omega_0 n} \\lrarr X(e^{j(\\omega - \\omega_0)})\n$$</div>\n\n<p>实现数字变频：</p>\n<div>$$\nx_B[n] = x[n]e^{-j\\frac{\\pi}{2}n}\n$$</div>\n\n<ul>\n<li>序列的平移</li>\n</ul>\n<div>$$\nx[n - n_0] \\lrarr e^{-j\\omega n_0}X(e^{j\\omega})\n$$</div>\n\n<ul>\n<li>共轭对称性</li>\n</ul>\n<div>$$\nx_e[n] \\lrarr \\text{Re}\\lbrace X(e^{j\\omega}) \\rbrace\n$$</div>\n\n<div>$$\nx_o[n] \\lrarr \\text{Im}\\lbrace X(e^{j\\omega}) \\rbrace\n$$</div>\n\n<p>下面是修正后的表格：</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">序列 $x[n]$</th>\n<th align=\"center\">DTFT $X(e^{j\\omega})$</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">$x[n]$</td>\n<td align=\"center\">$X(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x^*[n]$</td>\n<td align=\"center\">$X^*(e^{-j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x^*[-n]$</td>\n<td align=\"center\">$X^*(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_R[n]$</td>\n<td align=\"center\">$X_e(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$jx_I[n]$</td>\n<td align=\"center\">$X_o(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_e[n]$</td>\n<td align=\"center\">$X_R(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_o[n]$</td>\n<td align=\"center\">$jX_I(e^{j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">以下为实信号</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td align=\"center\">$x[n] &#x3D; x^*[n]$</td>\n<td align=\"center\">，$X(e^{j\\omega}) &#x3D; X^*(e^{-j\\omega})$</td>\n</tr>\n<tr>\n<td align=\"center\">$x_e[n] &#x3D; \\frac{1}{2}(x[n] + x[-n])$</td>\n<td align=\"center\">$X_R(e^{j\\omega})$ 实、偶函数</td>\n</tr>\n<tr>\n<td align=\"center\">$x_o[n] &#x3D; \\frac{1}{2}(x[n] - x[-n])$</td>\n<td align=\"center\">$jX_I(e^{j\\omega})$  虚、奇函数</td>\n</tr>\n</tbody></table>\n<ul>\n<li>卷积与相关性质<ul>\n<li>时域卷积： $x[n] * y[n] \\lrarr X(e^{j\\omega})\\cdot Y(e^{j\\omega})$</li>\n<li>频域卷积：$x[n] \\cdot y[n] \\lrarr \\frac{1}{2\\pi}X(e^{j\\omega}) * Y(e^{j\\omega})$</li>\n<li>时域相关：<ul>\n<li>互相关：$r_{xy}[k] &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}x[n]y^*[n - k]$</li>\n<li>自相关：$r_{xx}[k] &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}x[n]x^*[n - k]$</li>\n<li>$R_{xy}(e^{j\\omega}) &#x3D; X(e^{j\\omega}) \\cdot Y^*(e^{j\\omega})$</li>\n<li>$R_{xx}(e^{j\\omega}) &#x3D; X(e^{j\\omega}) \\cdot X^*(e^{j\\omega})$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>DTFT的存在条件：</strong></p>\n<p>取决于 $\\sum\\limits_{n&#x3D;-\\infty}^{\\infty}x[n]e^{-j\\omega n}$ 的收敛性</p>\n<p>有限和序列 $X_N(e^{j\\omega}) &#x3D;\\sum\\limits_{n&#x3D;-N}^{N}x[n]e^{-j\\omega n}$</p>\n<ul>\n<li>若 $x[n]$ 绝对可和，则 DTFT 存在，且一致收敛</li>\n<li>若序列满足平方可和，则 DTFT 满足均方收敛性<ul>\n<li>截断误差的能量趋于0，但是某些点的误差的绝对值不一定趋于0（例如理想低通滤波器，有吉布斯现象，在截止频率附近存在一个独立于 $N$ 的震荡，即使 $N$ 趋于无穷，在某些频率点上还是存在9%左右的误差）</li>\n</ul>\n</li>\n</ul>\n<p><strong>特殊信号的 DTFT</strong></p>\n<ul>\n<li>符号序列</li>\n</ul>\n<div>$$\n\\text{sgn}[n] = \\begin{cases}\n    1, &n\\gt 0,\\\\\n    0, &n = 0\\\\\n    -1, &n \\lt 0\n\\end{cases} \\lrarr \\text{SGN}(e^{j\\omega}) = \\frac{1}{j} \\cot \\left(\\frac{\\omega}{2}\\right)\n$$</div>\n\n<ul>\n<li>阶跃序列</li>\n</ul>\n<div>$$\nu[n] = \\frac{1}{2}(\\text{sgn}[n] + 1) + \\frac{1}{2} \\delta[n] \\lrarr U(e^{j\\omega}) = \\frac{1}{1 - e^{-j\\omega} + \\pi} + \\pi\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - 2\\pi k)\n$$</div>\n\n<ul>\n<li>离散周期单位冲激串</li>\n</ul>\n<div>$$\nx[n] =\\sum\\limits_{k=-\\infty}^{\\infty}\\delta[n - kN]\\lrarr X(e^{j\\omega}) =\\sum\\limits_{k=-\\infty}^{\\infty}e^{-j\\omega k N} = \\frac{2\\pi}{N}\\sum\\limits_{k=-\\infty}^{\\infty}\\delta(\\omega - \\frac{2k\\pi}{N})\n$$</div>\n\n<p>离散时限信号与周期单位冲激串的卷积，在频域上表现为对 DTFT 的采样，这正是从 DTFT 到 DFT 的过渡。</p>\n<h3 id=\"DFT\"><a href=\"#DFT\" class=\"headerlink\" title=\"DFT\"></a>DFT</h3><p>DTFT给出了离散信号频域的全部信息，但在实际应用中存在如下困难：</p>\n<ul>\n<li>实际信号往往没有解析表达式，无法计算其DTFT</li>\n<li>实际物理装置只能采集有限长度的数据</li>\n<li>DTFT给出的频谱是连续的，无法用数字设备记录和存储全部的值</li>\n</ul>\n<h4 id=\"DFT-的定义\"><a href=\"#DFT-的定义\" class=\"headerlink\" title=\"DFT 的定义\"></a>DFT 的定义</h4><div>$$\n\\begin{cases}\n    X[k] =\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n    x[n] =\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]W_N^{-nk}, &k = 0, 1, 2, \\dots, N - 1\\\\\n\\end{cases}\n$$</div>\n\n<p>其中，</p>\n<div>$$\nW_N = e^{-j\\frac{2\\pi}{N}}\n$$</div>\n\n<h4 id=\"理解-DFT\"><a href=\"#理解-DFT\" class=\"headerlink\" title=\"理解 DFT\"></a>理解 DFT</h4><p>DFT 是 DTFT 的频域采样</p>\n<div>$$\nX(e^{j\\omega}) =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{j\\omega n}\\\\\nX[k] = X(e^{j\\omega})\\big |_{\\omega_k = \\frac{2\\pi}{N}k} =\\sum\\limits_{n=-\\infty}^{\\infty}x[n]e^{-j\\frac{2\\pi}{N}kn}\n$$</div>\n\n<ul>\n<li><p>频域乘积等价于时域卷积，因此对离散序列在频域上以2𝜋&#x2F;𝑁为周期进行采样，等效于离散信号在时域上进行周期延拓，延拓周期为𝑁</p>\n</li>\n<li><p>为保证离散序列频域采样对应的时域序列不发生混叠，要求原离散序列为有限长且长度不超过𝑁。</p>\n</li>\n</ul>\n<h4 id=\"DFT-的频域重构\"><a href=\"#DFT-的频域重构\" class=\"headerlink\" title=\"DFT 的频域重构\"></a>DFT 的频域重构</h4><ul>\n<li>首先需要 $N \\ge L$</li>\n</ul>\n<div>$$\n\\begin{align*}\n    X(e^{j\\omega}) &=\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\omega n} =\\sum\\limits_{n=0}^{N - 1}\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}X[k]e^{j\\frac{2k\\pi}{N}n}\\bigg]e^{-j\\omega n}\\\\\n    &=\\sum\\limits_{k=0}^{N - 1}X[k]\\bigg[\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}e^{-j(\\omega - \\frac{2k\\pi}{N}n)}\\bigg]\\\\\n    &=\\sum\\limits_{k=0}^{N - 1} X[k]P\\bigg(\\omega - \\frac{2k\\pi}{N}\\bigg)\n\\end{align*}\n$$</div>\n\n<p>其中，内插函数</p>\n<div>$$\nP(\\omega) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1} e^{-j\\omega n} = \\frac{1}{N}\\frac{\\sin (\\omega N / 2)}{\\sin (\\omega / 2)}e^{-j \\frac{N - 1}{2}\\omega}\n$$</div>\n\n<h4 id=\"理解-DFT-II\"><a href=\"#理解-DFT-II\" class=\"headerlink\" title=\"理解 DFT II\"></a>理解 DFT II</h4><p>离散正交变换的定义：</p>\n<ul>\n<li>定义变换矩阵 $A$， 若 $A$ 满足 $A^HA &#x3D; cI$，其中$c$为常数，则称 $X &#x3D; Ax$ 为离散正交变换。若 $c &#x3D; 1$，则称变换是归一化的。</li>\n<li>归一化的离散正交变换满足 Parseval 定理：$||X||^2 &#x3D; X^HX &#x3D; x^HA^HAx &#x3D; x^Hx &#x3D; ||x||^2$</li>\n</ul>\n<p>DFT 是对离散时间信号的加权求和，其向量形式</p>\n<ul>\n<li>$X[k] &#x3D; w_k^Hx$, $w_k &#x3D; [e^{j\\frac{2\\pi0k}{N}}, e^{j\\frac{2\\pi1k}{N}}, \\dots, e^{j\\frac{2\\pi(N - 1)k}{N}}]^T$</li>\n<li>$X &#x3D; [X[0], X[1], \\dots, X[N - 1]]^T$，则有$X &#x3D; [w_0, w_1, \\dots, w_{N - 1}]^Hx &#x3D; W_Nx$</li>\n</ul>\n<div>$$\nX = W_Nx\\\\\nx = \\frac{1}{N} W_N^HX\n$$</div>\n\n<h4 id=\"DFT-的周期延拓\"><a href=\"#DFT-的周期延拓\" class=\"headerlink\" title=\"DFT 的周期延拓\"></a>DFT 的周期延拓</h4><p>• DFT本意是用有限个离散频域样本来表示有限长离散序列</p>\n<p>– 时域采样对应着频域周期延拓，频域采样对应着时域周期延拓</p>\n<p>• 由于周期延拓，DFT总是面对着周期序列</p>\n<p>– 在DFT计算和应用中，总是选择时域和频域的主值区间</p>\n<p>– DFT这种隐含的周期性决定了其与DTFT具有不同的性质</p>\n<p><strong>周期延拓的数学表示</strong></p>\n<div>$$\n\\big((n)\\big)_N\n$$</div>\n\n<p>周期延拓可以表示为：</p>\n<div>$$\n\\tilde X[k] = X\\bigg[\\big((k)\\big)_N\\bigg]\n\\tilde x[n] = X\\bigg[\\big((n)\\big)_N\\bigg]\n$$</div>\n\n<p>也可表示为卷积和：</p>\n<div>$$\n\\tilde{X}[k] = X[k] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[k - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}X[k - mN]\\\\\\tilde{x}[n] = x[n] *\\sum\\limits_{m=-\\infty}^{\\infty}\\delta[n - mN] =\\sum\\limits_{m=-\\infty}^{\\infty}x[n - mN]\n$$</div>\n\n<h4 id=\"DFT-性质\"><a href=\"#DFT-性质\" class=\"headerlink\" title=\"DFT 性质\"></a>DFT 性质</h4><ul>\n<li>线性性<ul>\n<li>前提：变换长度 $N$ 相同</li>\n<li>如果不相同，补零到长度 $N \\ge \\max(N_1, N_2)$</li>\n</ul>\n</li>\n<li>反转性质：若时域循环反转，则频域循环反转<ul>\n<li>$\\text{DFT} \\Bigg\\lbrace x\\big[\\big((-n)\\big)_N\\bigg] R_N[n]\\Bigg\\rbrace &#x3D; X\\bigg[\\big((-k)\\big)_N\\bigg] R_N[k]$</li>\n<li>0 时刻不变，其余前后反转</li>\n</ul>\n</li>\n<li>共轭性质：若时域共轭，则频域共轭且循环反转<ul>\n<li>$\\text{DFT}\\lbrace x^*[n]\\rbrace &#x3D; X^*[N - k]$</li>\n</ul>\n</li>\n<li>对偶性质：序列的DFT的DFT<ul>\n<li>$\\text{DFT}\\lbrace X[n]\\rbrace &#x3D; NX^*[N - k]$</li>\n</ul>\n</li>\n<li>周期序列的共轭对称性：<ul>\n<li>共轭对称：$x_{ep}[n] &#x3D; x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$</li>\n<li>共轭反对称：$x_{ep}[n] &#x3D; -x^*_{ep}\\bigg[\\big((-n)\\big)_N\\bigg]$</li>\n<li>任意有限长序列的周期延拓总可以分解为周期共轭对称和反对称的分量和的形式<ul>\n<li>$x[n] &#x3D; x_{ep}[n] + x_{op}[n]$</li>\n<li>$x_{ep}[n] &#x3D; \\frac12 (x[n] + x^*\\bigg[\\big((-n)\\big)_N\\bigg])$</li>\n<li>$x_{op}[n] &#x3D; \\frac12 (x[n] - x^*\\bigg[\\big((-n)\\big)_N\\bigg])$</li>\n</ul>\n</li>\n<li>实序列的DFT是周期共轭对称序列</li>\n<li>虚序列的DFT是周期共轭反对称序列</li>\n<li>周期共轭对称序列的DFT是实的</li>\n<li>周期共轭反对称序列的DFT是虚的</li>\n</ul>\n</li>\n<li>循环卷积性质：<ul>\n<li>有限长循环移位的 DFT 可以由原序列 DFT 乘上一个线性的相位因子得到：$\\text{DFT}\\Bigg \\lbrace\\bigg[x\\big((n - m)\\big)_N\\bigg]\\Bigg \\rbrace &#x3D; X[k]e^{-j\\frac{2\\pi k}{N}m}$</li>\n<li>在 DTFT 中：$x[n] * y[n] &#x3D; \\text{IDTFT}\\lbrace X(e^{j\\omega}) \\cdot Y(e^{j\\omega})\\rbrace$</li>\n<li>DFT 中：$x[n] \\circledast y[n] &#x3D;\\sum\\limits_{m&#x3D;0}^{N - 1}x[m]y\\bigg[\\big((n - m)\\big)<em>N\\bigg] &#x3D;\\sum\\limits</em>{m&#x3D;0}^{N - 1}x\\bigg[\\big((n - m)\\big)_N\\bigg]y[m]$</li>\n</ul>\n</li>\n<li>Parseval 定理：<ul>\n<li>$\\sum\\limits_{n&#x3D;0}^{N - 1}|x[n]|^2 &#x3D; \\frac{1}{N}\\sum\\limits_{k&#x3D;0}^{N - 1}|X[k]|^2$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"FFT\"><a href=\"#FFT\" class=\"headerlink\" title=\"FFT\"></a>FFT</h2><p>FFT 算法是一大类 DFT 快速算法的总称。</p>\n<ul>\n<li>基 2 FFT 算法：$N &#x3D; 2^m$</li>\n<li>基 4 FFT 算法：$N &#x3D; 4^m$</li>\n<li>分裂基算法：基本蝶形是倒 L 型，$N &#x3D; 2^m$</li>\n<li>组合数 FFT 算法：变换点数为组合数，即$N &#x3D; N_1N_2$</li>\n</ul>\n<p>根据处理基本蝶形的结构特点，可以分为：</p>\n<ul>\n<li>DIT (Decimation-In-Time)</li>\n<li>DIF (Decimation-In-Frequency)</li>\n</ul>\n<h3 id=\"基-2-DIT-FFT-算法\"><a href=\"#基-2-DIT-FFT-算法\" class=\"headerlink\" title=\"基 2 DIT-FFT 算法\"></a>基 2 DIT-FFT 算法</h3><p>按照奇偶时间拆分成两个短序列。</p>\n<p>长序列的 DFT 可以由两个短序列的 DFT 组合得到。</p>\n<div>$$\nX[k] = \\sum\\limits_{m=0}^{N/2 - 1}x[2m]W_N^{2mk} + \\sum\\limits_{m=0}^{N/2 - 1} x[2m + 1]W_N^{(2m + 1)k}\\\\\nf_1[n] = x[2n], f_2[n] = x[2n + 1]\\\\\nX[k] = F_1[k] + W_N^kF_2[k]\\\\\nX[k + N/2] = F_1[k] - W_N^kF_2[k]\n$$</div>\n\n<p>反复抽取，变成2点 DFT：</p>\n<div>$$\n\\begin{bmatrix}\n    X[0]\\\\\n    X[1]\n\\end{bmatrix} = \\begin{bmatrix}\n    x[0] + x[1]\\\\\n    x[0] - x[1]\n\\end{bmatrix}\n$$</div>\n\n<p><img src=\"/../images/DSP/4_2.jpg\" alt=\"alt\"></p>\n<p>计算复杂度：</p>\n<ul>\n<li>乘法次数为$\\frac{N}{2}\\log_2N$，$m_a &#x3D; Nm &#x3D; N\\log_2 N$</li>\n</ul>\n<p>输入和输出序列的顺序关系：二进制下的倒序关系。</p>\n<ul>\n<li>每次均分时，输入序列按照奇偶性划分，输出序列按照是否过半划分</li>\n<li>输入序列的奇偶性等价于最低位为1还是0，输出序列是否过半等价于最高位为1还是0</li>\n<li>因此输入映射到输出序列是低位映射到高位的关系。</li>\n</ul>\n<h2 id=\"数字频谱分析\"><a href=\"#数字频谱分析\" class=\"headerlink\" title=\"数字频谱分析\"></a>数字频谱分析</h2><h3 id=\"DFT-谱分析的基本概念\"><a href=\"#DFT-谱分析的基本概念\" class=\"headerlink\" title=\"DFT 谱分析的基本概念\"></a>DFT 谱分析的基本概念</h3><p>频谱：信号经过傅里叶变换转换到频域后，其频域表示的幅度和相位随频率变化的关系分别称为信号的幅度谱和相位谱</p>\n<p>基于 DFT 的数字频谱分析</p>\n<p>利用离散信号 DFT 结果 $X[k]$ 与原连续信号频谱 $X_a(j\\Omega)$ 之间存在对应关系来获得连续信号的频谱。</p>\n<div>$$\nX[k] = X(e^{j\\omega})|_{\\omega = \\frac{2\\pi}{N}k}\n$$</div>\n\n<div>$$\nX(e^{j\\omega}) = \\frac{1}{T_s}X_a(j\\Omega)|_{\\Omega = \\frac{\\omega}{T_s}}\n$$</div>\n\n<div>$$\n X_a(j\\Omega_k)= T_s X[k]\n$$</div>\n\n<p>利用 DFT 结果获得连续信号的频谱：</p>\n<div>$$\nX_a(j\\Omega_k) = X_a \\left ( j\\frac{2\\pi k}{NT_s} \\right) = \\begin{cases}\n    T_sX[k], 0 \\le k \\le \\lceil \\frac{N}{2} \\rceil, \\\\\n    T_sX[k + N], - \\lceil \\frac{N - 1}{2} \\rceil\\le k \\lt 0\n\\end{cases}\n$$</div>\n\n<p>基于DFT的频谱分析方法存在的问题</p>\n<ul>\n<li>理论上连续正弦信号的频谱应为冲激函数，但DFT结果为有限值</li>\n<li>DFT结果在连续正弦信号频谱幅度为0的位置却不为零</li>\n</ul>\n<h3 id=\"DFT-谱分析的一般过程\"><a href=\"#DFT-谱分析的一般过程\" class=\"headerlink\" title=\"DFT 谱分析的一般过程\"></a>DFT 谱分析的一般过程</h3><h4 id=\"抗混叠滤波\"><a href=\"#抗混叠滤波\" class=\"headerlink\" title=\"抗混叠滤波\"></a>抗混叠滤波</h4><p><img src=\"/../images/DSP/5_1.jpg\" alt=\"alt\"></p>\n<h4 id=\"采样\"><a href=\"#采样\" class=\"headerlink\" title=\"采样\"></a>采样</h4><p>提高采样率</p>\n<ul>\n<li>优点：能够无混叠分析的信号带宽增大</li>\n<li>缺点：数据率提高，系统复杂度增加，成本上升</li>\n</ul>\n<h4 id=\"加窗\"><a href=\"#加窗\" class=\"headerlink\" title=\"加窗\"></a>加窗</h4><p>由于DFT只能处理有限长序列，需要对输入信号<br>通过加窗进行截断</p>\n<ul>\n<li>窗长可根据频率分辨率、实时性和设备存储能力的要<br>求来权衡</li>\n<li>窗函数的形式也可根据主瓣宽度和旁瓣电平进行选择</li>\n</ul>\n<div>$$\nw_R[n] = \\begin{cases}\n    1, 0 \\le n \\lt M\\\\\n    0, \\text{others}\n\\end{cases}\n$$</div>\n\n<div>$$\nx_w[n] = x[n]w_R[n]\n$$</div>\n\n<h4 id=\"DFT计算、插值及频谱输出\"><a href=\"#DFT计算、插值及频谱输出\" class=\"headerlink\" title=\"DFT计算、插值及频谱输出\"></a>DFT计算、插值及频谱输出</h4><p>DFT计算</p>\n<ul>\n<li>可能需要补零，以获得更密集的频域采样，以及使变换点数𝑁满足FFT算法的要求（基2-FFT、基4-FFT）</li>\n</ul>\n<p>插值</p>\n<ul>\n<li>由DFT结果获得DTFT的估计值</li>\n<li>插值方法：<ul>\n<li>精确插值： $X(e^{j\\omega}) &#x3D;\\sum\\limits_{k&#x3D;0}^{N - 1} X[k] P \\left ( \\omega - \\frac{2\\pi k}{N} \\right)$, $P(\\omega) &#x3D; \\frac{\\sin(\\omega N&#x2F;2)}{\\sin(\\omega&#x2F;2)}e^{-j\\frac{N-1}{2}\\omega}$</li>\n<li>近似插值：线性插值，二次插值</li>\n</ul>\n</li>\n</ul>\n<p>连续信号频谱输出<br>– 通过坐标变换得到连续信号频谱 $X_a(j\\Omega) &#x3D; T_sX(e^{j\\Omega T_s})$</p>\n<h3 id=\"DFT-谱分析问题\"><a href=\"#DFT-谱分析问题\" class=\"headerlink\" title=\"DFT 谱分析问题\"></a>DFT 谱分析问题</h3><h4 id=\"谱分析滤波器\"><a href=\"#谱分析滤波器\" class=\"headerlink\" title=\"谱分析滤波器\"></a>谱分析滤波器</h4><div>$$\ns(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega t}\\mathrm d\\Omega\\\\\ns(nT_s) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}S(j\\Omega)e^{j\\Omega nT_s}\\mathrm d\\Omega\\\\\nx[n] = \\begin{cases}\n    s(nT_s), n = 0, 1, \\dots, M - 1,\\\\\n    0, M, M + 1, \\dots, N - 1\n\\end{cases}\\\\\nX[k] =\\sum\\limits_{n=0}^{N - 1}x[n]e^{-j\\frac{2\\pi nk}{N}} = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n}\\mathrm d\\Omega\n$$</div>\n\n<p>令 $\\theta &#x3D; T_s(\\Omega - \\Omega_k)$，</p>\n<div>$$\n\\varphi_k(M, \\theta) = \\sum\\limits_{n=0}^{M - 1}e^{j(\\Omega T_s - 2\\pi k/N)n} = \\frac{\\sin(M\\theta / 2)}{\\sin(\\theta/2)} e^{j\\frac{M - 1}{2}\\theta}\n$$</div>\n\n<p>梳状滤波特性</p>\n<p><img src=\"/../images/DSP/5_2.jpg\" alt=\"alt\"></p>\n<p>周期内存在多个过零点，把滤波器响应分割成多个区间</p>\n<ul>\n<li>主瓣：谱分析滤波器频率响应最大的那个区间</li>\n<li>主峰：主瓣中最大频率响应点 $Ω &#x3D; \\frac{2\\pi k}{NT_s}$处，高度为𝑀</li>\n<li>主瓣宽度：主瓣两边过零点之间的距离4𝜋⁄𝑀𝑇𝑠</li>\n<li>旁瓣：除响应最大的那个区间外的其它区间</li>\n</ul>\n<p>DFT频谱分析方法能否反映连续信号的频谱？</p>\n<ul>\n<li>DFT的结果主要给出了连续信号落在相应谱分析滤波器主瓣内的那部分信号的频域信息</li>\n<li>由于相邻谱分析滤波器主瓣间有交叠，同一个信号可能会在相邻两个谱分析滤波器都有响应</li>\n<li>谱分析滤波器的旁瓣会在其他谱分析滤波器的主瓣位置出现，其对应的DFT结果不可避免的包含了其他滤波器主瓣位置处的信号成分</li>\n</ul>\n<p>DFT 可用于连续信号的频谱分析，但由于其谱分析滤波器频率分割不理想的本质，必须对其输出结果进行小心的解释</p>\n<p>DFT谱估计得到的是对加窗后序列DTFT的采样</p>\n<div>$$\nx_w[n] = x[n]w_R[n]\\\\\nX_w(e^{j\\omega}) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}X(e^{j\\omega})W_R(e^{j(\\omega - \\theta)})\\mathrm d\\theta\n$$</div>\n\n<p>对于矩形窗：</p>\n<div>$$\nW_R(e^{j\\omega}) = \\text{DTFT}(w_R[n]) = \\frac{\\sin(M\\omega / 2)}{\\sin(\\omega/2)} e^{-j\\frac{M - 1}{2}\\omega}\n$$</div>\n\n<p>频率分辨力的定义：两个等幅单频信号能够被区分开的最小频率间隔</p>\n<p>矩形窗的主瓣宽度为 $4\\pi&#x2F;MT_s$</p>\n<p>实际工程中，采用 3dB带宽并加上适当余量作为频率分辨力</p>\n<ul>\n<li>矩形窗的数字角频率分辨力为 $\\Delta \\omega &#x3D; 2\\pi &#x2F; M$</li>\n<li>连续信号的分辨力为 $\\Delta f &#x3D; f_s&#x2F;M$</li>\n</ul>\n<p>分辨力仅决定于信号时长 $MT_s$。</p>\n<p>混叠效应</p>\n<p>混叠效应本质上由采样过程引起</p>\n<ul>\n<li>混叠效应带来的问题</li>\n<li>如果采样过程带来了混叠，DFT结果无法将已混叠的频<br>率分量分开</li>\n<li>采样之前作抗混叠滤波，把带外频率成分滤除</li>\n<li>增大采样频率（减小采样周期）<br>– 无法仅从DFT结果中判读原连续信号的模拟频率</li>\n<li>需要原连续信号频率分布或抗混叠滤波通带的先验<br>知识</li>\n</ul>\n<p>栅栏效应</p>\n<ul>\n<li>DFT 无法精确表示不在离散采样点的频率值</li>\n<li>频率估计的最大误差为 $\\pi &#x2F; N$</li>\n<li>可以通过加窗补零（增大 $N$）的方法改善</li>\n<li>通过局部插值的方法获得更精确的频率估计：精确插值，线性插值，二次插值</li>\n</ul>\n<h2 id=\"DFT-的应用\"><a href=\"#DFT-的应用\" class=\"headerlink\" title=\"DFT 的应用\"></a>DFT 的应用</h2><h3 id=\"线性卷积的计算\"><a href=\"#线性卷积的计算\" class=\"headerlink\" title=\"线性卷积的计算\"></a>线性卷积的计算</h3><p>假设有限长因果序列 $h[n]$ 和 $x[n]$，长度分别为 $P$ 和 $L$，均扩展到 $N$ 个点进行卷积</p>\n<ul>\n<li>当 $N \\ge P + L - 1$ 时，两种卷积的结果相等</li>\n<li>当 $N \\lt P + L - 1$ 时，循环卷积出现混叠</li>\n</ul>\n<p>基于 DFT 的 FIR 滤波器实现</p>\n<p>FIR 滤波器需要计算有限长序列和无限长序列的线性卷积</p>\n<ul>\n<li>$h[n]$ 有限</li>\n<li>$x[n]$ 无限</li>\n</ul>\n<p>方法1：重叠相加法</p>\n<div>$$\nx[n] =\\sum\\limits_{r=0}^{\\infty}x_r[n - rL]\\\\\ny[n] = h[n] * \\sum\\limits_{r=0}^{\\infty}x_r[n - rL] = \\sum\\limits_{r=0}^{\\infty}h[n] * x_r[n - rL]\\\\\n$$</div>\n\n<p>整个序列的线性卷积等于各段线性卷积后的移位加和</p>\n<p>IDFT 后，需要一个专门的加法器进行重叠部分的相加运算</p>\n<p>方法二：重叠保留法</p>\n<p>取 $L$ 点 $x[n]$ 与扩展的 $P$ 点 $h[n]$ 做循环卷积，取结果的后 $L - P + 1$ 个点作为结果。</p>\n<p>两种方法、直接计算线性相关的计算量对比？</p>\n<h3 id=\"线性调频-z-变换\"><a href=\"#线性调频-z-变换\" class=\"headerlink\" title=\"线性调频 z 变换\"></a>线性调频 z 变换</h3><p>CZT 的定义</p>\n<div>$$\nX_{cz}(z)|_{z = z_k} =\\sum\\limits_{n=0}^{N - 1}x[n]z_k^{-n}\\\\\nz_k = AW^{-k} = (A_0e^{j\\theta_0})(W_0e^{-j\\varphi_0})^{-k}\n$$</div>\n\n<p>一种广义的 DFT，在复平面螺旋线上的采样。</p>\n<p>CZT 的计算</p>\n<ul>\n<li>利用定义直接计算</li>\n<li>利用卷积计算，而卷积可以利用 FFT 计算</li>\n</ul>\n<div>$$\nX_{cz}(z_k) = W^{\\frac{k^2}{2}}\\sum\\limits_{n=0}^{N - 1}f[n]h[k - n]\\\\\nf[n] = x[n]A^{-n}W^{\\frac{n^2}{2}}\\\\\nh[n] = W^{-\\frac{n^2}{2}}\n$$</div>\n\n<h3 id=\"短时傅里叶变换\"><a href=\"#短时傅里叶变换\" class=\"headerlink\" title=\"短时傅里叶变换\"></a>短时傅里叶变换</h3><p>问题：基于傅里叶的频谱分析可以指导信号观测窗内的频率成分，但是无法得知这些频率成分何时出现，何时消失，持续多久</p>\n<p>定义</p>\n<div>$$\n\\text{STFT}(t^\\prime, \\Omega) = \\int_{-\\infty}^{\\infty}x(\\tau)g^*(\\tau - t^\\prime)e^{-j\\Omega\\tau}\\mathrm d\\tau\n$$</div>\n\n<ul>\n<li>窗的长度<ul>\n<li>窗长需要足够短，确保落入窗的信号近似平稳</li>\n<li>窗越长，频率分辨率越高，窗越短，时间分辨率越高<ul>\n<li>窗无限长，退化成 FT</li>\n<li>无限短，退化成 $s(t^\\prime)e^{-j\\Omega t^\\prime}$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>窗的类型<ul>\n<li>矩形窗，汉明窗，布莱克曼窗</li>\n<li>主瓣宽度与旁瓣电平之间的权衡</li>\n</ul>\n</li>\n</ul>\n<p>不确定性原理</p>\n<div>$$\n\\Delta t \\cdot \\Delta \\Omega \\ge \\frac{1}{2}\n$$</div>\n\n\n<h2 id=\"LTI-系统\"><a href=\"#LTI-系统\" class=\"headerlink\" title=\"LTI 系统\"></a>LTI 系统</h2><h3 id=\"LTI-系统的时域分析——冲激响应\"><a href=\"#LTI-系统的时域分析——冲激响应\" class=\"headerlink\" title=\"LTI 系统的时域分析——冲激响应\"></a>LTI 系统的时域分析——冲激响应</h3><p>根据冲激响应长度不同：</p>\n<ul>\n<li>FIR:用 $h[n]$ 表示系统</li>\n<li>IIR：用系统函数或者差分方程表示</li>\n</ul>\n<h3 id=\"LTI-系统的时域分析——冲激响应-1\"><a href=\"#LTI-系统的时域分析——冲激响应-1\" class=\"headerlink\" title=\"LTI 系统的时域分析——冲激响应\"></a>LTI 系统的时域分析——冲激响应</h3><p>复指数序列是 LTI 系统的特征函数</p>\n<div>$$\nT \\lbrace e^{j\\omega n} \\rbrace = H(e^{j\\omega})e^{j\\omega n}\n$$</div>\n\n<p>频率响应函数的表示方式</p>\n<ul>\n<li>$H(e^{j\\omega}) &#x3D; H_R(e^{j\\omega}) + jH_I(e^{j\\omega})$</li>\n<li>$H(e^{j\\omega}) &#x3D; |H(e^{j\\omega})|e^{j\\angle H(e^{j\\omega})}$</li>\n<li>幅频特性：<ul>\n<li>$|H(e^{j\\omega})|$</li>\n<li>$20\\log |H(e^{j\\omega})|$，单位 dB</li>\n</ul>\n</li>\n<li>相频特性<ul>\n<li>$arg(H(e^{j\\omega}))$：连续相位</li>\n<li>$Arg(H(e^{j\\omega}))$：主值相位</li>\n<li>无卷绕相位：$\\angle H(e^{j\\omega}) &#x3D; \\tan^{-1}\\frac{H_I(e^{j\\omega})}{H_R(e^{j\\omega})}$</li>\n<li>定义主值区间 $arg(H(e^{j\\omega})) &#x3D; ARG[H(e^{j\\omega})] + 2\\pi r(\\omega)$，$r(\\omega)$是补偿函数，仅取整数</li>\n</ul>\n</li>\n</ul>\n<p>相位延迟</p>\n<p>群延迟</p>\n<div>$$\n-\\frac{\\mathrm d}{\\mathrm d\\omega}\\text{arg}[H_{id}(e^{j\\omega})]\n$$</div>\n\n<p>可以表征窄带信号的相位失真（或者延迟）</p>\n<div>$$\nx[n] = a[n]e^{j\\omega_c n}\\\\\na[n] = c_1e^{j\\omega_1n}\\\\\ny[n] \\approx |H(e^{j\\omega_c})|c_1e^{j(\\omega_1 + \\omega_c)n + j\\varphi(\\omega_1 + \\omega_c)} \\approx |H(e^{j\\omega_c})|\\underbrace{a[n - \\tau_g(\\omega_c)]}_{群延迟给出了包络延迟}\\underbrace{e^{j\\omega_c[n - \\tau_p(\\omega_c)]}}_{相位延迟\\tau_p(\\omega_c) = \\varphi(\\omega_c)}\n$$</div>\n\n<h3 id=\"LTI-系统的零极点分析\"><a href=\"#LTI-系统的零极点分析\" class=\"headerlink\" title=\"LTI 系统的零极点分析\"></a>LTI 系统的零极点分析</h3><div>$$\n\\sum\\limits_{k=0}^{N}a_ky[n - k] =\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH[z] = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{\\sum\\limits_{k=0}^{N}a_kz^{-k}} = \\left ( \\frac{b_0}{a_0} \\right)\\frac{\\prod_{k = 1}^M(1 - c_kz^{-1})}{\\prod_{k = 1}^N(1 - d_kz^{-1})}\n$$</div>\n\n<p>$z &#x3D; 0, z &#x3D; \\infty$ 也可能是零点！求解的时候不要忘了。</p>\n<p>系统稳定性的条件：绝对可和。或者说 $H(z)$ 的极点在单位圆内。</p>\n<p>可逆性的条件：$h[n] * h_i[n] &#x3D; \\delta[n]$， $H(8z)H_i(z) &#x3D; 1$</p>\n<ul>\n<li>逆系统的极点和零点就是原系统的零点和极点</li>\n<li>逆系统和原系统必须有重叠的 ROC，因此可以确定逆系统的 ROC</li>\n</ul>\n<p>频率响应</p>\n<p>群延迟</p>\n<div>$$\n\\text{grd}[] =\\sum\\limits_{k=1}^{N}\\frac{|d_k|^2 - \\Re{d_ke^{-j\\omega}}}{1 + |d_k|^2 - 2\\Re{d_ke^{-j\\omega}}} - \\sum\\limits_{k=1}^{M}\\frac{|c_k|^2 - \\Re{c_ke^{-j\\omega}}}{1 + |c_k|^2 - 2\\Re{c_ke^{-j\\omega}}}\n$$</div>\n\n<h3 id=\"IIR滤波器\"><a href=\"#IIR滤波器\" class=\"headerlink\" title=\"IIR滤波器\"></a>IIR滤波器</h3><div>$$\ny[n] =\\sum\\limits_{k=1}^{N}a_ky[n - k] +\\sum\\limits_{k=0}^{M}b_kx[n - k]\\\\\nH(z) = \\frac{\\sum\\limits_{k=0}^{M}b_kz^{-k}}{1 -\\sum\\limits_{k=1}^{N}a_kz^{-k}}\n$$</div>\n\n<p>直接 I 型</p>\n<p>直接 II 型：交换次序，合并延迟单元</p>\n<p>级联形式：</p>\n<div>$$\nH(z) = K \\prod_{k = 1}^{N_s} \\frac{b_{0k} + b_{1k}z^{-1} + b_{2k}z^{-2}}{1 - a_{1k}z^{-1} - a_{2k}z^{-2}}\n$$</div>\n\n<p>考虑到有限字长效应，级联形式可以以更加灵活的方式减小有限字长的影响。可以控制零点和极点的位置。</p>\n<p>级联形式也可以用直接 I, II 型实现。</p>\n<p>多径衰落就是一个 FIR 滤波器，因此具有频率选择特性。</p>\n<p>并联形式</p>\n<div>$$\nH(z) =\\sum\\limits_{k=0}^{N_p}C_kz^{-k} +\\sum\\limits_{k=1}^{N_2}\\frac{e_{0k}+e_{1k}z^{-1}}{1 - a_{1k} - a_{2k}z^{-2}}\n$$</div>\n\n<p>各子系统的计算误差互不影响，防止误差传递和放大，可控极点位置</p>\n<p>流图转置定理：支路方向取反，系数不变，输入和输出交换位置</p>\n<h3 id=\"FIR-滤波器\"><a href=\"#FIR-滤波器\" class=\"headerlink\" title=\"FIR 滤波器\"></a>FIR 滤波器</h3><div>$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n}\n$$</div>\n\n<p>抽头延迟线 or 横向滤波器结构</p>\n<p>具有转置形式</p>\n<p>级联形式</p>\n<div>$$\nH(z) = \\prod_{k = 1}^{M_1}(f_{0k} - f_{1k}z^{-1}\\prod_{k = 1}^{M_2}(b_{0k} + b_{1k} z^{-1} + b_{2k}z^{-2})\n$$</div>\n\n<p>线性相位特性</p>\n<div>$$\nH(e^{j\\omega}) = A(e^{j\\omega})e^{-j\\omega\\alpha}\n$$</div>\n\n<div>$$\nh[n] = h[M - n] (I, II)\\\\\nh[n] = - h[M - n] (III,IV)\n$$</div>\n\n<p>线性相位 FIR 滤波器的直接形式</p>\n<p>偶数</p>\n<div>$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] + x[n - M + k]) + h[M/2]x[n - M/2], &I type\n    \\sum\\limits_{k=0}^{M/2 - 1}h[k](x[n - k] - x[n - M + k]), &III type\n\\end{cases}\n$$</div>\n\n<p>奇数</p>\n<div>$$\ny[n] = \\begin{cases}\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] + x[n - M + k]), &II type\n    \\sum\\limits_{k=0}^{(M - 1)/2}h[k](x[n - k] - x[n - M + k]), &IV type\n\\end{cases}\n$$</div>\n\n<p>级联形式</p>\n<p>对应四种零点分布情况，有四种网络结构</p>\n<div>$$\nH(z) = 1 \\pm z^{-1}\\\\\nH(z) = 1 - 2\\cos(\\theta)z^{-1} + z^{-2}\\\\\nH(z) = (1 - rz^{-1})(1 - r^{-1}z^{-1})\\\\\nH(z) = 1 + bz^{-1} + cz^{-2} + bz^{-3} + z^{-4}\n$$</div>\n\n<h3 id=\"FIR-滤波器的频率取样结构\"><a href=\"#FIR-滤波器的频率取样结构\" class=\"headerlink\" title=\"FIR 滤波器的频率取样结构\"></a>FIR 滤波器的频率取样结构</h3><div>$$\nH(z) =\\sum\\limits_{n=0}^{N - 1}h[n]z^{-n} = \\frac{1}{N}(1 - z^{-N})\\sum\\limits_{k=0}^{N - 1}\\frac{H(k)}{1 - W_N^{-j}z^{-1}}\n$$</div>\n\n<p>$H(k)$ 是 FFT 变换。</p>\n<p>若冲激响应是实序列，可以用共轭对称性将成对的一阶子系统合称为二阶子系统</p>\n<div>$$\nH_k(z) + H_{-k}(z) = 2|H(k)| \\frac{\\cos\\theta(k) - (\\cos(\\theta(k) - \\frac{2\\pi}{N}k))z^{-1}}{1 - 2\\cos(\\frac{2\\pi}{N}k)z^{-1} + z^{-2}}\n$$</div>\n\n<p>其中 $\\theta(k)$ 是 $H(k)$ 的相位</p>\n<p>不成对的子系统？</p>\n<div>$$\nH_0(z) = \\frac{H(0)}{1 - z^{-1}}\\\\\nH_{N/2}(z) = \\frac{H(0)}{1 + z^{-1}}\n$$</div>\n\n<p>FIR 滤波器的时分复用结构</p>\n<h2 id=\"离散希尔伯特变换\"><a href=\"#离散希尔伯特变换\" class=\"headerlink\" title=\"离散希尔伯特变换\"></a>离散希尔伯特变换</h2><div>$$\nh[n] = \\begin{cases}\n    \\frac{1 - \\cos(n\\pi)}{n\\pi}, n \\ne 0\\\\\n    0, n = 0\n\\end{cases}\n$$</div>\n\n<h2 id=\"典型数字信号处理系统及其误差源\"><a href=\"#典型数字信号处理系统及其误差源\" class=\"headerlink\" title=\"典型数字信号处理系统及其误差源\"></a>典型数字信号处理系统及其误差源</h2><ul>\n<li>引起有限字长的误差源<ul>\n<li>AD 变换引入的误差</li>\n<li>有限精度引起的误差</li>\n<li>限制乘法运算位数的误差</li>\n<li>防止加法溢出压缩信号电平的误差</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"量化误差的统计分析模型\"><a href=\"#量化误差的统计分析模型\" class=\"headerlink\" title=\"量化误差的统计分析模型\"></a>量化误差的统计分析模型</h3><div>$$\nQ_B \\lbrace x[n] \\rbrace = x[n] + e[n]\\\\\n$$</div>\n\n<p>$e[n]$ 是各态历经的平稳随机序列，与 $x[n]$ 相互统计独立，具有白噪声的性质，不同时刻的取值相互独立，是均匀分布的。</p>\n"},{"title":"Introduction-to-Probability","date":"2023-02-20T13:05:41.000Z","katex":true,"_content":"\n## Introduction\n\n## Probability Space\n\nProbability space is a triple $(\\Omega, \\mathcal{F}, \\mathbf{P})$, comprised of the following three\nelements:\n\n1 Sample space $\\Omega$: the set of all possible outcomes of an experiment\n\n2 $\\sigma$-algebra (or $\\sigma$-field) $\\mathcal F$: a collection of subsets of $\\Omega$\n\n3 Probability measure $\\mathbf P$: a function that assigns a nonnegative\nprobability to every set in the $\\sigma$-algebra $\\mathcal F$\n\n### Sample space\nMutually exclusive: no identical element.\n\nCollectively exhaustive: all results should be included.\n\n### $\\sigma$-algegra\n\nnot unique\n\n3 requirements:\n\n$$\n\\varnothing \\in \\mathcal F\\\\\n\\forall A \\in \\mathcal F, A^c \\in \\mathcal F\\\\\n\\forall A_k \\in \\mathcal F, k=1, 2, ..., \n\\cup_{k=1}^{\\infty}A_k\\in \\mathcal F\n$$\n\n### Borel field\n\nused to measure intervals\n\nwhen $\\Omega$ is continuous($\\R$ for example), Borel field is useful.\n\n\"minimum\" $\\sigma$-algebra means deleting any element in the $\\mathcal B (\\mathbf R)$ will miss the requirements.\n\n![](../images/prob/L2_1.jpg)\n\n### Uncountable\n\ndecimal numbers between 0 and 1 are uncountable.\n\n### Probability measures\n\n$$\nP:\\mathcal F \\rightarrow [0, 1]\n$$\n\n**Nonnegativity** $P(A)\\ge0, \\forall A \\in \\mathcal{  F}$\n\n**Normalization**  $P(\\empty)=0, P(\\Omega)=1$\n\n**Countable additivity** $A_1, A_2, ... \\text { is disjoint in }\\mathcal F, P(A_1\\cup A_2\\cup ...)=P(A_1)+P(A_2)+...$\n\n* They are the axioms of probability. \n* Probability is a mapping from $\\sigma$-algebra to a real number betwenn 0 and 1, which intuitively specifies the \"likelihood\" of any event. \n* There exist non-measurable sets, on which we cannot define a probability measure.\n\n### Discrete models\n\n$$\nP(\\{s_1, ..., s_n\\})=P(s_1)+...+P(s_n)\\\\\nP(A) = \\frac{\\text{\\# of elements of }A}{\\text{total \\# of elements of sample points}}\n$$\n\n\n### Continuous Models\n\nProbability = Area\n\n### Some properties of Probability measure\n\n$$\nA\\sub B\\Rightarrow P(A)\\le P(B)\\\\\nP(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\\\\nP(A\\cup B) \\le P(A) + P(B)\\\\\nP(A\\cup B \\cup C)=P(A) + P(A^C\\cap B) + P(A^C\\cap B^C\\cap C)\n$$\n\n### Conditional Probability\n\n$$\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}\n$$\n\n* If $P(B)=0$, $P(A|B)$ is undefined.\n* For a fixed event $B$, $P(A|B)$ can be verified as a legitimate probability measure on the new universe. $P(A, B)\\ge 0$, $P(\\Omega|B)=1$, $P(A_1\\cup A_2\\cup...|B)=P(A_1|B)+P(A_2|B)+...$\n* <div>$P(A|B)=\\frac{\\text{ \\# of elements of }A\\cap B}{\\text{total \\# of elements of }B}$</div>\n\n### Total probability theorem\n\nLet $A_1, ..., A_n$ be disjoint events that form a partition of the sample space and assume that $P(A_i)>0$ for all $i$. Then for any event B, we have\n\n$$\nP(B) = \\sum_{i=1}^n P(A_i\\cap B) = \\sum_{i=1}^nP(A_i)P(B|A_i)\n$$\n\n**Remark** \n* The definition of partition is that $\\cup_{i=1}^n A_i = \\Omega, A_i\\cap A_j = \\emptyset, \\forall i\\ne j$\n* The probability of B is a weighted average of its conditional probability under each scenario\n* Each scenario is weighted according to its prior probability\n* Useful when $P(B|A_i)$ is known or easy to derive\n\n### Inference and Bayes' rule\n\nLet $A_1, ..., A_2$ be disjoint events that from a partition of the sample space and assume that $P(A_i) \\gt 0$  for all $i$. Then for any event $B$ such that $P(B)\\gt 0$, we have \n\n$$\nP(A_i|B) = \\frac{P(A_i)P(B|A_i)}{P(B)} = \\frac{P(A_i)P(B|A_i)}{\\sum_{j=1}^nP(A_j)P(B|A_j)}\n$$\n\n**Remarks**\n* Relates conditional probabilities of the form $P(A_i|B)$ with conditional probabilities of the form $P(B|A_i)$\n* often used in inference: effect $B$ $\\lrarr$ cause $A_i$\n\nThe meaning of $P(A_i|B)$ in the view of Bayes: the belief of $A_i$ is revised if we observed effect $B$. If the cause and the effect are closely binded($P(B|A_i) > P(B|A_i^c)$), then the belief $A_i$ is enhanced by the observation of effect $B$($P(A_i|B) > P(A)$). This can be derived from the Bayes' rule through simple calculation. If $P(A_i|B)=P(A_i)$, then $B$ provides no information on $A_i$.\n\n### Independence\n\n#### Independence of two disjoint events\n\nEvents A and B are called **independent** if \n$$\nP(A\\cap B) = P(A)\\cdot P(B)\n$$\nor equivalently, when $P(B) > 0$, \n\n$$\nP(A|B) = P(A)\n$$\n\n**Remarks**\n* Occurrence of B provides no information about A's occurrence\n* Equivalence due to $P(A\\cap B) = P(B)\\cdot P(A|B)$\n* Symmetric with respect to $A$ and $B$.\n* - applies even if $P(B) = 0$\n* - implies $P(B|A) = P(B)$ and $P(A|B^c) = P(A)$\n* Does not imply that A and B are disjoint, indeed opposite!\n* - Two disjoint events are never independent!($P(A\\cap B) = 0$, but $P(A)\\cdot P(B)\\ne 0$)\n\n#### Conditional independence\n\n$$\nP(A\\cap B | C) = P(A| C) \\cdot P(B|C)\n$$\n\n**Definition**\n\nEvent $A_1, A_2, ..., A_n$ are called independent if: \n\n$$\nP(A_i\\cap A_j\\cap ...\\cap A_q) = P(A_1)P(A_j)...P(A_q)\n$$\n\nfor any distinct indices $i, j, \\dots q$ chosen from $\\{1, \\dots n\\}$.\n\nPairwise is independence does not imply independence.\n\n## Discrete Random Variables\n\nRandom Variable is neither random, nor variable.\n\n### Definition\n\nWe care about the probability that $X \\le x$ instead $X = x$ in the consideration of generality. \n\n**Random variables**\n\nGiven a probability space $(\\Omega, F, P)$, a random variable is a function $X: \\Omega \\rightarrow \\R$ with the probability that $\\{\\omega \\in \\Omega: X(\\omega) \\le x\\} \\in \\mathcal F$ for each $x\\in \\R$. Such a function $X$ is said to be $\\mathcal F$-measurable.\n\n**Probability Mass Function(PMF)**\n\n$$\np_X(x)=P(X=x)=P(\\{\\omega \\in \\Omega \\text{ s.t. } X(\\omega)=x\\})\n$$\n\nBonulli PMF: \n\n$$ \np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\n$$\n\nBinomial PMF: $p_X(k)=\\binom{n}{k}p^k(1-p)^{n-k}$\n\nGeometric PMF: $p_X(k)=(1-p)^{k-1}p$\n\nPoisson PMF: $p_X(k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}$. Note: $\\sum_{k=0}^\\infty e^{-\\lambda}\\frac{\\lambda^k}{k!}=e^{-\\lambda}e^\\lambda=1$\n\nIf $y=g(x)$, $p_Y(y)=\\sum_{\\lbrace x|g(x)=y \\rbrace} p(x)$.\n\n\n### Expectation and Variance\n\n**Expectation**\n\n$$\nE[X] = \\sum_x xp_X(x)\n$$\n\nNote: we assume that the sum converges.\n\nProperties:\n\n$$\nE[Y]=\\sum_x g(x)p_X(x)\\\\\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\n$$\n\n**Variance**\n\n$$\n\\text{var}(X) = E \\left[(X-E[X])^2\\right]=\\sum_x (x-E[X])^2 p_X(x)\n$$\n\nStandard deviation: $\\sigma_X=\\sqrt{\\text{var}(X)}$\n\nProperties: \n\n$$\n\\text{var}(X) = E[X^2] -(E[X])^2\\\\\n\\text{var}(X)\\ge 0\\\\\n\\text{var}(\\alpha X + \\beta) = \\alpha^2\\text{var} (X)\n$$\n\n**Bernoulli RV**\n\n$$\np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\\\\\nE[X] = p\\\\\nE[X^2] = p\\\\\n\\text{var}(X) = p(1-p)\n$$\n\n**Discrete Uniform RV**\n\n\n$$\np_X(k) = \\begin{cases}\n    \\frac {1}{b-a+1}, &\\text{if } k = a, a+1, ..., b\\\\\n    0, &\\text{otherwise}\n\\end{cases}\\\\\nE[X] = \\frac{a+b}{2}\\\\\n\\text{var}(X) = \\frac{(b-a)(b-a+2)}{12}\n$$\n\n**Poisson RV**\n\n$$\np_X(k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\\nE[X] = \\lambda\\\\\n\\text{var}(X)=\\lambda\n$$\n\n### Conditional\n\n$$\np_{X|A(x)} = P(X=x|A) = \\frac{P(\\{X=x\\}\\cap A)}{P(A)}\n$$\n\n$$\n\\sum_x p_{X|A}(x) = 1\n$$\n\n$$\nE[X|Y=y] = \\sum_x xp_{X|Y}(x|y)\\\\\nE[g(X)|Y=y] = \\sum_x g(x)p_{X|Y}(x|y)\n$$\n\n**Total expectation theorem**\n\n$A_1, \\dots, A_n$ is a partition of sample space\n\n$$\nP(B) = P(A_1)P(B|A_1) + \\dotsb + P(A_n)P(B|A_n)\\\\\np_X(x) = P(A_1)p_{X|A_1}(x) + \\dotsb + P(A_n)p_{X|A_n}(x)\\\\\nE[X] = P(A_1)E[X|A_1] + \\dotsb + P(A_n)E[X|A_n]\n$$\n\nWe derive the expectation and variance use the theories above.\n\n**Geometric PMF example**\n\n$$\np_X(k) = (1-p)^{k-1}p, k = 1, 2, \\dots\\\\\nE[X] = \\sum_{k=1}^\\infty kp_X(k) = \\sum_{k=1}^\\infty k(1-p)^{k-1}p\\\\\nE[X^2] = \\sum_{k=1}^\\infty k^2p_X(k) = \\sum_{k=1}^\\infty k^2(1-p)^{k-1}p\\\\\n\\text {var}(X) = E[X^2] - (E[X])^2\n$$\n\nHowever, the Geometric has a memoryless property.\n\n$$\np_{X|X>1}(k) = \\frac{P(\\{X>1\\}\\cap \\{X=k\\})}{P(X>1)} = \\frac{(1-p)^{k-1}p}{1-p} = (1-p)^{k-2}p\n$$\n\nThus, \n$$\nE[X] = P(X=1)E[X|X=1] + P(X>1)E[X|X>1]=p+(1-p)(E[1 + X])\\\\\n\\Rightarrow E[X] = 1/p\\\\\nE[X^2] = P(X=1)E[X^2|X=1] + P(X>1)E[X^2|X>1] = p + (1-p)E[(1+X)^2]=p + (1-p)(1+2E[X]+E[X^2])\\\\\n\\Rightarrow E[X^2] = \\frac{2-p}{p^2}\\\\\n\\Rightarrow\\text{var} (X) = \\frac{1-p}{p^2}\n$$\n\n### Multiple discrete random variables\n\n**Joint PMFs**\n\n$$\np_{X, Y}(x, y) = P(X = x, Y= y) = P(\\{X(\\omega) = x\\}\\cap \\{Y(\\omega) = y\\})\n$$\n\n$$\n\\sum_x\\sum_y p_{X, Y}(x, y) = 1\n$$\n\n**Marginal PMF**\n\n$$\np_X(x) = \\sum_y P(X=x, Y=y) = \\sum_y p_{X, Y}(x, y)\n$$\n\n**Conditional PMF**\n\n$$\np_{X|Y}(x|y) = P(X = x | Y = y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$\n\n$$\n\\sum_x p_{X|Y}(x|y) = 1\n$$\n\n**Funcitons of multiple RVs**\n\n$$\nZ = g(X, Y)\\\\\np_Z(z) = \\sum_{\\lbrace (x, y)|g(x, y)=z \\rbrace  } p_{X, Y}(x, y)\n$$\n\n**Expectations**\n\n$$\nE[g(X, Y)] = \\sum_x\\sum_y g(x, y)p(X, Y)(x, y)\\\\\nE[g(X, Y, Z)] = \\sum_x\\sum_y\\sum_z g(x, y, z)p(X, Y, Z)(x, y, z)\n$$\n\n$$\nE[g(X,  Y)] \\not\\equiv g(E[X], E[Y])\n$$\n\n**linearity**\n\n$$\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\\\\\nE[X + Y + Z] = E[X] + E[Y] + E[Z]\n$$\n\nLet's calculate the Mean of Binominal RV.\n\n$$\nX_i=\n\\begin{cases}\n    1, &\\text{if success in trial } i,\\\\\n    0, & \\text{otherwise.}\n\\end{cases}\\\\\nX = X_1 + X_2 + \\dotsb X_n\\\\\nE[X] = \\sum_{i = 1}^n E[X_i] = np\\\\\n\\text{var}(X) = np(1-p)\n$$\n\n### Independence\n\n**Independence**\n\n$$\np_{X, Y}(x, y) = p_X(x) \\cdot p_Y(y)\n$$\n\nif $X$ and $Y$ are independent:\n\n$$\nE[XY] = E[X]E[Y]\\\\\nE[g(X)h(Y)] = E[g(X)]E[h(Y)]\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\n$$\n\n**Conditional independence**\n\n$$\np_{X, Y|A}(X, Y) = p_{X|A}(x) \\cdot p_{Y|A}(y)\n$$\n\n## Continuous Random Variables\n\n\n### Probability Density Function\n\n* $f_X(x)\\ge 0\\text{ for all }x$\n* $\\int_{-\\infty}^\\infty f_X(x)\\mathrm dx = 1$\n* If $\\delta$ is very small, then $P([x, x+\\delta])\\approx f_X(x) \\cdot \\delta$\n* For any subset $B$ of the real line, $P(X\\in B) = \\int_B f_X(x)\\mathrm d x$.\n\n**Expectation**\n\n$$\nE[X] = \\int_{-\\infty}^\\infty xf_X(x)\\mathrm dx\\\\\nE[g(x)] = \\int_{-\\infty}^\\infty g(x)f_X(x)\\mathrm dx\n$$\n\nAssuming that the integration is well-defined. The Cauchy distribution ($\\frac{1}{1+x^2}$)doesn't have expectation since $\\frac{x}{1+x^2}$ is not absolutely integrably.\n\n**Variance**\n\n$$\n\\text{var}(X) = E[(X - E[X])^2] = \\int_{-\\infty}^\\infty(x - E[x])^2 f_X(x)\\mathrm dx\\\\\n0\\le \\text{var}(x) = E[X^2] - (E[X])^2\n$$\n\n**Uniform RV**\n\n$$\nf_X(x) = \\begin{cases}\n    \\frac{1}{b-a}, &\\text{if }a\\le x\\le b,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n$$\nE[X] = \\frac{a+b}{2}\\\\\nE[X^2] = \\frac{a^2+b^2 + ab}{3}\\\\\n\\text{var}(X) = \\frac{(b-a)^2}{12}\n$$\n\n\nProperties:\n\n$$\nE[aX+b] = aE[X] + b\\\\\n\\text{var}(aX+b) = a^2\\text{var}(X)\n$$\n\n### Common Example for PDF\n\n**Exponential Random Variable**\n\n$$\nf_X(x) = \\begin{cases}\n    \\lambda e^{-\\lambda x}, &\\text{if }x \\ge 0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n$$\nP(X\\ge a) = e^{-\\lambda a}\\\\\nE[X] = \\frac{1}{\\lambda}\\\\\n\\text{var}(X) = \\frac{1}{\\lambda^2}\n$$\n\n### Cumulative Distribution Functions\n\n$$\nF_X(x) = P(X\\le x) = \\begin{cases}\n    \\sum_{k\\le x}p_X(k), &\\text{if } X \\text{ is discrete,}\\\\\n    \\int_{-\\infty}^x f_X(t)\\mathrm dt, &\\text{if } X \\text{ is continuous.}\n\\end{cases}\n$$\n\n**Properties**\n\n$$\n\\text{if } x \\le y, \\text{then } F_X(x)\\le F_X(y).\\\\\nF_X(x)\\text{ tends to 0 as } x \\rightarrow -\\infty, \\text{and to 1 as} x \\rightarrow \\infty\\\\\n\\text{If } X \\text{ is discrete, then } F_X(x) \\text{ is a piecewise constant function of }x.\\\\\n\\text{If } X \\text{ is continuous, then } F_X(x) \\text{is a continuous funciton of }x.\\\\\n\\text{If } X \\text{ is discrete and takes integer values, the PMF and the CDF can be obtained from each other by summing or differcing: }\\\\\nF_X(k) = \\sum_{i = -\\infty}^k p_X(i),\\\\\np_X(k) = P(X\\le k) - P(X \\le k -1) = F_X(k) - F_X(k - 1),\\\\\n\\text{ for all integers }k.\\\\\n\\text{If } X \\text{ is continuous, the PDF and the CDF can be obtained from each other by integration or differentiation: }\\\\\nF_X(x) = \\int_{-\\infty}^x f_X(t)\\mathrm dt, f_X(x) = \\frac{\\mathrm dF_X}{\\mathrm dx}(x)\n$$\n\n### Examples for CDF\n\n**Geometric CDF**\n\n$$\nF_{\\text{geo}}(n) = \\sum_{k = 1}^n p(1-p)^{k-1} = 1-(1-p)^n, \\text{for } n = 1, 2, \\dots\n$$\n\n**Exponential CDF**\n\n$$\nF_{\\text{exp}}(x) = P(X\\le x) = 0, \\text{ for } x\\le0,\\\\\nF_{\\text{exp}}(x) = \\int_{0}^x \\lambda e^{-\\lambda t}\\mathrm dt = 1 - e^{-\\lambda x}, \\text{for }x\\ge 0.\n$$\n\nExponential Distribution is Memoriless, like Geometric: \n\n$$\nP(X \\ge c + x| X \\ge c) = e^{-\\lambda x} = P(X \\ge x)\\\\\n$$\n\nThe relationship: \n\n![](../images/prob/L6_1.jpg)\n\n### Normal Random Variables\n\n$$\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-(x-\\mu)^2/2\\sigma^2}\\\\\nE[X] =\\mu\\\\\n\\text{var}(X) = \\sigma^2\n$$\n\nGaussian is good, since adding two Gaussian functions resulting in a new Gaussian functions. And with a huge mount of samples, the distribution is close to Gaussian(Central limit theorem).\n\n**The Standard Normal Random Variable**\n\nNormal(Gaussian)\n\n$$\nY = \\frac{X - \\mu}{\\sigma}\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}}e^{-y^2/2}\\\\\nE[Y] = 0\\\\\n\\text{var}(Y) = 1\\\\\n$$\n\nThe CDF of Normal Random Variable $\\Phi(y)$ can not be derived directly, we can use the standard normal table to get the value.\n\n$$\n\\Phi(-y) = 1 - \\Phi(y)\n$$\n\n### Multiple Continuous Random Variables\n\n**Joint PDFs**\n\nThe two continuous RVs X and Y, with the same experiment, are jointly continuous if they can be described by a joint PDF $f_{X, Y}$, where $f_{X, Y}$ is a nonnegative function that satisfies \n\n$$\nP((X, Y) \\in B) = \\iint_{(x, y)\\in B} f(X, Y)\\mathrm d x\\mathrm dy\n$$\n\nfor every subset B of the two-dimensional plane. In particular, when B is the form $B = \\{(x, y)|a\\le x \\le b, c\\le y \\le d\\}$, we have\n\n$$\nP(a\\le X \\le b, c \\le Y \\le d) = \\int_c^d\\int_a^bf_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$\n\n**Normalization** \n\n$$\n\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\\mathrm dy = 1\n$$\n\n**Interpretation(Small rectangle)**\n\n$$\nP(a\\le X \\le a + \\delta, c \\le Y \\le c + \\delta) \\approx f_{X, Y}(a, c)\\cdot\\delta^2\n$$\n\n**Marginal PDF**\n\n$$\nP(X\\in A) = P(X \\in A, Y \\in (-\\infty, \\infty)) = \\int_A \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\mathrm dx\n$$\n\n$$\nf_X(x) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\\\\nf_Y(y) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\n$$\n\n**Joint CDF**\n\nIf X and Y are two RVs asscociated with the same experiment, then the joint CDF of X and Y is the function\n\n$$\nF_{X, Y}(x, y) = P(X\\le x, Y\\le y) = P(X\\le x|Y\\le y)P(Y\\le y) = \\int_{-\\infty}^y\\int_{-\\infty}^x f_{X, Y}(u, v)\\mathrm du\\mathrm dv\n$$\n\nConversely\n\n$$\nf_{X, Y}(x, y) = \\frac{\\partial^2F_{X, Y}}{\\partial x\\partial y}(x, y)\n$$\n\n**Expectations**\n\n$$\nE[g(X, Y)] = \\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty g(x, y)f_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$\n\nIf g is linear, of the form of $g(x, y) = ax + by + c$, then\n\n$$\nE[g(X, Y)] = aE[X] + bE[Y] + c\n$$\n\nX and Y are called independent if \n\n$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$\n\n### Conditional and Independence\n\n**Conditional PDFs**\n\nLet X and Y be continuous RVs with joint PDF $f_{X, Y}$. For any $f_Y(y) \\gt 0$, the conditional PDF of X given Y = y is defined by\n\n$$\nf_{X|Y}(x|y) = \\frac{f_{X, Y}(x, y)}{f_Y(y)}\n$$\n\nDiscrete case: \n\n$$\np_{X|Y}(x|y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$\n\nBy analogy, for fixed y would like: \n\n$$\nP(x \\le X \\le x + \\delta|Y = y) \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$\n\nBut {Y = y} is a zero-probability event.\n\nLet $B = \\{y\\le Y \\le y + \\epsilon\\}$, for small $\\epsilon > 0$. Then\n\n$$\nP(x \\le X \\le x + \\delta|Y \\in B) \\approx \\frac{P(x \\le X \\le x + \\delta)}{P(y \\le Y \\le y + \\epsilon)} \\approx \\frac{f_{X, Y}(x, y)\\cdot\\epsilon\\delta}{f_Y(y)\\cdot\\epsilon} \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$\n\nLimiting case when $\\epsilon \\rightarrow 0$, to define conditional PDF where the denominator is a zero-probability event.\n\n**Conditional Expectation**\n\nThe conditional expectation of X given that A has happened is defined by \n\n$$\nE[X|A] = \\int_{-\\infty}^\\infty xf_{X|A}(x)\\mathrm dx\n$$\n\nFor a function g, we have\n\n$$\nE[g(X)|A] = \\int_{-\\infty}^\\infty g(x)f_{X|A}(x)\\mathrm dx\n$$\n\n**Total expectation theorem**\n\nLe $A_1, A_2, \\dots A_n$ be disjoint events that form a partition of the sample space $\\Omega$. And $P(A_i)\\gt 0$ for all $i$. Then\n\n$$\nE[g(X)] = \\sum_{i=1}^n P(A_i)E[g(X)|A_i]\n$$\n\nConditional Expectation\n\n\nThe conditional expectation of X given that $Y = y$ has happened is defined by \n\n$$\nE[X|Y=y] = \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx\n$$\n\nFor a function g, we have\n\n$$\nE[g(X)|Y=y] = \\int_{-\\infty}^\\infty g(x)f_{X|Y}(x|y)\\mathrm dx\n$$\n\nTotal expectation theorem\n\n$$\nE[X] = E_{Y}\\left[E_{X|Y}[X|Y]\\right] = \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy\n$$\n\n**Independence**\n\nTwo continuous RVs $X$ and $Y$ are independent if and only if\n\n$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$\n\nIndependence is the same as the condition\n\n$$\nf_{X|Y}(x|y) = f_X(x)\n$$\n\nIf $X$ and $Y$ are independent, then\n\n$$\nE[XY] = E[X]E[Y]\\\\\nE[g(x)h(y)] = E[g(x)]E[h(y)], \\forall g, h\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\\\\\n$$\n\n### The continuous Bayes's rule\n\n\n$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{f_Y(y)}\n$$\n\nBased on the normalization property $\\int_{-\\infty}^\\infty f_{X|Y}(x|y)\\mathrm dx = 1$,\n\n$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{\\int_{-\\infty}^\\infty f_X(t)f_{Y|X}(y|t)\\mathrm dt}\n$$\n\n## Derived distributions and Entropy\n\n### Derived Distribution\n\nIf we want to calculate the expectation $E[g(X)]$, there's no need to calculate the PDF $f_X$ of $X$.\n\nBut sometimes we want the PDF $f_Y$ of $Y = g(X)$, where $Y$ is a new RV.\n\n**Principal Method**\n\nTwo-step procedure for the calculation of the PDF of a function $Y=g(X)$ of a continuous RV $X$\n\n1. Calcualte the CDF $F_Y$ of $Y$: $F_Y(y) = P(Y \\le y)$\n2. Differentiate $F_Y$ to obtain the PDF $f_Y$ of $Y$: $f_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y)$\n\n**The PDF of $Y=aX + b$**\n\nSuppose $a>0$ and $b$ are constants.\n\n$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(\\frac{y-b}{a}) = \\frac{1}{a}f_X(\\frac{y-b}{a})\n$$\n\nIf $X$ is Normal, then $Y = aX + b$ is also Normal.\n\nSuppose X is normal with mean $\\mu$ and variance $\\sigma^2$. Then\n\n$$\nf_Y(y) = \\frac{1}{a\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y-b-a\\mu)^2}{2a^2\\sigma^2}\\right)\n$$\n\n$$\nY = aX + b \\sim N(a\\mu + b, a^2\\sigma^2)\n$$\n\n**The PDF of a strictly monotonic function**\n\nSuppose $g$ is a strictly monotonic function and that for some function $h$ and all $x$ in the range of $X$ we have \n\n$$\ny = g(x) \\text{ if and only if } x = h(y)\n$$\n\nAssume that $h$ is differentiable.\n\nThen the PDF of $Y = g(X)$ is given by\n\n$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(h(y)) = f_X(h(y))\\left|\\frac{\\mathrm d h}{\\mathrm d y}(y)\\right|\n$$\n\n### Entropy\n**Defintion**\n\nDiscrete case\n\nLet $X$ be a discrete RV defined on probability space $(\\Omega, \\mathcal F, P)$. The **entropy** of $X$ is defined by\n\n$$\nH(X) = -E[\\ln p_X(X)] = -\\sum_{k} p_X(x_k)\\ln p_X(x_k)\n$$\n\nContinuous case\n\nLet $X$ be a continuous RV defined on probability space $(\\Omega, \\mathcal F, P)$. The **differential entropy** of $X$ is defined by\n\n$$\nH(X) = -E[\\ln f_X(X)] = -\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\n$$\n\n\n**Remarks**\n\n* a special expectation of a random variable\n* a measure of uncertainty in a random experiment\n* - the larger the entropy, the more uncertain the experiment\n* - For a deterministic event, the entropy is zero\n* The base of logarithm can be different. Changing the base od the logarithm is equivalent to multiplying the entropy by a constant.\n* - With base 2, we say that the entropy is in units of **bits**\n* - With base e, we say that the entropy is in units of **nats**\n* The basis of information theory\n\n### Maximum entropy distributions\n\n• Maximum entropy distributions\n\n− Distributions with maximum entropy under some constraints\n\n− Gaussian, exponential, and uniform distributions are all maximum entropy distributions under certain conditions\n\n• Why studying maximum entropy distributions?\n\n− The most random distribution, reflecting the maximum uncertainty about the quantity of interest\n\n**Definition**\n\n**Discrete Case**\n\nX can be a finite number of values $x_1, x_2, \\dots, x_n$, satisfying $p_X(x_k) = p_k.$\n\nWe have the following optimization problem:\n\n$$\n\\max_{X} H(X) = \\max_{p_1, p_2, \\dots, p_n} \\left(-\\sum_{k=1}^n p_k\\ln p_k\\right)\\\\\n\\text{s.t.} \\sum_{k=1}^n p_k = 1, p_k \\ge 0 \\text{ for } k = 1, 2, \\dots, n\n$$\n\n**Solution**\n\nApplying the Lagrange multiplier method, we have\n\n$$\nL(p_1, p_2, \\dots, p_n;\\lambda) = -\\sum_{k=1}^n p_k\\ln p_k + \\lambda\\left(\\sum_{k=1}^n p_k - 1\\right)\\\\\n\\frac{\\partial L}{\\partial p_k} = -\\ln p_k - 1 + \\lambda = 0\\\\\n\\Rightarrow p_k = e^{\\lambda - 1}\\\\\n$$\n\nNote that the above is true for all $k$. So we have\n\n$$\np_k = e^{\\lambda - 1}  = \\frac1{n}\\text{ for } k = 1, 2, \\dots, n.\n$$\n\n**Continuous Case 1**\n\n$X \\in [-\\infty, \\infty]$.\n\nConstrain on mean and variance,\nwe have the following optimization problem:\n\n$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu, \\quad Var(X) = \\sigma^2\n$$\n\nIn detail, \n\n$$\n\\max_{X} H(X) = \\max_{\\mu, \\sigma^2} \\left(-\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{-\\infty}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{-\\infty}^\\infty xf(x)\\mathrm dx = \\mu, \\quad \\int_{-\\infty}^\\infty x^2f(x)\\mathrm dx = \\sigma^2 + \\mu^2\n$$\n\nSolving the above problem, we have Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$.\n\n$$\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\n\n**Solution**\n\nFor all measurable functions $g$, we have\n\n$$\nG(t) = h(f + tg) = -\\int_{\\infty}^\\infty (f(x) + tg(x))\\ln (f(x) + tg(x))\\mathrm dx\n$$\n\nTherefore,\n\n$$\nh(f_{opt})\\ge h(f_{opt} + tg)\\\\\n\\Rightarrow G(0)\\ge G(t), \\forall t \\in \\R\n$$\n\n$G(t)$ reaches its maximum at $t = 0$.\n\nThen apply the Lagrange multiplier method, we have\n\n$$\n\\overline{G}(t) = G(t) + c_0h_0(t) + c_1h_1(t) + c_2h_2(t)\\\\\n$$\n\nGet the derivative of $\\overline{G}(t)$ with regard to $t$, and let the derivative equal to zero.\n\n**Continuous Case 2**\n\n$X \\in [0, \\infty)$.\n\nConstrain on mean only, we have the following optimization problem:\n\n$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu\n$$\n\nIn detail,\n\n$$\n\\max_{X} H(X) = \\max_{\\mu} \\left(-\\int_{0}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{0}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{0}^\\infty xf(x)\\mathrm dx = \\mu\n$$\n\nSolving the above problem, we have exponential distribution with parameter $\\lambda$.\n\n$$\nf(x) = \\lambda e^{-\\lambda x}, x \\in [0, \\infty)\n$$\n\n**Continuous Case 3**\n\n$X \\in [a, b]$.\n\nNo constrain, we have the unconstrained optimization problem:\n\n$$\n\\max_{X}h(X)\n$$\n\nIn detail,\n\n$$\n\\max_{X} H(X) = \\max_{a, b} \\left(-\\int_{a}^b f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{a}^b f(x)\\mathrm dx = 1\n$$\n\nSolving the above problem, we have uniform distribution within $[a, b]$.\n\n$$\nf(x) = \\frac{1}{b-a}, x \\in [a, b]\n$$\n\n## Convolution, covariance, correlation, and conditional expectation\n\n### Convolution\n\n**Discrete case**\n\n$$\n\\begin{align*}\np_W(w) &= P(X+Y=w)\\\\\n&= \\sum_{x}P(X=x, Y=w-x)\\\\\n&= \\sum_{x}P(X=x)P(Y=w-x)\\\\\n&= \\sum_{x}p_X(x)p_Y(w-x)\\\\\n\\end{align*}\n$$\n\nPMF $p_W$ is the convolution of PMFs $p_X$ and $p_Y$.\n\n**The distribution of $X+Y$**\n\nMechanics:\n- Put the PMF's on top of each other\n- Flip the PMF of $Y$\n- Shift the flipped PMF by $w$ (to the right if $w>0$)\n- Cross-multiply and add\n\n**Continuous Case**\n\n$$\n\\begin{align*}\n&W = X+Y, X, Y \\text{ are independent}\\\\\n&P(W\\le w|X=x) = P(Y\\le w-x)\\\\\n&f_{W|X}(w|x) = f_Y(w-x)\\\\\n&f_{W, X}(w, x) = f_X(x)f_Y(w-x)\\\\\n&f_W(w) = \\int_{-\\infty}^\\infty f_X(x)f_Y(w-x)\\mathrm dx\\\\\n\\end{align*}\n$$\n\n**Sum of 2 independent normal RVs**\n\n$$\n\\begin{align*}\n    & X\\sim N(\\mu_1, \\sigma_1^2), Y\\sim N(\\mu_2, \\sigma_2^2)\\\\\n    &f_{X,Y}(x, y) = \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{(x-\\mu_x)^2}{2\\sigma_x^2} - \\frac{(y-\\mu_y)^2}{2\\sigma_y^2}\\right\\rbrace\n\\end{align*}\n$$\n\nwhich is constant on the ellipse(circle if $\\sigma_x = \\sigma_y$).\n\n$$\n\\begin{align*}\n    X\\sim N(0, \\sigma_x), &Y\\sim N(0, \\sigma_y)\\\\\n    W &= X+Y\\\\\n    f_W(w) &= \\int_{-\\infty}^\\infty f_{X,Y}(x, w-x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{x^2}{2\\sigma_x^2} - \\frac{(w-x)^2}{2\\sigma_y^2}\\right\\rbrace\\mathrm dx\\\\\n    =ce^{-\\gamma \\omega^2}\n\\end{align*}\n$$\n\n$W$ is Normal.\n\nMean = 0, Variance = $\\sigma_x^2 + \\sigma_y^2$\n\nSame argument for nonzero mean case.\n\n**The difference of two independent RVs**\n\n$X$ and $Y$  are independent exponential RVs with parameter $\\lambda$.\n\nFix some $z\\ge 0$ and note that $f_Y(x-z)$ is non zero when $x\\ge z$.\n\n$$\n\\begin{align*}\n    Z &= X - Y\\\\\n    f_Z(z) &= \\int_{-\\infty}^\\infty f_X(x)f_{-Y}(z - x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty f_X(x)f_{Y}(x - z)\\mathrm dx\\\\\n    &= \\int_{z}^\\infty \\lambda e^{-\\lambda x}\\lambda e^{-\\lambda(x-z)}\\mathrm dx\\\\\n    &= \\frac{\\lambda}{2}e^{-\\lambda z}\n\\end{align*}\n$$\n\nThe answer for the case $z\\le 0$\n\n$$\nf_{X-Y}(z) = f_{Y-X}(z) = f_Z(-z)\n$$\n\nThe first quality holds by symmetry.\n\n### Covariance and Correlation\n\n**Definition**\n\nThe covariance of two RVs $X$ and $Y$, denoted by $\\text{cov}(X, Y)$, is defined by\n\n$$\n\\text{cov}(X, Y) = E\\left[(X - E[X])(Y - E[Y])\\right]\n$$\n\nor, \n\n$$\n\\text{cov}(X, Y) = E[XY] - E[X]E[Y]\n$$\n\n$X$ and $Y$ are **uncorrelated** if $\\text{cov}(X, Y) = 0$.\n\n**Zero mean case** $\\text{cov}(X, Y) = E[XY]$\n\n**Properties**\n\n$$\n\\text{cov}(X, Y) = \\text{var}(X, Y)\\\\\n\\text{cov}(X, aY+b) = a\\cdot\\text{cov}(X, Y)\\\\\n\\text{cov}(X, Y+Z) = \\text{cov}(X, Y) + \\text{cov}(X, Z)\\\\\n\\text{independent} \\Rightarrow \\text{cov}(X, Y) = 0(\\text{converse is not true})\n$$\n\n**Variance of the sum of RVs**\n\n$$\n\\text{var}\\left(\\sum_{i = 1}^nX_i\\right) = \\sum_{i = 1}^n\\text{var}(X_i) + \\sum_{\\lbrace(i, j)|i\\ne j\\rbrace}\\text{cov}(X_i, X_j)\n$$\n\nIn particular, \n\n$$\n\\text{var}(X_1 + X_2) = \\text{var}(X_1) + \\text{var}(X_2) + 2\\text{cov}(X_1, X_2)\n$$\n\n**Correlation coefficient**\n\nThe correlation coefficient $\\rho(X, Y)$ of two RVs $X$ and $Y$ that have nonzero variance is defined as\n\n$$\n\\begin{align*}\n\\rho &= E\\left[\\frac{(X - E[X])}{\\sigma_X} \\cdot \\frac{(Y - E[Y])}{\\sigma_Y}\\right]\\\\\n&= \\frac{\\text{cov}(X, Y)}{\\sigma_X\\sigma_Y}\n\\end{align*}\n$$\n\n* $-1 \\le \\rho \\le 1$\n* $|\\rho| = 1 \\Leftrightarrow (X-E[X]) = c(Y-E[Y])$\n* Independent $\\Rightarrow \\rho = 0(\\text{converse is not true})$\n\n**Conditional expected value**\n\n$$\nE[X|Y = y] = \\sum_x xp_{X|Y}(x|y)\n$$\n\n### Conditional expectation\n\n**Definition**\n\n$$\nE[X|Y = y] = \\begin{cases}\n    \\sum_x xp_{X|Y}(x|y), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$\n\n$E[X|Y=y]$ is a function of $y$.\n\n$$\nE[X|Y = y] = \\frac{y}{2}(\\text{number})\\\\\nE[X|Y] = \\frac{Y}{2}(\\text{RV})\n$$\n\n**Law of iterated expectations**\n\n$$\nE[X] = E[E[X|Y]] = \\begin{cases}\n    \\sum_y E[X | Y = y]p_Y(y), & Y \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy, & Y \\text{continuous}.\n\\end{cases}\n$$\n\n### Conditional expectation as an estimator\n\nDenote the conditional expectation\n\n$$\n\\hat{X} = E[X|Y]\n$$\n\nas an estimator of $X$ given $Y$, and the estimation error\n\n$$\n\\tilde{X} = X - \\hat{X}\n$$\n\nis a RV.\n\n**Properties of the estimator**: \n\n**Unbiased**\n\nFor **any** possible $Y=y$:\n\n$$\nE[\\tilde{X}|Y] = E[X - \\hat{X} | Y] = E[X | Y] - E[\\hat{X}|Y] = \\hat{X} - \\hat{X} = 0\n$$\n\nBy the law of iterated expectations\n\n$$\nE[\\tilde{X}] = E[E[\\tilde{X}|Y]] = 0\n$$\n\n**Uncorrelated**\n\n$$\nE[\\hat{X}\\tilde{X}] = E[E[\\hat{X}\\tilde{X}|Y]] = E[\\hat{X}E[\\tilde{X}|Y]] = 0\n$$\n\n$$\n\\text{cov}(\\hat{X}, \\tilde{X}) = E[\\hat{X}\\tilde{X}] - E[\\hat{X}]E[\\tilde{X}] = 0\n$$\n\nSince $X = \\hat{X} + \\tilde{X}$, the variance of X can be decomposed as\n\n$$\n\\text{var}(X) = \\text{var}(\\hat{X}) + \\text{var}(\\tilde{X})\n$$\n\n$$\n\\text{var}(\\tilde{X}) = \\text{var}(E[X|Y])\n$$\n\nConditional variance\n\n$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$\n\nhere comes the law of total variance:\n\n$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$\n\nThe total variability is avarage variability within sections + variability between sections.\n\n**Law of iterated expectations**\n\n$$\nE[X] = E[E[X|Y]] = \\sum_y E[X|Y = y]p_Y(y)\n$$\n\n\n**Conditional variance**\n\n$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$\n\n**Law of total variance**\n\n$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$\n\n\n## Transforms and sum of a random number of random variables\n\nThe transform associated with a RV $X$ is a function $M_X(s)$ of a scalar parameter $s$, defined by\n\n$$\nM_X(s) = E[e^{sX}] = \\begin{cases}\n    \\sum_x e^{sx}p_X(x), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty e^{sx}f_X(x)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$\n\n**Remarks**\n- a function of $s$, rather than a number\n- not necessarily defined for all (complex) s\n- always well defined for $\\Re(s)=0$\n- compared with Laplace transform\n### Properties\n**Sanity Checks**\n\n$$\nM_X(0) = 1\\\\\n|M_X(s)| \\le 1 \\text{ for } \\Re(s) = 0\n$$\n\n**Linear operation**\n$$\nM_{aX + b}(s) = e^{bs}M_X(as)\\\\\nM_{X + Y}(s) = M_X(s)M_Y(s) (\\text{if X, Y independent})\n$$\n\n**Expected Values**\n\n$$\nE[X^n] = \\frac{\\partial^n M_X(s)}{\\partial s^n}\\bigg|_{s=0}\n$$\n\n$$\nP(X = c) = \\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc}\n$$\n\nsince\n\n$$\n\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N e^{-jc(k - x)} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac{1}{N} \\frac{e^{j(x-c)} - e^{Nj(x - c)}}{1-e^{j(x-c)}} = p_X(c)\n$$\n\n**Example**\n\n$X$ is a Poisson RV with parameter $\\lambda$\n\n$$\np_X(x) = \\frac{\\lambda^x}{x!}e^{-\\lambda}\n$$\n\n$$\nM(s) = \\sum_{x = 0}^\\infty e^{sx}\\frac{\\lambda^x}{x!}e^{-\\lambda} = e^{-\\lambda}\\sum_{x = 0}^\\infty \\frac{(e^s\\lambda)^x}{x!} = e^{-\\lambda}e^{e^s\\lambda} = e^{\\lambda(e^s - 1)}\n$$\n\n$X$ is an exponential RV with parameter $\\lambda$\n\n$$\nf_X(x) = \\lambda e^{-\\lambda x}\n$$\n\n$$\nM(s) = \\int_0^\\infty e^{sx}\\lambda e^{-\\lambda x}\\mathrm dx = \\frac{\\lambda}{\\lambda - s}\n$$\n\n$Y$ is a standard normal RV, \n\n$$\nM_Y(s) = \\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi}}e^{-(y^2/2)}e^{sy}\\mathrm dy = e^{s^2/2}\n$$\n\nConsider $X = \\sigma Y + \\mu$\n\n$$\nM_X(s) = e^{s^2\\sigma^2/2 + \\mu s}\n$$\n\n### Inversion of transforms\n\n**Inversion Property**\n\nThe transform $M_X(s)$ associated with a RV $X$ uniquely determines the CDF of $X$, assuming that $M_X(s)$ is finite for all $s$ in some interval $[-a, a]$, where $a$ is a positive number.\n\nExample:\n\n$$\n\\begin{align*}\nM(s) &= \\frac{pe^s}{1 - (1 - p)e^s}\\\\\n&= pe^s(1 + (1-p)e^s + (1-p)^2e^{2s} + \\dotsb)\\\\\n&= \\sum_{k = 1}^\\infty p(1-p)^{k - 1}e^{ks}\n\\end{align*}\n$$\n\nThe probability $P(X = k)$ is found by reading the coefficient of the term $e^{ks}$:\n\n$$\nP(X = k) = p(1-p)^{k-1}\n$$\n\n### Transform of Mixture of Distributions\n\nLet $X_1,\\dotsb, X_n$ be continuous RVs with PDFs $f_{X_1}, \\dotsb, f_{X_n}$.\n\nThe value $y$ of RV $Y$ is generated as follows: an index $i$ is chosen with a corresponding probability $p_i$, and $y$ is taken to be equal to the value $X_i$. Then, \n\n$$\nf_Y(y) = p_1f_{X_1}(y) + \\dotsb + p_nf_{X_n}(y)\\\\\nM_Y(s) = p_1M_{X_1}(s) + \\dotsb + p_nM_{X_n}(s)\n$$\n\n### Sum of independend RVs\n\nLet $X$ and $Y$ be independent RVs, and let $Z = X + Y$. The transform associated with $Z$ is \n\n$$\nM_Z(s) = M_X(s)M_Y(s)\n$$\n\nSince\n\n$$\nM_Z(s) = E[e^{sZ}] = E[e^{s(X + Y)}] = E[e^{sX}e^{sY}] = E[e^{sX}]E[e^{sY}] = M_X(s)M_Y(s)\n$$\n\nGeneralization:\n\nA collection of independent RVs: $X_1, \\dotsb, X_n$, $Z = X_1 + \\dotsb + X_n$ ,\n\n$$\nM_Z(s) = M_{X_1}(s)\\dotsb M_{X_n}(s)\n$$\n\n**Example**\n\nLet $X_1, \\dotsb, X_n$ be independent Bernoulli RVs with a common parameter $p$:\n\n$$\nM_{X_i}(s) = 1 - p + pe^s\n$$\n\n$Z = X_1 + \\dotsb + X_n$ is binomial with parameters n and p:\n\n$$\nM_z(s) = (1 - p + pe^s)^n\n$$\n\nLet $X$ and $Y$ be independent Poisson RVs with means $\\lambda$ and $\\mu$, and let $Z = X + Y$. Then $Z$ is still Poisson with mean $\\lambda + \\mu$.\n\n$$\nM_Z(s) = M_X(s)M_Y(s) = e^{(\\lambda +\\mu)(e^s - 1)}\n$$\n\nLet $X$ and $Y$ be independent Gaussian RVs with means $\\mu_x$ and $\\mu_y$, and variances $\\sigma_x^2, \\sigma_y^2$. And let $Z = X + Y$. Then $Z$ is still Gaussian with mean $\\mu_x + \\mu_y$ and variance $\\sigma_x^2 + \\sigma_y^2$\n\n$$\nM_X(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_x^2s^2}{2} + \\mu_x s\\bigg\\rbrace\\\\\nM_Y(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_y^2s^2}{2} + \\mu_y s\\bigg\\rbrace\\\\\nM_Z(s) = M_X(s)M_Y(s) = \\exp\\bigg\\lbrace\\frac{(\\sigma_x^2 + \\sigma_y^2)s^2}{2} + (\\mu_x + \\mu_y)s\\bigg\\rbrace\n$$\n\nConsider\n\n$$\nY = X_1 + \\dotsb + X_N\n$$\n\nwhere $N$ is a RV that takes integer values, and $X_1, \\dotsb, X_N$ are identically distributed RVs.\n\nAssume that $N, X_1, \\dotsb$ are independent.\n\n$$\nE[Y|N = n] = E[X_1 + X_2 + \\dotsb + X_n|N = n] = nE[X]\\\\\nE[Y|N] = NE[X]\\\\\nE[Y] = E[E[Y|N]] = E[NE[X]] = E[N]E[X]\n$$\n\nFor the variance, \n\n$$\nE[Y|N] = NE[X]\\\\\n\\text{var}(E[Y|N]) = (E[X])^2\\text{var}(N)\\\\\n\\text{var}(Y|N=n) = n\\text{var}(X)\\\\\n\\text{var}(Y|N) = N \\text{var}(X)\\\\\nE[\\text{var}(Y|N)] = E[N]\\text{var}(X)\\\\\n$$\n\nSo, \n\n$$\n\\text{var}(Y) = E[\\text{var}(Y|N)] + \\text{var}(E[Y|N]) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\n$$\n\nFor transform,\n\n$$\nE[e^{sY}|N = n] = E[e^{sX_1}\\dotsb e^{sX_n}|N = n] = E[e^{sX}]^n = (M_X(s))^n\\\\\nM_Y(s) = E[e^{sY}] = E[E[e^{sY}|N]] = E[(M_X(s))^N] = \\sum_{n = 0}^\\infty (M_X(s))^n p_N(n) = \\sum_{n = 0}^\\infty e^{n\\log M_X(s)}p_N(n) = M_N(\\log M_X(s))\n$$\n\n**Summary on Properties**\n\nConsider the sum\n\n$$\nY = X_1 + \\dotsb + X_N\n$$\n\nwhere $N$ is a RV that takes integer values, and $X_1, X_2, \\dotsb$ are identically distributed RVs. Assume that $N$, $X_1, X_2, \\dotsb$ are independent.\n\n$$\nE[Y] = E[N]E[X]\\\\\n\\text{var}(Y) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\\\\\nM_Y(s) = M_N(\\log M_X(s))\n$$\n\n**Example**\n\nAssume that $N$ and $X_i$ are both geometrically distributed with parameters $p$ and $q$ respectively. All of these RVs are independent. $Y = X_1 + \\dotsb + X_N$\n\n$$\nM_N(s) = \\frac{pe^s}{1 - (1-p)e^s}\\\\\nM_X(s) = \\frac{qe^s}{1 - (1-q)e^s}\\\\\nM_Y(s) = M_N(\\log M_X(s)) = \\frac{pqe^s}{1 - (1-pq)e^s}\n$$\n\n$Y$ is also geometrically distributed, with parameter $pq$.\n\n## Weak law of large numbers\n\n### Markov inequality\n\nIf a RV $X$ can only take nonnegative values, then\n\n$$\nP(X \\ge a) \\le \\frac{E[X]}{a}, \\text{ for all } a \\gt 0.\n$$\n\nIntuition: If a nonnegative RV has a small mean, then the probability that it takes a large value must be small。\n\nFix a positive number $a$, \n\n$$\nE[X] = \\int_0^\\infty xf_X(x)dx = \\int_0^a xf_X(x)dx + \\int_a^\\infty xf_X(x)dx \\ge 0 + \\int_a^\\infty xf(x)dx \\ge \\int_a^\\infty af_X(x)dx = aP(X \\ge a)\n$$\n\n### Chebyshev's Inequality\n\nIf $X$ is a RV with mean $\\mu$ and variance $\\sigma^2$, then\n\n$$\nP(|X - \\mu| \\ge c) \\le \\frac{\\sigma^2}{c^2}\n$$\n\nIntuition: If a RV has small variance, then the probability that it takes a value far from its mean is also small.\n\n$$\n\\begin{align*}\n\\sigma^2 &= \\int (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} (x - \\mu)^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} c^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty c^2f_X(x)\\mathrm dx\\\\\n&= \\int_{|x - \\mu| \\ge c} c^2f_X(x)\\mathrm dx\\\\\n&=c^2P(|X - \\mu| \\ge c)\n\\end{align*}\n$$\n\nThe upperbounds of $\\sigma^2$:\n\n$$\nX \\in [a, b]\\\\\n\\sigma^2 \\le (b - a)^2/4\n$$\n\n**Chernoff inequality**\n\nIf a RV $X$ has MGF $M_X(s)$, then\n\n$$\nP(X \\ge a) \\le e^{-\\max_{s\\ge 0}\\left(sa - \\ln M_X(s)\\right)}\n$$\n\nor, for $s \\ge 0$\n\n$$\nP(X\\ge a) \\le e^{-sa}M_X(s)\n$$\n\nfor $s \\lt 0$\n\n$$\nP(X \\le a) \\le e^{-sa}M_X(s)\n$$\n\nproof: for $s \\ge 0$\n\n$$\nM_X(s) = \\int_{-\\infty}^a e^{sx}f_X(x)\\mathrm dx + \\int_a^{\\infty} e^{sx}f_X(x)\\mathrm dx\\\\\n\\ge 0 + e^{sa}\\int_a^{\\infty} f_X(x)\\mathrm dx = e^{sa}P(X \\ge a)\n$$\n\n### Weak law of large numbers\n\nLet $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$\n\n$$\nM_n = \\frac{X_1 + X_2 + \\dotsb + X_n}{n}\\\\\nE[M_n] = \\mu\\\\\n\\text{var}(M_n) = \\frac{\\sigma^2}{n}\n$$\n\nApplying the Chebyshev inequality and we get:\n\n$$\nP(|M_n - \\mu| \\ge \\epsilon) \\le \\frac{\\text{var}(M_n)}{\\epsilon^2} = \\frac{\\sigma^2}{n\\epsilon^2}\n$$\n\nFor large $n$, the bulk of the distribution of $M_n$ is concentrated near $\\mu$\n\n**Theorem**\n\nLet $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$. For every $\\epsilon \\gt 0$, we have\n\n$$\nP(|M_n - \\mu| \\ge \\epsilon) = P\\left(\\left|\\frac{X_1 + \\dotsb + X_n}{n} - \\mu\\right|\\ge \\epsilon\\right) \\rightarrow 0, \\text{ as } n \\rightarrow \\infty\n$$\n\n$M_n$ converges **in probability** to $\\mu$.\n\n### Convergence \"in Probability\"\n\nTheorem: Convergence in Probability\n\nLet $\\lbrace Y_n\\rbrace$(or $Y_1, Y_2, \\dots$) be a sequence of RVs(not necessarily independent), and let $a$ be a real number. We say that the sequence $Y_n$ **converges to** $a$ in probability, if for every $\\epsilon \\gt 0$, we have \n\n$$\n\\lim_{n \\rightarrow \\infty} P(|Y_n - a| \\ge \\epsilon) = 0\n$$\n\n(almost all) of the PMF/PDF of $Y_n$, eventually gets concentrated (arbitrarily) close to $a$.\n\n### Many types of convergence\n\nDeterministic limits: $\\lim_{n\\rightarrow \\infty} a_n = a$\n\n$$\n|a_n - a|\\le \\epsilon, \\forall n \\ge N, \\epsilon \\gt 0\n$$\n\nConvergence in probability: $X_n\\stackrel P{\\rightarrow} X$\n\n$$\n\\lim_{n \\rightarrow \\infty}P(|X_n - X|\\ge \\epsilon) = 0, \\forall \\epsilon \\gt 0\n$$\n\n(WLLN)\n\nConvergence in Distribution: $X_n \\stackrel{D}{\\rightarrow} X$\n\n$$\n\\lim_{n \\rightarrow \\infty} P(X_n \\le x) = P(X \\le x), \\forall x\n$$\n\nFor all points of $x$ at which the function $F_X(x) = P(X\\le x)$is continuous.\n\n(CLT)\n\nConvergence with probability $1$(almost surely): $X_n \\stackrel{\\text{a.s.}}{\\rightarrow} X$\n\n$$\nP\\left(\\lbrace\\omega\\in \\Omega: \\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\rbrace\\right) = 1\n$$\n\nor \n\n$$\nP\\left(\\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\right) = 1\n$$\n\nLemma:\n\n$$\nX_n \\stackrel{\\text{a.s.}}{\\rightarrow} X \\Leftrightarrow \\lim_{m \\rightarrow\\infty}P(|X_n - X|\\le \\epsilon, \\forall n \\gt m) = 1, \\forall \\epsilon \\gt 0\\\\\n\\Leftrightarrow P(|X_n - X|\\gt \\epsilon, \\text{i.o.}) = 0, \\forall \\epsilon \\gt 0\n$$\n\ni.o. stand for infinitely often\n\n(SLLN)\n\nConvergence in Mean/in Norm: $X_n \\stackrel{r}{\\rightarrow}X$\n\nif $E[X_n^r] \\lt \\infty$ for all $n$ and \n\n$$\n\\lim_{n \\rightarrow \\infty}E[|X_n - X|^r] = 0\n$$\n\nRelations:\n\n$$\n\\left(X_n\\stackrel {\\text{a.s.}}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\forall r\\ge s\\ge 1, \\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel s{\\rightarrow} X\\right)\n$$\n\nThe converse assertions fail in general!\n\nThe relation between “almost surely” and “in r-th mean” is complicated. There exist sequences which converge almost surely but\nnot in mean, and which converge in mean but not almost surely!\n\n## Central Limit Theorem\n\n### Theorem\n\nLet $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$ and variance $\\sigma^2$. Let \n\n$$\nZ_n = \\frac{X_1 + X_2 + \\dotsb + X_n - n\\mu}{\\sigma\\sqrt{n}}\n$$\n\nThen\n\n$$\n\\lim_{n\\rightarrow \\infty}P(Z_n\\le z) = \\Phi (z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^z e^{-\\frac{x^2}{2}}\\mathrm dx\n$$\n\nCDF of $Z_n$ converges to normal CDF(converge in distribution)\n\n### Normal Approximation Based on the Central Limit Theorem\n\nLet $S_n = X_1 + \\dotsb + X_n$, where $X_i$ are $\\text{i.i.d.}$ RVs with mean $\\mu$ and variance $\\sigma^2$. If $n$ is large, the probability $P(S_n ≤ c)$ can be approximated by\ntreating $S_n$ as if it were normal, according to the following procedure.\n\n1. Calculate the mean $n\\mu$ and the variance $n\\sigma^2$ of $S_n$\n2. Calculate the normalinzd value $z = (c - n\\mu)/(\\sigma\\sqrt{n})$\n3. Use the approxmation\n\n$$\n    P(S_n \\le c)  \\approx \\Phi(z)\n$$\n\nwhere $\\Phi(z)$ is available from the standard normal CDF.\n\n### Proof\n\nSuppose that $X_1, X_2, \\dots$ has mean zero.\n\n$$\n\\begin{align*}\nM_{Z_n}(s) &= E[e^{sZ_n}]\\\\\n&=E\\left[\\exp\\left(\\frac{s}{\\sigma\\sqrt{n}}\\sum_{i = 1}^n X_i\\right)\\right]\\\\\n&=\\prod_{i = 1}^n E[e^{\\frac{s}{\\sigma\\sqrt{n}}X_i}]\\\\\n&=\\prod_{i = 1}^n M_{X_i}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\\\\n&=\\left(M_{X}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\right)^n\\\\\n\\end{align*}\n$$\n\nSuppose that the transform $M_X(s)$ has a second order Taylor series expansion around $s=0$,\n\n$$\nM_X(s) = a + bs + cs^2 + o(s^2)\n$$\n\nwhere $a = M_X(0) = 1, b = M_X'(0) = E[X] = 0, c = \\frac{1}{2}M_X''(0) = \\frac{\\sigma^2}{2}$\n\nThen\n\n$$\nM_{Z_n}(s) = \\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n\n$$\n\nAs $n\\rightarrow \\infty$, \n\n$$\n\\lim_{n\\rightarrow \\infty}M_{Z_n}(s) = \\lim_{n\\rightarrow \\infty}\\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n = e^{\\frac{s^2}{2}}\n$$\n\nApproxmation on binomial:\n\n(De Moivre-Laplace Approxmation to the Binomial)\n\n$$\nP(k \\le S_n \\le l) = P\\left(\\frac{k - np}{\\sqrt{np(1-p)}} \\le \\frac{S_n - np}{\\sqrt{np(1 - p)}} \\le \\frac{l - np}{\\sqrt{np(1 - p)}}\\right)\\\\\n\\approx \\Phi\\left(\\frac{l - np}{\\sqrt{np(1 - p)}}\\right) - \\Phi\\left(\\frac{k - np}{\\sqrt{np(1 - p)}}\\right)\n$$\n\n## The Strong Law of Large Numbers\n\n### Theorem\n\nLet $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$.\n\n$$\nP(\\lim_{n \\rightarrow\\infty}\\frac{X_1 + \\dots + X_n}{n} = \\mu) = 1.\n$$\n\n## Borel-Cantelli lemma & Bernoulli Process\n\n### Limit of set sequence\n\n$$\n\\limsup_n A_n = \\bigcap_{n = 1}^\\infty \\bigcup_{k = n}^\\infty A_k\\\\\n\\liminf_n A_n = \\bigcup_{n = 1}^\\infty \\bigcap_{k = n}^\\infty A_k\n$$\n\nIf upper limit equals to lower limit, the limit of set sequence exists.\n\n$$\n\\limsup_n A_n \\supseteq \\liminf_n A_n\\\\\n\\limsup_n A_n = \\liminf_n A_n = \\lim_n A_n\n$$\n\nUpper limit can also be denoted as\n\n$$\n\\limsup_n A_n = \\{\\omega: \\omega \\in A_n, \\text{i.o.}\\} = \\lbrace A_n, \\text{i.o.}\\rbrace\n$$\n\n### Borel-Cantelli Lemma\n\nLet $\\lbrace A_n, n = 1, 2, \\dotsb\\rbrace$ be a sequence of events, then\n\n$$\n\\sum_{n = 1}^\\infty P(A_n)\\lt \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 0\n$$\n\nLet $\\lbrace A_n, n = 1, 2, \\dotsb\\rbrace$ be a sequence of **independent** events, then\n\n$$\n\\sum_{n = 1}^\\infty P(A_n) = \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 1\n$$\n\n### Stochastic process\n\nA stochastic process is a mathematical model of a probabilistic experiment that evolves in time and generates a sequence of\nnumerical values.\n\n* Bernoulli process(memoryless, discrete time)\n* Poisson process(memoryless, continuous time)\n\n### **The Bernoulli Process** \n\nis a sequence of independent Bernoulli trials, each with probability of success $p$.\n\n$$\nP(\\text{success}) = P(X_i = 1) = p\\\\\nP(\\text{failure}) = P(X_i = 0) = 1 - p\n$$\n\n**Independence property**: For any given time $n$, the sequence of $X_{n + 1}, X_{n + 2}, \\dots$ is also a Bernoulli process, and is independent from $X_1, \\dots, X_n$\n\n**Memoryless property**: Let $n$ be a given time and let $\\overline T$ be the time of the first success after\ntime $n$. Then $\\overline T − n$ has a geometric distribution with parameter $p$,\nand is independent of the RVs $X_1, \\dots , X_n$.\n\n$$\nP(\\overline T - n = t | \\overline T \\gt n) = (1 - p)^{t - 1}p = P(T = t)\n$$\n\n**Interarrival times**\n\nDenote the $k$th success as $Y_k$, the $k$th interarrival time as $T_k$.\n\n$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$\n\nrepresents the number of trials following the $(k - 1)$th success until the next success.\n\nNote that\n\n$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$\n\nAlternative description of the Bernoulli process: \n* Start with a sequence of independent geometric RVs $T_1, T_2, \\dots$ with common parameter p, and let these stand for the interarrival times.\n* Record a success at times $T_1$, $T_1 + T_2$, etc.\n\n$$\nE[Y_k] = \\frac{k}{p}\\\\\n\\text{var}(Y_k) = \\frac{k(1 - p)}{p^2}\n$$\n\n$$\np_{Y_k}(t) = \\binom{t - 1}{k - 1}p^k(1 - p)^{t - k}\n$$\n\n**Splitting of a Bernoulli process**\n\nWhenever there is an arrival, we choose to either keep it (with probability $q$), or to discard it (with probability $1 − q$).\n\nBoth the process of arrivals that are kept and the process of discarded arrivals are Bernoulli processes, with success probability $pq$ and $p(1 − q)$, respectively, at each time.\n\n**Merging of a Bernoulli process**\n\nIn a reverse situation, we start with two independent Bernoulli processes (with parameters $p$ and $q$ respectively). An arrival is\nrecorded in the merged process if and only if there is an arrival in at least one of the two original processes.\n\nThe merged process is Bernoulli, with success probability $p+q−pq$ at each time step.\n\n## The Poisson Process\n\n### Definition\nAn arrival process is called a Poisson process with rate $λ$ if it has the following properties:\n\n**Time homogenity**\n\n$$\nP(k, \\tau) = P(k \\text{ arrivals in interval of duration }\\tau)\n$$\n\n**Independence**\n\nNumbers of arrivals in disjoint time intervals are independent.\n\n**Small interval probabilities**\n\n$$\n\\begin{cases}\n    1 - \\lambda\\tau + o(\\tau), & \\text{if } k = 0,\\\\\n    \\lambda\\tau + o_1(\\tau), & \\text{if } k = 1,\\\\\n    o_k(\\tau), & \\text{if } k > 1.\n\\end{cases}\n$$\n\n### Bernoulli/Poisson Relation\n\nIn a short time interval $\\delta$\n\n$$\nn = t / \\delta\\\\\np = \\lambda\\delta\\\\\nnp = \\lambda t\n$$\n\nFor binomial PMF $p_S(k;n,p)$,\n\n$$\n\\lim_{n\\rightarrow \\infty}p_S(k;n, p) = \\lim_{n\\rightarrow\\infty}\\frac{n!}{(n - k)!k!}p^k(1 - p)^{n - k} = \\frac{(\\lambda t)^k}{k!}e^{-\\lambda t} = P(k, t)\n$$\n\n### PMF of Number of Arrivals $N$\n\n$$\nP(k, \\tau) = \\frac{(\\lambda\\tau)^ke^{-\\lambda\\tau}}{k!}\n$$\n\n$$\nE[N_t] = \\lambda t\\\\\n\\text{var}(N_t) = \\lambda t\n$$\n\n### Time $T$ of the first arrival\n\n$$\nF_T(t) = P(T \\le t) = 1 - P(T \\gt t) = 1 - e^{-\\lambda t}, t\\ge 0\\\\\nf_T(t) = \\lambda e^{-\\lambda t}, t\\ge 0\n$$\n\n**Memoryless property** The  time to next arrival is independent of the past.\n\n### Interarrival times\n\nWe also denote the time of the kth success as $Y_k$, and denote the\nkth interarrival time as $T_k$. That is,\n\n$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$\n\nNote that\n\n$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$\n\n$$\nf_{Y_k}(y) = \\frac{\\lambda^ky^{k-1}e^{-\\lambda y}}{(k - 1)!}, y\\ge 0\n$$\n\n### Merging Poisson Processes\n\n![](../images/prob/L14_1.jpg)\n\n$$\nP(\\text{Arrival is red} | \\text{1 arrival})\\approx \\frac{\\lambda_1\\delta}{(\\lambda_1 + \\lambda_2) \\delta}\n$$\n\n![](../images/prob/L15_1.jpg)","source":"_posts/Introduction-to-Probability.md","raw":"---\ntitle: Introduction-to-Probability\ndate: 2023-02-20 21:05:41\ntags: note\nkatex: true\n---\n\n## Introduction\n\n## Probability Space\n\nProbability space is a triple $(\\Omega, \\mathcal{F}, \\mathbf{P})$, comprised of the following three\nelements:\n\n1 Sample space $\\Omega$: the set of all possible outcomes of an experiment\n\n2 $\\sigma$-algebra (or $\\sigma$-field) $\\mathcal F$: a collection of subsets of $\\Omega$\n\n3 Probability measure $\\mathbf P$: a function that assigns a nonnegative\nprobability to every set in the $\\sigma$-algebra $\\mathcal F$\n\n### Sample space\nMutually exclusive: no identical element.\n\nCollectively exhaustive: all results should be included.\n\n### $\\sigma$-algegra\n\nnot unique\n\n3 requirements:\n\n$$\n\\varnothing \\in \\mathcal F\\\\\n\\forall A \\in \\mathcal F, A^c \\in \\mathcal F\\\\\n\\forall A_k \\in \\mathcal F, k=1, 2, ..., \n\\cup_{k=1}^{\\infty}A_k\\in \\mathcal F\n$$\n\n### Borel field\n\nused to measure intervals\n\nwhen $\\Omega$ is continuous($\\R$ for example), Borel field is useful.\n\n\"minimum\" $\\sigma$-algebra means deleting any element in the $\\mathcal B (\\mathbf R)$ will miss the requirements.\n\n![](../images/prob/L2_1.jpg)\n\n### Uncountable\n\ndecimal numbers between 0 and 1 are uncountable.\n\n### Probability measures\n\n$$\nP:\\mathcal F \\rightarrow [0, 1]\n$$\n\n**Nonnegativity** $P(A)\\ge0, \\forall A \\in \\mathcal{  F}$\n\n**Normalization**  $P(\\empty)=0, P(\\Omega)=1$\n\n**Countable additivity** $A_1, A_2, ... \\text { is disjoint in }\\mathcal F, P(A_1\\cup A_2\\cup ...)=P(A_1)+P(A_2)+...$\n\n* They are the axioms of probability. \n* Probability is a mapping from $\\sigma$-algebra to a real number betwenn 0 and 1, which intuitively specifies the \"likelihood\" of any event. \n* There exist non-measurable sets, on which we cannot define a probability measure.\n\n### Discrete models\n\n$$\nP(\\{s_1, ..., s_n\\})=P(s_1)+...+P(s_n)\\\\\nP(A) = \\frac{\\text{\\# of elements of }A}{\\text{total \\# of elements of sample points}}\n$$\n\n\n### Continuous Models\n\nProbability = Area\n\n### Some properties of Probability measure\n\n$$\nA\\sub B\\Rightarrow P(A)\\le P(B)\\\\\nP(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\\\\nP(A\\cup B) \\le P(A) + P(B)\\\\\nP(A\\cup B \\cup C)=P(A) + P(A^C\\cap B) + P(A^C\\cap B^C\\cap C)\n$$\n\n### Conditional Probability\n\n$$\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}\n$$\n\n* If $P(B)=0$, $P(A|B)$ is undefined.\n* For a fixed event $B$, $P(A|B)$ can be verified as a legitimate probability measure on the new universe. $P(A, B)\\ge 0$, $P(\\Omega|B)=1$, $P(A_1\\cup A_2\\cup...|B)=P(A_1|B)+P(A_2|B)+...$\n* <div>$P(A|B)=\\frac{\\text{ \\# of elements of }A\\cap B}{\\text{total \\# of elements of }B}$</div>\n\n### Total probability theorem\n\nLet $A_1, ..., A_n$ be disjoint events that form a partition of the sample space and assume that $P(A_i)>0$ for all $i$. Then for any event B, we have\n\n$$\nP(B) = \\sum_{i=1}^n P(A_i\\cap B) = \\sum_{i=1}^nP(A_i)P(B|A_i)\n$$\n\n**Remark** \n* The definition of partition is that $\\cup_{i=1}^n A_i = \\Omega, A_i\\cap A_j = \\emptyset, \\forall i\\ne j$\n* The probability of B is a weighted average of its conditional probability under each scenario\n* Each scenario is weighted according to its prior probability\n* Useful when $P(B|A_i)$ is known or easy to derive\n\n### Inference and Bayes' rule\n\nLet $A_1, ..., A_2$ be disjoint events that from a partition of the sample space and assume that $P(A_i) \\gt 0$  for all $i$. Then for any event $B$ such that $P(B)\\gt 0$, we have \n\n$$\nP(A_i|B) = \\frac{P(A_i)P(B|A_i)}{P(B)} = \\frac{P(A_i)P(B|A_i)}{\\sum_{j=1}^nP(A_j)P(B|A_j)}\n$$\n\n**Remarks**\n* Relates conditional probabilities of the form $P(A_i|B)$ with conditional probabilities of the form $P(B|A_i)$\n* often used in inference: effect $B$ $\\lrarr$ cause $A_i$\n\nThe meaning of $P(A_i|B)$ in the view of Bayes: the belief of $A_i$ is revised if we observed effect $B$. If the cause and the effect are closely binded($P(B|A_i) > P(B|A_i^c)$), then the belief $A_i$ is enhanced by the observation of effect $B$($P(A_i|B) > P(A)$). This can be derived from the Bayes' rule through simple calculation. If $P(A_i|B)=P(A_i)$, then $B$ provides no information on $A_i$.\n\n### Independence\n\n#### Independence of two disjoint events\n\nEvents A and B are called **independent** if \n$$\nP(A\\cap B) = P(A)\\cdot P(B)\n$$\nor equivalently, when $P(B) > 0$, \n\n$$\nP(A|B) = P(A)\n$$\n\n**Remarks**\n* Occurrence of B provides no information about A's occurrence\n* Equivalence due to $P(A\\cap B) = P(B)\\cdot P(A|B)$\n* Symmetric with respect to $A$ and $B$.\n* - applies even if $P(B) = 0$\n* - implies $P(B|A) = P(B)$ and $P(A|B^c) = P(A)$\n* Does not imply that A and B are disjoint, indeed opposite!\n* - Two disjoint events are never independent!($P(A\\cap B) = 0$, but $P(A)\\cdot P(B)\\ne 0$)\n\n#### Conditional independence\n\n$$\nP(A\\cap B | C) = P(A| C) \\cdot P(B|C)\n$$\n\n**Definition**\n\nEvent $A_1, A_2, ..., A_n$ are called independent if: \n\n$$\nP(A_i\\cap A_j\\cap ...\\cap A_q) = P(A_1)P(A_j)...P(A_q)\n$$\n\nfor any distinct indices $i, j, \\dots q$ chosen from $\\{1, \\dots n\\}$.\n\nPairwise is independence does not imply independence.\n\n## Discrete Random Variables\n\nRandom Variable is neither random, nor variable.\n\n### Definition\n\nWe care about the probability that $X \\le x$ instead $X = x$ in the consideration of generality. \n\n**Random variables**\n\nGiven a probability space $(\\Omega, F, P)$, a random variable is a function $X: \\Omega \\rightarrow \\R$ with the probability that $\\{\\omega \\in \\Omega: X(\\omega) \\le x\\} \\in \\mathcal F$ for each $x\\in \\R$. Such a function $X$ is said to be $\\mathcal F$-measurable.\n\n**Probability Mass Function(PMF)**\n\n$$\np_X(x)=P(X=x)=P(\\{\\omega \\in \\Omega \\text{ s.t. } X(\\omega)=x\\})\n$$\n\nBonulli PMF: \n\n$$ \np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\n$$\n\nBinomial PMF: $p_X(k)=\\binom{n}{k}p^k(1-p)^{n-k}$\n\nGeometric PMF: $p_X(k)=(1-p)^{k-1}p$\n\nPoisson PMF: $p_X(k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}$. Note: $\\sum_{k=0}^\\infty e^{-\\lambda}\\frac{\\lambda^k}{k!}=e^{-\\lambda}e^\\lambda=1$\n\nIf $y=g(x)$, $p_Y(y)=\\sum_{\\lbrace x|g(x)=y \\rbrace} p(x)$.\n\n\n### Expectation and Variance\n\n**Expectation**\n\n$$\nE[X] = \\sum_x xp_X(x)\n$$\n\nNote: we assume that the sum converges.\n\nProperties:\n\n$$\nE[Y]=\\sum_x g(x)p_X(x)\\\\\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\n$$\n\n**Variance**\n\n$$\n\\text{var}(X) = E \\left[(X-E[X])^2\\right]=\\sum_x (x-E[X])^2 p_X(x)\n$$\n\nStandard deviation: $\\sigma_X=\\sqrt{\\text{var}(X)}$\n\nProperties: \n\n$$\n\\text{var}(X) = E[X^2] -(E[X])^2\\\\\n\\text{var}(X)\\ge 0\\\\\n\\text{var}(\\alpha X + \\beta) = \\alpha^2\\text{var} (X)\n$$\n\n**Bernoulli RV**\n\n$$\np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\\\\\nE[X] = p\\\\\nE[X^2] = p\\\\\n\\text{var}(X) = p(1-p)\n$$\n\n**Discrete Uniform RV**\n\n\n$$\np_X(k) = \\begin{cases}\n    \\frac {1}{b-a+1}, &\\text{if } k = a, a+1, ..., b\\\\\n    0, &\\text{otherwise}\n\\end{cases}\\\\\nE[X] = \\frac{a+b}{2}\\\\\n\\text{var}(X) = \\frac{(b-a)(b-a+2)}{12}\n$$\n\n**Poisson RV**\n\n$$\np_X(k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\\nE[X] = \\lambda\\\\\n\\text{var}(X)=\\lambda\n$$\n\n### Conditional\n\n$$\np_{X|A(x)} = P(X=x|A) = \\frac{P(\\{X=x\\}\\cap A)}{P(A)}\n$$\n\n$$\n\\sum_x p_{X|A}(x) = 1\n$$\n\n$$\nE[X|Y=y] = \\sum_x xp_{X|Y}(x|y)\\\\\nE[g(X)|Y=y] = \\sum_x g(x)p_{X|Y}(x|y)\n$$\n\n**Total expectation theorem**\n\n$A_1, \\dots, A_n$ is a partition of sample space\n\n$$\nP(B) = P(A_1)P(B|A_1) + \\dotsb + P(A_n)P(B|A_n)\\\\\np_X(x) = P(A_1)p_{X|A_1}(x) + \\dotsb + P(A_n)p_{X|A_n}(x)\\\\\nE[X] = P(A_1)E[X|A_1] + \\dotsb + P(A_n)E[X|A_n]\n$$\n\nWe derive the expectation and variance use the theories above.\n\n**Geometric PMF example**\n\n$$\np_X(k) = (1-p)^{k-1}p, k = 1, 2, \\dots\\\\\nE[X] = \\sum_{k=1}^\\infty kp_X(k) = \\sum_{k=1}^\\infty k(1-p)^{k-1}p\\\\\nE[X^2] = \\sum_{k=1}^\\infty k^2p_X(k) = \\sum_{k=1}^\\infty k^2(1-p)^{k-1}p\\\\\n\\text {var}(X) = E[X^2] - (E[X])^2\n$$\n\nHowever, the Geometric has a memoryless property.\n\n$$\np_{X|X>1}(k) = \\frac{P(\\{X>1\\}\\cap \\{X=k\\})}{P(X>1)} = \\frac{(1-p)^{k-1}p}{1-p} = (1-p)^{k-2}p\n$$\n\nThus, \n$$\nE[X] = P(X=1)E[X|X=1] + P(X>1)E[X|X>1]=p+(1-p)(E[1 + X])\\\\\n\\Rightarrow E[X] = 1/p\\\\\nE[X^2] = P(X=1)E[X^2|X=1] + P(X>1)E[X^2|X>1] = p + (1-p)E[(1+X)^2]=p + (1-p)(1+2E[X]+E[X^2])\\\\\n\\Rightarrow E[X^2] = \\frac{2-p}{p^2}\\\\\n\\Rightarrow\\text{var} (X) = \\frac{1-p}{p^2}\n$$\n\n### Multiple discrete random variables\n\n**Joint PMFs**\n\n$$\np_{X, Y}(x, y) = P(X = x, Y= y) = P(\\{X(\\omega) = x\\}\\cap \\{Y(\\omega) = y\\})\n$$\n\n$$\n\\sum_x\\sum_y p_{X, Y}(x, y) = 1\n$$\n\n**Marginal PMF**\n\n$$\np_X(x) = \\sum_y P(X=x, Y=y) = \\sum_y p_{X, Y}(x, y)\n$$\n\n**Conditional PMF**\n\n$$\np_{X|Y}(x|y) = P(X = x | Y = y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$\n\n$$\n\\sum_x p_{X|Y}(x|y) = 1\n$$\n\n**Funcitons of multiple RVs**\n\n$$\nZ = g(X, Y)\\\\\np_Z(z) = \\sum_{\\lbrace (x, y)|g(x, y)=z \\rbrace  } p_{X, Y}(x, y)\n$$\n\n**Expectations**\n\n$$\nE[g(X, Y)] = \\sum_x\\sum_y g(x, y)p(X, Y)(x, y)\\\\\nE[g(X, Y, Z)] = \\sum_x\\sum_y\\sum_z g(x, y, z)p(X, Y, Z)(x, y, z)\n$$\n\n$$\nE[g(X,  Y)] \\not\\equiv g(E[X], E[Y])\n$$\n\n**linearity**\n\n$$\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\\\\\nE[X + Y + Z] = E[X] + E[Y] + E[Z]\n$$\n\nLet's calculate the Mean of Binominal RV.\n\n$$\nX_i=\n\\begin{cases}\n    1, &\\text{if success in trial } i,\\\\\n    0, & \\text{otherwise.}\n\\end{cases}\\\\\nX = X_1 + X_2 + \\dotsb X_n\\\\\nE[X] = \\sum_{i = 1}^n E[X_i] = np\\\\\n\\text{var}(X) = np(1-p)\n$$\n\n### Independence\n\n**Independence**\n\n$$\np_{X, Y}(x, y) = p_X(x) \\cdot p_Y(y)\n$$\n\nif $X$ and $Y$ are independent:\n\n$$\nE[XY] = E[X]E[Y]\\\\\nE[g(X)h(Y)] = E[g(X)]E[h(Y)]\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\n$$\n\n**Conditional independence**\n\n$$\np_{X, Y|A}(X, Y) = p_{X|A}(x) \\cdot p_{Y|A}(y)\n$$\n\n## Continuous Random Variables\n\n\n### Probability Density Function\n\n* $f_X(x)\\ge 0\\text{ for all }x$\n* $\\int_{-\\infty}^\\infty f_X(x)\\mathrm dx = 1$\n* If $\\delta$ is very small, then $P([x, x+\\delta])\\approx f_X(x) \\cdot \\delta$\n* For any subset $B$ of the real line, $P(X\\in B) = \\int_B f_X(x)\\mathrm d x$.\n\n**Expectation**\n\n$$\nE[X] = \\int_{-\\infty}^\\infty xf_X(x)\\mathrm dx\\\\\nE[g(x)] = \\int_{-\\infty}^\\infty g(x)f_X(x)\\mathrm dx\n$$\n\nAssuming that the integration is well-defined. The Cauchy distribution ($\\frac{1}{1+x^2}$)doesn't have expectation since $\\frac{x}{1+x^2}$ is not absolutely integrably.\n\n**Variance**\n\n$$\n\\text{var}(X) = E[(X - E[X])^2] = \\int_{-\\infty}^\\infty(x - E[x])^2 f_X(x)\\mathrm dx\\\\\n0\\le \\text{var}(x) = E[X^2] - (E[X])^2\n$$\n\n**Uniform RV**\n\n$$\nf_X(x) = \\begin{cases}\n    \\frac{1}{b-a}, &\\text{if }a\\le x\\le b,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n$$\nE[X] = \\frac{a+b}{2}\\\\\nE[X^2] = \\frac{a^2+b^2 + ab}{3}\\\\\n\\text{var}(X) = \\frac{(b-a)^2}{12}\n$$\n\n\nProperties:\n\n$$\nE[aX+b] = aE[X] + b\\\\\n\\text{var}(aX+b) = a^2\\text{var}(X)\n$$\n\n### Common Example for PDF\n\n**Exponential Random Variable**\n\n$$\nf_X(x) = \\begin{cases}\n    \\lambda e^{-\\lambda x}, &\\text{if }x \\ge 0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n$$\nP(X\\ge a) = e^{-\\lambda a}\\\\\nE[X] = \\frac{1}{\\lambda}\\\\\n\\text{var}(X) = \\frac{1}{\\lambda^2}\n$$\n\n### Cumulative Distribution Functions\n\n$$\nF_X(x) = P(X\\le x) = \\begin{cases}\n    \\sum_{k\\le x}p_X(k), &\\text{if } X \\text{ is discrete,}\\\\\n    \\int_{-\\infty}^x f_X(t)\\mathrm dt, &\\text{if } X \\text{ is continuous.}\n\\end{cases}\n$$\n\n**Properties**\n\n$$\n\\text{if } x \\le y, \\text{then } F_X(x)\\le F_X(y).\\\\\nF_X(x)\\text{ tends to 0 as } x \\rightarrow -\\infty, \\text{and to 1 as} x \\rightarrow \\infty\\\\\n\\text{If } X \\text{ is discrete, then } F_X(x) \\text{ is a piecewise constant function of }x.\\\\\n\\text{If } X \\text{ is continuous, then } F_X(x) \\text{is a continuous funciton of }x.\\\\\n\\text{If } X \\text{ is discrete and takes integer values, the PMF and the CDF can be obtained from each other by summing or differcing: }\\\\\nF_X(k) = \\sum_{i = -\\infty}^k p_X(i),\\\\\np_X(k) = P(X\\le k) - P(X \\le k -1) = F_X(k) - F_X(k - 1),\\\\\n\\text{ for all integers }k.\\\\\n\\text{If } X \\text{ is continuous, the PDF and the CDF can be obtained from each other by integration or differentiation: }\\\\\nF_X(x) = \\int_{-\\infty}^x f_X(t)\\mathrm dt, f_X(x) = \\frac{\\mathrm dF_X}{\\mathrm dx}(x)\n$$\n\n### Examples for CDF\n\n**Geometric CDF**\n\n$$\nF_{\\text{geo}}(n) = \\sum_{k = 1}^n p(1-p)^{k-1} = 1-(1-p)^n, \\text{for } n = 1, 2, \\dots\n$$\n\n**Exponential CDF**\n\n$$\nF_{\\text{exp}}(x) = P(X\\le x) = 0, \\text{ for } x\\le0,\\\\\nF_{\\text{exp}}(x) = \\int_{0}^x \\lambda e^{-\\lambda t}\\mathrm dt = 1 - e^{-\\lambda x}, \\text{for }x\\ge 0.\n$$\n\nExponential Distribution is Memoriless, like Geometric: \n\n$$\nP(X \\ge c + x| X \\ge c) = e^{-\\lambda x} = P(X \\ge x)\\\\\n$$\n\nThe relationship: \n\n![](../images/prob/L6_1.jpg)\n\n### Normal Random Variables\n\n$$\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-(x-\\mu)^2/2\\sigma^2}\\\\\nE[X] =\\mu\\\\\n\\text{var}(X) = \\sigma^2\n$$\n\nGaussian is good, since adding two Gaussian functions resulting in a new Gaussian functions. And with a huge mount of samples, the distribution is close to Gaussian(Central limit theorem).\n\n**The Standard Normal Random Variable**\n\nNormal(Gaussian)\n\n$$\nY = \\frac{X - \\mu}{\\sigma}\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}}e^{-y^2/2}\\\\\nE[Y] = 0\\\\\n\\text{var}(Y) = 1\\\\\n$$\n\nThe CDF of Normal Random Variable $\\Phi(y)$ can not be derived directly, we can use the standard normal table to get the value.\n\n$$\n\\Phi(-y) = 1 - \\Phi(y)\n$$\n\n### Multiple Continuous Random Variables\n\n**Joint PDFs**\n\nThe two continuous RVs X and Y, with the same experiment, are jointly continuous if they can be described by a joint PDF $f_{X, Y}$, where $f_{X, Y}$ is a nonnegative function that satisfies \n\n$$\nP((X, Y) \\in B) = \\iint_{(x, y)\\in B} f(X, Y)\\mathrm d x\\mathrm dy\n$$\n\nfor every subset B of the two-dimensional plane. In particular, when B is the form $B = \\{(x, y)|a\\le x \\le b, c\\le y \\le d\\}$, we have\n\n$$\nP(a\\le X \\le b, c \\le Y \\le d) = \\int_c^d\\int_a^bf_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$\n\n**Normalization** \n\n$$\n\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\\mathrm dy = 1\n$$\n\n**Interpretation(Small rectangle)**\n\n$$\nP(a\\le X \\le a + \\delta, c \\le Y \\le c + \\delta) \\approx f_{X, Y}(a, c)\\cdot\\delta^2\n$$\n\n**Marginal PDF**\n\n$$\nP(X\\in A) = P(X \\in A, Y \\in (-\\infty, \\infty)) = \\int_A \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\mathrm dx\n$$\n\n$$\nf_X(x) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\\\\nf_Y(y) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\n$$\n\n**Joint CDF**\n\nIf X and Y are two RVs asscociated with the same experiment, then the joint CDF of X and Y is the function\n\n$$\nF_{X, Y}(x, y) = P(X\\le x, Y\\le y) = P(X\\le x|Y\\le y)P(Y\\le y) = \\int_{-\\infty}^y\\int_{-\\infty}^x f_{X, Y}(u, v)\\mathrm du\\mathrm dv\n$$\n\nConversely\n\n$$\nf_{X, Y}(x, y) = \\frac{\\partial^2F_{X, Y}}{\\partial x\\partial y}(x, y)\n$$\n\n**Expectations**\n\n$$\nE[g(X, Y)] = \\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty g(x, y)f_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$\n\nIf g is linear, of the form of $g(x, y) = ax + by + c$, then\n\n$$\nE[g(X, Y)] = aE[X] + bE[Y] + c\n$$\n\nX and Y are called independent if \n\n$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$\n\n### Conditional and Independence\n\n**Conditional PDFs**\n\nLet X and Y be continuous RVs with joint PDF $f_{X, Y}$. For any $f_Y(y) \\gt 0$, the conditional PDF of X given Y = y is defined by\n\n$$\nf_{X|Y}(x|y) = \\frac{f_{X, Y}(x, y)}{f_Y(y)}\n$$\n\nDiscrete case: \n\n$$\np_{X|Y}(x|y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$\n\nBy analogy, for fixed y would like: \n\n$$\nP(x \\le X \\le x + \\delta|Y = y) \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$\n\nBut {Y = y} is a zero-probability event.\n\nLet $B = \\{y\\le Y \\le y + \\epsilon\\}$, for small $\\epsilon > 0$. Then\n\n$$\nP(x \\le X \\le x + \\delta|Y \\in B) \\approx \\frac{P(x \\le X \\le x + \\delta)}{P(y \\le Y \\le y + \\epsilon)} \\approx \\frac{f_{X, Y}(x, y)\\cdot\\epsilon\\delta}{f_Y(y)\\cdot\\epsilon} \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$\n\nLimiting case when $\\epsilon \\rightarrow 0$, to define conditional PDF where the denominator is a zero-probability event.\n\n**Conditional Expectation**\n\nThe conditional expectation of X given that A has happened is defined by \n\n$$\nE[X|A] = \\int_{-\\infty}^\\infty xf_{X|A}(x)\\mathrm dx\n$$\n\nFor a function g, we have\n\n$$\nE[g(X)|A] = \\int_{-\\infty}^\\infty g(x)f_{X|A}(x)\\mathrm dx\n$$\n\n**Total expectation theorem**\n\nLe $A_1, A_2, \\dots A_n$ be disjoint events that form a partition of the sample space $\\Omega$. And $P(A_i)\\gt 0$ for all $i$. Then\n\n$$\nE[g(X)] = \\sum_{i=1}^n P(A_i)E[g(X)|A_i]\n$$\n\nConditional Expectation\n\n\nThe conditional expectation of X given that $Y = y$ has happened is defined by \n\n$$\nE[X|Y=y] = \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx\n$$\n\nFor a function g, we have\n\n$$\nE[g(X)|Y=y] = \\int_{-\\infty}^\\infty g(x)f_{X|Y}(x|y)\\mathrm dx\n$$\n\nTotal expectation theorem\n\n$$\nE[X] = E_{Y}\\left[E_{X|Y}[X|Y]\\right] = \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy\n$$\n\n**Independence**\n\nTwo continuous RVs $X$ and $Y$ are independent if and only if\n\n$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$\n\nIndependence is the same as the condition\n\n$$\nf_{X|Y}(x|y) = f_X(x)\n$$\n\nIf $X$ and $Y$ are independent, then\n\n$$\nE[XY] = E[X]E[Y]\\\\\nE[g(x)h(y)] = E[g(x)]E[h(y)], \\forall g, h\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\\\\\n$$\n\n### The continuous Bayes's rule\n\n\n$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{f_Y(y)}\n$$\n\nBased on the normalization property $\\int_{-\\infty}^\\infty f_{X|Y}(x|y)\\mathrm dx = 1$,\n\n$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{\\int_{-\\infty}^\\infty f_X(t)f_{Y|X}(y|t)\\mathrm dt}\n$$\n\n## Derived distributions and Entropy\n\n### Derived Distribution\n\nIf we want to calculate the expectation $E[g(X)]$, there's no need to calculate the PDF $f_X$ of $X$.\n\nBut sometimes we want the PDF $f_Y$ of $Y = g(X)$, where $Y$ is a new RV.\n\n**Principal Method**\n\nTwo-step procedure for the calculation of the PDF of a function $Y=g(X)$ of a continuous RV $X$\n\n1. Calcualte the CDF $F_Y$ of $Y$: $F_Y(y) = P(Y \\le y)$\n2. Differentiate $F_Y$ to obtain the PDF $f_Y$ of $Y$: $f_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y)$\n\n**The PDF of $Y=aX + b$**\n\nSuppose $a>0$ and $b$ are constants.\n\n$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(\\frac{y-b}{a}) = \\frac{1}{a}f_X(\\frac{y-b}{a})\n$$\n\nIf $X$ is Normal, then $Y = aX + b$ is also Normal.\n\nSuppose X is normal with mean $\\mu$ and variance $\\sigma^2$. Then\n\n$$\nf_Y(y) = \\frac{1}{a\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y-b-a\\mu)^2}{2a^2\\sigma^2}\\right)\n$$\n\n$$\nY = aX + b \\sim N(a\\mu + b, a^2\\sigma^2)\n$$\n\n**The PDF of a strictly monotonic function**\n\nSuppose $g$ is a strictly monotonic function and that for some function $h$ and all $x$ in the range of $X$ we have \n\n$$\ny = g(x) \\text{ if and only if } x = h(y)\n$$\n\nAssume that $h$ is differentiable.\n\nThen the PDF of $Y = g(X)$ is given by\n\n$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(h(y)) = f_X(h(y))\\left|\\frac{\\mathrm d h}{\\mathrm d y}(y)\\right|\n$$\n\n### Entropy\n**Defintion**\n\nDiscrete case\n\nLet $X$ be a discrete RV defined on probability space $(\\Omega, \\mathcal F, P)$. The **entropy** of $X$ is defined by\n\n$$\nH(X) = -E[\\ln p_X(X)] = -\\sum_{k} p_X(x_k)\\ln p_X(x_k)\n$$\n\nContinuous case\n\nLet $X$ be a continuous RV defined on probability space $(\\Omega, \\mathcal F, P)$. The **differential entropy** of $X$ is defined by\n\n$$\nH(X) = -E[\\ln f_X(X)] = -\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\n$$\n\n\n**Remarks**\n\n* a special expectation of a random variable\n* a measure of uncertainty in a random experiment\n* - the larger the entropy, the more uncertain the experiment\n* - For a deterministic event, the entropy is zero\n* The base of logarithm can be different. Changing the base od the logarithm is equivalent to multiplying the entropy by a constant.\n* - With base 2, we say that the entropy is in units of **bits**\n* - With base e, we say that the entropy is in units of **nats**\n* The basis of information theory\n\n### Maximum entropy distributions\n\n• Maximum entropy distributions\n\n− Distributions with maximum entropy under some constraints\n\n− Gaussian, exponential, and uniform distributions are all maximum entropy distributions under certain conditions\n\n• Why studying maximum entropy distributions?\n\n− The most random distribution, reflecting the maximum uncertainty about the quantity of interest\n\n**Definition**\n\n**Discrete Case**\n\nX can be a finite number of values $x_1, x_2, \\dots, x_n$, satisfying $p_X(x_k) = p_k.$\n\nWe have the following optimization problem:\n\n$$\n\\max_{X} H(X) = \\max_{p_1, p_2, \\dots, p_n} \\left(-\\sum_{k=1}^n p_k\\ln p_k\\right)\\\\\n\\text{s.t.} \\sum_{k=1}^n p_k = 1, p_k \\ge 0 \\text{ for } k = 1, 2, \\dots, n\n$$\n\n**Solution**\n\nApplying the Lagrange multiplier method, we have\n\n$$\nL(p_1, p_2, \\dots, p_n;\\lambda) = -\\sum_{k=1}^n p_k\\ln p_k + \\lambda\\left(\\sum_{k=1}^n p_k - 1\\right)\\\\\n\\frac{\\partial L}{\\partial p_k} = -\\ln p_k - 1 + \\lambda = 0\\\\\n\\Rightarrow p_k = e^{\\lambda - 1}\\\\\n$$\n\nNote that the above is true for all $k$. So we have\n\n$$\np_k = e^{\\lambda - 1}  = \\frac1{n}\\text{ for } k = 1, 2, \\dots, n.\n$$\n\n**Continuous Case 1**\n\n$X \\in [-\\infty, \\infty]$.\n\nConstrain on mean and variance,\nwe have the following optimization problem:\n\n$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu, \\quad Var(X) = \\sigma^2\n$$\n\nIn detail, \n\n$$\n\\max_{X} H(X) = \\max_{\\mu, \\sigma^2} \\left(-\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{-\\infty}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{-\\infty}^\\infty xf(x)\\mathrm dx = \\mu, \\quad \\int_{-\\infty}^\\infty x^2f(x)\\mathrm dx = \\sigma^2 + \\mu^2\n$$\n\nSolving the above problem, we have Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$.\n\n$$\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\n\n**Solution**\n\nFor all measurable functions $g$, we have\n\n$$\nG(t) = h(f + tg) = -\\int_{\\infty}^\\infty (f(x) + tg(x))\\ln (f(x) + tg(x))\\mathrm dx\n$$\n\nTherefore,\n\n$$\nh(f_{opt})\\ge h(f_{opt} + tg)\\\\\n\\Rightarrow G(0)\\ge G(t), \\forall t \\in \\R\n$$\n\n$G(t)$ reaches its maximum at $t = 0$.\n\nThen apply the Lagrange multiplier method, we have\n\n$$\n\\overline{G}(t) = G(t) + c_0h_0(t) + c_1h_1(t) + c_2h_2(t)\\\\\n$$\n\nGet the derivative of $\\overline{G}(t)$ with regard to $t$, and let the derivative equal to zero.\n\n**Continuous Case 2**\n\n$X \\in [0, \\infty)$.\n\nConstrain on mean only, we have the following optimization problem:\n\n$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu\n$$\n\nIn detail,\n\n$$\n\\max_{X} H(X) = \\max_{\\mu} \\left(-\\int_{0}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{0}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{0}^\\infty xf(x)\\mathrm dx = \\mu\n$$\n\nSolving the above problem, we have exponential distribution with parameter $\\lambda$.\n\n$$\nf(x) = \\lambda e^{-\\lambda x}, x \\in [0, \\infty)\n$$\n\n**Continuous Case 3**\n\n$X \\in [a, b]$.\n\nNo constrain, we have the unconstrained optimization problem:\n\n$$\n\\max_{X}h(X)\n$$\n\nIn detail,\n\n$$\n\\max_{X} H(X) = \\max_{a, b} \\left(-\\int_{a}^b f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{a}^b f(x)\\mathrm dx = 1\n$$\n\nSolving the above problem, we have uniform distribution within $[a, b]$.\n\n$$\nf(x) = \\frac{1}{b-a}, x \\in [a, b]\n$$\n\n## Convolution, covariance, correlation, and conditional expectation\n\n### Convolution\n\n**Discrete case**\n\n$$\n\\begin{align*}\np_W(w) &= P(X+Y=w)\\\\\n&= \\sum_{x}P(X=x, Y=w-x)\\\\\n&= \\sum_{x}P(X=x)P(Y=w-x)\\\\\n&= \\sum_{x}p_X(x)p_Y(w-x)\\\\\n\\end{align*}\n$$\n\nPMF $p_W$ is the convolution of PMFs $p_X$ and $p_Y$.\n\n**The distribution of $X+Y$**\n\nMechanics:\n- Put the PMF's on top of each other\n- Flip the PMF of $Y$\n- Shift the flipped PMF by $w$ (to the right if $w>0$)\n- Cross-multiply and add\n\n**Continuous Case**\n\n$$\n\\begin{align*}\n&W = X+Y, X, Y \\text{ are independent}\\\\\n&P(W\\le w|X=x) = P(Y\\le w-x)\\\\\n&f_{W|X}(w|x) = f_Y(w-x)\\\\\n&f_{W, X}(w, x) = f_X(x)f_Y(w-x)\\\\\n&f_W(w) = \\int_{-\\infty}^\\infty f_X(x)f_Y(w-x)\\mathrm dx\\\\\n\\end{align*}\n$$\n\n**Sum of 2 independent normal RVs**\n\n$$\n\\begin{align*}\n    & X\\sim N(\\mu_1, \\sigma_1^2), Y\\sim N(\\mu_2, \\sigma_2^2)\\\\\n    &f_{X,Y}(x, y) = \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{(x-\\mu_x)^2}{2\\sigma_x^2} - \\frac{(y-\\mu_y)^2}{2\\sigma_y^2}\\right\\rbrace\n\\end{align*}\n$$\n\nwhich is constant on the ellipse(circle if $\\sigma_x = \\sigma_y$).\n\n$$\n\\begin{align*}\n    X\\sim N(0, \\sigma_x), &Y\\sim N(0, \\sigma_y)\\\\\n    W &= X+Y\\\\\n    f_W(w) &= \\int_{-\\infty}^\\infty f_{X,Y}(x, w-x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{x^2}{2\\sigma_x^2} - \\frac{(w-x)^2}{2\\sigma_y^2}\\right\\rbrace\\mathrm dx\\\\\n    =ce^{-\\gamma \\omega^2}\n\\end{align*}\n$$\n\n$W$ is Normal.\n\nMean = 0, Variance = $\\sigma_x^2 + \\sigma_y^2$\n\nSame argument for nonzero mean case.\n\n**The difference of two independent RVs**\n\n$X$ and $Y$  are independent exponential RVs with parameter $\\lambda$.\n\nFix some $z\\ge 0$ and note that $f_Y(x-z)$ is non zero when $x\\ge z$.\n\n$$\n\\begin{align*}\n    Z &= X - Y\\\\\n    f_Z(z) &= \\int_{-\\infty}^\\infty f_X(x)f_{-Y}(z - x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty f_X(x)f_{Y}(x - z)\\mathrm dx\\\\\n    &= \\int_{z}^\\infty \\lambda e^{-\\lambda x}\\lambda e^{-\\lambda(x-z)}\\mathrm dx\\\\\n    &= \\frac{\\lambda}{2}e^{-\\lambda z}\n\\end{align*}\n$$\n\nThe answer for the case $z\\le 0$\n\n$$\nf_{X-Y}(z) = f_{Y-X}(z) = f_Z(-z)\n$$\n\nThe first quality holds by symmetry.\n\n### Covariance and Correlation\n\n**Definition**\n\nThe covariance of two RVs $X$ and $Y$, denoted by $\\text{cov}(X, Y)$, is defined by\n\n$$\n\\text{cov}(X, Y) = E\\left[(X - E[X])(Y - E[Y])\\right]\n$$\n\nor, \n\n$$\n\\text{cov}(X, Y) = E[XY] - E[X]E[Y]\n$$\n\n$X$ and $Y$ are **uncorrelated** if $\\text{cov}(X, Y) = 0$.\n\n**Zero mean case** $\\text{cov}(X, Y) = E[XY]$\n\n**Properties**\n\n$$\n\\text{cov}(X, Y) = \\text{var}(X, Y)\\\\\n\\text{cov}(X, aY+b) = a\\cdot\\text{cov}(X, Y)\\\\\n\\text{cov}(X, Y+Z) = \\text{cov}(X, Y) + \\text{cov}(X, Z)\\\\\n\\text{independent} \\Rightarrow \\text{cov}(X, Y) = 0(\\text{converse is not true})\n$$\n\n**Variance of the sum of RVs**\n\n$$\n\\text{var}\\left(\\sum_{i = 1}^nX_i\\right) = \\sum_{i = 1}^n\\text{var}(X_i) + \\sum_{\\lbrace(i, j)|i\\ne j\\rbrace}\\text{cov}(X_i, X_j)\n$$\n\nIn particular, \n\n$$\n\\text{var}(X_1 + X_2) = \\text{var}(X_1) + \\text{var}(X_2) + 2\\text{cov}(X_1, X_2)\n$$\n\n**Correlation coefficient**\n\nThe correlation coefficient $\\rho(X, Y)$ of two RVs $X$ and $Y$ that have nonzero variance is defined as\n\n$$\n\\begin{align*}\n\\rho &= E\\left[\\frac{(X - E[X])}{\\sigma_X} \\cdot \\frac{(Y - E[Y])}{\\sigma_Y}\\right]\\\\\n&= \\frac{\\text{cov}(X, Y)}{\\sigma_X\\sigma_Y}\n\\end{align*}\n$$\n\n* $-1 \\le \\rho \\le 1$\n* $|\\rho| = 1 \\Leftrightarrow (X-E[X]) = c(Y-E[Y])$\n* Independent $\\Rightarrow \\rho = 0(\\text{converse is not true})$\n\n**Conditional expected value**\n\n$$\nE[X|Y = y] = \\sum_x xp_{X|Y}(x|y)\n$$\n\n### Conditional expectation\n\n**Definition**\n\n$$\nE[X|Y = y] = \\begin{cases}\n    \\sum_x xp_{X|Y}(x|y), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$\n\n$E[X|Y=y]$ is a function of $y$.\n\n$$\nE[X|Y = y] = \\frac{y}{2}(\\text{number})\\\\\nE[X|Y] = \\frac{Y}{2}(\\text{RV})\n$$\n\n**Law of iterated expectations**\n\n$$\nE[X] = E[E[X|Y]] = \\begin{cases}\n    \\sum_y E[X | Y = y]p_Y(y), & Y \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy, & Y \\text{continuous}.\n\\end{cases}\n$$\n\n### Conditional expectation as an estimator\n\nDenote the conditional expectation\n\n$$\n\\hat{X} = E[X|Y]\n$$\n\nas an estimator of $X$ given $Y$, and the estimation error\n\n$$\n\\tilde{X} = X - \\hat{X}\n$$\n\nis a RV.\n\n**Properties of the estimator**: \n\n**Unbiased**\n\nFor **any** possible $Y=y$:\n\n$$\nE[\\tilde{X}|Y] = E[X - \\hat{X} | Y] = E[X | Y] - E[\\hat{X}|Y] = \\hat{X} - \\hat{X} = 0\n$$\n\nBy the law of iterated expectations\n\n$$\nE[\\tilde{X}] = E[E[\\tilde{X}|Y]] = 0\n$$\n\n**Uncorrelated**\n\n$$\nE[\\hat{X}\\tilde{X}] = E[E[\\hat{X}\\tilde{X}|Y]] = E[\\hat{X}E[\\tilde{X}|Y]] = 0\n$$\n\n$$\n\\text{cov}(\\hat{X}, \\tilde{X}) = E[\\hat{X}\\tilde{X}] - E[\\hat{X}]E[\\tilde{X}] = 0\n$$\n\nSince $X = \\hat{X} + \\tilde{X}$, the variance of X can be decomposed as\n\n$$\n\\text{var}(X) = \\text{var}(\\hat{X}) + \\text{var}(\\tilde{X})\n$$\n\n$$\n\\text{var}(\\tilde{X}) = \\text{var}(E[X|Y])\n$$\n\nConditional variance\n\n$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$\n\nhere comes the law of total variance:\n\n$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$\n\nThe total variability is avarage variability within sections + variability between sections.\n\n**Law of iterated expectations**\n\n$$\nE[X] = E[E[X|Y]] = \\sum_y E[X|Y = y]p_Y(y)\n$$\n\n\n**Conditional variance**\n\n$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$\n\n**Law of total variance**\n\n$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$\n\n\n## Transforms and sum of a random number of random variables\n\nThe transform associated with a RV $X$ is a function $M_X(s)$ of a scalar parameter $s$, defined by\n\n$$\nM_X(s) = E[e^{sX}] = \\begin{cases}\n    \\sum_x e^{sx}p_X(x), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty e^{sx}f_X(x)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$\n\n**Remarks**\n- a function of $s$, rather than a number\n- not necessarily defined for all (complex) s\n- always well defined for $\\Re(s)=0$\n- compared with Laplace transform\n### Properties\n**Sanity Checks**\n\n$$\nM_X(0) = 1\\\\\n|M_X(s)| \\le 1 \\text{ for } \\Re(s) = 0\n$$\n\n**Linear operation**\n$$\nM_{aX + b}(s) = e^{bs}M_X(as)\\\\\nM_{X + Y}(s) = M_X(s)M_Y(s) (\\text{if X, Y independent})\n$$\n\n**Expected Values**\n\n$$\nE[X^n] = \\frac{\\partial^n M_X(s)}{\\partial s^n}\\bigg|_{s=0}\n$$\n\n$$\nP(X = c) = \\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc}\n$$\n\nsince\n\n$$\n\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N e^{-jc(k - x)} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac{1}{N} \\frac{e^{j(x-c)} - e^{Nj(x - c)}}{1-e^{j(x-c)}} = p_X(c)\n$$\n\n**Example**\n\n$X$ is a Poisson RV with parameter $\\lambda$\n\n$$\np_X(x) = \\frac{\\lambda^x}{x!}e^{-\\lambda}\n$$\n\n$$\nM(s) = \\sum_{x = 0}^\\infty e^{sx}\\frac{\\lambda^x}{x!}e^{-\\lambda} = e^{-\\lambda}\\sum_{x = 0}^\\infty \\frac{(e^s\\lambda)^x}{x!} = e^{-\\lambda}e^{e^s\\lambda} = e^{\\lambda(e^s - 1)}\n$$\n\n$X$ is an exponential RV with parameter $\\lambda$\n\n$$\nf_X(x) = \\lambda e^{-\\lambda x}\n$$\n\n$$\nM(s) = \\int_0^\\infty e^{sx}\\lambda e^{-\\lambda x}\\mathrm dx = \\frac{\\lambda}{\\lambda - s}\n$$\n\n$Y$ is a standard normal RV, \n\n$$\nM_Y(s) = \\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi}}e^{-(y^2/2)}e^{sy}\\mathrm dy = e^{s^2/2}\n$$\n\nConsider $X = \\sigma Y + \\mu$\n\n$$\nM_X(s) = e^{s^2\\sigma^2/2 + \\mu s}\n$$\n\n### Inversion of transforms\n\n**Inversion Property**\n\nThe transform $M_X(s)$ associated with a RV $X$ uniquely determines the CDF of $X$, assuming that $M_X(s)$ is finite for all $s$ in some interval $[-a, a]$, where $a$ is a positive number.\n\nExample:\n\n$$\n\\begin{align*}\nM(s) &= \\frac{pe^s}{1 - (1 - p)e^s}\\\\\n&= pe^s(1 + (1-p)e^s + (1-p)^2e^{2s} + \\dotsb)\\\\\n&= \\sum_{k = 1}^\\infty p(1-p)^{k - 1}e^{ks}\n\\end{align*}\n$$\n\nThe probability $P(X = k)$ is found by reading the coefficient of the term $e^{ks}$:\n\n$$\nP(X = k) = p(1-p)^{k-1}\n$$\n\n### Transform of Mixture of Distributions\n\nLet $X_1,\\dotsb, X_n$ be continuous RVs with PDFs $f_{X_1}, \\dotsb, f_{X_n}$.\n\nThe value $y$ of RV $Y$ is generated as follows: an index $i$ is chosen with a corresponding probability $p_i$, and $y$ is taken to be equal to the value $X_i$. Then, \n\n$$\nf_Y(y) = p_1f_{X_1}(y) + \\dotsb + p_nf_{X_n}(y)\\\\\nM_Y(s) = p_1M_{X_1}(s) + \\dotsb + p_nM_{X_n}(s)\n$$\n\n### Sum of independend RVs\n\nLet $X$ and $Y$ be independent RVs, and let $Z = X + Y$. The transform associated with $Z$ is \n\n$$\nM_Z(s) = M_X(s)M_Y(s)\n$$\n\nSince\n\n$$\nM_Z(s) = E[e^{sZ}] = E[e^{s(X + Y)}] = E[e^{sX}e^{sY}] = E[e^{sX}]E[e^{sY}] = M_X(s)M_Y(s)\n$$\n\nGeneralization:\n\nA collection of independent RVs: $X_1, \\dotsb, X_n$, $Z = X_1 + \\dotsb + X_n$ ,\n\n$$\nM_Z(s) = M_{X_1}(s)\\dotsb M_{X_n}(s)\n$$\n\n**Example**\n\nLet $X_1, \\dotsb, X_n$ be independent Bernoulli RVs with a common parameter $p$:\n\n$$\nM_{X_i}(s) = 1 - p + pe^s\n$$\n\n$Z = X_1 + \\dotsb + X_n$ is binomial with parameters n and p:\n\n$$\nM_z(s) = (1 - p + pe^s)^n\n$$\n\nLet $X$ and $Y$ be independent Poisson RVs with means $\\lambda$ and $\\mu$, and let $Z = X + Y$. Then $Z$ is still Poisson with mean $\\lambda + \\mu$.\n\n$$\nM_Z(s) = M_X(s)M_Y(s) = e^{(\\lambda +\\mu)(e^s - 1)}\n$$\n\nLet $X$ and $Y$ be independent Gaussian RVs with means $\\mu_x$ and $\\mu_y$, and variances $\\sigma_x^2, \\sigma_y^2$. And let $Z = X + Y$. Then $Z$ is still Gaussian with mean $\\mu_x + \\mu_y$ and variance $\\sigma_x^2 + \\sigma_y^2$\n\n$$\nM_X(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_x^2s^2}{2} + \\mu_x s\\bigg\\rbrace\\\\\nM_Y(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_y^2s^2}{2} + \\mu_y s\\bigg\\rbrace\\\\\nM_Z(s) = M_X(s)M_Y(s) = \\exp\\bigg\\lbrace\\frac{(\\sigma_x^2 + \\sigma_y^2)s^2}{2} + (\\mu_x + \\mu_y)s\\bigg\\rbrace\n$$\n\nConsider\n\n$$\nY = X_1 + \\dotsb + X_N\n$$\n\nwhere $N$ is a RV that takes integer values, and $X_1, \\dotsb, X_N$ are identically distributed RVs.\n\nAssume that $N, X_1, \\dotsb$ are independent.\n\n$$\nE[Y|N = n] = E[X_1 + X_2 + \\dotsb + X_n|N = n] = nE[X]\\\\\nE[Y|N] = NE[X]\\\\\nE[Y] = E[E[Y|N]] = E[NE[X]] = E[N]E[X]\n$$\n\nFor the variance, \n\n$$\nE[Y|N] = NE[X]\\\\\n\\text{var}(E[Y|N]) = (E[X])^2\\text{var}(N)\\\\\n\\text{var}(Y|N=n) = n\\text{var}(X)\\\\\n\\text{var}(Y|N) = N \\text{var}(X)\\\\\nE[\\text{var}(Y|N)] = E[N]\\text{var}(X)\\\\\n$$\n\nSo, \n\n$$\n\\text{var}(Y) = E[\\text{var}(Y|N)] + \\text{var}(E[Y|N]) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\n$$\n\nFor transform,\n\n$$\nE[e^{sY}|N = n] = E[e^{sX_1}\\dotsb e^{sX_n}|N = n] = E[e^{sX}]^n = (M_X(s))^n\\\\\nM_Y(s) = E[e^{sY}] = E[E[e^{sY}|N]] = E[(M_X(s))^N] = \\sum_{n = 0}^\\infty (M_X(s))^n p_N(n) = \\sum_{n = 0}^\\infty e^{n\\log M_X(s)}p_N(n) = M_N(\\log M_X(s))\n$$\n\n**Summary on Properties**\n\nConsider the sum\n\n$$\nY = X_1 + \\dotsb + X_N\n$$\n\nwhere $N$ is a RV that takes integer values, and $X_1, X_2, \\dotsb$ are identically distributed RVs. Assume that $N$, $X_1, X_2, \\dotsb$ are independent.\n\n$$\nE[Y] = E[N]E[X]\\\\\n\\text{var}(Y) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\\\\\nM_Y(s) = M_N(\\log M_X(s))\n$$\n\n**Example**\n\nAssume that $N$ and $X_i$ are both geometrically distributed with parameters $p$ and $q$ respectively. All of these RVs are independent. $Y = X_1 + \\dotsb + X_N$\n\n$$\nM_N(s) = \\frac{pe^s}{1 - (1-p)e^s}\\\\\nM_X(s) = \\frac{qe^s}{1 - (1-q)e^s}\\\\\nM_Y(s) = M_N(\\log M_X(s)) = \\frac{pqe^s}{1 - (1-pq)e^s}\n$$\n\n$Y$ is also geometrically distributed, with parameter $pq$.\n\n## Weak law of large numbers\n\n### Markov inequality\n\nIf a RV $X$ can only take nonnegative values, then\n\n$$\nP(X \\ge a) \\le \\frac{E[X]}{a}, \\text{ for all } a \\gt 0.\n$$\n\nIntuition: If a nonnegative RV has a small mean, then the probability that it takes a large value must be small。\n\nFix a positive number $a$, \n\n$$\nE[X] = \\int_0^\\infty xf_X(x)dx = \\int_0^a xf_X(x)dx + \\int_a^\\infty xf_X(x)dx \\ge 0 + \\int_a^\\infty xf(x)dx \\ge \\int_a^\\infty af_X(x)dx = aP(X \\ge a)\n$$\n\n### Chebyshev's Inequality\n\nIf $X$ is a RV with mean $\\mu$ and variance $\\sigma^2$, then\n\n$$\nP(|X - \\mu| \\ge c) \\le \\frac{\\sigma^2}{c^2}\n$$\n\nIntuition: If a RV has small variance, then the probability that it takes a value far from its mean is also small.\n\n$$\n\\begin{align*}\n\\sigma^2 &= \\int (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} (x - \\mu)^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} c^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty c^2f_X(x)\\mathrm dx\\\\\n&= \\int_{|x - \\mu| \\ge c} c^2f_X(x)\\mathrm dx\\\\\n&=c^2P(|X - \\mu| \\ge c)\n\\end{align*}\n$$\n\nThe upperbounds of $\\sigma^2$:\n\n$$\nX \\in [a, b]\\\\\n\\sigma^2 \\le (b - a)^2/4\n$$\n\n**Chernoff inequality**\n\nIf a RV $X$ has MGF $M_X(s)$, then\n\n$$\nP(X \\ge a) \\le e^{-\\max_{s\\ge 0}\\left(sa - \\ln M_X(s)\\right)}\n$$\n\nor, for $s \\ge 0$\n\n$$\nP(X\\ge a) \\le e^{-sa}M_X(s)\n$$\n\nfor $s \\lt 0$\n\n$$\nP(X \\le a) \\le e^{-sa}M_X(s)\n$$\n\nproof: for $s \\ge 0$\n\n$$\nM_X(s) = \\int_{-\\infty}^a e^{sx}f_X(x)\\mathrm dx + \\int_a^{\\infty} e^{sx}f_X(x)\\mathrm dx\\\\\n\\ge 0 + e^{sa}\\int_a^{\\infty} f_X(x)\\mathrm dx = e^{sa}P(X \\ge a)\n$$\n\n### Weak law of large numbers\n\nLet $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$\n\n$$\nM_n = \\frac{X_1 + X_2 + \\dotsb + X_n}{n}\\\\\nE[M_n] = \\mu\\\\\n\\text{var}(M_n) = \\frac{\\sigma^2}{n}\n$$\n\nApplying the Chebyshev inequality and we get:\n\n$$\nP(|M_n - \\mu| \\ge \\epsilon) \\le \\frac{\\text{var}(M_n)}{\\epsilon^2} = \\frac{\\sigma^2}{n\\epsilon^2}\n$$\n\nFor large $n$, the bulk of the distribution of $M_n$ is concentrated near $\\mu$\n\n**Theorem**\n\nLet $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$. For every $\\epsilon \\gt 0$, we have\n\n$$\nP(|M_n - \\mu| \\ge \\epsilon) = P\\left(\\left|\\frac{X_1 + \\dotsb + X_n}{n} - \\mu\\right|\\ge \\epsilon\\right) \\rightarrow 0, \\text{ as } n \\rightarrow \\infty\n$$\n\n$M_n$ converges **in probability** to $\\mu$.\n\n### Convergence \"in Probability\"\n\nTheorem: Convergence in Probability\n\nLet $\\lbrace Y_n\\rbrace$(or $Y_1, Y_2, \\dots$) be a sequence of RVs(not necessarily independent), and let $a$ be a real number. We say that the sequence $Y_n$ **converges to** $a$ in probability, if for every $\\epsilon \\gt 0$, we have \n\n$$\n\\lim_{n \\rightarrow \\infty} P(|Y_n - a| \\ge \\epsilon) = 0\n$$\n\n(almost all) of the PMF/PDF of $Y_n$, eventually gets concentrated (arbitrarily) close to $a$.\n\n### Many types of convergence\n\nDeterministic limits: $\\lim_{n\\rightarrow \\infty} a_n = a$\n\n$$\n|a_n - a|\\le \\epsilon, \\forall n \\ge N, \\epsilon \\gt 0\n$$\n\nConvergence in probability: $X_n\\stackrel P{\\rightarrow} X$\n\n$$\n\\lim_{n \\rightarrow \\infty}P(|X_n - X|\\ge \\epsilon) = 0, \\forall \\epsilon \\gt 0\n$$\n\n(WLLN)\n\nConvergence in Distribution: $X_n \\stackrel{D}{\\rightarrow} X$\n\n$$\n\\lim_{n \\rightarrow \\infty} P(X_n \\le x) = P(X \\le x), \\forall x\n$$\n\nFor all points of $x$ at which the function $F_X(x) = P(X\\le x)$is continuous.\n\n(CLT)\n\nConvergence with probability $1$(almost surely): $X_n \\stackrel{\\text{a.s.}}{\\rightarrow} X$\n\n$$\nP\\left(\\lbrace\\omega\\in \\Omega: \\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\rbrace\\right) = 1\n$$\n\nor \n\n$$\nP\\left(\\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\right) = 1\n$$\n\nLemma:\n\n$$\nX_n \\stackrel{\\text{a.s.}}{\\rightarrow} X \\Leftrightarrow \\lim_{m \\rightarrow\\infty}P(|X_n - X|\\le \\epsilon, \\forall n \\gt m) = 1, \\forall \\epsilon \\gt 0\\\\\n\\Leftrightarrow P(|X_n - X|\\gt \\epsilon, \\text{i.o.}) = 0, \\forall \\epsilon \\gt 0\n$$\n\ni.o. stand for infinitely often\n\n(SLLN)\n\nConvergence in Mean/in Norm: $X_n \\stackrel{r}{\\rightarrow}X$\n\nif $E[X_n^r] \\lt \\infty$ for all $n$ and \n\n$$\n\\lim_{n \\rightarrow \\infty}E[|X_n - X|^r] = 0\n$$\n\nRelations:\n\n$$\n\\left(X_n\\stackrel {\\text{a.s.}}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\forall r\\ge s\\ge 1, \\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel s{\\rightarrow} X\\right)\n$$\n\nThe converse assertions fail in general!\n\nThe relation between “almost surely” and “in r-th mean” is complicated. There exist sequences which converge almost surely but\nnot in mean, and which converge in mean but not almost surely!\n\n## Central Limit Theorem\n\n### Theorem\n\nLet $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$ and variance $\\sigma^2$. Let \n\n$$\nZ_n = \\frac{X_1 + X_2 + \\dotsb + X_n - n\\mu}{\\sigma\\sqrt{n}}\n$$\n\nThen\n\n$$\n\\lim_{n\\rightarrow \\infty}P(Z_n\\le z) = \\Phi (z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^z e^{-\\frac{x^2}{2}}\\mathrm dx\n$$\n\nCDF of $Z_n$ converges to normal CDF(converge in distribution)\n\n### Normal Approximation Based on the Central Limit Theorem\n\nLet $S_n = X_1 + \\dotsb + X_n$, where $X_i$ are $\\text{i.i.d.}$ RVs with mean $\\mu$ and variance $\\sigma^2$. If $n$ is large, the probability $P(S_n ≤ c)$ can be approximated by\ntreating $S_n$ as if it were normal, according to the following procedure.\n\n1. Calculate the mean $n\\mu$ and the variance $n\\sigma^2$ of $S_n$\n2. Calculate the normalinzd value $z = (c - n\\mu)/(\\sigma\\sqrt{n})$\n3. Use the approxmation\n\n$$\n    P(S_n \\le c)  \\approx \\Phi(z)\n$$\n\nwhere $\\Phi(z)$ is available from the standard normal CDF.\n\n### Proof\n\nSuppose that $X_1, X_2, \\dots$ has mean zero.\n\n$$\n\\begin{align*}\nM_{Z_n}(s) &= E[e^{sZ_n}]\\\\\n&=E\\left[\\exp\\left(\\frac{s}{\\sigma\\sqrt{n}}\\sum_{i = 1}^n X_i\\right)\\right]\\\\\n&=\\prod_{i = 1}^n E[e^{\\frac{s}{\\sigma\\sqrt{n}}X_i}]\\\\\n&=\\prod_{i = 1}^n M_{X_i}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\\\\n&=\\left(M_{X}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\right)^n\\\\\n\\end{align*}\n$$\n\nSuppose that the transform $M_X(s)$ has a second order Taylor series expansion around $s=0$,\n\n$$\nM_X(s) = a + bs + cs^2 + o(s^2)\n$$\n\nwhere $a = M_X(0) = 1, b = M_X'(0) = E[X] = 0, c = \\frac{1}{2}M_X''(0) = \\frac{\\sigma^2}{2}$\n\nThen\n\n$$\nM_{Z_n}(s) = \\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n\n$$\n\nAs $n\\rightarrow \\infty$, \n\n$$\n\\lim_{n\\rightarrow \\infty}M_{Z_n}(s) = \\lim_{n\\rightarrow \\infty}\\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n = e^{\\frac{s^2}{2}}\n$$\n\nApproxmation on binomial:\n\n(De Moivre-Laplace Approxmation to the Binomial)\n\n$$\nP(k \\le S_n \\le l) = P\\left(\\frac{k - np}{\\sqrt{np(1-p)}} \\le \\frac{S_n - np}{\\sqrt{np(1 - p)}} \\le \\frac{l - np}{\\sqrt{np(1 - p)}}\\right)\\\\\n\\approx \\Phi\\left(\\frac{l - np}{\\sqrt{np(1 - p)}}\\right) - \\Phi\\left(\\frac{k - np}{\\sqrt{np(1 - p)}}\\right)\n$$\n\n## The Strong Law of Large Numbers\n\n### Theorem\n\nLet $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$.\n\n$$\nP(\\lim_{n \\rightarrow\\infty}\\frac{X_1 + \\dots + X_n}{n} = \\mu) = 1.\n$$\n\n## Borel-Cantelli lemma & Bernoulli Process\n\n### Limit of set sequence\n\n$$\n\\limsup_n A_n = \\bigcap_{n = 1}^\\infty \\bigcup_{k = n}^\\infty A_k\\\\\n\\liminf_n A_n = \\bigcup_{n = 1}^\\infty \\bigcap_{k = n}^\\infty A_k\n$$\n\nIf upper limit equals to lower limit, the limit of set sequence exists.\n\n$$\n\\limsup_n A_n \\supseteq \\liminf_n A_n\\\\\n\\limsup_n A_n = \\liminf_n A_n = \\lim_n A_n\n$$\n\nUpper limit can also be denoted as\n\n$$\n\\limsup_n A_n = \\{\\omega: \\omega \\in A_n, \\text{i.o.}\\} = \\lbrace A_n, \\text{i.o.}\\rbrace\n$$\n\n### Borel-Cantelli Lemma\n\nLet $\\lbrace A_n, n = 1, 2, \\dotsb\\rbrace$ be a sequence of events, then\n\n$$\n\\sum_{n = 1}^\\infty P(A_n)\\lt \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 0\n$$\n\nLet $\\lbrace A_n, n = 1, 2, \\dotsb\\rbrace$ be a sequence of **independent** events, then\n\n$$\n\\sum_{n = 1}^\\infty P(A_n) = \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 1\n$$\n\n### Stochastic process\n\nA stochastic process is a mathematical model of a probabilistic experiment that evolves in time and generates a sequence of\nnumerical values.\n\n* Bernoulli process(memoryless, discrete time)\n* Poisson process(memoryless, continuous time)\n\n### **The Bernoulli Process** \n\nis a sequence of independent Bernoulli trials, each with probability of success $p$.\n\n$$\nP(\\text{success}) = P(X_i = 1) = p\\\\\nP(\\text{failure}) = P(X_i = 0) = 1 - p\n$$\n\n**Independence property**: For any given time $n$, the sequence of $X_{n + 1}, X_{n + 2}, \\dots$ is also a Bernoulli process, and is independent from $X_1, \\dots, X_n$\n\n**Memoryless property**: Let $n$ be a given time and let $\\overline T$ be the time of the first success after\ntime $n$. Then $\\overline T − n$ has a geometric distribution with parameter $p$,\nand is independent of the RVs $X_1, \\dots , X_n$.\n\n$$\nP(\\overline T - n = t | \\overline T \\gt n) = (1 - p)^{t - 1}p = P(T = t)\n$$\n\n**Interarrival times**\n\nDenote the $k$th success as $Y_k$, the $k$th interarrival time as $T_k$.\n\n$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$\n\nrepresents the number of trials following the $(k - 1)$th success until the next success.\n\nNote that\n\n$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$\n\nAlternative description of the Bernoulli process: \n* Start with a sequence of independent geometric RVs $T_1, T_2, \\dots$ with common parameter p, and let these stand for the interarrival times.\n* Record a success at times $T_1$, $T_1 + T_2$, etc.\n\n$$\nE[Y_k] = \\frac{k}{p}\\\\\n\\text{var}(Y_k) = \\frac{k(1 - p)}{p^2}\n$$\n\n$$\np_{Y_k}(t) = \\binom{t - 1}{k - 1}p^k(1 - p)^{t - k}\n$$\n\n**Splitting of a Bernoulli process**\n\nWhenever there is an arrival, we choose to either keep it (with probability $q$), or to discard it (with probability $1 − q$).\n\nBoth the process of arrivals that are kept and the process of discarded arrivals are Bernoulli processes, with success probability $pq$ and $p(1 − q)$, respectively, at each time.\n\n**Merging of a Bernoulli process**\n\nIn a reverse situation, we start with two independent Bernoulli processes (with parameters $p$ and $q$ respectively). An arrival is\nrecorded in the merged process if and only if there is an arrival in at least one of the two original processes.\n\nThe merged process is Bernoulli, with success probability $p+q−pq$ at each time step.\n\n## The Poisson Process\n\n### Definition\nAn arrival process is called a Poisson process with rate $λ$ if it has the following properties:\n\n**Time homogenity**\n\n$$\nP(k, \\tau) = P(k \\text{ arrivals in interval of duration }\\tau)\n$$\n\n**Independence**\n\nNumbers of arrivals in disjoint time intervals are independent.\n\n**Small interval probabilities**\n\n$$\n\\begin{cases}\n    1 - \\lambda\\tau + o(\\tau), & \\text{if } k = 0,\\\\\n    \\lambda\\tau + o_1(\\tau), & \\text{if } k = 1,\\\\\n    o_k(\\tau), & \\text{if } k > 1.\n\\end{cases}\n$$\n\n### Bernoulli/Poisson Relation\n\nIn a short time interval $\\delta$\n\n$$\nn = t / \\delta\\\\\np = \\lambda\\delta\\\\\nnp = \\lambda t\n$$\n\nFor binomial PMF $p_S(k;n,p)$,\n\n$$\n\\lim_{n\\rightarrow \\infty}p_S(k;n, p) = \\lim_{n\\rightarrow\\infty}\\frac{n!}{(n - k)!k!}p^k(1 - p)^{n - k} = \\frac{(\\lambda t)^k}{k!}e^{-\\lambda t} = P(k, t)\n$$\n\n### PMF of Number of Arrivals $N$\n\n$$\nP(k, \\tau) = \\frac{(\\lambda\\tau)^ke^{-\\lambda\\tau}}{k!}\n$$\n\n$$\nE[N_t] = \\lambda t\\\\\n\\text{var}(N_t) = \\lambda t\n$$\n\n### Time $T$ of the first arrival\n\n$$\nF_T(t) = P(T \\le t) = 1 - P(T \\gt t) = 1 - e^{-\\lambda t}, t\\ge 0\\\\\nf_T(t) = \\lambda e^{-\\lambda t}, t\\ge 0\n$$\n\n**Memoryless property** The  time to next arrival is independent of the past.\n\n### Interarrival times\n\nWe also denote the time of the kth success as $Y_k$, and denote the\nkth interarrival time as $T_k$. That is,\n\n$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$\n\nNote that\n\n$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$\n\n$$\nf_{Y_k}(y) = \\frac{\\lambda^ky^{k-1}e^{-\\lambda y}}{(k - 1)!}, y\\ge 0\n$$\n\n### Merging Poisson Processes\n\n![](../images/prob/L14_1.jpg)\n\n$$\nP(\\text{Arrival is red} | \\text{1 arrival})\\approx \\frac{\\lambda_1\\delta}{(\\lambda_1 + \\lambda_2) \\delta}\n$$\n\n![](../images/prob/L15_1.jpg)","slug":"Introduction-to-Probability","published":1,"updated":"2024-03-19T06:01:16.158Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfht0007rsug1d0g4rt1","content":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h2 id=\"Probability-Space\"><a href=\"#Probability-Space\" class=\"headerlink\" title=\"Probability Space\"></a>Probability Space</h2><p>Probability space is a triple $(\\Omega, \\mathcal{F}, \\mathbf{P})$, comprised of the following three<br>elements:</p>\n<p>1 Sample space $\\Omega$: the set of all possible outcomes of an experiment</p>\n<p>2 $\\sigma$-algebra (or $\\sigma$-field) $\\mathcal F$: a collection of subsets of $\\Omega$</p>\n<p>3 Probability measure $\\mathbf P$: a function that assigns a nonnegative<br>probability to every set in the $\\sigma$-algebra $\\mathcal F$</p>\n<h3 id=\"Sample-space\"><a href=\"#Sample-space\" class=\"headerlink\" title=\"Sample space\"></a>Sample space</h3><p>Mutually exclusive: no identical element.</p>\n<p>Collectively exhaustive: all results should be included.</p>\n<h3 id=\"sigma-algegra\"><a href=\"#sigma-algegra\" class=\"headerlink\" title=\"$\\sigma$-algegra\"></a>$\\sigma$-algegra</h3><p>not unique</p>\n<p>3 requirements:</p>\n<div>$$\n\\varnothing \\in \\mathcal F\\\\\n\\forall A \\in \\mathcal F, A^c \\in \\mathcal F\\\\\n\\forall A_k \\in \\mathcal F, k=1, 2, ..., \n\\cup_{k=1}^{\\infty}A_k\\in \\mathcal F\n$$</div>\n\n<h3 id=\"Borel-field\"><a href=\"#Borel-field\" class=\"headerlink\" title=\"Borel field\"></a>Borel field</h3><p>used to measure intervals</p>\n<p>when $\\Omega$ is continuous($\\R$ for example), Borel field is useful.</p>\n<p>“minimum” $\\sigma$-algebra means deleting any element in the $\\mathcal B (\\mathbf R)$ will miss the requirements.</p>\n<p><img src=\"/../images/prob/L2_1.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Uncountable\"><a href=\"#Uncountable\" class=\"headerlink\" title=\"Uncountable\"></a>Uncountable</h3><p>decimal numbers between 0 and 1 are uncountable.</p>\n<h3 id=\"Probability-measures\"><a href=\"#Probability-measures\" class=\"headerlink\" title=\"Probability measures\"></a>Probability measures</h3><div>$$\nP:\\mathcal F \\rightarrow [0, 1]\n$$</div>\n\n<p><strong>Nonnegativity</strong> $P(A)\\ge0, \\forall A \\in \\mathcal{  F}$</p>\n<p><strong>Normalization</strong>  $P(\\empty)&#x3D;0, P(\\Omega)&#x3D;1$</p>\n<p><strong>Countable additivity</strong> $A_1, A_2, … \\text { is disjoint in }\\mathcal F, P(A_1\\cup A_2\\cup …)&#x3D;P(A_1)+P(A_2)+…$</p>\n<ul>\n<li>They are the axioms of probability. </li>\n<li>Probability is a mapping from $\\sigma$-algebra to a real number betwenn 0 and 1, which intuitively specifies the “likelihood” of any event. </li>\n<li>There exist non-measurable sets, on which we cannot define a probability measure.</li>\n</ul>\n<h3 id=\"Discrete-models\"><a href=\"#Discrete-models\" class=\"headerlink\" title=\"Discrete models\"></a>Discrete models</h3><div>$$\nP(\\{s_1, ..., s_n\\})=P(s_1)+...+P(s_n)\\\\\nP(A) = \\frac{\\text{\\# of elements of }A}{\\text{total \\# of elements of sample points}}\n$$</div>\n\n\n<h3 id=\"Continuous-Models\"><a href=\"#Continuous-Models\" class=\"headerlink\" title=\"Continuous Models\"></a>Continuous Models</h3><p>Probability &#x3D; Area</p>\n<h3 id=\"Some-properties-of-Probability-measure\"><a href=\"#Some-properties-of-Probability-measure\" class=\"headerlink\" title=\"Some properties of Probability measure\"></a>Some properties of Probability measure</h3><div>$$\nA\\sub B\\Rightarrow P(A)\\le P(B)\\\\\nP(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\\\\nP(A\\cup B) \\le P(A) + P(B)\\\\\nP(A\\cup B \\cup C)=P(A) + P(A^C\\cap B) + P(A^C\\cap B^C\\cap C)\n$$</div>\n\n<h3 id=\"Conditional-Probability\"><a href=\"#Conditional-Probability\" class=\"headerlink\" title=\"Conditional Probability\"></a>Conditional Probability</h3><div>$$\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}\n$$</div>\n\n<ul>\n<li>If $P(B)&#x3D;0$, $P(A|B)$ is undefined.</li>\n<li>For a fixed event $B$, $P(A|B)$ can be verified as a legitimate probability measure on the new universe. $P(A, B)\\ge 0$, $P(\\Omega|B)&#x3D;1$, $P(A_1\\cup A_2\\cup…|B)&#x3D;P(A_1|B)+P(A_2|B)+…$</li>\n<li><div>$P(A|B)=\\frac{\\text{ \\# of elements of }A\\cap B}{\\text{total \\# of elements of }B}$</div></li>\n</ul>\n<h3 id=\"Total-probability-theorem\"><a href=\"#Total-probability-theorem\" class=\"headerlink\" title=\"Total probability theorem\"></a>Total probability theorem</h3><p>Let $A_1, …, A_n$ be disjoint events that form a partition of the sample space and assume that $P(A_i)&gt;0$ for all $i$. Then for any event B, we have</p>\n<div>$$\nP(B) = \\sum_{i=1}^n P(A_i\\cap B) = \\sum_{i=1}^nP(A_i)P(B|A_i)\n$$</div>\n\n<p><strong>Remark</strong> </p>\n<ul>\n<li>The definition of partition is that $\\cup_{i&#x3D;1}^n A_i &#x3D; \\Omega, A_i\\cap A_j &#x3D; \\emptyset, \\forall i\\ne j$</li>\n<li>The probability of B is a weighted average of its conditional probability under each scenario</li>\n<li>Each scenario is weighted according to its prior probability</li>\n<li>Useful when $P(B|A_i)$ is known or easy to derive</li>\n</ul>\n<h3 id=\"Inference-and-Bayes’-rule\"><a href=\"#Inference-and-Bayes’-rule\" class=\"headerlink\" title=\"Inference and Bayes’ rule\"></a>Inference and Bayes’ rule</h3><p>Let $A_1, …, A_2$ be disjoint events that from a partition of the sample space and assume that $P(A_i) \\gt 0$  for all $i$. Then for any event $B$ such that $P(B)\\gt 0$, we have </p>\n<div>$$\nP(A_i|B) = \\frac{P(A_i)P(B|A_i)}{P(B)} = \\frac{P(A_i)P(B|A_i)}{\\sum_{j=1}^nP(A_j)P(B|A_j)}\n$$</div>\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>Relates conditional probabilities of the form $P(A_i|B)$ with conditional probabilities of the form $P(B|A_i)$</li>\n<li>often used in inference: effect $B$ $\\lrarr$ cause $A_i$</li>\n</ul>\n<p>The meaning of $P(A_i|B)$ in the view of Bayes: the belief of $A_i$ is revised if we observed effect $B$. If the cause and the effect are closely binded($P(B|A_i) &gt; P(B|A_i^c)$), then the belief $A_i$ is enhanced by the observation of effect $B$($P(A_i|B) &gt; P(A)$). This can be derived from the Bayes’ rule through simple calculation. If $P(A_i|B)&#x3D;P(A_i)$, then $B$ provides no information on $A_i$.</p>\n<h3 id=\"Independence\"><a href=\"#Independence\" class=\"headerlink\" title=\"Independence\"></a>Independence</h3><h4 id=\"Independence-of-two-disjoint-events\"><a href=\"#Independence-of-two-disjoint-events\" class=\"headerlink\" title=\"Independence of two disjoint events\"></a>Independence of two disjoint events</h4><p>Events A and B are called <strong>independent</strong> if </p>\n<div>$$\nP(A\\cap B) = P(A)\\cdot P(B)\n$$</div>\nor equivalently, when $P(B) > 0$, \n\n<div>$$\nP(A|B) = P(A)\n$$</div>\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>Occurrence of B provides no information about A’s occurrence</li>\n<li>Equivalence due to $P(A\\cap B) &#x3D; P(B)\\cdot P(A|B)$</li>\n<li>Symmetric with respect to $A$ and $B$.</li>\n<li><ul>\n<li>applies even if $P(B) &#x3D; 0$</li>\n</ul>\n</li>\n<li><ul>\n<li>implies $P(B|A) &#x3D; P(B)$ and $P(A|B^c) &#x3D; P(A)$</li>\n</ul>\n</li>\n<li>Does not imply that A and B are disjoint, indeed opposite!</li>\n<li><ul>\n<li>Two disjoint events are never independent!($P(A\\cap B) &#x3D; 0$, but $P(A)\\cdot P(B)\\ne 0$)</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Conditional-independence\"><a href=\"#Conditional-independence\" class=\"headerlink\" title=\"Conditional independence\"></a>Conditional independence</h4><div>$$\nP(A\\cap B | C) = P(A| C) \\cdot P(B|C)\n$$</div>\n\n<p><strong>Definition</strong></p>\n<p>Event $A_1, A_2, …, A_n$ are called independent if: </p>\n<div>$$\nP(A_i\\cap A_j\\cap ...\\cap A_q) = P(A_1)P(A_j)...P(A_q)\n$$</div>\n\n<p>for any distinct indices $i, j, \\dots q$ chosen from ${1, \\dots n}$.</p>\n<p>Pairwise is independence does not imply independence.</p>\n<h2 id=\"Discrete-Random-Variables\"><a href=\"#Discrete-Random-Variables\" class=\"headerlink\" title=\"Discrete Random Variables\"></a>Discrete Random Variables</h2><p>Random Variable is neither random, nor variable.</p>\n<h3 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><p>We care about the probability that $X \\le x$ instead $X &#x3D; x$ in the consideration of generality. </p>\n<p><strong>Random variables</strong></p>\n<p>Given a probability space $(\\Omega, F, P)$, a random variable is a function $X: \\Omega \\rightarrow \\R$ with the probability that ${\\omega \\in \\Omega: X(\\omega) \\le x} \\in \\mathcal F$ for each $x\\in \\R$. Such a function $X$ is said to be $\\mathcal F$-measurable.</p>\n<p><strong>Probability Mass Function(PMF)</strong></p>\n<div>$$\np_X(x)=P(X=x)=P(\\{\\omega \\in \\Omega \\text{ s.t. } X(\\omega)=x\\})\n$$</div>\n\n<p>Bonulli PMF: </p>\n<div>$$ \np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\n$$</div>\n\n<p>Binomial PMF: $p_X(k)&#x3D;\\binom{n}{k}p^k(1-p)^{n-k}$</p>\n<p>Geometric PMF: $p_X(k)&#x3D;(1-p)^{k-1}p$</p>\n<p>Poisson PMF: $p_X(k)&#x3D;e^{-\\lambda}\\frac{\\lambda^k}{k!}$. Note: $\\sum_{k&#x3D;0}^\\infty e^{-\\lambda}\\frac{\\lambda^k}{k!}&#x3D;e^{-\\lambda}e^\\lambda&#x3D;1$</p>\n<p>If $y&#x3D;g(x)$, $p_Y(y)&#x3D;\\sum_{\\lbrace x|g(x)&#x3D;y \\rbrace} p(x)$.</p>\n<h3 id=\"Expectation-and-Variance\"><a href=\"#Expectation-and-Variance\" class=\"headerlink\" title=\"Expectation and Variance\"></a>Expectation and Variance</h3><p><strong>Expectation</strong></p>\n<div>$$\nE[X] = \\sum_x xp_X(x)\n$$</div>\n\n<p>Note: we assume that the sum converges.</p>\n<p>Properties:</p>\n<div>$$\nE[Y]=\\sum_x g(x)p_X(x)\\\\\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\n$$</div>\n\n<p><strong>Variance</strong></p>\n<div>$$\n\\text{var}(X) = E \\left[(X-E[X])^2\\right]=\\sum_x (x-E[X])^2 p_X(x)\n$$</div>\n\n<p>Standard deviation: $\\sigma_X&#x3D;\\sqrt{\\text{var}(X)}$</p>\n<p>Properties: </p>\n<div>$$\n\\text{var}(X) = E[X^2] -(E[X])^2\\\\\n\\text{var}(X)\\ge 0\\\\\n\\text{var}(\\alpha X + \\beta) = \\alpha^2\\text{var} (X)\n$$</div>\n\n<p><strong>Bernoulli RV</strong></p>\n<div>$$\np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\\\\\nE[X] = p\\\\\nE[X^2] = p\\\\\n\\text{var}(X) = p(1-p)\n$$</div>\n\n<p><strong>Discrete Uniform RV</strong></p>\n<div>$$\np_X(k) = \\begin{cases}\n    \\frac {1}{b-a+1}, &\\text{if } k = a, a+1, ..., b\\\\\n    0, &\\text{otherwise}\n\\end{cases}\\\\\nE[X] = \\frac{a+b}{2}\\\\\n\\text{var}(X) = \\frac{(b-a)(b-a+2)}{12}\n$$</div>\n\n<p><strong>Poisson RV</strong></p>\n<div>$$\np_X(k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\\nE[X] = \\lambda\\\\\n\\text{var}(X)=\\lambda\n$$</div>\n\n<h3 id=\"Conditional\"><a href=\"#Conditional\" class=\"headerlink\" title=\"Conditional\"></a>Conditional</h3><div>$$\np_{X|A(x)} = P(X=x|A) = \\frac{P(\\{X=x\\}\\cap A)}{P(A)}\n$$</div>\n\n<div>$$\n\\sum_x p_{X|A}(x) = 1\n$$</div>\n\n<div>$$\nE[X|Y=y] = \\sum_x xp_{X|Y}(x|y)\\\\\nE[g(X)|Y=y] = \\sum_x g(x)p_{X|Y}(x|y)\n$$</div>\n\n<p><strong>Total expectation theorem</strong></p>\n<p>$A_1, \\dots, A_n$ is a partition of sample space</p>\n<div>$$\nP(B) = P(A_1)P(B|A_1) + \\dotsb + P(A_n)P(B|A_n)\\\\\np_X(x) = P(A_1)p_{X|A_1}(x) + \\dotsb + P(A_n)p_{X|A_n}(x)\\\\\nE[X] = P(A_1)E[X|A_1] + \\dotsb + P(A_n)E[X|A_n]\n$$</div>\n\n<p>We derive the expectation and variance use the theories above.</p>\n<p><strong>Geometric PMF example</strong></p>\n<div>$$\np_X(k) = (1-p)^{k-1}p, k = 1, 2, \\dots\\\\\nE[X] = \\sum_{k=1}^\\infty kp_X(k) = \\sum_{k=1}^\\infty k(1-p)^{k-1}p\\\\\nE[X^2] = \\sum_{k=1}^\\infty k^2p_X(k) = \\sum_{k=1}^\\infty k^2(1-p)^{k-1}p\\\\\n\\text {var}(X) = E[X^2] - (E[X])^2\n$$</div>\n\n<p>However, the Geometric has a memoryless property.</p>\n<div>$$\np_{X|X>1}(k) = \\frac{P(\\{X>1\\}\\cap \\{X=k\\})}{P(X>1)} = \\frac{(1-p)^{k-1}p}{1-p} = (1-p)^{k-2}p\n$$</div>\n\n<p>Thus, </p>\n<div>$$\nE[X] = P(X=1)E[X|X=1] + P(X>1)E[X|X>1]=p+(1-p)(E[1 + X])\\\\\n\\Rightarrow E[X] = 1/p\\\\\nE[X^2] = P(X=1)E[X^2|X=1] + P(X>1)E[X^2|X>1] = p + (1-p)E[(1+X)^2]=p + (1-p)(1+2E[X]+E[X^2])\\\\\n\\Rightarrow E[X^2] = \\frac{2-p}{p^2}\\\\\n\\Rightarrow\\text{var} (X) = \\frac{1-p}{p^2}\n$$</div>\n\n<h3 id=\"Multiple-discrete-random-variables\"><a href=\"#Multiple-discrete-random-variables\" class=\"headerlink\" title=\"Multiple discrete random variables\"></a>Multiple discrete random variables</h3><p><strong>Joint PMFs</strong></p>\n<div>$$\np_{X, Y}(x, y) = P(X = x, Y= y) = P(\\{X(\\omega) = x\\}\\cap \\{Y(\\omega) = y\\})\n$$</div>\n\n<div>$$\n\\sum_x\\sum_y p_{X, Y}(x, y) = 1\n$$</div>\n\n<p><strong>Marginal PMF</strong></p>\n<div>$$\np_X(x) = \\sum_y P(X=x, Y=y) = \\sum_y p_{X, Y}(x, y)\n$$</div>\n\n<p><strong>Conditional PMF</strong></p>\n<div>$$\np_{X|Y}(x|y) = P(X = x | Y = y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$</div>\n\n<div>$$\n\\sum_x p_{X|Y}(x|y) = 1\n$$</div>\n\n<p><strong>Funcitons of multiple RVs</strong></p>\n<div>$$\nZ = g(X, Y)\\\\\np_Z(z) = \\sum_{\\lbrace (x, y)|g(x, y)=z \\rbrace  } p_{X, Y}(x, y)\n$$</div>\n\n<p><strong>Expectations</strong></p>\n<div>$$\nE[g(X, Y)] = \\sum_x\\sum_y g(x, y)p(X, Y)(x, y)\\\\\nE[g(X, Y, Z)] = \\sum_x\\sum_y\\sum_z g(x, y, z)p(X, Y, Z)(x, y, z)\n$$</div>\n\n<div>$$\nE[g(X,  Y)] \\not\\equiv g(E[X], E[Y])\n$$</div>\n\n<p><strong>linearity</strong></p>\n<div>$$\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\\\\\nE[X + Y + Z] = E[X] + E[Y] + E[Z]\n$$</div>\n\n<p>Let’s calculate the Mean of Binominal RV.</p>\n<div>$$\nX_i=\n\\begin{cases}\n    1, &\\text{if success in trial } i,\\\\\n    0, & \\text{otherwise.}\n\\end{cases}\\\\\nX = X_1 + X_2 + \\dotsb X_n\\\\\nE[X] = \\sum_{i = 1}^n E[X_i] = np\\\\\n\\text{var}(X) = np(1-p)\n$$</div>\n\n<h3 id=\"Independence-1\"><a href=\"#Independence-1\" class=\"headerlink\" title=\"Independence\"></a>Independence</h3><p><strong>Independence</strong></p>\n<div>$$\np_{X, Y}(x, y) = p_X(x) \\cdot p_Y(y)\n$$</div>\n\n<p>if $X$ and $Y$ are independent:</p>\n<div>$$\nE[XY] = E[X]E[Y]\\\\\nE[g(X)h(Y)] = E[g(X)]E[h(Y)]\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\n$$</div>\n\n<p><strong>Conditional independence</strong></p>\n<div>$$\np_{X, Y|A}(X, Y) = p_{X|A}(x) \\cdot p_{Y|A}(y)\n$$</div>\n\n<h2 id=\"Continuous-Random-Variables\"><a href=\"#Continuous-Random-Variables\" class=\"headerlink\" title=\"Continuous Random Variables\"></a>Continuous Random Variables</h2><h3 id=\"Probability-Density-Function\"><a href=\"#Probability-Density-Function\" class=\"headerlink\" title=\"Probability Density Function\"></a>Probability Density Function</h3><ul>\n<li>$f_X(x)\\ge 0\\text{ for all }x$</li>\n<li>$\\int_{-\\infty}^\\infty f_X(x)\\mathrm dx &#x3D; 1$</li>\n<li>If $\\delta$ is very small, then $P([x, x+\\delta])\\approx f_X(x) \\cdot \\delta$</li>\n<li>For any subset $B$ of the real line, $P(X\\in B) &#x3D; \\int_B f_X(x)\\mathrm d x$.</li>\n</ul>\n<p><strong>Expectation</strong></p>\n<div>$$\nE[X] = \\int_{-\\infty}^\\infty xf_X(x)\\mathrm dx\\\\\nE[g(x)] = \\int_{-\\infty}^\\infty g(x)f_X(x)\\mathrm dx\n$$</div>\n\n<p>Assuming that the integration is well-defined. The Cauchy distribution ($\\frac{1}{1+x^2}$)doesn’t have expectation since $\\frac{x}{1+x^2}$ is not absolutely integrably.</p>\n<p><strong>Variance</strong></p>\n<div>$$\n\\text{var}(X) = E[(X - E[X])^2] = \\int_{-\\infty}^\\infty(x - E[x])^2 f_X(x)\\mathrm dx\\\\\n0\\le \\text{var}(x) = E[X^2] - (E[X])^2\n$$</div>\n\n<p><strong>Uniform RV</strong></p>\n<div>$$\nf_X(x) = \\begin{cases}\n    \\frac{1}{b-a}, &\\text{if }a\\le x\\le b,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<div>$$\nE[X] = \\frac{a+b}{2}\\\\\nE[X^2] = \\frac{a^2+b^2 + ab}{3}\\\\\n\\text{var}(X) = \\frac{(b-a)^2}{12}\n$$</div>\n\n\n<p>Properties:</p>\n<div>$$\nE[aX+b] = aE[X] + b\\\\\n\\text{var}(aX+b) = a^2\\text{var}(X)\n$$</div>\n\n<h3 id=\"Common-Example-for-PDF\"><a href=\"#Common-Example-for-PDF\" class=\"headerlink\" title=\"Common Example for PDF\"></a>Common Example for PDF</h3><p><strong>Exponential Random Variable</strong></p>\n<div>$$\nf_X(x) = \\begin{cases}\n    \\lambda e^{-\\lambda x}, &\\text{if }x \\ge 0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<div>$$\nP(X\\ge a) = e^{-\\lambda a}\\\\\nE[X] = \\frac{1}{\\lambda}\\\\\n\\text{var}(X) = \\frac{1}{\\lambda^2}\n$$</div>\n\n<h3 id=\"Cumulative-Distribution-Functions\"><a href=\"#Cumulative-Distribution-Functions\" class=\"headerlink\" title=\"Cumulative Distribution Functions\"></a>Cumulative Distribution Functions</h3><div>$$\nF_X(x) = P(X\\le x) = \\begin{cases}\n    \\sum_{k\\le x}p_X(k), &\\text{if } X \\text{ is discrete,}\\\\\n    \\int_{-\\infty}^x f_X(t)\\mathrm dt, &\\text{if } X \\text{ is continuous.}\n\\end{cases}\n$$</div>\n\n<p><strong>Properties</strong></p>\n<div>$$\n\\text{if } x \\le y, \\text{then } F_X(x)\\le F_X(y).\\\\\nF_X(x)\\text{ tends to 0 as } x \\rightarrow -\\infty, \\text{and to 1 as} x \\rightarrow \\infty\\\\\n\\text{If } X \\text{ is discrete, then } F_X(x) \\text{ is a piecewise constant function of }x.\\\\\n\\text{If } X \\text{ is continuous, then } F_X(x) \\text{is a continuous funciton of }x.\\\\\n\\text{If } X \\text{ is discrete and takes integer values, the PMF and the CDF can be obtained from each other by summing or differcing: }\\\\\nF_X(k) = \\sum_{i = -\\infty}^k p_X(i),\\\\\np_X(k) = P(X\\le k) - P(X \\le k -1) = F_X(k) - F_X(k - 1),\\\\\n\\text{ for all integers }k.\\\\\n\\text{If } X \\text{ is continuous, the PDF and the CDF can be obtained from each other by integration or differentiation: }\\\\\nF_X(x) = \\int_{-\\infty}^x f_X(t)\\mathrm dt, f_X(x) = \\frac{\\mathrm dF_X}{\\mathrm dx}(x)\n$$</div>\n\n<h3 id=\"Examples-for-CDF\"><a href=\"#Examples-for-CDF\" class=\"headerlink\" title=\"Examples for CDF\"></a>Examples for CDF</h3><p><strong>Geometric CDF</strong></p>\n<div>$$\nF_{\\text{geo}}(n) = \\sum_{k = 1}^n p(1-p)^{k-1} = 1-(1-p)^n, \\text{for } n = 1, 2, \\dots\n$$</div>\n\n<p><strong>Exponential CDF</strong></p>\n<div>$$\nF_{\\text{exp}}(x) = P(X\\le x) = 0, \\text{ for } x\\le0,\\\\\nF_{\\text{exp}}(x) = \\int_{0}^x \\lambda e^{-\\lambda t}\\mathrm dt = 1 - e^{-\\lambda x}, \\text{for }x\\ge 0.\n$$</div>\n\n<p>Exponential Distribution is Memoriless, like Geometric: </p>\n<div>$$\nP(X \\ge c + x| X \\ge c) = e^{-\\lambda x} = P(X \\ge x)\\\\\n$$</div>\n\n<p>The relationship: </p>\n<p><img src=\"/../images/prob/L6_1.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Normal-Random-Variables\"><a href=\"#Normal-Random-Variables\" class=\"headerlink\" title=\"Normal Random Variables\"></a>Normal Random Variables</h3><div>$$\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-(x-\\mu)^2/2\\sigma^2}\\\\\nE[X] =\\mu\\\\\n\\text{var}(X) = \\sigma^2\n$$</div>\n\n<p>Gaussian is good, since adding two Gaussian functions resulting in a new Gaussian functions. And with a huge mount of samples, the distribution is close to Gaussian(Central limit theorem).</p>\n<p><strong>The Standard Normal Random Variable</strong></p>\n<p>Normal(Gaussian)</p>\n<div>$$\nY = \\frac{X - \\mu}{\\sigma}\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}}e^{-y^2/2}\\\\\nE[Y] = 0\\\\\n\\text{var}(Y) = 1\\\\\n$$</div>\n\n<p>The CDF of Normal Random Variable $\\Phi(y)$ can not be derived directly, we can use the standard normal table to get the value.</p>\n<div>$$\n\\Phi(-y) = 1 - \\Phi(y)\n$$</div>\n\n<h3 id=\"Multiple-Continuous-Random-Variables\"><a href=\"#Multiple-Continuous-Random-Variables\" class=\"headerlink\" title=\"Multiple Continuous Random Variables\"></a>Multiple Continuous Random Variables</h3><p><strong>Joint PDFs</strong></p>\n<p>The two continuous RVs X and Y, with the same experiment, are jointly continuous if they can be described by a joint PDF $f_{X, Y}$, where $f_{X, Y}$ is a nonnegative function that satisfies </p>\n<div>$$\nP((X, Y) \\in B) = \\iint_{(x, y)\\in B} f(X, Y)\\mathrm d x\\mathrm dy\n$$</div>\n\n<p>for every subset B of the two-dimensional plane. In particular, when B is the form $B &#x3D; {(x, y)|a\\le x \\le b, c\\le y \\le d}$, we have</p>\n<div>$$\nP(a\\le X \\le b, c \\le Y \\le d) = \\int_c^d\\int_a^bf_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$</div>\n\n<p><strong>Normalization</strong> </p>\n<div>$$\n\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\\mathrm dy = 1\n$$</div>\n\n<p><strong>Interpretation(Small rectangle)</strong></p>\n<div>$$\nP(a\\le X \\le a + \\delta, c \\le Y \\le c + \\delta) \\approx f_{X, Y}(a, c)\\cdot\\delta^2\n$$</div>\n\n<p><strong>Marginal PDF</strong></p>\n<div>$$\nP(X\\in A) = P(X \\in A, Y \\in (-\\infty, \\infty)) = \\int_A \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\mathrm dx\n$$</div>\n\n<div>$$\nf_X(x) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\\\\nf_Y(y) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\n$$</div>\n\n<p><strong>Joint CDF</strong></p>\n<p>If X and Y are two RVs asscociated with the same experiment, then the joint CDF of X and Y is the function</p>\n<div>$$\nF_{X, Y}(x, y) = P(X\\le x, Y\\le y) = P(X\\le x|Y\\le y)P(Y\\le y) = \\int_{-\\infty}^y\\int_{-\\infty}^x f_{X, Y}(u, v)\\mathrm du\\mathrm dv\n$$</div>\n\n<p>Conversely</p>\n<div>$$\nf_{X, Y}(x, y) = \\frac{\\partial^2F_{X, Y}}{\\partial x\\partial y}(x, y)\n$$</div>\n\n<p><strong>Expectations</strong></p>\n<div>$$\nE[g(X, Y)] = \\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty g(x, y)f_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$</div>\n\n<p>If g is linear, of the form of $g(x, y) &#x3D; ax + by + c$, then</p>\n<div>$$\nE[g(X, Y)] = aE[X] + bE[Y] + c\n$$</div>\n\n<p>X and Y are called independent if </p>\n<div>$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$</div>\n\n<h3 id=\"Conditional-and-Independence\"><a href=\"#Conditional-and-Independence\" class=\"headerlink\" title=\"Conditional and Independence\"></a>Conditional and Independence</h3><p><strong>Conditional PDFs</strong></p>\n<p>Let X and Y be continuous RVs with joint PDF $f_{X, Y}$. For any $f_Y(y) \\gt 0$, the conditional PDF of X given Y &#x3D; y is defined by</p>\n<div>$$\nf_{X|Y}(x|y) = \\frac{f_{X, Y}(x, y)}{f_Y(y)}\n$$</div>\n\n<p>Discrete case: </p>\n<div>$$\np_{X|Y}(x|y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$</div>\n\n<p>By analogy, for fixed y would like: </p>\n<div>$$\nP(x \\le X \\le x + \\delta|Y = y) \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$</div>\n\n<p>But {Y &#x3D; y} is a zero-probability event.</p>\n<p>Let $B &#x3D; {y\\le Y \\le y + \\epsilon}$, for small $\\epsilon &gt; 0$. Then</p>\n<div>$$\nP(x \\le X \\le x + \\delta|Y \\in B) \\approx \\frac{P(x \\le X \\le x + \\delta)}{P(y \\le Y \\le y + \\epsilon)} \\approx \\frac{f_{X, Y}(x, y)\\cdot\\epsilon\\delta}{f_Y(y)\\cdot\\epsilon} \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$</div>\n\n<p>Limiting case when $\\epsilon \\rightarrow 0$, to define conditional PDF where the denominator is a zero-probability event.</p>\n<p><strong>Conditional Expectation</strong></p>\n<p>The conditional expectation of X given that A has happened is defined by </p>\n<div>$$\nE[X|A] = \\int_{-\\infty}^\\infty xf_{X|A}(x)\\mathrm dx\n$$</div>\n\n<p>For a function g, we have</p>\n<div>$$\nE[g(X)|A] = \\int_{-\\infty}^\\infty g(x)f_{X|A}(x)\\mathrm dx\n$$</div>\n\n<p><strong>Total expectation theorem</strong></p>\n<p>Le $A_1, A_2, \\dots A_n$ be disjoint events that form a partition of the sample space $\\Omega$. And $P(A_i)\\gt 0$ for all $i$. Then</p>\n<div>$$\nE[g(X)] = \\sum_{i=1}^n P(A_i)E[g(X)|A_i]\n$$</div>\n\n<p>Conditional Expectation</p>\n<p>The conditional expectation of X given that $Y &#x3D; y$ has happened is defined by </p>\n<div>$$\nE[X|Y=y] = \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx\n$$</div>\n\n<p>For a function g, we have</p>\n<div>$$\nE[g(X)|Y=y] = \\int_{-\\infty}^\\infty g(x)f_{X|Y}(x|y)\\mathrm dx\n$$</div>\n\n<p>Total expectation theorem</p>\n<div>$$\nE[X] = E_{Y}\\left[E_{X|Y}[X|Y]\\right] = \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy\n$$</div>\n\n<p><strong>Independence</strong></p>\n<p>Two continuous RVs $X$ and $Y$ are independent if and only if</p>\n<div>$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$</div>\n\n<p>Independence is the same as the condition</p>\n<div>$$\nf_{X|Y}(x|y) = f_X(x)\n$$</div>\n\n<p>If $X$ and $Y$ are independent, then</p>\n<div>$$\nE[XY] = E[X]E[Y]\\\\\nE[g(x)h(y)] = E[g(x)]E[h(y)], \\forall g, h\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\\\\\n$$</div>\n\n<h3 id=\"The-continuous-Bayes’s-rule\"><a href=\"#The-continuous-Bayes’s-rule\" class=\"headerlink\" title=\"The continuous Bayes’s rule\"></a>The continuous Bayes’s rule</h3><div>$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{f_Y(y)}\n$$</div>\n\n<p>Based on the normalization property $\\int_{-\\infty}^\\infty f_{X|Y}(x|y)\\mathrm dx &#x3D; 1$,</p>\n<div>$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{\\int_{-\\infty}^\\infty f_X(t)f_{Y|X}(y|t)\\mathrm dt}\n$$</div>\n\n<h2 id=\"Derived-distributions-and-Entropy\"><a href=\"#Derived-distributions-and-Entropy\" class=\"headerlink\" title=\"Derived distributions and Entropy\"></a>Derived distributions and Entropy</h2><h3 id=\"Derived-Distribution\"><a href=\"#Derived-Distribution\" class=\"headerlink\" title=\"Derived Distribution\"></a>Derived Distribution</h3><p>If we want to calculate the expectation $E[g(X)]$, there’s no need to calculate the PDF $f_X$ of $X$.</p>\n<p>But sometimes we want the PDF $f_Y$ of $Y &#x3D; g(X)$, where $Y$ is a new RV.</p>\n<p><strong>Principal Method</strong></p>\n<p>Two-step procedure for the calculation of the PDF of a function $Y&#x3D;g(X)$ of a continuous RV $X$</p>\n<ol>\n<li>Calcualte the CDF $F_Y$ of $Y$: $F_Y(y) &#x3D; P(Y \\le y)$</li>\n<li>Differentiate $F_Y$ to obtain the PDF $f_Y$ of $Y$: $f_Y(y) &#x3D; \\frac{\\mathrm d F_Y}{\\mathrm d y}(y)$</li>\n</ol>\n<p><strong>The PDF of $Y&#x3D;aX + b$</strong></p>\n<p>Suppose $a&gt;0$ and $b$ are constants.</p>\n<div>$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(\\frac{y-b}{a}) = \\frac{1}{a}f_X(\\frac{y-b}{a})\n$$</div>\n\n<p>If $X$ is Normal, then $Y &#x3D; aX + b$ is also Normal.</p>\n<p>Suppose X is normal with mean $\\mu$ and variance $\\sigma^2$. Then</p>\n<div>$$\nf_Y(y) = \\frac{1}{a\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y-b-a\\mu)^2}{2a^2\\sigma^2}\\right)\n$$</div>\n\n<div>$$\nY = aX + b \\sim N(a\\mu + b, a^2\\sigma^2)\n$$</div>\n\n<p><strong>The PDF of a strictly monotonic function</strong></p>\n<p>Suppose $g$ is a strictly monotonic function and that for some function $h$ and all $x$ in the range of $X$ we have </p>\n<div>$$\ny = g(x) \\text{ if and only if } x = h(y)\n$$</div>\n\n<p>Assume that $h$ is differentiable.</p>\n<p>Then the PDF of $Y &#x3D; g(X)$ is given by</p>\n<div>$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(h(y)) = f_X(h(y))\\left|\\frac{\\mathrm d h}{\\mathrm d y}(y)\\right|\n$$</div>\n\n<h3 id=\"Entropy\"><a href=\"#Entropy\" class=\"headerlink\" title=\"Entropy\"></a>Entropy</h3><p><strong>Defintion</strong></p>\n<p>Discrete case</p>\n<p>Let $X$ be a discrete RV defined on probability space $(\\Omega, \\mathcal F, P)$. The <strong>entropy</strong> of $X$ is defined by</p>\n<div>$$\nH(X) = -E[\\ln p_X(X)] = -\\sum_{k} p_X(x_k)\\ln p_X(x_k)\n$$</div>\n\n<p>Continuous case</p>\n<p>Let $X$ be a continuous RV defined on probability space $(\\Omega, \\mathcal F, P)$. The <strong>differential entropy</strong> of $X$ is defined by</p>\n<div>$$\nH(X) = -E[\\ln f_X(X)] = -\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\n$$</div>\n\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>a special expectation of a random variable</li>\n<li>a measure of uncertainty in a random experiment</li>\n<li><ul>\n<li>the larger the entropy, the more uncertain the experiment</li>\n</ul>\n</li>\n<li><ul>\n<li>For a deterministic event, the entropy is zero</li>\n</ul>\n</li>\n<li>The base of logarithm can be different. Changing the base od the logarithm is equivalent to multiplying the entropy by a constant.</li>\n<li><ul>\n<li>With base 2, we say that the entropy is in units of <strong>bits</strong></li>\n</ul>\n</li>\n<li><ul>\n<li>With base e, we say that the entropy is in units of <strong>nats</strong></li>\n</ul>\n</li>\n<li>The basis of information theory</li>\n</ul>\n<h3 id=\"Maximum-entropy-distributions\"><a href=\"#Maximum-entropy-distributions\" class=\"headerlink\" title=\"Maximum entropy distributions\"></a>Maximum entropy distributions</h3><p>• Maximum entropy distributions</p>\n<p>− Distributions with maximum entropy under some constraints</p>\n<p>− Gaussian, exponential, and uniform distributions are all maximum entropy distributions under certain conditions</p>\n<p>• Why studying maximum entropy distributions?</p>\n<p>− The most random distribution, reflecting the maximum uncertainty about the quantity of interest</p>\n<p><strong>Definition</strong></p>\n<p><strong>Discrete Case</strong></p>\n<p>X can be a finite number of values $x_1, x_2, \\dots, x_n$, satisfying $p_X(x_k) &#x3D; p_k.$</p>\n<p>We have the following optimization problem:</p>\n<div>$$\n\\max_{X} H(X) = \\max_{p_1, p_2, \\dots, p_n} \\left(-\\sum_{k=1}^n p_k\\ln p_k\\right)\\\\\n\\text{s.t.} \\sum_{k=1}^n p_k = 1, p_k \\ge 0 \\text{ for } k = 1, 2, \\dots, n\n$$</div>\n\n<p><strong>Solution</strong></p>\n<p>Applying the Lagrange multiplier method, we have</p>\n<div>$$\nL(p_1, p_2, \\dots, p_n;\\lambda) = -\\sum_{k=1}^n p_k\\ln p_k + \\lambda\\left(\\sum_{k=1}^n p_k - 1\\right)\\\\\n\\frac{\\partial L}{\\partial p_k} = -\\ln p_k - 1 + \\lambda = 0\\\\\n\\Rightarrow p_k = e^{\\lambda - 1}\\\\\n$$</div>\n\n<p>Note that the above is true for all $k$. So we have</p>\n<div>$$\np_k = e^{\\lambda - 1}  = \\frac1{n}\\text{ for } k = 1, 2, \\dots, n.\n$$</div>\n\n<p><strong>Continuous Case 1</strong></p>\n<p>$X \\in [-\\infty, \\infty]$.</p>\n<p>Constrain on mean and variance,<br>we have the following optimization problem:</p>\n<div>$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu, \\quad Var(X) = \\sigma^2\n$$</div>\n\n<p>In detail, </p>\n<div>$$\n\\max_{X} H(X) = \\max_{\\mu, \\sigma^2} \\left(-\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{-\\infty}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{-\\infty}^\\infty xf(x)\\mathrm dx = \\mu, \\quad \\int_{-\\infty}^\\infty x^2f(x)\\mathrm dx = \\sigma^2 + \\mu^2\n$$</div>\n\n<p>Solving the above problem, we have Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$.</p>\n<div>$$\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$</div>\n\n<p><strong>Solution</strong></p>\n<p>For all measurable functions $g$, we have</p>\n<div>$$\nG(t) = h(f + tg) = -\\int_{\\infty}^\\infty (f(x) + tg(x))\\ln (f(x) + tg(x))\\mathrm dx\n$$</div>\n\n<p>Therefore,</p>\n<div>$$\nh(f_{opt})\\ge h(f_{opt} + tg)\\\\\n\\Rightarrow G(0)\\ge G(t), \\forall t \\in \\R\n$$</div>\n\n<p>$G(t)$ reaches its maximum at $t &#x3D; 0$.</p>\n<p>Then apply the Lagrange multiplier method, we have</p>\n<div>$$\n\\overline{G}(t) = G(t) + c_0h_0(t) + c_1h_1(t) + c_2h_2(t)\\\\\n$$</div>\n\n<p>Get the derivative of $\\overline{G}(t)$ with regard to $t$, and let the derivative equal to zero.</p>\n<p><strong>Continuous Case 2</strong></p>\n<p>$X \\in [0, \\infty)$.</p>\n<p>Constrain on mean only, we have the following optimization problem:</p>\n<div>$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu\n$$</div>\n\n<p>In detail,</p>\n<div>$$\n\\max_{X} H(X) = \\max_{\\mu} \\left(-\\int_{0}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{0}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{0}^\\infty xf(x)\\mathrm dx = \\mu\n$$</div>\n\n<p>Solving the above problem, we have exponential distribution with parameter $\\lambda$.</p>\n<div>$$\nf(x) = \\lambda e^{-\\lambda x}, x \\in [0, \\infty)\n$$</div>\n\n<p><strong>Continuous Case 3</strong></p>\n<p>$X \\in [a, b]$.</p>\n<p>No constrain, we have the unconstrained optimization problem:</p>\n<div>$$\n\\max_{X}h(X)\n$$</div>\n\n<p>In detail,</p>\n<div>$$\n\\max_{X} H(X) = \\max_{a, b} \\left(-\\int_{a}^b f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{a}^b f(x)\\mathrm dx = 1\n$$</div>\n\n<p>Solving the above problem, we have uniform distribution within $[a, b]$.</p>\n<div>$$\nf(x) = \\frac{1}{b-a}, x \\in [a, b]\n$$</div>\n\n<h2 id=\"Convolution-covariance-correlation-and-conditional-expectation\"><a href=\"#Convolution-covariance-correlation-and-conditional-expectation\" class=\"headerlink\" title=\"Convolution, covariance, correlation, and conditional expectation\"></a>Convolution, covariance, correlation, and conditional expectation</h2><h3 id=\"Convolution\"><a href=\"#Convolution\" class=\"headerlink\" title=\"Convolution\"></a>Convolution</h3><p><strong>Discrete case</strong></p>\n<div>$$\n\\begin{align*}\np_W(w) &= P(X+Y=w)\\\\\n&= \\sum_{x}P(X=x, Y=w-x)\\\\\n&= \\sum_{x}P(X=x)P(Y=w-x)\\\\\n&= \\sum_{x}p_X(x)p_Y(w-x)\\\\\n\\end{align*}\n$$</div>\n\n<p>PMF $p_W$ is the convolution of PMFs $p_X$ and $p_Y$.</p>\n<p><strong>The distribution of $X+Y$</strong></p>\n<p>Mechanics:</p>\n<ul>\n<li>Put the PMF’s on top of each other</li>\n<li>Flip the PMF of $Y$</li>\n<li>Shift the flipped PMF by $w$ (to the right if $w&gt;0$)</li>\n<li>Cross-multiply and add</li>\n</ul>\n<p><strong>Continuous Case</strong></p>\n<div>$$\n\\begin{align*}\n&W = X+Y, X, Y \\text{ are independent}\\\\\n&P(W\\le w|X=x) = P(Y\\le w-x)\\\\\n&f_{W|X}(w|x) = f_Y(w-x)\\\\\n&f_{W, X}(w, x) = f_X(x)f_Y(w-x)\\\\\n&f_W(w) = \\int_{-\\infty}^\\infty f_X(x)f_Y(w-x)\\mathrm dx\\\\\n\\end{align*}\n$$</div>\n\n<p><strong>Sum of 2 independent normal RVs</strong></p>\n<div>$$\n\\begin{align*}\n    & X\\sim N(\\mu_1, \\sigma_1^2), Y\\sim N(\\mu_2, \\sigma_2^2)\\\\\n    &f_{X,Y}(x, y) = \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{(x-\\mu_x)^2}{2\\sigma_x^2} - \\frac{(y-\\mu_y)^2}{2\\sigma_y^2}\\right\\rbrace\n\\end{align*}\n$$</div>\n\n<p>which is constant on the ellipse(circle if $\\sigma_x &#x3D; \\sigma_y$).</p>\n<div>$$\n\\begin{align*}\n    X\\sim N(0, \\sigma_x), &Y\\sim N(0, \\sigma_y)\\\\\n    W &= X+Y\\\\\n    f_W(w) &= \\int_{-\\infty}^\\infty f_{X,Y}(x, w-x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{x^2}{2\\sigma_x^2} - \\frac{(w-x)^2}{2\\sigma_y^2}\\right\\rbrace\\mathrm dx\\\\\n    =ce^{-\\gamma \\omega^2}\n\\end{align*}\n$$</div>\n\n<p>$W$ is Normal.</p>\n<p>Mean &#x3D; 0, Variance &#x3D; $\\sigma_x^2 + \\sigma_y^2$</p>\n<p>Same argument for nonzero mean case.</p>\n<p><strong>The difference of two independent RVs</strong></p>\n<p>$X$ and $Y$  are independent exponential RVs with parameter $\\lambda$.</p>\n<p>Fix some $z\\ge 0$ and note that $f_Y(x-z)$ is non zero when $x\\ge z$.</p>\n<div>$$\n\\begin{align*}\n    Z &= X - Y\\\\\n    f_Z(z) &= \\int_{-\\infty}^\\infty f_X(x)f_{-Y}(z - x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty f_X(x)f_{Y}(x - z)\\mathrm dx\\\\\n    &= \\int_{z}^\\infty \\lambda e^{-\\lambda x}\\lambda e^{-\\lambda(x-z)}\\mathrm dx\\\\\n    &= \\frac{\\lambda}{2}e^{-\\lambda z}\n\\end{align*}\n$$</div>\n\n<p>The answer for the case $z\\le 0$</p>\n<div>$$\nf_{X-Y}(z) = f_{Y-X}(z) = f_Z(-z)\n$$</div>\n\n<p>The first quality holds by symmetry.</p>\n<h3 id=\"Covariance-and-Correlation\"><a href=\"#Covariance-and-Correlation\" class=\"headerlink\" title=\"Covariance and Correlation\"></a>Covariance and Correlation</h3><p><strong>Definition</strong></p>\n<p>The covariance of two RVs $X$ and $Y$, denoted by $\\text{cov}(X, Y)$, is defined by</p>\n<div>$$\n\\text{cov}(X, Y) = E\\left[(X - E[X])(Y - E[Y])\\right]\n$$</div>\n\n<p>or, </p>\n<div>$$\n\\text{cov}(X, Y) = E[XY] - E[X]E[Y]\n$$</div>\n\n<p>$X$ and $Y$ are <strong>uncorrelated</strong> if $\\text{cov}(X, Y) &#x3D; 0$.</p>\n<p><strong>Zero mean case</strong> $\\text{cov}(X, Y) &#x3D; E[XY]$</p>\n<p><strong>Properties</strong></p>\n<div>$$\n\\text{cov}(X, Y) = \\text{var}(X, Y)\\\\\n\\text{cov}(X, aY+b) = a\\cdot\\text{cov}(X, Y)\\\\\n\\text{cov}(X, Y+Z) = \\text{cov}(X, Y) + \\text{cov}(X, Z)\\\\\n\\text{independent} \\Rightarrow \\text{cov}(X, Y) = 0(\\text{converse is not true})\n$$</div>\n\n<p><strong>Variance of the sum of RVs</strong></p>\n<div>$$\n\\text{var}\\left(\\sum_{i = 1}^nX_i\\right) = \\sum_{i = 1}^n\\text{var}(X_i) + \\sum_{\\lbrace(i, j)|i\\ne j\\rbrace}\\text{cov}(X_i, X_j)\n$$</div>\n\n<p>In particular, </p>\n<div>$$\n\\text{var}(X_1 + X_2) = \\text{var}(X_1) + \\text{var}(X_2) + 2\\text{cov}(X_1, X_2)\n$$</div>\n\n<p><strong>Correlation coefficient</strong></p>\n<p>The correlation coefficient $\\rho(X, Y)$ of two RVs $X$ and $Y$ that have nonzero variance is defined as</p>\n<div>$$\n\\begin{align*}\n\\rho &= E\\left[\\frac{(X - E[X])}{\\sigma_X} \\cdot \\frac{(Y - E[Y])}{\\sigma_Y}\\right]\\\\\n&= \\frac{\\text{cov}(X, Y)}{\\sigma_X\\sigma_Y}\n\\end{align*}\n$$</div>\n\n<ul>\n<li>$-1 \\le \\rho \\le 1$</li>\n<li>$|\\rho| &#x3D; 1 \\Leftrightarrow (X-E[X]) &#x3D; c(Y-E[Y])$</li>\n<li>Independent $\\Rightarrow \\rho &#x3D; 0(\\text{converse is not true})$</li>\n</ul>\n<p><strong>Conditional expected value</strong></p>\n<div>$$\nE[X|Y = y] = \\sum_x xp_{X|Y}(x|y)\n$$</div>\n\n<h3 id=\"Conditional-expectation\"><a href=\"#Conditional-expectation\" class=\"headerlink\" title=\"Conditional expectation\"></a>Conditional expectation</h3><p><strong>Definition</strong></p>\n<div>$$\nE[X|Y = y] = \\begin{cases}\n    \\sum_x xp_{X|Y}(x|y), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$</div>\n\n<p>$E[X|Y&#x3D;y]$ is a function of $y$.</p>\n<div>$$\nE[X|Y = y] = \\frac{y}{2}(\\text{number})\\\\\nE[X|Y] = \\frac{Y}{2}(\\text{RV})\n$$</div>\n\n<p><strong>Law of iterated expectations</strong></p>\n<div>$$\nE[X] = E[E[X|Y]] = \\begin{cases}\n    \\sum_y E[X | Y = y]p_Y(y), & Y \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy, & Y \\text{continuous}.\n\\end{cases}\n$$</div>\n\n<h3 id=\"Conditional-expectation-as-an-estimator\"><a href=\"#Conditional-expectation-as-an-estimator\" class=\"headerlink\" title=\"Conditional expectation as an estimator\"></a>Conditional expectation as an estimator</h3><p>Denote the conditional expectation</p>\n<div>$$\n\\hat{X} = E[X|Y]\n$$</div>\n\n<p>as an estimator of $X$ given $Y$, and the estimation error</p>\n<div>$$\n\\tilde{X} = X - \\hat{X}\n$$</div>\n\n<p>is a RV.</p>\n<p><strong>Properties of the estimator</strong>: </p>\n<p><strong>Unbiased</strong></p>\n<p>For <strong>any</strong> possible $Y&#x3D;y$:</p>\n<div>$$\nE[\\tilde{X}|Y] = E[X - \\hat{X} | Y] = E[X | Y] - E[\\hat{X}|Y] = \\hat{X} - \\hat{X} = 0\n$$</div>\n\n<p>By the law of iterated expectations</p>\n<div>$$\nE[\\tilde{X}] = E[E[\\tilde{X}|Y]] = 0\n$$</div>\n\n<p><strong>Uncorrelated</strong></p>\n<div>$$\nE[\\hat{X}\\tilde{X}] = E[E[\\hat{X}\\tilde{X}|Y]] = E[\\hat{X}E[\\tilde{X}|Y]] = 0\n$$</div>\n\n<div>$$\n\\text{cov}(\\hat{X}, \\tilde{X}) = E[\\hat{X}\\tilde{X}] - E[\\hat{X}]E[\\tilde{X}] = 0\n$$</div>\n\n<p>Since $X &#x3D; \\hat{X} + \\tilde{X}$, the variance of X can be decomposed as</p>\n<div>$$\n\\text{var}(X) = \\text{var}(\\hat{X}) + \\text{var}(\\tilde{X})\n$$</div>\n\n<div>$$\n\\text{var}(\\tilde{X}) = \\text{var}(E[X|Y])\n$$</div>\n\n<p>Conditional variance</p>\n<div>$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$</div>\n\n<p>here comes the law of total variance:</p>\n<div>$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$</div>\n\n<p>The total variability is avarage variability within sections + variability between sections.</p>\n<p><strong>Law of iterated expectations</strong></p>\n<div>$$\nE[X] = E[E[X|Y]] = \\sum_y E[X|Y = y]p_Y(y)\n$$</div>\n\n\n<p><strong>Conditional variance</strong></p>\n<div>$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$</div>\n\n<p><strong>Law of total variance</strong></p>\n<div>$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$</div>\n\n\n<h2 id=\"Transforms-and-sum-of-a-random-number-of-random-variables\"><a href=\"#Transforms-and-sum-of-a-random-number-of-random-variables\" class=\"headerlink\" title=\"Transforms and sum of a random number of random variables\"></a>Transforms and sum of a random number of random variables</h2><p>The transform associated with a RV $X$ is a function $M_X(s)$ of a scalar parameter $s$, defined by</p>\n<div>$$\nM_X(s) = E[e^{sX}] = \\begin{cases}\n    \\sum_x e^{sx}p_X(x), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty e^{sx}f_X(x)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$</div>\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>a function of $s$, rather than a number</li>\n<li>not necessarily defined for all (complex) s</li>\n<li>always well defined for $\\Re(s)&#x3D;0$</li>\n<li>compared with Laplace transform</li>\n</ul>\n<h3 id=\"Properties\"><a href=\"#Properties\" class=\"headerlink\" title=\"Properties\"></a>Properties</h3><p><strong>Sanity Checks</strong></p>\n<div>$$\nM_X(0) = 1\\\\\n|M_X(s)| \\le 1 \\text{ for } \\Re(s) = 0\n$$</div>\n\n<p><strong>Linear operation</strong></p>\n<div>$$\nM_{aX + b}(s) = e^{bs}M_X(as)\\\\\nM_{X + Y}(s) = M_X(s)M_Y(s) (\\text{if X, Y independent})\n$$</div>\n\n<p><strong>Expected Values</strong></p>\n<div>$$\nE[X^n] = \\frac{\\partial^n M_X(s)}{\\partial s^n}\\bigg|_{s=0}\n$$</div>\n\n<div>$$\nP(X = c) = \\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc}\n$$</div>\n\n<p>since</p>\n<div>$$\n\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N e^{-jc(k - x)} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac{1}{N} \\frac{e^{j(x-c)} - e^{Nj(x - c)}}{1-e^{j(x-c)}} = p_X(c)\n$$</div>\n\n<p><strong>Example</strong></p>\n<p>$X$ is a Poisson RV with parameter $\\lambda$</p>\n<div>$$\np_X(x) = \\frac{\\lambda^x}{x!}e^{-\\lambda}\n$$</div>\n\n<div>$$\nM(s) = \\sum_{x = 0}^\\infty e^{sx}\\frac{\\lambda^x}{x!}e^{-\\lambda} = e^{-\\lambda}\\sum_{x = 0}^\\infty \\frac{(e^s\\lambda)^x}{x!} = e^{-\\lambda}e^{e^s\\lambda} = e^{\\lambda(e^s - 1)}\n$$</div>\n\n<p>$X$ is an exponential RV with parameter $\\lambda$</p>\n<div>$$\nf_X(x) = \\lambda e^{-\\lambda x}\n$$</div>\n\n<div>$$\nM(s) = \\int_0^\\infty e^{sx}\\lambda e^{-\\lambda x}\\mathrm dx = \\frac{\\lambda}{\\lambda - s}\n$$</div>\n\n<p>$Y$ is a standard normal RV, </p>\n<div>$$\nM_Y(s) = \\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi}}e^{-(y^2/2)}e^{sy}\\mathrm dy = e^{s^2/2}\n$$</div>\n\n<p>Consider $X &#x3D; \\sigma Y + \\mu$</p>\n<div>$$\nM_X(s) = e^{s^2\\sigma^2/2 + \\mu s}\n$$</div>\n\n<h3 id=\"Inversion-of-transforms\"><a href=\"#Inversion-of-transforms\" class=\"headerlink\" title=\"Inversion of transforms\"></a>Inversion of transforms</h3><p><strong>Inversion Property</strong></p>\n<p>The transform $M_X(s)$ associated with a RV $X$ uniquely determines the CDF of $X$, assuming that $M_X(s)$ is finite for all $s$ in some interval $[-a, a]$, where $a$ is a positive number.</p>\n<p>Example:</p>\n<div>$$\n\\begin{align*}\nM(s) &= \\frac{pe^s}{1 - (1 - p)e^s}\\\\\n&= pe^s(1 + (1-p)e^s + (1-p)^2e^{2s} + \\dotsb)\\\\\n&= \\sum_{k = 1}^\\infty p(1-p)^{k - 1}e^{ks}\n\\end{align*}\n$$</div>\n\n<p>The probability $P(X &#x3D; k)$ is found by reading the coefficient of the term $e^{ks}$:</p>\n<div>$$\nP(X = k) = p(1-p)^{k-1}\n$$</div>\n\n<h3 id=\"Transform-of-Mixture-of-Distributions\"><a href=\"#Transform-of-Mixture-of-Distributions\" class=\"headerlink\" title=\"Transform of Mixture of Distributions\"></a>Transform of Mixture of Distributions</h3><p>Let $X_1,\\dotsb, X_n$ be continuous RVs with PDFs $f_{X_1}, \\dotsb, f_{X_n}$.</p>\n<p>The value $y$ of RV $Y$ is generated as follows: an index $i$ is chosen with a corresponding probability $p_i$, and $y$ is taken to be equal to the value $X_i$. Then, </p>\n<div>$$\nf_Y(y) = p_1f_{X_1}(y) + \\dotsb + p_nf_{X_n}(y)\\\\\nM_Y(s) = p_1M_{X_1}(s) + \\dotsb + p_nM_{X_n}(s)\n$$</div>\n\n<h3 id=\"Sum-of-independend-RVs\"><a href=\"#Sum-of-independend-RVs\" class=\"headerlink\" title=\"Sum of independend RVs\"></a>Sum of independend RVs</h3><p>Let $X$ and $Y$ be independent RVs, and let $Z &#x3D; X + Y$. The transform associated with $Z$ is </p>\n<div>$$\nM_Z(s) = M_X(s)M_Y(s)\n$$</div>\n\n<p>Since</p>\n<div>$$\nM_Z(s) = E[e^{sZ}] = E[e^{s(X + Y)}] = E[e^{sX}e^{sY}] = E[e^{sX}]E[e^{sY}] = M_X(s)M_Y(s)\n$$</div>\n\n<p>Generalization:</p>\n<p>A collection of independent RVs: $X_1, \\dotsb, X_n$, $Z &#x3D; X_1 + \\dotsb + X_n$ ,</p>\n<div>$$\nM_Z(s) = M_{X_1}(s)\\dotsb M_{X_n}(s)\n$$</div>\n\n<p><strong>Example</strong></p>\n<p>Let $X_1, \\dotsb, X_n$ be independent Bernoulli RVs with a common parameter $p$:</p>\n<div>$$\nM_{X_i}(s) = 1 - p + pe^s\n$$</div>\n\n<p>$Z &#x3D; X_1 + \\dotsb + X_n$ is binomial with parameters n and p:</p>\n<div>$$\nM_z(s) = (1 - p + pe^s)^n\n$$</div>\n\n<p>Let $X$ and $Y$ be independent Poisson RVs with means $\\lambda$ and $\\mu$, and let $Z &#x3D; X + Y$. Then $Z$ is still Poisson with mean $\\lambda + \\mu$.</p>\n<div>$$\nM_Z(s) = M_X(s)M_Y(s) = e^{(\\lambda +\\mu)(e^s - 1)}\n$$</div>\n\n<p>Let $X$ and $Y$ be independent Gaussian RVs with means $\\mu_x$ and $\\mu_y$, and variances $\\sigma_x^2, \\sigma_y^2$. And let $Z &#x3D; X + Y$. Then $Z$ is still Gaussian with mean $\\mu_x + \\mu_y$ and variance $\\sigma_x^2 + \\sigma_y^2$</p>\n<div>$$\nM_X(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_x^2s^2}{2} + \\mu_x s\\bigg\\rbrace\\\\\nM_Y(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_y^2s^2}{2} + \\mu_y s\\bigg\\rbrace\\\\\nM_Z(s) = M_X(s)M_Y(s) = \\exp\\bigg\\lbrace\\frac{(\\sigma_x^2 + \\sigma_y^2)s^2}{2} + (\\mu_x + \\mu_y)s\\bigg\\rbrace\n$$</div>\n\n<p>Consider</p>\n<div>$$\nY = X_1 + \\dotsb + X_N\n$$</div>\n\n<p>where $N$ is a RV that takes integer values, and $X_1, \\dotsb, X_N$ are identically distributed RVs.</p>\n<p>Assume that $N, X_1, \\dotsb$ are independent.</p>\n<div>$$\nE[Y|N = n] = E[X_1 + X_2 + \\dotsb + X_n|N = n] = nE[X]\\\\\nE[Y|N] = NE[X]\\\\\nE[Y] = E[E[Y|N]] = E[NE[X]] = E[N]E[X]\n$$</div>\n\n<p>For the variance, </p>\n<div>$$\nE[Y|N] = NE[X]\\\\\n\\text{var}(E[Y|N]) = (E[X])^2\\text{var}(N)\\\\\n\\text{var}(Y|N=n) = n\\text{var}(X)\\\\\n\\text{var}(Y|N) = N \\text{var}(X)\\\\\nE[\\text{var}(Y|N)] = E[N]\\text{var}(X)\\\\\n$$</div>\n\n<p>So, </p>\n<div>$$\n\\text{var}(Y) = E[\\text{var}(Y|N)] + \\text{var}(E[Y|N]) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\n$$</div>\n\n<p>For transform,</p>\n<div>$$\nE[e^{sY}|N = n] = E[e^{sX_1}\\dotsb e^{sX_n}|N = n] = E[e^{sX}]^n = (M_X(s))^n\\\\\nM_Y(s) = E[e^{sY}] = E[E[e^{sY}|N]] = E[(M_X(s))^N] = \\sum_{n = 0}^\\infty (M_X(s))^n p_N(n) = \\sum_{n = 0}^\\infty e^{n\\log M_X(s)}p_N(n) = M_N(\\log M_X(s))\n$$</div>\n\n<p><strong>Summary on Properties</strong></p>\n<p>Consider the sum</p>\n<div>$$\nY = X_1 + \\dotsb + X_N\n$$</div>\n\n<p>where $N$ is a RV that takes integer values, and $X_1, X_2, \\dotsb$ are identically distributed RVs. Assume that $N$, $X_1, X_2, \\dotsb$ are independent.</p>\n<div>$$\nE[Y] = E[N]E[X]\\\\\n\\text{var}(Y) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\\\\\nM_Y(s) = M_N(\\log M_X(s))\n$$</div>\n\n<p><strong>Example</strong></p>\n<p>Assume that $N$ and $X_i$ are both geometrically distributed with parameters $p$ and $q$ respectively. All of these RVs are independent. $Y &#x3D; X_1 + \\dotsb + X_N$</p>\n<div>$$\nM_N(s) = \\frac{pe^s}{1 - (1-p)e^s}\\\\\nM_X(s) = \\frac{qe^s}{1 - (1-q)e^s}\\\\\nM_Y(s) = M_N(\\log M_X(s)) = \\frac{pqe^s}{1 - (1-pq)e^s}\n$$</div>\n\n<p>$Y$ is also geometrically distributed, with parameter $pq$.</p>\n<h2 id=\"Weak-law-of-large-numbers\"><a href=\"#Weak-law-of-large-numbers\" class=\"headerlink\" title=\"Weak law of large numbers\"></a>Weak law of large numbers</h2><h3 id=\"Markov-inequality\"><a href=\"#Markov-inequality\" class=\"headerlink\" title=\"Markov inequality\"></a>Markov inequality</h3><p>If a RV $X$ can only take nonnegative values, then</p>\n<div>$$\nP(X \\ge a) \\le \\frac{E[X]}{a}, \\text{ for all } a \\gt 0.\n$$</div>\n\n<p>Intuition: If a nonnegative RV has a small mean, then the probability that it takes a large value must be small。</p>\n<p>Fix a positive number $a$, </p>\n<div>$$\nE[X] = \\int_0^\\infty xf_X(x)dx = \\int_0^a xf_X(x)dx + \\int_a^\\infty xf_X(x)dx \\ge 0 + \\int_a^\\infty xf(x)dx \\ge \\int_a^\\infty af_X(x)dx = aP(X \\ge a)\n$$</div>\n\n<h3 id=\"Chebyshev’s-Inequality\"><a href=\"#Chebyshev’s-Inequality\" class=\"headerlink\" title=\"Chebyshev’s Inequality\"></a>Chebyshev’s Inequality</h3><p>If $X$ is a RV with mean $\\mu$ and variance $\\sigma^2$, then</p>\n<div>$$\nP(|X - \\mu| \\ge c) \\le \\frac{\\sigma^2}{c^2}\n$$</div>\n\n<p>Intuition: If a RV has small variance, then the probability that it takes a value far from its mean is also small.</p>\n<div>$$\n\\begin{align*}\n\\sigma^2 &= \\int (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} (x - \\mu)^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} c^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty c^2f_X(x)\\mathrm dx\\\\\n&= \\int_{|x - \\mu| \\ge c} c^2f_X(x)\\mathrm dx\\\\\n&=c^2P(|X - \\mu| \\ge c)\n\\end{align*}\n$$</div>\n\n<p>The upperbounds of $\\sigma^2$:</p>\n<div>$$\nX \\in [a, b]\\\\\n\\sigma^2 \\le (b - a)^2/4\n$$</div>\n\n<p><strong>Chernoff inequality</strong></p>\n<p>If a RV $X$ has MGF $M_X(s)$, then</p>\n<div>$$\nP(X \\ge a) \\le e^{-\\max_{s\\ge 0}\\left(sa - \\ln M_X(s)\\right)}\n$$</div>\n\n<p>or, for $s \\ge 0$</p>\n<div>$$\nP(X\\ge a) \\le e^{-sa}M_X(s)\n$$</div>\n\n<p>for $s \\lt 0$</p>\n<div>$$\nP(X \\le a) \\le e^{-sa}M_X(s)\n$$</div>\n\n<p>proof: for $s \\ge 0$</p>\n<div>$$\nM_X(s) = \\int_{-\\infty}^a e^{sx}f_X(x)\\mathrm dx + \\int_a^{\\infty} e^{sx}f_X(x)\\mathrm dx\\\\\n\\ge 0 + e^{sa}\\int_a^{\\infty} f_X(x)\\mathrm dx = e^{sa}P(X \\ge a)\n$$</div>\n\n<h3 id=\"Weak-law-of-large-numbers-1\"><a href=\"#Weak-law-of-large-numbers-1\" class=\"headerlink\" title=\"Weak law of large numbers\"></a>Weak law of large numbers</h3><p>Let $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$</p>\n<div>$$\nM_n = \\frac{X_1 + X_2 + \\dotsb + X_n}{n}\\\\\nE[M_n] = \\mu\\\\\n\\text{var}(M_n) = \\frac{\\sigma^2}{n}\n$$</div>\n\n<p>Applying the Chebyshev inequality and we get:</p>\n<div>$$\nP(|M_n - \\mu| \\ge \\epsilon) \\le \\frac{\\text{var}(M_n)}{\\epsilon^2} = \\frac{\\sigma^2}{n\\epsilon^2}\n$$</div>\n\n<p>For large $n$, the bulk of the distribution of $M_n$ is concentrated near $\\mu$</p>\n<p><strong>Theorem</strong></p>\n<p>Let $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$. For every $\\epsilon \\gt 0$, we have</p>\n<div>$$\nP(|M_n - \\mu| \\ge \\epsilon) = P\\left(\\left|\\frac{X_1 + \\dotsb + X_n}{n} - \\mu\\right|\\ge \\epsilon\\right) \\rightarrow 0, \\text{ as } n \\rightarrow \\infty\n$$</div>\n\n<p>$M_n$ converges <strong>in probability</strong> to $\\mu$.</p>\n<h3 id=\"Convergence-“in-Probability”\"><a href=\"#Convergence-“in-Probability”\" class=\"headerlink\" title=\"Convergence “in Probability”\"></a>Convergence “in Probability”</h3><p>Theorem: Convergence in Probability</p>\n<p>Let $\\lbrace Y_n\\rbrace$(or $Y_1, Y_2, \\dots$) be a sequence of RVs(not necessarily independent), and let $a$ be a real number. We say that the sequence $Y_n$ <strong>converges to</strong> $a$ in probability, if for every $\\epsilon \\gt 0$, we have </p>\n<div>$$\n\\lim_{n \\rightarrow \\infty} P(|Y_n - a| \\ge \\epsilon) = 0\n$$</div>\n\n<p>(almost all) of the PMF&#x2F;PDF of $Y_n$, eventually gets concentrated (arbitrarily) close to $a$.</p>\n<h3 id=\"Many-types-of-convergence\"><a href=\"#Many-types-of-convergence\" class=\"headerlink\" title=\"Many types of convergence\"></a>Many types of convergence</h3><p>Deterministic limits: $\\lim_{n\\rightarrow \\infty} a_n &#x3D; a$</p>\n<div>$$\n|a_n - a|\\le \\epsilon, \\forall n \\ge N, \\epsilon \\gt 0\n$$</div>\n\n<p>Convergence in probability: $X_n\\stackrel P{\\rightarrow} X$</p>\n<div>$$\n\\lim_{n \\rightarrow \\infty}P(|X_n - X|\\ge \\epsilon) = 0, \\forall \\epsilon \\gt 0\n$$</div>\n\n<p>(WLLN)</p>\n<p>Convergence in Distribution: $X_n \\stackrel{D}{\\rightarrow} X$</p>\n<div>$$\n\\lim_{n \\rightarrow \\infty} P(X_n \\le x) = P(X \\le x), \\forall x\n$$</div>\n\n<p>For all points of $x$ at which the function $F_X(x) &#x3D; P(X\\le x)$is continuous.</p>\n<p>(CLT)</p>\n<p>Convergence with probability $1$(almost surely): $X_n \\stackrel{\\text{a.s.}}{\\rightarrow} X$</p>\n<div>$$\nP\\left(\\lbrace\\omega\\in \\Omega: \\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\rbrace\\right) = 1\n$$</div>\n\n<p>or </p>\n<div>$$\nP\\left(\\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\right) = 1\n$$</div>\n\n<p>Lemma:</p>\n<div>$$\nX_n \\stackrel{\\text{a.s.}}{\\rightarrow} X \\Leftrightarrow \\lim_{m \\rightarrow\\infty}P(|X_n - X|\\le \\epsilon, \\forall n \\gt m) = 1, \\forall \\epsilon \\gt 0\\\\\n\\Leftrightarrow P(|X_n - X|\\gt \\epsilon, \\text{i.o.}) = 0, \\forall \\epsilon \\gt 0\n$$</div>\n\n<p>i.o. stand for infinitely often</p>\n<p>(SLLN)</p>\n<p>Convergence in Mean&#x2F;in Norm: $X_n \\stackrel{r}{\\rightarrow}X$</p>\n<p>if $E[X_n^r] \\lt \\infty$ for all $n$ and </p>\n<div>$$\n\\lim_{n \\rightarrow \\infty}E[|X_n - X|^r] = 0\n$$</div>\n\n<p>Relations:</p>\n<div>$$\n\\left(X_n\\stackrel {\\text{a.s.}}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\forall r\\ge s\\ge 1, \\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel s{\\rightarrow} X\\right)\n$$</div>\n\n<p>The converse assertions fail in general!</p>\n<p>The relation between “almost surely” and “in r-th mean” is complicated. There exist sequences which converge almost surely but<br>not in mean, and which converge in mean but not almost surely!</p>\n<h2 id=\"Central-Limit-Theorem\"><a href=\"#Central-Limit-Theorem\" class=\"headerlink\" title=\"Central Limit Theorem\"></a>Central Limit Theorem</h2><h3 id=\"Theorem\"><a href=\"#Theorem\" class=\"headerlink\" title=\"Theorem\"></a>Theorem</h3><p>Let $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$ and variance $\\sigma^2$. Let </p>\n<div>$$\nZ_n = \\frac{X_1 + X_2 + \\dotsb + X_n - n\\mu}{\\sigma\\sqrt{n}}\n$$</div>\n\n<p>Then</p>\n<div>$$\n\\lim_{n\\rightarrow \\infty}P(Z_n\\le z) = \\Phi (z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^z e^{-\\frac{x^2}{2}}\\mathrm dx\n$$</div>\n\n<p>CDF of $Z_n$ converges to normal CDF(converge in distribution)</p>\n<h3 id=\"Normal-Approximation-Based-on-the-Central-Limit-Theorem\"><a href=\"#Normal-Approximation-Based-on-the-Central-Limit-Theorem\" class=\"headerlink\" title=\"Normal Approximation Based on the Central Limit Theorem\"></a>Normal Approximation Based on the Central Limit Theorem</h3><p>Let $S_n &#x3D; X_1 + \\dotsb + X_n$, where $X_i$ are $\\text{i.i.d.}$ RVs with mean $\\mu$ and variance $\\sigma^2$. If $n$ is large, the probability $P(S_n ≤ c)$ can be approximated by<br>treating $S_n$ as if it were normal, according to the following procedure.</p>\n<ol>\n<li>Calculate the mean $n\\mu$ and the variance $n\\sigma^2$ of $S_n$</li>\n<li>Calculate the normalinzd value $z &#x3D; (c - n\\mu)&#x2F;(\\sigma\\sqrt{n})$</li>\n<li>Use the approxmation</li>\n</ol>\n<div>$$\n    P(S_n \\le c)  \\approx \\Phi(z)\n$$</div>\n\n<p>where $\\Phi(z)$ is available from the standard normal CDF.</p>\n<h3 id=\"Proof\"><a href=\"#Proof\" class=\"headerlink\" title=\"Proof\"></a>Proof</h3><p>Suppose that $X_1, X_2, \\dots$ has mean zero.</p>\n<div>$$\n\\begin{align*}\nM_{Z_n}(s) &= E[e^{sZ_n}]\\\\\n&=E\\left[\\exp\\left(\\frac{s}{\\sigma\\sqrt{n}}\\sum_{i = 1}^n X_i\\right)\\right]\\\\\n&=\\prod_{i = 1}^n E[e^{\\frac{s}{\\sigma\\sqrt{n}}X_i}]\\\\\n&=\\prod_{i = 1}^n M_{X_i}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\\\\n&=\\left(M_{X}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\right)^n\\\\\n\\end{align*}\n$$</div>\n\n<p>Suppose that the transform $M_X(s)$ has a second order Taylor series expansion around $s&#x3D;0$,</p>\n<div>$$\nM_X(s) = a + bs + cs^2 + o(s^2)\n$$</div>\n\n<p>where $a &#x3D; M_X(0) &#x3D; 1, b &#x3D; M_X’(0) &#x3D; E[X] &#x3D; 0, c &#x3D; \\frac{1}{2}M_X’’(0) &#x3D; \\frac{\\sigma^2}{2}$</p>\n<p>Then</p>\n<div>$$\nM_{Z_n}(s) = \\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n\n$$</div>\n\n<p>As $n\\rightarrow \\infty$, </p>\n<div>$$\n\\lim_{n\\rightarrow \\infty}M_{Z_n}(s) = \\lim_{n\\rightarrow \\infty}\\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n = e^{\\frac{s^2}{2}}\n$$</div>\n\n<p>Approxmation on binomial:</p>\n<p>(De Moivre-Laplace Approxmation to the Binomial)</p>\n<div>$$\nP(k \\le S_n \\le l) = P\\left(\\frac{k - np}{\\sqrt{np(1-p)}} \\le \\frac{S_n - np}{\\sqrt{np(1 - p)}} \\le \\frac{l - np}{\\sqrt{np(1 - p)}}\\right)\\\\\n\\approx \\Phi\\left(\\frac{l - np}{\\sqrt{np(1 - p)}}\\right) - \\Phi\\left(\\frac{k - np}{\\sqrt{np(1 - p)}}\\right)\n$$</div>\n\n<h2 id=\"The-Strong-Law-of-Large-Numbers\"><a href=\"#The-Strong-Law-of-Large-Numbers\" class=\"headerlink\" title=\"The Strong Law of Large Numbers\"></a>The Strong Law of Large Numbers</h2><h3 id=\"Theorem-1\"><a href=\"#Theorem-1\" class=\"headerlink\" title=\"Theorem\"></a>Theorem</h3><p>Let $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$.</p>\n<div>$$\nP(\\lim_{n \\rightarrow\\infty}\\frac{X_1 + \\dots + X_n}{n} = \\mu) = 1.\n$$</div>\n\n<h2 id=\"Borel-Cantelli-lemma-amp-Bernoulli-Process\"><a href=\"#Borel-Cantelli-lemma-amp-Bernoulli-Process\" class=\"headerlink\" title=\"Borel-Cantelli lemma &amp; Bernoulli Process\"></a>Borel-Cantelli lemma &amp; Bernoulli Process</h2><h3 id=\"Limit-of-set-sequence\"><a href=\"#Limit-of-set-sequence\" class=\"headerlink\" title=\"Limit of set sequence\"></a>Limit of set sequence</h3><div>$$\n\\limsup_n A_n = \\bigcap_{n = 1}^\\infty \\bigcup_{k = n}^\\infty A_k\\\\\n\\liminf_n A_n = \\bigcup_{n = 1}^\\infty \\bigcap_{k = n}^\\infty A_k\n$$</div>\n\n<p>If upper limit equals to lower limit, the limit of set sequence exists.</p>\n<div>$$\n\\limsup_n A_n \\supseteq \\liminf_n A_n\\\\\n\\limsup_n A_n = \\liminf_n A_n = \\lim_n A_n\n$$</div>\n\n<p>Upper limit can also be denoted as</p>\n<div>$$\n\\limsup_n A_n = \\{\\omega: \\omega \\in A_n, \\text{i.o.}\\} = \\lbrace A_n, \\text{i.o.}\\rbrace\n$$</div>\n\n<h3 id=\"Borel-Cantelli-Lemma\"><a href=\"#Borel-Cantelli-Lemma\" class=\"headerlink\" title=\"Borel-Cantelli Lemma\"></a>Borel-Cantelli Lemma</h3><p>Let $\\lbrace A_n, n &#x3D; 1, 2, \\dotsb\\rbrace$ be a sequence of events, then</p>\n<div>$$\n\\sum_{n = 1}^\\infty P(A_n)\\lt \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 0\n$$</div>\n\n<p>Let $\\lbrace A_n, n &#x3D; 1, 2, \\dotsb\\rbrace$ be a sequence of <strong>independent</strong> events, then</p>\n<div>$$\n\\sum_{n = 1}^\\infty P(A_n) = \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 1\n$$</div>\n\n<h3 id=\"Stochastic-process\"><a href=\"#Stochastic-process\" class=\"headerlink\" title=\"Stochastic process\"></a>Stochastic process</h3><p>A stochastic process is a mathematical model of a probabilistic experiment that evolves in time and generates a sequence of<br>numerical values.</p>\n<ul>\n<li>Bernoulli process(memoryless, discrete time)</li>\n<li>Poisson process(memoryless, continuous time)</li>\n</ul>\n<h3 id=\"The-Bernoulli-Process\"><a href=\"#The-Bernoulli-Process\" class=\"headerlink\" title=\"The Bernoulli Process\"></a><strong>The Bernoulli Process</strong></h3><p>is a sequence of independent Bernoulli trials, each with probability of success $p$.</p>\n<div>$$\nP(\\text{success}) = P(X_i = 1) = p\\\\\nP(\\text{failure}) = P(X_i = 0) = 1 - p\n$$</div>\n\n<p><strong>Independence property</strong>: For any given time $n$, the sequence of $X_{n + 1}, X_{n + 2}, \\dots$ is also a Bernoulli process, and is independent from $X_1, \\dots, X_n$</p>\n<p><strong>Memoryless property</strong>: Let $n$ be a given time and let $\\overline T$ be the time of the first success after<br>time $n$. Then $\\overline T − n$ has a geometric distribution with parameter $p$,<br>and is independent of the RVs $X_1, \\dots , X_n$.</p>\n<div>$$\nP(\\overline T - n = t | \\overline T \\gt n) = (1 - p)^{t - 1}p = P(T = t)\n$$</div>\n\n<p><strong>Interarrival times</strong></p>\n<p>Denote the $k$th success as $Y_k$, the $k$th interarrival time as $T_k$.</p>\n<div>$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$</div>\n\n<p>represents the number of trials following the $(k - 1)$th success until the next success.</p>\n<p>Note that</p>\n<div>$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$</div>\n\n<p>Alternative description of the Bernoulli process: </p>\n<ul>\n<li>Start with a sequence of independent geometric RVs $T_1, T_2, \\dots$ with common parameter p, and let these stand for the interarrival times.</li>\n<li>Record a success at times $T_1$, $T_1 + T_2$, etc.</li>\n</ul>\n<div>$$\nE[Y_k] = \\frac{k}{p}\\\\\n\\text{var}(Y_k) = \\frac{k(1 - p)}{p^2}\n$$</div>\n\n<div>$$\np_{Y_k}(t) = \\binom{t - 1}{k - 1}p^k(1 - p)^{t - k}\n$$</div>\n\n<p><strong>Splitting of a Bernoulli process</strong></p>\n<p>Whenever there is an arrival, we choose to either keep it (with probability $q$), or to discard it (with probability $1 − q$).</p>\n<p>Both the process of arrivals that are kept and the process of discarded arrivals are Bernoulli processes, with success probability $pq$ and $p(1 − q)$, respectively, at each time.</p>\n<p><strong>Merging of a Bernoulli process</strong></p>\n<p>In a reverse situation, we start with two independent Bernoulli processes (with parameters $p$ and $q$ respectively). An arrival is<br>recorded in the merged process if and only if there is an arrival in at least one of the two original processes.</p>\n<p>The merged process is Bernoulli, with success probability $p+q−pq$ at each time step.</p>\n<h2 id=\"The-Poisson-Process\"><a href=\"#The-Poisson-Process\" class=\"headerlink\" title=\"The Poisson Process\"></a>The Poisson Process</h2><h3 id=\"Definition-1\"><a href=\"#Definition-1\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><p>An arrival process is called a Poisson process with rate $λ$ if it has the following properties:</p>\n<p><strong>Time homogenity</strong></p>\n<div>$$\nP(k, \\tau) = P(k \\text{ arrivals in interval of duration }\\tau)\n$$</div>\n\n<p><strong>Independence</strong></p>\n<p>Numbers of arrivals in disjoint time intervals are independent.</p>\n<p><strong>Small interval probabilities</strong></p>\n<div>$$\n\\begin{cases}\n    1 - \\lambda\\tau + o(\\tau), & \\text{if } k = 0,\\\\\n    \\lambda\\tau + o_1(\\tau), & \\text{if } k = 1,\\\\\n    o_k(\\tau), & \\text{if } k > 1.\n\\end{cases}\n$$</div>\n\n<h3 id=\"Bernoulli-x2F-Poisson-Relation\"><a href=\"#Bernoulli-x2F-Poisson-Relation\" class=\"headerlink\" title=\"Bernoulli&#x2F;Poisson Relation\"></a>Bernoulli&#x2F;Poisson Relation</h3><p>In a short time interval $\\delta$</p>\n<div>$$\nn = t / \\delta\\\\\np = \\lambda\\delta\\\\\nnp = \\lambda t\n$$</div>\n\n<p>For binomial PMF $p_S(k;n,p)$,</p>\n<div>$$\n\\lim_{n\\rightarrow \\infty}p_S(k;n, p) = \\lim_{n\\rightarrow\\infty}\\frac{n!}{(n - k)!k!}p^k(1 - p)^{n - k} = \\frac{(\\lambda t)^k}{k!}e^{-\\lambda t} = P(k, t)\n$$</div>\n\n<h3 id=\"PMF-of-Number-of-Arrivals-N\"><a href=\"#PMF-of-Number-of-Arrivals-N\" class=\"headerlink\" title=\"PMF of Number of Arrivals $N$\"></a>PMF of Number of Arrivals $N$</h3><div>$$\nP(k, \\tau) = \\frac{(\\lambda\\tau)^ke^{-\\lambda\\tau}}{k!}\n$$</div>\n\n<div>$$\nE[N_t] = \\lambda t\\\\\n\\text{var}(N_t) = \\lambda t\n$$</div>\n\n<h3 id=\"Time-T-of-the-first-arrival\"><a href=\"#Time-T-of-the-first-arrival\" class=\"headerlink\" title=\"Time $T$ of the first arrival\"></a>Time $T$ of the first arrival</h3><div>$$\nF_T(t) = P(T \\le t) = 1 - P(T \\gt t) = 1 - e^{-\\lambda t}, t\\ge 0\\\\\nf_T(t) = \\lambda e^{-\\lambda t}, t\\ge 0\n$$</div>\n\n<p><strong>Memoryless property</strong> The  time to next arrival is independent of the past.</p>\n<h3 id=\"Interarrival-times\"><a href=\"#Interarrival-times\" class=\"headerlink\" title=\"Interarrival times\"></a>Interarrival times</h3><p>We also denote the time of the kth success as $Y_k$, and denote the<br>kth interarrival time as $T_k$. That is,</p>\n<div>$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$</div>\n\n<p>Note that</p>\n<div>$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$</div>\n\n<div>$$\nf_{Y_k}(y) = \\frac{\\lambda^ky^{k-1}e^{-\\lambda y}}{(k - 1)!}, y\\ge 0\n$$</div>\n\n<h3 id=\"Merging-Poisson-Processes\"><a href=\"#Merging-Poisson-Processes\" class=\"headerlink\" title=\"Merging Poisson Processes\"></a>Merging Poisson Processes</h3><p><img src=\"/../images/prob/L14_1.jpg\" loading=\"lazy\"></p>\n<div>$$\nP(\\text{Arrival is red} | \\text{1 arrival})\\approx \\frac{\\lambda_1\\delta}{(\\lambda_1 + \\lambda_2) \\delta}\n$$</div>\n\n<p><img src=\"/../images/prob/L15_1.jpg\" loading=\"lazy\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h2 id=\"Probability-Space\"><a href=\"#Probability-Space\" class=\"headerlink\" title=\"Probability Space\"></a>Probability Space</h2><p>Probability space is a triple $(\\Omega, \\mathcal{F}, \\mathbf{P})$, comprised of the following three<br>elements:</p>\n<p>1 Sample space $\\Omega$: the set of all possible outcomes of an experiment</p>\n<p>2 $\\sigma$-algebra (or $\\sigma$-field) $\\mathcal F$: a collection of subsets of $\\Omega$</p>\n<p>3 Probability measure $\\mathbf P$: a function that assigns a nonnegative<br>probability to every set in the $\\sigma$-algebra $\\mathcal F$</p>\n<h3 id=\"Sample-space\"><a href=\"#Sample-space\" class=\"headerlink\" title=\"Sample space\"></a>Sample space</h3><p>Mutually exclusive: no identical element.</p>\n<p>Collectively exhaustive: all results should be included.</p>\n<h3 id=\"sigma-algegra\"><a href=\"#sigma-algegra\" class=\"headerlink\" title=\"$\\sigma$-algegra\"></a>$\\sigma$-algegra</h3><p>not unique</p>\n<p>3 requirements:</p>\n<div>$$\n\\varnothing \\in \\mathcal F\\\\\n\\forall A \\in \\mathcal F, A^c \\in \\mathcal F\\\\\n\\forall A_k \\in \\mathcal F, k=1, 2, ..., \n\\cup_{k=1}^{\\infty}A_k\\in \\mathcal F\n$$</div>\n\n<h3 id=\"Borel-field\"><a href=\"#Borel-field\" class=\"headerlink\" title=\"Borel field\"></a>Borel field</h3><p>used to measure intervals</p>\n<p>when $\\Omega$ is continuous($\\R$ for example), Borel field is useful.</p>\n<p>“minimum” $\\sigma$-algebra means deleting any element in the $\\mathcal B (\\mathbf R)$ will miss the requirements.</p>\n<p><img src=\"/../images/prob/L2_1.jpg\"></p>\n<h3 id=\"Uncountable\"><a href=\"#Uncountable\" class=\"headerlink\" title=\"Uncountable\"></a>Uncountable</h3><p>decimal numbers between 0 and 1 are uncountable.</p>\n<h3 id=\"Probability-measures\"><a href=\"#Probability-measures\" class=\"headerlink\" title=\"Probability measures\"></a>Probability measures</h3><div>$$\nP:\\mathcal F \\rightarrow [0, 1]\n$$</div>\n\n<p><strong>Nonnegativity</strong> $P(A)\\ge0, \\forall A \\in \\mathcal{  F}$</p>\n<p><strong>Normalization</strong>  $P(\\empty)&#x3D;0, P(\\Omega)&#x3D;1$</p>\n<p><strong>Countable additivity</strong> $A_1, A_2, … \\text { is disjoint in }\\mathcal F, P(A_1\\cup A_2\\cup …)&#x3D;P(A_1)+P(A_2)+…$</p>\n<ul>\n<li>They are the axioms of probability. </li>\n<li>Probability is a mapping from $\\sigma$-algebra to a real number betwenn 0 and 1, which intuitively specifies the “likelihood” of any event. </li>\n<li>There exist non-measurable sets, on which we cannot define a probability measure.</li>\n</ul>\n<h3 id=\"Discrete-models\"><a href=\"#Discrete-models\" class=\"headerlink\" title=\"Discrete models\"></a>Discrete models</h3><div>$$\nP(\\{s_1, ..., s_n\\})=P(s_1)+...+P(s_n)\\\\\nP(A) = \\frac{\\text{\\# of elements of }A}{\\text{total \\# of elements of sample points}}\n$$</div>\n\n\n<h3 id=\"Continuous-Models\"><a href=\"#Continuous-Models\" class=\"headerlink\" title=\"Continuous Models\"></a>Continuous Models</h3><p>Probability &#x3D; Area</p>\n<h3 id=\"Some-properties-of-Probability-measure\"><a href=\"#Some-properties-of-Probability-measure\" class=\"headerlink\" title=\"Some properties of Probability measure\"></a>Some properties of Probability measure</h3><div>$$\nA\\sub B\\Rightarrow P(A)\\le P(B)\\\\\nP(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\\\\nP(A\\cup B) \\le P(A) + P(B)\\\\\nP(A\\cup B \\cup C)=P(A) + P(A^C\\cap B) + P(A^C\\cap B^C\\cap C)\n$$</div>\n\n<h3 id=\"Conditional-Probability\"><a href=\"#Conditional-Probability\" class=\"headerlink\" title=\"Conditional Probability\"></a>Conditional Probability</h3><div>$$\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}\n$$</div>\n\n<ul>\n<li>If $P(B)&#x3D;0$, $P(A|B)$ is undefined.</li>\n<li>For a fixed event $B$, $P(A|B)$ can be verified as a legitimate probability measure on the new universe. $P(A, B)\\ge 0$, $P(\\Omega|B)&#x3D;1$, $P(A_1\\cup A_2\\cup…|B)&#x3D;P(A_1|B)+P(A_2|B)+…$</li>\n<li><div>$P(A|B)=\\frac{\\text{ \\# of elements of }A\\cap B}{\\text{total \\# of elements of }B}$</div></li>\n</ul>\n<h3 id=\"Total-probability-theorem\"><a href=\"#Total-probability-theorem\" class=\"headerlink\" title=\"Total probability theorem\"></a>Total probability theorem</h3><p>Let $A_1, …, A_n$ be disjoint events that form a partition of the sample space and assume that $P(A_i)&gt;0$ for all $i$. Then for any event B, we have</p>\n<div>$$\nP(B) = \\sum_{i=1}^n P(A_i\\cap B) = \\sum_{i=1}^nP(A_i)P(B|A_i)\n$$</div>\n\n<p><strong>Remark</strong> </p>\n<ul>\n<li>The definition of partition is that $\\cup_{i&#x3D;1}^n A_i &#x3D; \\Omega, A_i\\cap A_j &#x3D; \\emptyset, \\forall i\\ne j$</li>\n<li>The probability of B is a weighted average of its conditional probability under each scenario</li>\n<li>Each scenario is weighted according to its prior probability</li>\n<li>Useful when $P(B|A_i)$ is known or easy to derive</li>\n</ul>\n<h3 id=\"Inference-and-Bayes’-rule\"><a href=\"#Inference-and-Bayes’-rule\" class=\"headerlink\" title=\"Inference and Bayes’ rule\"></a>Inference and Bayes’ rule</h3><p>Let $A_1, …, A_2$ be disjoint events that from a partition of the sample space and assume that $P(A_i) \\gt 0$  for all $i$. Then for any event $B$ such that $P(B)\\gt 0$, we have </p>\n<div>$$\nP(A_i|B) = \\frac{P(A_i)P(B|A_i)}{P(B)} = \\frac{P(A_i)P(B|A_i)}{\\sum_{j=1}^nP(A_j)P(B|A_j)}\n$$</div>\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>Relates conditional probabilities of the form $P(A_i|B)$ with conditional probabilities of the form $P(B|A_i)$</li>\n<li>often used in inference: effect $B$ $\\lrarr$ cause $A_i$</li>\n</ul>\n<p>The meaning of $P(A_i|B)$ in the view of Bayes: the belief of $A_i$ is revised if we observed effect $B$. If the cause and the effect are closely binded($P(B|A_i) &gt; P(B|A_i^c)$), then the belief $A_i$ is enhanced by the observation of effect $B$($P(A_i|B) &gt; P(A)$). This can be derived from the Bayes’ rule through simple calculation. If $P(A_i|B)&#x3D;P(A_i)$, then $B$ provides no information on $A_i$.</p>\n<h3 id=\"Independence\"><a href=\"#Independence\" class=\"headerlink\" title=\"Independence\"></a>Independence</h3><h4 id=\"Independence-of-two-disjoint-events\"><a href=\"#Independence-of-two-disjoint-events\" class=\"headerlink\" title=\"Independence of two disjoint events\"></a>Independence of two disjoint events</h4><p>Events A and B are called <strong>independent</strong> if </p>\n<div>$$\nP(A\\cap B) = P(A)\\cdot P(B)\n$$</div>\nor equivalently, when $P(B) > 0$, \n\n<div>$$\nP(A|B) = P(A)\n$$</div>\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>Occurrence of B provides no information about A’s occurrence</li>\n<li>Equivalence due to $P(A\\cap B) &#x3D; P(B)\\cdot P(A|B)$</li>\n<li>Symmetric with respect to $A$ and $B$.</li>\n<li><ul>\n<li>applies even if $P(B) &#x3D; 0$</li>\n</ul>\n</li>\n<li><ul>\n<li>implies $P(B|A) &#x3D; P(B)$ and $P(A|B^c) &#x3D; P(A)$</li>\n</ul>\n</li>\n<li>Does not imply that A and B are disjoint, indeed opposite!</li>\n<li><ul>\n<li>Two disjoint events are never independent!($P(A\\cap B) &#x3D; 0$, but $P(A)\\cdot P(B)\\ne 0$)</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Conditional-independence\"><a href=\"#Conditional-independence\" class=\"headerlink\" title=\"Conditional independence\"></a>Conditional independence</h4><div>$$\nP(A\\cap B | C) = P(A| C) \\cdot P(B|C)\n$$</div>\n\n<p><strong>Definition</strong></p>\n<p>Event $A_1, A_2, …, A_n$ are called independent if: </p>\n<div>$$\nP(A_i\\cap A_j\\cap ...\\cap A_q) = P(A_1)P(A_j)...P(A_q)\n$$</div>\n\n<p>for any distinct indices $i, j, \\dots q$ chosen from ${1, \\dots n}$.</p>\n<p>Pairwise is independence does not imply independence.</p>\n<h2 id=\"Discrete-Random-Variables\"><a href=\"#Discrete-Random-Variables\" class=\"headerlink\" title=\"Discrete Random Variables\"></a>Discrete Random Variables</h2><p>Random Variable is neither random, nor variable.</p>\n<h3 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><p>We care about the probability that $X \\le x$ instead $X &#x3D; x$ in the consideration of generality. </p>\n<p><strong>Random variables</strong></p>\n<p>Given a probability space $(\\Omega, F, P)$, a random variable is a function $X: \\Omega \\rightarrow \\R$ with the probability that ${\\omega \\in \\Omega: X(\\omega) \\le x} \\in \\mathcal F$ for each $x\\in \\R$. Such a function $X$ is said to be $\\mathcal F$-measurable.</p>\n<p><strong>Probability Mass Function(PMF)</strong></p>\n<div>$$\np_X(x)=P(X=x)=P(\\{\\omega \\in \\Omega \\text{ s.t. } X(\\omega)=x\\})\n$$</div>\n\n<p>Bonulli PMF: </p>\n<div>$$ \np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\n$$</div>\n\n<p>Binomial PMF: $p_X(k)&#x3D;\\binom{n}{k}p^k(1-p)^{n-k}$</p>\n<p>Geometric PMF: $p_X(k)&#x3D;(1-p)^{k-1}p$</p>\n<p>Poisson PMF: $p_X(k)&#x3D;e^{-\\lambda}\\frac{\\lambda^k}{k!}$. Note: $\\sum_{k&#x3D;0}^\\infty e^{-\\lambda}\\frac{\\lambda^k}{k!}&#x3D;e^{-\\lambda}e^\\lambda&#x3D;1$</p>\n<p>If $y&#x3D;g(x)$, $p_Y(y)&#x3D;\\sum_{\\lbrace x|g(x)&#x3D;y \\rbrace} p(x)$.</p>\n<h3 id=\"Expectation-and-Variance\"><a href=\"#Expectation-and-Variance\" class=\"headerlink\" title=\"Expectation and Variance\"></a>Expectation and Variance</h3><p><strong>Expectation</strong></p>\n<div>$$\nE[X] = \\sum_x xp_X(x)\n$$</div>\n\n<p>Note: we assume that the sum converges.</p>\n<p>Properties:</p>\n<div>$$\nE[Y]=\\sum_x g(x)p_X(x)\\\\\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\n$$</div>\n\n<p><strong>Variance</strong></p>\n<div>$$\n\\text{var}(X) = E \\left[(X-E[X])^2\\right]=\\sum_x (x-E[X])^2 p_X(x)\n$$</div>\n\n<p>Standard deviation: $\\sigma_X&#x3D;\\sqrt{\\text{var}(X)}$</p>\n<p>Properties: </p>\n<div>$$\n\\text{var}(X) = E[X^2] -(E[X])^2\\\\\n\\text{var}(X)\\ge 0\\\\\n\\text{var}(\\alpha X + \\beta) = \\alpha^2\\text{var} (X)\n$$</div>\n\n<p><strong>Bernoulli RV</strong></p>\n<div>$$\np_X(k) = \\begin{cases}\n    p, &\\text{if } k = 1\\\\\n    1-p, &\\text{if }k=0\n\\end{cases}\\\\\nE[X] = p\\\\\nE[X^2] = p\\\\\n\\text{var}(X) = p(1-p)\n$$</div>\n\n<p><strong>Discrete Uniform RV</strong></p>\n<div>$$\np_X(k) = \\begin{cases}\n    \\frac {1}{b-a+1}, &\\text{if } k = a, a+1, ..., b\\\\\n    0, &\\text{otherwise}\n\\end{cases}\\\\\nE[X] = \\frac{a+b}{2}\\\\\n\\text{var}(X) = \\frac{(b-a)(b-a+2)}{12}\n$$</div>\n\n<p><strong>Poisson RV</strong></p>\n<div>$$\np_X(k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\\nE[X] = \\lambda\\\\\n\\text{var}(X)=\\lambda\n$$</div>\n\n<h3 id=\"Conditional\"><a href=\"#Conditional\" class=\"headerlink\" title=\"Conditional\"></a>Conditional</h3><div>$$\np_{X|A(x)} = P(X=x|A) = \\frac{P(\\{X=x\\}\\cap A)}{P(A)}\n$$</div>\n\n<div>$$\n\\sum_x p_{X|A}(x) = 1\n$$</div>\n\n<div>$$\nE[X|Y=y] = \\sum_x xp_{X|Y}(x|y)\\\\\nE[g(X)|Y=y] = \\sum_x g(x)p_{X|Y}(x|y)\n$$</div>\n\n<p><strong>Total expectation theorem</strong></p>\n<p>$A_1, \\dots, A_n$ is a partition of sample space</p>\n<div>$$\nP(B) = P(A_1)P(B|A_1) + \\dotsb + P(A_n)P(B|A_n)\\\\\np_X(x) = P(A_1)p_{X|A_1}(x) + \\dotsb + P(A_n)p_{X|A_n}(x)\\\\\nE[X] = P(A_1)E[X|A_1] + \\dotsb + P(A_n)E[X|A_n]\n$$</div>\n\n<p>We derive the expectation and variance use the theories above.</p>\n<p><strong>Geometric PMF example</strong></p>\n<div>$$\np_X(k) = (1-p)^{k-1}p, k = 1, 2, \\dots\\\\\nE[X] = \\sum_{k=1}^\\infty kp_X(k) = \\sum_{k=1}^\\infty k(1-p)^{k-1}p\\\\\nE[X^2] = \\sum_{k=1}^\\infty k^2p_X(k) = \\sum_{k=1}^\\infty k^2(1-p)^{k-1}p\\\\\n\\text {var}(X) = E[X^2] - (E[X])^2\n$$</div>\n\n<p>However, the Geometric has a memoryless property.</p>\n<div>$$\np_{X|X>1}(k) = \\frac{P(\\{X>1\\}\\cap \\{X=k\\})}{P(X>1)} = \\frac{(1-p)^{k-1}p}{1-p} = (1-p)^{k-2}p\n$$</div>\n\n<p>Thus, </p>\n<div>$$\nE[X] = P(X=1)E[X|X=1] + P(X>1)E[X|X>1]=p+(1-p)(E[1 + X])\\\\\n\\Rightarrow E[X] = 1/p\\\\\nE[X^2] = P(X=1)E[X^2|X=1] + P(X>1)E[X^2|X>1] = p + (1-p)E[(1+X)^2]=p + (1-p)(1+2E[X]+E[X^2])\\\\\n\\Rightarrow E[X^2] = \\frac{2-p}{p^2}\\\\\n\\Rightarrow\\text{var} (X) = \\frac{1-p}{p^2}\n$$</div>\n\n<h3 id=\"Multiple-discrete-random-variables\"><a href=\"#Multiple-discrete-random-variables\" class=\"headerlink\" title=\"Multiple discrete random variables\"></a>Multiple discrete random variables</h3><p><strong>Joint PMFs</strong></p>\n<div>$$\np_{X, Y}(x, y) = P(X = x, Y= y) = P(\\{X(\\omega) = x\\}\\cap \\{Y(\\omega) = y\\})\n$$</div>\n\n<div>$$\n\\sum_x\\sum_y p_{X, Y}(x, y) = 1\n$$</div>\n\n<p><strong>Marginal PMF</strong></p>\n<div>$$\np_X(x) = \\sum_y P(X=x, Y=y) = \\sum_y p_{X, Y}(x, y)\n$$</div>\n\n<p><strong>Conditional PMF</strong></p>\n<div>$$\np_{X|Y}(x|y) = P(X = x | Y = y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$</div>\n\n<div>$$\n\\sum_x p_{X|Y}(x|y) = 1\n$$</div>\n\n<p><strong>Funcitons of multiple RVs</strong></p>\n<div>$$\nZ = g(X, Y)\\\\\np_Z(z) = \\sum_{\\lbrace (x, y)|g(x, y)=z \\rbrace  } p_{X, Y}(x, y)\n$$</div>\n\n<p><strong>Expectations</strong></p>\n<div>$$\nE[g(X, Y)] = \\sum_x\\sum_y g(x, y)p(X, Y)(x, y)\\\\\nE[g(X, Y, Z)] = \\sum_x\\sum_y\\sum_z g(x, y, z)p(X, Y, Z)(x, y, z)\n$$</div>\n\n<div>$$\nE[g(X,  Y)] \\not\\equiv g(E[X], E[Y])\n$$</div>\n\n<p><strong>linearity</strong></p>\n<div>$$\nE[\\alpha X + \\beta] = \\alpha E[X] + \\beta\\\\\nE[X + Y + Z] = E[X] + E[Y] + E[Z]\n$$</div>\n\n<p>Let’s calculate the Mean of Binominal RV.</p>\n<div>$$\nX_i=\n\\begin{cases}\n    1, &\\text{if success in trial } i,\\\\\n    0, & \\text{otherwise.}\n\\end{cases}\\\\\nX = X_1 + X_2 + \\dotsb X_n\\\\\nE[X] = \\sum_{i = 1}^n E[X_i] = np\\\\\n\\text{var}(X) = np(1-p)\n$$</div>\n\n<h3 id=\"Independence-1\"><a href=\"#Independence-1\" class=\"headerlink\" title=\"Independence\"></a>Independence</h3><p><strong>Independence</strong></p>\n<div>$$\np_{X, Y}(x, y) = p_X(x) \\cdot p_Y(y)\n$$</div>\n\n<p>if $X$ and $Y$ are independent:</p>\n<div>$$\nE[XY] = E[X]E[Y]\\\\\nE[g(X)h(Y)] = E[g(X)]E[h(Y)]\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\n$$</div>\n\n<p><strong>Conditional independence</strong></p>\n<div>$$\np_{X, Y|A}(X, Y) = p_{X|A}(x) \\cdot p_{Y|A}(y)\n$$</div>\n\n<h2 id=\"Continuous-Random-Variables\"><a href=\"#Continuous-Random-Variables\" class=\"headerlink\" title=\"Continuous Random Variables\"></a>Continuous Random Variables</h2><h3 id=\"Probability-Density-Function\"><a href=\"#Probability-Density-Function\" class=\"headerlink\" title=\"Probability Density Function\"></a>Probability Density Function</h3><ul>\n<li>$f_X(x)\\ge 0\\text{ for all }x$</li>\n<li>$\\int_{-\\infty}^\\infty f_X(x)\\mathrm dx &#x3D; 1$</li>\n<li>If $\\delta$ is very small, then $P([x, x+\\delta])\\approx f_X(x) \\cdot \\delta$</li>\n<li>For any subset $B$ of the real line, $P(X\\in B) &#x3D; \\int_B f_X(x)\\mathrm d x$.</li>\n</ul>\n<p><strong>Expectation</strong></p>\n<div>$$\nE[X] = \\int_{-\\infty}^\\infty xf_X(x)\\mathrm dx\\\\\nE[g(x)] = \\int_{-\\infty}^\\infty g(x)f_X(x)\\mathrm dx\n$$</div>\n\n<p>Assuming that the integration is well-defined. The Cauchy distribution ($\\frac{1}{1+x^2}$)doesn’t have expectation since $\\frac{x}{1+x^2}$ is not absolutely integrably.</p>\n<p><strong>Variance</strong></p>\n<div>$$\n\\text{var}(X) = E[(X - E[X])^2] = \\int_{-\\infty}^\\infty(x - E[x])^2 f_X(x)\\mathrm dx\\\\\n0\\le \\text{var}(x) = E[X^2] - (E[X])^2\n$$</div>\n\n<p><strong>Uniform RV</strong></p>\n<div>$$\nf_X(x) = \\begin{cases}\n    \\frac{1}{b-a}, &\\text{if }a\\le x\\le b,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<div>$$\nE[X] = \\frac{a+b}{2}\\\\\nE[X^2] = \\frac{a^2+b^2 + ab}{3}\\\\\n\\text{var}(X) = \\frac{(b-a)^2}{12}\n$$</div>\n\n\n<p>Properties:</p>\n<div>$$\nE[aX+b] = aE[X] + b\\\\\n\\text{var}(aX+b) = a^2\\text{var}(X)\n$$</div>\n\n<h3 id=\"Common-Example-for-PDF\"><a href=\"#Common-Example-for-PDF\" class=\"headerlink\" title=\"Common Example for PDF\"></a>Common Example for PDF</h3><p><strong>Exponential Random Variable</strong></p>\n<div>$$\nf_X(x) = \\begin{cases}\n    \\lambda e^{-\\lambda x}, &\\text{if }x \\ge 0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<div>$$\nP(X\\ge a) = e^{-\\lambda a}\\\\\nE[X] = \\frac{1}{\\lambda}\\\\\n\\text{var}(X) = \\frac{1}{\\lambda^2}\n$$</div>\n\n<h3 id=\"Cumulative-Distribution-Functions\"><a href=\"#Cumulative-Distribution-Functions\" class=\"headerlink\" title=\"Cumulative Distribution Functions\"></a>Cumulative Distribution Functions</h3><div>$$\nF_X(x) = P(X\\le x) = \\begin{cases}\n    \\sum_{k\\le x}p_X(k), &\\text{if } X \\text{ is discrete,}\\\\\n    \\int_{-\\infty}^x f_X(t)\\mathrm dt, &\\text{if } X \\text{ is continuous.}\n\\end{cases}\n$$</div>\n\n<p><strong>Properties</strong></p>\n<div>$$\n\\text{if } x \\le y, \\text{then } F_X(x)\\le F_X(y).\\\\\nF_X(x)\\text{ tends to 0 as } x \\rightarrow -\\infty, \\text{and to 1 as} x \\rightarrow \\infty\\\\\n\\text{If } X \\text{ is discrete, then } F_X(x) \\text{ is a piecewise constant function of }x.\\\\\n\\text{If } X \\text{ is continuous, then } F_X(x) \\text{is a continuous funciton of }x.\\\\\n\\text{If } X \\text{ is discrete and takes integer values, the PMF and the CDF can be obtained from each other by summing or differcing: }\\\\\nF_X(k) = \\sum_{i = -\\infty}^k p_X(i),\\\\\np_X(k) = P(X\\le k) - P(X \\le k -1) = F_X(k) - F_X(k - 1),\\\\\n\\text{ for all integers }k.\\\\\n\\text{If } X \\text{ is continuous, the PDF and the CDF can be obtained from each other by integration or differentiation: }\\\\\nF_X(x) = \\int_{-\\infty}^x f_X(t)\\mathrm dt, f_X(x) = \\frac{\\mathrm dF_X}{\\mathrm dx}(x)\n$$</div>\n\n<h3 id=\"Examples-for-CDF\"><a href=\"#Examples-for-CDF\" class=\"headerlink\" title=\"Examples for CDF\"></a>Examples for CDF</h3><p><strong>Geometric CDF</strong></p>\n<div>$$\nF_{\\text{geo}}(n) = \\sum_{k = 1}^n p(1-p)^{k-1} = 1-(1-p)^n, \\text{for } n = 1, 2, \\dots\n$$</div>\n\n<p><strong>Exponential CDF</strong></p>\n<div>$$\nF_{\\text{exp}}(x) = P(X\\le x) = 0, \\text{ for } x\\le0,\\\\\nF_{\\text{exp}}(x) = \\int_{0}^x \\lambda e^{-\\lambda t}\\mathrm dt = 1 - e^{-\\lambda x}, \\text{for }x\\ge 0.\n$$</div>\n\n<p>Exponential Distribution is Memoriless, like Geometric: </p>\n<div>$$\nP(X \\ge c + x| X \\ge c) = e^{-\\lambda x} = P(X \\ge x)\\\\\n$$</div>\n\n<p>The relationship: </p>\n<p><img src=\"/../images/prob/L6_1.jpg\"></p>\n<h3 id=\"Normal-Random-Variables\"><a href=\"#Normal-Random-Variables\" class=\"headerlink\" title=\"Normal Random Variables\"></a>Normal Random Variables</h3><div>$$\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-(x-\\mu)^2/2\\sigma^2}\\\\\nE[X] =\\mu\\\\\n\\text{var}(X) = \\sigma^2\n$$</div>\n\n<p>Gaussian is good, since adding two Gaussian functions resulting in a new Gaussian functions. And with a huge mount of samples, the distribution is close to Gaussian(Central limit theorem).</p>\n<p><strong>The Standard Normal Random Variable</strong></p>\n<p>Normal(Gaussian)</p>\n<div>$$\nY = \\frac{X - \\mu}{\\sigma}\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}}e^{-y^2/2}\\\\\nE[Y] = 0\\\\\n\\text{var}(Y) = 1\\\\\n$$</div>\n\n<p>The CDF of Normal Random Variable $\\Phi(y)$ can not be derived directly, we can use the standard normal table to get the value.</p>\n<div>$$\n\\Phi(-y) = 1 - \\Phi(y)\n$$</div>\n\n<h3 id=\"Multiple-Continuous-Random-Variables\"><a href=\"#Multiple-Continuous-Random-Variables\" class=\"headerlink\" title=\"Multiple Continuous Random Variables\"></a>Multiple Continuous Random Variables</h3><p><strong>Joint PDFs</strong></p>\n<p>The two continuous RVs X and Y, with the same experiment, are jointly continuous if they can be described by a joint PDF $f_{X, Y}$, where $f_{X, Y}$ is a nonnegative function that satisfies </p>\n<div>$$\nP((X, Y) \\in B) = \\iint_{(x, y)\\in B} f(X, Y)\\mathrm d x\\mathrm dy\n$$</div>\n\n<p>for every subset B of the two-dimensional plane. In particular, when B is the form $B &#x3D; {(x, y)|a\\le x \\le b, c\\le y \\le d}$, we have</p>\n<div>$$\nP(a\\le X \\le b, c \\le Y \\le d) = \\int_c^d\\int_a^bf_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$</div>\n\n<p><strong>Normalization</strong> </p>\n<div>$$\n\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\\mathrm dy = 1\n$$</div>\n\n<p><strong>Interpretation(Small rectangle)</strong></p>\n<div>$$\nP(a\\le X \\le a + \\delta, c \\le Y \\le c + \\delta) \\approx f_{X, Y}(a, c)\\cdot\\delta^2\n$$</div>\n\n<p><strong>Marginal PDF</strong></p>\n<div>$$\nP(X\\in A) = P(X \\in A, Y \\in (-\\infty, \\infty)) = \\int_A \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\mathrm dx\n$$</div>\n\n<div>$$\nf_X(x) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dy\\\\\nf_Y(y) = \\int_{-\\infty}^\\infty f_{X, Y}(x, y)\\mathrm dx\n$$</div>\n\n<p><strong>Joint CDF</strong></p>\n<p>If X and Y are two RVs asscociated with the same experiment, then the joint CDF of X and Y is the function</p>\n<div>$$\nF_{X, Y}(x, y) = P(X\\le x, Y\\le y) = P(X\\le x|Y\\le y)P(Y\\le y) = \\int_{-\\infty}^y\\int_{-\\infty}^x f_{X, Y}(u, v)\\mathrm du\\mathrm dv\n$$</div>\n\n<p>Conversely</p>\n<div>$$\nf_{X, Y}(x, y) = \\frac{\\partial^2F_{X, Y}}{\\partial x\\partial y}(x, y)\n$$</div>\n\n<p><strong>Expectations</strong></p>\n<div>$$\nE[g(X, Y)] = \\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty g(x, y)f_{X, Y}(x, y)\\mathrm dx\\mathrm dy\n$$</div>\n\n<p>If g is linear, of the form of $g(x, y) &#x3D; ax + by + c$, then</p>\n<div>$$\nE[g(X, Y)] = aE[X] + bE[Y] + c\n$$</div>\n\n<p>X and Y are called independent if </p>\n<div>$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$</div>\n\n<h3 id=\"Conditional-and-Independence\"><a href=\"#Conditional-and-Independence\" class=\"headerlink\" title=\"Conditional and Independence\"></a>Conditional and Independence</h3><p><strong>Conditional PDFs</strong></p>\n<p>Let X and Y be continuous RVs with joint PDF $f_{X, Y}$. For any $f_Y(y) \\gt 0$, the conditional PDF of X given Y &#x3D; y is defined by</p>\n<div>$$\nf_{X|Y}(x|y) = \\frac{f_{X, Y}(x, y)}{f_Y(y)}\n$$</div>\n\n<p>Discrete case: </p>\n<div>$$\np_{X|Y}(x|y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}\n$$</div>\n\n<p>By analogy, for fixed y would like: </p>\n<div>$$\nP(x \\le X \\le x + \\delta|Y = y) \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$</div>\n\n<p>But {Y &#x3D; y} is a zero-probability event.</p>\n<p>Let $B &#x3D; {y\\le Y \\le y + \\epsilon}$, for small $\\epsilon &gt; 0$. Then</p>\n<div>$$\nP(x \\le X \\le x + \\delta|Y \\in B) \\approx \\frac{P(x \\le X \\le x + \\delta)}{P(y \\le Y \\le y + \\epsilon)} \\approx \\frac{f_{X, Y}(x, y)\\cdot\\epsilon\\delta}{f_Y(y)\\cdot\\epsilon} \\approx f_{X|Y}(x|y)\\cdot\\delta\n$$</div>\n\n<p>Limiting case when $\\epsilon \\rightarrow 0$, to define conditional PDF where the denominator is a zero-probability event.</p>\n<p><strong>Conditional Expectation</strong></p>\n<p>The conditional expectation of X given that A has happened is defined by </p>\n<div>$$\nE[X|A] = \\int_{-\\infty}^\\infty xf_{X|A}(x)\\mathrm dx\n$$</div>\n\n<p>For a function g, we have</p>\n<div>$$\nE[g(X)|A] = \\int_{-\\infty}^\\infty g(x)f_{X|A}(x)\\mathrm dx\n$$</div>\n\n<p><strong>Total expectation theorem</strong></p>\n<p>Le $A_1, A_2, \\dots A_n$ be disjoint events that form a partition of the sample space $\\Omega$. And $P(A_i)\\gt 0$ for all $i$. Then</p>\n<div>$$\nE[g(X)] = \\sum_{i=1}^n P(A_i)E[g(X)|A_i]\n$$</div>\n\n<p>Conditional Expectation</p>\n<p>The conditional expectation of X given that $Y &#x3D; y$ has happened is defined by </p>\n<div>$$\nE[X|Y=y] = \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx\n$$</div>\n\n<p>For a function g, we have</p>\n<div>$$\nE[g(X)|Y=y] = \\int_{-\\infty}^\\infty g(x)f_{X|Y}(x|y)\\mathrm dx\n$$</div>\n\n<p>Total expectation theorem</p>\n<div>$$\nE[X] = E_{Y}\\left[E_{X|Y}[X|Y]\\right] = \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy\n$$</div>\n\n<p><strong>Independence</strong></p>\n<p>Two continuous RVs $X$ and $Y$ are independent if and only if</p>\n<div>$$\nf_{X, Y}(x, y) = f_X(x)f_Y(y)\n$$</div>\n\n<p>Independence is the same as the condition</p>\n<div>$$\nf_{X|Y}(x|y) = f_X(x)\n$$</div>\n\n<p>If $X$ and $Y$ are independent, then</p>\n<div>$$\nE[XY] = E[X]E[Y]\\\\\nE[g(x)h(y)] = E[g(x)]E[h(y)], \\forall g, h\\\\\n\\text{var}(X + Y) = \\text{var}(X) + \\text{var}(Y)\\\\\n$$</div>\n\n<h3 id=\"The-continuous-Bayes’s-rule\"><a href=\"#The-continuous-Bayes’s-rule\" class=\"headerlink\" title=\"The continuous Bayes’s rule\"></a>The continuous Bayes’s rule</h3><div>$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{f_Y(y)}\n$$</div>\n\n<p>Based on the normalization property $\\int_{-\\infty}^\\infty f_{X|Y}(x|y)\\mathrm dx &#x3D; 1$,</p>\n<div>$$\nf_{Y|X}(y|x) = \\frac{f_Y(y)f_{X|Y}(x|y)}{\\int_{-\\infty}^\\infty f_X(t)f_{Y|X}(y|t)\\mathrm dt}\n$$</div>\n\n<h2 id=\"Derived-distributions-and-Entropy\"><a href=\"#Derived-distributions-and-Entropy\" class=\"headerlink\" title=\"Derived distributions and Entropy\"></a>Derived distributions and Entropy</h2><h3 id=\"Derived-Distribution\"><a href=\"#Derived-Distribution\" class=\"headerlink\" title=\"Derived Distribution\"></a>Derived Distribution</h3><p>If we want to calculate the expectation $E[g(X)]$, there’s no need to calculate the PDF $f_X$ of $X$.</p>\n<p>But sometimes we want the PDF $f_Y$ of $Y &#x3D; g(X)$, where $Y$ is a new RV.</p>\n<p><strong>Principal Method</strong></p>\n<p>Two-step procedure for the calculation of the PDF of a function $Y&#x3D;g(X)$ of a continuous RV $X$</p>\n<ol>\n<li>Calcualte the CDF $F_Y$ of $Y$: $F_Y(y) &#x3D; P(Y \\le y)$</li>\n<li>Differentiate $F_Y$ to obtain the PDF $f_Y$ of $Y$: $f_Y(y) &#x3D; \\frac{\\mathrm d F_Y}{\\mathrm d y}(y)$</li>\n</ol>\n<p><strong>The PDF of $Y&#x3D;aX + b$</strong></p>\n<p>Suppose $a&gt;0$ and $b$ are constants.</p>\n<div>$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(\\frac{y-b}{a}) = \\frac{1}{a}f_X(\\frac{y-b}{a})\n$$</div>\n\n<p>If $X$ is Normal, then $Y &#x3D; aX + b$ is also Normal.</p>\n<p>Suppose X is normal with mean $\\mu$ and variance $\\sigma^2$. Then</p>\n<div>$$\nf_Y(y) = \\frac{1}{a\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y-b-a\\mu)^2}{2a^2\\sigma^2}\\right)\n$$</div>\n\n<div>$$\nY = aX + b \\sim N(a\\mu + b, a^2\\sigma^2)\n$$</div>\n\n<p><strong>The PDF of a strictly monotonic function</strong></p>\n<p>Suppose $g$ is a strictly monotonic function and that for some function $h$ and all $x$ in the range of $X$ we have </p>\n<div>$$\ny = g(x) \\text{ if and only if } x = h(y)\n$$</div>\n\n<p>Assume that $h$ is differentiable.</p>\n<p>Then the PDF of $Y &#x3D; g(X)$ is given by</p>\n<div>$$\nf_Y(y) = \\frac{\\mathrm d F_Y}{\\mathrm d y}(y) = \\frac{\\mathrm d}{\\mathrm d y} F_X(h(y)) = f_X(h(y))\\left|\\frac{\\mathrm d h}{\\mathrm d y}(y)\\right|\n$$</div>\n\n<h3 id=\"Entropy\"><a href=\"#Entropy\" class=\"headerlink\" title=\"Entropy\"></a>Entropy</h3><p><strong>Defintion</strong></p>\n<p>Discrete case</p>\n<p>Let $X$ be a discrete RV defined on probability space $(\\Omega, \\mathcal F, P)$. The <strong>entropy</strong> of $X$ is defined by</p>\n<div>$$\nH(X) = -E[\\ln p_X(X)] = -\\sum_{k} p_X(x_k)\\ln p_X(x_k)\n$$</div>\n\n<p>Continuous case</p>\n<p>Let $X$ be a continuous RV defined on probability space $(\\Omega, \\mathcal F, P)$. The <strong>differential entropy</strong> of $X$ is defined by</p>\n<div>$$\nH(X) = -E[\\ln f_X(X)] = -\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\n$$</div>\n\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>a special expectation of a random variable</li>\n<li>a measure of uncertainty in a random experiment</li>\n<li><ul>\n<li>the larger the entropy, the more uncertain the experiment</li>\n</ul>\n</li>\n<li><ul>\n<li>For a deterministic event, the entropy is zero</li>\n</ul>\n</li>\n<li>The base of logarithm can be different. Changing the base od the logarithm is equivalent to multiplying the entropy by a constant.</li>\n<li><ul>\n<li>With base 2, we say that the entropy is in units of <strong>bits</strong></li>\n</ul>\n</li>\n<li><ul>\n<li>With base e, we say that the entropy is in units of <strong>nats</strong></li>\n</ul>\n</li>\n<li>The basis of information theory</li>\n</ul>\n<h3 id=\"Maximum-entropy-distributions\"><a href=\"#Maximum-entropy-distributions\" class=\"headerlink\" title=\"Maximum entropy distributions\"></a>Maximum entropy distributions</h3><p>• Maximum entropy distributions</p>\n<p>− Distributions with maximum entropy under some constraints</p>\n<p>− Gaussian, exponential, and uniform distributions are all maximum entropy distributions under certain conditions</p>\n<p>• Why studying maximum entropy distributions?</p>\n<p>− The most random distribution, reflecting the maximum uncertainty about the quantity of interest</p>\n<p><strong>Definition</strong></p>\n<p><strong>Discrete Case</strong></p>\n<p>X can be a finite number of values $x_1, x_2, \\dots, x_n$, satisfying $p_X(x_k) &#x3D; p_k.$</p>\n<p>We have the following optimization problem:</p>\n<div>$$\n\\max_{X} H(X) = \\max_{p_1, p_2, \\dots, p_n} \\left(-\\sum_{k=1}^n p_k\\ln p_k\\right)\\\\\n\\text{s.t.} \\sum_{k=1}^n p_k = 1, p_k \\ge 0 \\text{ for } k = 1, 2, \\dots, n\n$$</div>\n\n<p><strong>Solution</strong></p>\n<p>Applying the Lagrange multiplier method, we have</p>\n<div>$$\nL(p_1, p_2, \\dots, p_n;\\lambda) = -\\sum_{k=1}^n p_k\\ln p_k + \\lambda\\left(\\sum_{k=1}^n p_k - 1\\right)\\\\\n\\frac{\\partial L}{\\partial p_k} = -\\ln p_k - 1 + \\lambda = 0\\\\\n\\Rightarrow p_k = e^{\\lambda - 1}\\\\\n$$</div>\n\n<p>Note that the above is true for all $k$. So we have</p>\n<div>$$\np_k = e^{\\lambda - 1}  = \\frac1{n}\\text{ for } k = 1, 2, \\dots, n.\n$$</div>\n\n<p><strong>Continuous Case 1</strong></p>\n<p>$X \\in [-\\infty, \\infty]$.</p>\n<p>Constrain on mean and variance,<br>we have the following optimization problem:</p>\n<div>$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu, \\quad Var(X) = \\sigma^2\n$$</div>\n\n<p>In detail, </p>\n<div>$$\n\\max_{X} H(X) = \\max_{\\mu, \\sigma^2} \\left(-\\int_{-\\infty}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{-\\infty}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{-\\infty}^\\infty xf(x)\\mathrm dx = \\mu, \\quad \\int_{-\\infty}^\\infty x^2f(x)\\mathrm dx = \\sigma^2 + \\mu^2\n$$</div>\n\n<p>Solving the above problem, we have Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$.</p>\n<div>$$\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$</div>\n\n<p><strong>Solution</strong></p>\n<p>For all measurable functions $g$, we have</p>\n<div>$$\nG(t) = h(f + tg) = -\\int_{\\infty}^\\infty (f(x) + tg(x))\\ln (f(x) + tg(x))\\mathrm dx\n$$</div>\n\n<p>Therefore,</p>\n<div>$$\nh(f_{opt})\\ge h(f_{opt} + tg)\\\\\n\\Rightarrow G(0)\\ge G(t), \\forall t \\in \\R\n$$</div>\n\n<p>$G(t)$ reaches its maximum at $t &#x3D; 0$.</p>\n<p>Then apply the Lagrange multiplier method, we have</p>\n<div>$$\n\\overline{G}(t) = G(t) + c_0h_0(t) + c_1h_1(t) + c_2h_2(t)\\\\\n$$</div>\n\n<p>Get the derivative of $\\overline{G}(t)$ with regard to $t$, and let the derivative equal to zero.</p>\n<p><strong>Continuous Case 2</strong></p>\n<p>$X \\in [0, \\infty)$.</p>\n<p>Constrain on mean only, we have the following optimization problem:</p>\n<div>$$\n\\max_{X}h(X), \\\\\n\\text{s.t. }E[X] = \\mu\n$$</div>\n\n<p>In detail,</p>\n<div>$$\n\\max_{X} H(X) = \\max_{\\mu} \\left(-\\int_{0}^\\infty f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{0}^\\infty f(x)\\mathrm dx = 1, \\quad \\int_{0}^\\infty xf(x)\\mathrm dx = \\mu\n$$</div>\n\n<p>Solving the above problem, we have exponential distribution with parameter $\\lambda$.</p>\n<div>$$\nf(x) = \\lambda e^{-\\lambda x}, x \\in [0, \\infty)\n$$</div>\n\n<p><strong>Continuous Case 3</strong></p>\n<p>$X \\in [a, b]$.</p>\n<p>No constrain, we have the unconstrained optimization problem:</p>\n<div>$$\n\\max_{X}h(X)\n$$</div>\n\n<p>In detail,</p>\n<div>$$\n\\max_{X} H(X) = \\max_{a, b} \\left(-\\int_{a}^b f_X(x)\\ln f_X(x)\\mathrm dx\\right)\\\\\n\\text{s.t. }\\int_{a}^b f(x)\\mathrm dx = 1\n$$</div>\n\n<p>Solving the above problem, we have uniform distribution within $[a, b]$.</p>\n<div>$$\nf(x) = \\frac{1}{b-a}, x \\in [a, b]\n$$</div>\n\n<h2 id=\"Convolution-covariance-correlation-and-conditional-expectation\"><a href=\"#Convolution-covariance-correlation-and-conditional-expectation\" class=\"headerlink\" title=\"Convolution, covariance, correlation, and conditional expectation\"></a>Convolution, covariance, correlation, and conditional expectation</h2><h3 id=\"Convolution\"><a href=\"#Convolution\" class=\"headerlink\" title=\"Convolution\"></a>Convolution</h3><p><strong>Discrete case</strong></p>\n<div>$$\n\\begin{align*}\np_W(w) &= P(X+Y=w)\\\\\n&= \\sum_{x}P(X=x, Y=w-x)\\\\\n&= \\sum_{x}P(X=x)P(Y=w-x)\\\\\n&= \\sum_{x}p_X(x)p_Y(w-x)\\\\\n\\end{align*}\n$$</div>\n\n<p>PMF $p_W$ is the convolution of PMFs $p_X$ and $p_Y$.</p>\n<p><strong>The distribution of $X+Y$</strong></p>\n<p>Mechanics:</p>\n<ul>\n<li>Put the PMF’s on top of each other</li>\n<li>Flip the PMF of $Y$</li>\n<li>Shift the flipped PMF by $w$ (to the right if $w&gt;0$)</li>\n<li>Cross-multiply and add</li>\n</ul>\n<p><strong>Continuous Case</strong></p>\n<div>$$\n\\begin{align*}\n&W = X+Y, X, Y \\text{ are independent}\\\\\n&P(W\\le w|X=x) = P(Y\\le w-x)\\\\\n&f_{W|X}(w|x) = f_Y(w-x)\\\\\n&f_{W, X}(w, x) = f_X(x)f_Y(w-x)\\\\\n&f_W(w) = \\int_{-\\infty}^\\infty f_X(x)f_Y(w-x)\\mathrm dx\\\\\n\\end{align*}\n$$</div>\n\n<p><strong>Sum of 2 independent normal RVs</strong></p>\n<div>$$\n\\begin{align*}\n    & X\\sim N(\\mu_1, \\sigma_1^2), Y\\sim N(\\mu_2, \\sigma_2^2)\\\\\n    &f_{X,Y}(x, y) = \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{(x-\\mu_x)^2}{2\\sigma_x^2} - \\frac{(y-\\mu_y)^2}{2\\sigma_y^2}\\right\\rbrace\n\\end{align*}\n$$</div>\n\n<p>which is constant on the ellipse(circle if $\\sigma_x &#x3D; \\sigma_y$).</p>\n<div>$$\n\\begin{align*}\n    X\\sim N(0, \\sigma_x), &Y\\sim N(0, \\sigma_y)\\\\\n    W &= X+Y\\\\\n    f_W(w) &= \\int_{-\\infty}^\\infty f_{X,Y}(x, w-x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty \\frac{1}{2\\pi \\sigma_x\\sigma_y}\\text{exp}\\left\\lbrace-\\frac{x^2}{2\\sigma_x^2} - \\frac{(w-x)^2}{2\\sigma_y^2}\\right\\rbrace\\mathrm dx\\\\\n    =ce^{-\\gamma \\omega^2}\n\\end{align*}\n$$</div>\n\n<p>$W$ is Normal.</p>\n<p>Mean &#x3D; 0, Variance &#x3D; $\\sigma_x^2 + \\sigma_y^2$</p>\n<p>Same argument for nonzero mean case.</p>\n<p><strong>The difference of two independent RVs</strong></p>\n<p>$X$ and $Y$  are independent exponential RVs with parameter $\\lambda$.</p>\n<p>Fix some $z\\ge 0$ and note that $f_Y(x-z)$ is non zero when $x\\ge z$.</p>\n<div>$$\n\\begin{align*}\n    Z &= X - Y\\\\\n    f_Z(z) &= \\int_{-\\infty}^\\infty f_X(x)f_{-Y}(z - x)\\mathrm dx\\\\\n    &= \\int_{-\\infty}^\\infty f_X(x)f_{Y}(x - z)\\mathrm dx\\\\\n    &= \\int_{z}^\\infty \\lambda e^{-\\lambda x}\\lambda e^{-\\lambda(x-z)}\\mathrm dx\\\\\n    &= \\frac{\\lambda}{2}e^{-\\lambda z}\n\\end{align*}\n$$</div>\n\n<p>The answer for the case $z\\le 0$</p>\n<div>$$\nf_{X-Y}(z) = f_{Y-X}(z) = f_Z(-z)\n$$</div>\n\n<p>The first quality holds by symmetry.</p>\n<h3 id=\"Covariance-and-Correlation\"><a href=\"#Covariance-and-Correlation\" class=\"headerlink\" title=\"Covariance and Correlation\"></a>Covariance and Correlation</h3><p><strong>Definition</strong></p>\n<p>The covariance of two RVs $X$ and $Y$, denoted by $\\text{cov}(X, Y)$, is defined by</p>\n<div>$$\n\\text{cov}(X, Y) = E\\left[(X - E[X])(Y - E[Y])\\right]\n$$</div>\n\n<p>or, </p>\n<div>$$\n\\text{cov}(X, Y) = E[XY] - E[X]E[Y]\n$$</div>\n\n<p>$X$ and $Y$ are <strong>uncorrelated</strong> if $\\text{cov}(X, Y) &#x3D; 0$.</p>\n<p><strong>Zero mean case</strong> $\\text{cov}(X, Y) &#x3D; E[XY]$</p>\n<p><strong>Properties</strong></p>\n<div>$$\n\\text{cov}(X, Y) = \\text{var}(X, Y)\\\\\n\\text{cov}(X, aY+b) = a\\cdot\\text{cov}(X, Y)\\\\\n\\text{cov}(X, Y+Z) = \\text{cov}(X, Y) + \\text{cov}(X, Z)\\\\\n\\text{independent} \\Rightarrow \\text{cov}(X, Y) = 0(\\text{converse is not true})\n$$</div>\n\n<p><strong>Variance of the sum of RVs</strong></p>\n<div>$$\n\\text{var}\\left(\\sum_{i = 1}^nX_i\\right) = \\sum_{i = 1}^n\\text{var}(X_i) + \\sum_{\\lbrace(i, j)|i\\ne j\\rbrace}\\text{cov}(X_i, X_j)\n$$</div>\n\n<p>In particular, </p>\n<div>$$\n\\text{var}(X_1 + X_2) = \\text{var}(X_1) + \\text{var}(X_2) + 2\\text{cov}(X_1, X_2)\n$$</div>\n\n<p><strong>Correlation coefficient</strong></p>\n<p>The correlation coefficient $\\rho(X, Y)$ of two RVs $X$ and $Y$ that have nonzero variance is defined as</p>\n<div>$$\n\\begin{align*}\n\\rho &= E\\left[\\frac{(X - E[X])}{\\sigma_X} \\cdot \\frac{(Y - E[Y])}{\\sigma_Y}\\right]\\\\\n&= \\frac{\\text{cov}(X, Y)}{\\sigma_X\\sigma_Y}\n\\end{align*}\n$$</div>\n\n<ul>\n<li>$-1 \\le \\rho \\le 1$</li>\n<li>$|\\rho| &#x3D; 1 \\Leftrightarrow (X-E[X]) &#x3D; c(Y-E[Y])$</li>\n<li>Independent $\\Rightarrow \\rho &#x3D; 0(\\text{converse is not true})$</li>\n</ul>\n<p><strong>Conditional expected value</strong></p>\n<div>$$\nE[X|Y = y] = \\sum_x xp_{X|Y}(x|y)\n$$</div>\n\n<h3 id=\"Conditional-expectation\"><a href=\"#Conditional-expectation\" class=\"headerlink\" title=\"Conditional expectation\"></a>Conditional expectation</h3><p><strong>Definition</strong></p>\n<div>$$\nE[X|Y = y] = \\begin{cases}\n    \\sum_x xp_{X|Y}(x|y), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty xf_{X|Y}(x|y)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$</div>\n\n<p>$E[X|Y&#x3D;y]$ is a function of $y$.</p>\n<div>$$\nE[X|Y = y] = \\frac{y}{2}(\\text{number})\\\\\nE[X|Y] = \\frac{Y}{2}(\\text{RV})\n$$</div>\n\n<p><strong>Law of iterated expectations</strong></p>\n<div>$$\nE[X] = E[E[X|Y]] = \\begin{cases}\n    \\sum_y E[X | Y = y]p_Y(y), & Y \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty E[X|Y = y]f_Y(y)\\mathrm dy, & Y \\text{continuous}.\n\\end{cases}\n$$</div>\n\n<h3 id=\"Conditional-expectation-as-an-estimator\"><a href=\"#Conditional-expectation-as-an-estimator\" class=\"headerlink\" title=\"Conditional expectation as an estimator\"></a>Conditional expectation as an estimator</h3><p>Denote the conditional expectation</p>\n<div>$$\n\\hat{X} = E[X|Y]\n$$</div>\n\n<p>as an estimator of $X$ given $Y$, and the estimation error</p>\n<div>$$\n\\tilde{X} = X - \\hat{X}\n$$</div>\n\n<p>is a RV.</p>\n<p><strong>Properties of the estimator</strong>: </p>\n<p><strong>Unbiased</strong></p>\n<p>For <strong>any</strong> possible $Y&#x3D;y$:</p>\n<div>$$\nE[\\tilde{X}|Y] = E[X - \\hat{X} | Y] = E[X | Y] - E[\\hat{X}|Y] = \\hat{X} - \\hat{X} = 0\n$$</div>\n\n<p>By the law of iterated expectations</p>\n<div>$$\nE[\\tilde{X}] = E[E[\\tilde{X}|Y]] = 0\n$$</div>\n\n<p><strong>Uncorrelated</strong></p>\n<div>$$\nE[\\hat{X}\\tilde{X}] = E[E[\\hat{X}\\tilde{X}|Y]] = E[\\hat{X}E[\\tilde{X}|Y]] = 0\n$$</div>\n\n<div>$$\n\\text{cov}(\\hat{X}, \\tilde{X}) = E[\\hat{X}\\tilde{X}] - E[\\hat{X}]E[\\tilde{X}] = 0\n$$</div>\n\n<p>Since $X &#x3D; \\hat{X} + \\tilde{X}$, the variance of X can be decomposed as</p>\n<div>$$\n\\text{var}(X) = \\text{var}(\\hat{X}) + \\text{var}(\\tilde{X})\n$$</div>\n\n<div>$$\n\\text{var}(\\tilde{X}) = \\text{var}(E[X|Y])\n$$</div>\n\n<p>Conditional variance</p>\n<div>$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$</div>\n\n<p>here comes the law of total variance:</p>\n<div>$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$</div>\n\n<p>The total variability is avarage variability within sections + variability between sections.</p>\n<p><strong>Law of iterated expectations</strong></p>\n<div>$$\nE[X] = E[E[X|Y]] = \\sum_y E[X|Y = y]p_Y(y)\n$$</div>\n\n\n<p><strong>Conditional variance</strong></p>\n<div>$$\n\\text{var}(X|Y) = E[(X - E[X|Y])^2|Y] = E[\\tilde{X}^2|Y]\n$$</div>\n\n<p><strong>Law of total variance</strong></p>\n<div>$$\n\\text{var}(X) = \\text{var}(E[X|Y]) + E[\\text{var}(X|Y)] \n$$</div>\n\n\n<h2 id=\"Transforms-and-sum-of-a-random-number-of-random-variables\"><a href=\"#Transforms-and-sum-of-a-random-number-of-random-variables\" class=\"headerlink\" title=\"Transforms and sum of a random number of random variables\"></a>Transforms and sum of a random number of random variables</h2><p>The transform associated with a RV $X$ is a function $M_X(s)$ of a scalar parameter $s$, defined by</p>\n<div>$$\nM_X(s) = E[e^{sX}] = \\begin{cases}\n    \\sum_x e^{sx}p_X(x), & X \\text{discrete},\\\\\n    \\int_{-\\infty}^\\infty e^{sx}f_X(x)\\mathrm dx, & X \\text{continuous}.\n\\end{cases}\n$$</div>\n\n<p><strong>Remarks</strong></p>\n<ul>\n<li>a function of $s$, rather than a number</li>\n<li>not necessarily defined for all (complex) s</li>\n<li>always well defined for $\\Re(s)&#x3D;0$</li>\n<li>compared with Laplace transform</li>\n</ul>\n<h3 id=\"Properties\"><a href=\"#Properties\" class=\"headerlink\" title=\"Properties\"></a>Properties</h3><p><strong>Sanity Checks</strong></p>\n<div>$$\nM_X(0) = 1\\\\\n|M_X(s)| \\le 1 \\text{ for } \\Re(s) = 0\n$$</div>\n\n<p><strong>Linear operation</strong></p>\n<div>$$\nM_{aX + b}(s) = e^{bs}M_X(as)\\\\\nM_{X + Y}(s) = M_X(s)M_Y(s) (\\text{if X, Y independent})\n$$</div>\n\n<p><strong>Expected Values</strong></p>\n<div>$$\nE[X^n] = \\frac{\\partial^n M_X(s)}{\\partial s^n}\\bigg|_{s=0}\n$$</div>\n\n<div>$$\nP(X = c) = \\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc}\n$$</div>\n\n<p>since</p>\n<div>$$\n\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N M_X(jk)e^{-jkc} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac 1N\\sum_{k = 1}^N e^{-jc(k - x)} = \\sum_{x = 1}^\\infty p_X(x)\\lim_{N\\rightarrow \\infty}\\frac{1}{N} \\frac{e^{j(x-c)} - e^{Nj(x - c)}}{1-e^{j(x-c)}} = p_X(c)\n$$</div>\n\n<p><strong>Example</strong></p>\n<p>$X$ is a Poisson RV with parameter $\\lambda$</p>\n<div>$$\np_X(x) = \\frac{\\lambda^x}{x!}e^{-\\lambda}\n$$</div>\n\n<div>$$\nM(s) = \\sum_{x = 0}^\\infty e^{sx}\\frac{\\lambda^x}{x!}e^{-\\lambda} = e^{-\\lambda}\\sum_{x = 0}^\\infty \\frac{(e^s\\lambda)^x}{x!} = e^{-\\lambda}e^{e^s\\lambda} = e^{\\lambda(e^s - 1)}\n$$</div>\n\n<p>$X$ is an exponential RV with parameter $\\lambda$</p>\n<div>$$\nf_X(x) = \\lambda e^{-\\lambda x}\n$$</div>\n\n<div>$$\nM(s) = \\int_0^\\infty e^{sx}\\lambda e^{-\\lambda x}\\mathrm dx = \\frac{\\lambda}{\\lambda - s}\n$$</div>\n\n<p>$Y$ is a standard normal RV, </p>\n<div>$$\nM_Y(s) = \\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi}}e^{-(y^2/2)}e^{sy}\\mathrm dy = e^{s^2/2}\n$$</div>\n\n<p>Consider $X &#x3D; \\sigma Y + \\mu$</p>\n<div>$$\nM_X(s) = e^{s^2\\sigma^2/2 + \\mu s}\n$$</div>\n\n<h3 id=\"Inversion-of-transforms\"><a href=\"#Inversion-of-transforms\" class=\"headerlink\" title=\"Inversion of transforms\"></a>Inversion of transforms</h3><p><strong>Inversion Property</strong></p>\n<p>The transform $M_X(s)$ associated with a RV $X$ uniquely determines the CDF of $X$, assuming that $M_X(s)$ is finite for all $s$ in some interval $[-a, a]$, where $a$ is a positive number.</p>\n<p>Example:</p>\n<div>$$\n\\begin{align*}\nM(s) &= \\frac{pe^s}{1 - (1 - p)e^s}\\\\\n&= pe^s(1 + (1-p)e^s + (1-p)^2e^{2s} + \\dotsb)\\\\\n&= \\sum_{k = 1}^\\infty p(1-p)^{k - 1}e^{ks}\n\\end{align*}\n$$</div>\n\n<p>The probability $P(X &#x3D; k)$ is found by reading the coefficient of the term $e^{ks}$:</p>\n<div>$$\nP(X = k) = p(1-p)^{k-1}\n$$</div>\n\n<h3 id=\"Transform-of-Mixture-of-Distributions\"><a href=\"#Transform-of-Mixture-of-Distributions\" class=\"headerlink\" title=\"Transform of Mixture of Distributions\"></a>Transform of Mixture of Distributions</h3><p>Let $X_1,\\dotsb, X_n$ be continuous RVs with PDFs $f_{X_1}, \\dotsb, f_{X_n}$.</p>\n<p>The value $y$ of RV $Y$ is generated as follows: an index $i$ is chosen with a corresponding probability $p_i$, and $y$ is taken to be equal to the value $X_i$. Then, </p>\n<div>$$\nf_Y(y) = p_1f_{X_1}(y) + \\dotsb + p_nf_{X_n}(y)\\\\\nM_Y(s) = p_1M_{X_1}(s) + \\dotsb + p_nM_{X_n}(s)\n$$</div>\n\n<h3 id=\"Sum-of-independend-RVs\"><a href=\"#Sum-of-independend-RVs\" class=\"headerlink\" title=\"Sum of independend RVs\"></a>Sum of independend RVs</h3><p>Let $X$ and $Y$ be independent RVs, and let $Z &#x3D; X + Y$. The transform associated with $Z$ is </p>\n<div>$$\nM_Z(s) = M_X(s)M_Y(s)\n$$</div>\n\n<p>Since</p>\n<div>$$\nM_Z(s) = E[e^{sZ}] = E[e^{s(X + Y)}] = E[e^{sX}e^{sY}] = E[e^{sX}]E[e^{sY}] = M_X(s)M_Y(s)\n$$</div>\n\n<p>Generalization:</p>\n<p>A collection of independent RVs: $X_1, \\dotsb, X_n$, $Z &#x3D; X_1 + \\dotsb + X_n$ ,</p>\n<div>$$\nM_Z(s) = M_{X_1}(s)\\dotsb M_{X_n}(s)\n$$</div>\n\n<p><strong>Example</strong></p>\n<p>Let $X_1, \\dotsb, X_n$ be independent Bernoulli RVs with a common parameter $p$:</p>\n<div>$$\nM_{X_i}(s) = 1 - p + pe^s\n$$</div>\n\n<p>$Z &#x3D; X_1 + \\dotsb + X_n$ is binomial with parameters n and p:</p>\n<div>$$\nM_z(s) = (1 - p + pe^s)^n\n$$</div>\n\n<p>Let $X$ and $Y$ be independent Poisson RVs with means $\\lambda$ and $\\mu$, and let $Z &#x3D; X + Y$. Then $Z$ is still Poisson with mean $\\lambda + \\mu$.</p>\n<div>$$\nM_Z(s) = M_X(s)M_Y(s) = e^{(\\lambda +\\mu)(e^s - 1)}\n$$</div>\n\n<p>Let $X$ and $Y$ be independent Gaussian RVs with means $\\mu_x$ and $\\mu_y$, and variances $\\sigma_x^2, \\sigma_y^2$. And let $Z &#x3D; X + Y$. Then $Z$ is still Gaussian with mean $\\mu_x + \\mu_y$ and variance $\\sigma_x^2 + \\sigma_y^2$</p>\n<div>$$\nM_X(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_x^2s^2}{2} + \\mu_x s\\bigg\\rbrace\\\\\nM_Y(s) = \\exp\\bigg\\lbrace\\frac{\\sigma_y^2s^2}{2} + \\mu_y s\\bigg\\rbrace\\\\\nM_Z(s) = M_X(s)M_Y(s) = \\exp\\bigg\\lbrace\\frac{(\\sigma_x^2 + \\sigma_y^2)s^2}{2} + (\\mu_x + \\mu_y)s\\bigg\\rbrace\n$$</div>\n\n<p>Consider</p>\n<div>$$\nY = X_1 + \\dotsb + X_N\n$$</div>\n\n<p>where $N$ is a RV that takes integer values, and $X_1, \\dotsb, X_N$ are identically distributed RVs.</p>\n<p>Assume that $N, X_1, \\dotsb$ are independent.</p>\n<div>$$\nE[Y|N = n] = E[X_1 + X_2 + \\dotsb + X_n|N = n] = nE[X]\\\\\nE[Y|N] = NE[X]\\\\\nE[Y] = E[E[Y|N]] = E[NE[X]] = E[N]E[X]\n$$</div>\n\n<p>For the variance, </p>\n<div>$$\nE[Y|N] = NE[X]\\\\\n\\text{var}(E[Y|N]) = (E[X])^2\\text{var}(N)\\\\\n\\text{var}(Y|N=n) = n\\text{var}(X)\\\\\n\\text{var}(Y|N) = N \\text{var}(X)\\\\\nE[\\text{var}(Y|N)] = E[N]\\text{var}(X)\\\\\n$$</div>\n\n<p>So, </p>\n<div>$$\n\\text{var}(Y) = E[\\text{var}(Y|N)] + \\text{var}(E[Y|N]) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\n$$</div>\n\n<p>For transform,</p>\n<div>$$\nE[e^{sY}|N = n] = E[e^{sX_1}\\dotsb e^{sX_n}|N = n] = E[e^{sX}]^n = (M_X(s))^n\\\\\nM_Y(s) = E[e^{sY}] = E[E[e^{sY}|N]] = E[(M_X(s))^N] = \\sum_{n = 0}^\\infty (M_X(s))^n p_N(n) = \\sum_{n = 0}^\\infty e^{n\\log M_X(s)}p_N(n) = M_N(\\log M_X(s))\n$$</div>\n\n<p><strong>Summary on Properties</strong></p>\n<p>Consider the sum</p>\n<div>$$\nY = X_1 + \\dotsb + X_N\n$$</div>\n\n<p>where $N$ is a RV that takes integer values, and $X_1, X_2, \\dotsb$ are identically distributed RVs. Assume that $N$, $X_1, X_2, \\dotsb$ are independent.</p>\n<div>$$\nE[Y] = E[N]E[X]\\\\\n\\text{var}(Y) = E[N]\\text{var}(X) + (E[X])^2\\text{var}(N)\\\\\nM_Y(s) = M_N(\\log M_X(s))\n$$</div>\n\n<p><strong>Example</strong></p>\n<p>Assume that $N$ and $X_i$ are both geometrically distributed with parameters $p$ and $q$ respectively. All of these RVs are independent. $Y &#x3D; X_1 + \\dotsb + X_N$</p>\n<div>$$\nM_N(s) = \\frac{pe^s}{1 - (1-p)e^s}\\\\\nM_X(s) = \\frac{qe^s}{1 - (1-q)e^s}\\\\\nM_Y(s) = M_N(\\log M_X(s)) = \\frac{pqe^s}{1 - (1-pq)e^s}\n$$</div>\n\n<p>$Y$ is also geometrically distributed, with parameter $pq$.</p>\n<h2 id=\"Weak-law-of-large-numbers\"><a href=\"#Weak-law-of-large-numbers\" class=\"headerlink\" title=\"Weak law of large numbers\"></a>Weak law of large numbers</h2><h3 id=\"Markov-inequality\"><a href=\"#Markov-inequality\" class=\"headerlink\" title=\"Markov inequality\"></a>Markov inequality</h3><p>If a RV $X$ can only take nonnegative values, then</p>\n<div>$$\nP(X \\ge a) \\le \\frac{E[X]}{a}, \\text{ for all } a \\gt 0.\n$$</div>\n\n<p>Intuition: If a nonnegative RV has a small mean, then the probability that it takes a large value must be small。</p>\n<p>Fix a positive number $a$, </p>\n<div>$$\nE[X] = \\int_0^\\infty xf_X(x)dx = \\int_0^a xf_X(x)dx + \\int_a^\\infty xf_X(x)dx \\ge 0 + \\int_a^\\infty xf(x)dx \\ge \\int_a^\\infty af_X(x)dx = aP(X \\ge a)\n$$</div>\n\n<h3 id=\"Chebyshev’s-Inequality\"><a href=\"#Chebyshev’s-Inequality\" class=\"headerlink\" title=\"Chebyshev’s Inequality\"></a>Chebyshev’s Inequality</h3><p>If $X$ is a RV with mean $\\mu$ and variance $\\sigma^2$, then</p>\n<div>$$\nP(|X - \\mu| \\ge c) \\le \\frac{\\sigma^2}{c^2}\n$$</div>\n\n<p>Intuition: If a RV has small variance, then the probability that it takes a value far from its mean is also small.</p>\n<div>$$\n\\begin{align*}\n\\sigma^2 &= \\int (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} (x - \\mu)^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty (x - \\mu)^2f_X(x)\\mathrm dx\\\\\n&\\ge \\int_{-\\infty}^{\\mu - c} c^2f_X(x)\\mathrm dx + \\int_{ \\mu + c}^\\infty c^2f_X(x)\\mathrm dx\\\\\n&= \\int_{|x - \\mu| \\ge c} c^2f_X(x)\\mathrm dx\\\\\n&=c^2P(|X - \\mu| \\ge c)\n\\end{align*}\n$$</div>\n\n<p>The upperbounds of $\\sigma^2$:</p>\n<div>$$\nX \\in [a, b]\\\\\n\\sigma^2 \\le (b - a)^2/4\n$$</div>\n\n<p><strong>Chernoff inequality</strong></p>\n<p>If a RV $X$ has MGF $M_X(s)$, then</p>\n<div>$$\nP(X \\ge a) \\le e^{-\\max_{s\\ge 0}\\left(sa - \\ln M_X(s)\\right)}\n$$</div>\n\n<p>or, for $s \\ge 0$</p>\n<div>$$\nP(X\\ge a) \\le e^{-sa}M_X(s)\n$$</div>\n\n<p>for $s \\lt 0$</p>\n<div>$$\nP(X \\le a) \\le e^{-sa}M_X(s)\n$$</div>\n\n<p>proof: for $s \\ge 0$</p>\n<div>$$\nM_X(s) = \\int_{-\\infty}^a e^{sx}f_X(x)\\mathrm dx + \\int_a^{\\infty} e^{sx}f_X(x)\\mathrm dx\\\\\n\\ge 0 + e^{sa}\\int_a^{\\infty} f_X(x)\\mathrm dx = e^{sa}P(X \\ge a)\n$$</div>\n\n<h3 id=\"Weak-law-of-large-numbers-1\"><a href=\"#Weak-law-of-large-numbers-1\" class=\"headerlink\" title=\"Weak law of large numbers\"></a>Weak law of large numbers</h3><p>Let $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$</p>\n<div>$$\nM_n = \\frac{X_1 + X_2 + \\dotsb + X_n}{n}\\\\\nE[M_n] = \\mu\\\\\n\\text{var}(M_n) = \\frac{\\sigma^2}{n}\n$$</div>\n\n<p>Applying the Chebyshev inequality and we get:</p>\n<div>$$\nP(|M_n - \\mu| \\ge \\epsilon) \\le \\frac{\\text{var}(M_n)}{\\epsilon^2} = \\frac{\\sigma^2}{n\\epsilon^2}\n$$</div>\n\n<p>For large $n$, the bulk of the distribution of $M_n$ is concentrated near $\\mu$</p>\n<p><strong>Theorem</strong></p>\n<p>Let $X_1, X_2, \\dots$ be independent identically distributed (i.i.d.) RVs with finite mean $\\mu$ and variance $\\sigma^2$. For every $\\epsilon \\gt 0$, we have</p>\n<div>$$\nP(|M_n - \\mu| \\ge \\epsilon) = P\\left(\\left|\\frac{X_1 + \\dotsb + X_n}{n} - \\mu\\right|\\ge \\epsilon\\right) \\rightarrow 0, \\text{ as } n \\rightarrow \\infty\n$$</div>\n\n<p>$M_n$ converges <strong>in probability</strong> to $\\mu$.</p>\n<h3 id=\"Convergence-“in-Probability”\"><a href=\"#Convergence-“in-Probability”\" class=\"headerlink\" title=\"Convergence “in Probability”\"></a>Convergence “in Probability”</h3><p>Theorem: Convergence in Probability</p>\n<p>Let $\\lbrace Y_n\\rbrace$(or $Y_1, Y_2, \\dots$) be a sequence of RVs(not necessarily independent), and let $a$ be a real number. We say that the sequence $Y_n$ <strong>converges to</strong> $a$ in probability, if for every $\\epsilon \\gt 0$, we have </p>\n<div>$$\n\\lim_{n \\rightarrow \\infty} P(|Y_n - a| \\ge \\epsilon) = 0\n$$</div>\n\n<p>(almost all) of the PMF&#x2F;PDF of $Y_n$, eventually gets concentrated (arbitrarily) close to $a$.</p>\n<h3 id=\"Many-types-of-convergence\"><a href=\"#Many-types-of-convergence\" class=\"headerlink\" title=\"Many types of convergence\"></a>Many types of convergence</h3><p>Deterministic limits: $\\lim_{n\\rightarrow \\infty} a_n &#x3D; a$</p>\n<div>$$\n|a_n - a|\\le \\epsilon, \\forall n \\ge N, \\epsilon \\gt 0\n$$</div>\n\n<p>Convergence in probability: $X_n\\stackrel P{\\rightarrow} X$</p>\n<div>$$\n\\lim_{n \\rightarrow \\infty}P(|X_n - X|\\ge \\epsilon) = 0, \\forall \\epsilon \\gt 0\n$$</div>\n\n<p>(WLLN)</p>\n<p>Convergence in Distribution: $X_n \\stackrel{D}{\\rightarrow} X$</p>\n<div>$$\n\\lim_{n \\rightarrow \\infty} P(X_n \\le x) = P(X \\le x), \\forall x\n$$</div>\n\n<p>For all points of $x$ at which the function $F_X(x) &#x3D; P(X\\le x)$is continuous.</p>\n<p>(CLT)</p>\n<p>Convergence with probability $1$(almost surely): $X_n \\stackrel{\\text{a.s.}}{\\rightarrow} X$</p>\n<div>$$\nP\\left(\\lbrace\\omega\\in \\Omega: \\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\rbrace\\right) = 1\n$$</div>\n\n<p>or </p>\n<div>$$\nP\\left(\\lim_{n\\rightarrow\\infty}X_n(\\omega) =X(\\omega)\\right) = 1\n$$</div>\n\n<p>Lemma:</p>\n<div>$$\nX_n \\stackrel{\\text{a.s.}}{\\rightarrow} X \\Leftrightarrow \\lim_{m \\rightarrow\\infty}P(|X_n - X|\\le \\epsilon, \\forall n \\gt m) = 1, \\forall \\epsilon \\gt 0\\\\\n\\Leftrightarrow P(|X_n - X|\\gt \\epsilon, \\text{i.o.}) = 0, \\forall \\epsilon \\gt 0\n$$</div>\n\n<p>i.o. stand for infinitely often</p>\n<p>(SLLN)</p>\n<p>Convergence in Mean&#x2F;in Norm: $X_n \\stackrel{r}{\\rightarrow}X$</p>\n<p>if $E[X_n^r] \\lt \\infty$ for all $n$ and </p>\n<div>$$\n\\lim_{n \\rightarrow \\infty}E[|X_n - X|^r] = 0\n$$</div>\n\n<p>Relations:</p>\n<div>$$\n\\left(X_n\\stackrel {\\text{a.s.}}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel P{\\rightarrow} X\\right) \\Rightarrow \\left(X_n\\stackrel D{\\rightarrow} X\\right) \\\\\n\\forall r\\ge s\\ge 1, \\left(X_n\\stackrel {r}{\\rightarrow} X\\right) \\Rightarrow\\left(X_n\\stackrel s{\\rightarrow} X\\right)\n$$</div>\n\n<p>The converse assertions fail in general!</p>\n<p>The relation between “almost surely” and “in r-th mean” is complicated. There exist sequences which converge almost surely but<br>not in mean, and which converge in mean but not almost surely!</p>\n<h2 id=\"Central-Limit-Theorem\"><a href=\"#Central-Limit-Theorem\" class=\"headerlink\" title=\"Central Limit Theorem\"></a>Central Limit Theorem</h2><h3 id=\"Theorem\"><a href=\"#Theorem\" class=\"headerlink\" title=\"Theorem\"></a>Theorem</h3><p>Let $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$ and variance $\\sigma^2$. Let </p>\n<div>$$\nZ_n = \\frac{X_1 + X_2 + \\dotsb + X_n - n\\mu}{\\sigma\\sqrt{n}}\n$$</div>\n\n<p>Then</p>\n<div>$$\n\\lim_{n\\rightarrow \\infty}P(Z_n\\le z) = \\Phi (z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^z e^{-\\frac{x^2}{2}}\\mathrm dx\n$$</div>\n\n<p>CDF of $Z_n$ converges to normal CDF(converge in distribution)</p>\n<h3 id=\"Normal-Approximation-Based-on-the-Central-Limit-Theorem\"><a href=\"#Normal-Approximation-Based-on-the-Central-Limit-Theorem\" class=\"headerlink\" title=\"Normal Approximation Based on the Central Limit Theorem\"></a>Normal Approximation Based on the Central Limit Theorem</h3><p>Let $S_n &#x3D; X_1 + \\dotsb + X_n$, where $X_i$ are $\\text{i.i.d.}$ RVs with mean $\\mu$ and variance $\\sigma^2$. If $n$ is large, the probability $P(S_n ≤ c)$ can be approximated by<br>treating $S_n$ as if it were normal, according to the following procedure.</p>\n<ol>\n<li>Calculate the mean $n\\mu$ and the variance $n\\sigma^2$ of $S_n$</li>\n<li>Calculate the normalinzd value $z &#x3D; (c - n\\mu)&#x2F;(\\sigma\\sqrt{n})$</li>\n<li>Use the approxmation</li>\n</ol>\n<div>$$\n    P(S_n \\le c)  \\approx \\Phi(z)\n$$</div>\n\n<p>where $\\Phi(z)$ is available from the standard normal CDF.</p>\n<h3 id=\"Proof\"><a href=\"#Proof\" class=\"headerlink\" title=\"Proof\"></a>Proof</h3><p>Suppose that $X_1, X_2, \\dots$ has mean zero.</p>\n<div>$$\n\\begin{align*}\nM_{Z_n}(s) &= E[e^{sZ_n}]\\\\\n&=E\\left[\\exp\\left(\\frac{s}{\\sigma\\sqrt{n}}\\sum_{i = 1}^n X_i\\right)\\right]\\\\\n&=\\prod_{i = 1}^n E[e^{\\frac{s}{\\sigma\\sqrt{n}}X_i}]\\\\\n&=\\prod_{i = 1}^n M_{X_i}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\\\\n&=\\left(M_{X}\\left(\\frac{s}{\\sigma\\sqrt{n}}\\right)\\right)^n\\\\\n\\end{align*}\n$$</div>\n\n<p>Suppose that the transform $M_X(s)$ has a second order Taylor series expansion around $s&#x3D;0$,</p>\n<div>$$\nM_X(s) = a + bs + cs^2 + o(s^2)\n$$</div>\n\n<p>where $a &#x3D; M_X(0) &#x3D; 1, b &#x3D; M_X’(0) &#x3D; E[X] &#x3D; 0, c &#x3D; \\frac{1}{2}M_X’’(0) &#x3D; \\frac{\\sigma^2}{2}$</p>\n<p>Then</p>\n<div>$$\nM_{Z_n}(s) = \\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n\n$$</div>\n\n<p>As $n\\rightarrow \\infty$, </p>\n<div>$$\n\\lim_{n\\rightarrow \\infty}M_{Z_n}(s) = \\lim_{n\\rightarrow \\infty}\\left(1 + \\frac{s^2}{2n} + o\\left(\\frac{s^2}{n}\\right)\\right)^n = e^{\\frac{s^2}{2}}\n$$</div>\n\n<p>Approxmation on binomial:</p>\n<p>(De Moivre-Laplace Approxmation to the Binomial)</p>\n<div>$$\nP(k \\le S_n \\le l) = P\\left(\\frac{k - np}{\\sqrt{np(1-p)}} \\le \\frac{S_n - np}{\\sqrt{np(1 - p)}} \\le \\frac{l - np}{\\sqrt{np(1 - p)}}\\right)\\\\\n\\approx \\Phi\\left(\\frac{l - np}{\\sqrt{np(1 - p)}}\\right) - \\Phi\\left(\\frac{k - np}{\\sqrt{np(1 - p)}}\\right)\n$$</div>\n\n<h2 id=\"The-Strong-Law-of-Large-Numbers\"><a href=\"#The-Strong-Law-of-Large-Numbers\" class=\"headerlink\" title=\"The Strong Law of Large Numbers\"></a>The Strong Law of Large Numbers</h2><h3 id=\"Theorem-1\"><a href=\"#Theorem-1\" class=\"headerlink\" title=\"Theorem\"></a>Theorem</h3><p>Let $X_1, X_2, \\dots$ be i.i.d. RVs with mean $\\mu$.</p>\n<div>$$\nP(\\lim_{n \\rightarrow\\infty}\\frac{X_1 + \\dots + X_n}{n} = \\mu) = 1.\n$$</div>\n\n<h2 id=\"Borel-Cantelli-lemma-amp-Bernoulli-Process\"><a href=\"#Borel-Cantelli-lemma-amp-Bernoulli-Process\" class=\"headerlink\" title=\"Borel-Cantelli lemma &amp; Bernoulli Process\"></a>Borel-Cantelli lemma &amp; Bernoulli Process</h2><h3 id=\"Limit-of-set-sequence\"><a href=\"#Limit-of-set-sequence\" class=\"headerlink\" title=\"Limit of set sequence\"></a>Limit of set sequence</h3><div>$$\n\\limsup_n A_n = \\bigcap_{n = 1}^\\infty \\bigcup_{k = n}^\\infty A_k\\\\\n\\liminf_n A_n = \\bigcup_{n = 1}^\\infty \\bigcap_{k = n}^\\infty A_k\n$$</div>\n\n<p>If upper limit equals to lower limit, the limit of set sequence exists.</p>\n<div>$$\n\\limsup_n A_n \\supseteq \\liminf_n A_n\\\\\n\\limsup_n A_n = \\liminf_n A_n = \\lim_n A_n\n$$</div>\n\n<p>Upper limit can also be denoted as</p>\n<div>$$\n\\limsup_n A_n = \\{\\omega: \\omega \\in A_n, \\text{i.o.}\\} = \\lbrace A_n, \\text{i.o.}\\rbrace\n$$</div>\n\n<h3 id=\"Borel-Cantelli-Lemma\"><a href=\"#Borel-Cantelli-Lemma\" class=\"headerlink\" title=\"Borel-Cantelli Lemma\"></a>Borel-Cantelli Lemma</h3><p>Let $\\lbrace A_n, n &#x3D; 1, 2, \\dotsb\\rbrace$ be a sequence of events, then</p>\n<div>$$\n\\sum_{n = 1}^\\infty P(A_n)\\lt \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 0\n$$</div>\n\n<p>Let $\\lbrace A_n, n &#x3D; 1, 2, \\dotsb\\rbrace$ be a sequence of <strong>independent</strong> events, then</p>\n<div>$$\n\\sum_{n = 1}^\\infty P(A_n) = \\infty \\xRightarrow{} P(A_n, \\text{i.o.}) = 1\n$$</div>\n\n<h3 id=\"Stochastic-process\"><a href=\"#Stochastic-process\" class=\"headerlink\" title=\"Stochastic process\"></a>Stochastic process</h3><p>A stochastic process is a mathematical model of a probabilistic experiment that evolves in time and generates a sequence of<br>numerical values.</p>\n<ul>\n<li>Bernoulli process(memoryless, discrete time)</li>\n<li>Poisson process(memoryless, continuous time)</li>\n</ul>\n<h3 id=\"The-Bernoulli-Process\"><a href=\"#The-Bernoulli-Process\" class=\"headerlink\" title=\"The Bernoulli Process\"></a><strong>The Bernoulli Process</strong></h3><p>is a sequence of independent Bernoulli trials, each with probability of success $p$.</p>\n<div>$$\nP(\\text{success}) = P(X_i = 1) = p\\\\\nP(\\text{failure}) = P(X_i = 0) = 1 - p\n$$</div>\n\n<p><strong>Independence property</strong>: For any given time $n$, the sequence of $X_{n + 1}, X_{n + 2}, \\dots$ is also a Bernoulli process, and is independent from $X_1, \\dots, X_n$</p>\n<p><strong>Memoryless property</strong>: Let $n$ be a given time and let $\\overline T$ be the time of the first success after<br>time $n$. Then $\\overline T − n$ has a geometric distribution with parameter $p$,<br>and is independent of the RVs $X_1, \\dots , X_n$.</p>\n<div>$$\nP(\\overline T - n = t | \\overline T \\gt n) = (1 - p)^{t - 1}p = P(T = t)\n$$</div>\n\n<p><strong>Interarrival times</strong></p>\n<p>Denote the $k$th success as $Y_k$, the $k$th interarrival time as $T_k$.</p>\n<div>$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$</div>\n\n<p>represents the number of trials following the $(k - 1)$th success until the next success.</p>\n<p>Note that</p>\n<div>$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$</div>\n\n<p>Alternative description of the Bernoulli process: </p>\n<ul>\n<li>Start with a sequence of independent geometric RVs $T_1, T_2, \\dots$ with common parameter p, and let these stand for the interarrival times.</li>\n<li>Record a success at times $T_1$, $T_1 + T_2$, etc.</li>\n</ul>\n<div>$$\nE[Y_k] = \\frac{k}{p}\\\\\n\\text{var}(Y_k) = \\frac{k(1 - p)}{p^2}\n$$</div>\n\n<div>$$\np_{Y_k}(t) = \\binom{t - 1}{k - 1}p^k(1 - p)^{t - k}\n$$</div>\n\n<p><strong>Splitting of a Bernoulli process</strong></p>\n<p>Whenever there is an arrival, we choose to either keep it (with probability $q$), or to discard it (with probability $1 − q$).</p>\n<p>Both the process of arrivals that are kept and the process of discarded arrivals are Bernoulli processes, with success probability $pq$ and $p(1 − q)$, respectively, at each time.</p>\n<p><strong>Merging of a Bernoulli process</strong></p>\n<p>In a reverse situation, we start with two independent Bernoulli processes (with parameters $p$ and $q$ respectively). An arrival is<br>recorded in the merged process if and only if there is an arrival in at least one of the two original processes.</p>\n<p>The merged process is Bernoulli, with success probability $p+q−pq$ at each time step.</p>\n<h2 id=\"The-Poisson-Process\"><a href=\"#The-Poisson-Process\" class=\"headerlink\" title=\"The Poisson Process\"></a>The Poisson Process</h2><h3 id=\"Definition-1\"><a href=\"#Definition-1\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><p>An arrival process is called a Poisson process with rate $λ$ if it has the following properties:</p>\n<p><strong>Time homogenity</strong></p>\n<div>$$\nP(k, \\tau) = P(k \\text{ arrivals in interval of duration }\\tau)\n$$</div>\n\n<p><strong>Independence</strong></p>\n<p>Numbers of arrivals in disjoint time intervals are independent.</p>\n<p><strong>Small interval probabilities</strong></p>\n<div>$$\n\\begin{cases}\n    1 - \\lambda\\tau + o(\\tau), & \\text{if } k = 0,\\\\\n    \\lambda\\tau + o_1(\\tau), & \\text{if } k = 1,\\\\\n    o_k(\\tau), & \\text{if } k > 1.\n\\end{cases}\n$$</div>\n\n<h3 id=\"Bernoulli-x2F-Poisson-Relation\"><a href=\"#Bernoulli-x2F-Poisson-Relation\" class=\"headerlink\" title=\"Bernoulli&#x2F;Poisson Relation\"></a>Bernoulli&#x2F;Poisson Relation</h3><p>In a short time interval $\\delta$</p>\n<div>$$\nn = t / \\delta\\\\\np = \\lambda\\delta\\\\\nnp = \\lambda t\n$$</div>\n\n<p>For binomial PMF $p_S(k;n,p)$,</p>\n<div>$$\n\\lim_{n\\rightarrow \\infty}p_S(k;n, p) = \\lim_{n\\rightarrow\\infty}\\frac{n!}{(n - k)!k!}p^k(1 - p)^{n - k} = \\frac{(\\lambda t)^k}{k!}e^{-\\lambda t} = P(k, t)\n$$</div>\n\n<h3 id=\"PMF-of-Number-of-Arrivals-N\"><a href=\"#PMF-of-Number-of-Arrivals-N\" class=\"headerlink\" title=\"PMF of Number of Arrivals $N$\"></a>PMF of Number of Arrivals $N$</h3><div>$$\nP(k, \\tau) = \\frac{(\\lambda\\tau)^ke^{-\\lambda\\tau}}{k!}\n$$</div>\n\n<div>$$\nE[N_t] = \\lambda t\\\\\n\\text{var}(N_t) = \\lambda t\n$$</div>\n\n<h3 id=\"Time-T-of-the-first-arrival\"><a href=\"#Time-T-of-the-first-arrival\" class=\"headerlink\" title=\"Time $T$ of the first arrival\"></a>Time $T$ of the first arrival</h3><div>$$\nF_T(t) = P(T \\le t) = 1 - P(T \\gt t) = 1 - e^{-\\lambda t}, t\\ge 0\\\\\nf_T(t) = \\lambda e^{-\\lambda t}, t\\ge 0\n$$</div>\n\n<p><strong>Memoryless property</strong> The  time to next arrival is independent of the past.</p>\n<h3 id=\"Interarrival-times\"><a href=\"#Interarrival-times\" class=\"headerlink\" title=\"Interarrival times\"></a>Interarrival times</h3><p>We also denote the time of the kth success as $Y_k$, and denote the<br>kth interarrival time as $T_k$. That is,</p>\n<div>$$\nT_1 = Y_1, T_k = Y_k - Y_{k - 1}, k = 2, 3, \\dots\n$$</div>\n\n<p>Note that</p>\n<div>$$\nY_k = T_1 + T_2 + \\dotsb + T_k\n$$</div>\n\n<div>$$\nf_{Y_k}(y) = \\frac{\\lambda^ky^{k-1}e^{-\\lambda y}}{(k - 1)!}, y\\ge 0\n$$</div>\n\n<h3 id=\"Merging-Poisson-Processes\"><a href=\"#Merging-Poisson-Processes\" class=\"headerlink\" title=\"Merging Poisson Processes\"></a>Merging Poisson Processes</h3><p><img src=\"/../images/prob/L14_1.jpg\"></p>\n<div>$$\nP(\\text{Arrival is red} | \\text{1 arrival})\\approx \\frac{\\lambda_1\\delta}{(\\lambda_1 + \\lambda_2) \\delta}\n$$</div>\n\n<p><img src=\"/../images/prob/L15_1.jpg\"></p>\n"},{"title":"Python-OJ","katex":true,"date":"2023-10-09T04:49:57.000Z","_content":"\n## idea\n\npython语言以其时间性能和空间性能低下著称，在各类 OJ 竞赛中尤为劣势。因此，优化 python 语言的空间和时间成为了一种可以研究的技巧（）\n\n* 使用 python 练习 Codeforce 最新赛题\n* 比较 test case 的通过时间，从而得出优化结论\n\n### 解释器的选择\n\nCodeforce 官网称，采用 PyPy 运行 python 代码的速度远快于原生 python 解释器。\n\n《much faster》\n\n![alt](../images/oj/1.jpg)\n\n建议一个不快就换另一个\n\n### python 时间优化技巧\n\n**list.pop()很占用时间**\n\n赛题为 `Codeforces Round 902 (Div. 1, based on COMPFEST 15 - Final Round)`\n\n优化前的代码：\n\n~~~python\ndef single(n, p, a, b):\n    all_len = n\n    person_list = list(range(all_len))\n    person_list.sort(key=lambda x:b[x])\n    cost = p\n    informed_len = 1\n    while informed_len < all_len:\n        index = person_list.pop(0)\n        item_a = a[index]\n        item_b = b[index]\n        if item_b < p:\n            if item_a < all_len - informed_len:\n                # continue\n                informed_len += item_a\n                cost += item_a * item_b\n            else:\n                # end\n                rest_len = all_len - informed_len\n                cost += rest_len * item_b\n                break\n        else:\n            rest_len = all_len - informed_len\n            cost += rest_len * p\n            break\n\n    return cost\n~~~\n\n结局：`Test: #8, time: 1000 ms., memory: 12104 KB, exit code: -1, checker exit code: 0, verdict: TIME_LIMIT_EXCEEDED`\n\n优化后的代码：\n\n~~~python\ndef single(n, p, a, b):\n    all_len = n\n    person_list = list(range(all_len))\n    person_list.sort(key=lambda x:b[x])\n    cost = p\n    informed_len = 1\n    front = 0\n    while informed_len < all_len:\n        index = person_list[front]\n        item_a = a[index]\n        item_b = b[index]\n        if item_b < p:\n            if item_a < all_len - informed_len:\n                # continue\n                informed_len += item_a\n                cost += item_a * item_b\n            else:\n                # end\n                rest_len = all_len - informed_len\n                cost += rest_len * item_b\n                break\n        else:\n            # end\n            rest_len = all_len - informed_len\n            cost += rest_len * p\n            break\n        front += 1\n\n    return cost\n~~~\n\n结局：`Accepted`。在 test #8上：`Test: #8, time: 171 ms., memory: 12140 KB, exit code: 0, checker exit code: 0, verdict: OK`\n\npop会删除列表的元素，因此需要多余的时间。故采用下标记录列表的顶层元素更节约时间。\n\n","source":"_posts/Python-OJ.md","raw":"---\ntitle: Python-OJ\nkatex: true\ndate: 2023-10-09 12:49:57\ntags:\n---\n\n## idea\n\npython语言以其时间性能和空间性能低下著称，在各类 OJ 竞赛中尤为劣势。因此，优化 python 语言的空间和时间成为了一种可以研究的技巧（）\n\n* 使用 python 练习 Codeforce 最新赛题\n* 比较 test case 的通过时间，从而得出优化结论\n\n### 解释器的选择\n\nCodeforce 官网称，采用 PyPy 运行 python 代码的速度远快于原生 python 解释器。\n\n《much faster》\n\n![alt](../images/oj/1.jpg)\n\n建议一个不快就换另一个\n\n### python 时间优化技巧\n\n**list.pop()很占用时间**\n\n赛题为 `Codeforces Round 902 (Div. 1, based on COMPFEST 15 - Final Round)`\n\n优化前的代码：\n\n~~~python\ndef single(n, p, a, b):\n    all_len = n\n    person_list = list(range(all_len))\n    person_list.sort(key=lambda x:b[x])\n    cost = p\n    informed_len = 1\n    while informed_len < all_len:\n        index = person_list.pop(0)\n        item_a = a[index]\n        item_b = b[index]\n        if item_b < p:\n            if item_a < all_len - informed_len:\n                # continue\n                informed_len += item_a\n                cost += item_a * item_b\n            else:\n                # end\n                rest_len = all_len - informed_len\n                cost += rest_len * item_b\n                break\n        else:\n            rest_len = all_len - informed_len\n            cost += rest_len * p\n            break\n\n    return cost\n~~~\n\n结局：`Test: #8, time: 1000 ms., memory: 12104 KB, exit code: -1, checker exit code: 0, verdict: TIME_LIMIT_EXCEEDED`\n\n优化后的代码：\n\n~~~python\ndef single(n, p, a, b):\n    all_len = n\n    person_list = list(range(all_len))\n    person_list.sort(key=lambda x:b[x])\n    cost = p\n    informed_len = 1\n    front = 0\n    while informed_len < all_len:\n        index = person_list[front]\n        item_a = a[index]\n        item_b = b[index]\n        if item_b < p:\n            if item_a < all_len - informed_len:\n                # continue\n                informed_len += item_a\n                cost += item_a * item_b\n            else:\n                # end\n                rest_len = all_len - informed_len\n                cost += rest_len * item_b\n                break\n        else:\n            # end\n            rest_len = all_len - informed_len\n            cost += rest_len * p\n            break\n        front += 1\n\n    return cost\n~~~\n\n结局：`Accepted`。在 test #8上：`Test: #8, time: 171 ms., memory: 12140 KB, exit code: 0, checker exit code: 0, verdict: OK`\n\npop会删除列表的元素，因此需要多余的时间。故采用下标记录列表的顶层元素更节约时间。\n\n","slug":"Python-OJ","published":1,"updated":"2024-03-19T06:01:16.160Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhu0008rsugg7ji2vs2","content":"<h2 id=\"idea\"><a href=\"#idea\" class=\"headerlink\" title=\"idea\"></a>idea</h2><p>python语言以其时间性能和空间性能低下著称，在各类 OJ 竞赛中尤为劣势。因此，优化 python 语言的空间和时间成为了一种可以研究的技巧（）</p>\n<ul>\n<li>使用 python 练习 Codeforce 最新赛题</li>\n<li>比较 test case 的通过时间，从而得出优化结论</li>\n</ul>\n<h3 id=\"解释器的选择\"><a href=\"#解释器的选择\" class=\"headerlink\" title=\"解释器的选择\"></a>解释器的选择</h3><p>Codeforce 官网称，采用 PyPy 运行 python 代码的速度远快于原生 python 解释器。</p>\n<p>《much faster》</p>\n<p><img src=\"/../images/oj/1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>建议一个不快就换另一个</p>\n<h3 id=\"python-时间优化技巧\"><a href=\"#python-时间优化技巧\" class=\"headerlink\" title=\"python 时间优化技巧\"></a>python 时间优化技巧</h3><p><strong>list.pop()很占用时间</strong></p>\n<p>赛题为 <code>Codeforces Round 902 (Div. 1, based on COMPFEST 15 - Final Round)</code></p>\n<p>优化前的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">single</span>(<span class=\"params\">n, p, a, b</span>):</span><br><span class=\"line\">    all_len = n</span><br><span class=\"line\">    person_list = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(all_len))</span><br><span class=\"line\">    person_list.sort(key=<span class=\"keyword\">lambda</span> x:b[x])</span><br><span class=\"line\">    cost = p</span><br><span class=\"line\">    informed_len = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> informed_len &lt; all_len:</span><br><span class=\"line\">        index = person_list.pop(<span class=\"number\">0</span>)</span><br><span class=\"line\">        item_a = a[index]</span><br><span class=\"line\">        item_b = b[index]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> item_b &lt; p:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> item_a &lt; all_len - informed_len:</span><br><span class=\"line\">                <span class=\"comment\"># continue</span></span><br><span class=\"line\">                informed_len += item_a</span><br><span class=\"line\">                cost += item_a * item_b</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># end</span></span><br><span class=\"line\">                rest_len = all_len - informed_len</span><br><span class=\"line\">                cost += rest_len * item_b</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            rest_len = all_len - informed_len</span><br><span class=\"line\">            cost += rest_len * p</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> cost</span><br></pre></td></tr></table></figure>\n\n<p>结局：<code>Test: #8, time: 1000 ms., memory: 12104 KB, exit code: -1, checker exit code: 0, verdict: TIME_LIMIT_EXCEEDED</code></p>\n<p>优化后的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">single</span>(<span class=\"params\">n, p, a, b</span>):</span><br><span class=\"line\">    all_len = n</span><br><span class=\"line\">    person_list = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(all_len))</span><br><span class=\"line\">    person_list.sort(key=<span class=\"keyword\">lambda</span> x:b[x])</span><br><span class=\"line\">    cost = p</span><br><span class=\"line\">    informed_len = <span class=\"number\">1</span></span><br><span class=\"line\">    front = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> informed_len &lt; all_len:</span><br><span class=\"line\">        index = person_list[front]</span><br><span class=\"line\">        item_a = a[index]</span><br><span class=\"line\">        item_b = b[index]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> item_b &lt; p:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> item_a &lt; all_len - informed_len:</span><br><span class=\"line\">                <span class=\"comment\"># continue</span></span><br><span class=\"line\">                informed_len += item_a</span><br><span class=\"line\">                cost += item_a * item_b</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># end</span></span><br><span class=\"line\">                rest_len = all_len - informed_len</span><br><span class=\"line\">                cost += rest_len * item_b</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># end</span></span><br><span class=\"line\">            rest_len = all_len - informed_len</span><br><span class=\"line\">            cost += rest_len * p</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        front += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> cost</span><br></pre></td></tr></table></figure>\n\n<p>结局：<code>Accepted</code>。在 test #8上：<code>Test: #8, time: 171 ms., memory: 12140 KB, exit code: 0, checker exit code: 0, verdict: OK</code></p>\n<p>pop会删除列表的元素，因此需要多余的时间。故采用下标记录列表的顶层元素更节约时间。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"idea\"><a href=\"#idea\" class=\"headerlink\" title=\"idea\"></a>idea</h2><p>python语言以其时间性能和空间性能低下著称，在各类 OJ 竞赛中尤为劣势。因此，优化 python 语言的空间和时间成为了一种可以研究的技巧（）</p>\n<ul>\n<li>使用 python 练习 Codeforce 最新赛题</li>\n<li>比较 test case 的通过时间，从而得出优化结论</li>\n</ul>\n<h3 id=\"解释器的选择\"><a href=\"#解释器的选择\" class=\"headerlink\" title=\"解释器的选择\"></a>解释器的选择</h3><p>Codeforce 官网称，采用 PyPy 运行 python 代码的速度远快于原生 python 解释器。</p>\n<p>《much faster》</p>\n<p><img src=\"/../images/oj/1.jpg\" alt=\"alt\"></p>\n<p>建议一个不快就换另一个</p>\n<h3 id=\"python-时间优化技巧\"><a href=\"#python-时间优化技巧\" class=\"headerlink\" title=\"python 时间优化技巧\"></a>python 时间优化技巧</h3><p><strong>list.pop()很占用时间</strong></p>\n<p>赛题为 <code>Codeforces Round 902 (Div. 1, based on COMPFEST 15 - Final Round)</code></p>\n<p>优化前的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">single</span>(<span class=\"params\">n, p, a, b</span>):</span><br><span class=\"line\">    all_len = n</span><br><span class=\"line\">    person_list = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(all_len))</span><br><span class=\"line\">    person_list.sort(key=<span class=\"keyword\">lambda</span> x:b[x])</span><br><span class=\"line\">    cost = p</span><br><span class=\"line\">    informed_len = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> informed_len &lt; all_len:</span><br><span class=\"line\">        index = person_list.pop(<span class=\"number\">0</span>)</span><br><span class=\"line\">        item_a = a[index]</span><br><span class=\"line\">        item_b = b[index]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> item_b &lt; p:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> item_a &lt; all_len - informed_len:</span><br><span class=\"line\">                <span class=\"comment\"># continue</span></span><br><span class=\"line\">                informed_len += item_a</span><br><span class=\"line\">                cost += item_a * item_b</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># end</span></span><br><span class=\"line\">                rest_len = all_len - informed_len</span><br><span class=\"line\">                cost += rest_len * item_b</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            rest_len = all_len - informed_len</span><br><span class=\"line\">            cost += rest_len * p</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> cost</span><br></pre></td></tr></table></figure>\n\n<p>结局：<code>Test: #8, time: 1000 ms., memory: 12104 KB, exit code: -1, checker exit code: 0, verdict: TIME_LIMIT_EXCEEDED</code></p>\n<p>优化后的代码：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">single</span>(<span class=\"params\">n, p, a, b</span>):</span><br><span class=\"line\">    all_len = n</span><br><span class=\"line\">    person_list = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(all_len))</span><br><span class=\"line\">    person_list.sort(key=<span class=\"keyword\">lambda</span> x:b[x])</span><br><span class=\"line\">    cost = p</span><br><span class=\"line\">    informed_len = <span class=\"number\">1</span></span><br><span class=\"line\">    front = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> informed_len &lt; all_len:</span><br><span class=\"line\">        index = person_list[front]</span><br><span class=\"line\">        item_a = a[index]</span><br><span class=\"line\">        item_b = b[index]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> item_b &lt; p:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> item_a &lt; all_len - informed_len:</span><br><span class=\"line\">                <span class=\"comment\"># continue</span></span><br><span class=\"line\">                informed_len += item_a</span><br><span class=\"line\">                cost += item_a * item_b</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                <span class=\"comment\"># end</span></span><br><span class=\"line\">                rest_len = all_len - informed_len</span><br><span class=\"line\">                cost += rest_len * item_b</span><br><span class=\"line\">                <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"comment\"># end</span></span><br><span class=\"line\">            rest_len = all_len - informed_len</span><br><span class=\"line\">            cost += rest_len * p</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        front += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> cost</span><br></pre></td></tr></table></figure>\n\n<p>结局：<code>Accepted</code>。在 test #8上：<code>Test: #8, time: 171 ms., memory: 12140 KB, exit code: 0, checker exit code: 0, verdict: OK</code></p>\n<p>pop会删除列表的元素，因此需要多余的时间。故采用下标记录列表的顶层元素更节约时间。</p>\n"},{"title":"大雾笔记","date":"2022-09-14T09:20:10.000Z","katex":true,"_content":"\n# 参考教材\n\n嫌教材太简单可以看看\n\n《热学》lhf例题很多，很详细，很多数学比教材难\n\n《》\n\n《新概念物理教程-力学》新颖，比较硬核。\n\n《费恩曼物理学讲义》\n\n《新概念物理教程-光学》公认最好教材\n\n《光学》chb, lyp\n\n量子物理没有太好的参考书。\n\n《原子物理学》杨福家编。现在没有原子物理了，只有量子物理。有时用经典方法，有时候用量子物理的方法。前几章和教材一致，实验讲得不错。\n\n量子力学教程。周世勋。内容有点少。\n\n《费恩曼物理学讲义》第3卷。相当有深度（量子物理）。\n\n*Phyisics* Vol.1 & 2。难度介于大学物理学和物理系教材之间。\n\n\n\n### 杂项\n\n牛顿运动方程一般个数少，微分阶数高；哈密顿正则方程一般个数多，微分阶数低。\n\n# 热学\n\n## 温度\n\n分子动理论：热学中比较古老的理论。\n\n教材中关于统计物理的内容不够透彻。\n\n建议学习分析力学（重点：哈密顿力学），对后续量子力学有帮助。固体物理也会使用相关技巧。哈密顿量，相空间，拉格朗日方程。不用看证明，能用就行。\n\n\n\n### 热学研究内容与对象\n\n内容：与热现象有关的性质和规律。\n\n热现象：宏观上与温度有关，微观上与分子热运动有关。\n\n对象：大量微观粒子构成的体积有限的物体-热力学系统。（量大：统计学规律。）\n\n经常讨论系统和外界（环境）。一种说法：宇宙是不是热力学系统？不是，因为宇宙之外没有外界。所以热二定律可能不适用于整个宇宙。\n\n孤立系统：与外界没有任何相互作用。\n\n绝热系统：有功的交换，没有热量交换\n\n封闭系统：有能量交换，无粒子交换\n\n开放系统：既有能量交换，也有粒子交换\n\n### 热力学的研究方法\n\n#### 热力学\n\n宏观理论方法。依赖于实验。不涉及物质的微观结构和微观运动规律。具有极大的普遍性，可靠性。\n\n#### 统计物理学\n\n微观理论方法。从微观模型假设出发，力学 + 统计理论建立微观量和宏观量的关系。可解释本质，但是受模型局限。\n\n### 几个重要概念\n\n#### 平衡态\n\n热力学系统内部，宏观上不存在能量和粒子的流动，系统宏观性质不随时间变化。（体积、压强、温度）\n\n热力学平衡条件：\n\n力学平衡条件：若系统与外界有力学作用，平衡时内外压强相等。\n\n热平衡条件：若系统与外界可交换热量，平衡时内外温度应相等。\n\n相平衡条件：若系统与外界处于不同相的共存状态，平衡时要达到力学平衡、热平衡以及相平衡。\n\n化学平衡条件：浓度不同的系统混到一起，平衡时要满足上面三个条件，并且浓度均匀。\n\n注意区分平衡态和稳定态：\n\n![../images/pht.png]\n\n#### 宏观量\n\n描述系统宏观性质的量。可直接测量。\n\n广延量：有累加性。如M, V, E...\n\n强度量：无累加性。如p, T...\n\n#### 微观量\n\n描述微观粒子性质的量。需要间接测量。\n\n如分子的m, v, d...\n\n#### 状态参量\n\n描述系统平衡态及其宏观性质的物理量。\n\np, V, T, v, 内能E, 熵S, 焓H\n\n一组态参量对应一个平衡态。\n\n实验表明：状态参量之间不是相互独立的。\n\n常选p, V, T作为自变量，其他的当作函数（E, S, H）-热力学函数。\n\n对物质量确定的单元（单一组元，不能由多种物质混合）单相（同一种状态，不能有固液同时存在等等）系统，p, V, T只有两个是独立的：T(p, V), E(p, V)。\n\n统计物理：状态参量之间的偏导数关系。\n\n#### 物态方程\n\n两个最基本的热力学函数之一（物态方程和内能）。态参量之间的函数关系: f(T, p, V) = 0\n\n通过测量确定。\n\n理想气体物态方程：\n\n$pV = νRT$\n\n$p = nkT$\n\n$k = \\frac{R}{N_A}$\n\n$\\nu$ 气体摩尔数\n\n$k$ 玻尔兹曼常量\n\n### 温度\n\n#### 热平衡态\n\n两个系统长时间热接触达到的共同平衡态。\n\n#### 热力学第零定律\n\n实验表明： A与C热平衡，B与C热平衡，A和B也必然保持热平衡。\n\n非热接触的两个系统也可以处在同一个热平衡态。\n\n温度：处于同一热平衡态下的热力学系统所具有的共同的宏观性质。\n\n处在同一热平衡态的系统具有相同的温度。\n\n#### 温标\n\n理想气体温标；用理想气体做测温物质。单位: $K$(Kelvin)， 范围适用 $> 0.5K$\n\n实验表明：一定质量的理想气体在同一个热平衡态下，$pV$不变。\n\n规定$T \\propto pV$，水的三相点温度为$T_3 = 273.16K$\n\n$$T = T_3\\frac{pV}{p_3V_3} = 273.16\\frac{pV}{p_3V_3}$$\n\n热力学温标$T$：理论温标，与物质无关。\n\n单位: $K$，适用于所有温度范围，在理想气体温标范围内与理气温标一致。\n\n### 统计物理学的观点、概念简介\n\n统计物理学包括平衡态统计理论，非平衡态统计理论和涨落理论。它从物质的微观结构和微观运动来阐明物质的宏观性质。其基本观点：\n\n- 宏观物体由大量的微观粒子（原子、分子、电子、光子等）构成。\n- 微观粒子的运动服从力学规律。原则上说服从量子力学规律，一定条件下可以用经典力学处理。\n- 从微观角度看，物体以一定的概率出现在各个微观状态上，物质的宏观性质就是物质微观性质的统计平均。宏观量是有关微观量的统计平均值。\n\n#### 近独立子系统\n\n构成系统的粒子间相互作用很弱，系统能量近似等于各粒子能量总和，如理想气体。\n\n#### 微观状态（力学运动状态）\n\n##### 经典力学描述\n\n常采用正则形式，即广义坐标和广义动量描述。\n\n- 子相空间（μ空间）：由粒子的广义坐标$q_i$和广义动量$p_i$（$i = 1, \\dots, r$, $r$是粒子自由度）构成的2r维空间。\n\n  1组$(q_1, \\dots, q_r, p_1, \\dots, p_r)$的取值表示粒子的1个微观状态，对应于子相空间的一个点。\n\n  更确切的说，在子相空间 $( q_1,... , q_r , p_1,..., p_r )$位置处的体积元 $d q_1...d q_r dp_1...dp_r$中的点，都是由$( q_1,... , q_r , p_1,..., p_r )$描述的相同的粒子微观状态。\n\n  位形空间（坐标构成的空间），速度空间（速度构成的空间）。\n\n  傅里叶变换和傅里叶级数的区别：一个离散，一个连续。\n\n- 系统的微观状态是由所有粒子的广义坐标和广义动量描述的。\n\n##### 量子力学描述\n\n量子力学中假设运动状态用量子态描述。\n\n- 粒子的微观状态用单粒子（量子）态描述。\n\n  单粒子态由一组量子数描述：如 $|n, l, m_l, m_s >$ 。 1 组取值确定的$ |n, l, m_l, m_s > $表示 1 个单粒子态。 当粒子状态是由某个单粒子态描述时，称为粒子处于某个单粒子态，或粒子占据某个单粒子态\n\n- 系统微观状态用多粒子（量子）态描述。\n\n  对近独立子系统，多粒子态可由单粒子态表示： 系统所有粒子的 1 组单粒子占据态就表示系统的 1 个 多粒子态，即表示系统的 1 个 微观状态。\n\n微观粒子全同性原理\n\n全同粒子：内禀属性如质量、电荷、自旋等相同 \n\n微观粒子全同性原理是量子力学假设。 \n\n全同性原理：对全同粒子组成的系统，交换任意 2个全同粒子，系统微观状态不变。\n\n泡利不相容原理：对全同费米子系统，不能有两个及以上的费米子占据同一单粒子态。\n\n费米子：自旋为半整数；玻色子：自旋为整数。\n\n#### 宏观状态和微观状态的关系\n\n系统的宏观状态由宏观量表征，如 E、N、V。 \n\n系统的微观状态，如果用经典描述，则由所有粒子 的坐标和动量表征。 \n\n玻耳兹曼认为：从微观上看，对于一个系统的状态 的宏观描述是非常不完善的，系统的同一个宏观状 态实际上可能对应于非常非常多的微观状态，而这 些微观状态是粗略的宏观描述所不能加以区别的。\n\n 这意味着宏观状态和微观状态、宏观量和微观量具 有内在联系，这种联系是种统计关系。\n\n#### 统计规律性\n\n统计物理发展早期，人们普遍认为：研究物体宏观 性质，应从求解粒子的力学运动方程出发来解决。 但由于粒子数太多，求解力学方程困难，迫不得已 得引入统计方法。而且这个统计是：宏观量是相应 微观量的长时间平均。 即原则上力学规律可完全决定物体宏观性质  \n\n这种观点无法解释根本问题：热现象的不可逆性。 因为把力学运动方程（牛顿方程或薛定谔方程）用 到微观粒子，是时间反演对称的 — 可逆的。\n\n这表明仅通过力学规律来解释物体的宏观性质是 不可能的，而有赖于新的规律 — 统计规律。\n\n\n\n力学规律是决定论性的，可表述为：在一定初始 条件下，某时刻系统必然处于一确定的运动状态。 \n\n统计规律可以表述为：在一定的宏观条件下，某 时刻系统以一定的概率处于某一微观状态。 \n\n即宏观状态与微观状态之间的联系是概率性的， 具有统计规律的特性，而不是决定论性的。\n\n统计规律的稳定性：只要 N 足够大，每次得到的分布几乎相同\n\n统计规律的涨落：每次实验中得到的比例 Ni /N 稍有差别。N 越大，涨落越小。\n\n即对变量是离散取值的情况，直接采用概率， 对变量是连续取值的情况，需要引入概率密度。\n\n热现象本质是统计规律的反映。\n\n##### 平衡态统计理论的基本假设：等概率原理 \n\n处于平衡态下的孤立系统，系统各个可能的微观 状态出现的概率相等。 “可能的微观状态”是指孤立系统的宏观条件所 允许的那些微观状态，即这些微观状态对应于给 定的 E、V、N\n\n##### 平衡态下近独立子系统的统计规律 \n\n处于平衡态下的热力学系统，宏观状态不变，但 相应的微观状态不断变化，是一种动态平衡。 根据等概率原理，平衡态包含的微观状态数目是 最多的 — 最概然态\n\n求统计分布函数：对于每个统计分布函数，可以计算它们对应的微观态数目（微观态数目是统计分布函数的函数）。在E, N不变的条件下，只要找到对应微观态数目最多的统计分布函数，就是平衡态的统计分布函数。\n\n对近独立子系统，采用经典力学及等概率原理只能得到一种经典统计：麦克斯韦-玻尔兹曼统计；采用量子力学及等概率原理得到3种统计：麦克斯韦-玻尔兹曼统计，费米-狄拉克统计，玻色-爱因斯坦统计。\n\n造成 3 种量子统计规律的原因是微观粒子的全同性原理和泡利不相容原理。\n\n麦克斯韦-玻尔兹曼统计适用于定域子系统，费米 - 狄拉克统计、玻色 - 爱因斯坦统计适用于非定域 子系统。\n\n 定域：全同粒子系统中的粒子的波包局限在空间 一定范围内，之间没有重叠，全同性原理 不起作用，可以通过位置分辨粒子。\n\n 经典的和量子的麦克斯韦-玻尔兹曼统计在数学形 式上一致。而在一定条件下，量子的 3 种统计都可 退化为经典的麦克斯韦-玻尔兹曼统计\n\n## 气体动理论\n\n#### 气体动理论的基本观点\n\n气体动理论（分子动理论），发展于 19 世纪下半 期，基于经典理论，是统计物理学的原型，被不断 补充发展完善成为统计物理学，其所得的结论可通 过统计物理得到。至今仍在诸多领域有重要应用。\n\n1. 宏观物体是由大量分子、原子构成的，分子间 存在一定的间隙。\n1. 分子永不停息地作无规则运动 — 热运动\n1.  分子间存在一定的相互作用。\n\n### 理想气体的压强\n\n##### 关于理想气体的假设\n\n###### 单个分子服从的力学规律\n\n理想气体模型：\n\n大小：分子线度<<分子间平均距离\n\n分子力：除碰撞的瞬间，在分子间、分子与器壁间无作用力\n\n碰撞性质：弹性碰撞\n\n服从规律：牛顿力学\n\n###### 大量分子处于平衡态时的统计假设\n\n（1）无外场时，分子在各处出现的概率相同\n$$n = \\frac{\\mathrm d N}{\\mathrm d V} = \\frac NV = \\text{const}.$$\n（2）由于碰撞，分子可以有各种不同速度\n\n速度取向各方向等概率：\n$$\\bar{v_x} = \\bar{v_y} = \\bar{v_z} = 0\\\\\\\\\\bar{v_x^2} = \\bar{v_y^2} = \\bar{v_z^2} = \\frac 13 \\bar{v^2}$$\n\n##### 理想气体压强公式\n\n前提：平衡态，忽略重力，分子当成质点\n$$p = \\frac13nm\\bar{v^2} = \\frac23n\\bar\\varepsilon_t, \\\\\\\\\\bar\\varepsilon_t = \\frac12 mv^2$$\n\n### 温度的统计意义\n\n$$\\bar\\varepsilon_t = \\frac{3p}{2n} = \\frac{3nkT}{2n} = \\frac32kT\\\\\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}{M}}$$\n\n$T = 273K$, \n\n$\\bar{\\varepsilon}_t$数量级：$10^{-2}$eV\n\n$\\sqrt{\\bar{v^2}}$\n\n$H_2$: $1.84\\times 10^3m/s$\n\n$O2$: $4.61\\times 10^2m/s$\n\n### 能量均分定理\n\n自由度：决定物体空间位置的独立坐标数，用$i$表示\n\n##### 单原子分子\n\n平动自由度:$t = 3$ \n\n$i = 3$\n\n##### 双原子分子\n\n质心平动：$t = 3$\n\n轴取向：$r = 2$\n\n距离变化：$v = 1$\n\n总自由度: $i = 6$\n\n##### 多原子分子\n\n设分子包含$N$个原子\n\n$i = 3N$\n\n$t = 3$\n\n$r = 3$\n\n$v = 3N-6$\n\n##### 能量均分定理\n\n一个平动自由度对应的平均动能为$\\frac12kT$\n\n考虑平动、振动和转动，由于分子的碰撞，分子平均动能均匀分配到每个自由度上。\n\n在温度$T$的平衡态下，分子热运动的每个自由度对应的平均动能都等于$\\frac12kT$。\n\n\n\n普遍的能量均分定理：\n\n分子能量中每具有一个平方项，就对应一个$\\frac12kT$的平均能量。\n\n分子振动的动能和势能都是平方项，所以：\n\n$\\bar\\varepsilon_{vP} = \\bar\\varepsilon_{vk} = v\\frac12kT$,  $\\bar\\varepsilon_v = \\bar\\varepsilon_{vP}  + \\bar\\varepsilon_{vk} = vkT$\n$$\\bar\\varepsilon = \\bar\\varepsilon _t + \\bar\\varepsilon_r + \\bar\\varepsilon_v = (t + r + 2v)\\frac12kT$$\n通常情况下($T < 10^3K$)，振动自由度被“冻结”，分子可视为刚性\n\n刚性分子：$v = 0, i = t + r$\n$$\\bar\\varepsilon = \\frac{t+ r}2kT$$\n\n##### 理想气体内能\n\n内能：系统内部各种形式能量的总和，不包括系统整体质心运动的能量\n\n分子内部： $\\bar\\varepsilon = (t + r + 2v)\\frac12kT$\n\n分子之间：相互作用势能$\\varepsilon_{\\mathrm pij}$\n\n内能：$E = N\\bar\\varepsilon + \\sum_i\\sum_{j<i}\\varepsilon_{\\mathrm pij} = E(T, V)$\n\n理想气体： $\\varepsilon_{\\mathrm pij} = 0,E = E(T)$\n\n### 麦克斯韦速度分布律\n\n分布函数是体现热力学系统的统计规律性的重要函数.\n\n常见的统计分布函数包括：速率分布函数、速度分布函数、能量分布函数等。\n\n通过分布函数可计算微观量的统计平均值，如$\\bar\\varepsilon_t, \\bar{v^2}$等，进而得到系统的宏观量。\n\n##### 速率分布函数\n\n$$f(v) = \\frac{\\text dN}{N\\text dv}\\\\\\\\\\int_0^\\infty f(v)\\text dv = \\int_0^\\infty\\frac{\\text dN}{N} = 1$$\n\n##### 麦克斯韦速率分布函数（不用记）\n\n$$f(v) = 4\\pi (\\frac m{2\\pi kT})^{3/2}e$$\n\n##### 三种统计速率\n\n###### 最概然速率\n\n$$v_p = \\sqrt{\\frac{2kT}{m}}$$\n\nm一定时，温度T越高，速率大的分子数比例越大，最概然速率越大， $f(v_p)$越小。\n\n###### 平均速率\n\n$$\\bar v = \\int_0^\\infty vf(v)\\text dv$$\n\n任意函数对全体分子按速率分布的平均值为\n\n<font color =\"red\">$f(v)$一定要归一化!</font><p>例如求0到vp/2的平均速率，首先要将f(v)归一化成这个区间内的速率分布，而不是直接用全部速率分布</p>\n$$\\bar{\\phi(v)} =\\int_0^\\infty \\phi(v)f(v)\\text dv$$\n\n由麦克斯韦速率分布函数\n\n$$\\bar v = \\sqrt{\\frac{8kT}{\\pi m}} = \\sqrt{\\frac{8RT}{\\pi M}}$$\n\n###### 方均根速率\n\n$$\\bar{v^2} = \\int_0^\\infty v^2f(v)\\text dv = \\frac{3kT}{m}\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}M}$$\n\n##### 麦克斯韦速度分布律\n\n$$\\frac{\\text dN}{N} = \\left(\\frac{m}{2\\pi kT}\\right)^{3/2}e^{-m(v_x^2 + v_y^2 + v_z^2)/2kT}\\text{d}v_x\\text{d}v_y\\text{d}v_x$$\n\n速度分量的分布函数\n\n$$g(v) = (\\frac m{2\\pi kT})^{1/2}e^{-mv^2/2kT}$$\n\n##### 分子碰壁数$Γ$\n\n$$\\Gamma = \\frac14 n\\bar v$$\n\n##### 玻尔兹曼分布\n\n###### 恒温气压公式\n\n$$p = p_0e^{-mgz/kT}\\\\\\\\n = n_0e^{-mgz/kT}$$\n\n###### 玻尔兹曼分布\n\n$$\\text dN_{\\vec r} = n_0 \\cdot e^{-\\varepsilon_p(\\vec r)/kT} \\cdot \\text d^3 \\vec r\\\\\\\\\\text d^3\\vec r = \\text dx \\ \\text dy \\  \\text dz$$\n\n###### 玻尔兹曼-麦克斯韦分布\n\n$$\\text dN = n_0 \\cdot (\\frac m{2\\pi kT})^{3/2} \\cdot e^{-[\\frac12 mv^2 + \\varepsilon_p(\\vec r)]/kT} \\cdot \\text d^3\\vec r \\cdot \\text d^3 \\vec v$$\n\n能量简并：不同子相空间分子能量相等。\n\n分子按能量分布：\n\n$$N(\\varepsilon) = C \\cdot w(\\varepsilon) \\cdot e^{-\\frac{\\varepsilon}{kT}}$$\n\n$\\varepsilon$为粒子的能量，$w(\\varepsilon)$为具有此能量的体积元个数.\n\n### 范德瓦尔斯方程\n\n#### 范氏气体模型\n\n气体分子间的作用力：分子间的作用力很复杂，主要是电磁力，可以分为引力和斥力\n\n范氏气体模型：对理想气体做两方面的修正。考虑分子体积、分子间作用力引起的修正。\n\n![范氏气体](../images/physics/VanGas.png)\n\n* 分子是直径为d的刚球\n* 在$d\\rightarrow s$的范围内，分子间有恒定引力\n\n#### 范德瓦尔斯方程\n\n范德瓦尔斯方程：\n\n\n设:\n\n$\\nu = 1 mol$\n\n$p$ -- 实测气体压强\n\n$V_m$ -- $1\\ mol$气体容积\n\n对理想气体：$pV_m = RT$\n\n对真实气体：\n\n1. 分子体积引起的修正\n\n分子自由活动空间的体积为$V_m - b$\n\n$$p(V_m - b) = RT$$\n\n$$\np = \\frac{RT}{V_m - b}\n$$\n\n2. 分子间引力引起的修正\n\n气体分子间作用力一般表现为引力。\n\n在容器内部，单个气体分子受到各个方向的平均引力相等，合力可以看作零。\n\n但是在容器边缘，单个气体分子受到的引力是不对称的。气体分子所受的合力指向容器内部，因此撞击容器壁的气体分子动量比理想气体下的情况要小，宏观上形成的压强比理想气体情况要小。\n\n$$\np < \\frac{RT}{V_m - b}\\\\\n$$\n\n设\n\n$$\np = \\frac{RT}{V_m - b} - p_{in}\n$$\n\n$p_{in} \\propto nf_{合}, f_{合}\\propto n \\Rightarrow p_{in} \\propto n^2 \\propto \\frac 1{V_m^2}$\n\n最后得到：\n$$\n(p + \\frac a{V_m^2})(V_m - b) = RT\n$$\n\n对 ν mol 气体：\n\n$$\n(p + \\nu^2 \\cdot \\frac a{V^2})(V - \\nu b) = \\nu RT\n$$\n\n常温常压下：$b/V_m \\sim 10^{-3}, p_{in}/p \\sim 10^{-2}$，这时分子体积和分子间的作用力修正可以忽略。\n\n#### 气体的等温线\n\n真实气体的等温线：\n\n![RealGasTemp](../images/physics/RealGasTemp.png)\n\n范氏气体的等温线：\n\n![VanGasTemp](../images/physics/VanGasTemp.png)\n\n如何计算临界参数：\n\n临界参数：临界点K对应的$p_K, V_K, T_K$\n\n临界点K是等温线的拐点：\n\n$$\n\\left(\\frac{\\partial p}{\\partial V}\\right)_{T = T_K} = 0\\\\\n\\left(\\frac{\\partial^2 p}{\\partial V^2}\\right)_{T = T_K} = 0\n$$\n\nK同时也是三次方程的三重根，因此可以通过假设$(V_m - V_{mK})^3 = 0$展开后和范德瓦尔斯方程对比系数求解。\n\n#### 范氏气体内能\n\n理想气体： $E(T) = i\\nu RT / 2$\n\n范氏气体：$V\\uparrow \\rightarrow p_{in}做负功\\rightarrow 分子间势能E_p\\uparrow$\n\n要计算势能，首先要定义势能为0的状态：定义某种位形为0势能。其他状态的势能定义为从这种状态变形到0势能状态的过程中保守力的变化。\n\n$$\\mathrm dA = -p_{in}S\\mathrm dl = -p_{in}\\mathrm dV$$\n\n设$E_p(V = \\infty) = 0$。\n\n$$\nE_p(V) = \\int_V^\\infty -p_{in}\\mathrm dV = \\int_V^\\infty-\\nu^2 \\cdot \\frac a{V^2}\\mathrm dV = -v^2 \\cdot \\frac aV\n$$\n\n$$\nE = E_k + E_p = \\frac i2\\nu RT - \\nu ^2\\frac aV\n$$\n\n**结论：**\n$$E(T, V) = \\frac i2 \\nu RT - \\nu^2 \\frac aV$$\n\n#### 一个细节\n\n为什么不考虑气体分子和容器壁分子间的引力？\n\n事实上，这引力确实存在。但是可以通过动量定理证明，碰撞过程这引力的作用总和为0。\n\n### 气体分子的碰撞、平均自由程\n\n平均碰撞频率和平均自由程\n\n平均碰撞频率$\\bar z$：单位时间内一个气体分子与其他分子碰撞的平均次数\n\n平均自由程$\\bar \\lambda$：气体分子在相邻两次碰撞之间飞行的平均路程。\n\n平均碰撞频率和平均频率之间关系\n\n对象:平衡态下的理想气体\n\n假定：\n\n(1)只有一种分子；\n\n(2)分子可视作直径为d的刚球；\n\n(3)被考察的分子以平均相对速率$\\bar u$运动，其余的分子静止。\n\n碰撞界面为$\\sigma$。分子间平均相对速率为$\\bar u = \\sqrt 2 \\bar v$。\n\n$$\n\\bar z = \\sigma \\bar u n = \\pi d^2 n \\bar u = \\sqrt 2 \\pi d^2 n\\bar v\n$$\n\n平均自由程和压强、温度的关系：\n\n$$\n\\bar\\lambda = \\frac {\\bar v} {\\bar z} = \\frac 1{\\sqrt2 \\pi d^2 n} = \\frac {kT}{\\sqrt2\\pi d^2p} \\propto \\frac{T}{p}\n$$\n\n### 气体输运过程\n\n非平衡态下，气体内部各部分性质不均匀，就会产生热量、动量、质量的迁移，称为输运过程或内迁移过程。\n\n气体输运过程包括：热传导、扩散和内摩擦（粘滞）。\n\n输运现象的宏观实验定律和原因。\n\n热传导\n\n温度不均匀。实验定律：傅里叶定律，热传导方程。\n\n考虑1维的情形。\n\n$$\n\\mathrm dQ = -\\kappa \\frac{\\partial T}{\\partial x}\\mathrm dS \\mathrm dt\n$$\n\n$$\nj(x, t) = \\frac{\\mathrm dQ}{\\mathrm dS\\mathrm dt}  = -\\kappa \\frac {\\partial T(x, t)}{\\partial x}\n$$\n\n$j(x, t)$：热流密度，$\\partial T/\\partial x$：温度梯度。\n\n温度梯度“力”导致热流。\n\n> $T$在这里相当于电势，$-\\partial T / \\partial x$相当于电势的负梯度即电场强度，$j$相当于电流密度，$\\kappa$相当于电导率。因此类比$\\vec{J} = \\sigma \\vec{E}$有$j = -\\kappa \\partial T /\\partial x$。类似的，也许可以推导出热阻的概念？热学的“麦克斯韦”方程组又是什么？\n\n统计物理给出的结论：\n\n$$\n\\kappa = \\frac 13 nm\\bar v \\bar \\lambda c_V\n$$\n\n>如何理解此公式：热传导的本质是分子能量（热量）的交换，交换的热量等于粒子数乘以单个粒子交换的热量。\n>\n>$m$为单个分子质量。$c_V$为定体热容。$n\\bar v$用于描述$\\mathrm dt$内穿过$\\mathrm dS$的粒子数，$\\bar\\lambda$乘以$\\partial T/\\partial x$得到温度的变化量$\\mathrm dT$ ,$m,c_V$与温度的变化量相乘，得到单个粒子交换的热量。\n\n稳恒热流：$\\frac{\\mathrm dQ}{\\mathrm dt} = C$，$j$, $T$与$t$无关。\n\n$\\kappa$称为导热系数，由气体特性和$T, p$决定。\n\n扩散\n\n原因：气体内部离子数浓度不均匀。\n\n斐克定律\n\n$$\n\\mathrm dN = -D\\frac {\\partial n}{\\partial x}\\mathrm dS \\mathrm dt\n$$\n\n>教材的表述为\n>$$\n\\mathrm dM = -D\\frac {\\partial \\rho}{\\partial x}\\mathrm dS \\mathrm dt\n>$$\n>这里的两个$D$是一样的。\n\n统计物理给出的结论：\n\n$$\nD = \\frac13\\bar v\\bar \\lambda\n$$\n\n扩散流密度：\n\n$$\nj(x, t) = \\frac {\\mathrm dN}{\\mathrm dS \\mathrm dt} = -D\\frac {\\partial n}{\\partial x}\n$$\n\n稳恒扩散流：$\\frac {\\mathrm dN}{\\mathrm dt} = C$，$j$, $n$, 与$t$无关。\n\n粒子数守恒方程\n$$\n\\oiint_S j\\cdot \\vec {s} = -\\frac {\\mathrm dN}{\\mathrm dt}, \\nabla \\cdot \\vec j + \\frac{\\partial n}{\\partial x} = 0.\n$$\n\n结合粒子数守恒方程（微分形式）和斐克定律得到扩散方程\n\n$$\n\\frac{\\partial n}{\\partial t} = D\\frac{\\partial^2 n}{\\partial x^2}\n$$\n\n考试考定场稳恒流，不考内摩擦。\n\n内摩擦（粘滞）\n\n根据流体力学，对定常流动的粘滞流体，流速不太大时（雷诺数小），出现层流。\n\n粘滞定律（牛顿摩擦定律）\n\n$$\n\\Delta F = - \\eta \\frac{\\mathrm du}{\\mathrm dz}\\Delta S\n$$\n\n$$\np = -\\eta \\frac{\\mathrm du}{\\mathrm dz}\n$$\n\n粘度和温度有关，气体粘度随温度增加，液体温度随温度减小。遵从粘滞定律的流体称为牛顿流体。\n\n内摩擦原因：流速不均匀。\n\n统计物理给出的结论：\n\n$$\n\\eta = \\frac 13 nm\\bar v\\bar \\lambda\n$$\n\n## 热力学第一定律\n\n### 准静态过程\n\n准静态过程：过程的任一时刻，系统都处于平衡态— 一系列平衡态组成的理想化过程。\n\n若外界条件改变时，能保证和系统相应的强度量之间差无穷小，则过程是准静态的。\n\n弛豫时间τ：平衡破坏到恢复平衡的时间.\n\n当$\\Delta t_{过程} > \\tau$时，过程就可视为准静态过程。\n。\n### 功\n\n体积功：$\\mathrm{\\bar dA} = p\\mathrm dV$\n\n系统对外界做功:$A = \\int_{V_1}^{V_2}p\\mathrm dV$是一个过程量。\n\n通过做功改变系统热力学状态，微观上是分子规则运动的能量通过碰撞转变为无规则运动的能量。\n\n### 内能，热量和热力学第一定律\n\n内能：定义为$E_2 - E_1 = A_{1\\rightarrow 2}$（绝热过程）\n\n内能通过绝热功度量。\n\n热量：定义为$Q = (E_2 - E_1)$（无功过程）\n\n微观本质是分子无规则运动的能量通过碰撞从高温物体向低温物体传递。\n\n热力学第一定律：\n\n$Q = \\Delta E + A$\n\n$\\mathrm {\\bar{d}}Q = \\mathrm d E + \\mathrm{\\bar{d}}A$\n\n热力学第一定律是一条实验定律，适用于任何热力学系统的任何过程。\n\n### 热容量：\n\n$$\nC = \\frac{\\mathrm dQ}{\\mathrm dT}\n$$\n\n定体热容量：$C_v = \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_V$\n\n定压热容量：$C_p = \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_p$\n\n摩尔热容量：\n$$\nC_m = \\frac1\\nu\\frac{\\mathrm dQ}{\\mathrm dT}\n$$\n\n对应地有定体摩尔热容量和定压摩尔热容量。\n\n理想气体内能：$\\Delta E = \\nu C_{V, m}\\Delta T$。（推导：内能变化与过程无关，假设先等体后等温，等体过程无功只有热交换，等温过程内能不变。）\n\n迈耶公式：\n\n$$\nC_{p, m} - C_{V, m} = R\n$$\n\n（推导：用等压过程计算内能的变化，与定体过程的结论比较一下可得。）\n\n理想气体热容量理论公式：\n\n$$\nC_{V, m} = \\frac i2R, C_{p, m} = \\frac{i+2}{2}R\n$$\n\n推导：结合理想气体内能公式。\n\n定义比热容比:$\\gamma = C_{p, m}/C_{V, m}$\n\n### 绝热过程\n\n系统和外界没有热交换的过程。\n\n理想气体的准静态绝热过程：\n\n> $$\n> 0 = p\\mathrm dV + \\nu C_{V, m}\\mathrm dT\\\\\n> p\\mathrm dV + V\\mathrm dp = \\nu R\\mathrm dT\\\\\n> R  = C_{p, m} - C_{V ,m}\n> $$\n>\n> 得到：\n> $$\n> \\frac{\\mathrm dp}{p} = -\\gamma\\frac{\\mathrm dV}V\n> $$\n\n两边积分得到:\n$$\npV^{\\gamma} = C, TV^{\\gamma - 1} = C, p^{\\gamma - 1}T^{-\\gamma} = C\n$$\n\n绝热功\n\n$$\nA = \\int_{V_1}^{V_2} p\\mathrm dV = C \\int_{V_1}^{V_2}\\frac 1{V^{\\gamma}}\\mathrm dV = \\frac{C}{1 - \\gamma}(V_2^{1 - \\gamma} - V_1^{1 - \\gamma}) =\\frac{p_2V_2 - p_1V_1}{1 - \\gamma} \n$$\n\n绝热功等于内能的减少量：\n\n$$\nA = -\\Delta E = \\nu C_{V, m}\\Delta T\n$$\n\n理想气体的多方过程\n\n多方过程：热容量$C$为常数的过程\n\n多方过程方程：$pV^n = \\text{const}$\n\n其中，$n = (C - C_p)/(C - C_V) = (C_m - C_{p, m})/(C_m - C_{V, m}) = \\text{const}$\n\n如果为绝热过程则$C = 0$，$n = \\gamma$，从而$pV^{\\gamma} = \\text{const}$。\n\n如果为等温过程则$C = \\infty$，$n = 1$，因此$pV = \\text{const}$。\n\n绝热自由膨胀过程<font color=\"red\">（非准静态过程！！）</font>：\n\n理想气体：$Q = 0, A = 0 \\Rightarrow E_1 = E_2$\n\n真实气体：若分子间以引力为主, $T_2 < T_1$，以斥力为主，$T_2 > T_1$。\n\n焓：气体的绝热节流过程是等焓过程，即$H = E + pV$为常数，对于非理想气体而言，内能不仅与温度有关，也与体积有关（焦耳-汤姆孙效应）。\n\n绝热自由膨胀：初末状态在等温线上，但是过程中不是平衡态。\n\n准静态等温膨胀：吸热用来做功。\n\n准静态绝热膨胀：内能的减少量用来做功。\n\n![](../images/physics/guocheng.png)\n\n循环过程：\n\n系统，如热机中的工质，经一系列变化的回到初态的整个过程。\n\n状态图：\n\n![](../images/physics/xunhuantu.png)\n\n热循环：\n\n![](../images/physics/rexunhuan.png)\n\n蒸汽机的效率约为十几%，内燃机20-30%。\n\n制冷循环：\n\n![](../images/physics/zhilengxunhuan.png)\n\n制冷系数：\n\n$$\nw = \\frac{Q_2}{A} = \\frac{Q_2}{Q_1 - Q_2}\n$$\n\n### 卡诺循环\n\n卡诺循环是一种可逆循环，包括两个等温过程和两个绝热过程。它的效率为\n\n$$\n\\eta = 1 - \\frac{|Q_2|}{Q_1} = 1 - \\frac{T_2}{T_1}\n$$\n\n卡诺循环的效率仅与热源的温度比有关。\n\n由卡诺定理可以证明，卡诺循环的效率与工质无关。因此，不妨设工质为理想气体，利用理想气体等温和绝热过程方程得到效率公式。\n\n## 热力学第二定律\n\n开尔文表述：不可能将热量从低温热源搬运到高温热源，而不产生其他影响。（制冷系数不可能为无穷大）\n\n克劳修斯表述：不可能将功全部转化为热。（热机效率不可能为1）\n\n开尔文表述和克劳修斯表述是等价的。事实上，任何关于热现象不可逆的描述都是等价的，它们要么同时成立，要么同时不成立。因此，描述热现象的方向性，只需要举一个例子即可。\n\n### 卡诺定理\n\n在温度相同的高温热源和温度相同的低温热源之间工作的一切热机，可逆热机的效率最大。\n\n推论：一切可逆热机，只要它们的高温热源的温度相等，低温热源的温度相等，效率就相等。\n\n对于制冷机：\n\n可逆制冷机的制冷系数最大。\n\n所有2热源可逆制冷机制冷系数都相等，等于卡诺制冷机的制冷系数。\n\n### 热力学温标\n\n根据卡诺定理，可逆热机的效率只与温度有关。因此可以用效率，或者说热量比来定义温标。\n\n在热力学温标下，低温热源的温度不能为0，否则可逆热机的效率为1.\n\n### 任意可逆循环的效率\n\n$$\n\\eta \\le 1 - \\frac {T_2}{T_1}\n$$\n\n其中，$T_1$，$T_2$分别为循环中工质的最高和最低温度。\n\n### 克劳修斯熵公式\n\n热力学第零定理导出了温度，热力学第一定律导出了内能，热力学第二定律则导出了熵。\n\n可逆循环可以拆成若干小卡诺循环，每个卡诺循环满足\n\n可逆循环有克劳修斯等式\n$$\n\\oint_R \\frac{\\mathrm {\\bar d} Q}{T} = 0\n$$\n\n因此得到一个与路径无关的状态函数。\n\n熵与状态有关，和过程无关。即便过程是不可逆过程。\n\n但是，仅当过程为可逆过程时才有$\\mathrm dS=  \\mathrm{\\bar d}Q/T$。\n\n对于可逆过程：\n\n$$\nT\\mathrm dS = \\mathrm{\\bar d}Q = \\mathrm dE + p\\mathrm dV\n$$\n\n因而可以用$E, V$表示熵：\n$$\n\\mathrm dS = \\frac 1T \\mathrm dE + \\frac pT \\mathrm dV = \\frac 1T()\n$$\n\n### 克劳修斯不等式\n\n不可逆循环有\n$$\n\\oint_{Ir} \\frac{\\mathrm {\\bar d} Q}{T} < 0\n$$\n\n因而有熵增加原理:\n\n$$\n\\int_{1_{Ir}}^{2} + \\int_{2_R}^1 < 0\\Rightarrow S_1 - S_2= \\int_{1_{Ir}}^2\n$$\n\n# 振动和波动\n\n## 波动\n\n### 多普勒效应\n\n一般形式：\n\n![](../images/DSA/Duopule.jpg)\n\n机械波不存在多普勒效应。\n\n电磁波的多普勒效应：\n\n![](../images/DSA/waveDuopl.jpg)\n\n横向多普勒效应：$\\theta = \\pi /2$\n\n纵向多普勒效应：$\\theta = 0,\\pi$\n\n### 激波\n\n马赫数：$\\frac{v_s}{u} = \\frac 1{\\sin\\alpha}$\n\n# 光学\n\n光学分为几何光学，波动光学和量子光学。\n\n## 光的相干叠加\n\n光源：\n1. 普通光源：自发辐射。不同原子发光独立、不相干；同原子不同次发光独立、不相干。\n2. 激光光源：受激辐射。光放大，全通光子，相干光，波列长，相干性好。\n\n光的相干性：\n光学中强调电磁波的电场矢量$\\vec E$：光矢量\n\n相干条件：光矢量有平行分量，频率相同，相差恒定。\n\n电磁波叠加的强度公式推导：\n$$\nI = \\sqrt{\\varepsilon / \\mu}\\left<\\vec E \\cdot \\vec E \\right>_t \\\\\n\nI \\propto \\left<\\vec E \\cdot \\vec E \\right>_t \\\\\n\n叠加的电磁波：\\vec E_1 + \\vec E_2\\\\\n\n\n矢量的点乘运算可得叠加后的强度:\\\\\n\nI = I_1 + I_2 + 2\\sqrt{\\varepsilon / \\mu}\\left<\\vec E_1 \\cdot \\vec E_2 \\right>_t \n\n$$\n\n对光的相干叠加，用光矢量的平行分量描述光场--标量波函数。\n\n$$\nI = I_1 + I_2 + 2\\sqrt{I_1I_2}\\cos \\Delta \\varphi\n$$\n\n其中$\\Delta\\varphi = -k(r_2 - r_1) + (\\varphi_{20} - \\varphi_{10})$为相位差。\n\n在上面两式中，若$\\vec E_1 \\cdot \\vec E_2 \\ne 0$或者$\\Delta\\varphi \\ne \\pm\\frac{\\pi}{2}...$，则满足相干的条件。\n\n条纹的明显程度用衬比度衡量：$V = (I_{max} - I_{min})/(I_{max} + I_{min})$\n\n不同的位置$\\Delta\\varphi$不同，因而对应的$I$不同，造成了干涉条纹的出现。$I_1 = I_2$时$V=1$，$I_1 \\ne I_2$时，$V \\ne 1$。\n\n普通光源获得相干光的途径一般有分波阵面法（双缝干涉）和分振幅法（薄膜干涉）。\n\n### 双缝干涉\n\n![](../images/physics/shuangfeng.jpg)\n\n明纹：$\\delta = \\pm k\\lambda$\n\n暗纹：$\\delta = \\pm (2k + 1)\\frac \\lambda 2$\n\n$(k\\in N)$\n\n条纹间距：$\\Delta x = \\frac{D}{d}\\lambda$\n\n$\\Delta \\varphi \\approx \\frac{d\\sin \\theta}{\\lambda}2\\pi$\n\n时间相干性（光的颜色）：\n\n光的非单色性：\n\n准单色光：由某个中心频率或波长附近的频率或波长连续分布的光构成。采用谱密度函数描述。\n\n![](../images/physics/准单色光.jpg)\n\n造成谱线宽度的原因：自然宽度、多普勒增宽、碰撞增宽\n\n非单色性对干涉条纹的影响：\n\n![](../images/physics/非单色光.jpg)\n\n从图中可以看出，如果某个位置谱线中波长最长的成分的k级明纹和波长最短的成分的(k+1)级明纹重合，则在这个位置以后的条纹看不清楚了。\n\n可以解得最大相干级次：$k_M = \\lambda/\\Delta\\lambda$，进而有最大波程差：$\\delta_M = \\lambda^2/\\Delta\\lambda$。\n\n相干长度等于波列长度。\n\n通常用相干时间（光通过相干长度所需的时间）$\\tau = \\delta_M / c$ 衡量光的单色性。相干时间或相干长度越长，则单色性越好。\n\n空间相干性（光的宽度）：\n\n较宽的光源会导致明纹的非相干叠加，使衬比度下降。\n\n设光的宽度为$b_0$,则看到干涉条纹的条件是$b_0 < \\frac{R}{d}\\lambda$，这一上界称为光源极限宽度。\n\n固定b和R，则得到$d < \\frac{R}{b}\\lambda$，上界称为相干间隔。\n\n光源中心对两孔的张角为$\\theta = \\frac{d}{R} < \\frac{\\lambda}{b}$，上界称为相干孔径角。\n\n### 光程\n\n用于计算光经过不同介质的相差。\n$\\Delta\\varphi = \\frac{2\\pi r}{\\lambda}$。\n\n透镜不产生附加光程差。\n\n### 薄膜干涉\n\n为什么要薄？相干长度（时间相干性）限制。\n\n薄膜干涉有实际意义的是等倾条纹和等厚条纹。\n\n光程差\n$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2}\n$$\n\ne为膜厚度。\n\n等厚条纹：\n\n厚度不同，角度相同\n\n单色平行光入射，近似垂直于膜表面，因而$i, r \\approx 0$\n\n$$\n\\delta = 2ne + \\frac{\\lambda}{2}\n$$\n\n劈尖：\n\n由于明纹需满足$\\delta = k\\lambda$，暗纹需满足$\\delta = (2k+1)\\lambda/2$，故相邻亮纹所在的厚度差为$\\Delta e = \\lambda / (2n)$，而条纹间距为$L = \\Delta e / \\theta = \\lambda / (2n\\theta)$\n\n牛顿环：\n\n![](../images/physics/niudunhuan.jpg)\n\n可以得到暗环半径公式：$r_k=\\sqrt{kR\\lambda}$\n\n总结：条纹跟着厚度走。\n\n等倾条纹：\n\n厚度相同，角度不同。\n\n光程差(记!)\n$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2} = 2e\\sqrt{n^2 - n^{\\prime2}\\sin ^2 i} + \\frac \\lambda2\n$$\n\n等倾条纹实验通常采用面光源,因为透镜会把方向相同的光汇聚到一点，因而条纹的非常鲜明，衬比度很高，不会出现光源宽度和条纹衬比度的矛盾。\n\n应用：增透膜和增反膜\n\n### 迈克尔逊干涉仪\n\n平行：等倾条纹\n\n倾斜：等厚条纹\n\n条纹缩进N个，代表厚度变化：\n\n$$\n\\Delta d = \\frac{\\lambda}{2n} = \\frac {\\lambda}{2}\n$$\n\n在光路上放一个介质，条纹移动N个：\n\n$$\n\\delta = 2(n - 1)l = N\\lambda\n$$\n\n简而言之，一个条纹对应光程变化一个波长，厚度的变化（介质变化折算成厚度变化）乘以2等于光程的变化，因为一来一回经过了两次。\n\n## 衍射\n\n菲涅尔衍射和夫琅禾费衍射。\n\n惠更斯-菲涅尔原理\n\n夫琅禾费衍射研究光源和投影面在无限远处的情形。采用透镜将无限远转化为有限远。\n\n### 单缝衍射（夫琅禾费）\n\n利用半波带法计算明暗纹位置：\n\n中央明纹：$a\\sin \\theta = 0$\n\n暗纹：$a\\sin \\theta = \\pm k\\lambda$\n\n明纹（近似）:$a\\sin \\theta = \\pm (2k + 1)\\frac \\lambda 2$\n\n上述的$k$不能为0。因为如果k=0，即中央明纹，它没有半波带，因此要单独考虑。\n\n光强公式：$I_p = I_0(\\frac{\\sin \\alpha}{\\alpha})^2$\n\n其中$I_0$为中心亮纹强度，$\\alpha = \\frac{\\pi a \\sin \\theta}{\\lambda}$\n\n条纹宽度：\n\n条纹宽度的定义：两个相邻暗纹之间的距离，就是它们之间那个条纹的宽度。\n\n中央明纹角宽度：$\\Delta \\theta_0\\approx 2\\frac{\\lambda}{a}$，线宽度：$\\Delta x_0 \\approx 2 f \\frac{\\lambda}{a}$\n\n其他明纹线宽度：$\\Delta x \\approx f\\frac{\\lambda}{a}$\n\n### 光栅衍射\n\n光栅是由衍射单元（狭缝、反射面等）排列成的具有空间周期性结构的光学元件。\n\n光栅常数d-空间周期性结构常数\n\n正入射光栅方程：$d\\sin \\theta = \\pm k\\lambda$。（明纹位置）\n\n暗纹方程：$d\\sin \\theta = \\pm k\\lambda + \\frac{m}{N}\\lambda$\n\n主极大缺级公式：$k = k^\\prime d / a$\n\n主极大半角宽：$\\frac {\\lambda}{N d \\cos \\theta_k}$\n\n斜入射光栅方程：$d(sin\\theta - \\sin i) = \\pm k\\lambda$\n\n斜入射可以获得更高级次的条纹，但是观察到的条纹总数不变。\n\n调节入射角i或者波长$\\lambda$，衍射角$\\theta_k$也会改变。对于0级衍射光，$\\sin \\theta_0 = \\frac{\\lambda}{2\\pi d}\\Delta \\varphi_{in}$\n\n光学仪器的分辨本领：\n\n艾里斑半角宽$D\\sin \\theta_1 \\approx 1.22\\lambda$\n\n瑞利判据：一个象斑中心在另一个象斑边缘。\n\n根据瑞利判据得到透镜分辨本领（最小分辨角）：$R = \\frac{D}{1.22\\lambda}$\n\n光栅光谱：\n\n取决于光栅的色散能力和谱线（条纹）的线宽度\n\n角色散本领：$D_{\\theta} = \\frac{\\delta \\theta}{\\delta \\lambda}$\n\n色分辨本领：$R = \\frac{\\lambda}{\\delta \\lambda} = Nk$，$\\delta \\lambda$，$\\lambda $取较小者的波长，$k$是主极大级数。\n\n## 偏振\n\n### 定义\n\n线偏振光：光矢量做同向振动，方向不变。\n\n圆偏振光：光矢量的端点是圆。\n\n椭圆偏振光：光矢量的端点是椭圆。\n\n非偏振光：例如自然光。它的振动方向随机，各个方向振幅相等。自然光可以分解为两束垂直振动，振幅相等，相差随机的线偏振光。\n\n部分偏振光：自然光+完全偏振光。\n\n偏振度：$P = \\frac{I_p}{I_t} = \\frac{I_p}{I_n + I_p}$\n\n### 起偏与检偏\n\n偏振片：利用二向色性。有微晶型和分子型。\n\n线偏振光的起偏：通过偏振片。\n\n马吕斯定律：$A = A_0 \\cos \\alpha, I = I_0 \\cos^2 \\alpha$\n\n### 反射与折射中的偏振\n\nS分量：垂直于入射面。P分量：平行于入射面。\n\n反射光S分量多，折射光P分量多。\n\n当$i = i_0$使得反射光只有S分量，折射光大部分是P分量。称为布儒斯特角。$i_0 + r_0 = 90\\degree$，因而有布儒斯特定律：$\\tg i_0 = \\frac{n_2}{n_1}$\n\n玻璃片堆可以增强反射光的强度，增加折射光的偏振程度。\n\n散射引起光的偏振：\n\n微粒散射：丁达尔效应\n\n分子散射：纯净气体、液体的散射。\n\n\n双折射现象：\n\n1束光入射到各向异性介质内，产生2束折射光。o光为寻常光，符合折射定律；e光为非常光，不符合折射定律一般，也不一定在入射面内。o，e光都是线偏振光，振动方向互相垂直。\n\n晶体光轴：是晶体中的特殊方向，光在晶体中沿该方向传播不发生双折射。方解石是单轴晶体。云母是双轴晶体。\n\n主平面：晶体中光的传播方向与晶体光轴构成的平面。o光振动方向垂直于主平面，e的振动方向在主平面内。只有当光轴在入射面内，o光主平面、e光主平面、入射面才重合。\n\n折射角度不同的本质是不同角度下光的传播速度不同。据此区分正晶体和负晶体：\n\n$v_o$是o光速度，$v_e$是e光垂直光轴方向速度。o光是各向同性的，e光沿平行光轴方向的速度和o光相同，e光沿所有方向的速度构成一个旋转椭球面。\n\n![](../images/physics/shuangzheshe.jpg)\n\n正晶体：$v_o > v_e$\n\n负晶体：$v_o < v_e$\n\n定义主折射率：$n_o = c/v_o, n_e = c/v_e$\n\n利用惠更斯作图法可以讨论单轴晶体的光传播情况：\n\n以负晶体为例。\n* 若光轴平行于晶体表面，自然光垂直入射：o和e方向相同，速度不同，仍然是双折射；\n* 光轴平行晶体表面，且垂直入射面，自然光斜入射：e光也满足折射定律，折射率为$n_e$；\n* 光轴与晶体表面斜交，自然光垂直入射：e光偏离入射方向，惠更斯波面是斜椭圆。\n\n研究晶片时，o光和e光（垂直振动和平行振动）是独立的正交的分量。垂直振动不会变成平行振动，平行振动也不会变成垂直振动。\n\n双折射：两个垂直方向的线偏振光的不同速度造成的。\n\n旋光：两个不同旋转方向的圆偏振光的不同速度造成的。\n\n# 量子物理\n\n## 黑体辐射\n\n热辐射\n\n物体受热发出电磁辐射。热辐射是连续谱，温度升高，短波成分增加。\n\n平衡热辐射：物体温度不变时产生的热辐射。单位时间内物体吸收能量等于辐射能量。\n\n光谱幅出度（单色幅出度）\n\n单位面积内单位频率发射的电磁波能量。\n\n$$\nM_\\nu = \\frac{\\mathrm d E_\\nu(T)}{\\mathrm d\\nu}\n$$\n\n总幅出度\n\n$$\nM(T) = \\int_0^\\infty M_\\nu(T)\\mathrm d\\nu\n$$\n\n单色吸收比\n\n$$\n\\alpha_\\nu(T) = \\frac{\\mathrm d E_{\\nu(吸收)}}{\\mathrm d E_{\\nu(入射)}}\n$$\n\n黑体\n\n能吸收所有频率的电磁波，没有反射。$\\alpha_{\\nu}=1$。\n\n基尔霍夫辐射定律：\n\n$$\n\\frac{M_{\\nu i}}{\\alpha_{\\nu i}} = M_{\\nu 黑体}\n$$\n\n实验定律：\n\n维恩位移定律：$\\nu_m = C_\\nu T$, $\\lambda_m = b/T$\n\n注：$\\lambda_m \\nu_m \\ne c$。\n\n\n斯特藩-玻尔兹曼定律：$M(T) = \\sigma T^4$，$\\sigma$为斯特藩-玻尔兹曼常量。\n\n韦恩公式：低频段不符合；\n\n瑞利-金斯公式：高频段不符合。\n\n普朗克能量子假设：$\\varepsilon = h\\nu$\n\n普朗克公式：\n\n$$\nM_\\nu(T) = \\frac{2\\pi h}{c^2}\\cdot \\frac{\\nu^3}{e^{h\\nu/kT} - 1}\n$$\n\n由它可以导出所有其他热辐射公式。\n\n## 光电效应\n\n自学。\n\n## 光的二象性\n\n光子理论：能量$\\varepsilon = h\\nu$。光强：$I = N \\cdot h\\nu$，N是光子数流通量。\n\n解释光电效应：\n\n$$\n\\frac 12 mv_m^2 = h\\nu - A\n$$\n\n光的粒子性：\n\n$$\np = \\frac h \\lambda \\\\\nE = h\\nu \\\\\nm = \\frac{h\\nu}{c^2}\n$$\n\n解释干涉和衍射：\n\n光子在某处出现的概率是由该处的光强决定的：$I \\propto \\frac 1 {r^2}$，光子分布概率的不同导致了光强的不同。也就是说，光子的波动性表现为概率波。\n\n光子在某处出现的概率和该处光强（光振幅的平方）成正比。\n\n## 康普顿散射\n\n散射波出现新的波长：$\\Delta \\lambda = \\lambda_C(1 - \\cos\\varphi)$\n\n利用光子理论解释：光子和“静止”的“自由”电子碰撞过程动量守恒，能量守恒。\n\n解得$\\Delta \\lambda = \\frac{h}{m_0c}(1 - \\cos \\varphi)$\n\n如果光子撞到内层电子，则能量不变，因而存在原波长。\n\n自由电子只能散射光子，不能吸收光子。如果吸收了，根据能量守恒和动量守恒，解得v=c，违反了相对论。\n\n光电效应不考虑动量守恒，因为可见光、紫外线的能量低，电子不能视为自由，光子-电子不能视为动量守恒的系统。也因此，可见光观察不到康普顿效应。\n\n## 概率波和概率幅\n\n物质波的本质：\n\n德布罗意认为是引导物质运动的“导波”；（本质不明确）\n\n薛定谔认为波是基本的，电子是“波包”；（波包是不稳定的，而电子是稳定的）\n\n另一个观点：粒子是基本的，物质波是电子相互作用形成的（被电子双缝实验否定）\n\n波恩的解释：物质波是描述粒子在空间概率分布的“概率波”。\n\n量子力学的基本假设之一：微观粒子的状态用波函数描述\n\n概率波波函数(概率幅)：复函数$\\Psi (\\vec r, t)$\n\n波函数没有直接的物理意义。复函数模的平方$|\\Psi (\\vec r, t)|^2$表示概率密度。\n\n波函数需要满足标准条件：\n\n有限性:$\\iiint_{\\Delta V}|\\Psi|^2 \\mathrm dV$有限\n\n归一性：$\\int_\\Omega |\\Psi(\\vec r, t)|^2 \\mathrm dV = 1$\n\n单值性：波函数是单值函数。\n\n连续性：波函数和它的一阶导数是连续的。\n\n双缝的波函数：等于通过上缝和下缝的波函数的线性叠加。$\\Psi_{12}=\\Psi_1+\\Psi_2$。(一个基本假设)\n\n微观粒子波动性实质是波函数的叠加性。\n\n结合测量理解。\n\n态叠加原理：$\\Psi = \\sum_n C_n\\Psi_n$。其中$|C_n|^2$是该粒子处于$\\Psi_n$状态的概率。\n\n一维自由粒子的波函数：\n\n$$\n\\Psi(x, t) = A e^{i(px-Et)/\\hbar}\n$$\n\n概率密度$|\\Psi|^2 = |A|^2 = \\text {const.}$\n\n波粒二象性：\n\n粒子性：具有能量$E$和动量$\\vec p$。非经典粒子！没有轨道概念。\n\n波动性：具有波长$\\lambda$和频率$\\nu$。非经典波！非真实物理量的波动。\n\n## 不确定关系\n\n$$\n\\left<\\vec r|\\Psi\\right>\n$$\n\n不确定度：$\\Delta A = \\sqrt{\\overline{(A - \\bar A)^2}}$\n\n坐标和动量的不确定性关系：\n\n$$\n\\Delta x \\cdot \\Delta p \\ge \\frac \\hbar 2\n$$\n\n因而微观粒子没有“轨道”。\n\n能量和时间的不确定性关系：\n\n$$\n\\Delta E \\cdot \\Delta t \\ge \\frac{\\hbar}{2}\n$$\n\n时间不是力学量，它只是一个参数。位置，动量，能量等都是力学量。\n\n## 薛定谔方程\n\n定义\n\n$$\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} = \\hat {H} \\Psi\n$$\n\n哈密顿算符：$\\bar {H} = -\\frac{\\hbar ^2}{2m}\\nabla^2 + U(\\vec r, t)$\n\n若势函数不显含时间，则哈密顿算符$\\hat H$称为能量算符。此时薛定谔方程可以通过分离变量法求解。\n\n### 定态薛定谔方程-能量本征方程\n\n分离变量法求解：\n\n若势函数不显含t，则可设：\n\n$$\n\\Psi(\\vec r, t) = \\Phi(\\vec r) \\cdot T(t)\n$$\n\n得到：\n\n$$\ni\\hbar \\frac{\\mathrm dT(t)}{\\mathrm d t}\\frac 1{T(t)} = [\\hat H\\Phi (\\vec r)]\\frac{1}{\\Phi(\\vec r)} = E\n$$\n\n$$\nT(t) = Ce^{-\\frac{i}{\\hbar}Et}\\\\\n()\n$$\n\nE称为能量本征值（后面会讲什么叫本征值），对应的$\\Phi_E$称为本征波函数。\n\n定态：能量取确定值的状态，对应薛定谔方程的特解：$\\Psi_E(\\vec r, t) = \\Phi e^{-\\frac{i}{\\hbar}Et}$.\n\n对不同的势函数和能量区间，能量的本征值可能取连续的值，也可能取分立的值。设E取分立值，$\\{E_n, n = 1, 2, 3, \\dots\\}$，对应的本征波函数$\\Psi_E (\\vec r, t) = \\Phi_E(\\vec r)e^{-\\frac{i}{\\hbar}Et}$\n\n下面通过求解一维定态薛定谔方程来讨论两类问题：\n\n本征值问题：给定$U(x)$，求$E_n$和$\\Phi_n(x)$。\n\n散射问题：$E$已知，射向势垒$U(x)$，计算粒子穿透势垒的概率。 \n\n## 无限深方势阱中的粒子\n\n背景：长度为$a$的导体中自由移动的电子，只能在导体中自由运动，而不能离开导体。\n\n$|x| > a/2$时，$U(x) \\rightarrow \\infty$；\n\n$|x| \\le a/2$时，$U(x) = 0$。\n\n在$|x| > a/2$区间，$\\Phi_1 = 0$。\n\n在$|x| \\le  a/2$区间，$\\frac{\\mathrm d^2 \\Phi_2}{\\mathrm dx^2} + \\frac{2mE}{\\hbar^2}\\Phi_2 = 0$\n\n记$k = \\frac{2mE}{\\hbar^2}$。解得$\\Phi_2 = A\\sin(kx + \\varphi)$。\n\n求解定态的常规手法：利用波函数的三个条件，即单值、有限、连续，确定$A, k, \\varphi$。\n\n利用连续条件，波函数在势阱边界处连续：\n\n$$\nA\\sin(\\frac{ka}{2} + \\varphi) = 0, A\\sin(-\\frac{ka}{2} + \\varphi) = 0.\\\\\n\n\\Rightarrow k = \\frac{n\\pi}{a}, \\varphi = \\frac{l\\pi}{2}\n$$\n\n从而\n$$\nE = \\frac{\\pi^2\\hbar^2}{2ma^2}n^2 \\ (n = 1, 2, 3, \\dots)\n$$\n\n最低能量$E_1$被称为零点能。\n\n大量子数情况下，能量趋向于连续。\n\n$$\nl = 0, \\varphi = 0, \\Phi_2 = A\\sin \\frac{n\\pi}{a}x = \\Phi_{on},满足边界连续需要n为偶数\\\\\nl = 1, \\varphi =\\pi /2 , \\Phi_2 = A\\cos \\frac{n\\pi}{a}x = \\Phi_{en},满足边界连续需要n为奇数\\\\\nl \\ge 2，只差个符号，不影响|\\Phi|^2，不再考虑。\n$$\n\n求$A$：\n\n归一化：$\\int_{-a/2}^{a/2}|\\Phi_{on}|^2 \\mathrm dx = 1$， 得到$A = \\sqrt \\frac2a$\n\n$$\n\\Phi_{on} = \\sqrt{\\frac 2a}\\sin \\frac{n\\pi}{a}x, n = 2, 4, 6, \\dots\\\\\n\\Phi_{en} = \\sqrt{\\frac 2a}\\cos\\frac{n\\pi}{a}x, n = 1, 3, 5, \\dots\n$$ \n\n定态：\n\n$$\n\n\\Psi_n (x, t) = \\Phi_n(x) \\cdot e^{-\\frac i\\hbar Et}\n\n$$\n\n被称为驻波解(时间项指数为纯虚数，展开可以写成三角函数)。概率密度$|\\Psi_n(x, t)|^2 = |\\Phi_n(x)|^2$\n\n## 势垒穿透\n\n### 粒子进入势垒\n\n背景：金属与半导体接触处，势能隆起形成势垒。粒子以能量为$E(E < U_0)$的状态自由入射。\n\n$$\nU(x) = 0, x \\le 0;\\\\\nU(x) = U_0, x \\gt 0.\n$$\n\n量子力学认为有一部分粒子会穿透势垒。不仅有反射，还有投射。\n\n定态薛定谔方程：\n\n$$\n\\Phi^{\\prime\\prime}(x) + \\frac{2m}{\\hbar^2}(E - U(x))\\Phi(x) = 0\n$$\n\n$x \\le 0$: \n$$\nk_1 = \\sqrt{2mE/\\hbar^2} > 0\\\\\n\\Psi_1^{\\prime\\prime} + k_1^2 \\Psi_1 = 0\n$$\n\n$x \\gt 0$:\n$$\nik_2 = \\sqrt{2m(E - U_0)/\\hbar^2} (k_2 > 0)\\\\\n\\Psi_2^{\\prime\\prime} + (ik_2)^2\\Psi_2 = 0\n$$\n\n通解（利用了$x\\rightarrow\\infty$时$\\Psi_2$的有界性）：\n\n$$\n\\Psi_1(x) = Ae^{ik_1x} + Be^{-k_1x}(表现为入射和反射波)\\\\\n\\Psi_2(x) = Ce^{k_2x}(表现为透射波)\n$$\n\n粒子可以出现在势垒区！表现为电子溢出金属表面，形成金属表面的一层电子气。\n\n势垒区的概率密度：$|\\Psi_2(x)|\\propto e^{-\\frac{2x}{\\hbar}\\sqrt{U_0 - E}}$\n\n波可以穿过有限宽势垒，以平面波的形式继续前进。称为量子隧穿效应。\n$\\Psi_3(x) = Se^{i\\frac {\\sqrt{2mE}}{\\hbar} x}$\n\n扫描隧道显微镜：原理是量子隧穿效应，可以用来观测物质表面结构。\n\n![](../images/physics/STM.jpg)\n\n$$\ni \\propto Ue^{-C\\sqrt{\\varPhi}d}\n$$\n\n$\\varPhi$为样品表面平均势垒高度。\n\n## 一维谐振子\n\n$$\nU(x) = \\frac 12 kx^2 = \\frac 12m\\omega^2x^2, \\omega = \\sqrt{\\frac km}\n$$\n\n求解定态薛定谔方程得到\n$$\nE_n = (n + \\frac 12)\\hbar \\omega = (n + \\frac 12)h\\nu\n$$\n零点能：$\\frac{h\\nu}{2}$。间距：$h\\nu$。能量本征函数不用记。\n\n定态概率密度：\n\n经典情况下：平衡位置处$\\vec v$最大，停留时间最短，出现概率最小，振幅最大的时候$\\vec v$为0，出现概率最大。量子数n趋于无穷时，量子概率分布趋于经典概率分布。\n\n如果$E< U$，隧穿效应仍然存在。\n\n## 力学量算符\n\n以位矢$\\vec r$为自变量的空间，称为“坐标表象”。在坐标表象中，动量和位矢不存在对应关系$\\vec p = \\vec p(\\vec r)$（不确定关系）。\n\n量子力学将动量、角动量、能量等力学量“算符化”。力学量算符是量子力学的一个基本假设。\n\n### 力学量算符的引入\n\n定义能量算符$\\hat {E} \\equiv i\\hbar \\frac{\\partial}{\\partial t}$，与表象无关。\n\n坐标表象中定义动量算符$\\hat{\\vec p} = -i\\hbar\\nabla$，坐标算符$\\hat{\\vec r} = r$。\n\n由于坐标表象下坐标算符就是坐标，因此势能算符$\\hat{U} = U(\\vec r)$。动能算符$\\hat{E_k} = \\frac{(-i\\hbar\\nabla)\\cdot (-i\\hbar\\nabla)}{2m} = -\\frac{\\hbar^2}{2m}\\nabla^2$\n\n角动量算符$\\hat{\\vec L} = \\hat{\\vec r}\\times \\hat{\\vec p} = -i\\hbar\\vec r \\times \\nabla$。如果用球极坐标，可得$\\hat{L_z} = -i\\hbar \\frac{\\partial}{\\partial \\varphi}$。角动量算符的模方由极角和方位角的导数组成：$\\hat{L}^2 = -\\frac {\\hbar^2}{\\sin \\theta}\\frac{\\partial}{\\partial \\theta}(\\sin \\theta\\frac{\\partial}{\\partial \\theta})  +\\frac{\\hat{L_z^2}}{\\sin^2\\theta}$\n\n### 本征值和本征函数\n\n本征方程：$\\hat{A}\\Psi_n = A_n\\Psi_n$。其中$A_n$为本征值，$\\Psi_n$是$A$取$A_n$时的本征态，称为本征函数。\n\n本征值就是相应力学量的可能取值。\n\n$\\hat A$的本征函数系${\\Psi_n}$构成正交、归一的完备函数系。一维情况的归一化：$\\int_{-\\infty}^{+\\infty}\\Psi_n^*(x)\\Psi_n(x)\\mathrm dx = 1$。正交性：$\\int_{-\\infty}^{+\\infty}\\Psi_m(x)\\Psi_n(x)\\mathrm d x = \\delta_{mn}$.\n\n本征函数的完备性：在相同的函数空间内，任一物理上合理的归一化波函数，都可以由力学量A的本征函数系线性展开，即$\\Psi = \\sum_{n}C_n(t)\\Psi_n(x)$。\n\n### 态叠加原理：\n\n线性展开公式：\n\n$$\n\\Psi(x, t) = \\sum_{n }C_n(t)\\Psi_n(x) \\ (假设是归一化的)\n$$\n\n基本假设之一。\n\n### 力学量的测量原理\n\n量子力学假设：在$\\Psi(x,t)$态上测量$A$，则$\\Psi(x, t)$一定向着$A$的某个本征态$\\Psi_n$塌缩，测量结果为$A_n$。\n\n特别地，如果$\\Psi = \\Psi_n$，则测量结果是确定的，为$A_n$。\n\n测量结果中$A_n$出现的概率为$|C_n(t)|^2$。\n\n$$\n\\bar A = \\sum_n |C_n(t)|^2A_n = \\int_{-\\infty}^{+\\infty}\\Psi^*(x, t)\\hat A\\Psi(x, t)\\mathrm dx\n$$\n\n\n## Dirac符号\n\n### 量子态\n\n本征值离散的：$\\ket{n}$\n\n本征值是连续的：$\\ket{P_x}, \\ket{x}$\n\n它们各自张开一个线性空间。\n\n### 内积空间\n\n左矢与右矢一一对应，左矢张开一个共轭线性空间。\n\n$\\ket{A}$和$\\ket{B}$的内积(复内积)：$\\langle B|A\\rangle$\n\n左矢空间与右矢空间通过复内积练习，称为内积空间。\n\n### 线性算符\n\n$$\n\\hat{L}\\ket{A} = \\ket{B}\n$$\n\n满足：\n* $\\hat L (\\ket{A} + \\ket {B}) = \\hat L\\ket{A} + \\hat L\\ket{B}$\n* $(\\hat F + \\hat G)\\ket{A} = \\hat F \\ket{A} + \\hat G\\ket{A}$\n\n* $\\hat F(\\hat G \\ket{A}) = (\\hat F \\cdot \\hat G)\\ket {A}$\n\n共轭算符：$\\bra{A}\\bar{\\hat L}$与$\\hat L \\ket{A}$一一对应，将$\\bar{\\hat L}$或者$\\hat L ^+$称为共轭算符。\n\n厄米算符：$\\bar {\\hat L} = \\hat L$。\n\n算符是向右结合的。\n\n### 算符本征方程\n\n$$\n\\hat L \\ket{L_n} = l_n\\ket{L_n}\\\\\n\n\\hat L\\ket{n} = l_n\\ket{n}\n$$\n\n$l_n$是本征值，$L_n$是本征态。\n\n由测量原理，本征值必须是实数。所以可以观测的力学量对应的算符都是厄米算符。\n\n### 态叠加原理\n\n离散谱：\n\n$$\n\\bra{m}n\\rangle = \\delta_{mn}\\\\\n\\ket{\\psi} = \\sum_n C_n\\ket{n}\\\\\n概率幅：\\bra{m}\\psi \\rangle = C_m\\\\\n\\ket{A} = \\sum_{n}(\\bra{n}A\\rangle)\\ket{n} = \\left(\\sum_n \\ket{n}\\bra{n}\\right)\\ket{A}\\\\\n\\Rightarrow \\sum_n \\ket{n}\\bra{n}=1(本征矢的完备性表示)\n$$\n\n连续谱：\n\n$$\n\\bra{x_0^\\prime}x_0\\rangle = \\delta(x_0^\\prime - x_0)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}C(x_0)\\ket{x_0}\\mathrm dx_0 \\\\\n概率幅：\\bra{x_0^\\prime}\\psi\\rangle = C(x_0^\\prime)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}\\bra{x_0}\\psi\\rangle\\ket{x_0}\\mathrm dx_0 = \\left(\\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0\\right)\\ket{\\psi}\\\\\n\\Rightarrow \\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0 = 1(连续谱的完备性方程)\n$$\n\n注：$C(x_0) = \\bra{x_0}\\psi\\rangle$就是波函数$\\psi(x_0)$。$|\\bra{x_0}\\psi\\rangle|^2 = |\\psi(x_0)|^2 = \\psi^*(x_0)\\psi(x_0)$是概率密度。\n\n### 正则量子化假设\n\n对易关系：$[\\hat A, \\hat B]= \\hat A\\hat B - \\hat B\\hat A$，若$[\\hat A , \\hat B]=0$，则称$A$与$B$对易，否则称不对易。\n\n正则量子化假设：\n\n$$\n[\\hat{x}, \\hat{p_x}] = i\\hbar,\n[\\hat{y}, \\hat{p_y}] = i\\hbar, \n[\\hat{z}, \\hat{p_z}] = i\\hbar\n$$\n\n其余$x, y, z, p_x, p_y, p_z$的组合均对易。\n\n满足$\\hat{\\vec A}\\times \\hat{\\vec A} = i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L = \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。\n\n$\\hat A$和$\\hat B$可以同时测准的充分必要条件：\n\n$$\n[\\hat A, \\hat{B}] = 0\\Leftrightarrow 有共同本征态\n$$\n\n简并：1个本征值对应m个量子态,称为m重简并。\n\n产生简并的原因：对称性=>守恒量。\n\n如果$\\hat A$是m重简并的，只测量得到本征值A，无法确定对应的量子态。但是如果同时测量对易的$\\hat B$，就可以确定对应的$|A, B_i\\rangle$，则对应的A的量子态是$|A_i\\rangle$。\n\n力学量完全集：能完备描述、确定量子态的力学量算符必须包含$\\hat H$。\n\n$\\hat H$是核心力学量。\n\n$$\n[\\hat A, \\hat H]=0\\Leftrightarrow \\hat A是守恒量\n$$\n选择力学量的完全集，就是选择守恒量的完全集。\n\n## 原子中的电子\n\n### 氢原子理论\n\n巴耳末公式->里德伯方程->波尔氢原子理论\n\n氢原子理论：\n\n定态条件\n\n电子绕核作圆周运动，有确定能量，不辐射能量-经典轨道+定态\n\n频率条件\n\n电子在定态之间跃迁满足：$\\nu = (E_i - E_f)/h$\n\n轨道角动量：$L_n = mv_nr_n = n\\hbar$，轨道半径$r_n = n^2r_1$\n\n能级公式：$E_n = -13.6eV/n^2$\n\n类氢离子能级：核外只有一个电子，核电荷数大于1.例如$He^+, Li^{2+}$\n\n评价：\n\n波尔理论解释了氢原子和类氢离子光谱的波长和频率。\n\n但是不能解释氢原子的光谱线强度，也不能解释其他原子的光谱结构。\n* 与经典电磁理论矛盾\n* 角动量量子化条件是硬加的\n* 卢瑟福的质疑：电子知道要往$E_2$跳才能往$E_2$跳，但是又必须先跳过去才能知道要往$E_2$跳\n* 薛定谔的非难：当电子离开$E_1$态之后，进入$E_2$态之前，它在哪里，是什么状态？\n\n轨道概念不再适用。定态、能级、跃迁频率条件、角动量量子化仍然被认为是正确的。\n\n### 氢原子的量子力学处理\n\n求解量子问题的要点之一：确定体系的力学量完全集，即力学量可以同时测准，具有共同本征态，相应量子数集可完备地描述体系状态。\n\n通常选择守恒量完全集，和体系对称性有关。\n\n氢原子问题的守恒量完全集：$\\hat H, \\hat L^2, \\hat L_z$\n\n**角动量量子化：**\n\n处于中心力场的氢原子电子，角动量守恒。\n\n求$\\hat  L_z$的本征值：\n\n$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\\\\\n\n\\hat L_z \\varPhi = L_z \\varPhi\\Rightarrow \\varPhi = Ae^{\\frac{i}{\\hbar}L_z\\varphi}\n$$\n\n根据标准条件（周期性），$\\varPhi(\\varphi) = \\varPhi(\\varphi + 2\\pi)$，带入解得$L_z = m_l\\hbar$，$m_l = 0, \\pm1, \\pm2,\\dots$称为磁量子数。\n\n对应的本征函数：$\\varPhi_{m_l}(\\varphi) = Ae^{im_l\\varPhi} = \\frac{1}{\\sqrt{2\\pi}}e^{im_l\\varphi}$\n\n求$\\hat L^2$的本征值：\n\n结论：$L^2 = l(l+1)\\hbar^2$，$l = 0, 1, 2, \\dots$称为角量子数。\n\n（$\\hat L^2$和$\\hat L_z$具有的共同本征值为球谐函数$Y_{ml}(\\theta, \\varphi)$）\n\n角动量的空间量子化\n\n$L = \\sqrt{l(l+1)}\\hbar > L_z = m_l\\hbar \\Rightarrow m_l = 0, \\pm1, \\pm2,\\dots, \\pm l$。作矢量图可知，角动量有$2l+1$种取向。\n\n**能量量子化**\n\n(省略公式)\n\n$l = 0, 1, \\dots, n - 1$\n\n$\\hat H, \\hat L^2, \\hat L_z$的共同本征态就是定态。\n\n能量的本征值只与主量子数n有关，因而出现了能量简并，不同的角量子数和磁量子数可以对应相同的能量本征值。同能量的本征值态称为能级简并态，包含的态数目称为能级简并度。\n\n角量子数$l = 0, 1, 2...$对应的状态分别称为$s, p, d...$，从概率波图像可以看出，角量子数低的电子更容易靠近原子中心。\n\n### 电子自旋\n\n轨道角动量产生磁矩：\n$$\n\\hat{\\vec \\mu} = -\\frac{e}{2m_e}\\hat{\\vec L}\n$$\n\n玻尔磁子：\n\n$$\n\\mu_B = \\frac{e\\hbar}{2m_e}\n$$\n\n利用本征值的定义不难推出z方向的磁矩：\n$$\n\\mu_z = -m_l \\cdot \\mu_B\n$$\n\n斯特恩-盖拉赫实验\n\n理论分析：\n\n磁矩在外磁场中有势能：$E = -\\vec \\mu \\cdot \\vec B$\n\n轨道磁矩在z方向受力：\n\n$$\nF_z = \\frac{\\partial E}{\\partial z} = \\mu_z\\frac{\\partial B_z}{\\partial z} = -m_l\\mu_B\\frac{\\partial B_z}{\\partial z}\n$$\n\n由于$m_l$的$2l+1$种取值，对应的原子束应该在z方向上分裂成奇数条线。\n\n![](/source/images/physics/abaaba.jpg)\n\n问题：$Ag, H$等原子束($l = 0$)出现了2条线而不是一条线，矛盾。\n\n电子自旋的假设：\n\n* 电子不是质点，而是自旋的小球，具有固有的自旋角动量$\\vec S$和自旋磁矩$\\vec \\mu_S$\n* $S = \\sqrt{s(s+1)}\\hbar$，其中$s = \\frac 12$称为自旋量子数\n* $S_z = m_s\\hbar$，$m_s = \\pm\\frac 12$，称为自旋磁量子数\n* 自旋磁矩和自旋角动量满足$\\hat {\\vec \\mu_S} = -\\frac{e}{m_e}\\hat {\\vec S}$，进而推出$\\mu_{S,z}=\\pm \\mu_B$\n\n“自转小球”模型仍存在缺陷：电子表面的速度会超过光速。\n\n但是这些假设成功解释了原子光谱的精细结构和反常塞曼效应。\n\n量子力学的解释：\n\n* 自旋是与时空无关的内禀运动，一种新的自由度，一种新的角动量，无经典对应\n* 自旋、磁矩和静止质量、电荷一样，是反映微观粒子固有属性的基本量\n* 电子的自旋是一种相对论效应，被自动地包含在相对论波动方程(Dirac方程)中。\n\n电子的总角动量：\n\n$$\n\\hat {\\vec J} = \\hat {\\vec L} + \\hat {\\vec S}\n$$\n\n$\\hat {\\vec J}$也是量子化的，大小为：\n$$\nJ = \\sqrt{j(j + 1)}\\hbar\n$$\n\n前文已说过如下定义：\n>满足$\\hat{\\vec A}\\times \\hat{\\vec A} = i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L = \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。\n\n可以验证$\\hat {\\vec J }\\times \\hat {\\vec J } = i\\hbar \\hat {\\vec J }$。因此总角动量还是角动量。\n\n这一角动量的合成被称为自旋——轨道耦合。$j$称为总角动量量子数。\n\n$$\nl = 0: \n\\\\\nj = s = \\frac 12, m_j = -\\frac 12, +\\frac 12\\\\\nl \\ne 0:\\\\\nj = l + s = l + \\frac 12, m_j = -(l + \\frac 12), \\dots, l + \\frac 12;\\\\\nj = l - s = l - \\frac 12, m_j = -(l - \\frac12), \\dots, l - \\frac12\n$$\n\n碱金属原子光谱：\n\n碱金属的原子能级既和$n$有关，又和$l$有关。\n\n轨道角动量对原子的影响包括轨道贯穿和原子实极化，导致相应能级能量降低。\n\n因此原来相同能级的$3s,3p,...$会分裂成不同能级的轨道。\n\n碱金属原子光谱的精细结构：\n\n电子的轨道运动会使得它感受到原子绕它转动的磁场$\\vec B_{Nuc}$的作用。\n\n电子自旋磁矩$\\vec \\mu_s$和$\\vec B_{Nuc}$的相互作用就是自旋轨道耦合，是相对论效应。\n\n于是能级在自旋轨道耦合的影响下进一步分裂，形成了能级精细结构。\n\n### 微观粒子全同性原理\n\n两个微观粒子的全部内禀属性相同称为全同粒子。对调全同粒子不会影响系统的状态。\n\n数学上对应地表现为波函数模方相同，进而有波函数对称或者反对称。\n\n对称的波函数表达式：\n\n$$\n\\psi(q_1, q_2) = \\frac {1}{\\sqrt 2}[\\phi_A(q_1)\\phi_B(q_2) + \\phi_A(q_2)\\phi_B(q_1)]\n$$\n\n反对称的波函数表达式：\n\n\n$$\n\\psi(q_1, q_2) = \\frac{1}{\\sqrt{2}}[\\phi_A(q_1)\\phi_B(q_2) - \\phi_A(q_2)\\phi_B(q_1)]\n$$\n\n如果$\\phi_A=\\phi_B$，则反对称波函数为0。\n\n费米子是自旋为半整数的粒子。它是波函数反对称的粒子。由此得到泡利不相容原理：全同费米子系统不能有两个及以上的费米子占据同一单粒子态。\n\n玻色子是自旋为0或者整数的粒子。它是波函数对称的粒子。玻色子不受泡利不相容原理的限制。\n\n费米统计：\n\n$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} + 1}\n$$\n\n$\\mu = \\mu(T)$是粒子化学势。\n\n玻色统计：\n\n$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} - 1}\n$$\n\n对所有温度T,$0\\le N(E)\\lt \\infty$。\n\n玻色-爱因斯坦凝聚。\n\n当$E$很高时，$(E - \\mu) >> kT$。退化为麦克斯韦-玻尔兹曼统计。\n\n### 原子核外电子的排布\n\n4个量子数$n,l,m_l,m_s$可以完备描述原子的电子运动状态。\n\n","source":"_posts/Physics.md","raw":"---\ntitle: 大雾笔记\ndate: 2022-09-14 17:20:10\ntags: note\nkatex: true\n---\n\n# 参考教材\n\n嫌教材太简单可以看看\n\n《热学》lhf例题很多，很详细，很多数学比教材难\n\n《》\n\n《新概念物理教程-力学》新颖，比较硬核。\n\n《费恩曼物理学讲义》\n\n《新概念物理教程-光学》公认最好教材\n\n《光学》chb, lyp\n\n量子物理没有太好的参考书。\n\n《原子物理学》杨福家编。现在没有原子物理了，只有量子物理。有时用经典方法，有时候用量子物理的方法。前几章和教材一致，实验讲得不错。\n\n量子力学教程。周世勋。内容有点少。\n\n《费恩曼物理学讲义》第3卷。相当有深度（量子物理）。\n\n*Phyisics* Vol.1 & 2。难度介于大学物理学和物理系教材之间。\n\n\n\n### 杂项\n\n牛顿运动方程一般个数少，微分阶数高；哈密顿正则方程一般个数多，微分阶数低。\n\n# 热学\n\n## 温度\n\n分子动理论：热学中比较古老的理论。\n\n教材中关于统计物理的内容不够透彻。\n\n建议学习分析力学（重点：哈密顿力学），对后续量子力学有帮助。固体物理也会使用相关技巧。哈密顿量，相空间，拉格朗日方程。不用看证明，能用就行。\n\n\n\n### 热学研究内容与对象\n\n内容：与热现象有关的性质和规律。\n\n热现象：宏观上与温度有关，微观上与分子热运动有关。\n\n对象：大量微观粒子构成的体积有限的物体-热力学系统。（量大：统计学规律。）\n\n经常讨论系统和外界（环境）。一种说法：宇宙是不是热力学系统？不是，因为宇宙之外没有外界。所以热二定律可能不适用于整个宇宙。\n\n孤立系统：与外界没有任何相互作用。\n\n绝热系统：有功的交换，没有热量交换\n\n封闭系统：有能量交换，无粒子交换\n\n开放系统：既有能量交换，也有粒子交换\n\n### 热力学的研究方法\n\n#### 热力学\n\n宏观理论方法。依赖于实验。不涉及物质的微观结构和微观运动规律。具有极大的普遍性，可靠性。\n\n#### 统计物理学\n\n微观理论方法。从微观模型假设出发，力学 + 统计理论建立微观量和宏观量的关系。可解释本质，但是受模型局限。\n\n### 几个重要概念\n\n#### 平衡态\n\n热力学系统内部，宏观上不存在能量和粒子的流动，系统宏观性质不随时间变化。（体积、压强、温度）\n\n热力学平衡条件：\n\n力学平衡条件：若系统与外界有力学作用，平衡时内外压强相等。\n\n热平衡条件：若系统与外界可交换热量，平衡时内外温度应相等。\n\n相平衡条件：若系统与外界处于不同相的共存状态，平衡时要达到力学平衡、热平衡以及相平衡。\n\n化学平衡条件：浓度不同的系统混到一起，平衡时要满足上面三个条件，并且浓度均匀。\n\n注意区分平衡态和稳定态：\n\n![../images/pht.png]\n\n#### 宏观量\n\n描述系统宏观性质的量。可直接测量。\n\n广延量：有累加性。如M, V, E...\n\n强度量：无累加性。如p, T...\n\n#### 微观量\n\n描述微观粒子性质的量。需要间接测量。\n\n如分子的m, v, d...\n\n#### 状态参量\n\n描述系统平衡态及其宏观性质的物理量。\n\np, V, T, v, 内能E, 熵S, 焓H\n\n一组态参量对应一个平衡态。\n\n实验表明：状态参量之间不是相互独立的。\n\n常选p, V, T作为自变量，其他的当作函数（E, S, H）-热力学函数。\n\n对物质量确定的单元（单一组元，不能由多种物质混合）单相（同一种状态，不能有固液同时存在等等）系统，p, V, T只有两个是独立的：T(p, V), E(p, V)。\n\n统计物理：状态参量之间的偏导数关系。\n\n#### 物态方程\n\n两个最基本的热力学函数之一（物态方程和内能）。态参量之间的函数关系: f(T, p, V) = 0\n\n通过测量确定。\n\n理想气体物态方程：\n\n$pV = νRT$\n\n$p = nkT$\n\n$k = \\frac{R}{N_A}$\n\n$\\nu$ 气体摩尔数\n\n$k$ 玻尔兹曼常量\n\n### 温度\n\n#### 热平衡态\n\n两个系统长时间热接触达到的共同平衡态。\n\n#### 热力学第零定律\n\n实验表明： A与C热平衡，B与C热平衡，A和B也必然保持热平衡。\n\n非热接触的两个系统也可以处在同一个热平衡态。\n\n温度：处于同一热平衡态下的热力学系统所具有的共同的宏观性质。\n\n处在同一热平衡态的系统具有相同的温度。\n\n#### 温标\n\n理想气体温标；用理想气体做测温物质。单位: $K$(Kelvin)， 范围适用 $> 0.5K$\n\n实验表明：一定质量的理想气体在同一个热平衡态下，$pV$不变。\n\n规定$T \\propto pV$，水的三相点温度为$T_3 = 273.16K$\n\n$$T = T_3\\frac{pV}{p_3V_3} = 273.16\\frac{pV}{p_3V_3}$$\n\n热力学温标$T$：理论温标，与物质无关。\n\n单位: $K$，适用于所有温度范围，在理想气体温标范围内与理气温标一致。\n\n### 统计物理学的观点、概念简介\n\n统计物理学包括平衡态统计理论，非平衡态统计理论和涨落理论。它从物质的微观结构和微观运动来阐明物质的宏观性质。其基本观点：\n\n- 宏观物体由大量的微观粒子（原子、分子、电子、光子等）构成。\n- 微观粒子的运动服从力学规律。原则上说服从量子力学规律，一定条件下可以用经典力学处理。\n- 从微观角度看，物体以一定的概率出现在各个微观状态上，物质的宏观性质就是物质微观性质的统计平均。宏观量是有关微观量的统计平均值。\n\n#### 近独立子系统\n\n构成系统的粒子间相互作用很弱，系统能量近似等于各粒子能量总和，如理想气体。\n\n#### 微观状态（力学运动状态）\n\n##### 经典力学描述\n\n常采用正则形式，即广义坐标和广义动量描述。\n\n- 子相空间（μ空间）：由粒子的广义坐标$q_i$和广义动量$p_i$（$i = 1, \\dots, r$, $r$是粒子自由度）构成的2r维空间。\n\n  1组$(q_1, \\dots, q_r, p_1, \\dots, p_r)$的取值表示粒子的1个微观状态，对应于子相空间的一个点。\n\n  更确切的说，在子相空间 $( q_1,... , q_r , p_1,..., p_r )$位置处的体积元 $d q_1...d q_r dp_1...dp_r$中的点，都是由$( q_1,... , q_r , p_1,..., p_r )$描述的相同的粒子微观状态。\n\n  位形空间（坐标构成的空间），速度空间（速度构成的空间）。\n\n  傅里叶变换和傅里叶级数的区别：一个离散，一个连续。\n\n- 系统的微观状态是由所有粒子的广义坐标和广义动量描述的。\n\n##### 量子力学描述\n\n量子力学中假设运动状态用量子态描述。\n\n- 粒子的微观状态用单粒子（量子）态描述。\n\n  单粒子态由一组量子数描述：如 $|n, l, m_l, m_s >$ 。 1 组取值确定的$ |n, l, m_l, m_s > $表示 1 个单粒子态。 当粒子状态是由某个单粒子态描述时，称为粒子处于某个单粒子态，或粒子占据某个单粒子态\n\n- 系统微观状态用多粒子（量子）态描述。\n\n  对近独立子系统，多粒子态可由单粒子态表示： 系统所有粒子的 1 组单粒子占据态就表示系统的 1 个 多粒子态，即表示系统的 1 个 微观状态。\n\n微观粒子全同性原理\n\n全同粒子：内禀属性如质量、电荷、自旋等相同 \n\n微观粒子全同性原理是量子力学假设。 \n\n全同性原理：对全同粒子组成的系统，交换任意 2个全同粒子，系统微观状态不变。\n\n泡利不相容原理：对全同费米子系统，不能有两个及以上的费米子占据同一单粒子态。\n\n费米子：自旋为半整数；玻色子：自旋为整数。\n\n#### 宏观状态和微观状态的关系\n\n系统的宏观状态由宏观量表征，如 E、N、V。 \n\n系统的微观状态，如果用经典描述，则由所有粒子 的坐标和动量表征。 \n\n玻耳兹曼认为：从微观上看，对于一个系统的状态 的宏观描述是非常不完善的，系统的同一个宏观状 态实际上可能对应于非常非常多的微观状态，而这 些微观状态是粗略的宏观描述所不能加以区别的。\n\n 这意味着宏观状态和微观状态、宏观量和微观量具 有内在联系，这种联系是种统计关系。\n\n#### 统计规律性\n\n统计物理发展早期，人们普遍认为：研究物体宏观 性质，应从求解粒子的力学运动方程出发来解决。 但由于粒子数太多，求解力学方程困难，迫不得已 得引入统计方法。而且这个统计是：宏观量是相应 微观量的长时间平均。 即原则上力学规律可完全决定物体宏观性质  \n\n这种观点无法解释根本问题：热现象的不可逆性。 因为把力学运动方程（牛顿方程或薛定谔方程）用 到微观粒子，是时间反演对称的 — 可逆的。\n\n这表明仅通过力学规律来解释物体的宏观性质是 不可能的，而有赖于新的规律 — 统计规律。\n\n\n\n力学规律是决定论性的，可表述为：在一定初始 条件下，某时刻系统必然处于一确定的运动状态。 \n\n统计规律可以表述为：在一定的宏观条件下，某 时刻系统以一定的概率处于某一微观状态。 \n\n即宏观状态与微观状态之间的联系是概率性的， 具有统计规律的特性，而不是决定论性的。\n\n统计规律的稳定性：只要 N 足够大，每次得到的分布几乎相同\n\n统计规律的涨落：每次实验中得到的比例 Ni /N 稍有差别。N 越大，涨落越小。\n\n即对变量是离散取值的情况，直接采用概率， 对变量是连续取值的情况，需要引入概率密度。\n\n热现象本质是统计规律的反映。\n\n##### 平衡态统计理论的基本假设：等概率原理 \n\n处于平衡态下的孤立系统，系统各个可能的微观 状态出现的概率相等。 “可能的微观状态”是指孤立系统的宏观条件所 允许的那些微观状态，即这些微观状态对应于给 定的 E、V、N\n\n##### 平衡态下近独立子系统的统计规律 \n\n处于平衡态下的热力学系统，宏观状态不变，但 相应的微观状态不断变化，是一种动态平衡。 根据等概率原理，平衡态包含的微观状态数目是 最多的 — 最概然态\n\n求统计分布函数：对于每个统计分布函数，可以计算它们对应的微观态数目（微观态数目是统计分布函数的函数）。在E, N不变的条件下，只要找到对应微观态数目最多的统计分布函数，就是平衡态的统计分布函数。\n\n对近独立子系统，采用经典力学及等概率原理只能得到一种经典统计：麦克斯韦-玻尔兹曼统计；采用量子力学及等概率原理得到3种统计：麦克斯韦-玻尔兹曼统计，费米-狄拉克统计，玻色-爱因斯坦统计。\n\n造成 3 种量子统计规律的原因是微观粒子的全同性原理和泡利不相容原理。\n\n麦克斯韦-玻尔兹曼统计适用于定域子系统，费米 - 狄拉克统计、玻色 - 爱因斯坦统计适用于非定域 子系统。\n\n 定域：全同粒子系统中的粒子的波包局限在空间 一定范围内，之间没有重叠，全同性原理 不起作用，可以通过位置分辨粒子。\n\n 经典的和量子的麦克斯韦-玻尔兹曼统计在数学形 式上一致。而在一定条件下，量子的 3 种统计都可 退化为经典的麦克斯韦-玻尔兹曼统计\n\n## 气体动理论\n\n#### 气体动理论的基本观点\n\n气体动理论（分子动理论），发展于 19 世纪下半 期，基于经典理论，是统计物理学的原型，被不断 补充发展完善成为统计物理学，其所得的结论可通 过统计物理得到。至今仍在诸多领域有重要应用。\n\n1. 宏观物体是由大量分子、原子构成的，分子间 存在一定的间隙。\n1. 分子永不停息地作无规则运动 — 热运动\n1.  分子间存在一定的相互作用。\n\n### 理想气体的压强\n\n##### 关于理想气体的假设\n\n###### 单个分子服从的力学规律\n\n理想气体模型：\n\n大小：分子线度<<分子间平均距离\n\n分子力：除碰撞的瞬间，在分子间、分子与器壁间无作用力\n\n碰撞性质：弹性碰撞\n\n服从规律：牛顿力学\n\n###### 大量分子处于平衡态时的统计假设\n\n（1）无外场时，分子在各处出现的概率相同\n$$n = \\frac{\\mathrm d N}{\\mathrm d V} = \\frac NV = \\text{const}.$$\n（2）由于碰撞，分子可以有各种不同速度\n\n速度取向各方向等概率：\n$$\\bar{v_x} = \\bar{v_y} = \\bar{v_z} = 0\\\\\\\\\\bar{v_x^2} = \\bar{v_y^2} = \\bar{v_z^2} = \\frac 13 \\bar{v^2}$$\n\n##### 理想气体压强公式\n\n前提：平衡态，忽略重力，分子当成质点\n$$p = \\frac13nm\\bar{v^2} = \\frac23n\\bar\\varepsilon_t, \\\\\\\\\\bar\\varepsilon_t = \\frac12 mv^2$$\n\n### 温度的统计意义\n\n$$\\bar\\varepsilon_t = \\frac{3p}{2n} = \\frac{3nkT}{2n} = \\frac32kT\\\\\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}{M}}$$\n\n$T = 273K$, \n\n$\\bar{\\varepsilon}_t$数量级：$10^{-2}$eV\n\n$\\sqrt{\\bar{v^2}}$\n\n$H_2$: $1.84\\times 10^3m/s$\n\n$O2$: $4.61\\times 10^2m/s$\n\n### 能量均分定理\n\n自由度：决定物体空间位置的独立坐标数，用$i$表示\n\n##### 单原子分子\n\n平动自由度:$t = 3$ \n\n$i = 3$\n\n##### 双原子分子\n\n质心平动：$t = 3$\n\n轴取向：$r = 2$\n\n距离变化：$v = 1$\n\n总自由度: $i = 6$\n\n##### 多原子分子\n\n设分子包含$N$个原子\n\n$i = 3N$\n\n$t = 3$\n\n$r = 3$\n\n$v = 3N-6$\n\n##### 能量均分定理\n\n一个平动自由度对应的平均动能为$\\frac12kT$\n\n考虑平动、振动和转动，由于分子的碰撞，分子平均动能均匀分配到每个自由度上。\n\n在温度$T$的平衡态下，分子热运动的每个自由度对应的平均动能都等于$\\frac12kT$。\n\n\n\n普遍的能量均分定理：\n\n分子能量中每具有一个平方项，就对应一个$\\frac12kT$的平均能量。\n\n分子振动的动能和势能都是平方项，所以：\n\n$\\bar\\varepsilon_{vP} = \\bar\\varepsilon_{vk} = v\\frac12kT$,  $\\bar\\varepsilon_v = \\bar\\varepsilon_{vP}  + \\bar\\varepsilon_{vk} = vkT$\n$$\\bar\\varepsilon = \\bar\\varepsilon _t + \\bar\\varepsilon_r + \\bar\\varepsilon_v = (t + r + 2v)\\frac12kT$$\n通常情况下($T < 10^3K$)，振动自由度被“冻结”，分子可视为刚性\n\n刚性分子：$v = 0, i = t + r$\n$$\\bar\\varepsilon = \\frac{t+ r}2kT$$\n\n##### 理想气体内能\n\n内能：系统内部各种形式能量的总和，不包括系统整体质心运动的能量\n\n分子内部： $\\bar\\varepsilon = (t + r + 2v)\\frac12kT$\n\n分子之间：相互作用势能$\\varepsilon_{\\mathrm pij}$\n\n内能：$E = N\\bar\\varepsilon + \\sum_i\\sum_{j<i}\\varepsilon_{\\mathrm pij} = E(T, V)$\n\n理想气体： $\\varepsilon_{\\mathrm pij} = 0,E = E(T)$\n\n### 麦克斯韦速度分布律\n\n分布函数是体现热力学系统的统计规律性的重要函数.\n\n常见的统计分布函数包括：速率分布函数、速度分布函数、能量分布函数等。\n\n通过分布函数可计算微观量的统计平均值，如$\\bar\\varepsilon_t, \\bar{v^2}$等，进而得到系统的宏观量。\n\n##### 速率分布函数\n\n$$f(v) = \\frac{\\text dN}{N\\text dv}\\\\\\\\\\int_0^\\infty f(v)\\text dv = \\int_0^\\infty\\frac{\\text dN}{N} = 1$$\n\n##### 麦克斯韦速率分布函数（不用记）\n\n$$f(v) = 4\\pi (\\frac m{2\\pi kT})^{3/2}e$$\n\n##### 三种统计速率\n\n###### 最概然速率\n\n$$v_p = \\sqrt{\\frac{2kT}{m}}$$\n\nm一定时，温度T越高，速率大的分子数比例越大，最概然速率越大， $f(v_p)$越小。\n\n###### 平均速率\n\n$$\\bar v = \\int_0^\\infty vf(v)\\text dv$$\n\n任意函数对全体分子按速率分布的平均值为\n\n<font color =\"red\">$f(v)$一定要归一化!</font><p>例如求0到vp/2的平均速率，首先要将f(v)归一化成这个区间内的速率分布，而不是直接用全部速率分布</p>\n$$\\bar{\\phi(v)} =\\int_0^\\infty \\phi(v)f(v)\\text dv$$\n\n由麦克斯韦速率分布函数\n\n$$\\bar v = \\sqrt{\\frac{8kT}{\\pi m}} = \\sqrt{\\frac{8RT}{\\pi M}}$$\n\n###### 方均根速率\n\n$$\\bar{v^2} = \\int_0^\\infty v^2f(v)\\text dv = \\frac{3kT}{m}\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}M}$$\n\n##### 麦克斯韦速度分布律\n\n$$\\frac{\\text dN}{N} = \\left(\\frac{m}{2\\pi kT}\\right)^{3/2}e^{-m(v_x^2 + v_y^2 + v_z^2)/2kT}\\text{d}v_x\\text{d}v_y\\text{d}v_x$$\n\n速度分量的分布函数\n\n$$g(v) = (\\frac m{2\\pi kT})^{1/2}e^{-mv^2/2kT}$$\n\n##### 分子碰壁数$Γ$\n\n$$\\Gamma = \\frac14 n\\bar v$$\n\n##### 玻尔兹曼分布\n\n###### 恒温气压公式\n\n$$p = p_0e^{-mgz/kT}\\\\\\\\n = n_0e^{-mgz/kT}$$\n\n###### 玻尔兹曼分布\n\n$$\\text dN_{\\vec r} = n_0 \\cdot e^{-\\varepsilon_p(\\vec r)/kT} \\cdot \\text d^3 \\vec r\\\\\\\\\\text d^3\\vec r = \\text dx \\ \\text dy \\  \\text dz$$\n\n###### 玻尔兹曼-麦克斯韦分布\n\n$$\\text dN = n_0 \\cdot (\\frac m{2\\pi kT})^{3/2} \\cdot e^{-[\\frac12 mv^2 + \\varepsilon_p(\\vec r)]/kT} \\cdot \\text d^3\\vec r \\cdot \\text d^3 \\vec v$$\n\n能量简并：不同子相空间分子能量相等。\n\n分子按能量分布：\n\n$$N(\\varepsilon) = C \\cdot w(\\varepsilon) \\cdot e^{-\\frac{\\varepsilon}{kT}}$$\n\n$\\varepsilon$为粒子的能量，$w(\\varepsilon)$为具有此能量的体积元个数.\n\n### 范德瓦尔斯方程\n\n#### 范氏气体模型\n\n气体分子间的作用力：分子间的作用力很复杂，主要是电磁力，可以分为引力和斥力\n\n范氏气体模型：对理想气体做两方面的修正。考虑分子体积、分子间作用力引起的修正。\n\n![范氏气体](../images/physics/VanGas.png)\n\n* 分子是直径为d的刚球\n* 在$d\\rightarrow s$的范围内，分子间有恒定引力\n\n#### 范德瓦尔斯方程\n\n范德瓦尔斯方程：\n\n\n设:\n\n$\\nu = 1 mol$\n\n$p$ -- 实测气体压强\n\n$V_m$ -- $1\\ mol$气体容积\n\n对理想气体：$pV_m = RT$\n\n对真实气体：\n\n1. 分子体积引起的修正\n\n分子自由活动空间的体积为$V_m - b$\n\n$$p(V_m - b) = RT$$\n\n$$\np = \\frac{RT}{V_m - b}\n$$\n\n2. 分子间引力引起的修正\n\n气体分子间作用力一般表现为引力。\n\n在容器内部，单个气体分子受到各个方向的平均引力相等，合力可以看作零。\n\n但是在容器边缘，单个气体分子受到的引力是不对称的。气体分子所受的合力指向容器内部，因此撞击容器壁的气体分子动量比理想气体下的情况要小，宏观上形成的压强比理想气体情况要小。\n\n$$\np < \\frac{RT}{V_m - b}\\\\\n$$\n\n设\n\n$$\np = \\frac{RT}{V_m - b} - p_{in}\n$$\n\n$p_{in} \\propto nf_{合}, f_{合}\\propto n \\Rightarrow p_{in} \\propto n^2 \\propto \\frac 1{V_m^2}$\n\n最后得到：\n$$\n(p + \\frac a{V_m^2})(V_m - b) = RT\n$$\n\n对 ν mol 气体：\n\n$$\n(p + \\nu^2 \\cdot \\frac a{V^2})(V - \\nu b) = \\nu RT\n$$\n\n常温常压下：$b/V_m \\sim 10^{-3}, p_{in}/p \\sim 10^{-2}$，这时分子体积和分子间的作用力修正可以忽略。\n\n#### 气体的等温线\n\n真实气体的等温线：\n\n![RealGasTemp](../images/physics/RealGasTemp.png)\n\n范氏气体的等温线：\n\n![VanGasTemp](../images/physics/VanGasTemp.png)\n\n如何计算临界参数：\n\n临界参数：临界点K对应的$p_K, V_K, T_K$\n\n临界点K是等温线的拐点：\n\n$$\n\\left(\\frac{\\partial p}{\\partial V}\\right)_{T = T_K} = 0\\\\\n\\left(\\frac{\\partial^2 p}{\\partial V^2}\\right)_{T = T_K} = 0\n$$\n\nK同时也是三次方程的三重根，因此可以通过假设$(V_m - V_{mK})^3 = 0$展开后和范德瓦尔斯方程对比系数求解。\n\n#### 范氏气体内能\n\n理想气体： $E(T) = i\\nu RT / 2$\n\n范氏气体：$V\\uparrow \\rightarrow p_{in}做负功\\rightarrow 分子间势能E_p\\uparrow$\n\n要计算势能，首先要定义势能为0的状态：定义某种位形为0势能。其他状态的势能定义为从这种状态变形到0势能状态的过程中保守力的变化。\n\n$$\\mathrm dA = -p_{in}S\\mathrm dl = -p_{in}\\mathrm dV$$\n\n设$E_p(V = \\infty) = 0$。\n\n$$\nE_p(V) = \\int_V^\\infty -p_{in}\\mathrm dV = \\int_V^\\infty-\\nu^2 \\cdot \\frac a{V^2}\\mathrm dV = -v^2 \\cdot \\frac aV\n$$\n\n$$\nE = E_k + E_p = \\frac i2\\nu RT - \\nu ^2\\frac aV\n$$\n\n**结论：**\n$$E(T, V) = \\frac i2 \\nu RT - \\nu^2 \\frac aV$$\n\n#### 一个细节\n\n为什么不考虑气体分子和容器壁分子间的引力？\n\n事实上，这引力确实存在。但是可以通过动量定理证明，碰撞过程这引力的作用总和为0。\n\n### 气体分子的碰撞、平均自由程\n\n平均碰撞频率和平均自由程\n\n平均碰撞频率$\\bar z$：单位时间内一个气体分子与其他分子碰撞的平均次数\n\n平均自由程$\\bar \\lambda$：气体分子在相邻两次碰撞之间飞行的平均路程。\n\n平均碰撞频率和平均频率之间关系\n\n对象:平衡态下的理想气体\n\n假定：\n\n(1)只有一种分子；\n\n(2)分子可视作直径为d的刚球；\n\n(3)被考察的分子以平均相对速率$\\bar u$运动，其余的分子静止。\n\n碰撞界面为$\\sigma$。分子间平均相对速率为$\\bar u = \\sqrt 2 \\bar v$。\n\n$$\n\\bar z = \\sigma \\bar u n = \\pi d^2 n \\bar u = \\sqrt 2 \\pi d^2 n\\bar v\n$$\n\n平均自由程和压强、温度的关系：\n\n$$\n\\bar\\lambda = \\frac {\\bar v} {\\bar z} = \\frac 1{\\sqrt2 \\pi d^2 n} = \\frac {kT}{\\sqrt2\\pi d^2p} \\propto \\frac{T}{p}\n$$\n\n### 气体输运过程\n\n非平衡态下，气体内部各部分性质不均匀，就会产生热量、动量、质量的迁移，称为输运过程或内迁移过程。\n\n气体输运过程包括：热传导、扩散和内摩擦（粘滞）。\n\n输运现象的宏观实验定律和原因。\n\n热传导\n\n温度不均匀。实验定律：傅里叶定律，热传导方程。\n\n考虑1维的情形。\n\n$$\n\\mathrm dQ = -\\kappa \\frac{\\partial T}{\\partial x}\\mathrm dS \\mathrm dt\n$$\n\n$$\nj(x, t) = \\frac{\\mathrm dQ}{\\mathrm dS\\mathrm dt}  = -\\kappa \\frac {\\partial T(x, t)}{\\partial x}\n$$\n\n$j(x, t)$：热流密度，$\\partial T/\\partial x$：温度梯度。\n\n温度梯度“力”导致热流。\n\n> $T$在这里相当于电势，$-\\partial T / \\partial x$相当于电势的负梯度即电场强度，$j$相当于电流密度，$\\kappa$相当于电导率。因此类比$\\vec{J} = \\sigma \\vec{E}$有$j = -\\kappa \\partial T /\\partial x$。类似的，也许可以推导出热阻的概念？热学的“麦克斯韦”方程组又是什么？\n\n统计物理给出的结论：\n\n$$\n\\kappa = \\frac 13 nm\\bar v \\bar \\lambda c_V\n$$\n\n>如何理解此公式：热传导的本质是分子能量（热量）的交换，交换的热量等于粒子数乘以单个粒子交换的热量。\n>\n>$m$为单个分子质量。$c_V$为定体热容。$n\\bar v$用于描述$\\mathrm dt$内穿过$\\mathrm dS$的粒子数，$\\bar\\lambda$乘以$\\partial T/\\partial x$得到温度的变化量$\\mathrm dT$ ,$m,c_V$与温度的变化量相乘，得到单个粒子交换的热量。\n\n稳恒热流：$\\frac{\\mathrm dQ}{\\mathrm dt} = C$，$j$, $T$与$t$无关。\n\n$\\kappa$称为导热系数，由气体特性和$T, p$决定。\n\n扩散\n\n原因：气体内部离子数浓度不均匀。\n\n斐克定律\n\n$$\n\\mathrm dN = -D\\frac {\\partial n}{\\partial x}\\mathrm dS \\mathrm dt\n$$\n\n>教材的表述为\n>$$\n\\mathrm dM = -D\\frac {\\partial \\rho}{\\partial x}\\mathrm dS \\mathrm dt\n>$$\n>这里的两个$D$是一样的。\n\n统计物理给出的结论：\n\n$$\nD = \\frac13\\bar v\\bar \\lambda\n$$\n\n扩散流密度：\n\n$$\nj(x, t) = \\frac {\\mathrm dN}{\\mathrm dS \\mathrm dt} = -D\\frac {\\partial n}{\\partial x}\n$$\n\n稳恒扩散流：$\\frac {\\mathrm dN}{\\mathrm dt} = C$，$j$, $n$, 与$t$无关。\n\n粒子数守恒方程\n$$\n\\oiint_S j\\cdot \\vec {s} = -\\frac {\\mathrm dN}{\\mathrm dt}, \\nabla \\cdot \\vec j + \\frac{\\partial n}{\\partial x} = 0.\n$$\n\n结合粒子数守恒方程（微分形式）和斐克定律得到扩散方程\n\n$$\n\\frac{\\partial n}{\\partial t} = D\\frac{\\partial^2 n}{\\partial x^2}\n$$\n\n考试考定场稳恒流，不考内摩擦。\n\n内摩擦（粘滞）\n\n根据流体力学，对定常流动的粘滞流体，流速不太大时（雷诺数小），出现层流。\n\n粘滞定律（牛顿摩擦定律）\n\n$$\n\\Delta F = - \\eta \\frac{\\mathrm du}{\\mathrm dz}\\Delta S\n$$\n\n$$\np = -\\eta \\frac{\\mathrm du}{\\mathrm dz}\n$$\n\n粘度和温度有关，气体粘度随温度增加，液体温度随温度减小。遵从粘滞定律的流体称为牛顿流体。\n\n内摩擦原因：流速不均匀。\n\n统计物理给出的结论：\n\n$$\n\\eta = \\frac 13 nm\\bar v\\bar \\lambda\n$$\n\n## 热力学第一定律\n\n### 准静态过程\n\n准静态过程：过程的任一时刻，系统都处于平衡态— 一系列平衡态组成的理想化过程。\n\n若外界条件改变时，能保证和系统相应的强度量之间差无穷小，则过程是准静态的。\n\n弛豫时间τ：平衡破坏到恢复平衡的时间.\n\n当$\\Delta t_{过程} > \\tau$时，过程就可视为准静态过程。\n。\n### 功\n\n体积功：$\\mathrm{\\bar dA} = p\\mathrm dV$\n\n系统对外界做功:$A = \\int_{V_1}^{V_2}p\\mathrm dV$是一个过程量。\n\n通过做功改变系统热力学状态，微观上是分子规则运动的能量通过碰撞转变为无规则运动的能量。\n\n### 内能，热量和热力学第一定律\n\n内能：定义为$E_2 - E_1 = A_{1\\rightarrow 2}$（绝热过程）\n\n内能通过绝热功度量。\n\n热量：定义为$Q = (E_2 - E_1)$（无功过程）\n\n微观本质是分子无规则运动的能量通过碰撞从高温物体向低温物体传递。\n\n热力学第一定律：\n\n$Q = \\Delta E + A$\n\n$\\mathrm {\\bar{d}}Q = \\mathrm d E + \\mathrm{\\bar{d}}A$\n\n热力学第一定律是一条实验定律，适用于任何热力学系统的任何过程。\n\n### 热容量：\n\n$$\nC = \\frac{\\mathrm dQ}{\\mathrm dT}\n$$\n\n定体热容量：$C_v = \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_V$\n\n定压热容量：$C_p = \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_p$\n\n摩尔热容量：\n$$\nC_m = \\frac1\\nu\\frac{\\mathrm dQ}{\\mathrm dT}\n$$\n\n对应地有定体摩尔热容量和定压摩尔热容量。\n\n理想气体内能：$\\Delta E = \\nu C_{V, m}\\Delta T$。（推导：内能变化与过程无关，假设先等体后等温，等体过程无功只有热交换，等温过程内能不变。）\n\n迈耶公式：\n\n$$\nC_{p, m} - C_{V, m} = R\n$$\n\n（推导：用等压过程计算内能的变化，与定体过程的结论比较一下可得。）\n\n理想气体热容量理论公式：\n\n$$\nC_{V, m} = \\frac i2R, C_{p, m} = \\frac{i+2}{2}R\n$$\n\n推导：结合理想气体内能公式。\n\n定义比热容比:$\\gamma = C_{p, m}/C_{V, m}$\n\n### 绝热过程\n\n系统和外界没有热交换的过程。\n\n理想气体的准静态绝热过程：\n\n> $$\n> 0 = p\\mathrm dV + \\nu C_{V, m}\\mathrm dT\\\\\n> p\\mathrm dV + V\\mathrm dp = \\nu R\\mathrm dT\\\\\n> R  = C_{p, m} - C_{V ,m}\n> $$\n>\n> 得到：\n> $$\n> \\frac{\\mathrm dp}{p} = -\\gamma\\frac{\\mathrm dV}V\n> $$\n\n两边积分得到:\n$$\npV^{\\gamma} = C, TV^{\\gamma - 1} = C, p^{\\gamma - 1}T^{-\\gamma} = C\n$$\n\n绝热功\n\n$$\nA = \\int_{V_1}^{V_2} p\\mathrm dV = C \\int_{V_1}^{V_2}\\frac 1{V^{\\gamma}}\\mathrm dV = \\frac{C}{1 - \\gamma}(V_2^{1 - \\gamma} - V_1^{1 - \\gamma}) =\\frac{p_2V_2 - p_1V_1}{1 - \\gamma} \n$$\n\n绝热功等于内能的减少量：\n\n$$\nA = -\\Delta E = \\nu C_{V, m}\\Delta T\n$$\n\n理想气体的多方过程\n\n多方过程：热容量$C$为常数的过程\n\n多方过程方程：$pV^n = \\text{const}$\n\n其中，$n = (C - C_p)/(C - C_V) = (C_m - C_{p, m})/(C_m - C_{V, m}) = \\text{const}$\n\n如果为绝热过程则$C = 0$，$n = \\gamma$，从而$pV^{\\gamma} = \\text{const}$。\n\n如果为等温过程则$C = \\infty$，$n = 1$，因此$pV = \\text{const}$。\n\n绝热自由膨胀过程<font color=\"red\">（非准静态过程！！）</font>：\n\n理想气体：$Q = 0, A = 0 \\Rightarrow E_1 = E_2$\n\n真实气体：若分子间以引力为主, $T_2 < T_1$，以斥力为主，$T_2 > T_1$。\n\n焓：气体的绝热节流过程是等焓过程，即$H = E + pV$为常数，对于非理想气体而言，内能不仅与温度有关，也与体积有关（焦耳-汤姆孙效应）。\n\n绝热自由膨胀：初末状态在等温线上，但是过程中不是平衡态。\n\n准静态等温膨胀：吸热用来做功。\n\n准静态绝热膨胀：内能的减少量用来做功。\n\n![](../images/physics/guocheng.png)\n\n循环过程：\n\n系统，如热机中的工质，经一系列变化的回到初态的整个过程。\n\n状态图：\n\n![](../images/physics/xunhuantu.png)\n\n热循环：\n\n![](../images/physics/rexunhuan.png)\n\n蒸汽机的效率约为十几%，内燃机20-30%。\n\n制冷循环：\n\n![](../images/physics/zhilengxunhuan.png)\n\n制冷系数：\n\n$$\nw = \\frac{Q_2}{A} = \\frac{Q_2}{Q_1 - Q_2}\n$$\n\n### 卡诺循环\n\n卡诺循环是一种可逆循环，包括两个等温过程和两个绝热过程。它的效率为\n\n$$\n\\eta = 1 - \\frac{|Q_2|}{Q_1} = 1 - \\frac{T_2}{T_1}\n$$\n\n卡诺循环的效率仅与热源的温度比有关。\n\n由卡诺定理可以证明，卡诺循环的效率与工质无关。因此，不妨设工质为理想气体，利用理想气体等温和绝热过程方程得到效率公式。\n\n## 热力学第二定律\n\n开尔文表述：不可能将热量从低温热源搬运到高温热源，而不产生其他影响。（制冷系数不可能为无穷大）\n\n克劳修斯表述：不可能将功全部转化为热。（热机效率不可能为1）\n\n开尔文表述和克劳修斯表述是等价的。事实上，任何关于热现象不可逆的描述都是等价的，它们要么同时成立，要么同时不成立。因此，描述热现象的方向性，只需要举一个例子即可。\n\n### 卡诺定理\n\n在温度相同的高温热源和温度相同的低温热源之间工作的一切热机，可逆热机的效率最大。\n\n推论：一切可逆热机，只要它们的高温热源的温度相等，低温热源的温度相等，效率就相等。\n\n对于制冷机：\n\n可逆制冷机的制冷系数最大。\n\n所有2热源可逆制冷机制冷系数都相等，等于卡诺制冷机的制冷系数。\n\n### 热力学温标\n\n根据卡诺定理，可逆热机的效率只与温度有关。因此可以用效率，或者说热量比来定义温标。\n\n在热力学温标下，低温热源的温度不能为0，否则可逆热机的效率为1.\n\n### 任意可逆循环的效率\n\n$$\n\\eta \\le 1 - \\frac {T_2}{T_1}\n$$\n\n其中，$T_1$，$T_2$分别为循环中工质的最高和最低温度。\n\n### 克劳修斯熵公式\n\n热力学第零定理导出了温度，热力学第一定律导出了内能，热力学第二定律则导出了熵。\n\n可逆循环可以拆成若干小卡诺循环，每个卡诺循环满足\n\n可逆循环有克劳修斯等式\n$$\n\\oint_R \\frac{\\mathrm {\\bar d} Q}{T} = 0\n$$\n\n因此得到一个与路径无关的状态函数。\n\n熵与状态有关，和过程无关。即便过程是不可逆过程。\n\n但是，仅当过程为可逆过程时才有$\\mathrm dS=  \\mathrm{\\bar d}Q/T$。\n\n对于可逆过程：\n\n$$\nT\\mathrm dS = \\mathrm{\\bar d}Q = \\mathrm dE + p\\mathrm dV\n$$\n\n因而可以用$E, V$表示熵：\n$$\n\\mathrm dS = \\frac 1T \\mathrm dE + \\frac pT \\mathrm dV = \\frac 1T()\n$$\n\n### 克劳修斯不等式\n\n不可逆循环有\n$$\n\\oint_{Ir} \\frac{\\mathrm {\\bar d} Q}{T} < 0\n$$\n\n因而有熵增加原理:\n\n$$\n\\int_{1_{Ir}}^{2} + \\int_{2_R}^1 < 0\\Rightarrow S_1 - S_2= \\int_{1_{Ir}}^2\n$$\n\n# 振动和波动\n\n## 波动\n\n### 多普勒效应\n\n一般形式：\n\n![](../images/DSA/Duopule.jpg)\n\n机械波不存在多普勒效应。\n\n电磁波的多普勒效应：\n\n![](../images/DSA/waveDuopl.jpg)\n\n横向多普勒效应：$\\theta = \\pi /2$\n\n纵向多普勒效应：$\\theta = 0,\\pi$\n\n### 激波\n\n马赫数：$\\frac{v_s}{u} = \\frac 1{\\sin\\alpha}$\n\n# 光学\n\n光学分为几何光学，波动光学和量子光学。\n\n## 光的相干叠加\n\n光源：\n1. 普通光源：自发辐射。不同原子发光独立、不相干；同原子不同次发光独立、不相干。\n2. 激光光源：受激辐射。光放大，全通光子，相干光，波列长，相干性好。\n\n光的相干性：\n光学中强调电磁波的电场矢量$\\vec E$：光矢量\n\n相干条件：光矢量有平行分量，频率相同，相差恒定。\n\n电磁波叠加的强度公式推导：\n$$\nI = \\sqrt{\\varepsilon / \\mu}\\left<\\vec E \\cdot \\vec E \\right>_t \\\\\n\nI \\propto \\left<\\vec E \\cdot \\vec E \\right>_t \\\\\n\n叠加的电磁波：\\vec E_1 + \\vec E_2\\\\\n\n\n矢量的点乘运算可得叠加后的强度:\\\\\n\nI = I_1 + I_2 + 2\\sqrt{\\varepsilon / \\mu}\\left<\\vec E_1 \\cdot \\vec E_2 \\right>_t \n\n$$\n\n对光的相干叠加，用光矢量的平行分量描述光场--标量波函数。\n\n$$\nI = I_1 + I_2 + 2\\sqrt{I_1I_2}\\cos \\Delta \\varphi\n$$\n\n其中$\\Delta\\varphi = -k(r_2 - r_1) + (\\varphi_{20} - \\varphi_{10})$为相位差。\n\n在上面两式中，若$\\vec E_1 \\cdot \\vec E_2 \\ne 0$或者$\\Delta\\varphi \\ne \\pm\\frac{\\pi}{2}...$，则满足相干的条件。\n\n条纹的明显程度用衬比度衡量：$V = (I_{max} - I_{min})/(I_{max} + I_{min})$\n\n不同的位置$\\Delta\\varphi$不同，因而对应的$I$不同，造成了干涉条纹的出现。$I_1 = I_2$时$V=1$，$I_1 \\ne I_2$时，$V \\ne 1$。\n\n普通光源获得相干光的途径一般有分波阵面法（双缝干涉）和分振幅法（薄膜干涉）。\n\n### 双缝干涉\n\n![](../images/physics/shuangfeng.jpg)\n\n明纹：$\\delta = \\pm k\\lambda$\n\n暗纹：$\\delta = \\pm (2k + 1)\\frac \\lambda 2$\n\n$(k\\in N)$\n\n条纹间距：$\\Delta x = \\frac{D}{d}\\lambda$\n\n$\\Delta \\varphi \\approx \\frac{d\\sin \\theta}{\\lambda}2\\pi$\n\n时间相干性（光的颜色）：\n\n光的非单色性：\n\n准单色光：由某个中心频率或波长附近的频率或波长连续分布的光构成。采用谱密度函数描述。\n\n![](../images/physics/准单色光.jpg)\n\n造成谱线宽度的原因：自然宽度、多普勒增宽、碰撞增宽\n\n非单色性对干涉条纹的影响：\n\n![](../images/physics/非单色光.jpg)\n\n从图中可以看出，如果某个位置谱线中波长最长的成分的k级明纹和波长最短的成分的(k+1)级明纹重合，则在这个位置以后的条纹看不清楚了。\n\n可以解得最大相干级次：$k_M = \\lambda/\\Delta\\lambda$，进而有最大波程差：$\\delta_M = \\lambda^2/\\Delta\\lambda$。\n\n相干长度等于波列长度。\n\n通常用相干时间（光通过相干长度所需的时间）$\\tau = \\delta_M / c$ 衡量光的单色性。相干时间或相干长度越长，则单色性越好。\n\n空间相干性（光的宽度）：\n\n较宽的光源会导致明纹的非相干叠加，使衬比度下降。\n\n设光的宽度为$b_0$,则看到干涉条纹的条件是$b_0 < \\frac{R}{d}\\lambda$，这一上界称为光源极限宽度。\n\n固定b和R，则得到$d < \\frac{R}{b}\\lambda$，上界称为相干间隔。\n\n光源中心对两孔的张角为$\\theta = \\frac{d}{R} < \\frac{\\lambda}{b}$，上界称为相干孔径角。\n\n### 光程\n\n用于计算光经过不同介质的相差。\n$\\Delta\\varphi = \\frac{2\\pi r}{\\lambda}$。\n\n透镜不产生附加光程差。\n\n### 薄膜干涉\n\n为什么要薄？相干长度（时间相干性）限制。\n\n薄膜干涉有实际意义的是等倾条纹和等厚条纹。\n\n光程差\n$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2}\n$$\n\ne为膜厚度。\n\n等厚条纹：\n\n厚度不同，角度相同\n\n单色平行光入射，近似垂直于膜表面，因而$i, r \\approx 0$\n\n$$\n\\delta = 2ne + \\frac{\\lambda}{2}\n$$\n\n劈尖：\n\n由于明纹需满足$\\delta = k\\lambda$，暗纹需满足$\\delta = (2k+1)\\lambda/2$，故相邻亮纹所在的厚度差为$\\Delta e = \\lambda / (2n)$，而条纹间距为$L = \\Delta e / \\theta = \\lambda / (2n\\theta)$\n\n牛顿环：\n\n![](../images/physics/niudunhuan.jpg)\n\n可以得到暗环半径公式：$r_k=\\sqrt{kR\\lambda}$\n\n总结：条纹跟着厚度走。\n\n等倾条纹：\n\n厚度相同，角度不同。\n\n光程差(记!)\n$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2} = 2e\\sqrt{n^2 - n^{\\prime2}\\sin ^2 i} + \\frac \\lambda2\n$$\n\n等倾条纹实验通常采用面光源,因为透镜会把方向相同的光汇聚到一点，因而条纹的非常鲜明，衬比度很高，不会出现光源宽度和条纹衬比度的矛盾。\n\n应用：增透膜和增反膜\n\n### 迈克尔逊干涉仪\n\n平行：等倾条纹\n\n倾斜：等厚条纹\n\n条纹缩进N个，代表厚度变化：\n\n$$\n\\Delta d = \\frac{\\lambda}{2n} = \\frac {\\lambda}{2}\n$$\n\n在光路上放一个介质，条纹移动N个：\n\n$$\n\\delta = 2(n - 1)l = N\\lambda\n$$\n\n简而言之，一个条纹对应光程变化一个波长，厚度的变化（介质变化折算成厚度变化）乘以2等于光程的变化，因为一来一回经过了两次。\n\n## 衍射\n\n菲涅尔衍射和夫琅禾费衍射。\n\n惠更斯-菲涅尔原理\n\n夫琅禾费衍射研究光源和投影面在无限远处的情形。采用透镜将无限远转化为有限远。\n\n### 单缝衍射（夫琅禾费）\n\n利用半波带法计算明暗纹位置：\n\n中央明纹：$a\\sin \\theta = 0$\n\n暗纹：$a\\sin \\theta = \\pm k\\lambda$\n\n明纹（近似）:$a\\sin \\theta = \\pm (2k + 1)\\frac \\lambda 2$\n\n上述的$k$不能为0。因为如果k=0，即中央明纹，它没有半波带，因此要单独考虑。\n\n光强公式：$I_p = I_0(\\frac{\\sin \\alpha}{\\alpha})^2$\n\n其中$I_0$为中心亮纹强度，$\\alpha = \\frac{\\pi a \\sin \\theta}{\\lambda}$\n\n条纹宽度：\n\n条纹宽度的定义：两个相邻暗纹之间的距离，就是它们之间那个条纹的宽度。\n\n中央明纹角宽度：$\\Delta \\theta_0\\approx 2\\frac{\\lambda}{a}$，线宽度：$\\Delta x_0 \\approx 2 f \\frac{\\lambda}{a}$\n\n其他明纹线宽度：$\\Delta x \\approx f\\frac{\\lambda}{a}$\n\n### 光栅衍射\n\n光栅是由衍射单元（狭缝、反射面等）排列成的具有空间周期性结构的光学元件。\n\n光栅常数d-空间周期性结构常数\n\n正入射光栅方程：$d\\sin \\theta = \\pm k\\lambda$。（明纹位置）\n\n暗纹方程：$d\\sin \\theta = \\pm k\\lambda + \\frac{m}{N}\\lambda$\n\n主极大缺级公式：$k = k^\\prime d / a$\n\n主极大半角宽：$\\frac {\\lambda}{N d \\cos \\theta_k}$\n\n斜入射光栅方程：$d(sin\\theta - \\sin i) = \\pm k\\lambda$\n\n斜入射可以获得更高级次的条纹，但是观察到的条纹总数不变。\n\n调节入射角i或者波长$\\lambda$，衍射角$\\theta_k$也会改变。对于0级衍射光，$\\sin \\theta_0 = \\frac{\\lambda}{2\\pi d}\\Delta \\varphi_{in}$\n\n光学仪器的分辨本领：\n\n艾里斑半角宽$D\\sin \\theta_1 \\approx 1.22\\lambda$\n\n瑞利判据：一个象斑中心在另一个象斑边缘。\n\n根据瑞利判据得到透镜分辨本领（最小分辨角）：$R = \\frac{D}{1.22\\lambda}$\n\n光栅光谱：\n\n取决于光栅的色散能力和谱线（条纹）的线宽度\n\n角色散本领：$D_{\\theta} = \\frac{\\delta \\theta}{\\delta \\lambda}$\n\n色分辨本领：$R = \\frac{\\lambda}{\\delta \\lambda} = Nk$，$\\delta \\lambda$，$\\lambda $取较小者的波长，$k$是主极大级数。\n\n## 偏振\n\n### 定义\n\n线偏振光：光矢量做同向振动，方向不变。\n\n圆偏振光：光矢量的端点是圆。\n\n椭圆偏振光：光矢量的端点是椭圆。\n\n非偏振光：例如自然光。它的振动方向随机，各个方向振幅相等。自然光可以分解为两束垂直振动，振幅相等，相差随机的线偏振光。\n\n部分偏振光：自然光+完全偏振光。\n\n偏振度：$P = \\frac{I_p}{I_t} = \\frac{I_p}{I_n + I_p}$\n\n### 起偏与检偏\n\n偏振片：利用二向色性。有微晶型和分子型。\n\n线偏振光的起偏：通过偏振片。\n\n马吕斯定律：$A = A_0 \\cos \\alpha, I = I_0 \\cos^2 \\alpha$\n\n### 反射与折射中的偏振\n\nS分量：垂直于入射面。P分量：平行于入射面。\n\n反射光S分量多，折射光P分量多。\n\n当$i = i_0$使得反射光只有S分量，折射光大部分是P分量。称为布儒斯特角。$i_0 + r_0 = 90\\degree$，因而有布儒斯特定律：$\\tg i_0 = \\frac{n_2}{n_1}$\n\n玻璃片堆可以增强反射光的强度，增加折射光的偏振程度。\n\n散射引起光的偏振：\n\n微粒散射：丁达尔效应\n\n分子散射：纯净气体、液体的散射。\n\n\n双折射现象：\n\n1束光入射到各向异性介质内，产生2束折射光。o光为寻常光，符合折射定律；e光为非常光，不符合折射定律一般，也不一定在入射面内。o，e光都是线偏振光，振动方向互相垂直。\n\n晶体光轴：是晶体中的特殊方向，光在晶体中沿该方向传播不发生双折射。方解石是单轴晶体。云母是双轴晶体。\n\n主平面：晶体中光的传播方向与晶体光轴构成的平面。o光振动方向垂直于主平面，e的振动方向在主平面内。只有当光轴在入射面内，o光主平面、e光主平面、入射面才重合。\n\n折射角度不同的本质是不同角度下光的传播速度不同。据此区分正晶体和负晶体：\n\n$v_o$是o光速度，$v_e$是e光垂直光轴方向速度。o光是各向同性的，e光沿平行光轴方向的速度和o光相同，e光沿所有方向的速度构成一个旋转椭球面。\n\n![](../images/physics/shuangzheshe.jpg)\n\n正晶体：$v_o > v_e$\n\n负晶体：$v_o < v_e$\n\n定义主折射率：$n_o = c/v_o, n_e = c/v_e$\n\n利用惠更斯作图法可以讨论单轴晶体的光传播情况：\n\n以负晶体为例。\n* 若光轴平行于晶体表面，自然光垂直入射：o和e方向相同，速度不同，仍然是双折射；\n* 光轴平行晶体表面，且垂直入射面，自然光斜入射：e光也满足折射定律，折射率为$n_e$；\n* 光轴与晶体表面斜交，自然光垂直入射：e光偏离入射方向，惠更斯波面是斜椭圆。\n\n研究晶片时，o光和e光（垂直振动和平行振动）是独立的正交的分量。垂直振动不会变成平行振动，平行振动也不会变成垂直振动。\n\n双折射：两个垂直方向的线偏振光的不同速度造成的。\n\n旋光：两个不同旋转方向的圆偏振光的不同速度造成的。\n\n# 量子物理\n\n## 黑体辐射\n\n热辐射\n\n物体受热发出电磁辐射。热辐射是连续谱，温度升高，短波成分增加。\n\n平衡热辐射：物体温度不变时产生的热辐射。单位时间内物体吸收能量等于辐射能量。\n\n光谱幅出度（单色幅出度）\n\n单位面积内单位频率发射的电磁波能量。\n\n$$\nM_\\nu = \\frac{\\mathrm d E_\\nu(T)}{\\mathrm d\\nu}\n$$\n\n总幅出度\n\n$$\nM(T) = \\int_0^\\infty M_\\nu(T)\\mathrm d\\nu\n$$\n\n单色吸收比\n\n$$\n\\alpha_\\nu(T) = \\frac{\\mathrm d E_{\\nu(吸收)}}{\\mathrm d E_{\\nu(入射)}}\n$$\n\n黑体\n\n能吸收所有频率的电磁波，没有反射。$\\alpha_{\\nu}=1$。\n\n基尔霍夫辐射定律：\n\n$$\n\\frac{M_{\\nu i}}{\\alpha_{\\nu i}} = M_{\\nu 黑体}\n$$\n\n实验定律：\n\n维恩位移定律：$\\nu_m = C_\\nu T$, $\\lambda_m = b/T$\n\n注：$\\lambda_m \\nu_m \\ne c$。\n\n\n斯特藩-玻尔兹曼定律：$M(T) = \\sigma T^4$，$\\sigma$为斯特藩-玻尔兹曼常量。\n\n韦恩公式：低频段不符合；\n\n瑞利-金斯公式：高频段不符合。\n\n普朗克能量子假设：$\\varepsilon = h\\nu$\n\n普朗克公式：\n\n$$\nM_\\nu(T) = \\frac{2\\pi h}{c^2}\\cdot \\frac{\\nu^3}{e^{h\\nu/kT} - 1}\n$$\n\n由它可以导出所有其他热辐射公式。\n\n## 光电效应\n\n自学。\n\n## 光的二象性\n\n光子理论：能量$\\varepsilon = h\\nu$。光强：$I = N \\cdot h\\nu$，N是光子数流通量。\n\n解释光电效应：\n\n$$\n\\frac 12 mv_m^2 = h\\nu - A\n$$\n\n光的粒子性：\n\n$$\np = \\frac h \\lambda \\\\\nE = h\\nu \\\\\nm = \\frac{h\\nu}{c^2}\n$$\n\n解释干涉和衍射：\n\n光子在某处出现的概率是由该处的光强决定的：$I \\propto \\frac 1 {r^2}$，光子分布概率的不同导致了光强的不同。也就是说，光子的波动性表现为概率波。\n\n光子在某处出现的概率和该处光强（光振幅的平方）成正比。\n\n## 康普顿散射\n\n散射波出现新的波长：$\\Delta \\lambda = \\lambda_C(1 - \\cos\\varphi)$\n\n利用光子理论解释：光子和“静止”的“自由”电子碰撞过程动量守恒，能量守恒。\n\n解得$\\Delta \\lambda = \\frac{h}{m_0c}(1 - \\cos \\varphi)$\n\n如果光子撞到内层电子，则能量不变，因而存在原波长。\n\n自由电子只能散射光子，不能吸收光子。如果吸收了，根据能量守恒和动量守恒，解得v=c，违反了相对论。\n\n光电效应不考虑动量守恒，因为可见光、紫外线的能量低，电子不能视为自由，光子-电子不能视为动量守恒的系统。也因此，可见光观察不到康普顿效应。\n\n## 概率波和概率幅\n\n物质波的本质：\n\n德布罗意认为是引导物质运动的“导波”；（本质不明确）\n\n薛定谔认为波是基本的，电子是“波包”；（波包是不稳定的，而电子是稳定的）\n\n另一个观点：粒子是基本的，物质波是电子相互作用形成的（被电子双缝实验否定）\n\n波恩的解释：物质波是描述粒子在空间概率分布的“概率波”。\n\n量子力学的基本假设之一：微观粒子的状态用波函数描述\n\n概率波波函数(概率幅)：复函数$\\Psi (\\vec r, t)$\n\n波函数没有直接的物理意义。复函数模的平方$|\\Psi (\\vec r, t)|^2$表示概率密度。\n\n波函数需要满足标准条件：\n\n有限性:$\\iiint_{\\Delta V}|\\Psi|^2 \\mathrm dV$有限\n\n归一性：$\\int_\\Omega |\\Psi(\\vec r, t)|^2 \\mathrm dV = 1$\n\n单值性：波函数是单值函数。\n\n连续性：波函数和它的一阶导数是连续的。\n\n双缝的波函数：等于通过上缝和下缝的波函数的线性叠加。$\\Psi_{12}=\\Psi_1+\\Psi_2$。(一个基本假设)\n\n微观粒子波动性实质是波函数的叠加性。\n\n结合测量理解。\n\n态叠加原理：$\\Psi = \\sum_n C_n\\Psi_n$。其中$|C_n|^2$是该粒子处于$\\Psi_n$状态的概率。\n\n一维自由粒子的波函数：\n\n$$\n\\Psi(x, t) = A e^{i(px-Et)/\\hbar}\n$$\n\n概率密度$|\\Psi|^2 = |A|^2 = \\text {const.}$\n\n波粒二象性：\n\n粒子性：具有能量$E$和动量$\\vec p$。非经典粒子！没有轨道概念。\n\n波动性：具有波长$\\lambda$和频率$\\nu$。非经典波！非真实物理量的波动。\n\n## 不确定关系\n\n$$\n\\left<\\vec r|\\Psi\\right>\n$$\n\n不确定度：$\\Delta A = \\sqrt{\\overline{(A - \\bar A)^2}}$\n\n坐标和动量的不确定性关系：\n\n$$\n\\Delta x \\cdot \\Delta p \\ge \\frac \\hbar 2\n$$\n\n因而微观粒子没有“轨道”。\n\n能量和时间的不确定性关系：\n\n$$\n\\Delta E \\cdot \\Delta t \\ge \\frac{\\hbar}{2}\n$$\n\n时间不是力学量，它只是一个参数。位置，动量，能量等都是力学量。\n\n## 薛定谔方程\n\n定义\n\n$$\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} = \\hat {H} \\Psi\n$$\n\n哈密顿算符：$\\bar {H} = -\\frac{\\hbar ^2}{2m}\\nabla^2 + U(\\vec r, t)$\n\n若势函数不显含时间，则哈密顿算符$\\hat H$称为能量算符。此时薛定谔方程可以通过分离变量法求解。\n\n### 定态薛定谔方程-能量本征方程\n\n分离变量法求解：\n\n若势函数不显含t，则可设：\n\n$$\n\\Psi(\\vec r, t) = \\Phi(\\vec r) \\cdot T(t)\n$$\n\n得到：\n\n$$\ni\\hbar \\frac{\\mathrm dT(t)}{\\mathrm d t}\\frac 1{T(t)} = [\\hat H\\Phi (\\vec r)]\\frac{1}{\\Phi(\\vec r)} = E\n$$\n\n$$\nT(t) = Ce^{-\\frac{i}{\\hbar}Et}\\\\\n()\n$$\n\nE称为能量本征值（后面会讲什么叫本征值），对应的$\\Phi_E$称为本征波函数。\n\n定态：能量取确定值的状态，对应薛定谔方程的特解：$\\Psi_E(\\vec r, t) = \\Phi e^{-\\frac{i}{\\hbar}Et}$.\n\n对不同的势函数和能量区间，能量的本征值可能取连续的值，也可能取分立的值。设E取分立值，$\\{E_n, n = 1, 2, 3, \\dots\\}$，对应的本征波函数$\\Psi_E (\\vec r, t) = \\Phi_E(\\vec r)e^{-\\frac{i}{\\hbar}Et}$\n\n下面通过求解一维定态薛定谔方程来讨论两类问题：\n\n本征值问题：给定$U(x)$，求$E_n$和$\\Phi_n(x)$。\n\n散射问题：$E$已知，射向势垒$U(x)$，计算粒子穿透势垒的概率。 \n\n## 无限深方势阱中的粒子\n\n背景：长度为$a$的导体中自由移动的电子，只能在导体中自由运动，而不能离开导体。\n\n$|x| > a/2$时，$U(x) \\rightarrow \\infty$；\n\n$|x| \\le a/2$时，$U(x) = 0$。\n\n在$|x| > a/2$区间，$\\Phi_1 = 0$。\n\n在$|x| \\le  a/2$区间，$\\frac{\\mathrm d^2 \\Phi_2}{\\mathrm dx^2} + \\frac{2mE}{\\hbar^2}\\Phi_2 = 0$\n\n记$k = \\frac{2mE}{\\hbar^2}$。解得$\\Phi_2 = A\\sin(kx + \\varphi)$。\n\n求解定态的常规手法：利用波函数的三个条件，即单值、有限、连续，确定$A, k, \\varphi$。\n\n利用连续条件，波函数在势阱边界处连续：\n\n$$\nA\\sin(\\frac{ka}{2} + \\varphi) = 0, A\\sin(-\\frac{ka}{2} + \\varphi) = 0.\\\\\n\n\\Rightarrow k = \\frac{n\\pi}{a}, \\varphi = \\frac{l\\pi}{2}\n$$\n\n从而\n$$\nE = \\frac{\\pi^2\\hbar^2}{2ma^2}n^2 \\ (n = 1, 2, 3, \\dots)\n$$\n\n最低能量$E_1$被称为零点能。\n\n大量子数情况下，能量趋向于连续。\n\n$$\nl = 0, \\varphi = 0, \\Phi_2 = A\\sin \\frac{n\\pi}{a}x = \\Phi_{on},满足边界连续需要n为偶数\\\\\nl = 1, \\varphi =\\pi /2 , \\Phi_2 = A\\cos \\frac{n\\pi}{a}x = \\Phi_{en},满足边界连续需要n为奇数\\\\\nl \\ge 2，只差个符号，不影响|\\Phi|^2，不再考虑。\n$$\n\n求$A$：\n\n归一化：$\\int_{-a/2}^{a/2}|\\Phi_{on}|^2 \\mathrm dx = 1$， 得到$A = \\sqrt \\frac2a$\n\n$$\n\\Phi_{on} = \\sqrt{\\frac 2a}\\sin \\frac{n\\pi}{a}x, n = 2, 4, 6, \\dots\\\\\n\\Phi_{en} = \\sqrt{\\frac 2a}\\cos\\frac{n\\pi}{a}x, n = 1, 3, 5, \\dots\n$$ \n\n定态：\n\n$$\n\n\\Psi_n (x, t) = \\Phi_n(x) \\cdot e^{-\\frac i\\hbar Et}\n\n$$\n\n被称为驻波解(时间项指数为纯虚数，展开可以写成三角函数)。概率密度$|\\Psi_n(x, t)|^2 = |\\Phi_n(x)|^2$\n\n## 势垒穿透\n\n### 粒子进入势垒\n\n背景：金属与半导体接触处，势能隆起形成势垒。粒子以能量为$E(E < U_0)$的状态自由入射。\n\n$$\nU(x) = 0, x \\le 0;\\\\\nU(x) = U_0, x \\gt 0.\n$$\n\n量子力学认为有一部分粒子会穿透势垒。不仅有反射，还有投射。\n\n定态薛定谔方程：\n\n$$\n\\Phi^{\\prime\\prime}(x) + \\frac{2m}{\\hbar^2}(E - U(x))\\Phi(x) = 0\n$$\n\n$x \\le 0$: \n$$\nk_1 = \\sqrt{2mE/\\hbar^2} > 0\\\\\n\\Psi_1^{\\prime\\prime} + k_1^2 \\Psi_1 = 0\n$$\n\n$x \\gt 0$:\n$$\nik_2 = \\sqrt{2m(E - U_0)/\\hbar^2} (k_2 > 0)\\\\\n\\Psi_2^{\\prime\\prime} + (ik_2)^2\\Psi_2 = 0\n$$\n\n通解（利用了$x\\rightarrow\\infty$时$\\Psi_2$的有界性）：\n\n$$\n\\Psi_1(x) = Ae^{ik_1x} + Be^{-k_1x}(表现为入射和反射波)\\\\\n\\Psi_2(x) = Ce^{k_2x}(表现为透射波)\n$$\n\n粒子可以出现在势垒区！表现为电子溢出金属表面，形成金属表面的一层电子气。\n\n势垒区的概率密度：$|\\Psi_2(x)|\\propto e^{-\\frac{2x}{\\hbar}\\sqrt{U_0 - E}}$\n\n波可以穿过有限宽势垒，以平面波的形式继续前进。称为量子隧穿效应。\n$\\Psi_3(x) = Se^{i\\frac {\\sqrt{2mE}}{\\hbar} x}$\n\n扫描隧道显微镜：原理是量子隧穿效应，可以用来观测物质表面结构。\n\n![](../images/physics/STM.jpg)\n\n$$\ni \\propto Ue^{-C\\sqrt{\\varPhi}d}\n$$\n\n$\\varPhi$为样品表面平均势垒高度。\n\n## 一维谐振子\n\n$$\nU(x) = \\frac 12 kx^2 = \\frac 12m\\omega^2x^2, \\omega = \\sqrt{\\frac km}\n$$\n\n求解定态薛定谔方程得到\n$$\nE_n = (n + \\frac 12)\\hbar \\omega = (n + \\frac 12)h\\nu\n$$\n零点能：$\\frac{h\\nu}{2}$。间距：$h\\nu$。能量本征函数不用记。\n\n定态概率密度：\n\n经典情况下：平衡位置处$\\vec v$最大，停留时间最短，出现概率最小，振幅最大的时候$\\vec v$为0，出现概率最大。量子数n趋于无穷时，量子概率分布趋于经典概率分布。\n\n如果$E< U$，隧穿效应仍然存在。\n\n## 力学量算符\n\n以位矢$\\vec r$为自变量的空间，称为“坐标表象”。在坐标表象中，动量和位矢不存在对应关系$\\vec p = \\vec p(\\vec r)$（不确定关系）。\n\n量子力学将动量、角动量、能量等力学量“算符化”。力学量算符是量子力学的一个基本假设。\n\n### 力学量算符的引入\n\n定义能量算符$\\hat {E} \\equiv i\\hbar \\frac{\\partial}{\\partial t}$，与表象无关。\n\n坐标表象中定义动量算符$\\hat{\\vec p} = -i\\hbar\\nabla$，坐标算符$\\hat{\\vec r} = r$。\n\n由于坐标表象下坐标算符就是坐标，因此势能算符$\\hat{U} = U(\\vec r)$。动能算符$\\hat{E_k} = \\frac{(-i\\hbar\\nabla)\\cdot (-i\\hbar\\nabla)}{2m} = -\\frac{\\hbar^2}{2m}\\nabla^2$\n\n角动量算符$\\hat{\\vec L} = \\hat{\\vec r}\\times \\hat{\\vec p} = -i\\hbar\\vec r \\times \\nabla$。如果用球极坐标，可得$\\hat{L_z} = -i\\hbar \\frac{\\partial}{\\partial \\varphi}$。角动量算符的模方由极角和方位角的导数组成：$\\hat{L}^2 = -\\frac {\\hbar^2}{\\sin \\theta}\\frac{\\partial}{\\partial \\theta}(\\sin \\theta\\frac{\\partial}{\\partial \\theta})  +\\frac{\\hat{L_z^2}}{\\sin^2\\theta}$\n\n### 本征值和本征函数\n\n本征方程：$\\hat{A}\\Psi_n = A_n\\Psi_n$。其中$A_n$为本征值，$\\Psi_n$是$A$取$A_n$时的本征态，称为本征函数。\n\n本征值就是相应力学量的可能取值。\n\n$\\hat A$的本征函数系${\\Psi_n}$构成正交、归一的完备函数系。一维情况的归一化：$\\int_{-\\infty}^{+\\infty}\\Psi_n^*(x)\\Psi_n(x)\\mathrm dx = 1$。正交性：$\\int_{-\\infty}^{+\\infty}\\Psi_m(x)\\Psi_n(x)\\mathrm d x = \\delta_{mn}$.\n\n本征函数的完备性：在相同的函数空间内，任一物理上合理的归一化波函数，都可以由力学量A的本征函数系线性展开，即$\\Psi = \\sum_{n}C_n(t)\\Psi_n(x)$。\n\n### 态叠加原理：\n\n线性展开公式：\n\n$$\n\\Psi(x, t) = \\sum_{n }C_n(t)\\Psi_n(x) \\ (假设是归一化的)\n$$\n\n基本假设之一。\n\n### 力学量的测量原理\n\n量子力学假设：在$\\Psi(x,t)$态上测量$A$，则$\\Psi(x, t)$一定向着$A$的某个本征态$\\Psi_n$塌缩，测量结果为$A_n$。\n\n特别地，如果$\\Psi = \\Psi_n$，则测量结果是确定的，为$A_n$。\n\n测量结果中$A_n$出现的概率为$|C_n(t)|^2$。\n\n$$\n\\bar A = \\sum_n |C_n(t)|^2A_n = \\int_{-\\infty}^{+\\infty}\\Psi^*(x, t)\\hat A\\Psi(x, t)\\mathrm dx\n$$\n\n\n## Dirac符号\n\n### 量子态\n\n本征值离散的：$\\ket{n}$\n\n本征值是连续的：$\\ket{P_x}, \\ket{x}$\n\n它们各自张开一个线性空间。\n\n### 内积空间\n\n左矢与右矢一一对应，左矢张开一个共轭线性空间。\n\n$\\ket{A}$和$\\ket{B}$的内积(复内积)：$\\langle B|A\\rangle$\n\n左矢空间与右矢空间通过复内积练习，称为内积空间。\n\n### 线性算符\n\n$$\n\\hat{L}\\ket{A} = \\ket{B}\n$$\n\n满足：\n* $\\hat L (\\ket{A} + \\ket {B}) = \\hat L\\ket{A} + \\hat L\\ket{B}$\n* $(\\hat F + \\hat G)\\ket{A} = \\hat F \\ket{A} + \\hat G\\ket{A}$\n\n* $\\hat F(\\hat G \\ket{A}) = (\\hat F \\cdot \\hat G)\\ket {A}$\n\n共轭算符：$\\bra{A}\\bar{\\hat L}$与$\\hat L \\ket{A}$一一对应，将$\\bar{\\hat L}$或者$\\hat L ^+$称为共轭算符。\n\n厄米算符：$\\bar {\\hat L} = \\hat L$。\n\n算符是向右结合的。\n\n### 算符本征方程\n\n$$\n\\hat L \\ket{L_n} = l_n\\ket{L_n}\\\\\n\n\\hat L\\ket{n} = l_n\\ket{n}\n$$\n\n$l_n$是本征值，$L_n$是本征态。\n\n由测量原理，本征值必须是实数。所以可以观测的力学量对应的算符都是厄米算符。\n\n### 态叠加原理\n\n离散谱：\n\n$$\n\\bra{m}n\\rangle = \\delta_{mn}\\\\\n\\ket{\\psi} = \\sum_n C_n\\ket{n}\\\\\n概率幅：\\bra{m}\\psi \\rangle = C_m\\\\\n\\ket{A} = \\sum_{n}(\\bra{n}A\\rangle)\\ket{n} = \\left(\\sum_n \\ket{n}\\bra{n}\\right)\\ket{A}\\\\\n\\Rightarrow \\sum_n \\ket{n}\\bra{n}=1(本征矢的完备性表示)\n$$\n\n连续谱：\n\n$$\n\\bra{x_0^\\prime}x_0\\rangle = \\delta(x_0^\\prime - x_0)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}C(x_0)\\ket{x_0}\\mathrm dx_0 \\\\\n概率幅：\\bra{x_0^\\prime}\\psi\\rangle = C(x_0^\\prime)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}\\bra{x_0}\\psi\\rangle\\ket{x_0}\\mathrm dx_0 = \\left(\\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0\\right)\\ket{\\psi}\\\\\n\\Rightarrow \\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0 = 1(连续谱的完备性方程)\n$$\n\n注：$C(x_0) = \\bra{x_0}\\psi\\rangle$就是波函数$\\psi(x_0)$。$|\\bra{x_0}\\psi\\rangle|^2 = |\\psi(x_0)|^2 = \\psi^*(x_0)\\psi(x_0)$是概率密度。\n\n### 正则量子化假设\n\n对易关系：$[\\hat A, \\hat B]= \\hat A\\hat B - \\hat B\\hat A$，若$[\\hat A , \\hat B]=0$，则称$A$与$B$对易，否则称不对易。\n\n正则量子化假设：\n\n$$\n[\\hat{x}, \\hat{p_x}] = i\\hbar,\n[\\hat{y}, \\hat{p_y}] = i\\hbar, \n[\\hat{z}, \\hat{p_z}] = i\\hbar\n$$\n\n其余$x, y, z, p_x, p_y, p_z$的组合均对易。\n\n满足$\\hat{\\vec A}\\times \\hat{\\vec A} = i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L = \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。\n\n$\\hat A$和$\\hat B$可以同时测准的充分必要条件：\n\n$$\n[\\hat A, \\hat{B}] = 0\\Leftrightarrow 有共同本征态\n$$\n\n简并：1个本征值对应m个量子态,称为m重简并。\n\n产生简并的原因：对称性=>守恒量。\n\n如果$\\hat A$是m重简并的，只测量得到本征值A，无法确定对应的量子态。但是如果同时测量对易的$\\hat B$，就可以确定对应的$|A, B_i\\rangle$，则对应的A的量子态是$|A_i\\rangle$。\n\n力学量完全集：能完备描述、确定量子态的力学量算符必须包含$\\hat H$。\n\n$\\hat H$是核心力学量。\n\n$$\n[\\hat A, \\hat H]=0\\Leftrightarrow \\hat A是守恒量\n$$\n选择力学量的完全集，就是选择守恒量的完全集。\n\n## 原子中的电子\n\n### 氢原子理论\n\n巴耳末公式->里德伯方程->波尔氢原子理论\n\n氢原子理论：\n\n定态条件\n\n电子绕核作圆周运动，有确定能量，不辐射能量-经典轨道+定态\n\n频率条件\n\n电子在定态之间跃迁满足：$\\nu = (E_i - E_f)/h$\n\n轨道角动量：$L_n = mv_nr_n = n\\hbar$，轨道半径$r_n = n^2r_1$\n\n能级公式：$E_n = -13.6eV/n^2$\n\n类氢离子能级：核外只有一个电子，核电荷数大于1.例如$He^+, Li^{2+}$\n\n评价：\n\n波尔理论解释了氢原子和类氢离子光谱的波长和频率。\n\n但是不能解释氢原子的光谱线强度，也不能解释其他原子的光谱结构。\n* 与经典电磁理论矛盾\n* 角动量量子化条件是硬加的\n* 卢瑟福的质疑：电子知道要往$E_2$跳才能往$E_2$跳，但是又必须先跳过去才能知道要往$E_2$跳\n* 薛定谔的非难：当电子离开$E_1$态之后，进入$E_2$态之前，它在哪里，是什么状态？\n\n轨道概念不再适用。定态、能级、跃迁频率条件、角动量量子化仍然被认为是正确的。\n\n### 氢原子的量子力学处理\n\n求解量子问题的要点之一：确定体系的力学量完全集，即力学量可以同时测准，具有共同本征态，相应量子数集可完备地描述体系状态。\n\n通常选择守恒量完全集，和体系对称性有关。\n\n氢原子问题的守恒量完全集：$\\hat H, \\hat L^2, \\hat L_z$\n\n**角动量量子化：**\n\n处于中心力场的氢原子电子，角动量守恒。\n\n求$\\hat  L_z$的本征值：\n\n$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\\\\\n\n\\hat L_z \\varPhi = L_z \\varPhi\\Rightarrow \\varPhi = Ae^{\\frac{i}{\\hbar}L_z\\varphi}\n$$\n\n根据标准条件（周期性），$\\varPhi(\\varphi) = \\varPhi(\\varphi + 2\\pi)$，带入解得$L_z = m_l\\hbar$，$m_l = 0, \\pm1, \\pm2,\\dots$称为磁量子数。\n\n对应的本征函数：$\\varPhi_{m_l}(\\varphi) = Ae^{im_l\\varPhi} = \\frac{1}{\\sqrt{2\\pi}}e^{im_l\\varphi}$\n\n求$\\hat L^2$的本征值：\n\n结论：$L^2 = l(l+1)\\hbar^2$，$l = 0, 1, 2, \\dots$称为角量子数。\n\n（$\\hat L^2$和$\\hat L_z$具有的共同本征值为球谐函数$Y_{ml}(\\theta, \\varphi)$）\n\n角动量的空间量子化\n\n$L = \\sqrt{l(l+1)}\\hbar > L_z = m_l\\hbar \\Rightarrow m_l = 0, \\pm1, \\pm2,\\dots, \\pm l$。作矢量图可知，角动量有$2l+1$种取向。\n\n**能量量子化**\n\n(省略公式)\n\n$l = 0, 1, \\dots, n - 1$\n\n$\\hat H, \\hat L^2, \\hat L_z$的共同本征态就是定态。\n\n能量的本征值只与主量子数n有关，因而出现了能量简并，不同的角量子数和磁量子数可以对应相同的能量本征值。同能量的本征值态称为能级简并态，包含的态数目称为能级简并度。\n\n角量子数$l = 0, 1, 2...$对应的状态分别称为$s, p, d...$，从概率波图像可以看出，角量子数低的电子更容易靠近原子中心。\n\n### 电子自旋\n\n轨道角动量产生磁矩：\n$$\n\\hat{\\vec \\mu} = -\\frac{e}{2m_e}\\hat{\\vec L}\n$$\n\n玻尔磁子：\n\n$$\n\\mu_B = \\frac{e\\hbar}{2m_e}\n$$\n\n利用本征值的定义不难推出z方向的磁矩：\n$$\n\\mu_z = -m_l \\cdot \\mu_B\n$$\n\n斯特恩-盖拉赫实验\n\n理论分析：\n\n磁矩在外磁场中有势能：$E = -\\vec \\mu \\cdot \\vec B$\n\n轨道磁矩在z方向受力：\n\n$$\nF_z = \\frac{\\partial E}{\\partial z} = \\mu_z\\frac{\\partial B_z}{\\partial z} = -m_l\\mu_B\\frac{\\partial B_z}{\\partial z}\n$$\n\n由于$m_l$的$2l+1$种取值，对应的原子束应该在z方向上分裂成奇数条线。\n\n![](/source/images/physics/abaaba.jpg)\n\n问题：$Ag, H$等原子束($l = 0$)出现了2条线而不是一条线，矛盾。\n\n电子自旋的假设：\n\n* 电子不是质点，而是自旋的小球，具有固有的自旋角动量$\\vec S$和自旋磁矩$\\vec \\mu_S$\n* $S = \\sqrt{s(s+1)}\\hbar$，其中$s = \\frac 12$称为自旋量子数\n* $S_z = m_s\\hbar$，$m_s = \\pm\\frac 12$，称为自旋磁量子数\n* 自旋磁矩和自旋角动量满足$\\hat {\\vec \\mu_S} = -\\frac{e}{m_e}\\hat {\\vec S}$，进而推出$\\mu_{S,z}=\\pm \\mu_B$\n\n“自转小球”模型仍存在缺陷：电子表面的速度会超过光速。\n\n但是这些假设成功解释了原子光谱的精细结构和反常塞曼效应。\n\n量子力学的解释：\n\n* 自旋是与时空无关的内禀运动，一种新的自由度，一种新的角动量，无经典对应\n* 自旋、磁矩和静止质量、电荷一样，是反映微观粒子固有属性的基本量\n* 电子的自旋是一种相对论效应，被自动地包含在相对论波动方程(Dirac方程)中。\n\n电子的总角动量：\n\n$$\n\\hat {\\vec J} = \\hat {\\vec L} + \\hat {\\vec S}\n$$\n\n$\\hat {\\vec J}$也是量子化的，大小为：\n$$\nJ = \\sqrt{j(j + 1)}\\hbar\n$$\n\n前文已说过如下定义：\n>满足$\\hat{\\vec A}\\times \\hat{\\vec A} = i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L = \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。\n\n可以验证$\\hat {\\vec J }\\times \\hat {\\vec J } = i\\hbar \\hat {\\vec J }$。因此总角动量还是角动量。\n\n这一角动量的合成被称为自旋——轨道耦合。$j$称为总角动量量子数。\n\n$$\nl = 0: \n\\\\\nj = s = \\frac 12, m_j = -\\frac 12, +\\frac 12\\\\\nl \\ne 0:\\\\\nj = l + s = l + \\frac 12, m_j = -(l + \\frac 12), \\dots, l + \\frac 12;\\\\\nj = l - s = l - \\frac 12, m_j = -(l - \\frac12), \\dots, l - \\frac12\n$$\n\n碱金属原子光谱：\n\n碱金属的原子能级既和$n$有关，又和$l$有关。\n\n轨道角动量对原子的影响包括轨道贯穿和原子实极化，导致相应能级能量降低。\n\n因此原来相同能级的$3s,3p,...$会分裂成不同能级的轨道。\n\n碱金属原子光谱的精细结构：\n\n电子的轨道运动会使得它感受到原子绕它转动的磁场$\\vec B_{Nuc}$的作用。\n\n电子自旋磁矩$\\vec \\mu_s$和$\\vec B_{Nuc}$的相互作用就是自旋轨道耦合，是相对论效应。\n\n于是能级在自旋轨道耦合的影响下进一步分裂，形成了能级精细结构。\n\n### 微观粒子全同性原理\n\n两个微观粒子的全部内禀属性相同称为全同粒子。对调全同粒子不会影响系统的状态。\n\n数学上对应地表现为波函数模方相同，进而有波函数对称或者反对称。\n\n对称的波函数表达式：\n\n$$\n\\psi(q_1, q_2) = \\frac {1}{\\sqrt 2}[\\phi_A(q_1)\\phi_B(q_2) + \\phi_A(q_2)\\phi_B(q_1)]\n$$\n\n反对称的波函数表达式：\n\n\n$$\n\\psi(q_1, q_2) = \\frac{1}{\\sqrt{2}}[\\phi_A(q_1)\\phi_B(q_2) - \\phi_A(q_2)\\phi_B(q_1)]\n$$\n\n如果$\\phi_A=\\phi_B$，则反对称波函数为0。\n\n费米子是自旋为半整数的粒子。它是波函数反对称的粒子。由此得到泡利不相容原理：全同费米子系统不能有两个及以上的费米子占据同一单粒子态。\n\n玻色子是自旋为0或者整数的粒子。它是波函数对称的粒子。玻色子不受泡利不相容原理的限制。\n\n费米统计：\n\n$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} + 1}\n$$\n\n$\\mu = \\mu(T)$是粒子化学势。\n\n玻色统计：\n\n$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} - 1}\n$$\n\n对所有温度T,$0\\le N(E)\\lt \\infty$。\n\n玻色-爱因斯坦凝聚。\n\n当$E$很高时，$(E - \\mu) >> kT$。退化为麦克斯韦-玻尔兹曼统计。\n\n### 原子核外电子的排布\n\n4个量子数$n,l,m_l,m_s$可以完备描述原子的电子运动状态。\n\n","slug":"Physics","published":1,"updated":"2024-03-19T06:01:16.159Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhv000brsug87o2hmyi","content":"<h1 id=\"参考教材\"><a href=\"#参考教材\" class=\"headerlink\" title=\"参考教材\"></a>参考教材</h1><p>嫌教材太简单可以看看</p>\n<p>《热学》lhf例题很多，很详细，很多数学比教材难</p>\n<p>《》</p>\n<p>《新概念物理教程-力学》新颖，比较硬核。</p>\n<p>《费恩曼物理学讲义》</p>\n<p>《新概念物理教程-光学》公认最好教材</p>\n<p>《光学》chb, lyp</p>\n<p>量子物理没有太好的参考书。</p>\n<p>《原子物理学》杨福家编。现在没有原子物理了，只有量子物理。有时用经典方法，有时候用量子物理的方法。前几章和教材一致，实验讲得不错。</p>\n<p>量子力学教程。周世勋。内容有点少。</p>\n<p>《费恩曼物理学讲义》第3卷。相当有深度（量子物理）。</p>\n<p><em>Phyisics</em> Vol.1 &amp; 2。难度介于大学物理学和物理系教材之间。</p>\n<h3 id=\"杂项\"><a href=\"#杂项\" class=\"headerlink\" title=\"杂项\"></a>杂项</h3><p>牛顿运动方程一般个数少，微分阶数高；哈密顿正则方程一般个数多，微分阶数低。</p>\n<h1 id=\"热学\"><a href=\"#热学\" class=\"headerlink\" title=\"热学\"></a>热学</h1><h2 id=\"温度\"><a href=\"#温度\" class=\"headerlink\" title=\"温度\"></a>温度</h2><p>分子动理论：热学中比较古老的理论。</p>\n<p>教材中关于统计物理的内容不够透彻。</p>\n<p>建议学习分析力学（重点：哈密顿力学），对后续量子力学有帮助。固体物理也会使用相关技巧。哈密顿量，相空间，拉格朗日方程。不用看证明，能用就行。</p>\n<h3 id=\"热学研究内容与对象\"><a href=\"#热学研究内容与对象\" class=\"headerlink\" title=\"热学研究内容与对象\"></a>热学研究内容与对象</h3><p>内容：与热现象有关的性质和规律。</p>\n<p>热现象：宏观上与温度有关，微观上与分子热运动有关。</p>\n<p>对象：大量微观粒子构成的体积有限的物体-热力学系统。（量大：统计学规律。）</p>\n<p>经常讨论系统和外界（环境）。一种说法：宇宙是不是热力学系统？不是，因为宇宙之外没有外界。所以热二定律可能不适用于整个宇宙。</p>\n<p>孤立系统：与外界没有任何相互作用。</p>\n<p>绝热系统：有功的交换，没有热量交换</p>\n<p>封闭系统：有能量交换，无粒子交换</p>\n<p>开放系统：既有能量交换，也有粒子交换</p>\n<h3 id=\"热力学的研究方法\"><a href=\"#热力学的研究方法\" class=\"headerlink\" title=\"热力学的研究方法\"></a>热力学的研究方法</h3><h4 id=\"热力学\"><a href=\"#热力学\" class=\"headerlink\" title=\"热力学\"></a>热力学</h4><p>宏观理论方法。依赖于实验。不涉及物质的微观结构和微观运动规律。具有极大的普遍性，可靠性。</p>\n<h4 id=\"统计物理学\"><a href=\"#统计物理学\" class=\"headerlink\" title=\"统计物理学\"></a>统计物理学</h4><p>微观理论方法。从微观模型假设出发，力学 + 统计理论建立微观量和宏观量的关系。可解释本质，但是受模型局限。</p>\n<h3 id=\"几个重要概念\"><a href=\"#几个重要概念\" class=\"headerlink\" title=\"几个重要概念\"></a>几个重要概念</h3><h4 id=\"平衡态\"><a href=\"#平衡态\" class=\"headerlink\" title=\"平衡态\"></a>平衡态</h4><p>热力学系统内部，宏观上不存在能量和粒子的流动，系统宏观性质不随时间变化。（体积、压强、温度）</p>\n<p>热力学平衡条件：</p>\n<p>力学平衡条件：若系统与外界有力学作用，平衡时内外压强相等。</p>\n<p>热平衡条件：若系统与外界可交换热量，平衡时内外温度应相等。</p>\n<p>相平衡条件：若系统与外界处于不同相的共存状态，平衡时要达到力学平衡、热平衡以及相平衡。</p>\n<p>化学平衡条件：浓度不同的系统混到一起，平衡时要满足上面三个条件，并且浓度均匀。</p>\n<p>注意区分平衡态和稳定态：</p>\n<p>![..&#x2F;images&#x2F;pht.png]</p>\n<h4 id=\"宏观量\"><a href=\"#宏观量\" class=\"headerlink\" title=\"宏观量\"></a>宏观量</h4><p>描述系统宏观性质的量。可直接测量。</p>\n<p>广延量：有累加性。如M, V, E…</p>\n<p>强度量：无累加性。如p, T…</p>\n<h4 id=\"微观量\"><a href=\"#微观量\" class=\"headerlink\" title=\"微观量\"></a>微观量</h4><p>描述微观粒子性质的量。需要间接测量。</p>\n<p>如分子的m, v, d…</p>\n<h4 id=\"状态参量\"><a href=\"#状态参量\" class=\"headerlink\" title=\"状态参量\"></a>状态参量</h4><p>描述系统平衡态及其宏观性质的物理量。</p>\n<p>p, V, T, v, 内能E, 熵S, 焓H</p>\n<p>一组态参量对应一个平衡态。</p>\n<p>实验表明：状态参量之间不是相互独立的。</p>\n<p>常选p, V, T作为自变量，其他的当作函数（E, S, H）-热力学函数。</p>\n<p>对物质量确定的单元（单一组元，不能由多种物质混合）单相（同一种状态，不能有固液同时存在等等）系统，p, V, T只有两个是独立的：T(p, V), E(p, V)。</p>\n<p>统计物理：状态参量之间的偏导数关系。</p>\n<h4 id=\"物态方程\"><a href=\"#物态方程\" class=\"headerlink\" title=\"物态方程\"></a>物态方程</h4><p>两个最基本的热力学函数之一（物态方程和内能）。态参量之间的函数关系: f(T, p, V) &#x3D; 0</p>\n<p>通过测量确定。</p>\n<p>理想气体物态方程：</p>\n<p>$pV &#x3D; νRT$</p>\n<p>$p &#x3D; nkT$</p>\n<p>$k &#x3D; \\frac{R}{N_A}$</p>\n<p>$\\nu$ 气体摩尔数</p>\n<p>$k$ 玻尔兹曼常量</p>\n<h3 id=\"温度-1\"><a href=\"#温度-1\" class=\"headerlink\" title=\"温度\"></a>温度</h3><h4 id=\"热平衡态\"><a href=\"#热平衡态\" class=\"headerlink\" title=\"热平衡态\"></a>热平衡态</h4><p>两个系统长时间热接触达到的共同平衡态。</p>\n<h4 id=\"热力学第零定律\"><a href=\"#热力学第零定律\" class=\"headerlink\" title=\"热力学第零定律\"></a>热力学第零定律</h4><p>实验表明： A与C热平衡，B与C热平衡，A和B也必然保持热平衡。</p>\n<p>非热接触的两个系统也可以处在同一个热平衡态。</p>\n<p>温度：处于同一热平衡态下的热力学系统所具有的共同的宏观性质。</p>\n<p>处在同一热平衡态的系统具有相同的温度。</p>\n<h4 id=\"温标\"><a href=\"#温标\" class=\"headerlink\" title=\"温标\"></a>温标</h4><p>理想气体温标；用理想气体做测温物质。单位: $K$(Kelvin)， 范围适用 $&gt; 0.5K$</p>\n<p>实验表明：一定质量的理想气体在同一个热平衡态下，$pV$不变。</p>\n<p>规定$T \\propto pV$，水的三相点温度为$T_3 &#x3D; 273.16K$</p>\n<div>$$T = T_3\\frac{pV}{p_3V_3} = 273.16\\frac{pV}{p_3V_3}$$</div>\n\n<p>热力学温标$T$：理论温标，与物质无关。</p>\n<p>单位: $K$，适用于所有温度范围，在理想气体温标范围内与理气温标一致。</p>\n<h3 id=\"统计物理学的观点、概念简介\"><a href=\"#统计物理学的观点、概念简介\" class=\"headerlink\" title=\"统计物理学的观点、概念简介\"></a>统计物理学的观点、概念简介</h3><p>统计物理学包括平衡态统计理论，非平衡态统计理论和涨落理论。它从物质的微观结构和微观运动来阐明物质的宏观性质。其基本观点：</p>\n<ul>\n<li>宏观物体由大量的微观粒子（原子、分子、电子、光子等）构成。</li>\n<li>微观粒子的运动服从力学规律。原则上说服从量子力学规律，一定条件下可以用经典力学处理。</li>\n<li>从微观角度看，物体以一定的概率出现在各个微观状态上，物质的宏观性质就是物质微观性质的统计平均。宏观量是有关微观量的统计平均值。</li>\n</ul>\n<h4 id=\"近独立子系统\"><a href=\"#近独立子系统\" class=\"headerlink\" title=\"近独立子系统\"></a>近独立子系统</h4><p>构成系统的粒子间相互作用很弱，系统能量近似等于各粒子能量总和，如理想气体。</p>\n<h4 id=\"微观状态（力学运动状态）\"><a href=\"#微观状态（力学运动状态）\" class=\"headerlink\" title=\"微观状态（力学运动状态）\"></a>微观状态（力学运动状态）</h4><h5 id=\"经典力学描述\"><a href=\"#经典力学描述\" class=\"headerlink\" title=\"经典力学描述\"></a>经典力学描述</h5><p>常采用正则形式，即广义坐标和广义动量描述。</p>\n<ul>\n<li><p>子相空间（μ空间）：由粒子的广义坐标$q_i$和广义动量$p_i$（$i &#x3D; 1, \\dots, r$, $r$是粒子自由度）构成的2r维空间。</p>\n<p>1组$(q_1, \\dots, q_r, p_1, \\dots, p_r)$的取值表示粒子的1个微观状态，对应于子相空间的一个点。</p>\n<p>更确切的说，在子相空间 $( q_1,… , q_r , p_1,…, p_r )$位置处的体积元 $d q_1…d q_r dp_1…dp_r$中的点，都是由$( q_1,… , q_r , p_1,…, p_r )$描述的相同的粒子微观状态。</p>\n<p>位形空间（坐标构成的空间），速度空间（速度构成的空间）。</p>\n<p>傅里叶变换和傅里叶级数的区别：一个离散，一个连续。</p>\n</li>\n<li><p>系统的微观状态是由所有粒子的广义坐标和广义动量描述的。</p>\n</li>\n</ul>\n<h5 id=\"量子力学描述\"><a href=\"#量子力学描述\" class=\"headerlink\" title=\"量子力学描述\"></a>量子力学描述</h5><p>量子力学中假设运动状态用量子态描述。</p>\n<ul>\n<li><p>粒子的微观状态用单粒子（量子）态描述。</p>\n<p>单粒子态由一组量子数描述：如 $|n, l, m_l, m_s &gt;$ 。 1 组取值确定的$ |n, l, m_l, m_s &gt; $表示 1 个单粒子态。 当粒子状态是由某个单粒子态描述时，称为粒子处于某个单粒子态，或粒子占据某个单粒子态</p>\n</li>\n<li><p>系统微观状态用多粒子（量子）态描述。</p>\n<p>对近独立子系统，多粒子态可由单粒子态表示： 系统所有粒子的 1 组单粒子占据态就表示系统的 1 个 多粒子态，即表示系统的 1 个 微观状态。</p>\n</li>\n</ul>\n<p>微观粒子全同性原理</p>\n<p>全同粒子：内禀属性如质量、电荷、自旋等相同 </p>\n<p>微观粒子全同性原理是量子力学假设。 </p>\n<p>全同性原理：对全同粒子组成的系统，交换任意 2个全同粒子，系统微观状态不变。</p>\n<p>泡利不相容原理：对全同费米子系统，不能有两个及以上的费米子占据同一单粒子态。</p>\n<p>费米子：自旋为半整数；玻色子：自旋为整数。</p>\n<h4 id=\"宏观状态和微观状态的关系\"><a href=\"#宏观状态和微观状态的关系\" class=\"headerlink\" title=\"宏观状态和微观状态的关系\"></a>宏观状态和微观状态的关系</h4><p>系统的宏观状态由宏观量表征，如 E、N、V。 </p>\n<p>系统的微观状态，如果用经典描述，则由所有粒子 的坐标和动量表征。 </p>\n<p>玻耳兹曼认为：从微观上看，对于一个系统的状态 的宏观描述是非常不完善的，系统的同一个宏观状 态实际上可能对应于非常非常多的微观状态，而这 些微观状态是粗略的宏观描述所不能加以区别的。</p>\n<p> 这意味着宏观状态和微观状态、宏观量和微观量具 有内在联系，这种联系是种统计关系。</p>\n<h4 id=\"统计规律性\"><a href=\"#统计规律性\" class=\"headerlink\" title=\"统计规律性\"></a>统计规律性</h4><p>统计物理发展早期，人们普遍认为：研究物体宏观 性质，应从求解粒子的力学运动方程出发来解决。 但由于粒子数太多，求解力学方程困难，迫不得已 得引入统计方法。而且这个统计是：宏观量是相应 微观量的长时间平均。 即原则上力学规律可完全决定物体宏观性质  </p>\n<p>这种观点无法解释根本问题：热现象的不可逆性。 因为把力学运动方程（牛顿方程或薛定谔方程）用 到微观粒子，是时间反演对称的 — 可逆的。</p>\n<p>这表明仅通过力学规律来解释物体的宏观性质是 不可能的，而有赖于新的规律 — 统计规律。</p>\n<p>力学规律是决定论性的，可表述为：在一定初始 条件下，某时刻系统必然处于一确定的运动状态。 </p>\n<p>统计规律可以表述为：在一定的宏观条件下，某 时刻系统以一定的概率处于某一微观状态。 </p>\n<p>即宏观状态与微观状态之间的联系是概率性的， 具有统计规律的特性，而不是决定论性的。</p>\n<p>统计规律的稳定性：只要 N 足够大，每次得到的分布几乎相同</p>\n<p>统计规律的涨落：每次实验中得到的比例 Ni &#x2F;N 稍有差别。N 越大，涨落越小。</p>\n<p>即对变量是离散取值的情况，直接采用概率， 对变量是连续取值的情况，需要引入概率密度。</p>\n<p>热现象本质是统计规律的反映。</p>\n<h5 id=\"平衡态统计理论的基本假设：等概率原理\"><a href=\"#平衡态统计理论的基本假设：等概率原理\" class=\"headerlink\" title=\"平衡态统计理论的基本假设：等概率原理\"></a>平衡态统计理论的基本假设：等概率原理</h5><p>处于平衡态下的孤立系统，系统各个可能的微观 状态出现的概率相等。 “可能的微观状态”是指孤立系统的宏观条件所 允许的那些微观状态，即这些微观状态对应于给 定的 E、V、N</p>\n<h5 id=\"平衡态下近独立子系统的统计规律\"><a href=\"#平衡态下近独立子系统的统计规律\" class=\"headerlink\" title=\"平衡态下近独立子系统的统计规律\"></a>平衡态下近独立子系统的统计规律</h5><p>处于平衡态下的热力学系统，宏观状态不变，但 相应的微观状态不断变化，是一种动态平衡。 根据等概率原理，平衡态包含的微观状态数目是 最多的 — 最概然态</p>\n<p>求统计分布函数：对于每个统计分布函数，可以计算它们对应的微观态数目（微观态数目是统计分布函数的函数）。在E, N不变的条件下，只要找到对应微观态数目最多的统计分布函数，就是平衡态的统计分布函数。</p>\n<p>对近独立子系统，采用经典力学及等概率原理只能得到一种经典统计：麦克斯韦-玻尔兹曼统计；采用量子力学及等概率原理得到3种统计：麦克斯韦-玻尔兹曼统计，费米-狄拉克统计，玻色-爱因斯坦统计。</p>\n<p>造成 3 种量子统计规律的原因是微观粒子的全同性原理和泡利不相容原理。</p>\n<p>麦克斯韦-玻尔兹曼统计适用于定域子系统，费米 - 狄拉克统计、玻色 - 爱因斯坦统计适用于非定域 子系统。</p>\n<p> 定域：全同粒子系统中的粒子的波包局限在空间 一定范围内，之间没有重叠，全同性原理 不起作用，可以通过位置分辨粒子。</p>\n<p> 经典的和量子的麦克斯韦-玻尔兹曼统计在数学形 式上一致。而在一定条件下，量子的 3 种统计都可 退化为经典的麦克斯韦-玻尔兹曼统计</p>\n<h2 id=\"气体动理论\"><a href=\"#气体动理论\" class=\"headerlink\" title=\"气体动理论\"></a>气体动理论</h2><h4 id=\"气体动理论的基本观点\"><a href=\"#气体动理论的基本观点\" class=\"headerlink\" title=\"气体动理论的基本观点\"></a>气体动理论的基本观点</h4><p>气体动理论（分子动理论），发展于 19 世纪下半 期，基于经典理论，是统计物理学的原型，被不断 补充发展完善成为统计物理学，其所得的结论可通 过统计物理得到。至今仍在诸多领域有重要应用。</p>\n<ol>\n<li>宏观物体是由大量分子、原子构成的，分子间 存在一定的间隙。</li>\n<li>分子永不停息地作无规则运动 — 热运动</li>\n<li>分子间存在一定的相互作用。</li>\n</ol>\n<h3 id=\"理想气体的压强\"><a href=\"#理想气体的压强\" class=\"headerlink\" title=\"理想气体的压强\"></a>理想气体的压强</h3><h5 id=\"关于理想气体的假设\"><a href=\"#关于理想气体的假设\" class=\"headerlink\" title=\"关于理想气体的假设\"></a>关于理想气体的假设</h5><h6 id=\"单个分子服从的力学规律\"><a href=\"#单个分子服从的力学规律\" class=\"headerlink\" title=\"单个分子服从的力学规律\"></a>单个分子服从的力学规律</h6><p>理想气体模型：</p>\n<p>大小：分子线度&lt;&lt;分子间平均距离</p>\n<p>分子力：除碰撞的瞬间，在分子间、分子与器壁间无作用力</p>\n<p>碰撞性质：弹性碰撞</p>\n<p>服从规律：牛顿力学</p>\n<h6 id=\"大量分子处于平衡态时的统计假设\"><a href=\"#大量分子处于平衡态时的统计假设\" class=\"headerlink\" title=\"大量分子处于平衡态时的统计假设\"></a>大量分子处于平衡态时的统计假设</h6><p>（1）无外场时，分子在各处出现的概率相同</p>\n<div>$$n = \\frac{\\mathrm d N}{\\mathrm d V} = \\frac NV = \\text{const}.$$</div>\n（2）由于碰撞，分子可以有各种不同速度\n\n<p>速度取向各方向等概率：</p>\n<div>$$\\bar{v_x} = \\bar{v_y} = \\bar{v_z} = 0\\\\\\\\\\bar{v_x^2} = \\bar{v_y^2} = \\bar{v_z^2} = \\frac 13 \\bar{v^2}$$</div>\n\n<h5 id=\"理想气体压强公式\"><a href=\"#理想气体压强公式\" class=\"headerlink\" title=\"理想气体压强公式\"></a>理想气体压强公式</h5><p>前提：平衡态，忽略重力，分子当成质点</p>\n<div>$$p = \\frac13nm\\bar{v^2} = \\frac23n\\bar\\varepsilon_t, \\\\\\\\\\bar\\varepsilon_t = \\frac12 mv^2$$</div>\n\n<h3 id=\"温度的统计意义\"><a href=\"#温度的统计意义\" class=\"headerlink\" title=\"温度的统计意义\"></a>温度的统计意义</h3><div>$$\\bar\\varepsilon_t = \\frac{3p}{2n} = \\frac{3nkT}{2n} = \\frac32kT\\\\\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}{M}}$$</div>\n\n<p>$T &#x3D; 273K$, </p>\n<p>$\\bar{\\varepsilon}_t$数量级：$10^{-2}$eV</p>\n<p>$\\sqrt{\\bar{v^2}}$</p>\n<p>$H_2$: $1.84\\times 10^3m&#x2F;s$</p>\n<p>$O2$: $4.61\\times 10^2m&#x2F;s$</p>\n<h3 id=\"能量均分定理\"><a href=\"#能量均分定理\" class=\"headerlink\" title=\"能量均分定理\"></a>能量均分定理</h3><p>自由度：决定物体空间位置的独立坐标数，用$i$表示</p>\n<h5 id=\"单原子分子\"><a href=\"#单原子分子\" class=\"headerlink\" title=\"单原子分子\"></a>单原子分子</h5><p>平动自由度:$t &#x3D; 3$ </p>\n<p>$i &#x3D; 3$</p>\n<h5 id=\"双原子分子\"><a href=\"#双原子分子\" class=\"headerlink\" title=\"双原子分子\"></a>双原子分子</h5><p>质心平动：$t &#x3D; 3$</p>\n<p>轴取向：$r &#x3D; 2$</p>\n<p>距离变化：$v &#x3D; 1$</p>\n<p>总自由度: $i &#x3D; 6$</p>\n<h5 id=\"多原子分子\"><a href=\"#多原子分子\" class=\"headerlink\" title=\"多原子分子\"></a>多原子分子</h5><p>设分子包含$N$个原子</p>\n<p>$i &#x3D; 3N$</p>\n<p>$t &#x3D; 3$</p>\n<p>$r &#x3D; 3$</p>\n<p>$v &#x3D; 3N-6$</p>\n<h5 id=\"能量均分定理-1\"><a href=\"#能量均分定理-1\" class=\"headerlink\" title=\"能量均分定理\"></a>能量均分定理</h5><p>一个平动自由度对应的平均动能为$\\frac12kT$</p>\n<p>考虑平动、振动和转动，由于分子的碰撞，分子平均动能均匀分配到每个自由度上。</p>\n<p>在温度$T$的平衡态下，分子热运动的每个自由度对应的平均动能都等于$\\frac12kT$。</p>\n<p>普遍的能量均分定理：</p>\n<p>分子能量中每具有一个平方项，就对应一个$\\frac12kT$的平均能量。</p>\n<p>分子振动的动能和势能都是平方项，所以：</p>\n<p>$\\bar\\varepsilon_{vP} &#x3D; \\bar\\varepsilon_{vk} &#x3D; v\\frac12kT$,  $\\bar\\varepsilon_v &#x3D; \\bar\\varepsilon_{vP}  + \\bar\\varepsilon_{vk} &#x3D; vkT$</p>\n<div>$$\\bar\\varepsilon = \\bar\\varepsilon _t + \\bar\\varepsilon_r + \\bar\\varepsilon_v = (t + r + 2v)\\frac12kT$$</div>\n通常情况下($T < 10^3K$)，振动自由度被“冻结”，分子可视为刚性\n\n<p>刚性分子：$v &#x3D; 0, i &#x3D; t + r$</p>\n<div>$$\\bar\\varepsilon = \\frac{t+ r}2kT$$</div>\n\n<h5 id=\"理想气体内能\"><a href=\"#理想气体内能\" class=\"headerlink\" title=\"理想气体内能\"></a>理想气体内能</h5><p>内能：系统内部各种形式能量的总和，不包括系统整体质心运动的能量</p>\n<p>分子内部： $\\bar\\varepsilon &#x3D; (t + r + 2v)\\frac12kT$</p>\n<p>分子之间：相互作用势能$\\varepsilon_{\\mathrm pij}$</p>\n<p>内能：$E &#x3D; N\\bar\\varepsilon + \\sum_i\\sum_{j&lt;i}\\varepsilon_{\\mathrm pij} &#x3D; E(T, V)$</p>\n<p>理想气体： $\\varepsilon_{\\mathrm pij} &#x3D; 0,E &#x3D; E(T)$</p>\n<h3 id=\"麦克斯韦速度分布律\"><a href=\"#麦克斯韦速度分布律\" class=\"headerlink\" title=\"麦克斯韦速度分布律\"></a>麦克斯韦速度分布律</h3><p>分布函数是体现热力学系统的统计规律性的重要函数.</p>\n<p>常见的统计分布函数包括：速率分布函数、速度分布函数、能量分布函数等。</p>\n<p>通过分布函数可计算微观量的统计平均值，如$\\bar\\varepsilon_t, \\bar{v^2}$等，进而得到系统的宏观量。</p>\n<h5 id=\"速率分布函数\"><a href=\"#速率分布函数\" class=\"headerlink\" title=\"速率分布函数\"></a>速率分布函数</h5><div>$$f(v) = \\frac{\\text dN}{N\\text dv}\\\\\\\\\\int_0^\\infty f(v)\\text dv = \\int_0^\\infty\\frac{\\text dN}{N} = 1$$</div>\n\n<h5 id=\"麦克斯韦速率分布函数（不用记）\"><a href=\"#麦克斯韦速率分布函数（不用记）\" class=\"headerlink\" title=\"麦克斯韦速率分布函数（不用记）\"></a>麦克斯韦速率分布函数（不用记）</h5><div>$$f(v) = 4\\pi (\\frac m{2\\pi kT})^{3/2}e$$</div>\n\n<h5 id=\"三种统计速率\"><a href=\"#三种统计速率\" class=\"headerlink\" title=\"三种统计速率\"></a>三种统计速率</h5><h6 id=\"最概然速率\"><a href=\"#最概然速率\" class=\"headerlink\" title=\"最概然速率\"></a>最概然速率</h6><div>$$v_p = \\sqrt{\\frac{2kT}{m}}$$</div>\n\n<p>m一定时，温度T越高，速率大的分子数比例越大，最概然速率越大， $f(v_p)$越小。</p>\n<h6 id=\"平均速率\"><a href=\"#平均速率\" class=\"headerlink\" title=\"平均速率\"></a>平均速率</h6><div>$$\\bar v = \\int_0^\\infty vf(v)\\text dv$$</div>\n\n<p>任意函数对全体分子按速率分布的平均值为</p>\n<p><font color =\"red\">$f(v)$一定要归一化!</font><p>例如求0到vp&#x2F;2的平均速率，首先要将f(v)归一化成这个区间内的速率分布，而不是直接用全部速率分布</p></p>\n<div>$$\\bar{\\phi(v)} =\\int_0^\\infty \\phi(v)f(v)\\text dv$$</div>\n\n<p>由麦克斯韦速率分布函数</p>\n<div>$$\\bar v = \\sqrt{\\frac{8kT}{\\pi m}} = \\sqrt{\\frac{8RT}{\\pi M}}$$</div>\n\n<h6 id=\"方均根速率\"><a href=\"#方均根速率\" class=\"headerlink\" title=\"方均根速率\"></a>方均根速率</h6><div>$$\\bar{v^2} = \\int_0^\\infty v^2f(v)\\text dv = \\frac{3kT}{m}\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}M}$$</div>\n\n<h5 id=\"麦克斯韦速度分布律-1\"><a href=\"#麦克斯韦速度分布律-1\" class=\"headerlink\" title=\"麦克斯韦速度分布律\"></a>麦克斯韦速度分布律</h5><div>$$\\frac{\\text dN}{N} = \\left(\\frac{m}{2\\pi kT}\\right)^{3/2}e^{-m(v_x^2 + v_y^2 + v_z^2)/2kT}\\text{d}v_x\\text{d}v_y\\text{d}v_x$$</div>\n\n<p>速度分量的分布函数</p>\n<div>$$g(v) = (\\frac m{2\\pi kT})^{1/2}e^{-mv^2/2kT}$$</div>\n\n<h5 id=\"分子碰壁数-Γ\"><a href=\"#分子碰壁数-Γ\" class=\"headerlink\" title=\"分子碰壁数$Γ$\"></a>分子碰壁数$Γ$</h5><div>$$\\Gamma = \\frac14 n\\bar v$$</div>\n\n<h5 id=\"玻尔兹曼分布\"><a href=\"#玻尔兹曼分布\" class=\"headerlink\" title=\"玻尔兹曼分布\"></a>玻尔兹曼分布</h5><h6 id=\"恒温气压公式\"><a href=\"#恒温气压公式\" class=\"headerlink\" title=\"恒温气压公式\"></a>恒温气压公式</h6><div>$$p = p_0e^{-mgz/kT}\\\\\\\\n = n_0e^{-mgz/kT}$$</div>\n\n<h6 id=\"玻尔兹曼分布-1\"><a href=\"#玻尔兹曼分布-1\" class=\"headerlink\" title=\"玻尔兹曼分布\"></a>玻尔兹曼分布</h6><div>$$\\text dN_{\\vec r} = n_0 \\cdot e^{-\\varepsilon_p(\\vec r)/kT} \\cdot \\text d^3 \\vec r\\\\\\\\\\text d^3\\vec r = \\text dx \\ \\text dy \\  \\text dz$$</div>\n\n<h6 id=\"玻尔兹曼-麦克斯韦分布\"><a href=\"#玻尔兹曼-麦克斯韦分布\" class=\"headerlink\" title=\"玻尔兹曼-麦克斯韦分布\"></a>玻尔兹曼-麦克斯韦分布</h6><div>$$\\text dN = n_0 \\cdot (\\frac m{2\\pi kT})^{3/2} \\cdot e^{-[\\frac12 mv^2 + \\varepsilon_p(\\vec r)]/kT} \\cdot \\text d^3\\vec r \\cdot \\text d^3 \\vec v$$</div>\n\n<p>能量简并：不同子相空间分子能量相等。</p>\n<p>分子按能量分布：</p>\n<div>$$N(\\varepsilon) = C \\cdot w(\\varepsilon) \\cdot e^{-\\frac{\\varepsilon}{kT}}$$</div>\n\n<p>$\\varepsilon$为粒子的能量，$w(\\varepsilon)$为具有此能量的体积元个数.</p>\n<h3 id=\"范德瓦尔斯方程\"><a href=\"#范德瓦尔斯方程\" class=\"headerlink\" title=\"范德瓦尔斯方程\"></a>范德瓦尔斯方程</h3><h4 id=\"范氏气体模型\"><a href=\"#范氏气体模型\" class=\"headerlink\" title=\"范氏气体模型\"></a>范氏气体模型</h4><p>气体分子间的作用力：分子间的作用力很复杂，主要是电磁力，可以分为引力和斥力</p>\n<p>范氏气体模型：对理想气体做两方面的修正。考虑分子体积、分子间作用力引起的修正。</p>\n<p><img src=\"/../images/physics/VanGas.png\" alt=\"范氏气体\" loading=\"lazy\"></p>\n<ul>\n<li>分子是直径为d的刚球</li>\n<li>在$d\\rightarrow s$的范围内，分子间有恒定引力</li>\n</ul>\n<h4 id=\"范德瓦尔斯方程-1\"><a href=\"#范德瓦尔斯方程-1\" class=\"headerlink\" title=\"范德瓦尔斯方程\"></a>范德瓦尔斯方程</h4><p>范德瓦尔斯方程：</p>\n<p>设:</p>\n<p>$\\nu &#x3D; 1 mol$</p>\n<p>$p$ – 实测气体压强</p>\n<p>$V_m$ – $1\\ mol$气体容积</p>\n<p>对理想气体：$pV_m &#x3D; RT$</p>\n<p>对真实气体：</p>\n<ol>\n<li>分子体积引起的修正</li>\n</ol>\n<p>分子自由活动空间的体积为$V_m - b$</p>\n<div>$$p(V_m - b) = RT$$</div>\n\n<div>$$\np = \\frac{RT}{V_m - b}\n$$</div>\n\n<ol start=\"2\">\n<li>分子间引力引起的修正</li>\n</ol>\n<p>气体分子间作用力一般表现为引力。</p>\n<p>在容器内部，单个气体分子受到各个方向的平均引力相等，合力可以看作零。</p>\n<p>但是在容器边缘，单个气体分子受到的引力是不对称的。气体分子所受的合力指向容器内部，因此撞击容器壁的气体分子动量比理想气体下的情况要小，宏观上形成的压强比理想气体情况要小。</p>\n<div>$$\np < \\frac{RT}{V_m - b}\\\\\n$$</div>\n\n<p>设</p>\n<div>$$\np = \\frac{RT}{V_m - b} - p_{in}\n$$</div>\n\n<p>$p_{in} \\propto nf_{合}, f_{合}\\propto n \\Rightarrow p_{in} \\propto n^2 \\propto \\frac 1{V_m^2}$</p>\n<p>最后得到：</p>\n<div>$$\n(p + \\frac a{V_m^2})(V_m - b) = RT\n$$</div>\n\n<p>对 ν mol 气体：</p>\n<div>$$\n(p + \\nu^2 \\cdot \\frac a{V^2})(V - \\nu b) = \\nu RT\n$$</div>\n\n<p>常温常压下：$b&#x2F;V_m \\sim 10^{-3}, p_{in}&#x2F;p \\sim 10^{-2}$，这时分子体积和分子间的作用力修正可以忽略。</p>\n<h4 id=\"气体的等温线\"><a href=\"#气体的等温线\" class=\"headerlink\" title=\"气体的等温线\"></a>气体的等温线</h4><p>真实气体的等温线：</p>\n<p><img src=\"/../images/physics/RealGasTemp.png\" alt=\"RealGasTemp\" loading=\"lazy\"></p>\n<p>范氏气体的等温线：</p>\n<p><img src=\"/../images/physics/VanGasTemp.png\" alt=\"VanGasTemp\" loading=\"lazy\"></p>\n<p>如何计算临界参数：</p>\n<p>临界参数：临界点K对应的$p_K, V_K, T_K$</p>\n<p>临界点K是等温线的拐点：</p>\n<div>$$\n\\left(\\frac{\\partial p}{\\partial V}\\right)_{T = T_K} = 0\\\\\n\\left(\\frac{\\partial^2 p}{\\partial V^2}\\right)_{T = T_K} = 0\n$$</div>\n\n<p>K同时也是三次方程的三重根，因此可以通过假设$(V_m - V_{mK})^3 &#x3D; 0$展开后和范德瓦尔斯方程对比系数求解。</p>\n<h4 id=\"范氏气体内能\"><a href=\"#范氏气体内能\" class=\"headerlink\" title=\"范氏气体内能\"></a>范氏气体内能</h4><p>理想气体： $E(T) &#x3D; i\\nu RT &#x2F; 2$</p>\n<p>范氏气体：$V\\uparrow \\rightarrow p_{in}做负功\\rightarrow 分子间势能E_p\\uparrow$</p>\n<p>要计算势能，首先要定义势能为0的状态：定义某种位形为0势能。其他状态的势能定义为从这种状态变形到0势能状态的过程中保守力的变化。</p>\n<div>$$\\mathrm dA = -p_{in}S\\mathrm dl = -p_{in}\\mathrm dV$$</div>\n\n<p>设$E_p(V &#x3D; \\infty) &#x3D; 0$。</p>\n<div>$$\nE_p(V) = \\int_V^\\infty -p_{in}\\mathrm dV = \\int_V^\\infty-\\nu^2 \\cdot \\frac a{V^2}\\mathrm dV = -v^2 \\cdot \\frac aV\n$$</div>\n\n<div>$$\nE = E_k + E_p = \\frac i2\\nu RT - \\nu ^2\\frac aV\n$$</div>\n\n<p><strong>结论：</strong></p>\n<div>$$E(T, V) = \\frac i2 \\nu RT - \\nu^2 \\frac aV$$</div>\n\n<h4 id=\"一个细节\"><a href=\"#一个细节\" class=\"headerlink\" title=\"一个细节\"></a>一个细节</h4><p>为什么不考虑气体分子和容器壁分子间的引力？</p>\n<p>事实上，这引力确实存在。但是可以通过动量定理证明，碰撞过程这引力的作用总和为0。</p>\n<h3 id=\"气体分子的碰撞、平均自由程\"><a href=\"#气体分子的碰撞、平均自由程\" class=\"headerlink\" title=\"气体分子的碰撞、平均自由程\"></a>气体分子的碰撞、平均自由程</h3><p>平均碰撞频率和平均自由程</p>\n<p>平均碰撞频率$\\bar z$：单位时间内一个气体分子与其他分子碰撞的平均次数</p>\n<p>平均自由程$\\bar \\lambda$：气体分子在相邻两次碰撞之间飞行的平均路程。</p>\n<p>平均碰撞频率和平均频率之间关系</p>\n<p>对象:平衡态下的理想气体</p>\n<p>假定：</p>\n<p>(1)只有一种分子；</p>\n<p>(2)分子可视作直径为d的刚球；</p>\n<p>(3)被考察的分子以平均相对速率$\\bar u$运动，其余的分子静止。</p>\n<p>碰撞界面为$\\sigma$。分子间平均相对速率为$\\bar u &#x3D; \\sqrt 2 \\bar v$。</p>\n<div>$$\n\\bar z = \\sigma \\bar u n = \\pi d^2 n \\bar u = \\sqrt 2 \\pi d^2 n\\bar v\n$$</div>\n\n<p>平均自由程和压强、温度的关系：</p>\n<div>$$\n\\bar\\lambda = \\frac {\\bar v} {\\bar z} = \\frac 1{\\sqrt2 \\pi d^2 n} = \\frac {kT}{\\sqrt2\\pi d^2p} \\propto \\frac{T}{p}\n$$</div>\n\n<h3 id=\"气体输运过程\"><a href=\"#气体输运过程\" class=\"headerlink\" title=\"气体输运过程\"></a>气体输运过程</h3><p>非平衡态下，气体内部各部分性质不均匀，就会产生热量、动量、质量的迁移，称为输运过程或内迁移过程。</p>\n<p>气体输运过程包括：热传导、扩散和内摩擦（粘滞）。</p>\n<p>输运现象的宏观实验定律和原因。</p>\n<p>热传导</p>\n<p>温度不均匀。实验定律：傅里叶定律，热传导方程。</p>\n<p>考虑1维的情形。</p>\n<div>$$\n\\mathrm dQ = -\\kappa \\frac{\\partial T}{\\partial x}\\mathrm dS \\mathrm dt\n$$</div>\n\n<div>$$\nj(x, t) = \\frac{\\mathrm dQ}{\\mathrm dS\\mathrm dt}  = -\\kappa \\frac {\\partial T(x, t)}{\\partial x}\n$$</div>\n\n<p>$j(x, t)$：热流密度，$\\partial T&#x2F;\\partial x$：温度梯度。</p>\n<p>温度梯度“力”导致热流。</p>\n<blockquote>\n<p>$T$在这里相当于电势，$-\\partial T &#x2F; \\partial x$相当于电势的负梯度即电场强度，$j$相当于电流密度，$\\kappa$相当于电导率。因此类比$\\vec{J} &#x3D; \\sigma \\vec{E}$有$j &#x3D; -\\kappa \\partial T &#x2F;\\partial x$。类似的，也许可以推导出热阻的概念？热学的“麦克斯韦”方程组又是什么？</p>\n</blockquote>\n<p>统计物理给出的结论：</p>\n<div>$$\n\\kappa = \\frac 13 nm\\bar v \\bar \\lambda c_V\n$$</div>\n\n<blockquote>\n<p>如何理解此公式：热传导的本质是分子能量（热量）的交换，交换的热量等于粒子数乘以单个粒子交换的热量。</p>\n<p>$m$为单个分子质量。$c_V$为定体热容。$n\\bar v$用于描述$\\mathrm dt$内穿过$\\mathrm dS$的粒子数，$\\bar\\lambda$乘以$\\partial T&#x2F;\\partial x$得到温度的变化量$\\mathrm dT$ ,$m,c_V$与温度的变化量相乘，得到单个粒子交换的热量。</p>\n</blockquote>\n<p>稳恒热流：$\\frac{\\mathrm dQ}{\\mathrm dt} &#x3D; C$，$j$, $T$与$t$无关。</p>\n<p>$\\kappa$称为导热系数，由气体特性和$T, p$决定。</p>\n<p>扩散</p>\n<p>原因：气体内部离子数浓度不均匀。</p>\n<p>斐克定律</p>\n<div>$$\n\\mathrm dN = -D\\frac {\\partial n}{\\partial x}\\mathrm dS \\mathrm dt\n$$</div>\n\n<blockquote>\n<p>教材的表述为</p>\n<div>$$\n\\mathrm dM = -D\\frac {\\partial \\rho}{\\partial x}\\mathrm dS \\mathrm dt\n$$</div>\n这里的两个$D$是一样的。\n</blockquote>\n<p>统计物理给出的结论：</p>\n<div>$$\nD = \\frac13\\bar v\\bar \\lambda\n$$</div>\n\n<p>扩散流密度：</p>\n<div>$$\nj(x, t) = \\frac {\\mathrm dN}{\\mathrm dS \\mathrm dt} = -D\\frac {\\partial n}{\\partial x}\n$$</div>\n\n<p>稳恒扩散流：$\\frac {\\mathrm dN}{\\mathrm dt} &#x3D; C$，$j$, $n$, 与$t$无关。</p>\n<p>粒子数守恒方程</p>\n<div>$$\n\\oiint_S j\\cdot \\vec {s} = -\\frac {\\mathrm dN}{\\mathrm dt}, \\nabla \\cdot \\vec j + \\frac{\\partial n}{\\partial x} = 0.\n$$</div>\n\n<p>结合粒子数守恒方程（微分形式）和斐克定律得到扩散方程</p>\n<div>$$\n\\frac{\\partial n}{\\partial t} = D\\frac{\\partial^2 n}{\\partial x^2}\n$$</div>\n\n<p>考试考定场稳恒流，不考内摩擦。</p>\n<p>内摩擦（粘滞）</p>\n<p>根据流体力学，对定常流动的粘滞流体，流速不太大时（雷诺数小），出现层流。</p>\n<p>粘滞定律（牛顿摩擦定律）</p>\n<div>$$\n\\Delta F = - \\eta \\frac{\\mathrm du}{\\mathrm dz}\\Delta S\n$$</div>\n\n<div>$$\np = -\\eta \\frac{\\mathrm du}{\\mathrm dz}\n$$</div>\n\n<p>粘度和温度有关，气体粘度随温度增加，液体温度随温度减小。遵从粘滞定律的流体称为牛顿流体。</p>\n<p>内摩擦原因：流速不均匀。</p>\n<p>统计物理给出的结论：</p>\n<div>$$\n\\eta = \\frac 13 nm\\bar v\\bar \\lambda\n$$</div>\n\n<h2 id=\"热力学第一定律\"><a href=\"#热力学第一定律\" class=\"headerlink\" title=\"热力学第一定律\"></a>热力学第一定律</h2><h3 id=\"准静态过程\"><a href=\"#准静态过程\" class=\"headerlink\" title=\"准静态过程\"></a>准静态过程</h3><p>准静态过程：过程的任一时刻，系统都处于平衡态— 一系列平衡态组成的理想化过程。</p>\n<p>若外界条件改变时，能保证和系统相应的强度量之间差无穷小，则过程是准静态的。</p>\n<p>弛豫时间τ：平衡破坏到恢复平衡的时间.</p>\n<p>当$\\Delta t_{过程} &gt; \\tau$时，过程就可视为准静态过程。<br>。</p>\n<h3 id=\"功\"><a href=\"#功\" class=\"headerlink\" title=\"功\"></a>功</h3><p>体积功：$\\mathrm{\\bar dA} &#x3D; p\\mathrm dV$</p>\n<p>系统对外界做功:$A &#x3D; \\int_{V_1}^{V_2}p\\mathrm dV$是一个过程量。</p>\n<p>通过做功改变系统热力学状态，微观上是分子规则运动的能量通过碰撞转变为无规则运动的能量。</p>\n<h3 id=\"内能，热量和热力学第一定律\"><a href=\"#内能，热量和热力学第一定律\" class=\"headerlink\" title=\"内能，热量和热力学第一定律\"></a>内能，热量和热力学第一定律</h3><p>内能：定义为$E_2 - E_1 &#x3D; A_{1\\rightarrow 2}$（绝热过程）</p>\n<p>内能通过绝热功度量。</p>\n<p>热量：定义为$Q &#x3D; (E_2 - E_1)$（无功过程）</p>\n<p>微观本质是分子无规则运动的能量通过碰撞从高温物体向低温物体传递。</p>\n<p>热力学第一定律：</p>\n<p>$Q &#x3D; \\Delta E + A$</p>\n<p>$\\mathrm {\\bar{d}}Q &#x3D; \\mathrm d E + \\mathrm{\\bar{d}}A$</p>\n<p>热力学第一定律是一条实验定律，适用于任何热力学系统的任何过程。</p>\n<h3 id=\"热容量：\"><a href=\"#热容量：\" class=\"headerlink\" title=\"热容量：\"></a>热容量：</h3><div>$$\nC = \\frac{\\mathrm dQ}{\\mathrm dT}\n$$</div>\n\n<p>定体热容量：$C_v &#x3D; \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_V$</p>\n<p>定压热容量：$C_p &#x3D; \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_p$</p>\n<p>摩尔热容量：</p>\n<div>$$\nC_m = \\frac1\\nu\\frac{\\mathrm dQ}{\\mathrm dT}\n$$</div>\n\n<p>对应地有定体摩尔热容量和定压摩尔热容量。</p>\n<p>理想气体内能：$\\Delta E &#x3D; \\nu C_{V, m}\\Delta T$。（推导：内能变化与过程无关，假设先等体后等温，等体过程无功只有热交换，等温过程内能不变。）</p>\n<p>迈耶公式：</p>\n<div>$$\nC_{p, m} - C_{V, m} = R\n$$</div>\n\n<p>（推导：用等压过程计算内能的变化，与定体过程的结论比较一下可得。）</p>\n<p>理想气体热容量理论公式：</p>\n<div>$$\nC_{V, m} = \\frac i2R, C_{p, m} = \\frac{i+2}{2}R\n$$</div>\n\n<p>推导：结合理想气体内能公式。</p>\n<p>定义比热容比:$\\gamma &#x3D; C_{p, m}&#x2F;C_{V, m}$</p>\n<h3 id=\"绝热过程\"><a href=\"#绝热过程\" class=\"headerlink\" title=\"绝热过程\"></a>绝热过程</h3><p>系统和外界没有热交换的过程。</p>\n<p>理想气体的准静态绝热过程：</p>\n<blockquote>\n<div>$$\n0 = p\\mathrm dV + \\nu C_{V, m}\\mathrm dT\\\\\np\\mathrm dV + V\\mathrm dp = \\nu R\\mathrm dT\\\\\nR  = C_{p, m} - C_{V ,m}\n$$</div>\n\n<p>得到：</p>\n<div>$$\n\\frac{\\mathrm dp}{p} = -\\gamma\\frac{\\mathrm dV}V\n$$</div>\n</blockquote>\n<p>两边积分得到:</p>\n<div>$$\npV^{\\gamma} = C, TV^{\\gamma - 1} = C, p^{\\gamma - 1}T^{-\\gamma} = C\n$$</div>\n\n<p>绝热功</p>\n<div>$$\nA = \\int_{V_1}^{V_2} p\\mathrm dV = C \\int_{V_1}^{V_2}\\frac 1{V^{\\gamma}}\\mathrm dV = \\frac{C}{1 - \\gamma}(V_2^{1 - \\gamma} - V_1^{1 - \\gamma}) =\\frac{p_2V_2 - p_1V_1}{1 - \\gamma} \n$$</div>\n\n<p>绝热功等于内能的减少量：</p>\n<div>$$\nA = -\\Delta E = \\nu C_{V, m}\\Delta T\n$$</div>\n\n<p>理想气体的多方过程</p>\n<p>多方过程：热容量$C$为常数的过程</p>\n<p>多方过程方程：$pV^n &#x3D; \\text{const}$</p>\n<p>其中，$n &#x3D; (C - C_p)&#x2F;(C - C_V) &#x3D; (C_m - C_{p, m})&#x2F;(C_m - C_{V, m}) &#x3D; \\text{const}$</p>\n<p>如果为绝热过程则$C &#x3D; 0$，$n &#x3D; \\gamma$，从而$pV^{\\gamma} &#x3D; \\text{const}$。</p>\n<p>如果为等温过程则$C &#x3D; \\infty$，$n &#x3D; 1$，因此$pV &#x3D; \\text{const}$。</p>\n<p>绝热自由膨胀过程<font color=\"red\">（非准静态过程！！）</font>：</p>\n<p>理想气体：$Q &#x3D; 0, A &#x3D; 0 \\Rightarrow E_1 &#x3D; E_2$</p>\n<p>真实气体：若分子间以引力为主, $T_2 &lt; T_1$，以斥力为主，$T_2 &gt; T_1$。</p>\n<p>焓：气体的绝热节流过程是等焓过程，即$H &#x3D; E + pV$为常数，对于非理想气体而言，内能不仅与温度有关，也与体积有关（焦耳-汤姆孙效应）。</p>\n<p>绝热自由膨胀：初末状态在等温线上，但是过程中不是平衡态。</p>\n<p>准静态等温膨胀：吸热用来做功。</p>\n<p>准静态绝热膨胀：内能的减少量用来做功。</p>\n<p><img src=\"/../images/physics/guocheng.png\" loading=\"lazy\"></p>\n<p>循环过程：</p>\n<p>系统，如热机中的工质，经一系列变化的回到初态的整个过程。</p>\n<p>状态图：</p>\n<p><img src=\"/../images/physics/xunhuantu.png\" loading=\"lazy\"></p>\n<p>热循环：</p>\n<p><img src=\"/../images/physics/rexunhuan.png\" loading=\"lazy\"></p>\n<p>蒸汽机的效率约为十几%，内燃机20-30%。</p>\n<p>制冷循环：</p>\n<p><img src=\"/../images/physics/zhilengxunhuan.png\" loading=\"lazy\"></p>\n<p>制冷系数：</p>\n<div>$$\nw = \\frac{Q_2}{A} = \\frac{Q_2}{Q_1 - Q_2}\n$$</div>\n\n<h3 id=\"卡诺循环\"><a href=\"#卡诺循环\" class=\"headerlink\" title=\"卡诺循环\"></a>卡诺循环</h3><p>卡诺循环是一种可逆循环，包括两个等温过程和两个绝热过程。它的效率为</p>\n<div>$$\n\\eta = 1 - \\frac{|Q_2|}{Q_1} = 1 - \\frac{T_2}{T_1}\n$$</div>\n\n<p>卡诺循环的效率仅与热源的温度比有关。</p>\n<p>由卡诺定理可以证明，卡诺循环的效率与工质无关。因此，不妨设工质为理想气体，利用理想气体等温和绝热过程方程得到效率公式。</p>\n<h2 id=\"热力学第二定律\"><a href=\"#热力学第二定律\" class=\"headerlink\" title=\"热力学第二定律\"></a>热力学第二定律</h2><p>开尔文表述：不可能将热量从低温热源搬运到高温热源，而不产生其他影响。（制冷系数不可能为无穷大）</p>\n<p>克劳修斯表述：不可能将功全部转化为热。（热机效率不可能为1）</p>\n<p>开尔文表述和克劳修斯表述是等价的。事实上，任何关于热现象不可逆的描述都是等价的，它们要么同时成立，要么同时不成立。因此，描述热现象的方向性，只需要举一个例子即可。</p>\n<h3 id=\"卡诺定理\"><a href=\"#卡诺定理\" class=\"headerlink\" title=\"卡诺定理\"></a>卡诺定理</h3><p>在温度相同的高温热源和温度相同的低温热源之间工作的一切热机，可逆热机的效率最大。</p>\n<p>推论：一切可逆热机，只要它们的高温热源的温度相等，低温热源的温度相等，效率就相等。</p>\n<p>对于制冷机：</p>\n<p>可逆制冷机的制冷系数最大。</p>\n<p>所有2热源可逆制冷机制冷系数都相等，等于卡诺制冷机的制冷系数。</p>\n<h3 id=\"热力学温标\"><a href=\"#热力学温标\" class=\"headerlink\" title=\"热力学温标\"></a>热力学温标</h3><p>根据卡诺定理，可逆热机的效率只与温度有关。因此可以用效率，或者说热量比来定义温标。</p>\n<p>在热力学温标下，低温热源的温度不能为0，否则可逆热机的效率为1.</p>\n<h3 id=\"任意可逆循环的效率\"><a href=\"#任意可逆循环的效率\" class=\"headerlink\" title=\"任意可逆循环的效率\"></a>任意可逆循环的效率</h3><div>$$\n\\eta \\le 1 - \\frac {T_2}{T_1}\n$$</div>\n\n<p>其中，$T_1$，$T_2$分别为循环中工质的最高和最低温度。</p>\n<h3 id=\"克劳修斯熵公式\"><a href=\"#克劳修斯熵公式\" class=\"headerlink\" title=\"克劳修斯熵公式\"></a>克劳修斯熵公式</h3><p>热力学第零定理导出了温度，热力学第一定律导出了内能，热力学第二定律则导出了熵。</p>\n<p>可逆循环可以拆成若干小卡诺循环，每个卡诺循环满足</p>\n<p>可逆循环有克劳修斯等式</p>\n<div>$$\n\\oint_R \\frac{\\mathrm {\\bar d} Q}{T} = 0\n$$</div>\n\n<p>因此得到一个与路径无关的状态函数。</p>\n<p>熵与状态有关，和过程无关。即便过程是不可逆过程。</p>\n<p>但是，仅当过程为可逆过程时才有$\\mathrm dS&#x3D;  \\mathrm{\\bar d}Q&#x2F;T$。</p>\n<p>对于可逆过程：</p>\n<div>$$\nT\\mathrm dS = \\mathrm{\\bar d}Q = \\mathrm dE + p\\mathrm dV\n$$</div>\n\n<p>因而可以用$E, V$表示熵：</p>\n<div>$$\n\\mathrm dS = \\frac 1T \\mathrm dE + \\frac pT \\mathrm dV = \\frac 1T()\n$$</div>\n\n<h3 id=\"克劳修斯不等式\"><a href=\"#克劳修斯不等式\" class=\"headerlink\" title=\"克劳修斯不等式\"></a>克劳修斯不等式</h3><p>不可逆循环有</p>\n<div>$$\n\\oint_{Ir} \\frac{\\mathrm {\\bar d} Q}{T} < 0\n$$</div>\n\n<p>因而有熵增加原理:</p>\n<div>$$\n\\int_{1_{Ir}}^{2} + \\int_{2_R}^1 < 0\\Rightarrow S_1 - S_2= \\int_{1_{Ir}}^2\n$$</div>\n\n<h1 id=\"振动和波动\"><a href=\"#振动和波动\" class=\"headerlink\" title=\"振动和波动\"></a>振动和波动</h1><h2 id=\"波动\"><a href=\"#波动\" class=\"headerlink\" title=\"波动\"></a>波动</h2><h3 id=\"多普勒效应\"><a href=\"#多普勒效应\" class=\"headerlink\" title=\"多普勒效应\"></a>多普勒效应</h3><p>一般形式：</p>\n<p><img src=\"/../images/DSA/Duopule.jpg\" loading=\"lazy\"></p>\n<p>机械波不存在多普勒效应。</p>\n<p>电磁波的多普勒效应：</p>\n<p><img src=\"/../images/DSA/waveDuopl.jpg\" loading=\"lazy\"></p>\n<p>横向多普勒效应：$\\theta &#x3D; \\pi &#x2F;2$</p>\n<p>纵向多普勒效应：$\\theta &#x3D; 0,\\pi$</p>\n<h3 id=\"激波\"><a href=\"#激波\" class=\"headerlink\" title=\"激波\"></a>激波</h3><p>马赫数：$\\frac{v_s}{u} &#x3D; \\frac 1{\\sin\\alpha}$</p>\n<h1 id=\"光学\"><a href=\"#光学\" class=\"headerlink\" title=\"光学\"></a>光学</h1><p>光学分为几何光学，波动光学和量子光学。</p>\n<h2 id=\"光的相干叠加\"><a href=\"#光的相干叠加\" class=\"headerlink\" title=\"光的相干叠加\"></a>光的相干叠加</h2><p>光源：</p>\n<ol>\n<li>普通光源：自发辐射。不同原子发光独立、不相干；同原子不同次发光独立、不相干。</li>\n<li>激光光源：受激辐射。光放大，全通光子，相干光，波列长，相干性好。</li>\n</ol>\n<p>光的相干性：<br>光学中强调电磁波的电场矢量$\\vec E$：光矢量</p>\n<p>相干条件：光矢量有平行分量，频率相同，相差恒定。</p>\n<p>电磁波叠加的强度公式推导：</p>\n<div>$$\nI = \\sqrt{\\varepsilon / \\mu}\\left<\\vec E \\cdot \\vec E \\right>_t \\\\\n\n<p>I \\propto \\left&lt;\\vec E \\cdot \\vec E \\right&gt;_t \\</p>\n<p>叠加的电磁波：\\vec E_1 + \\vec E_2\\</p>\n<p>矢量的点乘运算可得叠加后的强度:\\</p>\n<p>I &#x3D; I_1 + I_2 + 2\\sqrt{\\varepsilon &#x2F; \\mu}\\left&lt;\\vec E_1 \\cdot \\vec E_2 \\right&gt;_t </p>\n<p>$$</div></p>\n<p>对光的相干叠加，用光矢量的平行分量描述光场–标量波函数。</p>\n<div>$$\nI = I_1 + I_2 + 2\\sqrt{I_1I_2}\\cos \\Delta \\varphi\n$$</div>\n\n<p>其中$\\Delta\\varphi &#x3D; -k(r_2 - r_1) + (\\varphi_{20} - \\varphi_{10})$为相位差。</p>\n<p>在上面两式中，若$\\vec E_1 \\cdot \\vec E_2 \\ne 0$或者$\\Delta\\varphi \\ne \\pm\\frac{\\pi}{2}…$，则满足相干的条件。</p>\n<p>条纹的明显程度用衬比度衡量：$V &#x3D; (I_{max} - I_{min})&#x2F;(I_{max} + I_{min})$</p>\n<p>不同的位置$\\Delta\\varphi$不同，因而对应的$I$不同，造成了干涉条纹的出现。$I_1 &#x3D; I_2$时$V&#x3D;1$，$I_1 \\ne I_2$时，$V \\ne 1$。</p>\n<p>普通光源获得相干光的途径一般有分波阵面法（双缝干涉）和分振幅法（薄膜干涉）。</p>\n<h3 id=\"双缝干涉\"><a href=\"#双缝干涉\" class=\"headerlink\" title=\"双缝干涉\"></a>双缝干涉</h3><p><img src=\"/../images/physics/shuangfeng.jpg\" loading=\"lazy\"></p>\n<p>明纹：$\\delta &#x3D; \\pm k\\lambda$</p>\n<p>暗纹：$\\delta &#x3D; \\pm (2k + 1)\\frac \\lambda 2$</p>\n<p>$(k\\in N)$</p>\n<p>条纹间距：$\\Delta x &#x3D; \\frac{D}{d}\\lambda$</p>\n<p>$\\Delta \\varphi \\approx \\frac{d\\sin \\theta}{\\lambda}2\\pi$</p>\n<p>时间相干性（光的颜色）：</p>\n<p>光的非单色性：</p>\n<p>准单色光：由某个中心频率或波长附近的频率或波长连续分布的光构成。采用谱密度函数描述。</p>\n<p><img src=\"/../images/physics/%E5%87%86%E5%8D%95%E8%89%B2%E5%85%89.jpg\" loading=\"lazy\"></p>\n<p>造成谱线宽度的原因：自然宽度、多普勒增宽、碰撞增宽</p>\n<p>非单色性对干涉条纹的影响：</p>\n<p><img src=\"/../images/physics/%E9%9D%9E%E5%8D%95%E8%89%B2%E5%85%89.jpg\" loading=\"lazy\"></p>\n<p>从图中可以看出，如果某个位置谱线中波长最长的成分的k级明纹和波长最短的成分的(k+1)级明纹重合，则在这个位置以后的条纹看不清楚了。</p>\n<p>可以解得最大相干级次：$k_M &#x3D; \\lambda&#x2F;\\Delta\\lambda$，进而有最大波程差：$\\delta_M &#x3D; \\lambda^2&#x2F;\\Delta\\lambda$。</p>\n<p>相干长度等于波列长度。</p>\n<p>通常用相干时间（光通过相干长度所需的时间）$\\tau &#x3D; \\delta_M &#x2F; c$ 衡量光的单色性。相干时间或相干长度越长，则单色性越好。</p>\n<p>空间相干性（光的宽度）：</p>\n<p>较宽的光源会导致明纹的非相干叠加，使衬比度下降。</p>\n<p>设光的宽度为$b_0$,则看到干涉条纹的条件是$b_0 &lt; \\frac{R}{d}\\lambda$，这一上界称为光源极限宽度。</p>\n<p>固定b和R，则得到$d &lt; \\frac{R}{b}\\lambda$，上界称为相干间隔。</p>\n<p>光源中心对两孔的张角为$\\theta &#x3D; \\frac{d}{R} &lt; \\frac{\\lambda}{b}$，上界称为相干孔径角。</p>\n<h3 id=\"光程\"><a href=\"#光程\" class=\"headerlink\" title=\"光程\"></a>光程</h3><p>用于计算光经过不同介质的相差。<br>$\\Delta\\varphi &#x3D; \\frac{2\\pi r}{\\lambda}$。</p>\n<p>透镜不产生附加光程差。</p>\n<h3 id=\"薄膜干涉\"><a href=\"#薄膜干涉\" class=\"headerlink\" title=\"薄膜干涉\"></a>薄膜干涉</h3><p>为什么要薄？相干长度（时间相干性）限制。</p>\n<p>薄膜干涉有实际意义的是等倾条纹和等厚条纹。</p>\n<p>光程差</p>\n<div>$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2}\n$$</div>\n\n<p>e为膜厚度。</p>\n<p>等厚条纹：</p>\n<p>厚度不同，角度相同</p>\n<p>单色平行光入射，近似垂直于膜表面，因而$i, r \\approx 0$</p>\n<div>$$\n\\delta = 2ne + \\frac{\\lambda}{2}\n$$</div>\n\n<p>劈尖：</p>\n<p>由于明纹需满足$\\delta &#x3D; k\\lambda$，暗纹需满足$\\delta &#x3D; (2k+1)\\lambda&#x2F;2$，故相邻亮纹所在的厚度差为$\\Delta e &#x3D; \\lambda &#x2F; (2n)$，而条纹间距为$L &#x3D; \\Delta e &#x2F; \\theta &#x3D; \\lambda &#x2F; (2n\\theta)$</p>\n<p>牛顿环：</p>\n<p><img src=\"/../images/physics/niudunhuan.jpg\" loading=\"lazy\"></p>\n<p>可以得到暗环半径公式：$r_k&#x3D;\\sqrt{kR\\lambda}$</p>\n<p>总结：条纹跟着厚度走。</p>\n<p>等倾条纹：</p>\n<p>厚度相同，角度不同。</p>\n<p>光程差(记!)</p>\n<div>$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2} = 2e\\sqrt{n^2 - n^{\\prime2}\\sin ^2 i} + \\frac \\lambda2\n$$</div>\n\n<p>等倾条纹实验通常采用面光源,因为透镜会把方向相同的光汇聚到一点，因而条纹的非常鲜明，衬比度很高，不会出现光源宽度和条纹衬比度的矛盾。</p>\n<p>应用：增透膜和增反膜</p>\n<h3 id=\"迈克尔逊干涉仪\"><a href=\"#迈克尔逊干涉仪\" class=\"headerlink\" title=\"迈克尔逊干涉仪\"></a>迈克尔逊干涉仪</h3><p>平行：等倾条纹</p>\n<p>倾斜：等厚条纹</p>\n<p>条纹缩进N个，代表厚度变化：</p>\n<div>$$\n\\Delta d = \\frac{\\lambda}{2n} = \\frac {\\lambda}{2}\n$$</div>\n\n<p>在光路上放一个介质，条纹移动N个：</p>\n<div>$$\n\\delta = 2(n - 1)l = N\\lambda\n$$</div>\n\n<p>简而言之，一个条纹对应光程变化一个波长，厚度的变化（介质变化折算成厚度变化）乘以2等于光程的变化，因为一来一回经过了两次。</p>\n<h2 id=\"衍射\"><a href=\"#衍射\" class=\"headerlink\" title=\"衍射\"></a>衍射</h2><p>菲涅尔衍射和夫琅禾费衍射。</p>\n<p>惠更斯-菲涅尔原理</p>\n<p>夫琅禾费衍射研究光源和投影面在无限远处的情形。采用透镜将无限远转化为有限远。</p>\n<h3 id=\"单缝衍射（夫琅禾费）\"><a href=\"#单缝衍射（夫琅禾费）\" class=\"headerlink\" title=\"单缝衍射（夫琅禾费）\"></a>单缝衍射（夫琅禾费）</h3><p>利用半波带法计算明暗纹位置：</p>\n<p>中央明纹：$a\\sin \\theta &#x3D; 0$</p>\n<p>暗纹：$a\\sin \\theta &#x3D; \\pm k\\lambda$</p>\n<p>明纹（近似）:$a\\sin \\theta &#x3D; \\pm (2k + 1)\\frac \\lambda 2$</p>\n<p>上述的$k$不能为0。因为如果k&#x3D;0，即中央明纹，它没有半波带，因此要单独考虑。</p>\n<p>光强公式：$I_p &#x3D; I_0(\\frac{\\sin \\alpha}{\\alpha})^2$</p>\n<p>其中$I_0$为中心亮纹强度，$\\alpha &#x3D; \\frac{\\pi a \\sin \\theta}{\\lambda}$</p>\n<p>条纹宽度：</p>\n<p>条纹宽度的定义：两个相邻暗纹之间的距离，就是它们之间那个条纹的宽度。</p>\n<p>中央明纹角宽度：$\\Delta \\theta_0\\approx 2\\frac{\\lambda}{a}$，线宽度：$\\Delta x_0 \\approx 2 f \\frac{\\lambda}{a}$</p>\n<p>其他明纹线宽度：$\\Delta x \\approx f\\frac{\\lambda}{a}$</p>\n<h3 id=\"光栅衍射\"><a href=\"#光栅衍射\" class=\"headerlink\" title=\"光栅衍射\"></a>光栅衍射</h3><p>光栅是由衍射单元（狭缝、反射面等）排列成的具有空间周期性结构的光学元件。</p>\n<p>光栅常数d-空间周期性结构常数</p>\n<p>正入射光栅方程：$d\\sin \\theta &#x3D; \\pm k\\lambda$。（明纹位置）</p>\n<p>暗纹方程：$d\\sin \\theta &#x3D; \\pm k\\lambda + \\frac{m}{N}\\lambda$</p>\n<p>主极大缺级公式：$k &#x3D; k^\\prime d &#x2F; a$</p>\n<p>主极大半角宽：$\\frac {\\lambda}{N d \\cos \\theta_k}$</p>\n<p>斜入射光栅方程：$d(sin\\theta - \\sin i) &#x3D; \\pm k\\lambda$</p>\n<p>斜入射可以获得更高级次的条纹，但是观察到的条纹总数不变。</p>\n<p>调节入射角i或者波长$\\lambda$，衍射角$\\theta_k$也会改变。对于0级衍射光，$\\sin \\theta_0 &#x3D; \\frac{\\lambda}{2\\pi d}\\Delta \\varphi_{in}$</p>\n<p>光学仪器的分辨本领：</p>\n<p>艾里斑半角宽$D\\sin \\theta_1 \\approx 1.22\\lambda$</p>\n<p>瑞利判据：一个象斑中心在另一个象斑边缘。</p>\n<p>根据瑞利判据得到透镜分辨本领（最小分辨角）：$R &#x3D; \\frac{D}{1.22\\lambda}$</p>\n<p>光栅光谱：</p>\n<p>取决于光栅的色散能力和谱线（条纹）的线宽度</p>\n<p>角色散本领：$D_{\\theta} &#x3D; \\frac{\\delta \\theta}{\\delta \\lambda}$</p>\n<p>色分辨本领：$R &#x3D; \\frac{\\lambda}{\\delta \\lambda} &#x3D; Nk$，$\\delta \\lambda$，$\\lambda $取较小者的波长，$k$是主极大级数。</p>\n<h2 id=\"偏振\"><a href=\"#偏振\" class=\"headerlink\" title=\"偏振\"></a>偏振</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>线偏振光：光矢量做同向振动，方向不变。</p>\n<p>圆偏振光：光矢量的端点是圆。</p>\n<p>椭圆偏振光：光矢量的端点是椭圆。</p>\n<p>非偏振光：例如自然光。它的振动方向随机，各个方向振幅相等。自然光可以分解为两束垂直振动，振幅相等，相差随机的线偏振光。</p>\n<p>部分偏振光：自然光+完全偏振光。</p>\n<p>偏振度：$P &#x3D; \\frac{I_p}{I_t} &#x3D; \\frac{I_p}{I_n + I_p}$</p>\n<h3 id=\"起偏与检偏\"><a href=\"#起偏与检偏\" class=\"headerlink\" title=\"起偏与检偏\"></a>起偏与检偏</h3><p>偏振片：利用二向色性。有微晶型和分子型。</p>\n<p>线偏振光的起偏：通过偏振片。</p>\n<p>马吕斯定律：$A &#x3D; A_0 \\cos \\alpha, I &#x3D; I_0 \\cos^2 \\alpha$</p>\n<h3 id=\"反射与折射中的偏振\"><a href=\"#反射与折射中的偏振\" class=\"headerlink\" title=\"反射与折射中的偏振\"></a>反射与折射中的偏振</h3><p>S分量：垂直于入射面。P分量：平行于入射面。</p>\n<p>反射光S分量多，折射光P分量多。</p>\n<p>当$i &#x3D; i_0$使得反射光只有S分量，折射光大部分是P分量。称为布儒斯特角。$i_0 + r_0 &#x3D; 90\\degree$，因而有布儒斯特定律：$\\tg i_0 &#x3D; \\frac{n_2}{n_1}$</p>\n<p>玻璃片堆可以增强反射光的强度，增加折射光的偏振程度。</p>\n<p>散射引起光的偏振：</p>\n<p>微粒散射：丁达尔效应</p>\n<p>分子散射：纯净气体、液体的散射。</p>\n<p>双折射现象：</p>\n<p>1束光入射到各向异性介质内，产生2束折射光。o光为寻常光，符合折射定律；e光为非常光，不符合折射定律一般，也不一定在入射面内。o，e光都是线偏振光，振动方向互相垂直。</p>\n<p>晶体光轴：是晶体中的特殊方向，光在晶体中沿该方向传播不发生双折射。方解石是单轴晶体。云母是双轴晶体。</p>\n<p>主平面：晶体中光的传播方向与晶体光轴构成的平面。o光振动方向垂直于主平面，e的振动方向在主平面内。只有当光轴在入射面内，o光主平面、e光主平面、入射面才重合。</p>\n<p>折射角度不同的本质是不同角度下光的传播速度不同。据此区分正晶体和负晶体：</p>\n<p>$v_o$是o光速度，$v_e$是e光垂直光轴方向速度。o光是各向同性的，e光沿平行光轴方向的速度和o光相同，e光沿所有方向的速度构成一个旋转椭球面。</p>\n<p><img src=\"/../images/physics/shuangzheshe.jpg\" loading=\"lazy\"></p>\n<p>正晶体：$v_o &gt; v_e$</p>\n<p>负晶体：$v_o &lt; v_e$</p>\n<p>定义主折射率：$n_o &#x3D; c&#x2F;v_o, n_e &#x3D; c&#x2F;v_e$</p>\n<p>利用惠更斯作图法可以讨论单轴晶体的光传播情况：</p>\n<p>以负晶体为例。</p>\n<ul>\n<li>若光轴平行于晶体表面，自然光垂直入射：o和e方向相同，速度不同，仍然是双折射；</li>\n<li>光轴平行晶体表面，且垂直入射面，自然光斜入射：e光也满足折射定律，折射率为$n_e$；</li>\n<li>光轴与晶体表面斜交，自然光垂直入射：e光偏离入射方向，惠更斯波面是斜椭圆。</li>\n</ul>\n<p>研究晶片时，o光和e光（垂直振动和平行振动）是独立的正交的分量。垂直振动不会变成平行振动，平行振动也不会变成垂直振动。</p>\n<p>双折射：两个垂直方向的线偏振光的不同速度造成的。</p>\n<p>旋光：两个不同旋转方向的圆偏振光的不同速度造成的。</p>\n<h1 id=\"量子物理\"><a href=\"#量子物理\" class=\"headerlink\" title=\"量子物理\"></a>量子物理</h1><h2 id=\"黑体辐射\"><a href=\"#黑体辐射\" class=\"headerlink\" title=\"黑体辐射\"></a>黑体辐射</h2><p>热辐射</p>\n<p>物体受热发出电磁辐射。热辐射是连续谱，温度升高，短波成分增加。</p>\n<p>平衡热辐射：物体温度不变时产生的热辐射。单位时间内物体吸收能量等于辐射能量。</p>\n<p>光谱幅出度（单色幅出度）</p>\n<p>单位面积内单位频率发射的电磁波能量。</p>\n<div>$$\nM_\\nu = \\frac{\\mathrm d E_\\nu(T)}{\\mathrm d\\nu}\n$$</div>\n\n<p>总幅出度</p>\n<div>$$\nM(T) = \\int_0^\\infty M_\\nu(T)\\mathrm d\\nu\n$$</div>\n\n<p>单色吸收比</p>\n<div>$$\n\\alpha_\\nu(T) = \\frac{\\mathrm d E_{\\nu(吸收)}}{\\mathrm d E_{\\nu(入射)}}\n$$</div>\n\n<p>黑体</p>\n<p>能吸收所有频率的电磁波，没有反射。$\\alpha_{\\nu}&#x3D;1$。</p>\n<p>基尔霍夫辐射定律：</p>\n<div>$$\n\\frac{M_{\\nu i}}{\\alpha_{\\nu i}} = M_{\\nu 黑体}\n$$</div>\n\n<p>实验定律：</p>\n<p>维恩位移定律：$\\nu_m &#x3D; C_\\nu T$, $\\lambda_m &#x3D; b&#x2F;T$</p>\n<p>注：$\\lambda_m \\nu_m \\ne c$。</p>\n<p>斯特藩-玻尔兹曼定律：$M(T) &#x3D; \\sigma T^4$，$\\sigma$为斯特藩-玻尔兹曼常量。</p>\n<p>韦恩公式：低频段不符合；</p>\n<p>瑞利-金斯公式：高频段不符合。</p>\n<p>普朗克能量子假设：$\\varepsilon &#x3D; h\\nu$</p>\n<p>普朗克公式：</p>\n<div>$$\nM_\\nu(T) = \\frac{2\\pi h}{c^2}\\cdot \\frac{\\nu^3}{e^{h\\nu/kT} - 1}\n$$</div>\n\n<p>由它可以导出所有其他热辐射公式。</p>\n<h2 id=\"光电效应\"><a href=\"#光电效应\" class=\"headerlink\" title=\"光电效应\"></a>光电效应</h2><p>自学。</p>\n<h2 id=\"光的二象性\"><a href=\"#光的二象性\" class=\"headerlink\" title=\"光的二象性\"></a>光的二象性</h2><p>光子理论：能量$\\varepsilon &#x3D; h\\nu$。光强：$I &#x3D; N \\cdot h\\nu$，N是光子数流通量。</p>\n<p>解释光电效应：</p>\n<div>$$\n\\frac 12 mv_m^2 = h\\nu - A\n$$</div>\n\n<p>光的粒子性：</p>\n<div>$$\np = \\frac h \\lambda \\\\\nE = h\\nu \\\\\nm = \\frac{h\\nu}{c^2}\n$$</div>\n\n<p>解释干涉和衍射：</p>\n<p>光子在某处出现的概率是由该处的光强决定的：$I \\propto \\frac 1 {r^2}$，光子分布概率的不同导致了光强的不同。也就是说，光子的波动性表现为概率波。</p>\n<p>光子在某处出现的概率和该处光强（光振幅的平方）成正比。</p>\n<h2 id=\"康普顿散射\"><a href=\"#康普顿散射\" class=\"headerlink\" title=\"康普顿散射\"></a>康普顿散射</h2><p>散射波出现新的波长：$\\Delta \\lambda &#x3D; \\lambda_C(1 - \\cos\\varphi)$</p>\n<p>利用光子理论解释：光子和“静止”的“自由”电子碰撞过程动量守恒，能量守恒。</p>\n<p>解得$\\Delta \\lambda &#x3D; \\frac{h}{m_0c}(1 - \\cos \\varphi)$</p>\n<p>如果光子撞到内层电子，则能量不变，因而存在原波长。</p>\n<p>自由电子只能散射光子，不能吸收光子。如果吸收了，根据能量守恒和动量守恒，解得v&#x3D;c，违反了相对论。</p>\n<p>光电效应不考虑动量守恒，因为可见光、紫外线的能量低，电子不能视为自由，光子-电子不能视为动量守恒的系统。也因此，可见光观察不到康普顿效应。</p>\n<h2 id=\"概率波和概率幅\"><a href=\"#概率波和概率幅\" class=\"headerlink\" title=\"概率波和概率幅\"></a>概率波和概率幅</h2><p>物质波的本质：</p>\n<p>德布罗意认为是引导物质运动的“导波”；（本质不明确）</p>\n<p>薛定谔认为波是基本的，电子是“波包”；（波包是不稳定的，而电子是稳定的）</p>\n<p>另一个观点：粒子是基本的，物质波是电子相互作用形成的（被电子双缝实验否定）</p>\n<p>波恩的解释：物质波是描述粒子在空间概率分布的“概率波”。</p>\n<p>量子力学的基本假设之一：微观粒子的状态用波函数描述</p>\n<p>概率波波函数(概率幅)：复函数$\\Psi (\\vec r, t)$</p>\n<p>波函数没有直接的物理意义。复函数模的平方$|\\Psi (\\vec r, t)|^2$表示概率密度。</p>\n<p>波函数需要满足标准条件：</p>\n<p>有限性:$\\iiint_{\\Delta V}|\\Psi|^2 \\mathrm dV$有限</p>\n<p>归一性：$\\int_\\Omega |\\Psi(\\vec r, t)|^2 \\mathrm dV &#x3D; 1$</p>\n<p>单值性：波函数是单值函数。</p>\n<p>连续性：波函数和它的一阶导数是连续的。</p>\n<p>双缝的波函数：等于通过上缝和下缝的波函数的线性叠加。$\\Psi_{12}&#x3D;\\Psi_1+\\Psi_2$。(一个基本假设)</p>\n<p>微观粒子波动性实质是波函数的叠加性。</p>\n<p>结合测量理解。</p>\n<p>态叠加原理：$\\Psi &#x3D; \\sum_n C_n\\Psi_n$。其中$|C_n|^2$是该粒子处于$\\Psi_n$状态的概率。</p>\n<p>一维自由粒子的波函数：</p>\n<div>$$\n\\Psi(x, t) = A e^{i(px-Et)/\\hbar}\n$$</div>\n\n<p>概率密度$|\\Psi|^2 &#x3D; |A|^2 &#x3D; \\text {const.}$</p>\n<p>波粒二象性：</p>\n<p>粒子性：具有能量$E$和动量$\\vec p$。非经典粒子！没有轨道概念。</p>\n<p>波动性：具有波长$\\lambda$和频率$\\nu$。非经典波！非真实物理量的波动。</p>\n<h2 id=\"不确定关系\"><a href=\"#不确定关系\" class=\"headerlink\" title=\"不确定关系\"></a>不确定关系</h2><div>$$\n\\left<\\vec r|\\Psi\\right>\n$$</div>\n\n<p>不确定度：$\\Delta A &#x3D; \\sqrt{\\overline{(A - \\bar A)^2}}$</p>\n<p>坐标和动量的不确定性关系：</p>\n<div>$$\n\\Delta x \\cdot \\Delta p \\ge \\frac \\hbar 2\n$$</div>\n\n<p>因而微观粒子没有“轨道”。</p>\n<p>能量和时间的不确定性关系：</p>\n<div>$$\n\\Delta E \\cdot \\Delta t \\ge \\frac{\\hbar}{2}\n$$</div>\n\n<p>时间不是力学量，它只是一个参数。位置，动量，能量等都是力学量。</p>\n<h2 id=\"薛定谔方程\"><a href=\"#薛定谔方程\" class=\"headerlink\" title=\"薛定谔方程\"></a>薛定谔方程</h2><p>定义</p>\n<div>$$\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} = \\hat {H} \\Psi\n$$</div>\n\n<p>哈密顿算符：$\\bar {H} &#x3D; -\\frac{\\hbar ^2}{2m}\\nabla^2 + U(\\vec r, t)$</p>\n<p>若势函数不显含时间，则哈密顿算符$\\hat H$称为能量算符。此时薛定谔方程可以通过分离变量法求解。</p>\n<h3 id=\"定态薛定谔方程-能量本征方程\"><a href=\"#定态薛定谔方程-能量本征方程\" class=\"headerlink\" title=\"定态薛定谔方程-能量本征方程\"></a>定态薛定谔方程-能量本征方程</h3><p>分离变量法求解：</p>\n<p>若势函数不显含t，则可设：</p>\n<div>$$\n\\Psi(\\vec r, t) = \\Phi(\\vec r) \\cdot T(t)\n$$</div>\n\n<p>得到：</p>\n<div>$$\ni\\hbar \\frac{\\mathrm dT(t)}{\\mathrm d t}\\frac 1{T(t)} = [\\hat H\\Phi (\\vec r)]\\frac{1}{\\Phi(\\vec r)} = E\n$$</div>\n\n<div>$$\nT(t) = Ce^{-\\frac{i}{\\hbar}Et}\\\\\n()\n$$</div>\n\n<p>E称为能量本征值（后面会讲什么叫本征值），对应的$\\Phi_E$称为本征波函数。</p>\n<p>定态：能量取确定值的状态，对应薛定谔方程的特解：$\\Psi_E(\\vec r, t) &#x3D; \\Phi e^{-\\frac{i}{\\hbar}Et}$.</p>\n<p>对不同的势函数和能量区间，能量的本征值可能取连续的值，也可能取分立的值。设E取分立值，${E_n, n &#x3D; 1, 2, 3, \\dots}$，对应的本征波函数$\\Psi_E (\\vec r, t) &#x3D; \\Phi_E(\\vec r)e^{-\\frac{i}{\\hbar}Et}$</p>\n<p>下面通过求解一维定态薛定谔方程来讨论两类问题：</p>\n<p>本征值问题：给定$U(x)$，求$E_n$和$\\Phi_n(x)$。</p>\n<p>散射问题：$E$已知，射向势垒$U(x)$，计算粒子穿透势垒的概率。 </p>\n<h2 id=\"无限深方势阱中的粒子\"><a href=\"#无限深方势阱中的粒子\" class=\"headerlink\" title=\"无限深方势阱中的粒子\"></a>无限深方势阱中的粒子</h2><p>背景：长度为$a$的导体中自由移动的电子，只能在导体中自由运动，而不能离开导体。</p>\n<p>$|x| &gt; a&#x2F;2$时，$U(x) \\rightarrow \\infty$；</p>\n<p>$|x| \\le a&#x2F;2$时，$U(x) &#x3D; 0$。</p>\n<p>在$|x| &gt; a&#x2F;2$区间，$\\Phi_1 &#x3D; 0$。</p>\n<p>在$|x| \\le  a&#x2F;2$区间，$\\frac{\\mathrm d^2 \\Phi_2}{\\mathrm dx^2} + \\frac{2mE}{\\hbar^2}\\Phi_2 &#x3D; 0$</p>\n<p>记$k &#x3D; \\frac{2mE}{\\hbar^2}$。解得$\\Phi_2 &#x3D; A\\sin(kx + \\varphi)$。</p>\n<p>求解定态的常规手法：利用波函数的三个条件，即单值、有限、连续，确定$A, k, \\varphi$。</p>\n<p>利用连续条件，波函数在势阱边界处连续：</p>\n<div>$$\nA\\sin(\\frac{ka}{2} + \\varphi) = 0, A\\sin(-\\frac{ka}{2} + \\varphi) = 0.\\\\\n\n<p>\\Rightarrow k &#x3D; \\frac{n\\pi}{a}, \\varphi &#x3D; \\frac{l\\pi}{2}<br>$$</div></p>\n<p>从而</p>\n<div>$$\nE = \\frac{\\pi^2\\hbar^2}{2ma^2}n^2 \\ (n = 1, 2, 3, \\dots)\n$$</div>\n\n<p>最低能量$E_1$被称为零点能。</p>\n<p>大量子数情况下，能量趋向于连续。</p>\n<div>$$\nl = 0, \\varphi = 0, \\Phi_2 = A\\sin \\frac{n\\pi}{a}x = \\Phi_{on},满足边界连续需要n为偶数\\\\\nl = 1, \\varphi =\\pi /2 , \\Phi_2 = A\\cos \\frac{n\\pi}{a}x = \\Phi_{en},满足边界连续需要n为奇数\\\\\nl \\ge 2，只差个符号，不影响|\\Phi|^2，不再考虑。\n$$</div>\n\n<p>求$A$：</p>\n<p>归一化：$\\int_{-a&#x2F;2}^{a&#x2F;2}|\\Phi_{on}|^2 \\mathrm dx &#x3D; 1$， 得到$A &#x3D; \\sqrt \\frac2a$</p>\n<div>$$\n\\Phi_{on} = \\sqrt{\\frac 2a}\\sin \\frac{n\\pi}{a}x, n = 2, 4, 6, \\dots\\\\\n\\Phi_{en} = \\sqrt{\\frac 2a}\\cos\\frac{n\\pi}{a}x, n = 1, 3, 5, \\dots\n$$</div> \n\n<p>定态：</p>\n<div>$$\n\n<p>\\Psi_n (x, t) &#x3D; \\Phi_n(x) \\cdot e^{-\\frac i\\hbar Et}</p>\n<p>$$</div></p>\n<p>被称为驻波解(时间项指数为纯虚数，展开可以写成三角函数)。概率密度$|\\Psi_n(x, t)|^2 &#x3D; |\\Phi_n(x)|^2$</p>\n<h2 id=\"势垒穿透\"><a href=\"#势垒穿透\" class=\"headerlink\" title=\"势垒穿透\"></a>势垒穿透</h2><h3 id=\"粒子进入势垒\"><a href=\"#粒子进入势垒\" class=\"headerlink\" title=\"粒子进入势垒\"></a>粒子进入势垒</h3><p>背景：金属与半导体接触处，势能隆起形成势垒。粒子以能量为$E(E &lt; U_0)$的状态自由入射。</p>\n<div>$$\nU(x) = 0, x \\le 0;\\\\\nU(x) = U_0, x \\gt 0.\n$$</div>\n\n<p>量子力学认为有一部分粒子会穿透势垒。不仅有反射，还有投射。</p>\n<p>定态薛定谔方程：</p>\n<div>$$\n\\Phi^{\\prime\\prime}(x) + \\frac{2m}{\\hbar^2}(E - U(x))\\Phi(x) = 0\n$$</div>\n\n<p>$x \\le 0$: </p>\n<div>$$\nk_1 = \\sqrt{2mE/\\hbar^2} > 0\\\\\n\\Psi_1^{\\prime\\prime} + k_1^2 \\Psi_1 = 0\n$$</div>\n\n<p>$x \\gt 0$:</p>\n<div>$$\nik_2 = \\sqrt{2m(E - U_0)/\\hbar^2} (k_2 > 0)\\\\\n\\Psi_2^{\\prime\\prime} + (ik_2)^2\\Psi_2 = 0\n$$</div>\n\n<p>通解（利用了$x\\rightarrow\\infty$时$\\Psi_2$的有界性）：</p>\n<div>$$\n\\Psi_1(x) = Ae^{ik_1x} + Be^{-k_1x}(表现为入射和反射波)\\\\\n\\Psi_2(x) = Ce^{k_2x}(表现为透射波)\n$$</div>\n\n<p>粒子可以出现在势垒区！表现为电子溢出金属表面，形成金属表面的一层电子气。</p>\n<p>势垒区的概率密度：$|\\Psi_2(x)|\\propto e^{-\\frac{2x}{\\hbar}\\sqrt{U_0 - E}}$</p>\n<p>波可以穿过有限宽势垒，以平面波的形式继续前进。称为量子隧穿效应。<br>$\\Psi_3(x) &#x3D; Se^{i\\frac {\\sqrt{2mE}}{\\hbar} x}$</p>\n<p>扫描隧道显微镜：原理是量子隧穿效应，可以用来观测物质表面结构。</p>\n<p><img src=\"/../images/physics/STM.jpg\" loading=\"lazy\"></p>\n<div>$$\ni \\propto Ue^{-C\\sqrt{\\varPhi}d}\n$$</div>\n\n<p>$\\varPhi$为样品表面平均势垒高度。</p>\n<h2 id=\"一维谐振子\"><a href=\"#一维谐振子\" class=\"headerlink\" title=\"一维谐振子\"></a>一维谐振子</h2><div>$$\nU(x) = \\frac 12 kx^2 = \\frac 12m\\omega^2x^2, \\omega = \\sqrt{\\frac km}\n$$</div>\n\n<p>求解定态薛定谔方程得到</p>\n<div>$$\nE_n = (n + \\frac 12)\\hbar \\omega = (n + \\frac 12)h\\nu\n$$</div>\n零点能：$\\frac{h\\nu}{2}$。间距：$h\\nu$。能量本征函数不用记。\n\n<p>定态概率密度：</p>\n<p>经典情况下：平衡位置处$\\vec v$最大，停留时间最短，出现概率最小，振幅最大的时候$\\vec v$为0，出现概率最大。量子数n趋于无穷时，量子概率分布趋于经典概率分布。</p>\n<p>如果$E&lt; U$，隧穿效应仍然存在。</p>\n<h2 id=\"力学量算符\"><a href=\"#力学量算符\" class=\"headerlink\" title=\"力学量算符\"></a>力学量算符</h2><p>以位矢$\\vec r$为自变量的空间，称为“坐标表象”。在坐标表象中，动量和位矢不存在对应关系$\\vec p &#x3D; \\vec p(\\vec r)$（不确定关系）。</p>\n<p>量子力学将动量、角动量、能量等力学量“算符化”。力学量算符是量子力学的一个基本假设。</p>\n<h3 id=\"力学量算符的引入\"><a href=\"#力学量算符的引入\" class=\"headerlink\" title=\"力学量算符的引入\"></a>力学量算符的引入</h3><p>定义能量算符$\\hat {E} \\equiv i\\hbar \\frac{\\partial}{\\partial t}$，与表象无关。</p>\n<p>坐标表象中定义动量算符$\\hat{\\vec p} &#x3D; -i\\hbar\\nabla$，坐标算符$\\hat{\\vec r} &#x3D; r$。</p>\n<p>由于坐标表象下坐标算符就是坐标，因此势能算符$\\hat{U} &#x3D; U(\\vec r)$。动能算符$\\hat{E_k} &#x3D; \\frac{(-i\\hbar\\nabla)\\cdot (-i\\hbar\\nabla)}{2m} &#x3D; -\\frac{\\hbar^2}{2m}\\nabla^2$</p>\n<p>角动量算符$\\hat{\\vec L} &#x3D; \\hat{\\vec r}\\times \\hat{\\vec p} &#x3D; -i\\hbar\\vec r \\times \\nabla$。如果用球极坐标，可得$\\hat{L_z} &#x3D; -i\\hbar \\frac{\\partial}{\\partial \\varphi}$。角动量算符的模方由极角和方位角的导数组成：$\\hat{L}^2 &#x3D; -\\frac {\\hbar^2}{\\sin \\theta}\\frac{\\partial}{\\partial \\theta}(\\sin \\theta\\frac{\\partial}{\\partial \\theta})  +\\frac{\\hat{L_z^2}}{\\sin^2\\theta}$</p>\n<h3 id=\"本征值和本征函数\"><a href=\"#本征值和本征函数\" class=\"headerlink\" title=\"本征值和本征函数\"></a>本征值和本征函数</h3><p>本征方程：$\\hat{A}\\Psi_n &#x3D; A_n\\Psi_n$。其中$A_n$为本征值，$\\Psi_n$是$A$取$A_n$时的本征态，称为本征函数。</p>\n<p>本征值就是相应力学量的可能取值。</p>\n<p>$\\hat A$的本征函数系${\\Psi_n}$构成正交、归一的完备函数系。一维情况的归一化：$\\int_{-\\infty}^{+\\infty}\\Psi_n^*(x)\\Psi_n(x)\\mathrm dx &#x3D; 1$。正交性：$\\int_{-\\infty}^{+\\infty}\\Psi_m(x)\\Psi_n(x)\\mathrm d x &#x3D; \\delta_{mn}$.</p>\n<p>本征函数的完备性：在相同的函数空间内，任一物理上合理的归一化波函数，都可以由力学量A的本征函数系线性展开，即$\\Psi &#x3D; \\sum_{n}C_n(t)\\Psi_n(x)$。</p>\n<h3 id=\"态叠加原理：\"><a href=\"#态叠加原理：\" class=\"headerlink\" title=\"态叠加原理：\"></a>态叠加原理：</h3><p>线性展开公式：</p>\n<div>$$\n\\Psi(x, t) = \\sum_{n }C_n(t)\\Psi_n(x) \\ (假设是归一化的)\n$$</div>\n\n<p>基本假设之一。</p>\n<h3 id=\"力学量的测量原理\"><a href=\"#力学量的测量原理\" class=\"headerlink\" title=\"力学量的测量原理\"></a>力学量的测量原理</h3><p>量子力学假设：在$\\Psi(x,t)$态上测量$A$，则$\\Psi(x, t)$一定向着$A$的某个本征态$\\Psi_n$塌缩，测量结果为$A_n$。</p>\n<p>特别地，如果$\\Psi &#x3D; \\Psi_n$，则测量结果是确定的，为$A_n$。</p>\n<p>测量结果中$A_n$出现的概率为$|C_n(t)|^2$。</p>\n<div>$$\n\\bar A = \\sum_n |C_n(t)|^2A_n = \\int_{-\\infty}^{+\\infty}\\Psi^*(x, t)\\hat A\\Psi(x, t)\\mathrm dx\n$$</div>\n\n\n<h2 id=\"Dirac符号\"><a href=\"#Dirac符号\" class=\"headerlink\" title=\"Dirac符号\"></a>Dirac符号</h2><h3 id=\"量子态\"><a href=\"#量子态\" class=\"headerlink\" title=\"量子态\"></a>量子态</h3><p>本征值离散的：$\\ket{n}$</p>\n<p>本征值是连续的：$\\ket{P_x}, \\ket{x}$</p>\n<p>它们各自张开一个线性空间。</p>\n<h3 id=\"内积空间\"><a href=\"#内积空间\" class=\"headerlink\" title=\"内积空间\"></a>内积空间</h3><p>左矢与右矢一一对应，左矢张开一个共轭线性空间。</p>\n<p>$\\ket{A}$和$\\ket{B}$的内积(复内积)：$\\langle B|A\\rangle$</p>\n<p>左矢空间与右矢空间通过复内积练习，称为内积空间。</p>\n<h3 id=\"线性算符\"><a href=\"#线性算符\" class=\"headerlink\" title=\"线性算符\"></a>线性算符</h3><div>$$\n\\hat{L}\\ket{A} = \\ket{B}\n$$</div>\n\n<p>满足：</p>\n<ul>\n<li><p>$\\hat L (\\ket{A} + \\ket {B}) &#x3D; \\hat L\\ket{A} + \\hat L\\ket{B}$</p>\n</li>\n<li><p>$(\\hat F + \\hat G)\\ket{A} &#x3D; \\hat F \\ket{A} + \\hat G\\ket{A}$</p>\n</li>\n<li><p>$\\hat F(\\hat G \\ket{A}) &#x3D; (\\hat F \\cdot \\hat G)\\ket {A}$</p>\n</li>\n</ul>\n<p>共轭算符：$\\bra{A}\\bar{\\hat L}$与$\\hat L \\ket{A}$一一对应，将$\\bar{\\hat L}$或者$\\hat L ^+$称为共轭算符。</p>\n<p>厄米算符：$\\bar {\\hat L} &#x3D; \\hat L$。</p>\n<p>算符是向右结合的。</p>\n<h3 id=\"算符本征方程\"><a href=\"#算符本征方程\" class=\"headerlink\" title=\"算符本征方程\"></a>算符本征方程</h3><div>$$\n\\hat L \\ket{L_n} = l_n\\ket{L_n}\\\\\n\n<p>\\hat L\\ket{n} &#x3D; l_n\\ket{n}<br>$$</div></p>\n<p>$l_n$是本征值，$L_n$是本征态。</p>\n<p>由测量原理，本征值必须是实数。所以可以观测的力学量对应的算符都是厄米算符。</p>\n<h3 id=\"态叠加原理\"><a href=\"#态叠加原理\" class=\"headerlink\" title=\"态叠加原理\"></a>态叠加原理</h3><p>离散谱：</p>\n<div>$$\n\\bra{m}n\\rangle = \\delta_{mn}\\\\\n\\ket{\\psi} = \\sum_n C_n\\ket{n}\\\\\n概率幅：\\bra{m}\\psi \\rangle = C_m\\\\\n\\ket{A} = \\sum_{n}(\\bra{n}A\\rangle)\\ket{n} = \\left(\\sum_n \\ket{n}\\bra{n}\\right)\\ket{A}\\\\\n\\Rightarrow \\sum_n \\ket{n}\\bra{n}=1(本征矢的完备性表示)\n$$</div>\n\n<p>连续谱：</p>\n<div>$$\n\\bra{x_0^\\prime}x_0\\rangle = \\delta(x_0^\\prime - x_0)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}C(x_0)\\ket{x_0}\\mathrm dx_0 \\\\\n概率幅：\\bra{x_0^\\prime}\\psi\\rangle = C(x_0^\\prime)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}\\bra{x_0}\\psi\\rangle\\ket{x_0}\\mathrm dx_0 = \\left(\\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0\\right)\\ket{\\psi}\\\\\n\\Rightarrow \\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0 = 1(连续谱的完备性方程)\n$$</div>\n\n<p>注：$C(x_0) &#x3D; \\bra{x_0}\\psi\\rangle$就是波函数$\\psi(x_0)$。$|\\bra{x_0}\\psi\\rangle|^2 &#x3D; |\\psi(x_0)|^2 &#x3D; \\psi^*(x_0)\\psi(x_0)$是概率密度。</p>\n<h3 id=\"正则量子化假设\"><a href=\"#正则量子化假设\" class=\"headerlink\" title=\"正则量子化假设\"></a>正则量子化假设</h3><p>对易关系：$[\\hat A, \\hat B]&#x3D; \\hat A\\hat B - \\hat B\\hat A$，若$[\\hat A , \\hat B]&#x3D;0$，则称$A$与$B$对易，否则称不对易。</p>\n<p>正则量子化假设：</p>\n<div>$$\n[\\hat{x}, \\hat{p_x}] = i\\hbar,\n[\\hat{y}, \\hat{p_y}] = i\\hbar, \n[\\hat{z}, \\hat{p_z}] = i\\hbar\n$$</div>\n\n<p>其余$x, y, z, p_x, p_y, p_z$的组合均对易。</p>\n<p>满足$\\hat{\\vec A}\\times \\hat{\\vec A} &#x3D; i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L &#x3D; \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。</p>\n<p>$\\hat A$和$\\hat B$可以同时测准的充分必要条件：</p>\n<div>$$\n[\\hat A, \\hat{B}] = 0\\Leftrightarrow 有共同本征态\n$$</div>\n\n<p>简并：1个本征值对应m个量子态,称为m重简并。</p>\n<p>产生简并的原因：对称性&#x3D;&gt;守恒量。</p>\n<p>如果$\\hat A$是m重简并的，只测量得到本征值A，无法确定对应的量子态。但是如果同时测量对易的$\\hat B$，就可以确定对应的$|A, B_i\\rangle$，则对应的A的量子态是$|A_i\\rangle$。</p>\n<p>力学量完全集：能完备描述、确定量子态的力学量算符必须包含$\\hat H$。</p>\n<p>$\\hat H$是核心力学量。</p>\n<div>$$\n[\\hat A, \\hat H]=0\\Leftrightarrow \\hat A是守恒量\n$$</div>\n选择力学量的完全集，就是选择守恒量的完全集。\n\n<h2 id=\"原子中的电子\"><a href=\"#原子中的电子\" class=\"headerlink\" title=\"原子中的电子\"></a>原子中的电子</h2><h3 id=\"氢原子理论\"><a href=\"#氢原子理论\" class=\"headerlink\" title=\"氢原子理论\"></a>氢原子理论</h3><p>巴耳末公式-&gt;里德伯方程-&gt;波尔氢原子理论</p>\n<p>氢原子理论：</p>\n<p>定态条件</p>\n<p>电子绕核作圆周运动，有确定能量，不辐射能量-经典轨道+定态</p>\n<p>频率条件</p>\n<p>电子在定态之间跃迁满足：$\\nu &#x3D; (E_i - E_f)&#x2F;h$</p>\n<p>轨道角动量：$L_n &#x3D; mv_nr_n &#x3D; n\\hbar$，轨道半径$r_n &#x3D; n^2r_1$</p>\n<p>能级公式：$E_n &#x3D; -13.6eV&#x2F;n^2$</p>\n<p>类氢离子能级：核外只有一个电子，核电荷数大于1.例如$He^+, Li^{2+}$</p>\n<p>评价：</p>\n<p>波尔理论解释了氢原子和类氢离子光谱的波长和频率。</p>\n<p>但是不能解释氢原子的光谱线强度，也不能解释其他原子的光谱结构。</p>\n<ul>\n<li>与经典电磁理论矛盾</li>\n<li>角动量量子化条件是硬加的</li>\n<li>卢瑟福的质疑：电子知道要往$E_2$跳才能往$E_2$跳，但是又必须先跳过去才能知道要往$E_2$跳</li>\n<li>薛定谔的非难：当电子离开$E_1$态之后，进入$E_2$态之前，它在哪里，是什么状态？</li>\n</ul>\n<p>轨道概念不再适用。定态、能级、跃迁频率条件、角动量量子化仍然被认为是正确的。</p>\n<h3 id=\"氢原子的量子力学处理\"><a href=\"#氢原子的量子力学处理\" class=\"headerlink\" title=\"氢原子的量子力学处理\"></a>氢原子的量子力学处理</h3><p>求解量子问题的要点之一：确定体系的力学量完全集，即力学量可以同时测准，具有共同本征态，相应量子数集可完备地描述体系状态。</p>\n<p>通常选择守恒量完全集，和体系对称性有关。</p>\n<p>氢原子问题的守恒量完全集：$\\hat H, \\hat L^2, \\hat L_z$</p>\n<p><strong>角动量量子化：</strong></p>\n<p>处于中心力场的氢原子电子，角动量守恒。</p>\n<p>求$\\hat  L_z$的本征值：</p>\n<div>$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\\\\\n\n<p>\\hat L_z \\varPhi &#x3D; L_z \\varPhi\\Rightarrow \\varPhi &#x3D; Ae^{\\frac{i}{\\hbar}L_z\\varphi}<br>$$</div></p>\n<p>根据标准条件（周期性），$\\varPhi(\\varphi) &#x3D; \\varPhi(\\varphi + 2\\pi)$，带入解得$L_z &#x3D; m_l\\hbar$，$m_l &#x3D; 0, \\pm1, \\pm2,\\dots$称为磁量子数。</p>\n<p>对应的本征函数：$\\varPhi_{m_l}(\\varphi) &#x3D; Ae^{im_l\\varPhi} &#x3D; \\frac{1}{\\sqrt{2\\pi}}e^{im_l\\varphi}$</p>\n<p>求$\\hat L^2$的本征值：</p>\n<p>结论：$L^2 &#x3D; l(l+1)\\hbar^2$，$l &#x3D; 0, 1, 2, \\dots$称为角量子数。</p>\n<p>（$\\hat L^2$和$\\hat L_z$具有的共同本征值为球谐函数$Y_{ml}(\\theta, \\varphi)$）</p>\n<p>角动量的空间量子化</p>\n<p>$L &#x3D; \\sqrt{l(l+1)}\\hbar &gt; L_z &#x3D; m_l\\hbar \\Rightarrow m_l &#x3D; 0, \\pm1, \\pm2,\\dots, \\pm l$。作矢量图可知，角动量有$2l+1$种取向。</p>\n<p><strong>能量量子化</strong></p>\n<p>(省略公式)</p>\n<p>$l &#x3D; 0, 1, \\dots, n - 1$</p>\n<p>$\\hat H, \\hat L^2, \\hat L_z$的共同本征态就是定态。</p>\n<p>能量的本征值只与主量子数n有关，因而出现了能量简并，不同的角量子数和磁量子数可以对应相同的能量本征值。同能量的本征值态称为能级简并态，包含的态数目称为能级简并度。</p>\n<p>角量子数$l &#x3D; 0, 1, 2…$对应的状态分别称为$s, p, d…$，从概率波图像可以看出，角量子数低的电子更容易靠近原子中心。</p>\n<h3 id=\"电子自旋\"><a href=\"#电子自旋\" class=\"headerlink\" title=\"电子自旋\"></a>电子自旋</h3><p>轨道角动量产生磁矩：</p>\n<div>$$\n\\hat{\\vec \\mu} = -\\frac{e}{2m_e}\\hat{\\vec L}\n$$</div>\n\n<p>玻尔磁子：</p>\n<div>$$\n\\mu_B = \\frac{e\\hbar}{2m_e}\n$$</div>\n\n<p>利用本征值的定义不难推出z方向的磁矩：</p>\n<div>$$\n\\mu_z = -m_l \\cdot \\mu_B\n$$</div>\n\n<p>斯特恩-盖拉赫实验</p>\n<p>理论分析：</p>\n<p>磁矩在外磁场中有势能：$E &#x3D; -\\vec \\mu \\cdot \\vec B$</p>\n<p>轨道磁矩在z方向受力：</p>\n<div>$$\nF_z = \\frac{\\partial E}{\\partial z} = \\mu_z\\frac{\\partial B_z}{\\partial z} = -m_l\\mu_B\\frac{\\partial B_z}{\\partial z}\n$$</div>\n\n<p>由于$m_l$的$2l+1$种取值，对应的原子束应该在z方向上分裂成奇数条线。</p>\n<p><img src=\"/source/images/physics/abaaba.jpg\" loading=\"lazy\"></p>\n<p>问题：$Ag, H$等原子束($l &#x3D; 0$)出现了2条线而不是一条线，矛盾。</p>\n<p>电子自旋的假设：</p>\n<ul>\n<li>电子不是质点，而是自旋的小球，具有固有的自旋角动量$\\vec S$和自旋磁矩$\\vec \\mu_S$</li>\n<li>$S &#x3D; \\sqrt{s(s+1)}\\hbar$，其中$s &#x3D; \\frac 12$称为自旋量子数</li>\n<li>$S_z &#x3D; m_s\\hbar$，$m_s &#x3D; \\pm\\frac 12$，称为自旋磁量子数</li>\n<li>自旋磁矩和自旋角动量满足$\\hat {\\vec \\mu_S} &#x3D; -\\frac{e}{m_e}\\hat {\\vec S}$，进而推出$\\mu_{S,z}&#x3D;\\pm \\mu_B$</li>\n</ul>\n<p>“自转小球”模型仍存在缺陷：电子表面的速度会超过光速。</p>\n<p>但是这些假设成功解释了原子光谱的精细结构和反常塞曼效应。</p>\n<p>量子力学的解释：</p>\n<ul>\n<li>自旋是与时空无关的内禀运动，一种新的自由度，一种新的角动量，无经典对应</li>\n<li>自旋、磁矩和静止质量、电荷一样，是反映微观粒子固有属性的基本量</li>\n<li>电子的自旋是一种相对论效应，被自动地包含在相对论波动方程(Dirac方程)中。</li>\n</ul>\n<p>电子的总角动量：</p>\n<div>$$\n\\hat {\\vec J} = \\hat {\\vec L} + \\hat {\\vec S}\n$$</div>\n\n<p>$\\hat {\\vec J}$也是量子化的，大小为：</p>\n<div>$$\nJ = \\sqrt{j(j + 1)}\\hbar\n$$</div>\n\n<p>前文已说过如下定义：</p>\n<blockquote>\n<p>满足$\\hat{\\vec A}\\times \\hat{\\vec A} &#x3D; i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L &#x3D; \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。</p>\n</blockquote>\n<p>可以验证$\\hat {\\vec J }\\times \\hat {\\vec J } &#x3D; i\\hbar \\hat {\\vec J }$。因此总角动量还是角动量。</p>\n<p>这一角动量的合成被称为自旋——轨道耦合。$j$称为总角动量量子数。</p>\n<div>$$\nl = 0: \n\\\\\nj = s = \\frac 12, m_j = -\\frac 12, +\\frac 12\\\\\nl \\ne 0:\\\\\nj = l + s = l + \\frac 12, m_j = -(l + \\frac 12), \\dots, l + \\frac 12;\\\\\nj = l - s = l - \\frac 12, m_j = -(l - \\frac12), \\dots, l - \\frac12\n$$</div>\n\n<p>碱金属原子光谱：</p>\n<p>碱金属的原子能级既和$n$有关，又和$l$有关。</p>\n<p>轨道角动量对原子的影响包括轨道贯穿和原子实极化，导致相应能级能量降低。</p>\n<p>因此原来相同能级的$3s,3p,…$会分裂成不同能级的轨道。</p>\n<p>碱金属原子光谱的精细结构：</p>\n<p>电子的轨道运动会使得它感受到原子绕它转动的磁场$\\vec B_{Nuc}$的作用。</p>\n<p>电子自旋磁矩$\\vec \\mu_s$和$\\vec B_{Nuc}$的相互作用就是自旋轨道耦合，是相对论效应。</p>\n<p>于是能级在自旋轨道耦合的影响下进一步分裂，形成了能级精细结构。</p>\n<h3 id=\"微观粒子全同性原理\"><a href=\"#微观粒子全同性原理\" class=\"headerlink\" title=\"微观粒子全同性原理\"></a>微观粒子全同性原理</h3><p>两个微观粒子的全部内禀属性相同称为全同粒子。对调全同粒子不会影响系统的状态。</p>\n<p>数学上对应地表现为波函数模方相同，进而有波函数对称或者反对称。</p>\n<p>对称的波函数表达式：</p>\n<div>$$\n\\psi(q_1, q_2) = \\frac {1}{\\sqrt 2}[\\phi_A(q_1)\\phi_B(q_2) + \\phi_A(q_2)\\phi_B(q_1)]\n$$</div>\n\n<p>反对称的波函数表达式：</p>\n<div>$$\n\\psi(q_1, q_2) = \\frac{1}{\\sqrt{2}}[\\phi_A(q_1)\\phi_B(q_2) - \\phi_A(q_2)\\phi_B(q_1)]\n$$</div>\n\n<p>如果$\\phi_A&#x3D;\\phi_B$，则反对称波函数为0。</p>\n<p>费米子是自旋为半整数的粒子。它是波函数反对称的粒子。由此得到泡利不相容原理：全同费米子系统不能有两个及以上的费米子占据同一单粒子态。</p>\n<p>玻色子是自旋为0或者整数的粒子。它是波函数对称的粒子。玻色子不受泡利不相容原理的限制。</p>\n<p>费米统计：</p>\n<div>$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} + 1}\n$$</div>\n\n<p>$\\mu &#x3D; \\mu(T)$是粒子化学势。</p>\n<p>玻色统计：</p>\n<div>$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} - 1}\n$$</div>\n\n<p>对所有温度T,$0\\le N(E)\\lt \\infty$。</p>\n<p>玻色-爱因斯坦凝聚。</p>\n<p>当$E$很高时，$(E - \\mu) &gt;&gt; kT$。退化为麦克斯韦-玻尔兹曼统计。</p>\n<h3 id=\"原子核外电子的排布\"><a href=\"#原子核外电子的排布\" class=\"headerlink\" title=\"原子核外电子的排布\"></a>原子核外电子的排布</h3><p>4个量子数$n,l,m_l,m_s$可以完备描述原子的电子运动状态。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"参考教材\"><a href=\"#参考教材\" class=\"headerlink\" title=\"参考教材\"></a>参考教材</h1><p>嫌教材太简单可以看看</p>\n<p>《热学》lhf例题很多，很详细，很多数学比教材难</p>\n<p>《》</p>\n<p>《新概念物理教程-力学》新颖，比较硬核。</p>\n<p>《费恩曼物理学讲义》</p>\n<p>《新概念物理教程-光学》公认最好教材</p>\n<p>《光学》chb, lyp</p>\n<p>量子物理没有太好的参考书。</p>\n<p>《原子物理学》杨福家编。现在没有原子物理了，只有量子物理。有时用经典方法，有时候用量子物理的方法。前几章和教材一致，实验讲得不错。</p>\n<p>量子力学教程。周世勋。内容有点少。</p>\n<p>《费恩曼物理学讲义》第3卷。相当有深度（量子物理）。</p>\n<p><em>Phyisics</em> Vol.1 &amp; 2。难度介于大学物理学和物理系教材之间。</p>\n<h3 id=\"杂项\"><a href=\"#杂项\" class=\"headerlink\" title=\"杂项\"></a>杂项</h3><p>牛顿运动方程一般个数少，微分阶数高；哈密顿正则方程一般个数多，微分阶数低。</p>\n<h1 id=\"热学\"><a href=\"#热学\" class=\"headerlink\" title=\"热学\"></a>热学</h1><h2 id=\"温度\"><a href=\"#温度\" class=\"headerlink\" title=\"温度\"></a>温度</h2><p>分子动理论：热学中比较古老的理论。</p>\n<p>教材中关于统计物理的内容不够透彻。</p>\n<p>建议学习分析力学（重点：哈密顿力学），对后续量子力学有帮助。固体物理也会使用相关技巧。哈密顿量，相空间，拉格朗日方程。不用看证明，能用就行。</p>\n<h3 id=\"热学研究内容与对象\"><a href=\"#热学研究内容与对象\" class=\"headerlink\" title=\"热学研究内容与对象\"></a>热学研究内容与对象</h3><p>内容：与热现象有关的性质和规律。</p>\n<p>热现象：宏观上与温度有关，微观上与分子热运动有关。</p>\n<p>对象：大量微观粒子构成的体积有限的物体-热力学系统。（量大：统计学规律。）</p>\n<p>经常讨论系统和外界（环境）。一种说法：宇宙是不是热力学系统？不是，因为宇宙之外没有外界。所以热二定律可能不适用于整个宇宙。</p>\n<p>孤立系统：与外界没有任何相互作用。</p>\n<p>绝热系统：有功的交换，没有热量交换</p>\n<p>封闭系统：有能量交换，无粒子交换</p>\n<p>开放系统：既有能量交换，也有粒子交换</p>\n<h3 id=\"热力学的研究方法\"><a href=\"#热力学的研究方法\" class=\"headerlink\" title=\"热力学的研究方法\"></a>热力学的研究方法</h3><h4 id=\"热力学\"><a href=\"#热力学\" class=\"headerlink\" title=\"热力学\"></a>热力学</h4><p>宏观理论方法。依赖于实验。不涉及物质的微观结构和微观运动规律。具有极大的普遍性，可靠性。</p>\n<h4 id=\"统计物理学\"><a href=\"#统计物理学\" class=\"headerlink\" title=\"统计物理学\"></a>统计物理学</h4><p>微观理论方法。从微观模型假设出发，力学 + 统计理论建立微观量和宏观量的关系。可解释本质，但是受模型局限。</p>\n<h3 id=\"几个重要概念\"><a href=\"#几个重要概念\" class=\"headerlink\" title=\"几个重要概念\"></a>几个重要概念</h3><h4 id=\"平衡态\"><a href=\"#平衡态\" class=\"headerlink\" title=\"平衡态\"></a>平衡态</h4><p>热力学系统内部，宏观上不存在能量和粒子的流动，系统宏观性质不随时间变化。（体积、压强、温度）</p>\n<p>热力学平衡条件：</p>\n<p>力学平衡条件：若系统与外界有力学作用，平衡时内外压强相等。</p>\n<p>热平衡条件：若系统与外界可交换热量，平衡时内外温度应相等。</p>\n<p>相平衡条件：若系统与外界处于不同相的共存状态，平衡时要达到力学平衡、热平衡以及相平衡。</p>\n<p>化学平衡条件：浓度不同的系统混到一起，平衡时要满足上面三个条件，并且浓度均匀。</p>\n<p>注意区分平衡态和稳定态：</p>\n<p>![..&#x2F;images&#x2F;pht.png]</p>\n<h4 id=\"宏观量\"><a href=\"#宏观量\" class=\"headerlink\" title=\"宏观量\"></a>宏观量</h4><p>描述系统宏观性质的量。可直接测量。</p>\n<p>广延量：有累加性。如M, V, E…</p>\n<p>强度量：无累加性。如p, T…</p>\n<h4 id=\"微观量\"><a href=\"#微观量\" class=\"headerlink\" title=\"微观量\"></a>微观量</h4><p>描述微观粒子性质的量。需要间接测量。</p>\n<p>如分子的m, v, d…</p>\n<h4 id=\"状态参量\"><a href=\"#状态参量\" class=\"headerlink\" title=\"状态参量\"></a>状态参量</h4><p>描述系统平衡态及其宏观性质的物理量。</p>\n<p>p, V, T, v, 内能E, 熵S, 焓H</p>\n<p>一组态参量对应一个平衡态。</p>\n<p>实验表明：状态参量之间不是相互独立的。</p>\n<p>常选p, V, T作为自变量，其他的当作函数（E, S, H）-热力学函数。</p>\n<p>对物质量确定的单元（单一组元，不能由多种物质混合）单相（同一种状态，不能有固液同时存在等等）系统，p, V, T只有两个是独立的：T(p, V), E(p, V)。</p>\n<p>统计物理：状态参量之间的偏导数关系。</p>\n<h4 id=\"物态方程\"><a href=\"#物态方程\" class=\"headerlink\" title=\"物态方程\"></a>物态方程</h4><p>两个最基本的热力学函数之一（物态方程和内能）。态参量之间的函数关系: f(T, p, V) &#x3D; 0</p>\n<p>通过测量确定。</p>\n<p>理想气体物态方程：</p>\n<p>$pV &#x3D; νRT$</p>\n<p>$p &#x3D; nkT$</p>\n<p>$k &#x3D; \\frac{R}{N_A}$</p>\n<p>$\\nu$ 气体摩尔数</p>\n<p>$k$ 玻尔兹曼常量</p>\n<h3 id=\"温度-1\"><a href=\"#温度-1\" class=\"headerlink\" title=\"温度\"></a>温度</h3><h4 id=\"热平衡态\"><a href=\"#热平衡态\" class=\"headerlink\" title=\"热平衡态\"></a>热平衡态</h4><p>两个系统长时间热接触达到的共同平衡态。</p>\n<h4 id=\"热力学第零定律\"><a href=\"#热力学第零定律\" class=\"headerlink\" title=\"热力学第零定律\"></a>热力学第零定律</h4><p>实验表明： A与C热平衡，B与C热平衡，A和B也必然保持热平衡。</p>\n<p>非热接触的两个系统也可以处在同一个热平衡态。</p>\n<p>温度：处于同一热平衡态下的热力学系统所具有的共同的宏观性质。</p>\n<p>处在同一热平衡态的系统具有相同的温度。</p>\n<h4 id=\"温标\"><a href=\"#温标\" class=\"headerlink\" title=\"温标\"></a>温标</h4><p>理想气体温标；用理想气体做测温物质。单位: $K$(Kelvin)， 范围适用 $&gt; 0.5K$</p>\n<p>实验表明：一定质量的理想气体在同一个热平衡态下，$pV$不变。</p>\n<p>规定$T \\propto pV$，水的三相点温度为$T_3 &#x3D; 273.16K$</p>\n<div>$$T = T_3\\frac{pV}{p_3V_3} = 273.16\\frac{pV}{p_3V_3}$$</div>\n\n<p>热力学温标$T$：理论温标，与物质无关。</p>\n<p>单位: $K$，适用于所有温度范围，在理想气体温标范围内与理气温标一致。</p>\n<h3 id=\"统计物理学的观点、概念简介\"><a href=\"#统计物理学的观点、概念简介\" class=\"headerlink\" title=\"统计物理学的观点、概念简介\"></a>统计物理学的观点、概念简介</h3><p>统计物理学包括平衡态统计理论，非平衡态统计理论和涨落理论。它从物质的微观结构和微观运动来阐明物质的宏观性质。其基本观点：</p>\n<ul>\n<li>宏观物体由大量的微观粒子（原子、分子、电子、光子等）构成。</li>\n<li>微观粒子的运动服从力学规律。原则上说服从量子力学规律，一定条件下可以用经典力学处理。</li>\n<li>从微观角度看，物体以一定的概率出现在各个微观状态上，物质的宏观性质就是物质微观性质的统计平均。宏观量是有关微观量的统计平均值。</li>\n</ul>\n<h4 id=\"近独立子系统\"><a href=\"#近独立子系统\" class=\"headerlink\" title=\"近独立子系统\"></a>近独立子系统</h4><p>构成系统的粒子间相互作用很弱，系统能量近似等于各粒子能量总和，如理想气体。</p>\n<h4 id=\"微观状态（力学运动状态）\"><a href=\"#微观状态（力学运动状态）\" class=\"headerlink\" title=\"微观状态（力学运动状态）\"></a>微观状态（力学运动状态）</h4><h5 id=\"经典力学描述\"><a href=\"#经典力学描述\" class=\"headerlink\" title=\"经典力学描述\"></a>经典力学描述</h5><p>常采用正则形式，即广义坐标和广义动量描述。</p>\n<ul>\n<li><p>子相空间（μ空间）：由粒子的广义坐标$q_i$和广义动量$p_i$（$i &#x3D; 1, \\dots, r$, $r$是粒子自由度）构成的2r维空间。</p>\n<p>1组$(q_1, \\dots, q_r, p_1, \\dots, p_r)$的取值表示粒子的1个微观状态，对应于子相空间的一个点。</p>\n<p>更确切的说，在子相空间 $( q_1,… , q_r , p_1,…, p_r )$位置处的体积元 $d q_1…d q_r dp_1…dp_r$中的点，都是由$( q_1,… , q_r , p_1,…, p_r )$描述的相同的粒子微观状态。</p>\n<p>位形空间（坐标构成的空间），速度空间（速度构成的空间）。</p>\n<p>傅里叶变换和傅里叶级数的区别：一个离散，一个连续。</p>\n</li>\n<li><p>系统的微观状态是由所有粒子的广义坐标和广义动量描述的。</p>\n</li>\n</ul>\n<h5 id=\"量子力学描述\"><a href=\"#量子力学描述\" class=\"headerlink\" title=\"量子力学描述\"></a>量子力学描述</h5><p>量子力学中假设运动状态用量子态描述。</p>\n<ul>\n<li><p>粒子的微观状态用单粒子（量子）态描述。</p>\n<p>单粒子态由一组量子数描述：如 $|n, l, m_l, m_s &gt;$ 。 1 组取值确定的$ |n, l, m_l, m_s &gt; $表示 1 个单粒子态。 当粒子状态是由某个单粒子态描述时，称为粒子处于某个单粒子态，或粒子占据某个单粒子态</p>\n</li>\n<li><p>系统微观状态用多粒子（量子）态描述。</p>\n<p>对近独立子系统，多粒子态可由单粒子态表示： 系统所有粒子的 1 组单粒子占据态就表示系统的 1 个 多粒子态，即表示系统的 1 个 微观状态。</p>\n</li>\n</ul>\n<p>微观粒子全同性原理</p>\n<p>全同粒子：内禀属性如质量、电荷、自旋等相同 </p>\n<p>微观粒子全同性原理是量子力学假设。 </p>\n<p>全同性原理：对全同粒子组成的系统，交换任意 2个全同粒子，系统微观状态不变。</p>\n<p>泡利不相容原理：对全同费米子系统，不能有两个及以上的费米子占据同一单粒子态。</p>\n<p>费米子：自旋为半整数；玻色子：自旋为整数。</p>\n<h4 id=\"宏观状态和微观状态的关系\"><a href=\"#宏观状态和微观状态的关系\" class=\"headerlink\" title=\"宏观状态和微观状态的关系\"></a>宏观状态和微观状态的关系</h4><p>系统的宏观状态由宏观量表征，如 E、N、V。 </p>\n<p>系统的微观状态，如果用经典描述，则由所有粒子 的坐标和动量表征。 </p>\n<p>玻耳兹曼认为：从微观上看，对于一个系统的状态 的宏观描述是非常不完善的，系统的同一个宏观状 态实际上可能对应于非常非常多的微观状态，而这 些微观状态是粗略的宏观描述所不能加以区别的。</p>\n<p> 这意味着宏观状态和微观状态、宏观量和微观量具 有内在联系，这种联系是种统计关系。</p>\n<h4 id=\"统计规律性\"><a href=\"#统计规律性\" class=\"headerlink\" title=\"统计规律性\"></a>统计规律性</h4><p>统计物理发展早期，人们普遍认为：研究物体宏观 性质，应从求解粒子的力学运动方程出发来解决。 但由于粒子数太多，求解力学方程困难，迫不得已 得引入统计方法。而且这个统计是：宏观量是相应 微观量的长时间平均。 即原则上力学规律可完全决定物体宏观性质  </p>\n<p>这种观点无法解释根本问题：热现象的不可逆性。 因为把力学运动方程（牛顿方程或薛定谔方程）用 到微观粒子，是时间反演对称的 — 可逆的。</p>\n<p>这表明仅通过力学规律来解释物体的宏观性质是 不可能的，而有赖于新的规律 — 统计规律。</p>\n<p>力学规律是决定论性的，可表述为：在一定初始 条件下，某时刻系统必然处于一确定的运动状态。 </p>\n<p>统计规律可以表述为：在一定的宏观条件下，某 时刻系统以一定的概率处于某一微观状态。 </p>\n<p>即宏观状态与微观状态之间的联系是概率性的， 具有统计规律的特性，而不是决定论性的。</p>\n<p>统计规律的稳定性：只要 N 足够大，每次得到的分布几乎相同</p>\n<p>统计规律的涨落：每次实验中得到的比例 Ni &#x2F;N 稍有差别。N 越大，涨落越小。</p>\n<p>即对变量是离散取值的情况，直接采用概率， 对变量是连续取值的情况，需要引入概率密度。</p>\n<p>热现象本质是统计规律的反映。</p>\n<h5 id=\"平衡态统计理论的基本假设：等概率原理\"><a href=\"#平衡态统计理论的基本假设：等概率原理\" class=\"headerlink\" title=\"平衡态统计理论的基本假设：等概率原理\"></a>平衡态统计理论的基本假设：等概率原理</h5><p>处于平衡态下的孤立系统，系统各个可能的微观 状态出现的概率相等。 “可能的微观状态”是指孤立系统的宏观条件所 允许的那些微观状态，即这些微观状态对应于给 定的 E、V、N</p>\n<h5 id=\"平衡态下近独立子系统的统计规律\"><a href=\"#平衡态下近独立子系统的统计规律\" class=\"headerlink\" title=\"平衡态下近独立子系统的统计规律\"></a>平衡态下近独立子系统的统计规律</h5><p>处于平衡态下的热力学系统，宏观状态不变，但 相应的微观状态不断变化，是一种动态平衡。 根据等概率原理，平衡态包含的微观状态数目是 最多的 — 最概然态</p>\n<p>求统计分布函数：对于每个统计分布函数，可以计算它们对应的微观态数目（微观态数目是统计分布函数的函数）。在E, N不变的条件下，只要找到对应微观态数目最多的统计分布函数，就是平衡态的统计分布函数。</p>\n<p>对近独立子系统，采用经典力学及等概率原理只能得到一种经典统计：麦克斯韦-玻尔兹曼统计；采用量子力学及等概率原理得到3种统计：麦克斯韦-玻尔兹曼统计，费米-狄拉克统计，玻色-爱因斯坦统计。</p>\n<p>造成 3 种量子统计规律的原因是微观粒子的全同性原理和泡利不相容原理。</p>\n<p>麦克斯韦-玻尔兹曼统计适用于定域子系统，费米 - 狄拉克统计、玻色 - 爱因斯坦统计适用于非定域 子系统。</p>\n<p> 定域：全同粒子系统中的粒子的波包局限在空间 一定范围内，之间没有重叠，全同性原理 不起作用，可以通过位置分辨粒子。</p>\n<p> 经典的和量子的麦克斯韦-玻尔兹曼统计在数学形 式上一致。而在一定条件下，量子的 3 种统计都可 退化为经典的麦克斯韦-玻尔兹曼统计</p>\n<h2 id=\"气体动理论\"><a href=\"#气体动理论\" class=\"headerlink\" title=\"气体动理论\"></a>气体动理论</h2><h4 id=\"气体动理论的基本观点\"><a href=\"#气体动理论的基本观点\" class=\"headerlink\" title=\"气体动理论的基本观点\"></a>气体动理论的基本观点</h4><p>气体动理论（分子动理论），发展于 19 世纪下半 期，基于经典理论，是统计物理学的原型，被不断 补充发展完善成为统计物理学，其所得的结论可通 过统计物理得到。至今仍在诸多领域有重要应用。</p>\n<ol>\n<li>宏观物体是由大量分子、原子构成的，分子间 存在一定的间隙。</li>\n<li>分子永不停息地作无规则运动 — 热运动</li>\n<li>分子间存在一定的相互作用。</li>\n</ol>\n<h3 id=\"理想气体的压强\"><a href=\"#理想气体的压强\" class=\"headerlink\" title=\"理想气体的压强\"></a>理想气体的压强</h3><h5 id=\"关于理想气体的假设\"><a href=\"#关于理想气体的假设\" class=\"headerlink\" title=\"关于理想气体的假设\"></a>关于理想气体的假设</h5><h6 id=\"单个分子服从的力学规律\"><a href=\"#单个分子服从的力学规律\" class=\"headerlink\" title=\"单个分子服从的力学规律\"></a>单个分子服从的力学规律</h6><p>理想气体模型：</p>\n<p>大小：分子线度&lt;&lt;分子间平均距离</p>\n<p>分子力：除碰撞的瞬间，在分子间、分子与器壁间无作用力</p>\n<p>碰撞性质：弹性碰撞</p>\n<p>服从规律：牛顿力学</p>\n<h6 id=\"大量分子处于平衡态时的统计假设\"><a href=\"#大量分子处于平衡态时的统计假设\" class=\"headerlink\" title=\"大量分子处于平衡态时的统计假设\"></a>大量分子处于平衡态时的统计假设</h6><p>（1）无外场时，分子在各处出现的概率相同</p>\n<div>$$n = \\frac{\\mathrm d N}{\\mathrm d V} = \\frac NV = \\text{const}.$$</div>\n（2）由于碰撞，分子可以有各种不同速度\n\n<p>速度取向各方向等概率：</p>\n<div>$$\\bar{v_x} = \\bar{v_y} = \\bar{v_z} = 0\\\\\\\\\\bar{v_x^2} = \\bar{v_y^2} = \\bar{v_z^2} = \\frac 13 \\bar{v^2}$$</div>\n\n<h5 id=\"理想气体压强公式\"><a href=\"#理想气体压强公式\" class=\"headerlink\" title=\"理想气体压强公式\"></a>理想气体压强公式</h5><p>前提：平衡态，忽略重力，分子当成质点</p>\n<div>$$p = \\frac13nm\\bar{v^2} = \\frac23n\\bar\\varepsilon_t, \\\\\\\\\\bar\\varepsilon_t = \\frac12 mv^2$$</div>\n\n<h3 id=\"温度的统计意义\"><a href=\"#温度的统计意义\" class=\"headerlink\" title=\"温度的统计意义\"></a>温度的统计意义</h3><div>$$\\bar\\varepsilon_t = \\frac{3p}{2n} = \\frac{3nkT}{2n} = \\frac32kT\\\\\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}{M}}$$</div>\n\n<p>$T &#x3D; 273K$, </p>\n<p>$\\bar{\\varepsilon}_t$数量级：$10^{-2}$eV</p>\n<p>$\\sqrt{\\bar{v^2}}$</p>\n<p>$H_2$: $1.84\\times 10^3m&#x2F;s$</p>\n<p>$O2$: $4.61\\times 10^2m&#x2F;s$</p>\n<h3 id=\"能量均分定理\"><a href=\"#能量均分定理\" class=\"headerlink\" title=\"能量均分定理\"></a>能量均分定理</h3><p>自由度：决定物体空间位置的独立坐标数，用$i$表示</p>\n<h5 id=\"单原子分子\"><a href=\"#单原子分子\" class=\"headerlink\" title=\"单原子分子\"></a>单原子分子</h5><p>平动自由度:$t &#x3D; 3$ </p>\n<p>$i &#x3D; 3$</p>\n<h5 id=\"双原子分子\"><a href=\"#双原子分子\" class=\"headerlink\" title=\"双原子分子\"></a>双原子分子</h5><p>质心平动：$t &#x3D; 3$</p>\n<p>轴取向：$r &#x3D; 2$</p>\n<p>距离变化：$v &#x3D; 1$</p>\n<p>总自由度: $i &#x3D; 6$</p>\n<h5 id=\"多原子分子\"><a href=\"#多原子分子\" class=\"headerlink\" title=\"多原子分子\"></a>多原子分子</h5><p>设分子包含$N$个原子</p>\n<p>$i &#x3D; 3N$</p>\n<p>$t &#x3D; 3$</p>\n<p>$r &#x3D; 3$</p>\n<p>$v &#x3D; 3N-6$</p>\n<h5 id=\"能量均分定理-1\"><a href=\"#能量均分定理-1\" class=\"headerlink\" title=\"能量均分定理\"></a>能量均分定理</h5><p>一个平动自由度对应的平均动能为$\\frac12kT$</p>\n<p>考虑平动、振动和转动，由于分子的碰撞，分子平均动能均匀分配到每个自由度上。</p>\n<p>在温度$T$的平衡态下，分子热运动的每个自由度对应的平均动能都等于$\\frac12kT$。</p>\n<p>普遍的能量均分定理：</p>\n<p>分子能量中每具有一个平方项，就对应一个$\\frac12kT$的平均能量。</p>\n<p>分子振动的动能和势能都是平方项，所以：</p>\n<p>$\\bar\\varepsilon_{vP} &#x3D; \\bar\\varepsilon_{vk} &#x3D; v\\frac12kT$,  $\\bar\\varepsilon_v &#x3D; \\bar\\varepsilon_{vP}  + \\bar\\varepsilon_{vk} &#x3D; vkT$</p>\n<div>$$\\bar\\varepsilon = \\bar\\varepsilon _t + \\bar\\varepsilon_r + \\bar\\varepsilon_v = (t + r + 2v)\\frac12kT$$</div>\n通常情况下($T < 10^3K$)，振动自由度被“冻结”，分子可视为刚性\n\n<p>刚性分子：$v &#x3D; 0, i &#x3D; t + r$</p>\n<div>$$\\bar\\varepsilon = \\frac{t+ r}2kT$$</div>\n\n<h5 id=\"理想气体内能\"><a href=\"#理想气体内能\" class=\"headerlink\" title=\"理想气体内能\"></a>理想气体内能</h5><p>内能：系统内部各种形式能量的总和，不包括系统整体质心运动的能量</p>\n<p>分子内部： $\\bar\\varepsilon &#x3D; (t + r + 2v)\\frac12kT$</p>\n<p>分子之间：相互作用势能$\\varepsilon_{\\mathrm pij}$</p>\n<p>内能：$E &#x3D; N\\bar\\varepsilon + \\sum_i\\sum_{j&lt;i}\\varepsilon_{\\mathrm pij} &#x3D; E(T, V)$</p>\n<p>理想气体： $\\varepsilon_{\\mathrm pij} &#x3D; 0,E &#x3D; E(T)$</p>\n<h3 id=\"麦克斯韦速度分布律\"><a href=\"#麦克斯韦速度分布律\" class=\"headerlink\" title=\"麦克斯韦速度分布律\"></a>麦克斯韦速度分布律</h3><p>分布函数是体现热力学系统的统计规律性的重要函数.</p>\n<p>常见的统计分布函数包括：速率分布函数、速度分布函数、能量分布函数等。</p>\n<p>通过分布函数可计算微观量的统计平均值，如$\\bar\\varepsilon_t, \\bar{v^2}$等，进而得到系统的宏观量。</p>\n<h5 id=\"速率分布函数\"><a href=\"#速率分布函数\" class=\"headerlink\" title=\"速率分布函数\"></a>速率分布函数</h5><div>$$f(v) = \\frac{\\text dN}{N\\text dv}\\\\\\\\\\int_0^\\infty f(v)\\text dv = \\int_0^\\infty\\frac{\\text dN}{N} = 1$$</div>\n\n<h5 id=\"麦克斯韦速率分布函数（不用记）\"><a href=\"#麦克斯韦速率分布函数（不用记）\" class=\"headerlink\" title=\"麦克斯韦速率分布函数（不用记）\"></a>麦克斯韦速率分布函数（不用记）</h5><div>$$f(v) = 4\\pi (\\frac m{2\\pi kT})^{3/2}e$$</div>\n\n<h5 id=\"三种统计速率\"><a href=\"#三种统计速率\" class=\"headerlink\" title=\"三种统计速率\"></a>三种统计速率</h5><h6 id=\"最概然速率\"><a href=\"#最概然速率\" class=\"headerlink\" title=\"最概然速率\"></a>最概然速率</h6><div>$$v_p = \\sqrt{\\frac{2kT}{m}}$$</div>\n\n<p>m一定时，温度T越高，速率大的分子数比例越大，最概然速率越大， $f(v_p)$越小。</p>\n<h6 id=\"平均速率\"><a href=\"#平均速率\" class=\"headerlink\" title=\"平均速率\"></a>平均速率</h6><div>$$\\bar v = \\int_0^\\infty vf(v)\\text dv$$</div>\n\n<p>任意函数对全体分子按速率分布的平均值为</p>\n<p><font color =\"red\">$f(v)$一定要归一化!</font><p>例如求0到vp&#x2F;2的平均速率，首先要将f(v)归一化成这个区间内的速率分布，而不是直接用全部速率分布</p></p>\n<div>$$\\bar{\\phi(v)} =\\int_0^\\infty \\phi(v)f(v)\\text dv$$</div>\n\n<p>由麦克斯韦速率分布函数</p>\n<div>$$\\bar v = \\sqrt{\\frac{8kT}{\\pi m}} = \\sqrt{\\frac{8RT}{\\pi M}}$$</div>\n\n<h6 id=\"方均根速率\"><a href=\"#方均根速率\" class=\"headerlink\" title=\"方均根速率\"></a>方均根速率</h6><div>$$\\bar{v^2} = \\int_0^\\infty v^2f(v)\\text dv = \\frac{3kT}{m}\\\\\\sqrt{\\bar{v^2}} = \\sqrt{\\frac{3kT}{m}} = \\sqrt{\\frac{3RT}M}$$</div>\n\n<h5 id=\"麦克斯韦速度分布律-1\"><a href=\"#麦克斯韦速度分布律-1\" class=\"headerlink\" title=\"麦克斯韦速度分布律\"></a>麦克斯韦速度分布律</h5><div>$$\\frac{\\text dN}{N} = \\left(\\frac{m}{2\\pi kT}\\right)^{3/2}e^{-m(v_x^2 + v_y^2 + v_z^2)/2kT}\\text{d}v_x\\text{d}v_y\\text{d}v_x$$</div>\n\n<p>速度分量的分布函数</p>\n<div>$$g(v) = (\\frac m{2\\pi kT})^{1/2}e^{-mv^2/2kT}$$</div>\n\n<h5 id=\"分子碰壁数-Γ\"><a href=\"#分子碰壁数-Γ\" class=\"headerlink\" title=\"分子碰壁数$Γ$\"></a>分子碰壁数$Γ$</h5><div>$$\\Gamma = \\frac14 n\\bar v$$</div>\n\n<h5 id=\"玻尔兹曼分布\"><a href=\"#玻尔兹曼分布\" class=\"headerlink\" title=\"玻尔兹曼分布\"></a>玻尔兹曼分布</h5><h6 id=\"恒温气压公式\"><a href=\"#恒温气压公式\" class=\"headerlink\" title=\"恒温气压公式\"></a>恒温气压公式</h6><div>$$p = p_0e^{-mgz/kT}\\\\\\\\n = n_0e^{-mgz/kT}$$</div>\n\n<h6 id=\"玻尔兹曼分布-1\"><a href=\"#玻尔兹曼分布-1\" class=\"headerlink\" title=\"玻尔兹曼分布\"></a>玻尔兹曼分布</h6><div>$$\\text dN_{\\vec r} = n_0 \\cdot e^{-\\varepsilon_p(\\vec r)/kT} \\cdot \\text d^3 \\vec r\\\\\\\\\\text d^3\\vec r = \\text dx \\ \\text dy \\  \\text dz$$</div>\n\n<h6 id=\"玻尔兹曼-麦克斯韦分布\"><a href=\"#玻尔兹曼-麦克斯韦分布\" class=\"headerlink\" title=\"玻尔兹曼-麦克斯韦分布\"></a>玻尔兹曼-麦克斯韦分布</h6><div>$$\\text dN = n_0 \\cdot (\\frac m{2\\pi kT})^{3/2} \\cdot e^{-[\\frac12 mv^2 + \\varepsilon_p(\\vec r)]/kT} \\cdot \\text d^3\\vec r \\cdot \\text d^3 \\vec v$$</div>\n\n<p>能量简并：不同子相空间分子能量相等。</p>\n<p>分子按能量分布：</p>\n<div>$$N(\\varepsilon) = C \\cdot w(\\varepsilon) \\cdot e^{-\\frac{\\varepsilon}{kT}}$$</div>\n\n<p>$\\varepsilon$为粒子的能量，$w(\\varepsilon)$为具有此能量的体积元个数.</p>\n<h3 id=\"范德瓦尔斯方程\"><a href=\"#范德瓦尔斯方程\" class=\"headerlink\" title=\"范德瓦尔斯方程\"></a>范德瓦尔斯方程</h3><h4 id=\"范氏气体模型\"><a href=\"#范氏气体模型\" class=\"headerlink\" title=\"范氏气体模型\"></a>范氏气体模型</h4><p>气体分子间的作用力：分子间的作用力很复杂，主要是电磁力，可以分为引力和斥力</p>\n<p>范氏气体模型：对理想气体做两方面的修正。考虑分子体积、分子间作用力引起的修正。</p>\n<p><img src=\"/../images/physics/VanGas.png\" alt=\"范氏气体\"></p>\n<ul>\n<li>分子是直径为d的刚球</li>\n<li>在$d\\rightarrow s$的范围内，分子间有恒定引力</li>\n</ul>\n<h4 id=\"范德瓦尔斯方程-1\"><a href=\"#范德瓦尔斯方程-1\" class=\"headerlink\" title=\"范德瓦尔斯方程\"></a>范德瓦尔斯方程</h4><p>范德瓦尔斯方程：</p>\n<p>设:</p>\n<p>$\\nu &#x3D; 1 mol$</p>\n<p>$p$ – 实测气体压强</p>\n<p>$V_m$ – $1\\ mol$气体容积</p>\n<p>对理想气体：$pV_m &#x3D; RT$</p>\n<p>对真实气体：</p>\n<ol>\n<li>分子体积引起的修正</li>\n</ol>\n<p>分子自由活动空间的体积为$V_m - b$</p>\n<div>$$p(V_m - b) = RT$$</div>\n\n<div>$$\np = \\frac{RT}{V_m - b}\n$$</div>\n\n<ol start=\"2\">\n<li>分子间引力引起的修正</li>\n</ol>\n<p>气体分子间作用力一般表现为引力。</p>\n<p>在容器内部，单个气体分子受到各个方向的平均引力相等，合力可以看作零。</p>\n<p>但是在容器边缘，单个气体分子受到的引力是不对称的。气体分子所受的合力指向容器内部，因此撞击容器壁的气体分子动量比理想气体下的情况要小，宏观上形成的压强比理想气体情况要小。</p>\n<div>$$\np < \\frac{RT}{V_m - b}\\\\\n$$</div>\n\n<p>设</p>\n<div>$$\np = \\frac{RT}{V_m - b} - p_{in}\n$$</div>\n\n<p>$p_{in} \\propto nf_{合}, f_{合}\\propto n \\Rightarrow p_{in} \\propto n^2 \\propto \\frac 1{V_m^2}$</p>\n<p>最后得到：</p>\n<div>$$\n(p + \\frac a{V_m^2})(V_m - b) = RT\n$$</div>\n\n<p>对 ν mol 气体：</p>\n<div>$$\n(p + \\nu^2 \\cdot \\frac a{V^2})(V - \\nu b) = \\nu RT\n$$</div>\n\n<p>常温常压下：$b&#x2F;V_m \\sim 10^{-3}, p_{in}&#x2F;p \\sim 10^{-2}$，这时分子体积和分子间的作用力修正可以忽略。</p>\n<h4 id=\"气体的等温线\"><a href=\"#气体的等温线\" class=\"headerlink\" title=\"气体的等温线\"></a>气体的等温线</h4><p>真实气体的等温线：</p>\n<p><img src=\"/../images/physics/RealGasTemp.png\" alt=\"RealGasTemp\"></p>\n<p>范氏气体的等温线：</p>\n<p><img src=\"/../images/physics/VanGasTemp.png\" alt=\"VanGasTemp\"></p>\n<p>如何计算临界参数：</p>\n<p>临界参数：临界点K对应的$p_K, V_K, T_K$</p>\n<p>临界点K是等温线的拐点：</p>\n<div>$$\n\\left(\\frac{\\partial p}{\\partial V}\\right)_{T = T_K} = 0\\\\\n\\left(\\frac{\\partial^2 p}{\\partial V^2}\\right)_{T = T_K} = 0\n$$</div>\n\n<p>K同时也是三次方程的三重根，因此可以通过假设$(V_m - V_{mK})^3 &#x3D; 0$展开后和范德瓦尔斯方程对比系数求解。</p>\n<h4 id=\"范氏气体内能\"><a href=\"#范氏气体内能\" class=\"headerlink\" title=\"范氏气体内能\"></a>范氏气体内能</h4><p>理想气体： $E(T) &#x3D; i\\nu RT &#x2F; 2$</p>\n<p>范氏气体：$V\\uparrow \\rightarrow p_{in}做负功\\rightarrow 分子间势能E_p\\uparrow$</p>\n<p>要计算势能，首先要定义势能为0的状态：定义某种位形为0势能。其他状态的势能定义为从这种状态变形到0势能状态的过程中保守力的变化。</p>\n<div>$$\\mathrm dA = -p_{in}S\\mathrm dl = -p_{in}\\mathrm dV$$</div>\n\n<p>设$E_p(V &#x3D; \\infty) &#x3D; 0$。</p>\n<div>$$\nE_p(V) = \\int_V^\\infty -p_{in}\\mathrm dV = \\int_V^\\infty-\\nu^2 \\cdot \\frac a{V^2}\\mathrm dV = -v^2 \\cdot \\frac aV\n$$</div>\n\n<div>$$\nE = E_k + E_p = \\frac i2\\nu RT - \\nu ^2\\frac aV\n$$</div>\n\n<p><strong>结论：</strong></p>\n<div>$$E(T, V) = \\frac i2 \\nu RT - \\nu^2 \\frac aV$$</div>\n\n<h4 id=\"一个细节\"><a href=\"#一个细节\" class=\"headerlink\" title=\"一个细节\"></a>一个细节</h4><p>为什么不考虑气体分子和容器壁分子间的引力？</p>\n<p>事实上，这引力确实存在。但是可以通过动量定理证明，碰撞过程这引力的作用总和为0。</p>\n<h3 id=\"气体分子的碰撞、平均自由程\"><a href=\"#气体分子的碰撞、平均自由程\" class=\"headerlink\" title=\"气体分子的碰撞、平均自由程\"></a>气体分子的碰撞、平均自由程</h3><p>平均碰撞频率和平均自由程</p>\n<p>平均碰撞频率$\\bar z$：单位时间内一个气体分子与其他分子碰撞的平均次数</p>\n<p>平均自由程$\\bar \\lambda$：气体分子在相邻两次碰撞之间飞行的平均路程。</p>\n<p>平均碰撞频率和平均频率之间关系</p>\n<p>对象:平衡态下的理想气体</p>\n<p>假定：</p>\n<p>(1)只有一种分子；</p>\n<p>(2)分子可视作直径为d的刚球；</p>\n<p>(3)被考察的分子以平均相对速率$\\bar u$运动，其余的分子静止。</p>\n<p>碰撞界面为$\\sigma$。分子间平均相对速率为$\\bar u &#x3D; \\sqrt 2 \\bar v$。</p>\n<div>$$\n\\bar z = \\sigma \\bar u n = \\pi d^2 n \\bar u = \\sqrt 2 \\pi d^2 n\\bar v\n$$</div>\n\n<p>平均自由程和压强、温度的关系：</p>\n<div>$$\n\\bar\\lambda = \\frac {\\bar v} {\\bar z} = \\frac 1{\\sqrt2 \\pi d^2 n} = \\frac {kT}{\\sqrt2\\pi d^2p} \\propto \\frac{T}{p}\n$$</div>\n\n<h3 id=\"气体输运过程\"><a href=\"#气体输运过程\" class=\"headerlink\" title=\"气体输运过程\"></a>气体输运过程</h3><p>非平衡态下，气体内部各部分性质不均匀，就会产生热量、动量、质量的迁移，称为输运过程或内迁移过程。</p>\n<p>气体输运过程包括：热传导、扩散和内摩擦（粘滞）。</p>\n<p>输运现象的宏观实验定律和原因。</p>\n<p>热传导</p>\n<p>温度不均匀。实验定律：傅里叶定律，热传导方程。</p>\n<p>考虑1维的情形。</p>\n<div>$$\n\\mathrm dQ = -\\kappa \\frac{\\partial T}{\\partial x}\\mathrm dS \\mathrm dt\n$$</div>\n\n<div>$$\nj(x, t) = \\frac{\\mathrm dQ}{\\mathrm dS\\mathrm dt}  = -\\kappa \\frac {\\partial T(x, t)}{\\partial x}\n$$</div>\n\n<p>$j(x, t)$：热流密度，$\\partial T&#x2F;\\partial x$：温度梯度。</p>\n<p>温度梯度“力”导致热流。</p>\n<blockquote>\n<p>$T$在这里相当于电势，$-\\partial T &#x2F; \\partial x$相当于电势的负梯度即电场强度，$j$相当于电流密度，$\\kappa$相当于电导率。因此类比$\\vec{J} &#x3D; \\sigma \\vec{E}$有$j &#x3D; -\\kappa \\partial T &#x2F;\\partial x$。类似的，也许可以推导出热阻的概念？热学的“麦克斯韦”方程组又是什么？</p>\n</blockquote>\n<p>统计物理给出的结论：</p>\n<div>$$\n\\kappa = \\frac 13 nm\\bar v \\bar \\lambda c_V\n$$</div>\n\n<blockquote>\n<p>如何理解此公式：热传导的本质是分子能量（热量）的交换，交换的热量等于粒子数乘以单个粒子交换的热量。</p>\n<p>$m$为单个分子质量。$c_V$为定体热容。$n\\bar v$用于描述$\\mathrm dt$内穿过$\\mathrm dS$的粒子数，$\\bar\\lambda$乘以$\\partial T&#x2F;\\partial x$得到温度的变化量$\\mathrm dT$ ,$m,c_V$与温度的变化量相乘，得到单个粒子交换的热量。</p>\n</blockquote>\n<p>稳恒热流：$\\frac{\\mathrm dQ}{\\mathrm dt} &#x3D; C$，$j$, $T$与$t$无关。</p>\n<p>$\\kappa$称为导热系数，由气体特性和$T, p$决定。</p>\n<p>扩散</p>\n<p>原因：气体内部离子数浓度不均匀。</p>\n<p>斐克定律</p>\n<div>$$\n\\mathrm dN = -D\\frac {\\partial n}{\\partial x}\\mathrm dS \\mathrm dt\n$$</div>\n\n<blockquote>\n<p>教材的表述为</p>\n<div>$$\n\\mathrm dM = -D\\frac {\\partial \\rho}{\\partial x}\\mathrm dS \\mathrm dt\n$$</div>\n这里的两个$D$是一样的。\n</blockquote>\n<p>统计物理给出的结论：</p>\n<div>$$\nD = \\frac13\\bar v\\bar \\lambda\n$$</div>\n\n<p>扩散流密度：</p>\n<div>$$\nj(x, t) = \\frac {\\mathrm dN}{\\mathrm dS \\mathrm dt} = -D\\frac {\\partial n}{\\partial x}\n$$</div>\n\n<p>稳恒扩散流：$\\frac {\\mathrm dN}{\\mathrm dt} &#x3D; C$，$j$, $n$, 与$t$无关。</p>\n<p>粒子数守恒方程</p>\n<div>$$\n\\oiint_S j\\cdot \\vec {s} = -\\frac {\\mathrm dN}{\\mathrm dt}, \\nabla \\cdot \\vec j + \\frac{\\partial n}{\\partial x} = 0.\n$$</div>\n\n<p>结合粒子数守恒方程（微分形式）和斐克定律得到扩散方程</p>\n<div>$$\n\\frac{\\partial n}{\\partial t} = D\\frac{\\partial^2 n}{\\partial x^2}\n$$</div>\n\n<p>考试考定场稳恒流，不考内摩擦。</p>\n<p>内摩擦（粘滞）</p>\n<p>根据流体力学，对定常流动的粘滞流体，流速不太大时（雷诺数小），出现层流。</p>\n<p>粘滞定律（牛顿摩擦定律）</p>\n<div>$$\n\\Delta F = - \\eta \\frac{\\mathrm du}{\\mathrm dz}\\Delta S\n$$</div>\n\n<div>$$\np = -\\eta \\frac{\\mathrm du}{\\mathrm dz}\n$$</div>\n\n<p>粘度和温度有关，气体粘度随温度增加，液体温度随温度减小。遵从粘滞定律的流体称为牛顿流体。</p>\n<p>内摩擦原因：流速不均匀。</p>\n<p>统计物理给出的结论：</p>\n<div>$$\n\\eta = \\frac 13 nm\\bar v\\bar \\lambda\n$$</div>\n\n<h2 id=\"热力学第一定律\"><a href=\"#热力学第一定律\" class=\"headerlink\" title=\"热力学第一定律\"></a>热力学第一定律</h2><h3 id=\"准静态过程\"><a href=\"#准静态过程\" class=\"headerlink\" title=\"准静态过程\"></a>准静态过程</h3><p>准静态过程：过程的任一时刻，系统都处于平衡态— 一系列平衡态组成的理想化过程。</p>\n<p>若外界条件改变时，能保证和系统相应的强度量之间差无穷小，则过程是准静态的。</p>\n<p>弛豫时间τ：平衡破坏到恢复平衡的时间.</p>\n<p>当$\\Delta t_{过程} &gt; \\tau$时，过程就可视为准静态过程。<br>。</p>\n<h3 id=\"功\"><a href=\"#功\" class=\"headerlink\" title=\"功\"></a>功</h3><p>体积功：$\\mathrm{\\bar dA} &#x3D; p\\mathrm dV$</p>\n<p>系统对外界做功:$A &#x3D; \\int_{V_1}^{V_2}p\\mathrm dV$是一个过程量。</p>\n<p>通过做功改变系统热力学状态，微观上是分子规则运动的能量通过碰撞转变为无规则运动的能量。</p>\n<h3 id=\"内能，热量和热力学第一定律\"><a href=\"#内能，热量和热力学第一定律\" class=\"headerlink\" title=\"内能，热量和热力学第一定律\"></a>内能，热量和热力学第一定律</h3><p>内能：定义为$E_2 - E_1 &#x3D; A_{1\\rightarrow 2}$（绝热过程）</p>\n<p>内能通过绝热功度量。</p>\n<p>热量：定义为$Q &#x3D; (E_2 - E_1)$（无功过程）</p>\n<p>微观本质是分子无规则运动的能量通过碰撞从高温物体向低温物体传递。</p>\n<p>热力学第一定律：</p>\n<p>$Q &#x3D; \\Delta E + A$</p>\n<p>$\\mathrm {\\bar{d}}Q &#x3D; \\mathrm d E + \\mathrm{\\bar{d}}A$</p>\n<p>热力学第一定律是一条实验定律，适用于任何热力学系统的任何过程。</p>\n<h3 id=\"热容量：\"><a href=\"#热容量：\" class=\"headerlink\" title=\"热容量：\"></a>热容量：</h3><div>$$\nC = \\frac{\\mathrm dQ}{\\mathrm dT}\n$$</div>\n\n<p>定体热容量：$C_v &#x3D; \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_V$</p>\n<p>定压热容量：$C_p &#x3D; \\left(\\frac{\\mathrm dQ}{\\mathrm dT}\\right)_p$</p>\n<p>摩尔热容量：</p>\n<div>$$\nC_m = \\frac1\\nu\\frac{\\mathrm dQ}{\\mathrm dT}\n$$</div>\n\n<p>对应地有定体摩尔热容量和定压摩尔热容量。</p>\n<p>理想气体内能：$\\Delta E &#x3D; \\nu C_{V, m}\\Delta T$。（推导：内能变化与过程无关，假设先等体后等温，等体过程无功只有热交换，等温过程内能不变。）</p>\n<p>迈耶公式：</p>\n<div>$$\nC_{p, m} - C_{V, m} = R\n$$</div>\n\n<p>（推导：用等压过程计算内能的变化，与定体过程的结论比较一下可得。）</p>\n<p>理想气体热容量理论公式：</p>\n<div>$$\nC_{V, m} = \\frac i2R, C_{p, m} = \\frac{i+2}{2}R\n$$</div>\n\n<p>推导：结合理想气体内能公式。</p>\n<p>定义比热容比:$\\gamma &#x3D; C_{p, m}&#x2F;C_{V, m}$</p>\n<h3 id=\"绝热过程\"><a href=\"#绝热过程\" class=\"headerlink\" title=\"绝热过程\"></a>绝热过程</h3><p>系统和外界没有热交换的过程。</p>\n<p>理想气体的准静态绝热过程：</p>\n<blockquote>\n<div>$$\n0 = p\\mathrm dV + \\nu C_{V, m}\\mathrm dT\\\\\np\\mathrm dV + V\\mathrm dp = \\nu R\\mathrm dT\\\\\nR  = C_{p, m} - C_{V ,m}\n$$</div>\n\n<p>得到：</p>\n<div>$$\n\\frac{\\mathrm dp}{p} = -\\gamma\\frac{\\mathrm dV}V\n$$</div>\n</blockquote>\n<p>两边积分得到:</p>\n<div>$$\npV^{\\gamma} = C, TV^{\\gamma - 1} = C, p^{\\gamma - 1}T^{-\\gamma} = C\n$$</div>\n\n<p>绝热功</p>\n<div>$$\nA = \\int_{V_1}^{V_2} p\\mathrm dV = C \\int_{V_1}^{V_2}\\frac 1{V^{\\gamma}}\\mathrm dV = \\frac{C}{1 - \\gamma}(V_2^{1 - \\gamma} - V_1^{1 - \\gamma}) =\\frac{p_2V_2 - p_1V_1}{1 - \\gamma} \n$$</div>\n\n<p>绝热功等于内能的减少量：</p>\n<div>$$\nA = -\\Delta E = \\nu C_{V, m}\\Delta T\n$$</div>\n\n<p>理想气体的多方过程</p>\n<p>多方过程：热容量$C$为常数的过程</p>\n<p>多方过程方程：$pV^n &#x3D; \\text{const}$</p>\n<p>其中，$n &#x3D; (C - C_p)&#x2F;(C - C_V) &#x3D; (C_m - C_{p, m})&#x2F;(C_m - C_{V, m}) &#x3D; \\text{const}$</p>\n<p>如果为绝热过程则$C &#x3D; 0$，$n &#x3D; \\gamma$，从而$pV^{\\gamma} &#x3D; \\text{const}$。</p>\n<p>如果为等温过程则$C &#x3D; \\infty$，$n &#x3D; 1$，因此$pV &#x3D; \\text{const}$。</p>\n<p>绝热自由膨胀过程<font color=\"red\">（非准静态过程！！）</font>：</p>\n<p>理想气体：$Q &#x3D; 0, A &#x3D; 0 \\Rightarrow E_1 &#x3D; E_2$</p>\n<p>真实气体：若分子间以引力为主, $T_2 &lt; T_1$，以斥力为主，$T_2 &gt; T_1$。</p>\n<p>焓：气体的绝热节流过程是等焓过程，即$H &#x3D; E + pV$为常数，对于非理想气体而言，内能不仅与温度有关，也与体积有关（焦耳-汤姆孙效应）。</p>\n<p>绝热自由膨胀：初末状态在等温线上，但是过程中不是平衡态。</p>\n<p>准静态等温膨胀：吸热用来做功。</p>\n<p>准静态绝热膨胀：内能的减少量用来做功。</p>\n<p><img src=\"/../images/physics/guocheng.png\"></p>\n<p>循环过程：</p>\n<p>系统，如热机中的工质，经一系列变化的回到初态的整个过程。</p>\n<p>状态图：</p>\n<p><img src=\"/../images/physics/xunhuantu.png\"></p>\n<p>热循环：</p>\n<p><img src=\"/../images/physics/rexunhuan.png\"></p>\n<p>蒸汽机的效率约为十几%，内燃机20-30%。</p>\n<p>制冷循环：</p>\n<p><img src=\"/../images/physics/zhilengxunhuan.png\"></p>\n<p>制冷系数：</p>\n<div>$$\nw = \\frac{Q_2}{A} = \\frac{Q_2}{Q_1 - Q_2}\n$$</div>\n\n<h3 id=\"卡诺循环\"><a href=\"#卡诺循环\" class=\"headerlink\" title=\"卡诺循环\"></a>卡诺循环</h3><p>卡诺循环是一种可逆循环，包括两个等温过程和两个绝热过程。它的效率为</p>\n<div>$$\n\\eta = 1 - \\frac{|Q_2|}{Q_1} = 1 - \\frac{T_2}{T_1}\n$$</div>\n\n<p>卡诺循环的效率仅与热源的温度比有关。</p>\n<p>由卡诺定理可以证明，卡诺循环的效率与工质无关。因此，不妨设工质为理想气体，利用理想气体等温和绝热过程方程得到效率公式。</p>\n<h2 id=\"热力学第二定律\"><a href=\"#热力学第二定律\" class=\"headerlink\" title=\"热力学第二定律\"></a>热力学第二定律</h2><p>开尔文表述：不可能将热量从低温热源搬运到高温热源，而不产生其他影响。（制冷系数不可能为无穷大）</p>\n<p>克劳修斯表述：不可能将功全部转化为热。（热机效率不可能为1）</p>\n<p>开尔文表述和克劳修斯表述是等价的。事实上，任何关于热现象不可逆的描述都是等价的，它们要么同时成立，要么同时不成立。因此，描述热现象的方向性，只需要举一个例子即可。</p>\n<h3 id=\"卡诺定理\"><a href=\"#卡诺定理\" class=\"headerlink\" title=\"卡诺定理\"></a>卡诺定理</h3><p>在温度相同的高温热源和温度相同的低温热源之间工作的一切热机，可逆热机的效率最大。</p>\n<p>推论：一切可逆热机，只要它们的高温热源的温度相等，低温热源的温度相等，效率就相等。</p>\n<p>对于制冷机：</p>\n<p>可逆制冷机的制冷系数最大。</p>\n<p>所有2热源可逆制冷机制冷系数都相等，等于卡诺制冷机的制冷系数。</p>\n<h3 id=\"热力学温标\"><a href=\"#热力学温标\" class=\"headerlink\" title=\"热力学温标\"></a>热力学温标</h3><p>根据卡诺定理，可逆热机的效率只与温度有关。因此可以用效率，或者说热量比来定义温标。</p>\n<p>在热力学温标下，低温热源的温度不能为0，否则可逆热机的效率为1.</p>\n<h3 id=\"任意可逆循环的效率\"><a href=\"#任意可逆循环的效率\" class=\"headerlink\" title=\"任意可逆循环的效率\"></a>任意可逆循环的效率</h3><div>$$\n\\eta \\le 1 - \\frac {T_2}{T_1}\n$$</div>\n\n<p>其中，$T_1$，$T_2$分别为循环中工质的最高和最低温度。</p>\n<h3 id=\"克劳修斯熵公式\"><a href=\"#克劳修斯熵公式\" class=\"headerlink\" title=\"克劳修斯熵公式\"></a>克劳修斯熵公式</h3><p>热力学第零定理导出了温度，热力学第一定律导出了内能，热力学第二定律则导出了熵。</p>\n<p>可逆循环可以拆成若干小卡诺循环，每个卡诺循环满足</p>\n<p>可逆循环有克劳修斯等式</p>\n<div>$$\n\\oint_R \\frac{\\mathrm {\\bar d} Q}{T} = 0\n$$</div>\n\n<p>因此得到一个与路径无关的状态函数。</p>\n<p>熵与状态有关，和过程无关。即便过程是不可逆过程。</p>\n<p>但是，仅当过程为可逆过程时才有$\\mathrm dS&#x3D;  \\mathrm{\\bar d}Q&#x2F;T$。</p>\n<p>对于可逆过程：</p>\n<div>$$\nT\\mathrm dS = \\mathrm{\\bar d}Q = \\mathrm dE + p\\mathrm dV\n$$</div>\n\n<p>因而可以用$E, V$表示熵：</p>\n<div>$$\n\\mathrm dS = \\frac 1T \\mathrm dE + \\frac pT \\mathrm dV = \\frac 1T()\n$$</div>\n\n<h3 id=\"克劳修斯不等式\"><a href=\"#克劳修斯不等式\" class=\"headerlink\" title=\"克劳修斯不等式\"></a>克劳修斯不等式</h3><p>不可逆循环有</p>\n<div>$$\n\\oint_{Ir} \\frac{\\mathrm {\\bar d} Q}{T} < 0\n$$</div>\n\n<p>因而有熵增加原理:</p>\n<div>$$\n\\int_{1_{Ir}}^{2} + \\int_{2_R}^1 < 0\\Rightarrow S_1 - S_2= \\int_{1_{Ir}}^2\n$$</div>\n\n<h1 id=\"振动和波动\"><a href=\"#振动和波动\" class=\"headerlink\" title=\"振动和波动\"></a>振动和波动</h1><h2 id=\"波动\"><a href=\"#波动\" class=\"headerlink\" title=\"波动\"></a>波动</h2><h3 id=\"多普勒效应\"><a href=\"#多普勒效应\" class=\"headerlink\" title=\"多普勒效应\"></a>多普勒效应</h3><p>一般形式：</p>\n<p><img src=\"/../images/DSA/Duopule.jpg\"></p>\n<p>机械波不存在多普勒效应。</p>\n<p>电磁波的多普勒效应：</p>\n<p><img src=\"/../images/DSA/waveDuopl.jpg\"></p>\n<p>横向多普勒效应：$\\theta &#x3D; \\pi &#x2F;2$</p>\n<p>纵向多普勒效应：$\\theta &#x3D; 0,\\pi$</p>\n<h3 id=\"激波\"><a href=\"#激波\" class=\"headerlink\" title=\"激波\"></a>激波</h3><p>马赫数：$\\frac{v_s}{u} &#x3D; \\frac 1{\\sin\\alpha}$</p>\n<h1 id=\"光学\"><a href=\"#光学\" class=\"headerlink\" title=\"光学\"></a>光学</h1><p>光学分为几何光学，波动光学和量子光学。</p>\n<h2 id=\"光的相干叠加\"><a href=\"#光的相干叠加\" class=\"headerlink\" title=\"光的相干叠加\"></a>光的相干叠加</h2><p>光源：</p>\n<ol>\n<li>普通光源：自发辐射。不同原子发光独立、不相干；同原子不同次发光独立、不相干。</li>\n<li>激光光源：受激辐射。光放大，全通光子，相干光，波列长，相干性好。</li>\n</ol>\n<p>光的相干性：<br>光学中强调电磁波的电场矢量$\\vec E$：光矢量</p>\n<p>相干条件：光矢量有平行分量，频率相同，相差恒定。</p>\n<p>电磁波叠加的强度公式推导：</p>\n<div>$$\nI = \\sqrt{\\varepsilon / \\mu}\\left<\\vec E \\cdot \\vec E \\right>_t \\\\\n\n<p>I \\propto \\left&lt;\\vec E \\cdot \\vec E \\right&gt;_t \\</p>\n<p>叠加的电磁波：\\vec E_1 + \\vec E_2\\</p>\n<p>矢量的点乘运算可得叠加后的强度:\\</p>\n<p>I &#x3D; I_1 + I_2 + 2\\sqrt{\\varepsilon &#x2F; \\mu}\\left&lt;\\vec E_1 \\cdot \\vec E_2 \\right&gt;_t </p>\n<p>$$</div></p>\n<p>对光的相干叠加，用光矢量的平行分量描述光场–标量波函数。</p>\n<div>$$\nI = I_1 + I_2 + 2\\sqrt{I_1I_2}\\cos \\Delta \\varphi\n$$</div>\n\n<p>其中$\\Delta\\varphi &#x3D; -k(r_2 - r_1) + (\\varphi_{20} - \\varphi_{10})$为相位差。</p>\n<p>在上面两式中，若$\\vec E_1 \\cdot \\vec E_2 \\ne 0$或者$\\Delta\\varphi \\ne \\pm\\frac{\\pi}{2}…$，则满足相干的条件。</p>\n<p>条纹的明显程度用衬比度衡量：$V &#x3D; (I_{max} - I_{min})&#x2F;(I_{max} + I_{min})$</p>\n<p>不同的位置$\\Delta\\varphi$不同，因而对应的$I$不同，造成了干涉条纹的出现。$I_1 &#x3D; I_2$时$V&#x3D;1$，$I_1 \\ne I_2$时，$V \\ne 1$。</p>\n<p>普通光源获得相干光的途径一般有分波阵面法（双缝干涉）和分振幅法（薄膜干涉）。</p>\n<h3 id=\"双缝干涉\"><a href=\"#双缝干涉\" class=\"headerlink\" title=\"双缝干涉\"></a>双缝干涉</h3><p><img src=\"/../images/physics/shuangfeng.jpg\"></p>\n<p>明纹：$\\delta &#x3D; \\pm k\\lambda$</p>\n<p>暗纹：$\\delta &#x3D; \\pm (2k + 1)\\frac \\lambda 2$</p>\n<p>$(k\\in N)$</p>\n<p>条纹间距：$\\Delta x &#x3D; \\frac{D}{d}\\lambda$</p>\n<p>$\\Delta \\varphi \\approx \\frac{d\\sin \\theta}{\\lambda}2\\pi$</p>\n<p>时间相干性（光的颜色）：</p>\n<p>光的非单色性：</p>\n<p>准单色光：由某个中心频率或波长附近的频率或波长连续分布的光构成。采用谱密度函数描述。</p>\n<p><img src=\"/../images/physics/%E5%87%86%E5%8D%95%E8%89%B2%E5%85%89.jpg\"></p>\n<p>造成谱线宽度的原因：自然宽度、多普勒增宽、碰撞增宽</p>\n<p>非单色性对干涉条纹的影响：</p>\n<p><img src=\"/../images/physics/%E9%9D%9E%E5%8D%95%E8%89%B2%E5%85%89.jpg\"></p>\n<p>从图中可以看出，如果某个位置谱线中波长最长的成分的k级明纹和波长最短的成分的(k+1)级明纹重合，则在这个位置以后的条纹看不清楚了。</p>\n<p>可以解得最大相干级次：$k_M &#x3D; \\lambda&#x2F;\\Delta\\lambda$，进而有最大波程差：$\\delta_M &#x3D; \\lambda^2&#x2F;\\Delta\\lambda$。</p>\n<p>相干长度等于波列长度。</p>\n<p>通常用相干时间（光通过相干长度所需的时间）$\\tau &#x3D; \\delta_M &#x2F; c$ 衡量光的单色性。相干时间或相干长度越长，则单色性越好。</p>\n<p>空间相干性（光的宽度）：</p>\n<p>较宽的光源会导致明纹的非相干叠加，使衬比度下降。</p>\n<p>设光的宽度为$b_0$,则看到干涉条纹的条件是$b_0 &lt; \\frac{R}{d}\\lambda$，这一上界称为光源极限宽度。</p>\n<p>固定b和R，则得到$d &lt; \\frac{R}{b}\\lambda$，上界称为相干间隔。</p>\n<p>光源中心对两孔的张角为$\\theta &#x3D; \\frac{d}{R} &lt; \\frac{\\lambda}{b}$，上界称为相干孔径角。</p>\n<h3 id=\"光程\"><a href=\"#光程\" class=\"headerlink\" title=\"光程\"></a>光程</h3><p>用于计算光经过不同介质的相差。<br>$\\Delta\\varphi &#x3D; \\frac{2\\pi r}{\\lambda}$。</p>\n<p>透镜不产生附加光程差。</p>\n<h3 id=\"薄膜干涉\"><a href=\"#薄膜干涉\" class=\"headerlink\" title=\"薄膜干涉\"></a>薄膜干涉</h3><p>为什么要薄？相干长度（时间相干性）限制。</p>\n<p>薄膜干涉有实际意义的是等倾条纹和等厚条纹。</p>\n<p>光程差</p>\n<div>$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2}\n$$</div>\n\n<p>e为膜厚度。</p>\n<p>等厚条纹：</p>\n<p>厚度不同，角度相同</p>\n<p>单色平行光入射，近似垂直于膜表面，因而$i, r \\approx 0$</p>\n<div>$$\n\\delta = 2ne + \\frac{\\lambda}{2}\n$$</div>\n\n<p>劈尖：</p>\n<p>由于明纹需满足$\\delta &#x3D; k\\lambda$，暗纹需满足$\\delta &#x3D; (2k+1)\\lambda&#x2F;2$，故相邻亮纹所在的厚度差为$\\Delta e &#x3D; \\lambda &#x2F; (2n)$，而条纹间距为$L &#x3D; \\Delta e &#x2F; \\theta &#x3D; \\lambda &#x2F; (2n\\theta)$</p>\n<p>牛顿环：</p>\n<p><img src=\"/../images/physics/niudunhuan.jpg\"></p>\n<p>可以得到暗环半径公式：$r_k&#x3D;\\sqrt{kR\\lambda}$</p>\n<p>总结：条纹跟着厚度走。</p>\n<p>等倾条纹：</p>\n<p>厚度相同，角度不同。</p>\n<p>光程差(记!)</p>\n<div>$$\n\\delta = 2ne \\cos r + \\frac{\\lambda}{2} = 2e\\sqrt{n^2 - n^{\\prime2}\\sin ^2 i} + \\frac \\lambda2\n$$</div>\n\n<p>等倾条纹实验通常采用面光源,因为透镜会把方向相同的光汇聚到一点，因而条纹的非常鲜明，衬比度很高，不会出现光源宽度和条纹衬比度的矛盾。</p>\n<p>应用：增透膜和增反膜</p>\n<h3 id=\"迈克尔逊干涉仪\"><a href=\"#迈克尔逊干涉仪\" class=\"headerlink\" title=\"迈克尔逊干涉仪\"></a>迈克尔逊干涉仪</h3><p>平行：等倾条纹</p>\n<p>倾斜：等厚条纹</p>\n<p>条纹缩进N个，代表厚度变化：</p>\n<div>$$\n\\Delta d = \\frac{\\lambda}{2n} = \\frac {\\lambda}{2}\n$$</div>\n\n<p>在光路上放一个介质，条纹移动N个：</p>\n<div>$$\n\\delta = 2(n - 1)l = N\\lambda\n$$</div>\n\n<p>简而言之，一个条纹对应光程变化一个波长，厚度的变化（介质变化折算成厚度变化）乘以2等于光程的变化，因为一来一回经过了两次。</p>\n<h2 id=\"衍射\"><a href=\"#衍射\" class=\"headerlink\" title=\"衍射\"></a>衍射</h2><p>菲涅尔衍射和夫琅禾费衍射。</p>\n<p>惠更斯-菲涅尔原理</p>\n<p>夫琅禾费衍射研究光源和投影面在无限远处的情形。采用透镜将无限远转化为有限远。</p>\n<h3 id=\"单缝衍射（夫琅禾费）\"><a href=\"#单缝衍射（夫琅禾费）\" class=\"headerlink\" title=\"单缝衍射（夫琅禾费）\"></a>单缝衍射（夫琅禾费）</h3><p>利用半波带法计算明暗纹位置：</p>\n<p>中央明纹：$a\\sin \\theta &#x3D; 0$</p>\n<p>暗纹：$a\\sin \\theta &#x3D; \\pm k\\lambda$</p>\n<p>明纹（近似）:$a\\sin \\theta &#x3D; \\pm (2k + 1)\\frac \\lambda 2$</p>\n<p>上述的$k$不能为0。因为如果k&#x3D;0，即中央明纹，它没有半波带，因此要单独考虑。</p>\n<p>光强公式：$I_p &#x3D; I_0(\\frac{\\sin \\alpha}{\\alpha})^2$</p>\n<p>其中$I_0$为中心亮纹强度，$\\alpha &#x3D; \\frac{\\pi a \\sin \\theta}{\\lambda}$</p>\n<p>条纹宽度：</p>\n<p>条纹宽度的定义：两个相邻暗纹之间的距离，就是它们之间那个条纹的宽度。</p>\n<p>中央明纹角宽度：$\\Delta \\theta_0\\approx 2\\frac{\\lambda}{a}$，线宽度：$\\Delta x_0 \\approx 2 f \\frac{\\lambda}{a}$</p>\n<p>其他明纹线宽度：$\\Delta x \\approx f\\frac{\\lambda}{a}$</p>\n<h3 id=\"光栅衍射\"><a href=\"#光栅衍射\" class=\"headerlink\" title=\"光栅衍射\"></a>光栅衍射</h3><p>光栅是由衍射单元（狭缝、反射面等）排列成的具有空间周期性结构的光学元件。</p>\n<p>光栅常数d-空间周期性结构常数</p>\n<p>正入射光栅方程：$d\\sin \\theta &#x3D; \\pm k\\lambda$。（明纹位置）</p>\n<p>暗纹方程：$d\\sin \\theta &#x3D; \\pm k\\lambda + \\frac{m}{N}\\lambda$</p>\n<p>主极大缺级公式：$k &#x3D; k^\\prime d &#x2F; a$</p>\n<p>主极大半角宽：$\\frac {\\lambda}{N d \\cos \\theta_k}$</p>\n<p>斜入射光栅方程：$d(sin\\theta - \\sin i) &#x3D; \\pm k\\lambda$</p>\n<p>斜入射可以获得更高级次的条纹，但是观察到的条纹总数不变。</p>\n<p>调节入射角i或者波长$\\lambda$，衍射角$\\theta_k$也会改变。对于0级衍射光，$\\sin \\theta_0 &#x3D; \\frac{\\lambda}{2\\pi d}\\Delta \\varphi_{in}$</p>\n<p>光学仪器的分辨本领：</p>\n<p>艾里斑半角宽$D\\sin \\theta_1 \\approx 1.22\\lambda$</p>\n<p>瑞利判据：一个象斑中心在另一个象斑边缘。</p>\n<p>根据瑞利判据得到透镜分辨本领（最小分辨角）：$R &#x3D; \\frac{D}{1.22\\lambda}$</p>\n<p>光栅光谱：</p>\n<p>取决于光栅的色散能力和谱线（条纹）的线宽度</p>\n<p>角色散本领：$D_{\\theta} &#x3D; \\frac{\\delta \\theta}{\\delta \\lambda}$</p>\n<p>色分辨本领：$R &#x3D; \\frac{\\lambda}{\\delta \\lambda} &#x3D; Nk$，$\\delta \\lambda$，$\\lambda $取较小者的波长，$k$是主极大级数。</p>\n<h2 id=\"偏振\"><a href=\"#偏振\" class=\"headerlink\" title=\"偏振\"></a>偏振</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>线偏振光：光矢量做同向振动，方向不变。</p>\n<p>圆偏振光：光矢量的端点是圆。</p>\n<p>椭圆偏振光：光矢量的端点是椭圆。</p>\n<p>非偏振光：例如自然光。它的振动方向随机，各个方向振幅相等。自然光可以分解为两束垂直振动，振幅相等，相差随机的线偏振光。</p>\n<p>部分偏振光：自然光+完全偏振光。</p>\n<p>偏振度：$P &#x3D; \\frac{I_p}{I_t} &#x3D; \\frac{I_p}{I_n + I_p}$</p>\n<h3 id=\"起偏与检偏\"><a href=\"#起偏与检偏\" class=\"headerlink\" title=\"起偏与检偏\"></a>起偏与检偏</h3><p>偏振片：利用二向色性。有微晶型和分子型。</p>\n<p>线偏振光的起偏：通过偏振片。</p>\n<p>马吕斯定律：$A &#x3D; A_0 \\cos \\alpha, I &#x3D; I_0 \\cos^2 \\alpha$</p>\n<h3 id=\"反射与折射中的偏振\"><a href=\"#反射与折射中的偏振\" class=\"headerlink\" title=\"反射与折射中的偏振\"></a>反射与折射中的偏振</h3><p>S分量：垂直于入射面。P分量：平行于入射面。</p>\n<p>反射光S分量多，折射光P分量多。</p>\n<p>当$i &#x3D; i_0$使得反射光只有S分量，折射光大部分是P分量。称为布儒斯特角。$i_0 + r_0 &#x3D; 90\\degree$，因而有布儒斯特定律：$\\tg i_0 &#x3D; \\frac{n_2}{n_1}$</p>\n<p>玻璃片堆可以增强反射光的强度，增加折射光的偏振程度。</p>\n<p>散射引起光的偏振：</p>\n<p>微粒散射：丁达尔效应</p>\n<p>分子散射：纯净气体、液体的散射。</p>\n<p>双折射现象：</p>\n<p>1束光入射到各向异性介质内，产生2束折射光。o光为寻常光，符合折射定律；e光为非常光，不符合折射定律一般，也不一定在入射面内。o，e光都是线偏振光，振动方向互相垂直。</p>\n<p>晶体光轴：是晶体中的特殊方向，光在晶体中沿该方向传播不发生双折射。方解石是单轴晶体。云母是双轴晶体。</p>\n<p>主平面：晶体中光的传播方向与晶体光轴构成的平面。o光振动方向垂直于主平面，e的振动方向在主平面内。只有当光轴在入射面内，o光主平面、e光主平面、入射面才重合。</p>\n<p>折射角度不同的本质是不同角度下光的传播速度不同。据此区分正晶体和负晶体：</p>\n<p>$v_o$是o光速度，$v_e$是e光垂直光轴方向速度。o光是各向同性的，e光沿平行光轴方向的速度和o光相同，e光沿所有方向的速度构成一个旋转椭球面。</p>\n<p><img src=\"/../images/physics/shuangzheshe.jpg\"></p>\n<p>正晶体：$v_o &gt; v_e$</p>\n<p>负晶体：$v_o &lt; v_e$</p>\n<p>定义主折射率：$n_o &#x3D; c&#x2F;v_o, n_e &#x3D; c&#x2F;v_e$</p>\n<p>利用惠更斯作图法可以讨论单轴晶体的光传播情况：</p>\n<p>以负晶体为例。</p>\n<ul>\n<li>若光轴平行于晶体表面，自然光垂直入射：o和e方向相同，速度不同，仍然是双折射；</li>\n<li>光轴平行晶体表面，且垂直入射面，自然光斜入射：e光也满足折射定律，折射率为$n_e$；</li>\n<li>光轴与晶体表面斜交，自然光垂直入射：e光偏离入射方向，惠更斯波面是斜椭圆。</li>\n</ul>\n<p>研究晶片时，o光和e光（垂直振动和平行振动）是独立的正交的分量。垂直振动不会变成平行振动，平行振动也不会变成垂直振动。</p>\n<p>双折射：两个垂直方向的线偏振光的不同速度造成的。</p>\n<p>旋光：两个不同旋转方向的圆偏振光的不同速度造成的。</p>\n<h1 id=\"量子物理\"><a href=\"#量子物理\" class=\"headerlink\" title=\"量子物理\"></a>量子物理</h1><h2 id=\"黑体辐射\"><a href=\"#黑体辐射\" class=\"headerlink\" title=\"黑体辐射\"></a>黑体辐射</h2><p>热辐射</p>\n<p>物体受热发出电磁辐射。热辐射是连续谱，温度升高，短波成分增加。</p>\n<p>平衡热辐射：物体温度不变时产生的热辐射。单位时间内物体吸收能量等于辐射能量。</p>\n<p>光谱幅出度（单色幅出度）</p>\n<p>单位面积内单位频率发射的电磁波能量。</p>\n<div>$$\nM_\\nu = \\frac{\\mathrm d E_\\nu(T)}{\\mathrm d\\nu}\n$$</div>\n\n<p>总幅出度</p>\n<div>$$\nM(T) = \\int_0^\\infty M_\\nu(T)\\mathrm d\\nu\n$$</div>\n\n<p>单色吸收比</p>\n<div>$$\n\\alpha_\\nu(T) = \\frac{\\mathrm d E_{\\nu(吸收)}}{\\mathrm d E_{\\nu(入射)}}\n$$</div>\n\n<p>黑体</p>\n<p>能吸收所有频率的电磁波，没有反射。$\\alpha_{\\nu}&#x3D;1$。</p>\n<p>基尔霍夫辐射定律：</p>\n<div>$$\n\\frac{M_{\\nu i}}{\\alpha_{\\nu i}} = M_{\\nu 黑体}\n$$</div>\n\n<p>实验定律：</p>\n<p>维恩位移定律：$\\nu_m &#x3D; C_\\nu T$, $\\lambda_m &#x3D; b&#x2F;T$</p>\n<p>注：$\\lambda_m \\nu_m \\ne c$。</p>\n<p>斯特藩-玻尔兹曼定律：$M(T) &#x3D; \\sigma T^4$，$\\sigma$为斯特藩-玻尔兹曼常量。</p>\n<p>韦恩公式：低频段不符合；</p>\n<p>瑞利-金斯公式：高频段不符合。</p>\n<p>普朗克能量子假设：$\\varepsilon &#x3D; h\\nu$</p>\n<p>普朗克公式：</p>\n<div>$$\nM_\\nu(T) = \\frac{2\\pi h}{c^2}\\cdot \\frac{\\nu^3}{e^{h\\nu/kT} - 1}\n$$</div>\n\n<p>由它可以导出所有其他热辐射公式。</p>\n<h2 id=\"光电效应\"><a href=\"#光电效应\" class=\"headerlink\" title=\"光电效应\"></a>光电效应</h2><p>自学。</p>\n<h2 id=\"光的二象性\"><a href=\"#光的二象性\" class=\"headerlink\" title=\"光的二象性\"></a>光的二象性</h2><p>光子理论：能量$\\varepsilon &#x3D; h\\nu$。光强：$I &#x3D; N \\cdot h\\nu$，N是光子数流通量。</p>\n<p>解释光电效应：</p>\n<div>$$\n\\frac 12 mv_m^2 = h\\nu - A\n$$</div>\n\n<p>光的粒子性：</p>\n<div>$$\np = \\frac h \\lambda \\\\\nE = h\\nu \\\\\nm = \\frac{h\\nu}{c^2}\n$$</div>\n\n<p>解释干涉和衍射：</p>\n<p>光子在某处出现的概率是由该处的光强决定的：$I \\propto \\frac 1 {r^2}$，光子分布概率的不同导致了光强的不同。也就是说，光子的波动性表现为概率波。</p>\n<p>光子在某处出现的概率和该处光强（光振幅的平方）成正比。</p>\n<h2 id=\"康普顿散射\"><a href=\"#康普顿散射\" class=\"headerlink\" title=\"康普顿散射\"></a>康普顿散射</h2><p>散射波出现新的波长：$\\Delta \\lambda &#x3D; \\lambda_C(1 - \\cos\\varphi)$</p>\n<p>利用光子理论解释：光子和“静止”的“自由”电子碰撞过程动量守恒，能量守恒。</p>\n<p>解得$\\Delta \\lambda &#x3D; \\frac{h}{m_0c}(1 - \\cos \\varphi)$</p>\n<p>如果光子撞到内层电子，则能量不变，因而存在原波长。</p>\n<p>自由电子只能散射光子，不能吸收光子。如果吸收了，根据能量守恒和动量守恒，解得v&#x3D;c，违反了相对论。</p>\n<p>光电效应不考虑动量守恒，因为可见光、紫外线的能量低，电子不能视为自由，光子-电子不能视为动量守恒的系统。也因此，可见光观察不到康普顿效应。</p>\n<h2 id=\"概率波和概率幅\"><a href=\"#概率波和概率幅\" class=\"headerlink\" title=\"概率波和概率幅\"></a>概率波和概率幅</h2><p>物质波的本质：</p>\n<p>德布罗意认为是引导物质运动的“导波”；（本质不明确）</p>\n<p>薛定谔认为波是基本的，电子是“波包”；（波包是不稳定的，而电子是稳定的）</p>\n<p>另一个观点：粒子是基本的，物质波是电子相互作用形成的（被电子双缝实验否定）</p>\n<p>波恩的解释：物质波是描述粒子在空间概率分布的“概率波”。</p>\n<p>量子力学的基本假设之一：微观粒子的状态用波函数描述</p>\n<p>概率波波函数(概率幅)：复函数$\\Psi (\\vec r, t)$</p>\n<p>波函数没有直接的物理意义。复函数模的平方$|\\Psi (\\vec r, t)|^2$表示概率密度。</p>\n<p>波函数需要满足标准条件：</p>\n<p>有限性:$\\iiint_{\\Delta V}|\\Psi|^2 \\mathrm dV$有限</p>\n<p>归一性：$\\int_\\Omega |\\Psi(\\vec r, t)|^2 \\mathrm dV &#x3D; 1$</p>\n<p>单值性：波函数是单值函数。</p>\n<p>连续性：波函数和它的一阶导数是连续的。</p>\n<p>双缝的波函数：等于通过上缝和下缝的波函数的线性叠加。$\\Psi_{12}&#x3D;\\Psi_1+\\Psi_2$。(一个基本假设)</p>\n<p>微观粒子波动性实质是波函数的叠加性。</p>\n<p>结合测量理解。</p>\n<p>态叠加原理：$\\Psi &#x3D; \\sum_n C_n\\Psi_n$。其中$|C_n|^2$是该粒子处于$\\Psi_n$状态的概率。</p>\n<p>一维自由粒子的波函数：</p>\n<div>$$\n\\Psi(x, t) = A e^{i(px-Et)/\\hbar}\n$$</div>\n\n<p>概率密度$|\\Psi|^2 &#x3D; |A|^2 &#x3D; \\text {const.}$</p>\n<p>波粒二象性：</p>\n<p>粒子性：具有能量$E$和动量$\\vec p$。非经典粒子！没有轨道概念。</p>\n<p>波动性：具有波长$\\lambda$和频率$\\nu$。非经典波！非真实物理量的波动。</p>\n<h2 id=\"不确定关系\"><a href=\"#不确定关系\" class=\"headerlink\" title=\"不确定关系\"></a>不确定关系</h2><div>$$\n\\left<\\vec r|\\Psi\\right>\n$$</div>\n\n<p>不确定度：$\\Delta A &#x3D; \\sqrt{\\overline{(A - \\bar A)^2}}$</p>\n<p>坐标和动量的不确定性关系：</p>\n<div>$$\n\\Delta x \\cdot \\Delta p \\ge \\frac \\hbar 2\n$$</div>\n\n<p>因而微观粒子没有“轨道”。</p>\n<p>能量和时间的不确定性关系：</p>\n<div>$$\n\\Delta E \\cdot \\Delta t \\ge \\frac{\\hbar}{2}\n$$</div>\n\n<p>时间不是力学量，它只是一个参数。位置，动量，能量等都是力学量。</p>\n<h2 id=\"薛定谔方程\"><a href=\"#薛定谔方程\" class=\"headerlink\" title=\"薛定谔方程\"></a>薛定谔方程</h2><p>定义</p>\n<div>$$\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} = \\hat {H} \\Psi\n$$</div>\n\n<p>哈密顿算符：$\\bar {H} &#x3D; -\\frac{\\hbar ^2}{2m}\\nabla^2 + U(\\vec r, t)$</p>\n<p>若势函数不显含时间，则哈密顿算符$\\hat H$称为能量算符。此时薛定谔方程可以通过分离变量法求解。</p>\n<h3 id=\"定态薛定谔方程-能量本征方程\"><a href=\"#定态薛定谔方程-能量本征方程\" class=\"headerlink\" title=\"定态薛定谔方程-能量本征方程\"></a>定态薛定谔方程-能量本征方程</h3><p>分离变量法求解：</p>\n<p>若势函数不显含t，则可设：</p>\n<div>$$\n\\Psi(\\vec r, t) = \\Phi(\\vec r) \\cdot T(t)\n$$</div>\n\n<p>得到：</p>\n<div>$$\ni\\hbar \\frac{\\mathrm dT(t)}{\\mathrm d t}\\frac 1{T(t)} = [\\hat H\\Phi (\\vec r)]\\frac{1}{\\Phi(\\vec r)} = E\n$$</div>\n\n<div>$$\nT(t) = Ce^{-\\frac{i}{\\hbar}Et}\\\\\n()\n$$</div>\n\n<p>E称为能量本征值（后面会讲什么叫本征值），对应的$\\Phi_E$称为本征波函数。</p>\n<p>定态：能量取确定值的状态，对应薛定谔方程的特解：$\\Psi_E(\\vec r, t) &#x3D; \\Phi e^{-\\frac{i}{\\hbar}Et}$.</p>\n<p>对不同的势函数和能量区间，能量的本征值可能取连续的值，也可能取分立的值。设E取分立值，${E_n, n &#x3D; 1, 2, 3, \\dots}$，对应的本征波函数$\\Psi_E (\\vec r, t) &#x3D; \\Phi_E(\\vec r)e^{-\\frac{i}{\\hbar}Et}$</p>\n<p>下面通过求解一维定态薛定谔方程来讨论两类问题：</p>\n<p>本征值问题：给定$U(x)$，求$E_n$和$\\Phi_n(x)$。</p>\n<p>散射问题：$E$已知，射向势垒$U(x)$，计算粒子穿透势垒的概率。 </p>\n<h2 id=\"无限深方势阱中的粒子\"><a href=\"#无限深方势阱中的粒子\" class=\"headerlink\" title=\"无限深方势阱中的粒子\"></a>无限深方势阱中的粒子</h2><p>背景：长度为$a$的导体中自由移动的电子，只能在导体中自由运动，而不能离开导体。</p>\n<p>$|x| &gt; a&#x2F;2$时，$U(x) \\rightarrow \\infty$；</p>\n<p>$|x| \\le a&#x2F;2$时，$U(x) &#x3D; 0$。</p>\n<p>在$|x| &gt; a&#x2F;2$区间，$\\Phi_1 &#x3D; 0$。</p>\n<p>在$|x| \\le  a&#x2F;2$区间，$\\frac{\\mathrm d^2 \\Phi_2}{\\mathrm dx^2} + \\frac{2mE}{\\hbar^2}\\Phi_2 &#x3D; 0$</p>\n<p>记$k &#x3D; \\frac{2mE}{\\hbar^2}$。解得$\\Phi_2 &#x3D; A\\sin(kx + \\varphi)$。</p>\n<p>求解定态的常规手法：利用波函数的三个条件，即单值、有限、连续，确定$A, k, \\varphi$。</p>\n<p>利用连续条件，波函数在势阱边界处连续：</p>\n<div>$$\nA\\sin(\\frac{ka}{2} + \\varphi) = 0, A\\sin(-\\frac{ka}{2} + \\varphi) = 0.\\\\\n\n<p>\\Rightarrow k &#x3D; \\frac{n\\pi}{a}, \\varphi &#x3D; \\frac{l\\pi}{2}<br>$$</div></p>\n<p>从而</p>\n<div>$$\nE = \\frac{\\pi^2\\hbar^2}{2ma^2}n^2 \\ (n = 1, 2, 3, \\dots)\n$$</div>\n\n<p>最低能量$E_1$被称为零点能。</p>\n<p>大量子数情况下，能量趋向于连续。</p>\n<div>$$\nl = 0, \\varphi = 0, \\Phi_2 = A\\sin \\frac{n\\pi}{a}x = \\Phi_{on},满足边界连续需要n为偶数\\\\\nl = 1, \\varphi =\\pi /2 , \\Phi_2 = A\\cos \\frac{n\\pi}{a}x = \\Phi_{en},满足边界连续需要n为奇数\\\\\nl \\ge 2，只差个符号，不影响|\\Phi|^2，不再考虑。\n$$</div>\n\n<p>求$A$：</p>\n<p>归一化：$\\int_{-a&#x2F;2}^{a&#x2F;2}|\\Phi_{on}|^2 \\mathrm dx &#x3D; 1$， 得到$A &#x3D; \\sqrt \\frac2a$</p>\n<div>$$\n\\Phi_{on} = \\sqrt{\\frac 2a}\\sin \\frac{n\\pi}{a}x, n = 2, 4, 6, \\dots\\\\\n\\Phi_{en} = \\sqrt{\\frac 2a}\\cos\\frac{n\\pi}{a}x, n = 1, 3, 5, \\dots\n$$</div> \n\n<p>定态：</p>\n<div>$$\n\n<p>\\Psi_n (x, t) &#x3D; \\Phi_n(x) \\cdot e^{-\\frac i\\hbar Et}</p>\n<p>$$</div></p>\n<p>被称为驻波解(时间项指数为纯虚数，展开可以写成三角函数)。概率密度$|\\Psi_n(x, t)|^2 &#x3D; |\\Phi_n(x)|^2$</p>\n<h2 id=\"势垒穿透\"><a href=\"#势垒穿透\" class=\"headerlink\" title=\"势垒穿透\"></a>势垒穿透</h2><h3 id=\"粒子进入势垒\"><a href=\"#粒子进入势垒\" class=\"headerlink\" title=\"粒子进入势垒\"></a>粒子进入势垒</h3><p>背景：金属与半导体接触处，势能隆起形成势垒。粒子以能量为$E(E &lt; U_0)$的状态自由入射。</p>\n<div>$$\nU(x) = 0, x \\le 0;\\\\\nU(x) = U_0, x \\gt 0.\n$$</div>\n\n<p>量子力学认为有一部分粒子会穿透势垒。不仅有反射，还有投射。</p>\n<p>定态薛定谔方程：</p>\n<div>$$\n\\Phi^{\\prime\\prime}(x) + \\frac{2m}{\\hbar^2}(E - U(x))\\Phi(x) = 0\n$$</div>\n\n<p>$x \\le 0$: </p>\n<div>$$\nk_1 = \\sqrt{2mE/\\hbar^2} > 0\\\\\n\\Psi_1^{\\prime\\prime} + k_1^2 \\Psi_1 = 0\n$$</div>\n\n<p>$x \\gt 0$:</p>\n<div>$$\nik_2 = \\sqrt{2m(E - U_0)/\\hbar^2} (k_2 > 0)\\\\\n\\Psi_2^{\\prime\\prime} + (ik_2)^2\\Psi_2 = 0\n$$</div>\n\n<p>通解（利用了$x\\rightarrow\\infty$时$\\Psi_2$的有界性）：</p>\n<div>$$\n\\Psi_1(x) = Ae^{ik_1x} + Be^{-k_1x}(表现为入射和反射波)\\\\\n\\Psi_2(x) = Ce^{k_2x}(表现为透射波)\n$$</div>\n\n<p>粒子可以出现在势垒区！表现为电子溢出金属表面，形成金属表面的一层电子气。</p>\n<p>势垒区的概率密度：$|\\Psi_2(x)|\\propto e^{-\\frac{2x}{\\hbar}\\sqrt{U_0 - E}}$</p>\n<p>波可以穿过有限宽势垒，以平面波的形式继续前进。称为量子隧穿效应。<br>$\\Psi_3(x) &#x3D; Se^{i\\frac {\\sqrt{2mE}}{\\hbar} x}$</p>\n<p>扫描隧道显微镜：原理是量子隧穿效应，可以用来观测物质表面结构。</p>\n<p><img src=\"/../images/physics/STM.jpg\"></p>\n<div>$$\ni \\propto Ue^{-C\\sqrt{\\varPhi}d}\n$$</div>\n\n<p>$\\varPhi$为样品表面平均势垒高度。</p>\n<h2 id=\"一维谐振子\"><a href=\"#一维谐振子\" class=\"headerlink\" title=\"一维谐振子\"></a>一维谐振子</h2><div>$$\nU(x) = \\frac 12 kx^2 = \\frac 12m\\omega^2x^2, \\omega = \\sqrt{\\frac km}\n$$</div>\n\n<p>求解定态薛定谔方程得到</p>\n<div>$$\nE_n = (n + \\frac 12)\\hbar \\omega = (n + \\frac 12)h\\nu\n$$</div>\n零点能：$\\frac{h\\nu}{2}$。间距：$h\\nu$。能量本征函数不用记。\n\n<p>定态概率密度：</p>\n<p>经典情况下：平衡位置处$\\vec v$最大，停留时间最短，出现概率最小，振幅最大的时候$\\vec v$为0，出现概率最大。量子数n趋于无穷时，量子概率分布趋于经典概率分布。</p>\n<p>如果$E&lt; U$，隧穿效应仍然存在。</p>\n<h2 id=\"力学量算符\"><a href=\"#力学量算符\" class=\"headerlink\" title=\"力学量算符\"></a>力学量算符</h2><p>以位矢$\\vec r$为自变量的空间，称为“坐标表象”。在坐标表象中，动量和位矢不存在对应关系$\\vec p &#x3D; \\vec p(\\vec r)$（不确定关系）。</p>\n<p>量子力学将动量、角动量、能量等力学量“算符化”。力学量算符是量子力学的一个基本假设。</p>\n<h3 id=\"力学量算符的引入\"><a href=\"#力学量算符的引入\" class=\"headerlink\" title=\"力学量算符的引入\"></a>力学量算符的引入</h3><p>定义能量算符$\\hat {E} \\equiv i\\hbar \\frac{\\partial}{\\partial t}$，与表象无关。</p>\n<p>坐标表象中定义动量算符$\\hat{\\vec p} &#x3D; -i\\hbar\\nabla$，坐标算符$\\hat{\\vec r} &#x3D; r$。</p>\n<p>由于坐标表象下坐标算符就是坐标，因此势能算符$\\hat{U} &#x3D; U(\\vec r)$。动能算符$\\hat{E_k} &#x3D; \\frac{(-i\\hbar\\nabla)\\cdot (-i\\hbar\\nabla)}{2m} &#x3D; -\\frac{\\hbar^2}{2m}\\nabla^2$</p>\n<p>角动量算符$\\hat{\\vec L} &#x3D; \\hat{\\vec r}\\times \\hat{\\vec p} &#x3D; -i\\hbar\\vec r \\times \\nabla$。如果用球极坐标，可得$\\hat{L_z} &#x3D; -i\\hbar \\frac{\\partial}{\\partial \\varphi}$。角动量算符的模方由极角和方位角的导数组成：$\\hat{L}^2 &#x3D; -\\frac {\\hbar^2}{\\sin \\theta}\\frac{\\partial}{\\partial \\theta}(\\sin \\theta\\frac{\\partial}{\\partial \\theta})  +\\frac{\\hat{L_z^2}}{\\sin^2\\theta}$</p>\n<h3 id=\"本征值和本征函数\"><a href=\"#本征值和本征函数\" class=\"headerlink\" title=\"本征值和本征函数\"></a>本征值和本征函数</h3><p>本征方程：$\\hat{A}\\Psi_n &#x3D; A_n\\Psi_n$。其中$A_n$为本征值，$\\Psi_n$是$A$取$A_n$时的本征态，称为本征函数。</p>\n<p>本征值就是相应力学量的可能取值。</p>\n<p>$\\hat A$的本征函数系${\\Psi_n}$构成正交、归一的完备函数系。一维情况的归一化：$\\int_{-\\infty}^{+\\infty}\\Psi_n^*(x)\\Psi_n(x)\\mathrm dx &#x3D; 1$。正交性：$\\int_{-\\infty}^{+\\infty}\\Psi_m(x)\\Psi_n(x)\\mathrm d x &#x3D; \\delta_{mn}$.</p>\n<p>本征函数的完备性：在相同的函数空间内，任一物理上合理的归一化波函数，都可以由力学量A的本征函数系线性展开，即$\\Psi &#x3D; \\sum_{n}C_n(t)\\Psi_n(x)$。</p>\n<h3 id=\"态叠加原理：\"><a href=\"#态叠加原理：\" class=\"headerlink\" title=\"态叠加原理：\"></a>态叠加原理：</h3><p>线性展开公式：</p>\n<div>$$\n\\Psi(x, t) = \\sum_{n }C_n(t)\\Psi_n(x) \\ (假设是归一化的)\n$$</div>\n\n<p>基本假设之一。</p>\n<h3 id=\"力学量的测量原理\"><a href=\"#力学量的测量原理\" class=\"headerlink\" title=\"力学量的测量原理\"></a>力学量的测量原理</h3><p>量子力学假设：在$\\Psi(x,t)$态上测量$A$，则$\\Psi(x, t)$一定向着$A$的某个本征态$\\Psi_n$塌缩，测量结果为$A_n$。</p>\n<p>特别地，如果$\\Psi &#x3D; \\Psi_n$，则测量结果是确定的，为$A_n$。</p>\n<p>测量结果中$A_n$出现的概率为$|C_n(t)|^2$。</p>\n<div>$$\n\\bar A = \\sum_n |C_n(t)|^2A_n = \\int_{-\\infty}^{+\\infty}\\Psi^*(x, t)\\hat A\\Psi(x, t)\\mathrm dx\n$$</div>\n\n\n<h2 id=\"Dirac符号\"><a href=\"#Dirac符号\" class=\"headerlink\" title=\"Dirac符号\"></a>Dirac符号</h2><h3 id=\"量子态\"><a href=\"#量子态\" class=\"headerlink\" title=\"量子态\"></a>量子态</h3><p>本征值离散的：$\\ket{n}$</p>\n<p>本征值是连续的：$\\ket{P_x}, \\ket{x}$</p>\n<p>它们各自张开一个线性空间。</p>\n<h3 id=\"内积空间\"><a href=\"#内积空间\" class=\"headerlink\" title=\"内积空间\"></a>内积空间</h3><p>左矢与右矢一一对应，左矢张开一个共轭线性空间。</p>\n<p>$\\ket{A}$和$\\ket{B}$的内积(复内积)：$\\langle B|A\\rangle$</p>\n<p>左矢空间与右矢空间通过复内积练习，称为内积空间。</p>\n<h3 id=\"线性算符\"><a href=\"#线性算符\" class=\"headerlink\" title=\"线性算符\"></a>线性算符</h3><div>$$\n\\hat{L}\\ket{A} = \\ket{B}\n$$</div>\n\n<p>满足：</p>\n<ul>\n<li><p>$\\hat L (\\ket{A} + \\ket {B}) &#x3D; \\hat L\\ket{A} + \\hat L\\ket{B}$</p>\n</li>\n<li><p>$(\\hat F + \\hat G)\\ket{A} &#x3D; \\hat F \\ket{A} + \\hat G\\ket{A}$</p>\n</li>\n<li><p>$\\hat F(\\hat G \\ket{A}) &#x3D; (\\hat F \\cdot \\hat G)\\ket {A}$</p>\n</li>\n</ul>\n<p>共轭算符：$\\bra{A}\\bar{\\hat L}$与$\\hat L \\ket{A}$一一对应，将$\\bar{\\hat L}$或者$\\hat L ^+$称为共轭算符。</p>\n<p>厄米算符：$\\bar {\\hat L} &#x3D; \\hat L$。</p>\n<p>算符是向右结合的。</p>\n<h3 id=\"算符本征方程\"><a href=\"#算符本征方程\" class=\"headerlink\" title=\"算符本征方程\"></a>算符本征方程</h3><div>$$\n\\hat L \\ket{L_n} = l_n\\ket{L_n}\\\\\n\n<p>\\hat L\\ket{n} &#x3D; l_n\\ket{n}<br>$$</div></p>\n<p>$l_n$是本征值，$L_n$是本征态。</p>\n<p>由测量原理，本征值必须是实数。所以可以观测的力学量对应的算符都是厄米算符。</p>\n<h3 id=\"态叠加原理\"><a href=\"#态叠加原理\" class=\"headerlink\" title=\"态叠加原理\"></a>态叠加原理</h3><p>离散谱：</p>\n<div>$$\n\\bra{m}n\\rangle = \\delta_{mn}\\\\\n\\ket{\\psi} = \\sum_n C_n\\ket{n}\\\\\n概率幅：\\bra{m}\\psi \\rangle = C_m\\\\\n\\ket{A} = \\sum_{n}(\\bra{n}A\\rangle)\\ket{n} = \\left(\\sum_n \\ket{n}\\bra{n}\\right)\\ket{A}\\\\\n\\Rightarrow \\sum_n \\ket{n}\\bra{n}=1(本征矢的完备性表示)\n$$</div>\n\n<p>连续谱：</p>\n<div>$$\n\\bra{x_0^\\prime}x_0\\rangle = \\delta(x_0^\\prime - x_0)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}C(x_0)\\ket{x_0}\\mathrm dx_0 \\\\\n概率幅：\\bra{x_0^\\prime}\\psi\\rangle = C(x_0^\\prime)\\\\\n\\ket{\\psi} = \\int_{-\\infty}^{\\infty}\\bra{x_0}\\psi\\rangle\\ket{x_0}\\mathrm dx_0 = \\left(\\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0\\right)\\ket{\\psi}\\\\\n\\Rightarrow \\int_{-\\infty}^{\\infty}\\ket{x_0}\\bra{x_0}\\mathrm dx_0 = 1(连续谱的完备性方程)\n$$</div>\n\n<p>注：$C(x_0) &#x3D; \\bra{x_0}\\psi\\rangle$就是波函数$\\psi(x_0)$。$|\\bra{x_0}\\psi\\rangle|^2 &#x3D; |\\psi(x_0)|^2 &#x3D; \\psi^*(x_0)\\psi(x_0)$是概率密度。</p>\n<h3 id=\"正则量子化假设\"><a href=\"#正则量子化假设\" class=\"headerlink\" title=\"正则量子化假设\"></a>正则量子化假设</h3><p>对易关系：$[\\hat A, \\hat B]&#x3D; \\hat A\\hat B - \\hat B\\hat A$，若$[\\hat A , \\hat B]&#x3D;0$，则称$A$与$B$对易，否则称不对易。</p>\n<p>正则量子化假设：</p>\n<div>$$\n[\\hat{x}, \\hat{p_x}] = i\\hbar,\n[\\hat{y}, \\hat{p_y}] = i\\hbar, \n[\\hat{z}, \\hat{p_z}] = i\\hbar\n$$</div>\n\n<p>其余$x, y, z, p_x, p_y, p_z$的组合均对易。</p>\n<p>满足$\\hat{\\vec A}\\times \\hat{\\vec A} &#x3D; i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L &#x3D; \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。</p>\n<p>$\\hat A$和$\\hat B$可以同时测准的充分必要条件：</p>\n<div>$$\n[\\hat A, \\hat{B}] = 0\\Leftrightarrow 有共同本征态\n$$</div>\n\n<p>简并：1个本征值对应m个量子态,称为m重简并。</p>\n<p>产生简并的原因：对称性&#x3D;&gt;守恒量。</p>\n<p>如果$\\hat A$是m重简并的，只测量得到本征值A，无法确定对应的量子态。但是如果同时测量对易的$\\hat B$，就可以确定对应的$|A, B_i\\rangle$，则对应的A的量子态是$|A_i\\rangle$。</p>\n<p>力学量完全集：能完备描述、确定量子态的力学量算符必须包含$\\hat H$。</p>\n<p>$\\hat H$是核心力学量。</p>\n<div>$$\n[\\hat A, \\hat H]=0\\Leftrightarrow \\hat A是守恒量\n$$</div>\n选择力学量的完全集，就是选择守恒量的完全集。\n\n<h2 id=\"原子中的电子\"><a href=\"#原子中的电子\" class=\"headerlink\" title=\"原子中的电子\"></a>原子中的电子</h2><h3 id=\"氢原子理论\"><a href=\"#氢原子理论\" class=\"headerlink\" title=\"氢原子理论\"></a>氢原子理论</h3><p>巴耳末公式-&gt;里德伯方程-&gt;波尔氢原子理论</p>\n<p>氢原子理论：</p>\n<p>定态条件</p>\n<p>电子绕核作圆周运动，有确定能量，不辐射能量-经典轨道+定态</p>\n<p>频率条件</p>\n<p>电子在定态之间跃迁满足：$\\nu &#x3D; (E_i - E_f)&#x2F;h$</p>\n<p>轨道角动量：$L_n &#x3D; mv_nr_n &#x3D; n\\hbar$，轨道半径$r_n &#x3D; n^2r_1$</p>\n<p>能级公式：$E_n &#x3D; -13.6eV&#x2F;n^2$</p>\n<p>类氢离子能级：核外只有一个电子，核电荷数大于1.例如$He^+, Li^{2+}$</p>\n<p>评价：</p>\n<p>波尔理论解释了氢原子和类氢离子光谱的波长和频率。</p>\n<p>但是不能解释氢原子的光谱线强度，也不能解释其他原子的光谱结构。</p>\n<ul>\n<li>与经典电磁理论矛盾</li>\n<li>角动量量子化条件是硬加的</li>\n<li>卢瑟福的质疑：电子知道要往$E_2$跳才能往$E_2$跳，但是又必须先跳过去才能知道要往$E_2$跳</li>\n<li>薛定谔的非难：当电子离开$E_1$态之后，进入$E_2$态之前，它在哪里，是什么状态？</li>\n</ul>\n<p>轨道概念不再适用。定态、能级、跃迁频率条件、角动量量子化仍然被认为是正确的。</p>\n<h3 id=\"氢原子的量子力学处理\"><a href=\"#氢原子的量子力学处理\" class=\"headerlink\" title=\"氢原子的量子力学处理\"></a>氢原子的量子力学处理</h3><p>求解量子问题的要点之一：确定体系的力学量完全集，即力学量可以同时测准，具有共同本征态，相应量子数集可完备地描述体系状态。</p>\n<p>通常选择守恒量完全集，和体系对称性有关。</p>\n<p>氢原子问题的守恒量完全集：$\\hat H, \\hat L^2, \\hat L_z$</p>\n<p><strong>角动量量子化：</strong></p>\n<p>处于中心力场的氢原子电子，角动量守恒。</p>\n<p>求$\\hat  L_z$的本征值：</p>\n<div>$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\\\\\n\n<p>\\hat L_z \\varPhi &#x3D; L_z \\varPhi\\Rightarrow \\varPhi &#x3D; Ae^{\\frac{i}{\\hbar}L_z\\varphi}<br>$$</div></p>\n<p>根据标准条件（周期性），$\\varPhi(\\varphi) &#x3D; \\varPhi(\\varphi + 2\\pi)$，带入解得$L_z &#x3D; m_l\\hbar$，$m_l &#x3D; 0, \\pm1, \\pm2,\\dots$称为磁量子数。</p>\n<p>对应的本征函数：$\\varPhi_{m_l}(\\varphi) &#x3D; Ae^{im_l\\varPhi} &#x3D; \\frac{1}{\\sqrt{2\\pi}}e^{im_l\\varphi}$</p>\n<p>求$\\hat L^2$的本征值：</p>\n<p>结论：$L^2 &#x3D; l(l+1)\\hbar^2$，$l &#x3D; 0, 1, 2, \\dots$称为角量子数。</p>\n<p>（$\\hat L^2$和$\\hat L_z$具有的共同本征值为球谐函数$Y_{ml}(\\theta, \\varphi)$）</p>\n<p>角动量的空间量子化</p>\n<p>$L &#x3D; \\sqrt{l(l+1)}\\hbar &gt; L_z &#x3D; m_l\\hbar \\Rightarrow m_l &#x3D; 0, \\pm1, \\pm2,\\dots, \\pm l$。作矢量图可知，角动量有$2l+1$种取向。</p>\n<p><strong>能量量子化</strong></p>\n<p>(省略公式)</p>\n<p>$l &#x3D; 0, 1, \\dots, n - 1$</p>\n<p>$\\hat H, \\hat L^2, \\hat L_z$的共同本征态就是定态。</p>\n<p>能量的本征值只与主量子数n有关，因而出现了能量简并，不同的角量子数和磁量子数可以对应相同的能量本征值。同能量的本征值态称为能级简并态，包含的态数目称为能级简并度。</p>\n<p>角量子数$l &#x3D; 0, 1, 2…$对应的状态分别称为$s, p, d…$，从概率波图像可以看出，角量子数低的电子更容易靠近原子中心。</p>\n<h3 id=\"电子自旋\"><a href=\"#电子自旋\" class=\"headerlink\" title=\"电子自旋\"></a>电子自旋</h3><p>轨道角动量产生磁矩：</p>\n<div>$$\n\\hat{\\vec \\mu} = -\\frac{e}{2m_e}\\hat{\\vec L}\n$$</div>\n\n<p>玻尔磁子：</p>\n<div>$$\n\\mu_B = \\frac{e\\hbar}{2m_e}\n$$</div>\n\n<p>利用本征值的定义不难推出z方向的磁矩：</p>\n<div>$$\n\\mu_z = -m_l \\cdot \\mu_B\n$$</div>\n\n<p>斯特恩-盖拉赫实验</p>\n<p>理论分析：</p>\n<p>磁矩在外磁场中有势能：$E &#x3D; -\\vec \\mu \\cdot \\vec B$</p>\n<p>轨道磁矩在z方向受力：</p>\n<div>$$\nF_z = \\frac{\\partial E}{\\partial z} = \\mu_z\\frac{\\partial B_z}{\\partial z} = -m_l\\mu_B\\frac{\\partial B_z}{\\partial z}\n$$</div>\n\n<p>由于$m_l$的$2l+1$种取值，对应的原子束应该在z方向上分裂成奇数条线。</p>\n<p><img src=\"/source/images/physics/abaaba.jpg\"></p>\n<p>问题：$Ag, H$等原子束($l &#x3D; 0$)出现了2条线而不是一条线，矛盾。</p>\n<p>电子自旋的假设：</p>\n<ul>\n<li>电子不是质点，而是自旋的小球，具有固有的自旋角动量$\\vec S$和自旋磁矩$\\vec \\mu_S$</li>\n<li>$S &#x3D; \\sqrt{s(s+1)}\\hbar$，其中$s &#x3D; \\frac 12$称为自旋量子数</li>\n<li>$S_z &#x3D; m_s\\hbar$，$m_s &#x3D; \\pm\\frac 12$，称为自旋磁量子数</li>\n<li>自旋磁矩和自旋角动量满足$\\hat {\\vec \\mu_S} &#x3D; -\\frac{e}{m_e}\\hat {\\vec S}$，进而推出$\\mu_{S,z}&#x3D;\\pm \\mu_B$</li>\n</ul>\n<p>“自转小球”模型仍存在缺陷：电子表面的速度会超过光速。</p>\n<p>但是这些假设成功解释了原子光谱的精细结构和反常塞曼效应。</p>\n<p>量子力学的解释：</p>\n<ul>\n<li>自旋是与时空无关的内禀运动，一种新的自由度，一种新的角动量，无经典对应</li>\n<li>自旋、磁矩和静止质量、电荷一样，是反映微观粒子固有属性的基本量</li>\n<li>电子的自旋是一种相对论效应，被自动地包含在相对论波动方程(Dirac方程)中。</li>\n</ul>\n<p>电子的总角动量：</p>\n<div>$$\n\\hat {\\vec J} = \\hat {\\vec L} + \\hat {\\vec S}\n$$</div>\n\n<p>$\\hat {\\vec J}$也是量子化的，大小为：</p>\n<div>$$\nJ = \\sqrt{j(j + 1)}\\hbar\n$$</div>\n\n<p>前文已说过如下定义：</p>\n<blockquote>\n<p>满足$\\hat{\\vec A}\\times \\hat{\\vec A} &#x3D; i\\hbar \\hat{\\vec A}$的算符被称为角动量。所有的角动量算符都满足这个关系。例如$\\hat L &#x3D; \\hat r\\times \\hat p$，可以利用正则量子化假设对三个坐标进行计算验证。</p>\n</blockquote>\n<p>可以验证$\\hat {\\vec J }\\times \\hat {\\vec J } &#x3D; i\\hbar \\hat {\\vec J }$。因此总角动量还是角动量。</p>\n<p>这一角动量的合成被称为自旋——轨道耦合。$j$称为总角动量量子数。</p>\n<div>$$\nl = 0: \n\\\\\nj = s = \\frac 12, m_j = -\\frac 12, +\\frac 12\\\\\nl \\ne 0:\\\\\nj = l + s = l + \\frac 12, m_j = -(l + \\frac 12), \\dots, l + \\frac 12;\\\\\nj = l - s = l - \\frac 12, m_j = -(l - \\frac12), \\dots, l - \\frac12\n$$</div>\n\n<p>碱金属原子光谱：</p>\n<p>碱金属的原子能级既和$n$有关，又和$l$有关。</p>\n<p>轨道角动量对原子的影响包括轨道贯穿和原子实极化，导致相应能级能量降低。</p>\n<p>因此原来相同能级的$3s,3p,…$会分裂成不同能级的轨道。</p>\n<p>碱金属原子光谱的精细结构：</p>\n<p>电子的轨道运动会使得它感受到原子绕它转动的磁场$\\vec B_{Nuc}$的作用。</p>\n<p>电子自旋磁矩$\\vec \\mu_s$和$\\vec B_{Nuc}$的相互作用就是自旋轨道耦合，是相对论效应。</p>\n<p>于是能级在自旋轨道耦合的影响下进一步分裂，形成了能级精细结构。</p>\n<h3 id=\"微观粒子全同性原理\"><a href=\"#微观粒子全同性原理\" class=\"headerlink\" title=\"微观粒子全同性原理\"></a>微观粒子全同性原理</h3><p>两个微观粒子的全部内禀属性相同称为全同粒子。对调全同粒子不会影响系统的状态。</p>\n<p>数学上对应地表现为波函数模方相同，进而有波函数对称或者反对称。</p>\n<p>对称的波函数表达式：</p>\n<div>$$\n\\psi(q_1, q_2) = \\frac {1}{\\sqrt 2}[\\phi_A(q_1)\\phi_B(q_2) + \\phi_A(q_2)\\phi_B(q_1)]\n$$</div>\n\n<p>反对称的波函数表达式：</p>\n<div>$$\n\\psi(q_1, q_2) = \\frac{1}{\\sqrt{2}}[\\phi_A(q_1)\\phi_B(q_2) - \\phi_A(q_2)\\phi_B(q_1)]\n$$</div>\n\n<p>如果$\\phi_A&#x3D;\\phi_B$，则反对称波函数为0。</p>\n<p>费米子是自旋为半整数的粒子。它是波函数反对称的粒子。由此得到泡利不相容原理：全同费米子系统不能有两个及以上的费米子占据同一单粒子态。</p>\n<p>玻色子是自旋为0或者整数的粒子。它是波函数对称的粒子。玻色子不受泡利不相容原理的限制。</p>\n<p>费米统计：</p>\n<div>$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} + 1}\n$$</div>\n\n<p>$\\mu &#x3D; \\mu(T)$是粒子化学势。</p>\n<p>玻色统计：</p>\n<div>$$\nN(E) = \\frac{1}{e^{(E - \\mu)/kT} - 1}\n$$</div>\n\n<p>对所有温度T,$0\\le N(E)\\lt \\infty$。</p>\n<p>玻色-爱因斯坦凝聚。</p>\n<p>当$E$很高时，$(E - \\mu) &gt;&gt; kT$。退化为麦克斯韦-玻尔兹曼统计。</p>\n<h3 id=\"原子核外电子的排布\"><a href=\"#原子核外电子的排布\" class=\"headerlink\" title=\"原子核外电子的排布\"></a>原子核外电子的排布</h3><p>4个量子数$n,l,m_l,m_s$可以完备描述原子的电子运动状态。</p>\n"},{"title":"大雾习题笔记","date":"2022-10-04T11:12:17.000Z","_content":"\n# 热学\n\n***气体压强越小，理想气体状态方程就越准确。***\n\n![](../images/physics/Exer9.29.jpg)\n\n***双原子分子的压强公式是$2n\\bar\\varepsilon_k/5$吗***\n\n无论分子有多少个原子，根据统计理论推算微观压强公式都应该是$p = 2n\\bar\\varepsilon_t/3$。原因是微观压强公式只考虑平动动能，不考虑转动和振动动能（显然转动和振动不会对压强造成影响）。而$\\bar\\varepsilon_k = \\bar\\varepsilon_t + \\bar\\varepsilon_r + \\bar\\varepsilon_v$。","source":"_posts/PhysicsExercise.md","raw":"---\ntitle: 大雾习题笔记\ndate: 2022-10-04 19:12:17\ntags: note\n---\n\n# 热学\n\n***气体压强越小，理想气体状态方程就越准确。***\n\n![](../images/physics/Exer9.29.jpg)\n\n***双原子分子的压强公式是$2n\\bar\\varepsilon_k/5$吗***\n\n无论分子有多少个原子，根据统计理论推算微观压强公式都应该是$p = 2n\\bar\\varepsilon_t/3$。原因是微观压强公式只考虑平动动能，不考虑转动和振动动能（显然转动和振动不会对压强造成影响）。而$\\bar\\varepsilon_k = \\bar\\varepsilon_t + \\bar\\varepsilon_r + \\bar\\varepsilon_v$。","slug":"PhysicsExercise","published":1,"updated":"2024-03-19T06:01:16.160Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhx000grsugc4mdblt2","content":"<h1 id=\"热学\"><a href=\"#热学\" class=\"headerlink\" title=\"热学\"></a>热学</h1><p><em><strong>气体压强越小，理想气体状态方程就越准确。</strong></em></p>\n<p><img src=\"/../images/physics/Exer9.29.jpg\" loading=\"lazy\"></p>\n<p><em><strong>双原子分子的压强公式是$2n\\bar\\varepsilon_k&#x2F;5$吗</strong></em></p>\n<p>无论分子有多少个原子，根据统计理论推算微观压强公式都应该是$p &#x3D; 2n\\bar\\varepsilon_t&#x2F;3$。原因是微观压强公式只考虑平动动能，不考虑转动和振动动能（显然转动和振动不会对压强造成影响）。而$\\bar\\varepsilon_k &#x3D; \\bar\\varepsilon_t + \\bar\\varepsilon_r + \\bar\\varepsilon_v$。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"热学\"><a href=\"#热学\" class=\"headerlink\" title=\"热学\"></a>热学</h1><p><em><strong>气体压强越小，理想气体状态方程就越准确。</strong></em></p>\n<p><img src=\"/../images/physics/Exer9.29.jpg\"></p>\n<p><em><strong>双原子分子的压强公式是$2n\\bar\\varepsilon_k&#x2F;5$吗</strong></em></p>\n<p>无论分子有多少个原子，根据统计理论推算微观压强公式都应该是$p &#x3D; 2n\\bar\\varepsilon_t&#x2F;3$。原因是微观压强公式只考虑平动动能，不考虑转动和振动动能（显然转动和振动不会对压强造成影响）。而$\\bar\\varepsilon_k &#x3D; \\bar\\varepsilon_t + \\bar\\varepsilon_r + \\bar\\varepsilon_v$。</p>\n"},{"title":"Speech-SP","katex":true,"date":"2024-02-28T11:24:02.000Z","_content":"## 语音信号的线性预测编码技术\n\n线性预测编码技术（维纳滤波）。可以参考隔壁统计信号处理的笔记hh。\n\n维纳滤波的正交原理：\n\n$$\nE \\langle x(n-k), e(n) \\rangle = 0\n$$\n\n正交原理可以用来估计任何时候的任何值，不管是现在（滤波），过去（平滑）还是未来（预测），也不管估计的对象是 $x,y$，上述公式的含义是：估计误差始终与已知信号垂直，与估计的是哪个时间的信号无关。\n\n利用前面的 $P$ 个信号预测下一个信号：\n\n$$\n\\hat{s}(n)=-\\sum_{i=1}^{P^{\\prime}}\\hat{\\alpha}_i\\cdot s(n-i)\n$$\n\n误差定义为\n\n$$\n\\begin{aligned}\n\\varepsilon(n)& =s(n)-\\overset{\\wedge}{\\operatorname*{s}}(n)=s(n)+\\sum_{i=1}\\widehat{\\alpha}_i\\cdot s(n-i)  \\\\\n&=\\sum_{i=0}^{P^{\\prime}}\\widehat{\\alpha}_i\\cdot s(n-i)\n\\end{aligned}\n$$\n\n从 z 域看，这是一个全极点模型产生了目标信号：\n\n$$\nS(z) = -S(z)\\sum\\limits_{i=1}^{P}\\alpha_iz^{-i} + E(z)\n$$\n\n接下来的所有步骤，目的都是推导 $\\alpha$ 的取值。\n\n### 自相关法\n\n本文中假设信号具有遍历性，即时间平均等于统计平均，时间上的自相关等于统计意义上的自相关。\n\n利用 LMMSE 准则可以推出\n\n$$\n\\begin{bmatrix}R(0)&R(1)&R(2)&\\cdots&R(P-1)\\\\R(1)&R(0)&R(1)&\\cdots&R(P-2)\\\\R(2)&R(1)&R(0)&\\cdots&R(P-3)\\\\\\vdots&\\vdots&&&\\vdots\\\\R(P-1)&R(P-2)&\\cdots&\\cdots&R(0)\\end{bmatrix}\\cdot\\begin{bmatrix}\\hat\\alpha_1\\\\\\hat\\alpha_2\\\\\\vdots\\\\\\vdots\\\\\\hat\\alpha_P\\end{bmatrix}=-\\begin{bmatrix}R(1)\\\\R(2)\\\\\\vdots\\\\\\vdots\\\\R(P)\\end{bmatrix}\n$$\n\n一个例子：Durbin 递推算法\n\n### 协方差法\n\n不能保证声码器稳定\n\n### Durbin 递推算法\n\n#### 滤波器的内积\n\n定义$s_w(n)$关于$F(z)$和$G(z)$的内积如下：\n\n$$\n\\langle F(z),G(z)\\rangle=\\sum_{-\\infty}^{+\\infty}u(n)\\cdot v(n)\n$$\n\n特别地若这里的$F(z),\\quad G(z)$都用我们的逆滤波器$A(z)=\\sum_{i=0}^P\\alpha_iZ^{-i}$替换，那么语音信号$s_w(n)$经过$A(z)$后的输出$e(n)$就是预测误差。\n\n$\\alpha_i\\cdot s_W(n-i)$ 因此$A(z)$范数$\\|A(z)\\|$的平方就是预测误差。即\n\n$$\n\\|A(z)\\|^2=\\langle A(z),A(z)\\rangle=\\sum_{-\\infty}^{+\\infty}e(n)\\cdot e(n)=\\sum_{-\\infty}^{+\\infty}e^2(n)\n$$\n\n内积有正定性，线性，三角不等式\n\n特殊性质：\n\n$$\n\\langle z^{-i}, z^{-j} \\rangle = R(|i - j|)\\\\\n\\langle F(z), G(z) \\rangle = \\sum\\limits_{i=0}^{M}\\sum\\limits_{j=0}^{M}f_ig_jR(|i - j|)\\\\\n\\langle F(z),G(z)\\rangle=\\left\\langle z^kF(z),z^kG(z)\\right\\rangle\\\\\n\\langle F(z),G(z)\\rangle=\\langle F(1/z),G(1/z)\\rangle\n$$\n\n#### 逆滤波器\n\n定义FIR滤波器$\\hat{A}(z)$:\n\n$$\n\\hat{A}(z)=\\sum_{i=0}^P\\hat{\\alpha}_iz^{-i}\\quad,\\quad\\alpha_0=1\n$$\n\n若$\\hat{\\alpha}_{i}$是满足LPC正则方程的解，则称$\\hat{A}(z)$称为逆滤波器。$\\hat{E}(z)=\\hat{A}(z)\\cdot S(z)$是预测误差$\\varepsilon(n)$的z 变换。显然有：\n\n (1) 若s(n)是由全极点模型$1/A(z)$产生的，这时$A(z)=\\sum_{i=0}^P\\alpha_iz^{-i}$, 即：\n\n$s(n)=-\\sum_{i=1}^P\\alpha_is(n-i)+Ge(n)$\n\n$$\nS(z) \\cdot A(z) = G \\cdot E(z)\n$$\n\n#### 前向和后向预测\n\n前向线性预测器(P阶)\n\n$$\n\\hat{s}(n)=-\\sum_{i=1}^P\\alpha_i^{(P)}\\cdot s(n-i)\n$$\n\n前向预测误差(P阶)\n\n$$\n\\varepsilon_\\alpha^{(P)}(n)=s(n)-\\hat{s}(n)=\\sum_{i=0}^P\\alpha_i^{(P)}\\cdot s(n-i)\\:,\\alpha_0^{(P)}=1\n$$\n\n前向逆滤波器(P阶)\n\n$$\nA^{(P)}(z)=\\sum_{i=0}^P\\alpha_i^{(P)}z^{-i}\n$$\n\n显然有\n\n$$\nE^{(P)}_\\alpha(z) = S(z) \\cdot A^{(P)}(z)\n$$\n\n后向线性预测器(P阶)\n\n$$\n\\hat{s}(n-P-1)=-\\sum_{i=1}^P\\beta_i^{(P)}\\cdot s(n-i)\n$$\n\nn时刻对$s(n-P-1)$的后向预测误差(P阶)\n\n$$\n\\begin{aligned}&\\varepsilon_{\\beta}^{(P)}(n)=s(n-P-1)-\\hat{s}(n-P-1)\\\\&=\\sum_{i=1}^{P+1}\\beta_i^{(P)}\\cdot s(n-i)\\quad,\\quad\\beta_{P+1}^{(P)}=1\\end{aligned}\n$$\n\n后向逆滤波器 (P阶)\n\n$$\nB^{(P)}(z)=\\sum_{i=1}^{P+1}\\beta_i^{(P)}z^{-i}\n$$\n\n显然有\n\n$$\nE_\\beta^{(P)}(z) = S(z) \\cdot B^{(P)}(z)\n$$\n\n#### 正交性原理\n\n判定最佳预测器的充要条件是\n\n$$\n\\langle A^{(m)}(z), z^{-l} \\rangle = 0\\\\\n\\langle B^{(m)}(z), z^{-l} \\rangle = 0\\\\\nl = 1, 2, \\dots, m\n$$\n\n一个不严谨的理解：\n\n$$\nu(n) = s(n) * Z^{-1}[A(z)] = \\varepsilon(n)\\\\\nv(n) = s(n) * Z^{-1}[z^{-l}] = s(n - l)\\\\\n\\begin{align*}\n    &\\langle A^{(m)}(z), z^{-l} \\rangle\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}u(n)v(n)\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}\\varepsilon(n)s(n - l)\\\\\n\\end{align*}\n$$\n\n由于时间平均等于统计平均，\n\n$$\n\\frac1{2N} \\sum\\limits_{n=-N}^{N - 1}\\varepsilon(n)s(n-l) = E \\langle \\varepsilon(n), s(n-l) \\rangle\n$$\n\n根据开头提到的维纳滤波正交原理可知上式等于0。\n\n#### 递推公式\n\n根据定义，当$m=0$时，显然有\n\n$$\nA^{(0)}(z)=1\\\\B^{(0)}(z)=z^{-1}\n$$\n\n$m>0$时有如下递推公式（施密特正交化）\n\n$$\nA^{(m)}(z)=A^{(m-1)}(z)+K^{(m)}B^{(m-1)}(z)\n$$\n\n$$\nB^{(m)}(z)=z^{-1}\\Big[B^{(m-1)}(z)+K^{(m)}A^{(m-1)}(z)\\Big]\n$$\n\n$$\nK^{(m)} = -\\frac{\\langle A^{(m-1)}(z), B^{(m-1)}(z)\\rangle}{||B^{(m-1)}(z)||^2}\n$$\n\n根据正交性原理，需要证明由递推公式得到的$A^{(m)}(z)$和$B^{(m)}(z)$满足正交性条件公式。\n\n 在公式(76) 中，根据多项式对应项系数相等的原则，可以得到\n\n$$\n\\begin{aligned}&\\alpha_{i}^{(m)}=\\alpha_{i}^{(m-1)}+K^{(m)}\\cdot\\beta_{i}^{(m-1)}\\quad,\\quad i=1,\\cdots,m-1\\\\&\\alpha_{i}^{(m)}=K^{(m)}\\quad,\\quad i=m\\end{aligned}\n$$\n\n由公式(73)可知\n\n$$\n\\beta_j^{(m)}=\\alpha_{m+1-j}^{(m)},\\:j=1,\\cdots,m+1\n$$\n\n> 从这里可以推出\n>\n> $$\n> B^{(m)}(z) = z^{-(m+1)}A^{(m)}(1/z)\n> $$\n\n因此可以得到预测器系数的递推公式\n\n$$\n\\begin{cases}\\alpha_\\mathrm{m}^{(\\mathrm{m})}=\\mathrm{K}^{(\\mathrm{m})}\\\\\\alpha_\\mathrm{i}^{(\\mathrm{m})}=\\alpha_\\mathrm{i}^{(\\mathrm{m}-1)}+\\mathrm{K}^{(\\mathrm{m})}\\cdot\\alpha_\\mathrm{m-i}^{(\\mathrm{m}-1)}\\quad,\\:\\mathrm{i}=1,\\cdots,\\mathrm{m}-1\\end{cases}\n$$\n\n这是线性预测系数的Durbin递推算法公式。$m$阶部分相关系数$K^{(m)}$可以用以下方法计算：\n\n$$\nK^{(m)} = -\\frac{\\sum\\limits_{j=1}^{m}\\alpha_{m-j}^{(m-1)}R(j)}{||B^{(m-1)}(z)||^2}\n$$\n\n$||B^{(m)}(z)||^2$ 可以用这个递推式计算：\n\n$$\n\\begin{Vmatrix}B^{(m)}(z)\\end{Vmatrix}^2=(1-[K^{(m)}]^2)\\begin{Vmatrix}B^{(m-1)}(z)\\end{Vmatrix}^2\n$$\n\n初值\n\n$$\n||B^{(0)}(z)|| = R(0)\\\\\n\\alpha^{(0)}_0 = 1\n$$\n\n### Durbin 算法系统的稳定性\n\n充分性：\n\n$$\n\\frac{1}{A^{(m)}(z)} 稳定 \\Rarr |k^{(m)}| < 1\n$$\n\n必要性：\n\n$$\n|k^{(m)}| < 1 \\Rarr \\frac{1}{A^{(m)}(z)} 稳定\n$$\n\nHighlight:\n\nDurbin 逆序递推公式\n\n$$\nA^{(m-1)}(z)=\\frac{A^{(m)}(z)-k^{(m)}zB^{(m)}(z)}{1-(k^{(m)})^2}\n$$\n\n证明过程中引入的一个辅助函数\n\n$$\nF^{(m)}(z)=\\frac{A^{(m)}(z)}{zB^{(m)}(z)}=\\frac{z^mA^{(m)}(z)}{A^{(m)}(1/z)}\n$$\n\n满足 $F^{(m)}(z) < 1 \\lrArr |z| < 1$\n\n#### 稳定性的应用\n\n充分性：说明使用 Durbin 算法可以保证 $1/A(z)$ 稳定\n\n必要性：\n\n判定高阶多项式 $A(z)$ 构成的系统 $1/A(z)$ 是否稳定。\n\n只要计算出 $k_m$，判断 $|k_m|$ 是否小于1即可。\n\n### LPC 模型参数讨论\n\n#### 阶数\n\n误差能量是单调减的，一般 $P = 8 \\sim 14$\n\n#### 激励增益 G\n\n采用缓变窗（哈明窗），$N >> P$\n\n$$\n\\varepsilon_\\alpha^{(p)}(n)\\approx Ge_w(n)=Ge(n)w(n)\n$$\n\n$$\nG^2\\approx\\frac{\\sum_{n=-\\infty}^\\infty\\left(\\varepsilon_\\alpha^{(p)}(n)\\right)^2}{\\sum_{n=-\\infty}^\\infty e^2(n)w^2(n)}\n$$\n\n#### 短时分析对于LPC参数估计的影响\n\n1. 𝑒(𝑛)为白噪声时，$E[\\hat \\alpha_i] = \\alpha_i$，无偏估计\n2. 𝑒(𝑛)为浊音时，采用基音同步算法可以达到无偏估计。否则如果是任意截取一段语音作分析估计是有偏的。\n\n#### LPC分析的频域解释\n\n用LPC分析可以用来跟踪声道模型谱（或称语音的平滑谱）。若用LPC算法解出的全极点模型来逼近实际声道，则它的单位冲激响应ℎ(𝑛)为：\n\n$$\n\\begin{cases}\n    h(n) = 0, n \\lt 0\\\\\n    h(n) = - \\sum\\limits_{i=1}^{p}\\alpha_i^{(p)}h(n - 1) + \\delta(n), n \\ge 0\n\\end{cases}\n$$\n\n若 $R_h(l) = R_h(-l) = \\sum\\limits_{n=0}^{\\infty}h(n - l)h(n), l \\ge 0$\n\n$$\n\\sum\\limits_{i=1}^{p}\\alpha_i^{(P)}R_h(|k - i|) = -R_h(k), l \\ge 0\\\\\nR_h(l)/R_h(0) = R(l) / R(0)\n$$\n\n当激励为均方值为1，均值为0的白噪声序列时，输出的自关函数𝑅𝑤(𝑙)也有此关系。\nP阶LPC预测模型也称为P阶自关匹配模型。\n\n#### 各种LPC参数计算其它们之间的关系\n\n1. $R(l) \\Rightarrow \\alpha$\n2. $K \\Rightarrow \\alpha$\n\n$$\n\\begin{cases}\\alpha_m^m=K^{(m)}\\\\\\alpha_i^{(m)}=\\alpha_i^{(m-1)}+K^{(m)}\\alpha_{m-i}^{(m-1)}\\end{cases}\n$$\n\n3. LPC 系数 => 倒谱（因为是最小相位序列）\n4. PARCOR 系数($K^{(m)}$)\n   1. 由 Durbin 解得\n   2. 由格形算法解得\n   3. 由 Schur 算法解得\n5. 由 $A(z)$ 根确定振峰\n   1. 每一对根与一个共振峰对应\n6. 声道面积比系数和对数面积比系数\n\n$$\n\\frac{A_m}{A_{m-1}}=\\frac{1-K^{(m)}}{1+K^{(m)}}\\:,\\:m=1,2,\\cdots P\\\\\ng_m = \\ln\\Bigg[\\frac{A_m}{A_{m-1}}\\Bigg]\n$$\n\n7. 线谱对（LSP）或者线谱频率参数(LSF)\n\n$$\nP(z) = A^{(p)}(z) + z^{-(p+1)}A^{(p)}(z^{-1})\\\\\nQ(z) = A^{(p)}(z) - z^{-(p+1)}A^{(p)}(z^{-1})\n$$\n\n性质：\n\n1. $P(z)$ 和 $Q(z)$ 的根均在单位圆上\n2. $P(z)$ 和 $Q(z)$ 的根在单位元上交错\n3. $\\alpha$ 参数和 $LSP$ 参数互推\n\n某个特定的𝐿𝑆𝑃 [𝑓1, 𝑓2, ⋯ 𝑓𝑝]中只移动其中任意一个频率𝑓𝑖的位置，那么对应的平滑谱只\n有𝑓𝑖附近与原平滑谱有异，而在其它频域则变化很小\n\n## 语音信号编码\n\n### 语音信号的标量量化\n\n#### 标量量化器\n\n#### 均匀量化器\n\n#### 非均匀量化器\n\n#### 非线性压扩量化器\n\n### 自适应量化（Adaptive Delta Modulation，ADM）\n\n#### 前向自适应量化（AQF）\n\n#### 后向自适应量化（AQB）\n\n### 差分编码 DPCM\n\n![1713960093567](../images/Speech-SP/1713960093567.png)\n\nDPCM是指采用固定预测器与固定量化器的差值脉冲调制。\n\n### CVSD 编码器\n\n![1713958735363](../images/Speech-SP/1713958735363.png)\n\n### Delta-Sigma 量化器\n\n![1713958768829](../images/Speech-SP/1713958768829.png)\n\n考虑 $D/A$ 变换器的增益为 1 的情况，此时 $V_a(z)\\approx V(z)$，\n\n$$\n\\begin{gathered}\nV(z)=[U(z)-V(z)]\\cdot H(z)+Q(z) \\\\\n[1+H(z)]\\cdot V(z)=U(z)\\cdot H(z)+Q(z) \\\\\nV(z)=\\frac{H(z)}{1+H(z)}U(z)\\cdot+\\frac{1}{1+H(z)}Q(z) \n\\end{gathered}\n$$\n\n定义信号传输函数\n\n$$\nSTF(z)=\\frac{V(z)}{U(z)}\\Bigg|_{Q(z)=0}=\\frac{H(z)}{1+H(z)}\n$$\n\n定义超取样量化噪声传输函数\n\n$$\nNTF(z)=\\frac{V(z)}{Q(z)}\\Bigg|_{U(z)=0}=\\frac{1}{1+H(z)}\n$$\n\n让 $H(z)$ 为低通，则 $STF(z)$ 是低通，$NTF(z)$ 是高通\n\n$$\nV(z)=STF(z)\\cdot U(z)+NTF(z)\\cdot Q(z)\n$$\n\n噪声整形（Noise-Shaping）技术：$NTF(z)$ 去掉了噪声能量的低频部分。接下来，只要经过低通滤波器 $H_d(z)$，就可以滤除高频部分的噪声能量，剩下的只有所需要的信号 $U(z)$，$H_d(z)$ 的输出 $V_d(z)$ 的量化噪声可以小于直接用 A/D 量化器量化的噪声。\n\n采用速度（超采样）换精度（高量化比特数），量化器的精度可以非常低，甚至可以用 1 bit 量化器。1 bit 量化器，就不存在 A/D 非线性问题。\n\n超采样的好处：扩展了频带宽度，我们认为噪声的功率一定，当频带变宽，噪声功率谱的高度就降低了。\n\n![1713960064882](../images/Speech-SP/1713960064882.png)\n\n### 子带编码\n\n含有多个频点信号分量的复合宽带信号\n\n首先用一组滤波器将信号分解成若干子带信号\n\n$$\n\\langle f_1(t),f_2(t)\\rangle=\\frac1{2\\pi}\\cdot\\langle F_1(\\omega),F_2(\\omega)\\rangle\n$$\n\n若 $\\langle F_1(\\omega),F_2(\\omega)\\rangle\\approx0$，则采用子带滤波后，两个信号的相关性 $\\langle f_1(t),f_2(t)\\rangle$ 降低，对于这些不相关的子带信号独立编码可能提高编码效率。\n\n#### 比特数分配\n\n$$\n\\sum_{k=1}^MR_k=R\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{x_k}^2\\\\\n\n\\min_{R_k} \\sigma_{r,SBC}^2=\\sum_{k=1}^M\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{xk}^2\\\\\n$$\n\n解得\n\n$$\nR_{k,opt}=R/M+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}}\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R/M}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}\\\\\nmin\\{\\sigma_{r,SBC}^2\\}=M\\cdot\\varepsilon_*^2\\cdot2^{-\\frac{2R}{M}}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{M}}\n$$\n\n每个子带的采样率变为总带宽的 1/M，总的信息比特速率为 $R \\cdot f/M$，为了与 PCM 进行比较，假设 SBC 和 PCM 的编码速率相等：\n\n$$\nR_{PCM} \\cdot f = R_{SBC} \\cdot f / M\\\\\n\\Rarr R_{PCM} = R_{SBC}/M\n$$\n\n此时可推出 SBC 较于 PCM 的信噪比增益为\n\n$$\nmax\\{G_{SBC}\\}=\\frac{\\sigma_{r,PCM}^{2}}{\\sigma_{r,SBC}^{2}}=\\frac{2^{-2R_{PCM}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{2^{-\\frac{2R_{SBC}}{M}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}=\\frac{\\sigma_{x}^{2}}{M\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{\\frac{1}{M}\\sigma_{x}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}=\\frac{\\frac{1}{M}\\sum_{k=1}^{M}\\sigma_{xk}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}\n$$\n\n因此 SBC 的信噪比增益等于子带信号的算术平均和几何平均之比。\n\n* 子带信号能量越大，则分配比特数越多；\n* 最佳分配条件下，各个子带的量化噪声相同；\n* 若各个子带能量相同，则子带编码的增益为1\n\n#### 多相正交滤波器组\n\n用一组不同频率的余弦信号对低通滤波器进行调制，变成了带通滤波器组：\n\n$$\nH_i(z)=\\sum_{n=-\\infty}^{+\\infty}h(n)\\cdot cos\\left(\\pi(2i+1)\\cdot\\frac{n}{2M}\\right)\\cdot z^{-n}=\\frac12F_i(z)+\\frac12G_i(z)\n$$\n\n$$\nF_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega-\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\\\\G_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega+\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\n$$\n\n![1713963786950](../images/Speech-SP/1713963786950.png)\n\n分析滤波器：子带滤波，降采样；\n\n降采样率过程等价于：采样(b, 将非M倍数的采样点置为0) + 分频(c，抽取 M 倍数上的采样点形成新的信号)\n\n![1713963998639](../images/Speech-SP/1713963998639.png)\n\n$$\n\\hat{X}_i(z)=\\frac1M\\sum_{l=0}^{M-1}X_i(z^{\\frac1M}W_M^{-l})\n$$\n\n![1713965424496](../images/Speech-SP/1713965424496.png)\n\n每个子带的输出会产生四种混叠干扰：\n\n$$\n\\begin{aligned}\nU_i(e^{j\\omega})& =K_i(e^{j\\omega})\\cdot Y_i(e^{j\\omega})  \\\\\n&\\approx\\frac1MK_i(e^{j\\omega})\\{a_iF_i(e^{j\\omega})X(e^{j\\omega})+b_iG_i(e^{j\\omega})X(e^{j\\omega})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})\\} \\\\\n&i=1\\sim M-2\n\\end{aligned}\n$$\n\n为了解决升采样后的频谱混叠，在综合滤波器部分精确对消混叠信号：\n\n$$\na_id_i=-a_{i-1}d_{i-1},\\quad i>0\n$$\n\n### 变换域编码\n\n正交变换后编码：\n\n$$\nY = AX\n$$\n\n正交变换满足能量守恒\n\n$$\n||Y||^2 = ||X||^2\n$$\n\n重建信号的误差等于变换域上量化器的误差\n\n$$\nE = Y - [Y]\\\\\n||X - [x]||^2 = ||E||^2\n$$\n\n#### 比特分配\n\n假设 N 个输入样本组成一个矢量 X，变换域 Y 的每个分量用 $R_k$  个比特量化\n\n$$\nR=\\frac1N\\sum_{k=0}^{N-1}R_k\\\\\n\\sigma_q^2=\\sum_{k=0}^{N-1}\\sigma_{q,k}^2=\\varepsilon_*^2\\cdot\\sum_{k=0}^{N-1}2^{-2R_k}\\sigma_k^2\\\\\n\\min \\sigma_{q}^{2}=\\frac{1}{N}\\sum_{k=0}^{N-1}\\sigma_{q,k}^{2}\n$$\n\n$$\nR_{k,opt}=R+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/N}}\\\\\n\\sigma_{q}^2 = min\\{\\sigma_{q,k}^2\\}=\\varepsilon_*^2\\cdot2^{-2R}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{N}}\n$$\n\n相比 PCM 的增益为\n\n$$\n\\begin{gathered}\nG_{TC} =\\frac{min\\{\\sigma_{r,PCM}^{2}\\}}{min\\{\\sigma_{r,TC}^{2}\\}}=\\frac{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\sigma_{\\chi}^{2}}{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\prod_{k=0}^{N-1}[\\sigma_{k}^{2}]^{\\frac{1}{N}}} \\\\\n=\\frac{\\sigma_x^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}}=\\frac{\\frac1N\\sum_{k=0}^{N-1}\\sigma_k^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}} \n\\end{gathered}\n$$\n\n#### 最佳正交变换 - KL 变换\n\n## 语音信号的参数编码\n\n### 感觉加权滤波器\n\n误差函数加权：\n\n$$\nJ=\\int_0^{f_s}\\lvert s(f)-\\hat{s}(f)\\rvert^2\\cdot\\lvert w(f)\\rvert^2df\n$$\n\n其中，加权滤波器满足\n\n$$\n\\int_0^{f_S}|w(f)|df= Const.\n$$\n\n当误差函数最小的时候，应当保证\n\n$$\n|s(f)-\\hat{s}(f)|^2\\cdot|w(f)|=\\frac{\\gamma}{2}=\\text{常数}\n$$\n\n可以选择如下的滤波器：\n\n$$\nw(z)=\\frac{A(z)}{A\\left(\\frac{z}{\\gamma}\\right)}=\\frac{1-\\sum_{i=1}^P\\alpha_iz^{-i}}{1-\\sum_{i=1}^P\\alpha_i\\gamma^iz^{-i}},\\quad0\\leq\\gamma\\leq1\n$$\n\n$\\gamma$ 为加权因子，在 0-1 之间。\n\n$\\gamma=0$ 时变成逆滤波器，其频谱包络的峰值点就是语音谱的谷值点。\n\n> 分析：语音信号是全极点模型产生的，即 $S(z) = GE(z)/A(z)$，与逆滤波器点频谱成反比。\n\n![1715172645812](../images/Speech-SP/1715172645812.png)\n\n### 多脉冲激励线性预测声码器\n\n![1715172680511](../images/Speech-SP/1715172680511.png)\n\n语音综合器的激励源有若干个不同位置和幅度的脉冲信号组成。\n\n$$\n\\hat{s}(n)=\\hat{s}_0(n)+\\sum_{k=1}^Mg_kh(n-n_k)\n$$\n\n其中 $\\hat s_0(n)$ 是 LPC 综合器的零输入响应。\n\n$$\n\\begin{aligned}&e_{s}(n)=s(n)-\\hat{s}(n)=s(n)-\\hat{s}_{0}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\\\&=\\bar{e}(n)-\\sum_{k=1}^Mg_kh(n-n_k)\\end{aligned}\n$$\n\n用 $\\bar{e}(n)=s(n)-\\hat{s}_0(n)$ 表示输入语音减去零输入响应（受历史激励影响的部分）。\n\n输入感觉加权滤波器，得到输出\n\n$$\n\\begin{aligned}e(n)&=e_{s}(n)*w(n)=\\left[\\bar{e}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\right]*w(n)\\\\&=\\bar{e}_{w}(n)-\\sum_{k=1}^{M}g_{k}h_{w}(n-n_{k})\\end{aligned}\n$$\n\n从而，得到感觉加权滤波器的误差函数\n\n$$\nE=\\sum_{n=1}^Ne^2(n)=\\sum_{n=1}^N\\left[\\bar{e}_w(n)-\\sum_{k=1}^Mg_kh_w(n-n_k)\\right]^2\n$$\n\n选择合适的 $n_k$, $g_k$ 使得上面的误差函数最小\n\n$$\n\\frac{\\partial E}{\\partial n_j}=0,\\quad j=1,\\cdots M\\\\\\frac{\\partial E}{\\partial g_j}=0,\\quad j=1,\\cdots M\n$$\n\n上面那个方程很复杂，会导出非线性的方程；\n\n从下面的那个方程可以推出\n\n$$\n\\sum_{k=1}^Mg_kR_{hh}(n_k,n_j)=R_{eh}(n_j),\\quad j=1,\\cdots M\n$$\n\n其中\n\n$$\nR_{eh}(n_j)=\\sum_{n=1}^N\\bar{e}_w(n)\\cdot h_w(n-n_j)\\\\R_{hh}(n_k,n_j)=\\sum_{n=1}^Nh_w(n-n_k)h_w(n-n_j)\n$$\n\n此时可改写最小均方误差\n\n$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-\\sum_{k=1}^Mg_kR_{eh}(n_k)\n$$\n\n最优解的计算涉及到非线性方程的求解，不太现实。考虑采用次优搜索，一个一个求解。\n\n当只有一个脉冲时\n\n$$\ng_1R_{hh}(n_1,n_1)=R_{eh}(n_1)\\\\\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-g_1R_{eh}(n_1)\n$$\n\n消元得到\n\n$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-R_{eh}^2(n_1)/R_{hh}(n_1,n_1)\n$$\n\n接下来搜索 $n_1$ 使得上式最优化。解出 $n_1$ 后即可解出 $g_1$。\n\n接下来一个个求解，每次都要把前面求解过的脉冲折算到零输入响应中，然后求解当前的结果：\n\n## 语音信号修整与综合技术\n\n短时谱分析\n\n$$\n\\begin{gathered}w[n]=\\begin{cases}\\neq0&,&0\\leq n<L\\\\0&,&\\text{其它}\\end{cases}\\\\X(p,k)=\\sum_{n=-\\infty}^{+\\infty}x[n]w[p-n]e^{-j\\frac{2\\pi}{N}nk}\\\\x[n]w[p-n]=\\left[\\frac{1}{N}\\sum_{i=0}^{N-1}X(p,k)e^{j\\frac{2\\pi}{N}nk}\\right]\\cdot R[p-n]\\end{gathered}\n$$\n\n### 利用修正短时谱进行最小方差信号估计\n\n首先计算短时谱\n\n$$\nX(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}x[m]w(p-m)e^{-j\\omega m}\n$$\n\n对短时谱进行修正\n\n$$\nY(p,\\omega)=X(p,\\omega)H(p,\\omega)\n$$\n\n需要得到一个“有效”的短时谱，满足：\n\n1. 时域短时段有限长，非零段不超过窗函数 $w(p-n)$的范围\n2. 一致性约束，即不同的𝑝时刻 𝑌(𝑝,𝜔)所对应的时域短时段，若有部分重叠，那么在去除分析窗的加权影响后，在重叠的部分，它们应该是相等的。\n\n实际上很难得到上述信号，可以通过最小方差准则逼近\n\n$$\nD[\\hat{Y}(n,\\omega),Y(n,\\omega)]=\\sum_{m=-\\infty}^{+\\infty}\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}\\left|\\hat{Y}(m,\\omega)-Y(m,\\omega)\\right|^{2}d\\omega\n$$\n\n其中\n\n$$\n\\hat{Y}(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}\\hat{y}[m]w(p-m)e^{-j\\omega m}\n$$\n\n利用 Parseval 定理\n\n$$\n\\begin{aligned}&D\\big[\\hat{Y}(n,\\omega),Y(n,\\omega)\\big]=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}_{m}(n)-y_{m}(n)|^{2}\\\\&=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}(n)w(m-n)-y_{m}(n)|^{2}\\end{aligned}\n$$\n\n变分法求得最小值\n\n$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(m-n)y_m(n)}{\\sum_{m=-\\infty}^\\infty w^2(m-n)}\n$$\n\n其中\n\n$$\ny_m(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi Y(m,\\omega)e^{j\\omega n}d\\omega\n$$\n\n应用中，以周期 $T$ 分析\n\n$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)y_{mT}(n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$\n\n如果 $w(n)$ 取三角窗的平方根\n\n$$\nw^2(n)=\\begin{cases}1-\\frac{|n-T|}{T}&,\\quad0\\leq n\\leq2T\\\\\\\\0&,\\quad\\text{其它}\\end{cases}\n$$\n\n若 n 此时为奇数，$T = (N-1)/2$，这时$\\sum_{m=-\\infty}^{\\infty}w^{2}(mT-n)=1$，可简化计算，如果频谱无修正，最优解为\n\n$$\n\\hat{y}(n)=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)[w(mT-n)x(n)]}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=\\frac{x(n)\\sum_{m=-\\infty}^\\infty w^2(mT-n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=x(n)\n$$\n\n若改变语音的速度，$p=k\\cdot p^{\\prime}$，满足$|Y(p,\\omega)|=|X(p^{\\prime},\\omega)|$ 。\n\n$$\ny_{p'}(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}Y(p',\\omega)e^{j\\omega n}d\\omega=w(p'-n)x(n)\n$$\n\n让 $\\tau_p=p-p^{\\prime}=(1-1/k)\\cdot p$，\n\n$$\n\\begin{aligned}&y_p(n)=y_{p^{\\prime}}(n-\\tau_p)=w(p^{\\prime}-n+\\tau_p)x(n-\\tau_p)\\\\&=w(p-n)x(n-\\tau_p)\\end{aligned}\n\n$$\n\n代入重建公式\n\n$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w^2(mT-n)x(n-\\tau_{mT})}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$\n\n让$\\sum_{m=-\\infty}^{\\infty}W(mT-n)= \\sum_{m=-\\infty}^{\\infty}w^2(mT-n) =1$，\n\n$$\n\\hat{y}[n]=\\sum_{m=-\\infty}^{\\infty}W(mT-n)x(n-\\tau_{mT})\n$$\n","source":"_posts/Speech-SP.md","raw":"---\ntitle: Speech-SP\nkatex: true\ndate: 2024-02-28 19:24:02\ntags:\n---\n## 语音信号的线性预测编码技术\n\n线性预测编码技术（维纳滤波）。可以参考隔壁统计信号处理的笔记hh。\n\n维纳滤波的正交原理：\n\n$$\nE \\langle x(n-k), e(n) \\rangle = 0\n$$\n\n正交原理可以用来估计任何时候的任何值，不管是现在（滤波），过去（平滑）还是未来（预测），也不管估计的对象是 $x,y$，上述公式的含义是：估计误差始终与已知信号垂直，与估计的是哪个时间的信号无关。\n\n利用前面的 $P$ 个信号预测下一个信号：\n\n$$\n\\hat{s}(n)=-\\sum_{i=1}^{P^{\\prime}}\\hat{\\alpha}_i\\cdot s(n-i)\n$$\n\n误差定义为\n\n$$\n\\begin{aligned}\n\\varepsilon(n)& =s(n)-\\overset{\\wedge}{\\operatorname*{s}}(n)=s(n)+\\sum_{i=1}\\widehat{\\alpha}_i\\cdot s(n-i)  \\\\\n&=\\sum_{i=0}^{P^{\\prime}}\\widehat{\\alpha}_i\\cdot s(n-i)\n\\end{aligned}\n$$\n\n从 z 域看，这是一个全极点模型产生了目标信号：\n\n$$\nS(z) = -S(z)\\sum\\limits_{i=1}^{P}\\alpha_iz^{-i} + E(z)\n$$\n\n接下来的所有步骤，目的都是推导 $\\alpha$ 的取值。\n\n### 自相关法\n\n本文中假设信号具有遍历性，即时间平均等于统计平均，时间上的自相关等于统计意义上的自相关。\n\n利用 LMMSE 准则可以推出\n\n$$\n\\begin{bmatrix}R(0)&R(1)&R(2)&\\cdots&R(P-1)\\\\R(1)&R(0)&R(1)&\\cdots&R(P-2)\\\\R(2)&R(1)&R(0)&\\cdots&R(P-3)\\\\\\vdots&\\vdots&&&\\vdots\\\\R(P-1)&R(P-2)&\\cdots&\\cdots&R(0)\\end{bmatrix}\\cdot\\begin{bmatrix}\\hat\\alpha_1\\\\\\hat\\alpha_2\\\\\\vdots\\\\\\vdots\\\\\\hat\\alpha_P\\end{bmatrix}=-\\begin{bmatrix}R(1)\\\\R(2)\\\\\\vdots\\\\\\vdots\\\\R(P)\\end{bmatrix}\n$$\n\n一个例子：Durbin 递推算法\n\n### 协方差法\n\n不能保证声码器稳定\n\n### Durbin 递推算法\n\n#### 滤波器的内积\n\n定义$s_w(n)$关于$F(z)$和$G(z)$的内积如下：\n\n$$\n\\langle F(z),G(z)\\rangle=\\sum_{-\\infty}^{+\\infty}u(n)\\cdot v(n)\n$$\n\n特别地若这里的$F(z),\\quad G(z)$都用我们的逆滤波器$A(z)=\\sum_{i=0}^P\\alpha_iZ^{-i}$替换，那么语音信号$s_w(n)$经过$A(z)$后的输出$e(n)$就是预测误差。\n\n$\\alpha_i\\cdot s_W(n-i)$ 因此$A(z)$范数$\\|A(z)\\|$的平方就是预测误差。即\n\n$$\n\\|A(z)\\|^2=\\langle A(z),A(z)\\rangle=\\sum_{-\\infty}^{+\\infty}e(n)\\cdot e(n)=\\sum_{-\\infty}^{+\\infty}e^2(n)\n$$\n\n内积有正定性，线性，三角不等式\n\n特殊性质：\n\n$$\n\\langle z^{-i}, z^{-j} \\rangle = R(|i - j|)\\\\\n\\langle F(z), G(z) \\rangle = \\sum\\limits_{i=0}^{M}\\sum\\limits_{j=0}^{M}f_ig_jR(|i - j|)\\\\\n\\langle F(z),G(z)\\rangle=\\left\\langle z^kF(z),z^kG(z)\\right\\rangle\\\\\n\\langle F(z),G(z)\\rangle=\\langle F(1/z),G(1/z)\\rangle\n$$\n\n#### 逆滤波器\n\n定义FIR滤波器$\\hat{A}(z)$:\n\n$$\n\\hat{A}(z)=\\sum_{i=0}^P\\hat{\\alpha}_iz^{-i}\\quad,\\quad\\alpha_0=1\n$$\n\n若$\\hat{\\alpha}_{i}$是满足LPC正则方程的解，则称$\\hat{A}(z)$称为逆滤波器。$\\hat{E}(z)=\\hat{A}(z)\\cdot S(z)$是预测误差$\\varepsilon(n)$的z 变换。显然有：\n\n (1) 若s(n)是由全极点模型$1/A(z)$产生的，这时$A(z)=\\sum_{i=0}^P\\alpha_iz^{-i}$, 即：\n\n$s(n)=-\\sum_{i=1}^P\\alpha_is(n-i)+Ge(n)$\n\n$$\nS(z) \\cdot A(z) = G \\cdot E(z)\n$$\n\n#### 前向和后向预测\n\n前向线性预测器(P阶)\n\n$$\n\\hat{s}(n)=-\\sum_{i=1}^P\\alpha_i^{(P)}\\cdot s(n-i)\n$$\n\n前向预测误差(P阶)\n\n$$\n\\varepsilon_\\alpha^{(P)}(n)=s(n)-\\hat{s}(n)=\\sum_{i=0}^P\\alpha_i^{(P)}\\cdot s(n-i)\\:,\\alpha_0^{(P)}=1\n$$\n\n前向逆滤波器(P阶)\n\n$$\nA^{(P)}(z)=\\sum_{i=0}^P\\alpha_i^{(P)}z^{-i}\n$$\n\n显然有\n\n$$\nE^{(P)}_\\alpha(z) = S(z) \\cdot A^{(P)}(z)\n$$\n\n后向线性预测器(P阶)\n\n$$\n\\hat{s}(n-P-1)=-\\sum_{i=1}^P\\beta_i^{(P)}\\cdot s(n-i)\n$$\n\nn时刻对$s(n-P-1)$的后向预测误差(P阶)\n\n$$\n\\begin{aligned}&\\varepsilon_{\\beta}^{(P)}(n)=s(n-P-1)-\\hat{s}(n-P-1)\\\\&=\\sum_{i=1}^{P+1}\\beta_i^{(P)}\\cdot s(n-i)\\quad,\\quad\\beta_{P+1}^{(P)}=1\\end{aligned}\n$$\n\n后向逆滤波器 (P阶)\n\n$$\nB^{(P)}(z)=\\sum_{i=1}^{P+1}\\beta_i^{(P)}z^{-i}\n$$\n\n显然有\n\n$$\nE_\\beta^{(P)}(z) = S(z) \\cdot B^{(P)}(z)\n$$\n\n#### 正交性原理\n\n判定最佳预测器的充要条件是\n\n$$\n\\langle A^{(m)}(z), z^{-l} \\rangle = 0\\\\\n\\langle B^{(m)}(z), z^{-l} \\rangle = 0\\\\\nl = 1, 2, \\dots, m\n$$\n\n一个不严谨的理解：\n\n$$\nu(n) = s(n) * Z^{-1}[A(z)] = \\varepsilon(n)\\\\\nv(n) = s(n) * Z^{-1}[z^{-l}] = s(n - l)\\\\\n\\begin{align*}\n    &\\langle A^{(m)}(z), z^{-l} \\rangle\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}u(n)v(n)\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}\\varepsilon(n)s(n - l)\\\\\n\\end{align*}\n$$\n\n由于时间平均等于统计平均，\n\n$$\n\\frac1{2N} \\sum\\limits_{n=-N}^{N - 1}\\varepsilon(n)s(n-l) = E \\langle \\varepsilon(n), s(n-l) \\rangle\n$$\n\n根据开头提到的维纳滤波正交原理可知上式等于0。\n\n#### 递推公式\n\n根据定义，当$m=0$时，显然有\n\n$$\nA^{(0)}(z)=1\\\\B^{(0)}(z)=z^{-1}\n$$\n\n$m>0$时有如下递推公式（施密特正交化）\n\n$$\nA^{(m)}(z)=A^{(m-1)}(z)+K^{(m)}B^{(m-1)}(z)\n$$\n\n$$\nB^{(m)}(z)=z^{-1}\\Big[B^{(m-1)}(z)+K^{(m)}A^{(m-1)}(z)\\Big]\n$$\n\n$$\nK^{(m)} = -\\frac{\\langle A^{(m-1)}(z), B^{(m-1)}(z)\\rangle}{||B^{(m-1)}(z)||^2}\n$$\n\n根据正交性原理，需要证明由递推公式得到的$A^{(m)}(z)$和$B^{(m)}(z)$满足正交性条件公式。\n\n 在公式(76) 中，根据多项式对应项系数相等的原则，可以得到\n\n$$\n\\begin{aligned}&\\alpha_{i}^{(m)}=\\alpha_{i}^{(m-1)}+K^{(m)}\\cdot\\beta_{i}^{(m-1)}\\quad,\\quad i=1,\\cdots,m-1\\\\&\\alpha_{i}^{(m)}=K^{(m)}\\quad,\\quad i=m\\end{aligned}\n$$\n\n由公式(73)可知\n\n$$\n\\beta_j^{(m)}=\\alpha_{m+1-j}^{(m)},\\:j=1,\\cdots,m+1\n$$\n\n> 从这里可以推出\n>\n> $$\n> B^{(m)}(z) = z^{-(m+1)}A^{(m)}(1/z)\n> $$\n\n因此可以得到预测器系数的递推公式\n\n$$\n\\begin{cases}\\alpha_\\mathrm{m}^{(\\mathrm{m})}=\\mathrm{K}^{(\\mathrm{m})}\\\\\\alpha_\\mathrm{i}^{(\\mathrm{m})}=\\alpha_\\mathrm{i}^{(\\mathrm{m}-1)}+\\mathrm{K}^{(\\mathrm{m})}\\cdot\\alpha_\\mathrm{m-i}^{(\\mathrm{m}-1)}\\quad,\\:\\mathrm{i}=1,\\cdots,\\mathrm{m}-1\\end{cases}\n$$\n\n这是线性预测系数的Durbin递推算法公式。$m$阶部分相关系数$K^{(m)}$可以用以下方法计算：\n\n$$\nK^{(m)} = -\\frac{\\sum\\limits_{j=1}^{m}\\alpha_{m-j}^{(m-1)}R(j)}{||B^{(m-1)}(z)||^2}\n$$\n\n$||B^{(m)}(z)||^2$ 可以用这个递推式计算：\n\n$$\n\\begin{Vmatrix}B^{(m)}(z)\\end{Vmatrix}^2=(1-[K^{(m)}]^2)\\begin{Vmatrix}B^{(m-1)}(z)\\end{Vmatrix}^2\n$$\n\n初值\n\n$$\n||B^{(0)}(z)|| = R(0)\\\\\n\\alpha^{(0)}_0 = 1\n$$\n\n### Durbin 算法系统的稳定性\n\n充分性：\n\n$$\n\\frac{1}{A^{(m)}(z)} 稳定 \\Rarr |k^{(m)}| < 1\n$$\n\n必要性：\n\n$$\n|k^{(m)}| < 1 \\Rarr \\frac{1}{A^{(m)}(z)} 稳定\n$$\n\nHighlight:\n\nDurbin 逆序递推公式\n\n$$\nA^{(m-1)}(z)=\\frac{A^{(m)}(z)-k^{(m)}zB^{(m)}(z)}{1-(k^{(m)})^2}\n$$\n\n证明过程中引入的一个辅助函数\n\n$$\nF^{(m)}(z)=\\frac{A^{(m)}(z)}{zB^{(m)}(z)}=\\frac{z^mA^{(m)}(z)}{A^{(m)}(1/z)}\n$$\n\n满足 $F^{(m)}(z) < 1 \\lrArr |z| < 1$\n\n#### 稳定性的应用\n\n充分性：说明使用 Durbin 算法可以保证 $1/A(z)$ 稳定\n\n必要性：\n\n判定高阶多项式 $A(z)$ 构成的系统 $1/A(z)$ 是否稳定。\n\n只要计算出 $k_m$，判断 $|k_m|$ 是否小于1即可。\n\n### LPC 模型参数讨论\n\n#### 阶数\n\n误差能量是单调减的，一般 $P = 8 \\sim 14$\n\n#### 激励增益 G\n\n采用缓变窗（哈明窗），$N >> P$\n\n$$\n\\varepsilon_\\alpha^{(p)}(n)\\approx Ge_w(n)=Ge(n)w(n)\n$$\n\n$$\nG^2\\approx\\frac{\\sum_{n=-\\infty}^\\infty\\left(\\varepsilon_\\alpha^{(p)}(n)\\right)^2}{\\sum_{n=-\\infty}^\\infty e^2(n)w^2(n)}\n$$\n\n#### 短时分析对于LPC参数估计的影响\n\n1. 𝑒(𝑛)为白噪声时，$E[\\hat \\alpha_i] = \\alpha_i$，无偏估计\n2. 𝑒(𝑛)为浊音时，采用基音同步算法可以达到无偏估计。否则如果是任意截取一段语音作分析估计是有偏的。\n\n#### LPC分析的频域解释\n\n用LPC分析可以用来跟踪声道模型谱（或称语音的平滑谱）。若用LPC算法解出的全极点模型来逼近实际声道，则它的单位冲激响应ℎ(𝑛)为：\n\n$$\n\\begin{cases}\n    h(n) = 0, n \\lt 0\\\\\n    h(n) = - \\sum\\limits_{i=1}^{p}\\alpha_i^{(p)}h(n - 1) + \\delta(n), n \\ge 0\n\\end{cases}\n$$\n\n若 $R_h(l) = R_h(-l) = \\sum\\limits_{n=0}^{\\infty}h(n - l)h(n), l \\ge 0$\n\n$$\n\\sum\\limits_{i=1}^{p}\\alpha_i^{(P)}R_h(|k - i|) = -R_h(k), l \\ge 0\\\\\nR_h(l)/R_h(0) = R(l) / R(0)\n$$\n\n当激励为均方值为1，均值为0的白噪声序列时，输出的自关函数𝑅𝑤(𝑙)也有此关系。\nP阶LPC预测模型也称为P阶自关匹配模型。\n\n#### 各种LPC参数计算其它们之间的关系\n\n1. $R(l) \\Rightarrow \\alpha$\n2. $K \\Rightarrow \\alpha$\n\n$$\n\\begin{cases}\\alpha_m^m=K^{(m)}\\\\\\alpha_i^{(m)}=\\alpha_i^{(m-1)}+K^{(m)}\\alpha_{m-i}^{(m-1)}\\end{cases}\n$$\n\n3. LPC 系数 => 倒谱（因为是最小相位序列）\n4. PARCOR 系数($K^{(m)}$)\n   1. 由 Durbin 解得\n   2. 由格形算法解得\n   3. 由 Schur 算法解得\n5. 由 $A(z)$ 根确定振峰\n   1. 每一对根与一个共振峰对应\n6. 声道面积比系数和对数面积比系数\n\n$$\n\\frac{A_m}{A_{m-1}}=\\frac{1-K^{(m)}}{1+K^{(m)}}\\:,\\:m=1,2,\\cdots P\\\\\ng_m = \\ln\\Bigg[\\frac{A_m}{A_{m-1}}\\Bigg]\n$$\n\n7. 线谱对（LSP）或者线谱频率参数(LSF)\n\n$$\nP(z) = A^{(p)}(z) + z^{-(p+1)}A^{(p)}(z^{-1})\\\\\nQ(z) = A^{(p)}(z) - z^{-(p+1)}A^{(p)}(z^{-1})\n$$\n\n性质：\n\n1. $P(z)$ 和 $Q(z)$ 的根均在单位圆上\n2. $P(z)$ 和 $Q(z)$ 的根在单位元上交错\n3. $\\alpha$ 参数和 $LSP$ 参数互推\n\n某个特定的𝐿𝑆𝑃 [𝑓1, 𝑓2, ⋯ 𝑓𝑝]中只移动其中任意一个频率𝑓𝑖的位置，那么对应的平滑谱只\n有𝑓𝑖附近与原平滑谱有异，而在其它频域则变化很小\n\n## 语音信号编码\n\n### 语音信号的标量量化\n\n#### 标量量化器\n\n#### 均匀量化器\n\n#### 非均匀量化器\n\n#### 非线性压扩量化器\n\n### 自适应量化（Adaptive Delta Modulation，ADM）\n\n#### 前向自适应量化（AQF）\n\n#### 后向自适应量化（AQB）\n\n### 差分编码 DPCM\n\n![1713960093567](../images/Speech-SP/1713960093567.png)\n\nDPCM是指采用固定预测器与固定量化器的差值脉冲调制。\n\n### CVSD 编码器\n\n![1713958735363](../images/Speech-SP/1713958735363.png)\n\n### Delta-Sigma 量化器\n\n![1713958768829](../images/Speech-SP/1713958768829.png)\n\n考虑 $D/A$ 变换器的增益为 1 的情况，此时 $V_a(z)\\approx V(z)$，\n\n$$\n\\begin{gathered}\nV(z)=[U(z)-V(z)]\\cdot H(z)+Q(z) \\\\\n[1+H(z)]\\cdot V(z)=U(z)\\cdot H(z)+Q(z) \\\\\nV(z)=\\frac{H(z)}{1+H(z)}U(z)\\cdot+\\frac{1}{1+H(z)}Q(z) \n\\end{gathered}\n$$\n\n定义信号传输函数\n\n$$\nSTF(z)=\\frac{V(z)}{U(z)}\\Bigg|_{Q(z)=0}=\\frac{H(z)}{1+H(z)}\n$$\n\n定义超取样量化噪声传输函数\n\n$$\nNTF(z)=\\frac{V(z)}{Q(z)}\\Bigg|_{U(z)=0}=\\frac{1}{1+H(z)}\n$$\n\n让 $H(z)$ 为低通，则 $STF(z)$ 是低通，$NTF(z)$ 是高通\n\n$$\nV(z)=STF(z)\\cdot U(z)+NTF(z)\\cdot Q(z)\n$$\n\n噪声整形（Noise-Shaping）技术：$NTF(z)$ 去掉了噪声能量的低频部分。接下来，只要经过低通滤波器 $H_d(z)$，就可以滤除高频部分的噪声能量，剩下的只有所需要的信号 $U(z)$，$H_d(z)$ 的输出 $V_d(z)$ 的量化噪声可以小于直接用 A/D 量化器量化的噪声。\n\n采用速度（超采样）换精度（高量化比特数），量化器的精度可以非常低，甚至可以用 1 bit 量化器。1 bit 量化器，就不存在 A/D 非线性问题。\n\n超采样的好处：扩展了频带宽度，我们认为噪声的功率一定，当频带变宽，噪声功率谱的高度就降低了。\n\n![1713960064882](../images/Speech-SP/1713960064882.png)\n\n### 子带编码\n\n含有多个频点信号分量的复合宽带信号\n\n首先用一组滤波器将信号分解成若干子带信号\n\n$$\n\\langle f_1(t),f_2(t)\\rangle=\\frac1{2\\pi}\\cdot\\langle F_1(\\omega),F_2(\\omega)\\rangle\n$$\n\n若 $\\langle F_1(\\omega),F_2(\\omega)\\rangle\\approx0$，则采用子带滤波后，两个信号的相关性 $\\langle f_1(t),f_2(t)\\rangle$ 降低，对于这些不相关的子带信号独立编码可能提高编码效率。\n\n#### 比特数分配\n\n$$\n\\sum_{k=1}^MR_k=R\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{x_k}^2\\\\\n\n\\min_{R_k} \\sigma_{r,SBC}^2=\\sum_{k=1}^M\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{xk}^2\\\\\n$$\n\n解得\n\n$$\nR_{k,opt}=R/M+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}}\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R/M}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}\\\\\nmin\\{\\sigma_{r,SBC}^2\\}=M\\cdot\\varepsilon_*^2\\cdot2^{-\\frac{2R}{M}}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{M}}\n$$\n\n每个子带的采样率变为总带宽的 1/M，总的信息比特速率为 $R \\cdot f/M$，为了与 PCM 进行比较，假设 SBC 和 PCM 的编码速率相等：\n\n$$\nR_{PCM} \\cdot f = R_{SBC} \\cdot f / M\\\\\n\\Rarr R_{PCM} = R_{SBC}/M\n$$\n\n此时可推出 SBC 较于 PCM 的信噪比增益为\n\n$$\nmax\\{G_{SBC}\\}=\\frac{\\sigma_{r,PCM}^{2}}{\\sigma_{r,SBC}^{2}}=\\frac{2^{-2R_{PCM}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{2^{-\\frac{2R_{SBC}}{M}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}=\\frac{\\sigma_{x}^{2}}{M\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{\\frac{1}{M}\\sigma_{x}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}=\\frac{\\frac{1}{M}\\sum_{k=1}^{M}\\sigma_{xk}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}\n$$\n\n因此 SBC 的信噪比增益等于子带信号的算术平均和几何平均之比。\n\n* 子带信号能量越大，则分配比特数越多；\n* 最佳分配条件下，各个子带的量化噪声相同；\n* 若各个子带能量相同，则子带编码的增益为1\n\n#### 多相正交滤波器组\n\n用一组不同频率的余弦信号对低通滤波器进行调制，变成了带通滤波器组：\n\n$$\nH_i(z)=\\sum_{n=-\\infty}^{+\\infty}h(n)\\cdot cos\\left(\\pi(2i+1)\\cdot\\frac{n}{2M}\\right)\\cdot z^{-n}=\\frac12F_i(z)+\\frac12G_i(z)\n$$\n\n$$\nF_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega-\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\\\\G_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega+\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\n$$\n\n![1713963786950](../images/Speech-SP/1713963786950.png)\n\n分析滤波器：子带滤波，降采样；\n\n降采样率过程等价于：采样(b, 将非M倍数的采样点置为0) + 分频(c，抽取 M 倍数上的采样点形成新的信号)\n\n![1713963998639](../images/Speech-SP/1713963998639.png)\n\n$$\n\\hat{X}_i(z)=\\frac1M\\sum_{l=0}^{M-1}X_i(z^{\\frac1M}W_M^{-l})\n$$\n\n![1713965424496](../images/Speech-SP/1713965424496.png)\n\n每个子带的输出会产生四种混叠干扰：\n\n$$\n\\begin{aligned}\nU_i(e^{j\\omega})& =K_i(e^{j\\omega})\\cdot Y_i(e^{j\\omega})  \\\\\n&\\approx\\frac1MK_i(e^{j\\omega})\\{a_iF_i(e^{j\\omega})X(e^{j\\omega})+b_iG_i(e^{j\\omega})X(e^{j\\omega})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})\\} \\\\\n&i=1\\sim M-2\n\\end{aligned}\n$$\n\n为了解决升采样后的频谱混叠，在综合滤波器部分精确对消混叠信号：\n\n$$\na_id_i=-a_{i-1}d_{i-1},\\quad i>0\n$$\n\n### 变换域编码\n\n正交变换后编码：\n\n$$\nY = AX\n$$\n\n正交变换满足能量守恒\n\n$$\n||Y||^2 = ||X||^2\n$$\n\n重建信号的误差等于变换域上量化器的误差\n\n$$\nE = Y - [Y]\\\\\n||X - [x]||^2 = ||E||^2\n$$\n\n#### 比特分配\n\n假设 N 个输入样本组成一个矢量 X，变换域 Y 的每个分量用 $R_k$  个比特量化\n\n$$\nR=\\frac1N\\sum_{k=0}^{N-1}R_k\\\\\n\\sigma_q^2=\\sum_{k=0}^{N-1}\\sigma_{q,k}^2=\\varepsilon_*^2\\cdot\\sum_{k=0}^{N-1}2^{-2R_k}\\sigma_k^2\\\\\n\\min \\sigma_{q}^{2}=\\frac{1}{N}\\sum_{k=0}^{N-1}\\sigma_{q,k}^{2}\n$$\n\n$$\nR_{k,opt}=R+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/N}}\\\\\n\\sigma_{q}^2 = min\\{\\sigma_{q,k}^2\\}=\\varepsilon_*^2\\cdot2^{-2R}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{N}}\n$$\n\n相比 PCM 的增益为\n\n$$\n\\begin{gathered}\nG_{TC} =\\frac{min\\{\\sigma_{r,PCM}^{2}\\}}{min\\{\\sigma_{r,TC}^{2}\\}}=\\frac{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\sigma_{\\chi}^{2}}{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\prod_{k=0}^{N-1}[\\sigma_{k}^{2}]^{\\frac{1}{N}}} \\\\\n=\\frac{\\sigma_x^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}}=\\frac{\\frac1N\\sum_{k=0}^{N-1}\\sigma_k^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}} \n\\end{gathered}\n$$\n\n#### 最佳正交变换 - KL 变换\n\n## 语音信号的参数编码\n\n### 感觉加权滤波器\n\n误差函数加权：\n\n$$\nJ=\\int_0^{f_s}\\lvert s(f)-\\hat{s}(f)\\rvert^2\\cdot\\lvert w(f)\\rvert^2df\n$$\n\n其中，加权滤波器满足\n\n$$\n\\int_0^{f_S}|w(f)|df= Const.\n$$\n\n当误差函数最小的时候，应当保证\n\n$$\n|s(f)-\\hat{s}(f)|^2\\cdot|w(f)|=\\frac{\\gamma}{2}=\\text{常数}\n$$\n\n可以选择如下的滤波器：\n\n$$\nw(z)=\\frac{A(z)}{A\\left(\\frac{z}{\\gamma}\\right)}=\\frac{1-\\sum_{i=1}^P\\alpha_iz^{-i}}{1-\\sum_{i=1}^P\\alpha_i\\gamma^iz^{-i}},\\quad0\\leq\\gamma\\leq1\n$$\n\n$\\gamma$ 为加权因子，在 0-1 之间。\n\n$\\gamma=0$ 时变成逆滤波器，其频谱包络的峰值点就是语音谱的谷值点。\n\n> 分析：语音信号是全极点模型产生的，即 $S(z) = GE(z)/A(z)$，与逆滤波器点频谱成反比。\n\n![1715172645812](../images/Speech-SP/1715172645812.png)\n\n### 多脉冲激励线性预测声码器\n\n![1715172680511](../images/Speech-SP/1715172680511.png)\n\n语音综合器的激励源有若干个不同位置和幅度的脉冲信号组成。\n\n$$\n\\hat{s}(n)=\\hat{s}_0(n)+\\sum_{k=1}^Mg_kh(n-n_k)\n$$\n\n其中 $\\hat s_0(n)$ 是 LPC 综合器的零输入响应。\n\n$$\n\\begin{aligned}&e_{s}(n)=s(n)-\\hat{s}(n)=s(n)-\\hat{s}_{0}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\\\&=\\bar{e}(n)-\\sum_{k=1}^Mg_kh(n-n_k)\\end{aligned}\n$$\n\n用 $\\bar{e}(n)=s(n)-\\hat{s}_0(n)$ 表示输入语音减去零输入响应（受历史激励影响的部分）。\n\n输入感觉加权滤波器，得到输出\n\n$$\n\\begin{aligned}e(n)&=e_{s}(n)*w(n)=\\left[\\bar{e}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\right]*w(n)\\\\&=\\bar{e}_{w}(n)-\\sum_{k=1}^{M}g_{k}h_{w}(n-n_{k})\\end{aligned}\n$$\n\n从而，得到感觉加权滤波器的误差函数\n\n$$\nE=\\sum_{n=1}^Ne^2(n)=\\sum_{n=1}^N\\left[\\bar{e}_w(n)-\\sum_{k=1}^Mg_kh_w(n-n_k)\\right]^2\n$$\n\n选择合适的 $n_k$, $g_k$ 使得上面的误差函数最小\n\n$$\n\\frac{\\partial E}{\\partial n_j}=0,\\quad j=1,\\cdots M\\\\\\frac{\\partial E}{\\partial g_j}=0,\\quad j=1,\\cdots M\n$$\n\n上面那个方程很复杂，会导出非线性的方程；\n\n从下面的那个方程可以推出\n\n$$\n\\sum_{k=1}^Mg_kR_{hh}(n_k,n_j)=R_{eh}(n_j),\\quad j=1,\\cdots M\n$$\n\n其中\n\n$$\nR_{eh}(n_j)=\\sum_{n=1}^N\\bar{e}_w(n)\\cdot h_w(n-n_j)\\\\R_{hh}(n_k,n_j)=\\sum_{n=1}^Nh_w(n-n_k)h_w(n-n_j)\n$$\n\n此时可改写最小均方误差\n\n$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-\\sum_{k=1}^Mg_kR_{eh}(n_k)\n$$\n\n最优解的计算涉及到非线性方程的求解，不太现实。考虑采用次优搜索，一个一个求解。\n\n当只有一个脉冲时\n\n$$\ng_1R_{hh}(n_1,n_1)=R_{eh}(n_1)\\\\\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-g_1R_{eh}(n_1)\n$$\n\n消元得到\n\n$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-R_{eh}^2(n_1)/R_{hh}(n_1,n_1)\n$$\n\n接下来搜索 $n_1$ 使得上式最优化。解出 $n_1$ 后即可解出 $g_1$。\n\n接下来一个个求解，每次都要把前面求解过的脉冲折算到零输入响应中，然后求解当前的结果：\n\n## 语音信号修整与综合技术\n\n短时谱分析\n\n$$\n\\begin{gathered}w[n]=\\begin{cases}\\neq0&,&0\\leq n<L\\\\0&,&\\text{其它}\\end{cases}\\\\X(p,k)=\\sum_{n=-\\infty}^{+\\infty}x[n]w[p-n]e^{-j\\frac{2\\pi}{N}nk}\\\\x[n]w[p-n]=\\left[\\frac{1}{N}\\sum_{i=0}^{N-1}X(p,k)e^{j\\frac{2\\pi}{N}nk}\\right]\\cdot R[p-n]\\end{gathered}\n$$\n\n### 利用修正短时谱进行最小方差信号估计\n\n首先计算短时谱\n\n$$\nX(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}x[m]w(p-m)e^{-j\\omega m}\n$$\n\n对短时谱进行修正\n\n$$\nY(p,\\omega)=X(p,\\omega)H(p,\\omega)\n$$\n\n需要得到一个“有效”的短时谱，满足：\n\n1. 时域短时段有限长，非零段不超过窗函数 $w(p-n)$的范围\n2. 一致性约束，即不同的𝑝时刻 𝑌(𝑝,𝜔)所对应的时域短时段，若有部分重叠，那么在去除分析窗的加权影响后，在重叠的部分，它们应该是相等的。\n\n实际上很难得到上述信号，可以通过最小方差准则逼近\n\n$$\nD[\\hat{Y}(n,\\omega),Y(n,\\omega)]=\\sum_{m=-\\infty}^{+\\infty}\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}\\left|\\hat{Y}(m,\\omega)-Y(m,\\omega)\\right|^{2}d\\omega\n$$\n\n其中\n\n$$\n\\hat{Y}(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}\\hat{y}[m]w(p-m)e^{-j\\omega m}\n$$\n\n利用 Parseval 定理\n\n$$\n\\begin{aligned}&D\\big[\\hat{Y}(n,\\omega),Y(n,\\omega)\\big]=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}_{m}(n)-y_{m}(n)|^{2}\\\\&=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}(n)w(m-n)-y_{m}(n)|^{2}\\end{aligned}\n$$\n\n变分法求得最小值\n\n$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(m-n)y_m(n)}{\\sum_{m=-\\infty}^\\infty w^2(m-n)}\n$$\n\n其中\n\n$$\ny_m(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi Y(m,\\omega)e^{j\\omega n}d\\omega\n$$\n\n应用中，以周期 $T$ 分析\n\n$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)y_{mT}(n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$\n\n如果 $w(n)$ 取三角窗的平方根\n\n$$\nw^2(n)=\\begin{cases}1-\\frac{|n-T|}{T}&,\\quad0\\leq n\\leq2T\\\\\\\\0&,\\quad\\text{其它}\\end{cases}\n$$\n\n若 n 此时为奇数，$T = (N-1)/2$，这时$\\sum_{m=-\\infty}^{\\infty}w^{2}(mT-n)=1$，可简化计算，如果频谱无修正，最优解为\n\n$$\n\\hat{y}(n)=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)[w(mT-n)x(n)]}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=\\frac{x(n)\\sum_{m=-\\infty}^\\infty w^2(mT-n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=x(n)\n$$\n\n若改变语音的速度，$p=k\\cdot p^{\\prime}$，满足$|Y(p,\\omega)|=|X(p^{\\prime},\\omega)|$ 。\n\n$$\ny_{p'}(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}Y(p',\\omega)e^{j\\omega n}d\\omega=w(p'-n)x(n)\n$$\n\n让 $\\tau_p=p-p^{\\prime}=(1-1/k)\\cdot p$，\n\n$$\n\\begin{aligned}&y_p(n)=y_{p^{\\prime}}(n-\\tau_p)=w(p^{\\prime}-n+\\tau_p)x(n-\\tau_p)\\\\&=w(p-n)x(n-\\tau_p)\\end{aligned}\n\n$$\n\n代入重建公式\n\n$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w^2(mT-n)x(n-\\tau_{mT})}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$\n\n让$\\sum_{m=-\\infty}^{\\infty}W(mT-n)= \\sum_{m=-\\infty}^{\\infty}w^2(mT-n) =1$，\n\n$$\n\\hat{y}[n]=\\sum_{m=-\\infty}^{\\infty}W(mT-n)x(n-\\tau_{mT})\n$$\n","slug":"Speech-SP","published":1,"updated":"2024-05-29T13:19:02.607Z","_id":"clu1gtfhx000irsug1k3n097d","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"语音信号的线性预测编码技术\"><a href=\"#语音信号的线性预测编码技术\" class=\"headerlink\" title=\"语音信号的线性预测编码技术\"></a>语音信号的线性预测编码技术</h2><p>线性预测编码技术（维纳滤波）。可以参考隔壁统计信号处理的笔记hh。</p>\n<p>维纳滤波的正交原理：</p>\n<div>$$\nE \\langle x(n-k), e(n) \\rangle = 0\n$$</div>\n\n<p>正交原理可以用来估计任何时候的任何值，不管是现在（滤波），过去（平滑）还是未来（预测），也不管估计的对象是 $x,y$，上述公式的含义是：估计误差始终与已知信号垂直，与估计的是哪个时间的信号无关。</p>\n<p>利用前面的 $P$ 个信号预测下一个信号：</p>\n<div>$$\n\\hat{s}(n)=-\\sum_{i=1}^{P^{\\prime}}\\hat{\\alpha}_i\\cdot s(n-i)\n$$</div>\n\n<p>误差定义为</p>\n<div>$$\n\\begin{aligned}\n\\varepsilon(n)& =s(n)-\\overset{\\wedge}{\\operatorname*{s}}(n)=s(n)+\\sum_{i=1}\\widehat{\\alpha}_i\\cdot s(n-i)  \\\\\n&=\\sum_{i=0}^{P^{\\prime}}\\widehat{\\alpha}_i\\cdot s(n-i)\n\\end{aligned}\n$$</div>\n\n<p>从 z 域看，这是一个全极点模型产生了目标信号：</p>\n<div>$$\nS(z) = -S(z)\\sum\\limits_{i=1}^{P}\\alpha_iz^{-i} + E(z)\n$$</div>\n\n<p>接下来的所有步骤，目的都是推导 $\\alpha$ 的取值。</p>\n<h3 id=\"自相关法\"><a href=\"#自相关法\" class=\"headerlink\" title=\"自相关法\"></a>自相关法</h3><p>本文中假设信号具有遍历性，即时间平均等于统计平均，时间上的自相关等于统计意义上的自相关。</p>\n<p>利用 LMMSE 准则可以推出</p>\n<div>$$\n\\begin{bmatrix}R(0)&R(1)&R(2)&\\cdots&R(P-1)\\\\R(1)&R(0)&R(1)&\\cdots&R(P-2)\\\\R(2)&R(1)&R(0)&\\cdots&R(P-3)\\\\\\vdots&\\vdots&&&\\vdots\\\\R(P-1)&R(P-2)&\\cdots&\\cdots&R(0)\\end{bmatrix}\\cdot\\begin{bmatrix}\\hat\\alpha_1\\\\\\hat\\alpha_2\\\\\\vdots\\\\\\vdots\\\\\\hat\\alpha_P\\end{bmatrix}=-\\begin{bmatrix}R(1)\\\\R(2)\\\\\\vdots\\\\\\vdots\\\\R(P)\\end{bmatrix}\n$$</div>\n\n<p>一个例子：Durbin 递推算法</p>\n<h3 id=\"协方差法\"><a href=\"#协方差法\" class=\"headerlink\" title=\"协方差法\"></a>协方差法</h3><p>不能保证声码器稳定</p>\n<h3 id=\"Durbin-递推算法\"><a href=\"#Durbin-递推算法\" class=\"headerlink\" title=\"Durbin 递推算法\"></a>Durbin 递推算法</h3><h4 id=\"滤波器的内积\"><a href=\"#滤波器的内积\" class=\"headerlink\" title=\"滤波器的内积\"></a>滤波器的内积</h4><p>定义$s_w(n)$关于$F(z)$和$G(z)$的内积如下：</p>\n<div>$$\n\\langle F(z),G(z)\\rangle=\\sum_{-\\infty}^{+\\infty}u(n)\\cdot v(n)\n$$</div>\n\n<p>特别地若这里的$F(z),\\quad G(z)$都用我们的逆滤波器$A(z)&#x3D;\\sum_{i&#x3D;0}^P\\alpha_iZ^{-i}$替换，那么语音信号$s_w(n)$经过$A(z)$后的输出$e(n)$就是预测误差。</p>\n<p>$\\alpha_i\\cdot s_W(n-i)$ 因此$A(z)$范数$|A(z)|$的平方就是预测误差。即</p>\n<div>$$\n\\|A(z)\\|^2=\\langle A(z),A(z)\\rangle=\\sum_{-\\infty}^{+\\infty}e(n)\\cdot e(n)=\\sum_{-\\infty}^{+\\infty}e^2(n)\n$$</div>\n\n<p>内积有正定性，线性，三角不等式</p>\n<p>特殊性质：</p>\n<div>$$\n\\langle z^{-i}, z^{-j} \\rangle = R(|i - j|)\\\\\n\\langle F(z), G(z) \\rangle = \\sum\\limits_{i=0}^{M}\\sum\\limits_{j=0}^{M}f_ig_jR(|i - j|)\\\\\n\\langle F(z),G(z)\\rangle=\\left\\langle z^kF(z),z^kG(z)\\right\\rangle\\\\\n\\langle F(z),G(z)\\rangle=\\langle F(1/z),G(1/z)\\rangle\n$$</div>\n\n<h4 id=\"逆滤波器\"><a href=\"#逆滤波器\" class=\"headerlink\" title=\"逆滤波器\"></a>逆滤波器</h4><p>定义FIR滤波器$\\hat{A}(z)$:</p>\n<div>$$\n\\hat{A}(z)=\\sum_{i=0}^P\\hat{\\alpha}_iz^{-i}\\quad,\\quad\\alpha_0=1\n$$</div>\n\n<p>若$\\hat{\\alpha}_{i}$是满足LPC正则方程的解，则称$\\hat{A}(z)$称为逆滤波器。$\\hat{E}(z)&#x3D;\\hat{A}(z)\\cdot S(z)$是预测误差$\\varepsilon(n)$的z 变换。显然有：</p>\n<p> (1) 若s(n)是由全极点模型$1&#x2F;A(z)$产生的，这时$A(z)&#x3D;\\sum_{i&#x3D;0}^P\\alpha_iz^{-i}$, 即：</p>\n<p>$s(n)&#x3D;-\\sum_{i&#x3D;1}^P\\alpha_is(n-i)+Ge(n)$</p>\n<div>$$\nS(z) \\cdot A(z) = G \\cdot E(z)\n$$</div>\n\n<h4 id=\"前向和后向预测\"><a href=\"#前向和后向预测\" class=\"headerlink\" title=\"前向和后向预测\"></a>前向和后向预测</h4><p>前向线性预测器(P阶)</p>\n<div>$$\n\\hat{s}(n)=-\\sum_{i=1}^P\\alpha_i^{(P)}\\cdot s(n-i)\n$$</div>\n\n<p>前向预测误差(P阶)</p>\n<div>$$\n\\varepsilon_\\alpha^{(P)}(n)=s(n)-\\hat{s}(n)=\\sum_{i=0}^P\\alpha_i^{(P)}\\cdot s(n-i)\\:,\\alpha_0^{(P)}=1\n$$</div>\n\n<p>前向逆滤波器(P阶)</p>\n<div>$$\nA^{(P)}(z)=\\sum_{i=0}^P\\alpha_i^{(P)}z^{-i}\n$$</div>\n\n<p>显然有</p>\n<div>$$\nE^{(P)}_\\alpha(z) = S(z) \\cdot A^{(P)}(z)\n$$</div>\n\n<p>后向线性预测器(P阶)</p>\n<div>$$\n\\hat{s}(n-P-1)=-\\sum_{i=1}^P\\beta_i^{(P)}\\cdot s(n-i)\n$$</div>\n\n<p>n时刻对$s(n-P-1)$的后向预测误差(P阶)</p>\n<div>$$\n\\begin{aligned}&\\varepsilon_{\\beta}^{(P)}(n)=s(n-P-1)-\\hat{s}(n-P-1)\\\\&=\\sum_{i=1}^{P+1}\\beta_i^{(P)}\\cdot s(n-i)\\quad,\\quad\\beta_{P+1}^{(P)}=1\\end{aligned}\n$$</div>\n\n<p>后向逆滤波器 (P阶)</p>\n<div>$$\nB^{(P)}(z)=\\sum_{i=1}^{P+1}\\beta_i^{(P)}z^{-i}\n$$</div>\n\n<p>显然有</p>\n<div>$$\nE_\\beta^{(P)}(z) = S(z) \\cdot B^{(P)}(z)\n$$</div>\n\n<h4 id=\"正交性原理\"><a href=\"#正交性原理\" class=\"headerlink\" title=\"正交性原理\"></a>正交性原理</h4><p>判定最佳预测器的充要条件是</p>\n<div>$$\n\\langle A^{(m)}(z), z^{-l} \\rangle = 0\\\\\n\\langle B^{(m)}(z), z^{-l} \\rangle = 0\\\\\nl = 1, 2, \\dots, m\n$$</div>\n\n<p>一个不严谨的理解：</p>\n<div>$$\nu(n) = s(n) * Z^{-1}[A(z)] = \\varepsilon(n)\\\\\nv(n) = s(n) * Z^{-1}[z^{-l}] = s(n - l)\\\\\n\\begin{align*}\n    &\\langle A^{(m)}(z), z^{-l} \\rangle\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}u(n)v(n)\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}\\varepsilon(n)s(n - l)\\\\\n\\end{align*}\n$$</div>\n\n<p>由于时间平均等于统计平均，</p>\n<div>$$\n\\frac1{2N} \\sum\\limits_{n=-N}^{N - 1}\\varepsilon(n)s(n-l) = E \\langle \\varepsilon(n), s(n-l) \\rangle\n$$</div>\n\n<p>根据开头提到的维纳滤波正交原理可知上式等于0。</p>\n<h4 id=\"递推公式\"><a href=\"#递推公式\" class=\"headerlink\" title=\"递推公式\"></a>递推公式</h4><p>根据定义，当$m&#x3D;0$时，显然有</p>\n<div>$$\nA^{(0)}(z)=1\\\\B^{(0)}(z)=z^{-1}\n$$</div>\n\n<p>$m&gt;0$时有如下递推公式（施密特正交化）</p>\n<div>$$\nA^{(m)}(z)=A^{(m-1)}(z)+K^{(m)}B^{(m-1)}(z)\n$$</div>\n\n<div>$$\nB^{(m)}(z)=z^{-1}\\Big[B^{(m-1)}(z)+K^{(m)}A^{(m-1)}(z)\\Big]\n$$</div>\n\n<div>$$\nK^{(m)} = -\\frac{\\langle A^{(m-1)}(z), B^{(m-1)}(z)\\rangle}{||B^{(m-1)}(z)||^2}\n$$</div>\n\n<p>根据正交性原理，需要证明由递推公式得到的$A^{(m)}(z)$和$B^{(m)}(z)$满足正交性条件公式。</p>\n<p> 在公式(76) 中，根据多项式对应项系数相等的原则，可以得到</p>\n<div>$$\n\\begin{aligned}&\\alpha_{i}^{(m)}=\\alpha_{i}^{(m-1)}+K^{(m)}\\cdot\\beta_{i}^{(m-1)}\\quad,\\quad i=1,\\cdots,m-1\\\\&\\alpha_{i}^{(m)}=K^{(m)}\\quad,\\quad i=m\\end{aligned}\n$$</div>\n\n<p>由公式(73)可知</p>\n<div>$$\n\\beta_j^{(m)}=\\alpha_{m+1-j}^{(m)},\\:j=1,\\cdots,m+1\n$$</div>\n\n<blockquote>\n<p>从这里可以推出</p>\n<div>$$\nB^{(m)}(z) = z^{-(m+1)}A^{(m)}(1/z)\n$$</div>\n</blockquote>\n<p>因此可以得到预测器系数的递推公式</p>\n<div>$$\n\\begin{cases}\\alpha_\\mathrm{m}^{(\\mathrm{m})}=\\mathrm{K}^{(\\mathrm{m})}\\\\\\alpha_\\mathrm{i}^{(\\mathrm{m})}=\\alpha_\\mathrm{i}^{(\\mathrm{m}-1)}+\\mathrm{K}^{(\\mathrm{m})}\\cdot\\alpha_\\mathrm{m-i}^{(\\mathrm{m}-1)}\\quad,\\:\\mathrm{i}=1,\\cdots,\\mathrm{m}-1\\end{cases}\n$$</div>\n\n<p>这是线性预测系数的Durbin递推算法公式。$m$阶部分相关系数$K^{(m)}$可以用以下方法计算：</p>\n<div>$$\nK^{(m)} = -\\frac{\\sum\\limits_{j=1}^{m}\\alpha_{m-j}^{(m-1)}R(j)}{||B^{(m-1)}(z)||^2}\n$$</div>\n\n<p>$||B^{(m)}(z)||^2$ 可以用这个递推式计算：</p>\n<div>$$\n\\begin{Vmatrix}B^{(m)}(z)\\end{Vmatrix}^2=(1-[K^{(m)}]^2)\\begin{Vmatrix}B^{(m-1)}(z)\\end{Vmatrix}^2\n$$</div>\n\n<p>初值</p>\n<div>$$\n||B^{(0)}(z)|| = R(0)\\\\\n\\alpha^{(0)}_0 = 1\n$$</div>\n\n<h3 id=\"Durbin-算法系统的稳定性\"><a href=\"#Durbin-算法系统的稳定性\" class=\"headerlink\" title=\"Durbin 算法系统的稳定性\"></a>Durbin 算法系统的稳定性</h3><p>充分性：</p>\n<div>$$\n\\frac{1}{A^{(m)}(z)} 稳定 \\Rarr |k^{(m)}| < 1\n$$</div>\n\n<p>必要性：</p>\n<div>$$\n|k^{(m)}| < 1 \\Rarr \\frac{1}{A^{(m)}(z)} 稳定\n$$</div>\n\n<p>Highlight:</p>\n<p>Durbin 逆序递推公式</p>\n<div>$$\nA^{(m-1)}(z)=\\frac{A^{(m)}(z)-k^{(m)}zB^{(m)}(z)}{1-(k^{(m)})^2}\n$$</div>\n\n<p>证明过程中引入的一个辅助函数</p>\n<div>$$\nF^{(m)}(z)=\\frac{A^{(m)}(z)}{zB^{(m)}(z)}=\\frac{z^mA^{(m)}(z)}{A^{(m)}(1/z)}\n$$</div>\n\n<p>满足 $F^{(m)}(z) &lt; 1 \\lrArr |z| &lt; 1$</p>\n<h4 id=\"稳定性的应用\"><a href=\"#稳定性的应用\" class=\"headerlink\" title=\"稳定性的应用\"></a>稳定性的应用</h4><p>充分性：说明使用 Durbin 算法可以保证 $1&#x2F;A(z)$ 稳定</p>\n<p>必要性：</p>\n<p>判定高阶多项式 $A(z)$ 构成的系统 $1&#x2F;A(z)$ 是否稳定。</p>\n<p>只要计算出 $k_m$，判断 $|k_m|$ 是否小于1即可。</p>\n<h3 id=\"LPC-模型参数讨论\"><a href=\"#LPC-模型参数讨论\" class=\"headerlink\" title=\"LPC 模型参数讨论\"></a>LPC 模型参数讨论</h3><h4 id=\"阶数\"><a href=\"#阶数\" class=\"headerlink\" title=\"阶数\"></a>阶数</h4><p>误差能量是单调减的，一般 $P &#x3D; 8 \\sim 14$</p>\n<h4 id=\"激励增益-G\"><a href=\"#激励增益-G\" class=\"headerlink\" title=\"激励增益 G\"></a>激励增益 G</h4><p>采用缓变窗（哈明窗），$N &gt;&gt; P$</p>\n<div>$$\n\\varepsilon_\\alpha^{(p)}(n)\\approx Ge_w(n)=Ge(n)w(n)\n$$</div>\n\n<div>$$\nG^2\\approx\\frac{\\sum_{n=-\\infty}^\\infty\\left(\\varepsilon_\\alpha^{(p)}(n)\\right)^2}{\\sum_{n=-\\infty}^\\infty e^2(n)w^2(n)}\n$$</div>\n\n<h4 id=\"短时分析对于LPC参数估计的影响\"><a href=\"#短时分析对于LPC参数估计的影响\" class=\"headerlink\" title=\"短时分析对于LPC参数估计的影响\"></a>短时分析对于LPC参数估计的影响</h4><ol>\n<li>𝑒(𝑛)为白噪声时，$E[\\hat \\alpha_i] &#x3D; \\alpha_i$，无偏估计</li>\n<li>𝑒(𝑛)为浊音时，采用基音同步算法可以达到无偏估计。否则如果是任意截取一段语音作分析估计是有偏的。</li>\n</ol>\n<h4 id=\"LPC分析的频域解释\"><a href=\"#LPC分析的频域解释\" class=\"headerlink\" title=\"LPC分析的频域解释\"></a>LPC分析的频域解释</h4><p>用LPC分析可以用来跟踪声道模型谱（或称语音的平滑谱）。若用LPC算法解出的全极点模型来逼近实际声道，则它的单位冲激响应ℎ(𝑛)为：</p>\n<div>$$\n\\begin{cases}\n    h(n) = 0, n \\lt 0\\\\\n    h(n) = - \\sum\\limits_{i=1}^{p}\\alpha_i^{(p)}h(n - 1) + \\delta(n), n \\ge 0\n\\end{cases}\n$$</div>\n\n<p>若 $R_h(l) &#x3D; R_h(-l) &#x3D; \\sum\\limits_{n&#x3D;0}^{\\infty}h(n - l)h(n), l \\ge 0$</p>\n<div>$$\n\\sum\\limits_{i=1}^{p}\\alpha_i^{(P)}R_h(|k - i|) = -R_h(k), l \\ge 0\\\\\nR_h(l)/R_h(0) = R(l) / R(0)\n$$</div>\n\n<p>当激励为均方值为1，均值为0的白噪声序列时，输出的自关函数𝑅𝑤(𝑙)也有此关系。<br>P阶LPC预测模型也称为P阶自关匹配模型。</p>\n<h4 id=\"各种LPC参数计算其它们之间的关系\"><a href=\"#各种LPC参数计算其它们之间的关系\" class=\"headerlink\" title=\"各种LPC参数计算其它们之间的关系\"></a>各种LPC参数计算其它们之间的关系</h4><ol>\n<li>$R(l) \\Rightarrow \\alpha$</li>\n<li>$K \\Rightarrow \\alpha$</li>\n</ol>\n<div>$$\n\\begin{cases}\\alpha_m^m=K^{(m)}\\\\\\alpha_i^{(m)}=\\alpha_i^{(m-1)}+K^{(m)}\\alpha_{m-i}^{(m-1)}\\end{cases}\n$$</div>\n\n<ol start=\"3\">\n<li>LPC 系数 &#x3D;&gt; 倒谱（因为是最小相位序列）</li>\n<li>PARCOR 系数($K^{(m)}$)<ol>\n<li>由 Durbin 解得</li>\n<li>由格形算法解得</li>\n<li>由 Schur 算法解得</li>\n</ol>\n</li>\n<li>由 $A(z)$ 根确定振峰<ol>\n<li>每一对根与一个共振峰对应</li>\n</ol>\n</li>\n<li>声道面积比系数和对数面积比系数</li>\n</ol>\n<div>$$\n\\frac{A_m}{A_{m-1}}=\\frac{1-K^{(m)}}{1+K^{(m)}}\\:,\\:m=1,2,\\cdots P\\\\\ng_m = \\ln\\Bigg[\\frac{A_m}{A_{m-1}}\\Bigg]\n$$</div>\n\n<ol start=\"7\">\n<li>线谱对（LSP）或者线谱频率参数(LSF)</li>\n</ol>\n<div>$$\nP(z) = A^{(p)}(z) + z^{-(p+1)}A^{(p)}(z^{-1})\\\\\nQ(z) = A^{(p)}(z) - z^{-(p+1)}A^{(p)}(z^{-1})\n$$</div>\n\n<p>性质：</p>\n<ol>\n<li>$P(z)$ 和 $Q(z)$ 的根均在单位圆上</li>\n<li>$P(z)$ 和 $Q(z)$ 的根在单位元上交错</li>\n<li>$\\alpha$ 参数和 $LSP$ 参数互推</li>\n</ol>\n<p>某个特定的𝐿𝑆𝑃 [𝑓1, 𝑓2, ⋯ 𝑓𝑝]中只移动其中任意一个频率𝑓𝑖的位置，那么对应的平滑谱只<br>有𝑓𝑖附近与原平滑谱有异，而在其它频域则变化很小</p>\n<h2 id=\"语音信号编码\"><a href=\"#语音信号编码\" class=\"headerlink\" title=\"语音信号编码\"></a>语音信号编码</h2><h3 id=\"语音信号的标量量化\"><a href=\"#语音信号的标量量化\" class=\"headerlink\" title=\"语音信号的标量量化\"></a>语音信号的标量量化</h3><h4 id=\"标量量化器\"><a href=\"#标量量化器\" class=\"headerlink\" title=\"标量量化器\"></a>标量量化器</h4><h4 id=\"均匀量化器\"><a href=\"#均匀量化器\" class=\"headerlink\" title=\"均匀量化器\"></a>均匀量化器</h4><h4 id=\"非均匀量化器\"><a href=\"#非均匀量化器\" class=\"headerlink\" title=\"非均匀量化器\"></a>非均匀量化器</h4><h4 id=\"非线性压扩量化器\"><a href=\"#非线性压扩量化器\" class=\"headerlink\" title=\"非线性压扩量化器\"></a>非线性压扩量化器</h4><h3 id=\"自适应量化（Adaptive-Delta-Modulation，ADM）\"><a href=\"#自适应量化（Adaptive-Delta-Modulation，ADM）\" class=\"headerlink\" title=\"自适应量化（Adaptive Delta Modulation，ADM）\"></a>自适应量化（Adaptive Delta Modulation，ADM）</h3><h4 id=\"前向自适应量化（AQF）\"><a href=\"#前向自适应量化（AQF）\" class=\"headerlink\" title=\"前向自适应量化（AQF）\"></a>前向自适应量化（AQF）</h4><h4 id=\"后向自适应量化（AQB）\"><a href=\"#后向自适应量化（AQB）\" class=\"headerlink\" title=\"后向自适应量化（AQB）\"></a>后向自适应量化（AQB）</h4><h3 id=\"差分编码-DPCM\"><a href=\"#差分编码-DPCM\" class=\"headerlink\" title=\"差分编码 DPCM\"></a>差分编码 DPCM</h3><p><img src=\"/../images/Speech-SP/1713960093567.png\" alt=\"1713960093567\" loading=\"lazy\"></p>\n<p>DPCM是指采用固定预测器与固定量化器的差值脉冲调制。</p>\n<h3 id=\"CVSD-编码器\"><a href=\"#CVSD-编码器\" class=\"headerlink\" title=\"CVSD 编码器\"></a>CVSD 编码器</h3><p><img src=\"/../images/Speech-SP/1713958735363.png\" alt=\"1713958735363\" loading=\"lazy\"></p>\n<h3 id=\"Delta-Sigma-量化器\"><a href=\"#Delta-Sigma-量化器\" class=\"headerlink\" title=\"Delta-Sigma 量化器\"></a>Delta-Sigma 量化器</h3><p><img src=\"/../images/Speech-SP/1713958768829.png\" alt=\"1713958768829\" loading=\"lazy\"></p>\n<p>考虑 $D&#x2F;A$ 变换器的增益为 1 的情况，此时 $V_a(z)\\approx V(z)$，</p>\n<div>$$\n\\begin{gathered}\nV(z)=[U(z)-V(z)]\\cdot H(z)+Q(z) \\\\\n[1+H(z)]\\cdot V(z)=U(z)\\cdot H(z)+Q(z) \\\\\nV(z)=\\frac{H(z)}{1+H(z)}U(z)\\cdot+\\frac{1}{1+H(z)}Q(z) \n\\end{gathered}\n$$</div>\n\n<p>定义信号传输函数</p>\n<div>$$\nSTF(z)=\\frac{V(z)}{U(z)}\\Bigg|_{Q(z)=0}=\\frac{H(z)}{1+H(z)}\n$$</div>\n\n<p>定义超取样量化噪声传输函数</p>\n<div>$$\nNTF(z)=\\frac{V(z)}{Q(z)}\\Bigg|_{U(z)=0}=\\frac{1}{1+H(z)}\n$$</div>\n\n<p>让 $H(z)$ 为低通，则 $STF(z)$ 是低通，$NTF(z)$ 是高通</p>\n<div>$$\nV(z)=STF(z)\\cdot U(z)+NTF(z)\\cdot Q(z)\n$$</div>\n\n<p>噪声整形（Noise-Shaping）技术：$NTF(z)$ 去掉了噪声能量的低频部分。接下来，只要经过低通滤波器 $H_d(z)$，就可以滤除高频部分的噪声能量，剩下的只有所需要的信号 $U(z)$，$H_d(z)$ 的输出 $V_d(z)$ 的量化噪声可以小于直接用 A&#x2F;D 量化器量化的噪声。</p>\n<p>采用速度（超采样）换精度（高量化比特数），量化器的精度可以非常低，甚至可以用 1 bit 量化器。1 bit 量化器，就不存在 A&#x2F;D 非线性问题。</p>\n<p>超采样的好处：扩展了频带宽度，我们认为噪声的功率一定，当频带变宽，噪声功率谱的高度就降低了。</p>\n<p><img src=\"/../images/Speech-SP/1713960064882.png\" alt=\"1713960064882\" loading=\"lazy\"></p>\n<h3 id=\"子带编码\"><a href=\"#子带编码\" class=\"headerlink\" title=\"子带编码\"></a>子带编码</h3><p>含有多个频点信号分量的复合宽带信号</p>\n<p>首先用一组滤波器将信号分解成若干子带信号</p>\n<div>$$\n\\langle f_1(t),f_2(t)\\rangle=\\frac1{2\\pi}\\cdot\\langle F_1(\\omega),F_2(\\omega)\\rangle\n$$</div>\n\n<p>若 $\\langle F_1(\\omega),F_2(\\omega)\\rangle\\approx0$，则采用子带滤波后，两个信号的相关性 $\\langle f_1(t),f_2(t)\\rangle$ 降低，对于这些不相关的子带信号独立编码可能提高编码效率。</p>\n<h4 id=\"比特数分配\"><a href=\"#比特数分配\" class=\"headerlink\" title=\"比特数分配\"></a>比特数分配</h4><div>$$\n\\sum_{k=1}^MR_k=R\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{x_k}^2\\\\\n\n<p>\\min_{R_k} \\sigma_{r,SBC}^2&#x3D;\\sum_{k&#x3D;1}^M\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{xk}^2\\<br>$$</div></p>\n<p>解得</p>\n<div>$$\nR_{k,opt}=R/M+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}}\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R/M}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}\\\\\nmin\\lbrace\\sigma_{r,SBC}^2\\rbrace=M\\cdot\\varepsilon_*^2\\cdot2^{-\\frac{2R}{M}}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{M}}\n$$</div>\n\n<p>每个子带的采样率变为总带宽的 1&#x2F;M，总的信息比特速率为 $R \\cdot f&#x2F;M$，为了与 PCM 进行比较，假设 SBC 和 PCM 的编码速率相等：</p>\n<div>$$\nR_{PCM} \\cdot f = R_{SBC} \\cdot f / M\\\\\n\\Rarr R_{PCM} = R_{SBC}/M\n$$</div>\n\n<p>此时可推出 SBC 较于 PCM 的信噪比增益为</p>\n<div>$$\nmax\\{G_{SBC}\\}=\\frac{\\sigma_{r,PCM}^{2}}{\\sigma_{r,SBC}^{2}}=\\frac{2^{-2R_{PCM}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{2^{-\\frac{2R_{SBC}}{M}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}=\\frac{\\sigma_{x}^{2}}{M\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{\\frac{1}{M}\\sigma_{x}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}=\\frac{\\frac{1}{M}\\sum_{k=1}^{M}\\sigma_{xk}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}\n$$</div>\n\n<p>因此 SBC 的信噪比增益等于子带信号的算术平均和几何平均之比。</p>\n<ul>\n<li>子带信号能量越大，则分配比特数越多；</li>\n<li>最佳分配条件下，各个子带的量化噪声相同；</li>\n<li>若各个子带能量相同，则子带编码的增益为1</li>\n</ul>\n<h4 id=\"多相正交滤波器组\"><a href=\"#多相正交滤波器组\" class=\"headerlink\" title=\"多相正交滤波器组\"></a>多相正交滤波器组</h4><p>用一组不同频率的余弦信号对低通滤波器进行调制，变成了带通滤波器组：</p>\n<div>$$\nH_i(z)=\\sum_{n=-\\infty}^{+\\infty}h(n)\\cdot cos\\left(\\pi(2i+1)\\cdot\\frac{n}{2M}\\right)\\cdot z^{-n}=\\frac12F_i(z)+\\frac12G_i(z)\n$$</div>\n\n<div>$$\nF_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega-\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\\\\G_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega+\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\n$$</div>\n\n<p><img src=\"/../images/Speech-SP/1713963786950.png\" alt=\"1713963786950\" loading=\"lazy\"></p>\n<p>分析滤波器：子带滤波，降采样；</p>\n<p>降采样率过程等价于：采样(b, 将非M倍数的采样点置为0) + 分频(c，抽取 M 倍数上的采样点形成新的信号)</p>\n<p><img src=\"/../images/Speech-SP/1713963998639.png\" alt=\"1713963998639\" loading=\"lazy\"></p>\n<div>$$\n\\hat{X}_i(z)=\\frac1M\\sum_{l=0}^{M-1}X_i(z^{\\frac1M}W_M^{-l})\n$$</div>\n\n<p><img src=\"/../images/Speech-SP/1713965424496.png\" alt=\"1713965424496\" loading=\"lazy\"></p>\n<p>每个子带的输出会产生四种混叠干扰：</p>\n<div>$$\n\\begin{aligned}\nU_i(e^{j\\omega})& =K_i(e^{j\\omega})\\cdot Y_i(e^{j\\omega})  \\\\\n&\\approx\\frac1MK_i(e^{j\\omega})\\{a_iF_i(e^{j\\omega})X(e^{j\\omega})+b_iG_i(e^{j\\omega})X(e^{j\\omega})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})\\} \\\\\n&i=1\\sim M-2\n\\end{aligned}\n$$</div>\n\n<p>为了解决升采样后的频谱混叠，在综合滤波器部分精确对消混叠信号：</p>\n<div>$$\na_id_i=-a_{i-1}d_{i-1},\\quad i>0\n$$</div>\n\n<h3 id=\"变换域编码\"><a href=\"#变换域编码\" class=\"headerlink\" title=\"变换域编码\"></a>变换域编码</h3><p>正交变换后编码：</p>\n<div>$$\nY = AX\n$$</div>\n\n<p>正交变换满足能量守恒</p>\n<div>$$\n||Y||^2 = ||X||^2\n$$</div>\n\n<p>重建信号的误差等于变换域上量化器的误差</p>\n<div>$$\nE = Y - [Y]\\\\\n||X - [x]||^2 = ||E||^2\n$$</div>\n\n<h4 id=\"比特分配\"><a href=\"#比特分配\" class=\"headerlink\" title=\"比特分配\"></a>比特分配</h4><p>假设 N 个输入样本组成一个矢量 X，变换域 Y 的每个分量用 $R_k$  个比特量化</p>\n<div>$$\nR=\\frac1N\\sum_{k=0}^{N-1}R_k\\\\\n\\sigma_q^2=\\sum_{k=0}^{N-1}\\sigma_{q,k}^2=\\varepsilon_*^2\\cdot\\sum_{k=0}^{N-1}2^{-2R_k}\\sigma_k^2\\\\\n\\min \\sigma_{q}^{2}=\\frac{1}{N}\\sum_{k=0}^{N-1}\\sigma_{q,k}^{2}\n$$</div>\n\n<div>$$\nR_{k,opt}=R+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/N}}\\\\\n\\sigma_{q}^2 = min\\{\\sigma_{q,k}^2\\}=\\varepsilon_*^2\\cdot2^{-2R}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{N}}\n$$</div>\n\n<p>相比 PCM 的增益为</p>\n<div>$$\n\\begin{gathered}\nG_{TC} =\\frac{min\\{\\sigma_{r,PCM}^{2}\\}}{min\\{\\sigma_{r,TC}^{2}\\}}=\\frac{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\sigma_{\\chi}^{2}}{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\prod_{k=0}^{N-1}[\\sigma_{k}^{2}]^{\\frac{1}{N}}} \\\\\n=\\frac{\\sigma_x^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}}=\\frac{\\frac1N\\sum_{k=0}^{N-1}\\sigma_k^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}} \n\\end{gathered}\n$$</div>\n\n<h4 id=\"最佳正交变换-KL-变换\"><a href=\"#最佳正交变换-KL-变换\" class=\"headerlink\" title=\"最佳正交变换 - KL 变换\"></a>最佳正交变换 - KL 变换</h4><h2 id=\"语音信号的参数编码\"><a href=\"#语音信号的参数编码\" class=\"headerlink\" title=\"语音信号的参数编码\"></a>语音信号的参数编码</h2><h3 id=\"感觉加权滤波器\"><a href=\"#感觉加权滤波器\" class=\"headerlink\" title=\"感觉加权滤波器\"></a>感觉加权滤波器</h3><p>误差函数加权：</p>\n<div>$$\nJ=\\int_0^{f_s}\\lvert s(f)-\\hat{s}(f)\\rvert^2\\cdot\\lvert w(f)\\rvert^2df\n$$</div>\n\n<p>其中，加权滤波器满足</p>\n<div>$$\n\\int_0^{f_S}|w(f)|df= Const.\n$$</div>\n\n<p>当误差函数最小的时候，应当保证</p>\n<div>$$\n|s(f)-\\hat{s}(f)|^2\\cdot|w(f)|=\\frac{\\gamma}{2}=\\text{常数}\n$$</div>\n\n<p>可以选择如下的滤波器：</p>\n<div>$$\nw(z)=\\frac{A(z)}{A\\left(\\frac{z}{\\gamma}\\right)}=\\frac{1-\\sum_{i=1}^P\\alpha_iz^{-i}}{1-\\sum_{i=1}^P\\alpha_i\\gamma^iz^{-i}},\\quad0\\leq\\gamma\\leq1\n$$</div>\n\n<p>$\\gamma$ 为加权因子，在 0-1 之间。</p>\n<p>$\\gamma&#x3D;0$ 时变成逆滤波器，其频谱包络的峰值点就是语音谱的谷值点。</p>\n<blockquote>\n<p>分析：语音信号是全极点模型产生的，即 $S(z) &#x3D; GE(z)&#x2F;A(z)$，与逆滤波器点频谱成反比。</p>\n</blockquote>\n<p><img src=\"/../images/Speech-SP/1715172645812.png\" alt=\"1715172645812\" loading=\"lazy\"></p>\n<h3 id=\"多脉冲激励线性预测声码器\"><a href=\"#多脉冲激励线性预测声码器\" class=\"headerlink\" title=\"多脉冲激励线性预测声码器\"></a>多脉冲激励线性预测声码器</h3><p><img src=\"/../images/Speech-SP/1715172680511.png\" alt=\"1715172680511\" loading=\"lazy\"></p>\n<p>语音综合器的激励源有若干个不同位置和幅度的脉冲信号组成。</p>\n<div>$$\n\\hat{s}(n)=\\hat{s}_0(n)+\\sum_{k=1}^Mg_kh(n-n_k)\n$$</div>\n\n<p>其中 $\\hat s_0(n)$ 是 LPC 综合器的零输入响应。</p>\n<div>$$\n\\begin{aligned}&e_{s}(n)=s(n)-\\hat{s}(n)=s(n)-\\hat{s}_{0}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\\\&=\\bar{e}(n)-\\sum_{k=1}^Mg_kh(n-n_k)\\end{aligned}\n$$</div>\n\n<p>用 $\\bar{e}(n)&#x3D;s(n)-\\hat{s}_0(n)$ 表示输入语音减去零输入响应（受历史激励影响的部分）。</p>\n<p>输入感觉加权滤波器，得到输出</p>\n<div>$$\n\\begin{aligned}e(n)&=e_{s}(n)*w(n)=\\left[\\bar{e}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\right]*w(n)\\\\&=\\bar{e}_{w}(n)-\\sum_{k=1}^{M}g_{k}h_{w}(n-n_{k})\\end{aligned}\n$$</div>\n\n<p>从而，得到感觉加权滤波器的误差函数</p>\n<div>$$\nE=\\sum_{n=1}^Ne^2(n)=\\sum_{n=1}^N\\left[\\bar{e}_w(n)-\\sum_{k=1}^Mg_kh_w(n-n_k)\\right]^2\n$$</div>\n\n<p>选择合适的 $n_k$, $g_k$ 使得上面的误差函数最小</p>\n<div>$$\n\\frac{\\partial E}{\\partial n_j}=0,\\quad j=1,\\cdots M\\\\\\frac{\\partial E}{\\partial g_j}=0,\\quad j=1,\\cdots M\n$$</div>\n\n<p>上面那个方程很复杂，会导出非线性的方程；</p>\n<p>从下面的那个方程可以推出</p>\n<div>$$\n\\sum_{k=1}^Mg_kR_{hh}(n_k,n_j)=R_{eh}(n_j),\\quad j=1,\\cdots M\n$$</div>\n\n<p>其中</p>\n<div>$$\nR_{eh}(n_j)=\\sum_{n=1}^N\\bar{e}_w(n)\\cdot h_w(n-n_j)\\\\R_{hh}(n_k,n_j)=\\sum_{n=1}^Nh_w(n-n_k)h_w(n-n_j)\n$$</div>\n\n<p>此时可改写最小均方误差</p>\n<div>$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-\\sum_{k=1}^Mg_kR_{eh}(n_k)\n$$</div>\n\n<p>最优解的计算涉及到非线性方程的求解，不太现实。考虑采用次优搜索，一个一个求解。</p>\n<p>当只有一个脉冲时</p>\n<div>$$\ng_1R_{hh}(n_1,n_1)=R_{eh}(n_1)\\\\\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-g_1R_{eh}(n_1)\n$$</div>\n\n<p>消元得到</p>\n<div>$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-R_{eh}^2(n_1)/R_{hh}(n_1,n_1)\n$$</div>\n\n<p>接下来搜索 $n_1$ 使得上式最优化。解出 $n_1$ 后即可解出 $g_1$。</p>\n<p>接下来一个个求解，每次都要把前面求解过的脉冲折算到零输入响应中，然后求解当前的结果：</p>\n<h2 id=\"语音信号修整与综合技术\"><a href=\"#语音信号修整与综合技术\" class=\"headerlink\" title=\"语音信号修整与综合技术\"></a>语音信号修整与综合技术</h2><p>短时谱分析</p>\n<div>$$\n\\begin{gathered}w[n]=\\begin{cases}\\neq0&,&0\\leq n<L\\\\0&,&\\text{其它}\\end{cases}\\\\X(p,k)=\\sum_{n=-\\infty}^{+\\infty}x[n]w[p-n]e^{-j\\frac{2\\pi}{N}nk}\\\\x[n]w[p-n]=\\left[\\frac{1}{N}\\sum_{i=0}^{N-1}X(p,k)e^{j\\frac{2\\pi}{N}nk}\\right]\\cdot R[p-n]\\end{gathered}\n$$</div>\n\n<h3 id=\"利用修正短时谱进行最小方差信号估计\"><a href=\"#利用修正短时谱进行最小方差信号估计\" class=\"headerlink\" title=\"利用修正短时谱进行最小方差信号估计\"></a>利用修正短时谱进行最小方差信号估计</h3><p>首先计算短时谱</p>\n<div>$$\nX(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}x[m]w(p-m)e^{-j\\omega m}\n$$</div>\n\n<p>对短时谱进行修正</p>\n<div>$$\nY(p,\\omega)=X(p,\\omega)H(p,\\omega)\n$$</div>\n\n<p>需要得到一个“有效”的短时谱，满足：</p>\n<ol>\n<li>时域短时段有限长，非零段不超过窗函数 $w(p-n)$的范围</li>\n<li>一致性约束，即不同的𝑝时刻 𝑌(𝑝,𝜔)所对应的时域短时段，若有部分重叠，那么在去除分析窗的加权影响后，在重叠的部分，它们应该是相等的。</li>\n</ol>\n<p>实际上很难得到上述信号，可以通过最小方差准则逼近</p>\n<div>$$\nD[\\hat{Y}(n,\\omega),Y(n,\\omega)]=\\sum_{m=-\\infty}^{+\\infty}\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}\\left|\\hat{Y}(m,\\omega)-Y(m,\\omega)\\right|^{2}d\\omega\n$$</div>\n\n<p>其中</p>\n<div>$$\n\\hat{Y}(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}\\hat{y}[m]w(p-m)e^{-j\\omega m}\n$$</div>\n\n<p>利用 Parseval 定理</p>\n<div>$$\n\\begin{aligned}&D\\big[\\hat{Y}(n,\\omega),Y(n,\\omega)\\big]=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}_{m}(n)-y_{m}(n)|^{2}\\\\&=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}(n)w(m-n)-y_{m}(n)|^{2}\\end{aligned}\n$$</div>\n\n<p>变分法求得最小值</p>\n<div>$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(m-n)y_m(n)}{\\sum_{m=-\\infty}^\\infty w^2(m-n)}\n$$</div>\n\n<p>其中</p>\n<div>$$\ny_m(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi Y(m,\\omega)e^{j\\omega n}d\\omega\n$$</div>\n\n<p>应用中，以周期 $T$ 分析</p>\n<div>$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)y_{mT}(n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$</div>\n\n<p>如果 $w(n)$ 取三角窗的平方根</p>\n<div>$$\nw^2(n)=\\begin{cases}1-\\frac{|n-T|}{T}&,\\quad0\\leq n\\leq2T\\\\\\\\0&,\\quad\\text{其它}\\end{cases}\n$$</div>\n\n<p>若 n 此时为奇数，$T &#x3D; (N-1)&#x2F;2$，这时$\\sum_{m&#x3D;-\\infty}^{\\infty}w^{2}(mT-n)&#x3D;1$，可简化计算，如果频谱无修正，最优解为</p>\n<div>$$\n\\hat{y}(n)=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)[w(mT-n)x(n)]}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=\\frac{x(n)\\sum_{m=-\\infty}^\\infty w^2(mT-n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=x(n)\n$$</div>\n\n<p>若改变语音的速度，$p&#x3D;k\\cdot p^{\\prime}$，满足$|Y(p,\\omega)|&#x3D;|X(p^{\\prime},\\omega)|$ 。</p>\n<div>$$\ny_{p'}(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}Y(p',\\omega)e^{j\\omega n}d\\omega=w(p'-n)x(n)\n$$</div>\n\n<p>让 $\\tau_p&#x3D;p-p^{\\prime}&#x3D;(1-1&#x2F;k)\\cdot p$，</p>\n<div>$$\n\\begin{aligned}&y_p(n)=y_{p^{\\prime}}(n-\\tau_p)=w(p^{\\prime}-n+\\tau_p)x(n-\\tau_p)\\\\&=w(p-n)x(n-\\tau_p)\\end{aligned}\n\n<p>$$</div></p>\n<p>代入重建公式</p>\n<div>$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w^2(mT-n)x(n-\\tau_{mT})}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$</div>\n\n<p>让$\\sum_{m&#x3D;-\\infty}^{\\infty}W(mT-n)&#x3D; \\sum_{m&#x3D;-\\infty}^{\\infty}w^2(mT-n) &#x3D;1$，</p>\n<div>$$\n\\hat{y}[n]=\\sum_{m=-\\infty}^{\\infty}W(mT-n)x(n-\\tau_{mT})\n$$</div>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"语音信号的线性预测编码技术\"><a href=\"#语音信号的线性预测编码技术\" class=\"headerlink\" title=\"语音信号的线性预测编码技术\"></a>语音信号的线性预测编码技术</h2><p>线性预测编码技术（维纳滤波）。可以参考隔壁统计信号处理的笔记hh。</p>\n<p>维纳滤波的正交原理：</p>\n<div>$$\nE \\langle x(n-k), e(n) \\rangle = 0\n$$</div>\n\n<p>正交原理可以用来估计任何时候的任何值，不管是现在（滤波），过去（平滑）还是未来（预测），也不管估计的对象是 $x,y$，上述公式的含义是：估计误差始终与已知信号垂直，与估计的是哪个时间的信号无关。</p>\n<p>利用前面的 $P$ 个信号预测下一个信号：</p>\n<div>$$\n\\hat{s}(n)=-\\sum_{i=1}^{P^{\\prime}}\\hat{\\alpha}_i\\cdot s(n-i)\n$$</div>\n\n<p>误差定义为</p>\n<div>$$\n\\begin{aligned}\n\\varepsilon(n)& =s(n)-\\overset{\\wedge}{\\operatorname*{s}}(n)=s(n)+\\sum_{i=1}\\widehat{\\alpha}_i\\cdot s(n-i)  \\\\\n&=\\sum_{i=0}^{P^{\\prime}}\\widehat{\\alpha}_i\\cdot s(n-i)\n\\end{aligned}\n$$</div>\n\n<p>从 z 域看，这是一个全极点模型产生了目标信号：</p>\n<div>$$\nS(z) = -S(z)\\sum\\limits_{i=1}^{P}\\alpha_iz^{-i} + E(z)\n$$</div>\n\n<p>接下来的所有步骤，目的都是推导 $\\alpha$ 的取值。</p>\n<h3 id=\"自相关法\"><a href=\"#自相关法\" class=\"headerlink\" title=\"自相关法\"></a>自相关法</h3><p>本文中假设信号具有遍历性，即时间平均等于统计平均，时间上的自相关等于统计意义上的自相关。</p>\n<p>利用 LMMSE 准则可以推出</p>\n<div>$$\n\\begin{bmatrix}R(0)&R(1)&R(2)&\\cdots&R(P-1)\\\\R(1)&R(0)&R(1)&\\cdots&R(P-2)\\\\R(2)&R(1)&R(0)&\\cdots&R(P-3)\\\\\\vdots&\\vdots&&&\\vdots\\\\R(P-1)&R(P-2)&\\cdots&\\cdots&R(0)\\end{bmatrix}\\cdot\\begin{bmatrix}\\hat\\alpha_1\\\\\\hat\\alpha_2\\\\\\vdots\\\\\\vdots\\\\\\hat\\alpha_P\\end{bmatrix}=-\\begin{bmatrix}R(1)\\\\R(2)\\\\\\vdots\\\\\\vdots\\\\R(P)\\end{bmatrix}\n$$</div>\n\n<p>一个例子：Durbin 递推算法</p>\n<h3 id=\"协方差法\"><a href=\"#协方差法\" class=\"headerlink\" title=\"协方差法\"></a>协方差法</h3><p>不能保证声码器稳定</p>\n<h3 id=\"Durbin-递推算法\"><a href=\"#Durbin-递推算法\" class=\"headerlink\" title=\"Durbin 递推算法\"></a>Durbin 递推算法</h3><h4 id=\"滤波器的内积\"><a href=\"#滤波器的内积\" class=\"headerlink\" title=\"滤波器的内积\"></a>滤波器的内积</h4><p>定义$s_w(n)$关于$F(z)$和$G(z)$的内积如下：</p>\n<div>$$\n\\langle F(z),G(z)\\rangle=\\sum_{-\\infty}^{+\\infty}u(n)\\cdot v(n)\n$$</div>\n\n<p>特别地若这里的$F(z),\\quad G(z)$都用我们的逆滤波器$A(z)&#x3D;\\sum_{i&#x3D;0}^P\\alpha_iZ^{-i}$替换，那么语音信号$s_w(n)$经过$A(z)$后的输出$e(n)$就是预测误差。</p>\n<p>$\\alpha_i\\cdot s_W(n-i)$ 因此$A(z)$范数$|A(z)|$的平方就是预测误差。即</p>\n<div>$$\n\\|A(z)\\|^2=\\langle A(z),A(z)\\rangle=\\sum_{-\\infty}^{+\\infty}e(n)\\cdot e(n)=\\sum_{-\\infty}^{+\\infty}e^2(n)\n$$</div>\n\n<p>内积有正定性，线性，三角不等式</p>\n<p>特殊性质：</p>\n<div>$$\n\\langle z^{-i}, z^{-j} \\rangle = R(|i - j|)\\\\\n\\langle F(z), G(z) \\rangle = \\sum\\limits_{i=0}^{M}\\sum\\limits_{j=0}^{M}f_ig_jR(|i - j|)\\\\\n\\langle F(z),G(z)\\rangle=\\left\\langle z^kF(z),z^kG(z)\\right\\rangle\\\\\n\\langle F(z),G(z)\\rangle=\\langle F(1/z),G(1/z)\\rangle\n$$</div>\n\n<h4 id=\"逆滤波器\"><a href=\"#逆滤波器\" class=\"headerlink\" title=\"逆滤波器\"></a>逆滤波器</h4><p>定义FIR滤波器$\\hat{A}(z)$:</p>\n<div>$$\n\\hat{A}(z)=\\sum_{i=0}^P\\hat{\\alpha}_iz^{-i}\\quad,\\quad\\alpha_0=1\n$$</div>\n\n<p>若$\\hat{\\alpha}_{i}$是满足LPC正则方程的解，则称$\\hat{A}(z)$称为逆滤波器。$\\hat{E}(z)&#x3D;\\hat{A}(z)\\cdot S(z)$是预测误差$\\varepsilon(n)$的z 变换。显然有：</p>\n<p> (1) 若s(n)是由全极点模型$1&#x2F;A(z)$产生的，这时$A(z)&#x3D;\\sum_{i&#x3D;0}^P\\alpha_iz^{-i}$, 即：</p>\n<p>$s(n)&#x3D;-\\sum_{i&#x3D;1}^P\\alpha_is(n-i)+Ge(n)$</p>\n<div>$$\nS(z) \\cdot A(z) = G \\cdot E(z)\n$$</div>\n\n<h4 id=\"前向和后向预测\"><a href=\"#前向和后向预测\" class=\"headerlink\" title=\"前向和后向预测\"></a>前向和后向预测</h4><p>前向线性预测器(P阶)</p>\n<div>$$\n\\hat{s}(n)=-\\sum_{i=1}^P\\alpha_i^{(P)}\\cdot s(n-i)\n$$</div>\n\n<p>前向预测误差(P阶)</p>\n<div>$$\n\\varepsilon_\\alpha^{(P)}(n)=s(n)-\\hat{s}(n)=\\sum_{i=0}^P\\alpha_i^{(P)}\\cdot s(n-i)\\:,\\alpha_0^{(P)}=1\n$$</div>\n\n<p>前向逆滤波器(P阶)</p>\n<div>$$\nA^{(P)}(z)=\\sum_{i=0}^P\\alpha_i^{(P)}z^{-i}\n$$</div>\n\n<p>显然有</p>\n<div>$$\nE^{(P)}_\\alpha(z) = S(z) \\cdot A^{(P)}(z)\n$$</div>\n\n<p>后向线性预测器(P阶)</p>\n<div>$$\n\\hat{s}(n-P-1)=-\\sum_{i=1}^P\\beta_i^{(P)}\\cdot s(n-i)\n$$</div>\n\n<p>n时刻对$s(n-P-1)$的后向预测误差(P阶)</p>\n<div>$$\n\\begin{aligned}&\\varepsilon_{\\beta}^{(P)}(n)=s(n-P-1)-\\hat{s}(n-P-1)\\\\&=\\sum_{i=1}^{P+1}\\beta_i^{(P)}\\cdot s(n-i)\\quad,\\quad\\beta_{P+1}^{(P)}=1\\end{aligned}\n$$</div>\n\n<p>后向逆滤波器 (P阶)</p>\n<div>$$\nB^{(P)}(z)=\\sum_{i=1}^{P+1}\\beta_i^{(P)}z^{-i}\n$$</div>\n\n<p>显然有</p>\n<div>$$\nE_\\beta^{(P)}(z) = S(z) \\cdot B^{(P)}(z)\n$$</div>\n\n<h4 id=\"正交性原理\"><a href=\"#正交性原理\" class=\"headerlink\" title=\"正交性原理\"></a>正交性原理</h4><p>判定最佳预测器的充要条件是</p>\n<div>$$\n\\langle A^{(m)}(z), z^{-l} \\rangle = 0\\\\\n\\langle B^{(m)}(z), z^{-l} \\rangle = 0\\\\\nl = 1, 2, \\dots, m\n$$</div>\n\n<p>一个不严谨的理解：</p>\n<div>$$\nu(n) = s(n) * Z^{-1}[A(z)] = \\varepsilon(n)\\\\\nv(n) = s(n) * Z^{-1}[z^{-l}] = s(n - l)\\\\\n\\begin{align*}\n    &\\langle A^{(m)}(z), z^{-l} \\rangle\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}u(n)v(n)\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}\\varepsilon(n)s(n - l)\\\\\n\\end{align*}\n$$</div>\n\n<p>由于时间平均等于统计平均，</p>\n<div>$$\n\\frac1{2N} \\sum\\limits_{n=-N}^{N - 1}\\varepsilon(n)s(n-l) = E \\langle \\varepsilon(n), s(n-l) \\rangle\n$$</div>\n\n<p>根据开头提到的维纳滤波正交原理可知上式等于0。</p>\n<h4 id=\"递推公式\"><a href=\"#递推公式\" class=\"headerlink\" title=\"递推公式\"></a>递推公式</h4><p>根据定义，当$m&#x3D;0$时，显然有</p>\n<div>$$\nA^{(0)}(z)=1\\\\B^{(0)}(z)=z^{-1}\n$$</div>\n\n<p>$m&gt;0$时有如下递推公式（施密特正交化）</p>\n<div>$$\nA^{(m)}(z)=A^{(m-1)}(z)+K^{(m)}B^{(m-1)}(z)\n$$</div>\n\n<div>$$\nB^{(m)}(z)=z^{-1}\\Big[B^{(m-1)}(z)+K^{(m)}A^{(m-1)}(z)\\Big]\n$$</div>\n\n<div>$$\nK^{(m)} = -\\frac{\\langle A^{(m-1)}(z), B^{(m-1)}(z)\\rangle}{||B^{(m-1)}(z)||^2}\n$$</div>\n\n<p>根据正交性原理，需要证明由递推公式得到的$A^{(m)}(z)$和$B^{(m)}(z)$满足正交性条件公式。</p>\n<p> 在公式(76) 中，根据多项式对应项系数相等的原则，可以得到</p>\n<div>$$\n\\begin{aligned}&\\alpha_{i}^{(m)}=\\alpha_{i}^{(m-1)}+K^{(m)}\\cdot\\beta_{i}^{(m-1)}\\quad,\\quad i=1,\\cdots,m-1\\\\&\\alpha_{i}^{(m)}=K^{(m)}\\quad,\\quad i=m\\end{aligned}\n$$</div>\n\n<p>由公式(73)可知</p>\n<div>$$\n\\beta_j^{(m)}=\\alpha_{m+1-j}^{(m)},\\:j=1,\\cdots,m+1\n$$</div>\n\n<blockquote>\n<p>从这里可以推出</p>\n<div>$$\nB^{(m)}(z) = z^{-(m+1)}A^{(m)}(1/z)\n$$</div>\n</blockquote>\n<p>因此可以得到预测器系数的递推公式</p>\n<div>$$\n\\begin{cases}\\alpha_\\mathrm{m}^{(\\mathrm{m})}=\\mathrm{K}^{(\\mathrm{m})}\\\\\\alpha_\\mathrm{i}^{(\\mathrm{m})}=\\alpha_\\mathrm{i}^{(\\mathrm{m}-1)}+\\mathrm{K}^{(\\mathrm{m})}\\cdot\\alpha_\\mathrm{m-i}^{(\\mathrm{m}-1)}\\quad,\\:\\mathrm{i}=1,\\cdots,\\mathrm{m}-1\\end{cases}\n$$</div>\n\n<p>这是线性预测系数的Durbin递推算法公式。$m$阶部分相关系数$K^{(m)}$可以用以下方法计算：</p>\n<div>$$\nK^{(m)} = -\\frac{\\sum\\limits_{j=1}^{m}\\alpha_{m-j}^{(m-1)}R(j)}{||B^{(m-1)}(z)||^2}\n$$</div>\n\n<p>$||B^{(m)}(z)||^2$ 可以用这个递推式计算：</p>\n<div>$$\n\\begin{Vmatrix}B^{(m)}(z)\\end{Vmatrix}^2=(1-[K^{(m)}]^2)\\begin{Vmatrix}B^{(m-1)}(z)\\end{Vmatrix}^2\n$$</div>\n\n<p>初值</p>\n<div>$$\n||B^{(0)}(z)|| = R(0)\\\\\n\\alpha^{(0)}_0 = 1\n$$</div>\n\n<h3 id=\"Durbin-算法系统的稳定性\"><a href=\"#Durbin-算法系统的稳定性\" class=\"headerlink\" title=\"Durbin 算法系统的稳定性\"></a>Durbin 算法系统的稳定性</h3><p>充分性：</p>\n<div>$$\n\\frac{1}{A^{(m)}(z)} 稳定 \\Rarr |k^{(m)}| < 1\n$$</div>\n\n<p>必要性：</p>\n<div>$$\n|k^{(m)}| < 1 \\Rarr \\frac{1}{A^{(m)}(z)} 稳定\n$$</div>\n\n<p>Highlight:</p>\n<p>Durbin 逆序递推公式</p>\n<div>$$\nA^{(m-1)}(z)=\\frac{A^{(m)}(z)-k^{(m)}zB^{(m)}(z)}{1-(k^{(m)})^2}\n$$</div>\n\n<p>证明过程中引入的一个辅助函数</p>\n<div>$$\nF^{(m)}(z)=\\frac{A^{(m)}(z)}{zB^{(m)}(z)}=\\frac{z^mA^{(m)}(z)}{A^{(m)}(1/z)}\n$$</div>\n\n<p>满足 $F^{(m)}(z) &lt; 1 \\lrArr |z| &lt; 1$</p>\n<h4 id=\"稳定性的应用\"><a href=\"#稳定性的应用\" class=\"headerlink\" title=\"稳定性的应用\"></a>稳定性的应用</h4><p>充分性：说明使用 Durbin 算法可以保证 $1&#x2F;A(z)$ 稳定</p>\n<p>必要性：</p>\n<p>判定高阶多项式 $A(z)$ 构成的系统 $1&#x2F;A(z)$ 是否稳定。</p>\n<p>只要计算出 $k_m$，判断 $|k_m|$ 是否小于1即可。</p>\n<h3 id=\"LPC-模型参数讨论\"><a href=\"#LPC-模型参数讨论\" class=\"headerlink\" title=\"LPC 模型参数讨论\"></a>LPC 模型参数讨论</h3><h4 id=\"阶数\"><a href=\"#阶数\" class=\"headerlink\" title=\"阶数\"></a>阶数</h4><p>误差能量是单调减的，一般 $P &#x3D; 8 \\sim 14$</p>\n<h4 id=\"激励增益-G\"><a href=\"#激励增益-G\" class=\"headerlink\" title=\"激励增益 G\"></a>激励增益 G</h4><p>采用缓变窗（哈明窗），$N &gt;&gt; P$</p>\n<div>$$\n\\varepsilon_\\alpha^{(p)}(n)\\approx Ge_w(n)=Ge(n)w(n)\n$$</div>\n\n<div>$$\nG^2\\approx\\frac{\\sum_{n=-\\infty}^\\infty\\left(\\varepsilon_\\alpha^{(p)}(n)\\right)^2}{\\sum_{n=-\\infty}^\\infty e^2(n)w^2(n)}\n$$</div>\n\n<h4 id=\"短时分析对于LPC参数估计的影响\"><a href=\"#短时分析对于LPC参数估计的影响\" class=\"headerlink\" title=\"短时分析对于LPC参数估计的影响\"></a>短时分析对于LPC参数估计的影响</h4><ol>\n<li>𝑒(𝑛)为白噪声时，$E[\\hat \\alpha_i] &#x3D; \\alpha_i$，无偏估计</li>\n<li>𝑒(𝑛)为浊音时，采用基音同步算法可以达到无偏估计。否则如果是任意截取一段语音作分析估计是有偏的。</li>\n</ol>\n<h4 id=\"LPC分析的频域解释\"><a href=\"#LPC分析的频域解释\" class=\"headerlink\" title=\"LPC分析的频域解释\"></a>LPC分析的频域解释</h4><p>用LPC分析可以用来跟踪声道模型谱（或称语音的平滑谱）。若用LPC算法解出的全极点模型来逼近实际声道，则它的单位冲激响应ℎ(𝑛)为：</p>\n<div>$$\n\\begin{cases}\n    h(n) = 0, n \\lt 0\\\\\n    h(n) = - \\sum\\limits_{i=1}^{p}\\alpha_i^{(p)}h(n - 1) + \\delta(n), n \\ge 0\n\\end{cases}\n$$</div>\n\n<p>若 $R_h(l) &#x3D; R_h(-l) &#x3D; \\sum\\limits_{n&#x3D;0}^{\\infty}h(n - l)h(n), l \\ge 0$</p>\n<div>$$\n\\sum\\limits_{i=1}^{p}\\alpha_i^{(P)}R_h(|k - i|) = -R_h(k), l \\ge 0\\\\\nR_h(l)/R_h(0) = R(l) / R(0)\n$$</div>\n\n<p>当激励为均方值为1，均值为0的白噪声序列时，输出的自关函数𝑅𝑤(𝑙)也有此关系。<br>P阶LPC预测模型也称为P阶自关匹配模型。</p>\n<h4 id=\"各种LPC参数计算其它们之间的关系\"><a href=\"#各种LPC参数计算其它们之间的关系\" class=\"headerlink\" title=\"各种LPC参数计算其它们之间的关系\"></a>各种LPC参数计算其它们之间的关系</h4><ol>\n<li>$R(l) \\Rightarrow \\alpha$</li>\n<li>$K \\Rightarrow \\alpha$</li>\n</ol>\n<div>$$\n\\begin{cases}\\alpha_m^m=K^{(m)}\\\\\\alpha_i^{(m)}=\\alpha_i^{(m-1)}+K^{(m)}\\alpha_{m-i}^{(m-1)}\\end{cases}\n$$</div>\n\n<ol start=\"3\">\n<li>LPC 系数 &#x3D;&gt; 倒谱（因为是最小相位序列）</li>\n<li>PARCOR 系数($K^{(m)}$)<ol>\n<li>由 Durbin 解得</li>\n<li>由格形算法解得</li>\n<li>由 Schur 算法解得</li>\n</ol>\n</li>\n<li>由 $A(z)$ 根确定振峰<ol>\n<li>每一对根与一个共振峰对应</li>\n</ol>\n</li>\n<li>声道面积比系数和对数面积比系数</li>\n</ol>\n<div>$$\n\\frac{A_m}{A_{m-1}}=\\frac{1-K^{(m)}}{1+K^{(m)}}\\:,\\:m=1,2,\\cdots P\\\\\ng_m = \\ln\\Bigg[\\frac{A_m}{A_{m-1}}\\Bigg]\n$$</div>\n\n<ol start=\"7\">\n<li>线谱对（LSP）或者线谱频率参数(LSF)</li>\n</ol>\n<div>$$\nP(z) = A^{(p)}(z) + z^{-(p+1)}A^{(p)}(z^{-1})\\\\\nQ(z) = A^{(p)}(z) - z^{-(p+1)}A^{(p)}(z^{-1})\n$$</div>\n\n<p>性质：</p>\n<ol>\n<li>$P(z)$ 和 $Q(z)$ 的根均在单位圆上</li>\n<li>$P(z)$ 和 $Q(z)$ 的根在单位元上交错</li>\n<li>$\\alpha$ 参数和 $LSP$ 参数互推</li>\n</ol>\n<p>某个特定的𝐿𝑆𝑃 [𝑓1, 𝑓2, ⋯ 𝑓𝑝]中只移动其中任意一个频率𝑓𝑖的位置，那么对应的平滑谱只<br>有𝑓𝑖附近与原平滑谱有异，而在其它频域则变化很小</p>\n<h2 id=\"语音信号编码\"><a href=\"#语音信号编码\" class=\"headerlink\" title=\"语音信号编码\"></a>语音信号编码</h2><h3 id=\"语音信号的标量量化\"><a href=\"#语音信号的标量量化\" class=\"headerlink\" title=\"语音信号的标量量化\"></a>语音信号的标量量化</h3><h4 id=\"标量量化器\"><a href=\"#标量量化器\" class=\"headerlink\" title=\"标量量化器\"></a>标量量化器</h4><h4 id=\"均匀量化器\"><a href=\"#均匀量化器\" class=\"headerlink\" title=\"均匀量化器\"></a>均匀量化器</h4><h4 id=\"非均匀量化器\"><a href=\"#非均匀量化器\" class=\"headerlink\" title=\"非均匀量化器\"></a>非均匀量化器</h4><h4 id=\"非线性压扩量化器\"><a href=\"#非线性压扩量化器\" class=\"headerlink\" title=\"非线性压扩量化器\"></a>非线性压扩量化器</h4><h3 id=\"自适应量化（Adaptive-Delta-Modulation，ADM）\"><a href=\"#自适应量化（Adaptive-Delta-Modulation，ADM）\" class=\"headerlink\" title=\"自适应量化（Adaptive Delta Modulation，ADM）\"></a>自适应量化（Adaptive Delta Modulation，ADM）</h3><h4 id=\"前向自适应量化（AQF）\"><a href=\"#前向自适应量化（AQF）\" class=\"headerlink\" title=\"前向自适应量化（AQF）\"></a>前向自适应量化（AQF）</h4><h4 id=\"后向自适应量化（AQB）\"><a href=\"#后向自适应量化（AQB）\" class=\"headerlink\" title=\"后向自适应量化（AQB）\"></a>后向自适应量化（AQB）</h4><h3 id=\"差分编码-DPCM\"><a href=\"#差分编码-DPCM\" class=\"headerlink\" title=\"差分编码 DPCM\"></a>差分编码 DPCM</h3><p><img src=\"/../images/Speech-SP/1713960093567.png\" alt=\"1713960093567\"></p>\n<p>DPCM是指采用固定预测器与固定量化器的差值脉冲调制。</p>\n<h3 id=\"CVSD-编码器\"><a href=\"#CVSD-编码器\" class=\"headerlink\" title=\"CVSD 编码器\"></a>CVSD 编码器</h3><p><img src=\"/../images/Speech-SP/1713958735363.png\" alt=\"1713958735363\"></p>\n<h3 id=\"Delta-Sigma-量化器\"><a href=\"#Delta-Sigma-量化器\" class=\"headerlink\" title=\"Delta-Sigma 量化器\"></a>Delta-Sigma 量化器</h3><p><img src=\"/../images/Speech-SP/1713958768829.png\" alt=\"1713958768829\"></p>\n<p>考虑 $D&#x2F;A$ 变换器的增益为 1 的情况，此时 $V_a(z)\\approx V(z)$，</p>\n<div>$$\n\\begin{gathered}\nV(z)=[U(z)-V(z)]\\cdot H(z)+Q(z) \\\\\n[1+H(z)]\\cdot V(z)=U(z)\\cdot H(z)+Q(z) \\\\\nV(z)=\\frac{H(z)}{1+H(z)}U(z)\\cdot+\\frac{1}{1+H(z)}Q(z) \n\\end{gathered}\n$$</div>\n\n<p>定义信号传输函数</p>\n<div>$$\nSTF(z)=\\frac{V(z)}{U(z)}\\Bigg|_{Q(z)=0}=\\frac{H(z)}{1+H(z)}\n$$</div>\n\n<p>定义超取样量化噪声传输函数</p>\n<div>$$\nNTF(z)=\\frac{V(z)}{Q(z)}\\Bigg|_{U(z)=0}=\\frac{1}{1+H(z)}\n$$</div>\n\n<p>让 $H(z)$ 为低通，则 $STF(z)$ 是低通，$NTF(z)$ 是高通</p>\n<div>$$\nV(z)=STF(z)\\cdot U(z)+NTF(z)\\cdot Q(z)\n$$</div>\n\n<p>噪声整形（Noise-Shaping）技术：$NTF(z)$ 去掉了噪声能量的低频部分。接下来，只要经过低通滤波器 $H_d(z)$，就可以滤除高频部分的噪声能量，剩下的只有所需要的信号 $U(z)$，$H_d(z)$ 的输出 $V_d(z)$ 的量化噪声可以小于直接用 A&#x2F;D 量化器量化的噪声。</p>\n<p>采用速度（超采样）换精度（高量化比特数），量化器的精度可以非常低，甚至可以用 1 bit 量化器。1 bit 量化器，就不存在 A&#x2F;D 非线性问题。</p>\n<p>超采样的好处：扩展了频带宽度，我们认为噪声的功率一定，当频带变宽，噪声功率谱的高度就降低了。</p>\n<p><img src=\"/../images/Speech-SP/1713960064882.png\" alt=\"1713960064882\"></p>\n<h3 id=\"子带编码\"><a href=\"#子带编码\" class=\"headerlink\" title=\"子带编码\"></a>子带编码</h3><p>含有多个频点信号分量的复合宽带信号</p>\n<p>首先用一组滤波器将信号分解成若干子带信号</p>\n<div>$$\n\\langle f_1(t),f_2(t)\\rangle=\\frac1{2\\pi}\\cdot\\langle F_1(\\omega),F_2(\\omega)\\rangle\n$$</div>\n\n<p>若 $\\langle F_1(\\omega),F_2(\\omega)\\rangle\\approx0$，则采用子带滤波后，两个信号的相关性 $\\langle f_1(t),f_2(t)\\rangle$ 降低，对于这些不相关的子带信号独立编码可能提高编码效率。</p>\n<h4 id=\"比特数分配\"><a href=\"#比特数分配\" class=\"headerlink\" title=\"比特数分配\"></a>比特数分配</h4><div>$$\n\\sum_{k=1}^MR_k=R\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{x_k}^2\\\\\n\n<p>\\min_{R_k} \\sigma_{r,SBC}^2&#x3D;\\sum_{k&#x3D;1}^M\\varepsilon_{*k}^2\\cdot2^{-2R_k}\\cdot\\sigma_{xk}^2\\<br>$$</div></p>\n<p>解得</p>\n<div>$$\nR_{k,opt}=R/M+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}}\\\\\n\\sigma_{r_k}^2=\\varepsilon_{*k}^2\\cdot2^{-2R/M}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/M}\\\\\nmin\\lbrace\\sigma_{r,SBC}^2\\rbrace=M\\cdot\\varepsilon_*^2\\cdot2^{-\\frac{2R}{M}}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{M}}\n$$</div>\n\n<p>每个子带的采样率变为总带宽的 1&#x2F;M，总的信息比特速率为 $R \\cdot f&#x2F;M$，为了与 PCM 进行比较，假设 SBC 和 PCM 的编码速率相等：</p>\n<div>$$\nR_{PCM} \\cdot f = R_{SBC} \\cdot f / M\\\\\n\\Rarr R_{PCM} = R_{SBC}/M\n$$</div>\n\n<p>此时可推出 SBC 较于 PCM 的信噪比增益为</p>\n<div>$$\nmax\\{G_{SBC}\\}=\\frac{\\sigma_{r,PCM}^{2}}{\\sigma_{r,SBC}^{2}}=\\frac{2^{-2R_{PCM}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{2^{-\\frac{2R_{SBC}}{M}}\\sigma_{x}^{2}}{M\\cdot2^{-\\frac{2R_{SBC}}{M}}\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}=\\frac{\\sigma_{x}^{2}}{M\\cdot[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{\\frac{1}{M}}}\\\\=\\frac{\\frac{1}{M}\\sigma_{x}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}=\\frac{\\frac{1}{M}\\sum_{k=1}^{M}\\sigma_{xk}^{2}}{[\\prod_{k=1}^{M}\\sigma_{xk}^{2}]^{1/M}}\n$$</div>\n\n<p>因此 SBC 的信噪比增益等于子带信号的算术平均和几何平均之比。</p>\n<ul>\n<li>子带信号能量越大，则分配比特数越多；</li>\n<li>最佳分配条件下，各个子带的量化噪声相同；</li>\n<li>若各个子带能量相同，则子带编码的增益为1</li>\n</ul>\n<h4 id=\"多相正交滤波器组\"><a href=\"#多相正交滤波器组\" class=\"headerlink\" title=\"多相正交滤波器组\"></a>多相正交滤波器组</h4><p>用一组不同频率的余弦信号对低通滤波器进行调制，变成了带通滤波器组：</p>\n<div>$$\nH_i(z)=\\sum_{n=-\\infty}^{+\\infty}h(n)\\cdot cos\\left(\\pi(2i+1)\\cdot\\frac{n}{2M}\\right)\\cdot z^{-n}=\\frac12F_i(z)+\\frac12G_i(z)\n$$</div>\n\n<div>$$\nF_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega-\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\\\\G_{i}\\big(e^{j\\omega}\\big)=H(e^{j(\\omega+\\frac{\\pi(2i+1)}{2M})}),\\quad i=0,1,\\cdots M-1\n$$</div>\n\n<p><img src=\"/../images/Speech-SP/1713963786950.png\" alt=\"1713963786950\"></p>\n<p>分析滤波器：子带滤波，降采样；</p>\n<p>降采样率过程等价于：采样(b, 将非M倍数的采样点置为0) + 分频(c，抽取 M 倍数上的采样点形成新的信号)</p>\n<p><img src=\"/../images/Speech-SP/1713963998639.png\" alt=\"1713963998639\"></p>\n<div>$$\n\\hat{X}_i(z)=\\frac1M\\sum_{l=0}^{M-1}X_i(z^{\\frac1M}W_M^{-l})\n$$</div>\n\n<p><img src=\"/../images/Speech-SP/1713965424496.png\" alt=\"1713965424496\"></p>\n<p>每个子带的输出会产生四种混叠干扰：</p>\n<div>$$\n\\begin{aligned}\nU_i(e^{j\\omega})& =K_i(e^{j\\omega})\\cdot Y_i(e^{j\\omega})  \\\\\n&\\approx\\frac1MK_i(e^{j\\omega})\\{a_iF_i(e^{j\\omega})X(e^{j\\omega})+b_iG_i(e^{j\\omega})X(e^{j\\omega})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot i)})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot i)})+ \\\\\n&a_iF_i(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega+\\frac{2\\pi}M\\cdot(i+1))})+b_iG_i(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})X(e^{j(\\omega-\\frac{2\\pi}M\\cdot(i+1))})\\} \\\\\n&i=1\\sim M-2\n\\end{aligned}\n$$</div>\n\n<p>为了解决升采样后的频谱混叠，在综合滤波器部分精确对消混叠信号：</p>\n<div>$$\na_id_i=-a_{i-1}d_{i-1},\\quad i>0\n$$</div>\n\n<h3 id=\"变换域编码\"><a href=\"#变换域编码\" class=\"headerlink\" title=\"变换域编码\"></a>变换域编码</h3><p>正交变换后编码：</p>\n<div>$$\nY = AX\n$$</div>\n\n<p>正交变换满足能量守恒</p>\n<div>$$\n||Y||^2 = ||X||^2\n$$</div>\n\n<p>重建信号的误差等于变换域上量化器的误差</p>\n<div>$$\nE = Y - [Y]\\\\\n||X - [x]||^2 = ||E||^2\n$$</div>\n\n<h4 id=\"比特分配\"><a href=\"#比特分配\" class=\"headerlink\" title=\"比特分配\"></a>比特分配</h4><p>假设 N 个输入样本组成一个矢量 X，变换域 Y 的每个分量用 $R_k$  个比特量化</p>\n<div>$$\nR=\\frac1N\\sum_{k=0}^{N-1}R_k\\\\\n\\sigma_q^2=\\sum_{k=0}^{N-1}\\sigma_{q,k}^2=\\varepsilon_*^2\\cdot\\sum_{k=0}^{N-1}2^{-2R_k}\\sigma_k^2\\\\\n\\min \\sigma_{q}^{2}=\\frac{1}{N}\\sum_{k=0}^{N-1}\\sigma_{q,k}^{2}\n$$</div>\n\n<div>$$\nR_{k,opt}=R+\\frac12\\log_2\\frac{\\sigma_{x_k}^2}{\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{1/N}}\\\\\n\\sigma_{q}^2 = min\\{\\sigma_{q,k}^2\\}=\\varepsilon_*^2\\cdot2^{-2R}\\cdot\\left[\\prod_{i=1}^M\\sigma_{x_i}^2\\right]^{\\frac{1}{N}}\n$$</div>\n\n<p>相比 PCM 的增益为</p>\n<div>$$\n\\begin{gathered}\nG_{TC} =\\frac{min\\{\\sigma_{r,PCM}^{2}\\}}{min\\{\\sigma_{r,TC}^{2}\\}}=\\frac{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\sigma_{\\chi}^{2}}{\\varepsilon_{*}\\cdot2^{-2R}\\cdot\\prod_{k=0}^{N-1}[\\sigma_{k}^{2}]^{\\frac{1}{N}}} \\\\\n=\\frac{\\sigma_x^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}}=\\frac{\\frac1N\\sum_{k=0}^{N-1}\\sigma_k^2}{\\prod_{k=0}^{N-1}[\\sigma_k^2]^{1/N}} \n\\end{gathered}\n$$</div>\n\n<h4 id=\"最佳正交变换-KL-变换\"><a href=\"#最佳正交变换-KL-变换\" class=\"headerlink\" title=\"最佳正交变换 - KL 变换\"></a>最佳正交变换 - KL 变换</h4><h2 id=\"语音信号的参数编码\"><a href=\"#语音信号的参数编码\" class=\"headerlink\" title=\"语音信号的参数编码\"></a>语音信号的参数编码</h2><h3 id=\"感觉加权滤波器\"><a href=\"#感觉加权滤波器\" class=\"headerlink\" title=\"感觉加权滤波器\"></a>感觉加权滤波器</h3><p>误差函数加权：</p>\n<div>$$\nJ=\\int_0^{f_s}\\lvert s(f)-\\hat{s}(f)\\rvert^2\\cdot\\lvert w(f)\\rvert^2df\n$$</div>\n\n<p>其中，加权滤波器满足</p>\n<div>$$\n\\int_0^{f_S}|w(f)|df= Const.\n$$</div>\n\n<p>当误差函数最小的时候，应当保证</p>\n<div>$$\n|s(f)-\\hat{s}(f)|^2\\cdot|w(f)|=\\frac{\\gamma}{2}=\\text{常数}\n$$</div>\n\n<p>可以选择如下的滤波器：</p>\n<div>$$\nw(z)=\\frac{A(z)}{A\\left(\\frac{z}{\\gamma}\\right)}=\\frac{1-\\sum_{i=1}^P\\alpha_iz^{-i}}{1-\\sum_{i=1}^P\\alpha_i\\gamma^iz^{-i}},\\quad0\\leq\\gamma\\leq1\n$$</div>\n\n<p>$\\gamma$ 为加权因子，在 0-1 之间。</p>\n<p>$\\gamma&#x3D;0$ 时变成逆滤波器，其频谱包络的峰值点就是语音谱的谷值点。</p>\n<blockquote>\n<p>分析：语音信号是全极点模型产生的，即 $S(z) &#x3D; GE(z)&#x2F;A(z)$，与逆滤波器点频谱成反比。</p>\n</blockquote>\n<p><img src=\"/../images/Speech-SP/1715172645812.png\" alt=\"1715172645812\"></p>\n<h3 id=\"多脉冲激励线性预测声码器\"><a href=\"#多脉冲激励线性预测声码器\" class=\"headerlink\" title=\"多脉冲激励线性预测声码器\"></a>多脉冲激励线性预测声码器</h3><p><img src=\"/../images/Speech-SP/1715172680511.png\" alt=\"1715172680511\"></p>\n<p>语音综合器的激励源有若干个不同位置和幅度的脉冲信号组成。</p>\n<div>$$\n\\hat{s}(n)=\\hat{s}_0(n)+\\sum_{k=1}^Mg_kh(n-n_k)\n$$</div>\n\n<p>其中 $\\hat s_0(n)$ 是 LPC 综合器的零输入响应。</p>\n<div>$$\n\\begin{aligned}&e_{s}(n)=s(n)-\\hat{s}(n)=s(n)-\\hat{s}_{0}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\\\&=\\bar{e}(n)-\\sum_{k=1}^Mg_kh(n-n_k)\\end{aligned}\n$$</div>\n\n<p>用 $\\bar{e}(n)&#x3D;s(n)-\\hat{s}_0(n)$ 表示输入语音减去零输入响应（受历史激励影响的部分）。</p>\n<p>输入感觉加权滤波器，得到输出</p>\n<div>$$\n\\begin{aligned}e(n)&=e_{s}(n)*w(n)=\\left[\\bar{e}(n)-\\sum_{k=1}^{M}g_{k}h(n-n_{k})\\right]*w(n)\\\\&=\\bar{e}_{w}(n)-\\sum_{k=1}^{M}g_{k}h_{w}(n-n_{k})\\end{aligned}\n$$</div>\n\n<p>从而，得到感觉加权滤波器的误差函数</p>\n<div>$$\nE=\\sum_{n=1}^Ne^2(n)=\\sum_{n=1}^N\\left[\\bar{e}_w(n)-\\sum_{k=1}^Mg_kh_w(n-n_k)\\right]^2\n$$</div>\n\n<p>选择合适的 $n_k$, $g_k$ 使得上面的误差函数最小</p>\n<div>$$\n\\frac{\\partial E}{\\partial n_j}=0,\\quad j=1,\\cdots M\\\\\\frac{\\partial E}{\\partial g_j}=0,\\quad j=1,\\cdots M\n$$</div>\n\n<p>上面那个方程很复杂，会导出非线性的方程；</p>\n<p>从下面的那个方程可以推出</p>\n<div>$$\n\\sum_{k=1}^Mg_kR_{hh}(n_k,n_j)=R_{eh}(n_j),\\quad j=1,\\cdots M\n$$</div>\n\n<p>其中</p>\n<div>$$\nR_{eh}(n_j)=\\sum_{n=1}^N\\bar{e}_w(n)\\cdot h_w(n-n_j)\\\\R_{hh}(n_k,n_j)=\\sum_{n=1}^Nh_w(n-n_k)h_w(n-n_j)\n$$</div>\n\n<p>此时可改写最小均方误差</p>\n<div>$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-\\sum_{k=1}^Mg_kR_{eh}(n_k)\n$$</div>\n\n<p>最优解的计算涉及到非线性方程的求解，不太现实。考虑采用次优搜索，一个一个求解。</p>\n<p>当只有一个脉冲时</p>\n<div>$$\ng_1R_{hh}(n_1,n_1)=R_{eh}(n_1)\\\\\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-g_1R_{eh}(n_1)\n$$</div>\n\n<p>消元得到</p>\n<div>$$\nE_{min}=\\sum_{n=1}^N[\\bar{e}_w(n)]^2-R_{eh}^2(n_1)/R_{hh}(n_1,n_1)\n$$</div>\n\n<p>接下来搜索 $n_1$ 使得上式最优化。解出 $n_1$ 后即可解出 $g_1$。</p>\n<p>接下来一个个求解，每次都要把前面求解过的脉冲折算到零输入响应中，然后求解当前的结果：</p>\n<h2 id=\"语音信号修整与综合技术\"><a href=\"#语音信号修整与综合技术\" class=\"headerlink\" title=\"语音信号修整与综合技术\"></a>语音信号修整与综合技术</h2><p>短时谱分析</p>\n<div>$$\n\\begin{gathered}w[n]=\\begin{cases}\\neq0&,&0\\leq n<L\\\\0&,&\\text{其它}\\end{cases}\\\\X(p,k)=\\sum_{n=-\\infty}^{+\\infty}x[n]w[p-n]e^{-j\\frac{2\\pi}{N}nk}\\\\x[n]w[p-n]=\\left[\\frac{1}{N}\\sum_{i=0}^{N-1}X(p,k)e^{j\\frac{2\\pi}{N}nk}\\right]\\cdot R[p-n]\\end{gathered}\n$$</div>\n\n<h3 id=\"利用修正短时谱进行最小方差信号估计\"><a href=\"#利用修正短时谱进行最小方差信号估计\" class=\"headerlink\" title=\"利用修正短时谱进行最小方差信号估计\"></a>利用修正短时谱进行最小方差信号估计</h3><p>首先计算短时谱</p>\n<div>$$\nX(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}x[m]w(p-m)e^{-j\\omega m}\n$$</div>\n\n<p>对短时谱进行修正</p>\n<div>$$\nY(p,\\omega)=X(p,\\omega)H(p,\\omega)\n$$</div>\n\n<p>需要得到一个“有效”的短时谱，满足：</p>\n<ol>\n<li>时域短时段有限长，非零段不超过窗函数 $w(p-n)$的范围</li>\n<li>一致性约束，即不同的𝑝时刻 𝑌(𝑝,𝜔)所对应的时域短时段，若有部分重叠，那么在去除分析窗的加权影响后，在重叠的部分，它们应该是相等的。</li>\n</ol>\n<p>实际上很难得到上述信号，可以通过最小方差准则逼近</p>\n<div>$$\nD[\\hat{Y}(n,\\omega),Y(n,\\omega)]=\\sum_{m=-\\infty}^{+\\infty}\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}\\left|\\hat{Y}(m,\\omega)-Y(m,\\omega)\\right|^{2}d\\omega\n$$</div>\n\n<p>其中</p>\n<div>$$\n\\hat{Y}(p,\\omega)=\\sum_{m=-\\infty}^{+\\infty}\\hat{y}[m]w(p-m)e^{-j\\omega m}\n$$</div>\n\n<p>利用 Parseval 定理</p>\n<div>$$\n\\begin{aligned}&D\\big[\\hat{Y}(n,\\omega),Y(n,\\omega)\\big]=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}_{m}(n)-y_{m}(n)|^{2}\\\\&=\\sum_{m=-\\infty}^{+\\infty}\\sum_{n=-\\infty}^{+\\infty}|\\hat{y}(n)w(m-n)-y_{m}(n)|^{2}\\end{aligned}\n$$</div>\n\n<p>变分法求得最小值</p>\n<div>$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(m-n)y_m(n)}{\\sum_{m=-\\infty}^\\infty w^2(m-n)}\n$$</div>\n\n<p>其中</p>\n<div>$$\ny_m(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi Y(m,\\omega)e^{j\\omega n}d\\omega\n$$</div>\n\n<p>应用中，以周期 $T$ 分析</p>\n<div>$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)y_{mT}(n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$</div>\n\n<p>如果 $w(n)$ 取三角窗的平方根</p>\n<div>$$\nw^2(n)=\\begin{cases}1-\\frac{|n-T|}{T}&,\\quad0\\leq n\\leq2T\\\\\\\\0&,\\quad\\text{其它}\\end{cases}\n$$</div>\n\n<p>若 n 此时为奇数，$T &#x3D; (N-1)&#x2F;2$，这时$\\sum_{m&#x3D;-\\infty}^{\\infty}w^{2}(mT-n)&#x3D;1$，可简化计算，如果频谱无修正，最优解为</p>\n<div>$$\n\\hat{y}(n)=\\frac{\\sum_{m=-\\infty}^\\infty w(mT-n)[w(mT-n)x(n)]}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=\\frac{x(n)\\sum_{m=-\\infty}^\\infty w^2(mT-n)}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}=x(n)\n$$</div>\n\n<p>若改变语音的速度，$p&#x3D;k\\cdot p^{\\prime}$，满足$|Y(p,\\omega)|&#x3D;|X(p^{\\prime},\\omega)|$ 。</p>\n<div>$$\ny_{p'}(n)=\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}Y(p',\\omega)e^{j\\omega n}d\\omega=w(p'-n)x(n)\n$$</div>\n\n<p>让 $\\tau_p&#x3D;p-p^{\\prime}&#x3D;(1-1&#x2F;k)\\cdot p$，</p>\n<div>$$\n\\begin{aligned}&y_p(n)=y_{p^{\\prime}}(n-\\tau_p)=w(p^{\\prime}-n+\\tau_p)x(n-\\tau_p)\\\\&=w(p-n)x(n-\\tau_p)\\end{aligned}\n\n<p>$$</div></p>\n<p>代入重建公式</p>\n<div>$$\n\\hat{y}[n]=\\frac{\\sum_{m=-\\infty}^\\infty w^2(mT-n)x(n-\\tau_{mT})}{\\sum_{m=-\\infty}^\\infty w^2(mT-n)}\n$$</div>\n\n<p>让$\\sum_{m&#x3D;-\\infty}^{\\infty}W(mT-n)&#x3D; \\sum_{m&#x3D;-\\infty}^{\\infty}w^2(mT-n) &#x3D;1$，</p>\n<div>$$\n\\hat{y}[n]=\\sum_{m=-\\infty}^{\\infty}W(mT-n)x(n-\\tau_{mT})\n$$</div>\n"},{"title":"Signals and Systems","date":"2023-02-22T01:46:36.000Z","katex":true,"_content":"\nMarch 15\n## Basic\n### Classification\nDeterministic & random\n\nPeriodic/non-periodic\n\nContinuous/Discrete(time)\n\nAnalog/Digital(Amplitude & time)\n\n### Operations\n\nShifting\n\nReflection\n\nScaling\n\nDiffrential\n\nIntegral\n\nAddition\n\nMultiplication\n\nConvolution\n\n$$\nf_1(t) * f_2(t) = \\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$\n\n### Singularity Signals\n\n#### Unit ramp function\n$$\nR(t) = 0, t\\lt 0; t, t>0\n$$\n\n#### Unit step function\n$$\nu(t) = 0, t<0;1/2, t=0;1, t>0\n$$\n\n#### Rectangular pulse\n$$\nu(t) - u(t-t_0)\n$$\n\n#### Sign function\n$$\nsgn(t) = 1, t>0;-1, t<0\n$$\ndefine $sgn(0)=0$, then $sgn(t)=2u(t)-1$\n\n#### Unit impulse function\nDirac definition\n$$\n\\int_{-\\infty}^{\\infty}\\delta(t)\\mathrm dt=1\\\\\n\\delta(t)=0(t\\ne 0)\n$$\n$$\n\\delta(t)=\\lim_{\\tau \\rightarrow0}\\left[U(t+\\frac\\tau2)-U(t-\\frac \\tau 2)\\right]\n$$\n\n$$\n\\int_{-\\infty}^{\\infty}\\delta(t)f(t)=f(0)\\\\\n\\int_{-\\infty}^{\\infty}\\delta(t - t_0)f(t)=f(t_0)\\\\\n\\delta(t)=\\delta(-t)\\\\\n\\frac{d}{dt}u(t)=\\delta(t)\n$$\n\n#### Impulse doublet function\n\n$\\delta^\\prime(t)$\nDouble impulses at t=0 which are mirror-imaged with their amplitude of infinite. \n\n$$\n\\int^{\\infty}_{-\\infty}\\delta^\\prime(t)\\mathrm dt=0\\\\\n\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t)\\mathrm dt=-f^{\\prime}(0)\\\\\n\\text{shifted:}\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t-t_0)\\mathrm dt=-f^{\\prime}(t_0)\\\\\n$$\n![](../images/ss/lec2_.jpg)\n\n### Signal Decomposition\n\n$$\nf(t) = f_D+f_A(t)\\\\\nf(t)=f_e(t)+f_o(t)\\\\\nf(t)=f_r(t)+jf_i(t)\\\\\nf_r(t)=\\frac{1}{2}\\left[f(t)+f^*(t)\\right]\\\\\nf_i(t)=\\frac{1}{2}\\left[f(t)-f^*(t)\\right]\n$$\n\n#### Pulse Component\n\n$$\nf(t)=\\int_{-\\infty}^{\\infty}f(t_1)\\delta(t-t_1)\\mathrm dt_1\n$$\n\nWe also have orthogonal function decomposition(Chap.3, Chap.6).\n\n### System modeling and Classification\n\nSystem model can be represented by math equation(including input-output description and state variables or state equation) graphic symbol and block diagrams.\n\nWe use the input-output description mostly. If controling something internal is needed, state euqtion is useful.\n\nBlock diagram: \n\n![](../images/ss/lec2_2.jpg)\n![](../images/ss/lec2_3.jpg)\n\n### System classification\n\n#### Linear or Non-linear\n\n$$\ne_1(t)\\rightarrow r_1(t),\ne_2(t)\\rightarrow r_2(t)\\Rightarrow\\\\\na_1e_1(t)+a_2e_2(t)\\rightarrow a_1r_1(t)+a_2r_2(t)\n$$\n\n#### Time-variant or Time-invariant\n\n#### Memory or Memoryless\n\nwith memory: dynamic system, differential equation\n\nwithout memory: instant system, algebraic equation\n\n#### Continuous or Discrete\n\nContinuous  Differential equation\n\nDiscrete  Difference equation\n\n#### Lumped- or Distributed-Parameter\n\nLumped: constant coefficient differential equation\n\nDistributed: partial equation\n\n#### Causal or Non-Causal\n\nwhen $t<0, e(t)=0 \\Rightarrow t<0, r(t)=0$ Generic definition?\n\nthe future state cannot have effect on now state. The state of causal system can only be determined by now and past states.\n\n#### Reversible or irreversible\n\ndifferent input to different output, otherwise irreversible.\n\n### LTI System\n\n#### Linearity\n\nLinearity leads to superposition and homogeneity.\n\n#### Time-Invariant\n\na time shift in the input results in a same time shift in the output.\n\n$$\ne(t)\\rightarrow r(t)\\Rightarrow e(t-t_0)\\rightarrow r(t-t_0)\\\\\n\\lim_{\\Delta t\\rightarrow 0}\\frac{e(t)-e(t-\\Delta t)}{\\Delta t}\\rightarrow \\lim_{\\Delta t\\rightarrow 0}\\frac{r(t)-r(t-\\Delta t)}{\\Delta t}\\\\\n\\frac{\\mathrm de(t)}{dt}\\rightarrow \\frac{\\mathrm dr(t)}{dt}\n$$\n\nIf every coefficient is time independent, the system is time invariant.\n\n## Time-Domain(TD) Analysis\n\n$$\nC_0\\frac{d^nr(t)}{dt^n}+C_1\\frac{d^{n-1}r(t)}{dt^{n-1}} + ... + C_nr(t)\\\\\n=E_0\\frac{d^me(t)}{dt^m}+E_1\\frac{d^{m-1}e(t)}{dt^{m-1}}+...+E_me(t)\n$$\n\n**Three Steps**\n\n* Homogeneous\n* Particular\n* Calculation on coefficients\n\n### Determining Coefficients\n\nIf functions are continuous, we can get their boundary conditions by determining the derivatives.\n\nThen the coefficients can be solved by multipling the inverse of Vandermonde matrix with the boundary condition matrix.\n\n#### Zero-input and -state Responses\n\n**Zero-input response** The response caused by the initial state (i.e., energy originally stored in the system), and it is denoted by $r_{zi}(t)$\n\n**Zero-state response** $r(0_-)\\equiv 0$, the response caused only by the external excitation and it is denoted by $r_{zs}(t)$\n\n![](../images/ss/lec3_1.jpg)\n\n![](../images/ss/lec3_2.jpg)\n\nThe combination of zero-input response and the zero-state response is not necessarily linear, since the existence of constant. If one of them vanishes, the other is linear.\n\n### Impulse and Step Responses\n\n**Impulse Response** the zero-state response $h(t)$ to $\\delta (t)$, which can be equalized to the initial condition.\n\nNote: normally $n>m$.\n\n**Unit Step Response** The zero-state response $g(t)$ to $u(t)$\n\nThere might be a forced term in $g(t)$.\n\n$$\ng(t) = \\int_0^th(\\tau)d\\tau\n$$\n\n### Convolution\n\nZero-state required\n\n$$\ne(t) = \\int_{-\\infty}^{\\infty}e(\\tau)\\delta(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=\\int_{-\\infty}^{\\infty}e(\\tau)h(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=e(t)*h(t)\n$$\n\nthe definition of convoluiton:\n\n$$\nf_1(t)*f_2(t)=\\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$\n\n**Integral interval** $e(t)=0, \\forall t<0$, $h(t)=0,\\forall t<0$, so $r(t)=\\int_0^t{e(\\tau)h(t-\\tau)\\mathrm d\\tau}$\n\nThe condition for applying convolution:\n\n* For linear system ONLY\n* For time variant systems, $h(t, \\tau)$ means response at time $t$ generated by the impulse at time $\\tau$, then $r(t)=\\int_0^th(t,\\tau)e(\\tau)\\mathrm d \\tau$; for time-invariant system is a special case, $h(t,\\tau)=h(t-\\tau)$.\n\n**The Properties of Convolution** The commutative property, the distributive property, the associative property\n\nDifferential:\n\n$$\n(f_1(t)*f_2(t))^\\prime=f_1^\\prime(t)*f_2(t)\n$$\n\nIntegral\n\n$$\n\\int f_1(t)*f_2(t)=f_1(t) * \\int f_2(t)\n$$\n\n$$\n(f_1(t) * f_2(t))^{(i)}=f_1^{(j)}(t) * f_2^{(i-j)}(t)\n$$\n\n**Convolution with $\\delta (t)$ or $u(t)$**\n\n(1) $f(t) * \\delta(t) = f(t)$\n\n(2) $f(t) * \\delta(t - t_0) = f(t-t_0)$\n\n(3) $f(t) * u(t) = \\int_{\\infty}^{t}f(\\tau)\\mathrm d\\tau$\n\n(4) $f(t) * \\delta^\\prime(t) = f^\\prime(t)$\n\n## Fourier Transform\n\n### Fourier Series\n\nrequirements:\n\n* has finite number of discontinuities\n* has finite number of maxima and minima\n* $\\int_{t_0}^{t_0+T_1} |f(t)|\\mathrm dt < \\infty$\n\n$$\n\\begin{align*}\nf(t)&=a_0+\\sum_{n=1}^\\infty \\left[a_n\\cos(n\\omega_1)t + b_n\\sin(n\\omega_1t)\\right]\\\\\n&=c_0 + \\sum_{n=1}^\\infty c_n\\cos \\left(n\\omega_1t+\\varphi_n \\right)\\\\\n&=\\sum_{n=-\\infty}^{\\infty}F_ne^{jn\\omega_1 t}\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n    a_0&=\\frac{1}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\mathrm dt=c_0\\\\\n    a_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\cos(n\\omega_1t)\\mathrm dt\\\\\n    b_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\sin(n\\omega_1t)\\mathrm dt\\\\\n    c_n&=\\sqrt{a_n^2+b_n^2}\\\\\n    \\varphi_n&=-\\tg^{-1}\\frac{b_n}{a_n}\\\\\n    F_n&=\\frac 1{T_1}\\int_{t_0}^{t_0+T_1}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\n    &=\\frac 12e^{j\\varphi_n}\\\\\n    &=\\frac 12(a_n-jb_n)\n\\end{align*}\n$$\n\n**note** When $b_n=0$, $\\varphi_n = a_n > 0\\ ?\\ 0:\\pi$\n\nIn the last part, the negative frequency is introduced for the convenience of the signal analysis. Therefore the amplitude is reduced to half.\n\n\n**FS for special functions**\n\n1. Even function $c_n=a_n, \\varphi_n = 0, F_n=F_{-n}=\\frac 12 a_n$\n2. Odd function $a_0=0, a_n=0, \\varphi_n=-\\frac{\\pi}{2}, F_n=F_{-n}=-\\frac{1}{2}jb_n$\n3. Half-wave Odd (odd harmonic) function, $f(t)=-f\\left(t\\pm \\frac{T_1}2{}\\right)$, contains only odd harmonics(both sine and cosine)\n4. Finite term series\n\n### FS for typical periodic signals\n\n**Periodic square wave**\n\n$$\nf(t)=\\frac{E\\tau}{T_1}+\\sum_{n=1}^{\\infty}\\frac{2E\\tau}{T_1}\\text{Sa}(\\frac{n\\omega_1\\tau}{2})\n$$\n\n1. Spectrum is discrete with frequency spacing $\\omega_1 = \\frac{2\\pi}{T_1}$. When $T_1 \\rightarrow \\infty$, the spectrum will be continuous.\n2. Amplitude: $\\text{Sa}\\left(\\frac{n\\pi\\tau}{T_1}\\right)$ or $\\text{Sa} \\left(\\frac{n\\omega_1\\tau}{2}\\right)$, cross zero when $\\omega_1 = \\frac{2m\\pi}{\\tau}$\n3. Non-zero FS coefficients of a aperiodic signal are infinite with most energy concentrated at low frequency components (within $\\left(-\\frac{2\\pi}{\\tau},\\frac{2\\pi}{\\tau}\\right)$). Thus we define the bandwith $B_{\\omega} = \\frac{2\\pi}{\\tau}$\n\n**Periodic symmetric square wave**\n\nSince the spectrum crosses zero when $\\omega_1 = \\frac{2m\\pi}{\\tau}$, the even harmonic vanishes. Also the sine component vanishes.\n\n$$\nc_n = \\frac{2E\\tau}{T_1}\\left|\\text{Sa}\\left(\\frac{n\\omega_1\\tau}{2}\\right)\\right|\\\\\nf(t) = \\frac{2E}{\\pi}\\left[\\cos(\\omega_1t) - \\frac{1}3\\cos(3\\omega_1t) + \\frac{1}{5}\\cos(5\\omega_1t)-...\\right]\n$$\n\n**Periodic Serrated Pulse**\n\n$$\nf(t) = \\sum_{n = 1}^\\infty \\frac{E}{n\\pi}(-1)^{n+1}\\sin (n\\omega_1t)\n$$\n\n**Periodic Triangular Pulse**\n\n$$\nf(t)=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{n^2}\\sin^2\\left(\\frac{n\\pi}{2}\\right)\\cos(n\\omega_1t)\\\\=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{(2n-1)^2}\\cos((2n-1)\\omega_1t)\n$$\n\n**consine of non-negative values**\n\n$$\nf(t) = \\frac E\\pi - \\frac{2E}{\\pi}\\sum_{n=1}^\\infty\\frac{1}{n^2-1}\\cos(\\frac {n\\pi}2)\\cos(n\\omega_1t)\n$$\n\n**cosine of absoulute values**\n\n$$\nf(t) = \\frac{2E}{\\pi} + \\frac{4E}{\\pi}\\sum_{n=1}^\\infty (-1)^{n+1}\\frac{1}{4n^2-1}\\cos(2n\\omega_0t)\n$$\n\n其中$\\omega_0$ = $2\\omega_1$\n\n### Fourier Transform\n\nThe case where $T_1\\rightarrow \\infty$. Signal becomes aperiodic.\n\nAlso, $\\omega_1\\rightarrow 0$ results in the continuous frequency axis. For square wave the magnitude $\\frac{E\\tau}{T_1}\\rightarrow 0$.\n\n$$\nf(t) =\\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)e^{jn\\omega_1 t}\\\\\nF(n\\omega_1) = \\frac 1T_1\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\n$$\n\nWe use spectrum density to replace spectrum, making the magnitude dropping to zero remain its meaning.\n\n$$\n\\frac{F(n\\omega_1)}{\\omega_1} = \\frac{1}{2\\pi}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\nF(\\omega) = \\lim_{\\omega_1\\rightarrow 0}\\frac{2\\pi F(n\\omega_1)}{\\omega_1}=\\lim_{T_1\\rightarrow \\infty}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm d t=\\int_{-\\infty}^\\infty f(t)e^{-j\\omega t}\\mathrm d t\\\\\nf(t) = \\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)\\cdot \\frac{1}{\\omega_1}e^{jn\\omega_1 t} \\Delta(n\\omega_1) = \\frac{1}{2\\pi}\\int_{-\\infty}^\\infty F(\\omega)e^{j\\omega t}\\mathrm d\\omega\n$$\n\n$$\nF(\\omega) = |F(\\omega)|e^{j\\varphi(\\omega)}\n$$\n\nThe fourier transfrom is continuous waveform, where every frequency has no energy but energy density, used to analyse aperiodic function.\n\nSufficient condition, but not necessary.\n\n$$\n\\int_{-\\infty}^\\infty |f(t)|\\mathrm dt<\\infty\n$$\n\n### FT for typical aperiodic signals\n\n**Rectangular pulses**\n\n$$\nF(\\omega) = \\int_{-\\tau/2}^{\\tau/2} Ee^{-j\\omega t}\\mathrm dt = E\\tau \\text{Sa}\\left(\\frac{\\omega \\tau}{2}\\right)\n$$\n\n**Raised Cosine Signal**\n\n$$\nf(t) = \\frac{E}{2}(1+\\cos\\frac{\\pi t}{\\tau})(u(t+\\tau) - u(t - \\tau))\\\\\nF(\\omega) = \\int_{-\\tau}^{\\tau}(1+\\cos\\frac{\\pi t}{\\tau})\\mathrm dt = \\frac{E\\tau}{1 - \\left(\\frac{\\omega \\tau}{\\pi}\\right)^2}\\text{Sa}({\\omega \\tau})\n$$\n\nMore compacted than square signal($|F(\\omega)|\\propto \\frac 1{\\omega^3}$). An explanation is that the raised cosine has no discontinuities.\n\nGenerally:\n\n1. $f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega}$\n2. $\\frac{d}{dt}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^2}$\n3. $\\frac{d^2}{dt^2}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^3}$\n\nThe **width** $\\tau$ of the raised cosine signal is defined at $\\frac E2$ rather than at the bottom, making it easy to compare with \n     the rectangular pulse of same width. The first zeros of the \n   frequency spectrum are identical.\n\n\nraised consine is energy-concentrative and has been widely used in digital communications.\n\n**Single-sided exponential singal** \n\n$$\nf(t) = e^{-at}u(t)\\\\\nF(\\omega) = \\frac{1}{a+j\\omega}\n$$\n\n**Two-sided, anti-symmetric exponential signal**\n\n$$\nf(t) = -e^{at}u(-t) + e^{-at}u(t)\\\\\nF(\\omega) = \\frac{-2j\\omega}{a^2+\\omega^2}\n$$\n\n**Sign function**\n\n$$\n\\text{sgn}(t) = u(t) - u(-t)\\\\\nF(\\omega) = \\lim_{a\\rightarrow 0}\\frac{-2j\\omega}{a^2+\\omega^2}= \\frac{2}{j\\omega}\n$$\n\n**Gaussian singal**\n\n$$\nf(t) = Ee^{-\\left(\\frac{t}{\\tau}\\right)^2}\\\\\nF(\\omega) = \\sqrt \\pi E\\tau e^{-\\left(\\frac{\\omega\\tau}{2}\\right)^2}\n$$\n\n**Sinc Function**\n\n$$\nf(t) = \\frac{E}{\\pi}\\frac{\\sin(\\omega_c t)}{t}\\\\\nF(\\omega) = E(u(\\omega - \\omega_c ) + u(\\omega + \\omega_c ))\\\\\n$$\n\n\n### FT on impulse and step functions\n\n$$\n\\mathcal F[\\delta(t)] = 1\\\\\n\\mathcal F[1] = 2\\pi \\delta(\\omega)\n$$\n\nThe spectrum of impulse function covers the entire frequency range. The interferences caused by a variety of electric sparks always cover the full frequency range.\n\n$$\n\\mathcal F[\\delta^\\prime (t)]= j\\omega\\\\\n\\mathcal F[\\delta^{(n)}(t)] = (j\\omega)^n\n$$\n\n$$\n\\mathcal F[u(t)] = \\pi \\delta(\\omega) + \\frac{1}{j\\omega}\n$$\n\nDue to the DC component in u(t), an impulse exists.\n\n### Properties of FT\n\n**Symmetry** $\\mathcal F[F(t)]= 2\\pi f(-\\omega)$ , if $f(t)$ is a even function, $\\mathcal F[F(t)]= 2\\pi f(\\omega)$\n\n**Linearity** $\\mathcal{F}[\\Sigma_{i=1}^{n}a_if_i(t)] = \\Sigma_{i=1}^{n}a_iF_i(\\omega)$\n\n**Odd-Even, Imaginary-Real** $f(t) = f_e(t)+f_o(t)$, then\n\n$$\n\\begin{align*}\n  F(\\omega) &= \\int_{-\\infty}^\\infty f(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f(t)\\sin \\omega t \\mathrm dt\\\\\n  &=R(\\omega)+jX(\\omega)\\\\\n  &=\\int_{-\\infty}^\\infty f_e(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f_o(t)\\sin \\omega t \\mathrm dt\\\\\n\\end{align*}.\n$$\n\n$R(\\omega)$ is an even function of $\\omega$, $X(\\omega)$ is an odd function of $\\omega$.\n\n$|F(\\omega) = \\sqrt{R^2(\\omega)+F^2(\\omega)}|$ is even function.\n\n$\\varphi(\\omega) = \\tg^{-1}\\frac{R(\\omega)}{X(\\omega)}$\n\nif $f(t)$ is real and even, then $f(t)=f_e(t), F(\\omega)=R(\\omega)$, the phase shift is $0$ or $\\pi$.\n\nif $f(t)$ is real and odd, $f(t) = f_o(t)$, then $F(\\omega)=jX(\\omega)$, $F(\\omega)$ has only imaginary part and is odd, the phase shift is $\\pm \\frac{\\pi}{2}$\n\n**Scaling** $\\mathcal{F}[f(at)]=\\frac 1{|a|}F\\left(\\frac{\\omega}a\\right)$ Expansion in TD results in Compression in FD.\n\n**Time Shifting** $\\mathcal{F}[f(t\\pm t_0)] = F(\\omega)e^{\\pm j\\omega t_0}$\n\n**Frequency Shifting** $\\mathcal F[f(t)e^{\\pm j\\omega_0t}] = F(\\omega\\mp\\omega_0)$\n\n**Differentiation property**$\\mathcal F\\left[\\frac{\\mathrm d}{\\mathrm dt}f(t)\\right] = j\\omega F(\\omega)$\n\n$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm dt^n}f(t)\\right] = (j\\omega)^n F(\\omega)$\n\n$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm d\\omega^n}F(\\omega)\\right] = (-jt)^nf(t)$\n\n\n**Integration Property** $\\mathcal{F}\\left[\\int_{-\\infty}^t f(\\tau)\\mathrm{d} \\tau\\right] = \\frac{F(\\omega)}{j\\omega} + \\pi F(0)\\delta(\\omega)$\n\n### Convolution theorem\n\n$$\n\\mathcal F[f_1(t)* f_2(t)] = F_1(\\omega)F_2(\\omega)\\\\\n\\mathcal F[f_1(t)\\cdot f_2(t)] = \\frac 1{2\\pi} F_1(\\omega) * F_2(\\omega)\n$$\n\n### FT for Periodic Signals\n\n$$\n\\mathcal F[\\cos (\\omega_0 t)] = \\pi [\\delta(\\omega + \\omega_0) + \\delta(\\omega - \\omega_0)]\\\\\n\\mathcal{F} [\\sin (\\omega_0 t)] = j\\pi [\\delta(\\omega+\\omega_0) + \\delta(\\omega - \\omega_0)]\n$$\n\nFT for periodic of $T_1$ & $\\omega_1=2\\pi/T_1$\n\n$$\n\\mathcal F[f(t)] = 2\\pi\\sum_{n=-\\infty}^{+\\infty} F_n\\delta(\\omega - n\\omega_1)\\\\\nF_n = \\frac 1{T_1}\\int_{-T_1/2}^{T_1/2}f(t)e^{-jn\\omega_1 t}\\mathrm dt = \\frac{1}{T_1}F_0(\\omega)\\vert_{\\omega =n\\omega_1}\n$$\n\nWhere $F_0(\\omega)$ is the FT considering waveform of $f(t)$ only in $|t|\\le T_1/2$.\n\nexample: \n\n$$\nf(t) = \\sum_{n=0}^{\\infty}\\delta(t-nT_1), F_n=\\frac{1}{T_1}\\\\\nF(\\omega) = \\frac{2\\pi}{T_1}\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)=\\omega_1\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)\n$$\n\n$$\nF_0(ω) \\text{ determines the profile of } F(ω)\\\\\nT_1\\text{ determines the density of the impulses\n}\\\\\nT_1↑, ω_1↓\\text{, intensity of harmonics}↓\\\\\nT_1↓,ω_1↑\\text{, intensity of harmonics}↑\\\\\n$$\n\n![](../images/ss/lec7_1.jpg)\n\nIn the same way: \n\n![](../images/ss/lec7_2.jpg)\n\n### FT for periodically sampled signals\n\n$$\nF(\\omega) = \\mathcal F[f(t)]\\\\\nP(\\omega) = \\mathcal F[p(t)]\\\\\nf_s(t) = f(t)p(t)\\\\\nF_s(\\omega) =\\frac{1}{2\\pi} F(\\omega) * P(\\omega)\n$$\n\nThen, \n\n$$\nP(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_n\\delta(\\omega - \\omega_s)\\\\\nF(\\omega) * P(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\\\\\nF_s(\\omega) = \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\n$$\n\n![](../images/ss/lec7_3.jpg)\n\nFor the frequency-domain sampling: \n\n$$\nF_1(\\omega) = F(\\omega)P(\\omega)\\\\\nP(\\omega) = \\sum_{n=-\\infty}^{+\\infty} \\delta(\\omega - n\\omega_1)\\\\\nf_1(t) = f(t) *  \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{+\\infty} \\delta(t - nT_1) = \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{\\infty} f(t-nT_1)\n$$\n\n**The Sampling Theorem**\n\n$$\n\\omega_s \\ge 2\\omega_m\n$$\n\nA band-limited signal whose spectrum is strictly within $[0, f_m]$ could be uniquely determined by the samples on itself, if and only if the sampling interval $T_s \\le 1/(2f_m)$.\n\n$T_s = \\frac{1}{2f_m}$ is called the **Nyquist interval**.\n\n$2f_m$ is called the **Nyquist frequency**.\n\n对于单频信号，奈奎斯特频率的采样可能会出现问题。例如正弦信号，每次采样都采在零点上，那就没法复现信号。单频信号没法描述带宽。\n\nA FD verison:\n\n![](../images/ss/lec7_4.jpg)\n\n\n\n## L Transform\n\n### Unilateral L-transform\n\n$$\nF(s) = \\int^{\\infty}_{0}f(t)e^{-st}\\mathrm dt, s=\\sigma+j\\omega\\\\\nf(t)=\\frac{1}{2\\pi j}\\int_{\\sigma-j\\infty}^{\\sigma+j\\infty}F(s)e^{st}\\mathrm ds\n$$\n\n$F(s) = \\mathcal{L}[f(t)]$ is called image function, $f(t) = \\mathcal{L}^{-1}[F(s)]$ is called primitive function.\n\nassuming that $f(t)$ is causal and always 0 if $t<0$.\n\n$$\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0) + sF(s)\n$$\n\nThe initial state is automatically included in differential equation.\n\nWe define the **unilateral** L-Transform as: \n\n$$\nF(s) = \\int_{0_-}^{\\infty}f(t)e^{-st}\\mathrm dt\\\\\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0_-) + sF(s)\n$$\n\nConditions for L-Transform: \n\n1. Limited discontinuities\n2. Exponential order\n\nThe strong attenuation factor can make the function convergent.\n\nRegion of Convergence (ROC)\n\nAxis of convergence\n\nCoordinate of convergence $\\sigma_0$\n\n### Comman LT Pairs\n\n$$\n\\begin{align*}\nf(t)&\\Rightarrow F(s)\\\\  \n\\delta(t) &\\Rightarrow 1\\\\\nu(t) &\\Rightarrow \\frac 1s\\\\\ne^{-at} &\\Rightarrow \\frac{1}{s+a}\\\\\nt^n & \\Rightarrow \\frac{n!}{s^{n+1}}\\\\\n\\sin (\\omega t)&\\Rightarrow \\frac{\\omega}{s^2 + \\omega^2}\\\\\n\\cos (\\omega t)&\\Rightarrow \\frac{s}{s^2+\\omega^2}\\\\\n\\end{align*}\n$$\n\n### Properties of LT\n\n**Linarity**\n\n$$\n\\mathcal L [k_1f_1(t) + k_2f_2(t)] = k_1F_1(s) + k_2F_2(s)\\\\\n$$\n\n**Differentiation**\n\n$$\n\\mathcal L \\left[\\frac{\\mathrm d f(t)}{\\mathrm d t}\\right] = sF(s) - f(0_-)\n$$\n\n**Intergration**\n\n$$\n\\mathcal L\\left[\\int_{-\\infty}^t f(\\tau)\\mathcal d\\tau\\right]=\\frac{F(s)}{s} + \\frac{f^{(-1)}(0)}{s}\n$$\n\n**Time Shifting**\n\n$$\n\\mathcal L\\left[f(t-t_0)u(t-t_0)\\right] = e^{-st_0}F(s)\n$$\n\nUse $u(t-t_0)$ to avoid nagative part of $f(t)$ emerges.\n\n**Frequency Shifting**\n\n$$\n\\mathcal L[f(t)e^{-at}] = F(s+a)\n$$\n\n**Scaling**\n\n$$\n\\mathcal L[f(at)] = \\frac 1a F\\left(\\frac{s}{a}\\right)\n$$\n\n**s-Domain Differentiation**\n\n$$\n\\frac{\\mathrm d}{\\mathrm ds}\\mathcal L[f(t)] = \\mathcal L[-tf(t)]\n$$\n\n**s-Domain Differentiation**\n\n$$\n\\int_s^\\infty F(s) = \\mathcal{L}\\left[\\frac{f(t)}{t}\\right]\n$$\n\n**Initial value**\n\n$$\nf(0_+) = \\lim_{s\\rightarrow\\infty}sF(s)\n$$\n\n**Final value**\n\n$$\n\\lim_{t\\rightarrow\\infty} f(t) = \\lim_{s\\rightarrow0} sF(s)\n$$\n\nGeneralized limit: $\\lim_{t\\rightarrow\\infty} \\sin(\\omega t)=0$\n\n**Convolution**\n\n$$\n\\mathcal L[f_1(t)*f_2(t)] = F_1(s)F_2(s)\n$$\n\n### Applications\n\n**Differential Equations**\n\n$$\n  F(s) = \\frac{A(s)}{B(s)} = \\frac{a_ns^n + a_{n-1}s^{n-1} + \\cdots + a_1s + a_0}{b_ms^m + b_{m-1}s^{m-1} + \\cdots + b_1s + b_0} % The division of two polynomials\n$$\n\n(assume that $n<m$)\n\nThe roots of numerator is called zeros, while the roots of denominator is called poles.\n\nUnknown function F(s) can be represented by the ratio of two polynomials if all initial states are 0.\n\n1. real poles\n\n$$\nF(s) = \\frac{A(s)}{(s-p_1)(s-p_2)(s-p_3)}\n$$\n\n2. complex conjugate poles\n\n$$\nF(s) = \\frac{A(s)}{D(s)[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{(s+\\alpha - j\\beta)(s+\\alpha + j\\beta)} + \\dots\n$$\n\n$$\nk_1 = (s+\\alpha - j\\beta)F(s)|_{s = -\\alpha + j\\beta} = \\frac {F_1(-\\alpha + j\\beta)}{2j\\beta}\\\\\nk_2 = (s+\\alpha + j\\beta)F(s)|_{s = -\\alpha - j\\beta} = \\frac {F_1(-\\alpha - j\\beta)}{-2j\\beta}\n$$\n\n3. Multiple poles\n\n$$\nF(s) = \\frac {A(s)}{B(s)} = \\frac{A(s)}{(s-p_1)^k D(s)}\\\\\n= \\frac{K_{11}}{(s-p_1)^k}+\\frac{K_{12}}{(s-p_1)^{k-1}}+\\dotsb+\\frac{K_{1k}}{s-p_1} + \\frac{E(s)}{D(s)}(s-p_1)^k\n$$\n\n![](../images/ss/lec9_1.jpg)\n\n![](../images/ss/lec9_2.jpg)\n\n\nCircuit model:\n\n![](../images/ss/lec9_3.jpg)\n\n![](../images/ss/lec9_4.jpg)\n\n![](../images/ss/lec9_5.jpg)\n\nUse initial value and final value to verify it.\n\n### System Function\n\n$$\n\\begin{cases}\n  R(s) = H(s) \\cdot E(s)\\\\\n  r(t) = h(t) * e(t)\n\\end{cases}\n\\Rightarrow H(s) = L[h(t)]\n$$\n\n**Driving point function & transfer function**\n\n![](../images/ss/lec9_6.jpg)\n\nL-transform can be used in the following analysis:\n\n* TD characteristics (response decomposition)\n* FD characteristics (steady-state with sine signal input,applications such as filtering) \n* Stability (active network, feedback, oscillator, control system)\n\n\n### TD characteristics by 0-point distribution\n\nThree cases: \n\n* Real poles\n* Complex conjugate poles\n* Real pole of high-order\n\n1. Zero pole of H(s)\n\n\n\n![](../images/ss/lec10_1.jpg)\n\n![](../images/ss/lec10_2.jpg)\n\nZero only affects the phase and amplitude, while the shape and type of waveform is determined by the poles.\n\n2. pole distribution $\\Leftrightarrow$ corresponding natural/forced responses\n\n$$\nH(s) = \\frac{\\prod_{i = 1}^m(s-z_{hj})}{\\prod_{i = 1}^n(s-p_{hi})}\\\\\nE(s) = \\frac{\\prod_{i = 1}^u(s-z_{el})}{\\prod_{i = 1}^v(s-p_{ek})}\\\\\n\\text{if } m + u < n + v\\\\\nR(s) = E(s)H(s) = \\sum_{k=1}^n\\frac{K_{hk}}{s - p_{hk}} + \\sum_{k=1}^v\\frac{K_{ek}}{s-p_{ek}}\n$$\n\nThe natural response of $r(t)$ is only related to $p_{hk}$, while the forced response is only related to $p_{ek}$.\n\n$K_{hk}$, $K_{ek}$ are related to both $H(s)$ and $E(s)$.\n\nHowever natural and forced responses could not be completely separated, if there exists $k, k^\\prime$ satisfying $p_{hk}=p_{ek^\\prime}$.\n\n$p_{hi}$ are called natural frequency of the system.\n\nHowever, some common factors may be eliminated: \n\n$$\n\\frac{(s+1)}{(s+1)(s+2)} = \\frac{1}{(s+2)}\n$$\n\n$$\nH(s) = \\frac{\\Delta_{jk}}{\\Delta}\n$$\n\nAll the poles of $H(s)$ are the natural frequencies of the system, but $h(t)$ may not include all the natural frequencies(but the root of $\\Delta$ contains all natural frequencies).\n\nIn most cases:\n\n$$\n\\text{Re}(p_{hi}) < 0, \\text{Re}(p_{ei}) = 0\n$$\n\nThus the natural response is transient, while the forced response is steady-state.\n\nHowever, some natural response can be steady-state(conjugate poles of $Re(p_{hi})$), while some forced response can be transient.\n\n![](../images/ss/lec10_3.jpg)\n\n![](../images/ss/lec10_4.jpg)\n\n![](../images/ss/lec10_5.jpg)\n\n$$\nE_m|H(j\\omega)|\\sin (\\omega_0t + \\varphi_0)\n$$\n\n$$\nH(j\\omega) =K\\cdot \\frac{\\prod(j\\omega - z_j)}{\\prod (j\\omega - p_i)}\n$$\n\n![](../images/ss/lec10_7.jpg)\n\n![](../images/ss/lec10_6.jpg)\n\n![](../images/ss/lec10_8.jpg)\n\nfor band-pass filter, \n\nBW is where Peak(dB) - 3dB\n\nfor low-pass filter,\n\nBW = $f_{\\text{cut-off}}$\n\nAccording to the sampling theorem, the signal bandwith is often determined by the first zero of the spectrum.\n\n**All Pass Systems**\n\n$$\nR_e(p_i) = -R_e(z_i)\\\\\nI_m(p_i) = I_m(z_i)\n$$\n\nThe Amplitude is const., while the phase can change.\n\n**Minimum-phase system/function**\n\nDefinition: A stable system with poles on left-half s-plane is called minimum-phase system/function, if all the zeros are also on left-half s-plane or at the jω-axis. Otherwise is a non-minimum-phase system/function. \n![](../images/ss/lec11_1.jpg)\n\n\nProperty: A non-minimum-phase function can be represented as the product of  a minimum-phase function and an all-pass function.\n\n### Stability of Linear System\n\nA system is considered to be stable if bounded input always leads to bounded output.\n\nBounded-input, Bounded-output(BIBO)\n\nThe necessary & sufficient conditions for BIBO:\n\n$$\n\\int_{-\\infty}^\\infty|h(t)|\\mathrm dt \\le M\n$$\n\nPoles are: \n\n* on the left half-plane: $\\lim_{t\\rightarrow \\infty}[h(t)] = 0$, stable system\n* on the right half-plane, or at $j\\omega$-axis with order of more than one: $\\lim_{t\\rightarrow \\infty}[h(t)] = \\infty$, unstable system\n* at $j\\omega$-axis with order of one: $h(t)$ is non-zero or oscillated with equal amplitude, critical stable system\n\n### Two-sided (Bilateral) LT\n\n$$\nF_B(s) = \\int_{-\\infty}^\\infty f(t)e^{-st}\\mathrm{d} t\n$$\n\n * t starts from −∞, i.e., non-causal signal as the input\n       or regarding the initial condition as the input.\n*  Easily to be associated with F-transform and Z-   \n       transforms\n\nWe determine the ROC by:\n\n$$\n\\lim_{t\\rightarrow \\infty} f(t)e^{-\\sigma t} = 0\\\\\n\\lim_{t\\rightarrow -\\infty} f(t)e^{-\\sigma t} = 0\n$$\n\nNOTE: \n\n* If no overlap between the two constraints, then $F_B(s)$ does not exist.\n* $F_B(s)$ and $f(t)$ are not uniquely corresponding to each other.($\\int_{-\\infty}^\\infty u(t)e^{-st}\\mathrm{d} t = \\frac{1}{s}$, $\\int_{-\\infty}^\\infty -u(-t)e^{-st}\\mathrm{d} t=\\frac{1}{s}$)\n* Two-sided L-Transform shares almost all the properties with its single-sided counterpart except for the initial-value theorem.\n* Two-sided L-Transform has very limited applications as most continuous-time systems are causal.\n\n**Relationship between LT and FT **\n\n* $\\sigma_0 > 0$, $F(\\omega)$ does not exist\n* $\\sigma_0 = 0$, impulse appears in $F(\\omega)$\n* $\\sigma_0 < 0$, $F(\\omega)$ exists, $F(\\omega) = F(s)|_{s=j\\omega}$\n\n![](../images/ss/lec11_2.jpg)\n(The LT above is unilateral LT.)\n\n\n![](../images/ss/lec11_3.jpg)\n\n### Extra Attention\n\n$1 + e^{-s}$ also has zero(many!). Note that if it is on the denominator.\n\n## FT in Telecom. Systems\n\nSystem discussed in this chapter are strictly stable: \n\n$$\n\\mathcal{F}[f(t)] = F(s)|_{s=j\\omega}\n$$\n\nBecause even for critical stable system, FT is not  the same as LT(containing $\\delta$), there will be ambiguity between $H(j\\omega)$ and $H(s)|_{s=j\\omega}$.\n\nFor every freq. component, it is reshaped in its phase and amplitude by the system function when passing through the system, related with its frequency. Thus the system can distort the original signal.\n\n**Distortion**\n\n2 types of distortion:\n\n* Non-linear distortion (new frequency components)\n* Linear distortion (without new frequency components), just the amplitude and/or phase distortion.\n\n **Distortionless transmission**\n\n$$\ne(t)\\rightarrow ke(t - t_0)\n$$\n\n$$\nR(j\\omega) = \\int_{-\\infty}^\\infty ke(t -t_0)e^{-j\\omega t}\\mathrm dt=ke^{-j\\omega t_0}\\int_{-\\infty}^\\infty e(x)e^{-j\\omega x}\\mathrm dx=ke^{-j\\omega t_0} E(j\\omega)\n$$\n\nSo, $H(j\\omega) = ke^{-j\\omega t_0}$, $h(t)=K\\delta(t - t_0)$.\n\nThe Amplitude is frequency independent, $BW\\rightarrow \\infty$.\n\nPhase response is linear at negative slope.\n\nThe impulse response of a distortionless linear system is  \n     also an impulse.\n\nThe physical scenario: group delay.\n\n$$\n\\tau = -\\frac{\\mathrm d\\varphi (\\omega)}{\\mathrm d\\omega}\n$$\n\nCondition for phase distortionless property: the group delay remains a constant.\n\n### Filter\n\n**Ideal Low pass (LP) Filter**\n\n$$\nH(j\\omega) = \\begin{cases}\n  1 \\cdot e^{-j\\omega t_0}, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$\n\n![](../images/ss/lec12_1.jpg)\n\n**The Impulse response of Ideal LP**\n\n![](../images/ss/lec12_2.jpg)\n\n* Severe distortion. $BW_{\\delta(t)}\\rightarrow \\infty$, but $BW_{\\text{Lowpass}}=\\omega_c$, the higier frequency is eliminated.\n* Non-causal. When $t\\lt 0$, $h(t)\\ne 0$.\n\n**Unit-step response of Ideal LP**\n\n![](../images/ss/lec12_3.jpg)\n\n![](../images/ss/lec12_4.jpg)\n\n![](../images/ss/lec12_5.jpg)\n\nThe response is similar to the input if $\\frac{1}{2}=\\frac{\\pi}{\\omega_c}\\llless \\tau$. \n\n**Gibbs phenomenon**: 9% overshoot at discontinuity. Use other window functions can eliminate this, e.g. raised-cosine window.\n\n### Modulation and demodulation\n\nMeans of modulation:\n\n**Spectrum shifting** \n\n$f(t) = g(t)\\cos(\\omega_0t)$, $F(\\omega) =\\frac{1}{2\\pi} G(\\omega) * \\pi[\\delta(\\omega - \\omega_0) + \\delta (\\omega + \\omega_0)] = \\frac{1}{2}[G(\\omega + \\omega_0) + G(\\omega - \\omega_0)]$.\n\n![](../images/ss/lec12_6.jpg)\n\nDemodulation: \n\n**coherent demodulation**\n\n$g_0(t)=[g(t)\\cos(\\omega_0 t)]\\cos(\\omega_0t) = \\frac{1}{2}g(t) + \\frac{1}{2}g(t)\\cos2\\omega_0t$\n\n![](../images/ss/lec12_7.jpg)\n\n**Envelope Detection**\n\n![](../images/ss/lec12_8.jpg)\n\n### Applications of BPF\n\n**Window Function**\n(Page 304)\n$$\nh_a(t) = \\frac{\\sqrt a \\sin\\left(\\frac{\\pi t}{a}\\right)\\cos \\left(\\frac{3\\pi t}{a}\\right)}{\\sqrt{ \\pi} \\pi t}\\\\\nH_a(\\omega) = \\begin{cases}\n  \\frac{1}{2}\\sqrt{\\frac{a}{\\pi}}, \\text{if } \\frac{2\\pi}{a}\\le |\\omega| \\le \\frac{4\\pi}{a},\\\\\n  0, \\text{otherwise}.\n\\end{cases}\n$$\n\n![](../images/ss/lec13_1.jpg)\n\n### Recover Continuous Time signal from its Samples\n\n**Analysis on signal after band-pass filter**\n\nPage 301\n\n**Sampling with impulse func.**\n\nFD analysis:\n\nSampled signal(By impulse function):\n\n$$\nF_s(\\omega) = \\frac{1}{T_s}\\sum_{n=-\\infty}^\\infty F(\\omega - n\\omega_s)\n$$\n\nIdeal LP Filter:\n\n$$\nH(j\\omega) = \\begin{cases}\n  T_s, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$\n\nRecovered signal: \n\n$$\nF(\\omega) = F_s(\\omega) \\cdot H(\\omega)\n$$\n\nTD analysis:\n\nSampled signal:\n\n$$\nf_s(t) = \\sum_{n=-\\infty}^\\infty f(nT_s)\\delta(t - nT_s)\n$$\n\nIdeal LP Filter:\n\n$$\nh(t) = T_s\\frac{\\omega_c}\\pi \\text{Sa}(\\omega_c t)\n$$\n\nRecovered signal:\n\n$$\nf(t) = f_s(t) * h(t) = T_s\\frac{\\omega_c}\\pi  \\sum_{n=-\\infty}^\\infty f(nT_s) \\text{Sa}(\\omega_c (t-nT_s))\n$$\n\n![](../images/ss/lec14_1.jpg)\n\n![](../images/ss/lec14_2.jpg)\n\n**Sampling with a zero-order hold**\n\n![](../images/ss/lec14_3.jpg)\n\n$$\nh_0(t) = u(t) - u(t - T_s)\\\\\nf_{s0}(t) = f_s(t)* h_0(t)\n$$\n\n$$\n\\begin{align*} \n&\\mathcal F\\{f_{s0}(t)\\} \\\\&=\\mathcal F\\{f_s(t)\\} \\cdot \\mathcal F\\{h_0(t)\\} \\\\ &=F_s(\\omega) \\cdot H_0(\\omega)\\\\\n&=\\sum_{-\\infty}^{\\infty}F(\\omega - n\\omega_s) \\cdot  \\text{Sa}(\\frac{\\omega_c T_s}{2})e^{-j\\frac{\\omega T_s}{2}}\\\\\n\\end{align*}\n$$\n\nLP Filter for compensation\n\n$$\nH_{0r}(\\omega) = \\begin{cases}\n  \\frac{1}{\\text{Sa}(\\frac{\\omega T_s}{2})}e^{j\\omega T_s/2}, &|\\omega| \\le \\omega_s/2,\\\\\n  0, &|\\omega|> \\omega_s/2.\n\\end{cases}\n$$\n\nLinear phase response is OK! No needed for delay compensation. \n\n**1st-order hold Sampling**\n\n![](../images/ss/lec14_4.jpg)\n\n### Mulitplexing FDM and TDM\n\nTransmit mulitple singals over a single channel concurrently.\n\nFrequency Division Multiplexing (FDM) － OFDM (Orthogonal FDM)\n\nTime Division Multiplexing (TDM)－sharing slot, statistical multiplexing\n\nCode Division Multiplexing (CDM)－ Code division, logical multiplexing\n\nWavelength Division Multiplexing (WDM)－ Optical carrier\n\n![](../images/ss/lec14_5.jpg)\n\n![](../images/ss/lec14_6.jpg)\n\n![](../images/ss/lec14_7.jpg)\n\n## Vector Analysis of Signals\n\n### Vector Space\n\n![](../images/ss/lec15_1.jpg)\n\n![](../images/ss/lec15_2.jpg)\n\n![](../images/ss/lec15_3.jpg)\n\n![](../images/ss/lec15_4.jpg)\n\n![](../images/ss/lec15_5.jpg)\n\n### Objective for singal decomposition\n\n$$\nr(t) = H[e(t)] = H\\left[\\sum_{i=0}^ne_i(t)\\right] = \\sum_{i=0}^nH[e_i(t)]\n$$\n\n### Basics\n\n**Orthogonal Vector**\n\n![](../images/ss/lec15_6.jpg)\n\n**Orthogonal Function**\n\nRepresend $f_1(t)$ in terms of $f_2(t)$(both real), for $t_1<t<t_2$\n\n$$\nf_1(t)\\approx c_{12}f_2(t)\n$$\n\nResidual error $\\overline{\\varepsilon^2} = \\overline{f_e^2(t)} = \\frac{1}{t_2 - t_1}\\int_{t_1}^{t_2}[f_1(t) - c_{12}f_2(t)]^2\\mathrm dt$\n\nLet $\\frac{\\mathrm d \\overline{\\varepsilon^2}}{\\mathrm d c_{12}} = 0$, then $\\overline{\\varepsilon^2}$ is minimized.\n\nThe coefficient can be determined as\n\n$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt} = \\frac{\\langle f_1, f_2\\rangle}{\\langle f_2, f_2\\rangle}\n$$\n\nIf $c_{12} = 0$, then $f_1(t), f_2(t)$ are called **Orthogonal Functions**.\n\nAnd \n\n$$\n\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt = 0\n$$\n\n**Orthogonal Function Set**\n\nAny real function $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.\n\n$$\nf(t) = \\sum_{r=1}^n c_rg_r(t)\n$$\n\nAccording to the minimal mean square error, the coefficient can be determined as\n\n$$\nc_r = \\frac{\\int_{t_1}^{t_2}f(t)g_r(t)\\mathrm dt}{\\int_{t_1}^{t_2}g_r^2(t)\\mathrm dt} = \\frac{\\langle f, g_r\\rangle}{\\langle g_r, g_r\\rangle}\n$$\n\nIf $g_1(t), g_2(t), ..., g_n(t)$ are orthogonal to each other, i.e.\n\n$$\n\\int_{t_1}^{t_2}g_r(t)g_s(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$\n\nThen $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.\n\nThen $g_1(t), g_2(t), ..., g_n(t)$ are called **Orthogonal Function Set**.\n\nIf $\\int_{t_1}^{t_2}g_i^2(t)\\mathrm dt = 1$, the orthogonal function set is called **Orthonormal Function Set**.\n\n**Orthogonality of Complex Function**\n\n$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2(t)f_2^*(t)\\mathrm dt} = \\frac{\\langle f_1, f_2^*\\rangle}{\\langle f_2, f_2^*\\rangle}\n$$\n\n**Orthogonal Function Set** satisfies\n\n$$\n\\int_{t_1}^{t_2}g_r(t)g_s^*(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$\n\nThe definition of Orthogonal is\n\n$$\n\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt = \\int_{t_1}^{t_2}f_2(t)f_1^*(t)\\mathrm dt = 0\n$$\n\nNOTE:\n\n* If two signals are orthogonal within a given interval, they are not necessarily orthogonal within other intervals.\n\n* If two signals are not orthogonal, they must be correlated.\n\n### Complete Orthogonal Function and Parseval's Theorem\n\n**Complete Orthogonal Funtion Set**\n\n$$\n\\overline{\\varepsilon^2} = \\frac{1}{t_2-t_1}\\left[\\int_{t_1}^{t_2}f^2(t)\\mathrm dt  - \\sum_{r = 1}^nc_r^2K_r\\right]\n$$\n\nIf $\\lim_{t_2 \\to \\infty}\\overline{\\varepsilon^2} = 0$, then $\\{g_r(t)\\}$ is said to be a **Complete Orthogonal Function Set**.\n\nAlternative definition of complete orthogonal set\n\nOther than the elements in $\\{g_r(t)\\}$, there is no finite-energy signal $x(t)$, which satisfies\n\n$$\n\\int_{t_1}^{t_2}x(t)g_r(t)\\mathrm dt = 0, \\forall r\\\\\n\\text{or } \\int_{t_1}^{t_2}x(t)g_r^*(t)\\mathrm dt = 0, \\forall r\n$$\n\n\nTrigonometric Set\n\n$$\n\\left\\{\\cos n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\\\\\n\\left\\{\\sin n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\n$$\n\nComplex exponential set\n\n$$\n\\left\\{e^{jn\\omega_1 t}\\right\\}_{n\\rightarrow\\infty}\n$$\n\n**Parseval's Theorem**\n\n$$\n\\int_{t_1}^{t_2}f(t)^2\\mathrm dt = \\sum_{r=1}^\\infty c_r^2K_r = \\sum_{r=1}^\\infty\\int_{t_1}^{t_2}[c_rg_r(t)]^2\\mathrm dt\n$$\n\nPhysical interpretation:\n\nThe energy (power) of a signal always equals to the sum of the energy (power) of all its components in a complete orthogonal function set. \n\nMathematical interpretation:\n\nThe norm of vector signals keeps invariant under orthogonal transform.\n\n### Correlation\n\nPhysical interpretation:\n\nGauge of the similarity of two signals \n\n**Energy and Power Signals**\n\nInstaneous Power $p(t) = i^2(t) R$\n\nThe energy consumed by $R$ in a period\n\n$$\nE = \\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$\n\nAverage Power:\n\n$$\nP = \\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = \\frac{1}{T_0}R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$\n\nThe energy signals and power signals:\n\n$$\nE = \\lim_{T_0 \\to \\infty}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\\\\\nP = \\lim_{T_0 \\to \\infty}\\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\n$$\n\n**Correlation Coefficient**\n\n$$\n\\rho_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\sqrt{\\int_{t_1}^{t_2}f_1^2(t)\\mathrm dt}\\sqrt{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt}} = \\frac{\\langle f_1, f_2\\rangle}{\\sqrt{\\langle f_1, f_1\\rangle}\\sqrt{\\langle f_2, f_2\\rangle}} = \\frac{\\langle f_1, f_2\\rangle}{\\|f_1\\|_2\\|f_2\\|_2} \n$$\n\nIf $f_1(t)$ is a linear function of $f_2(t)$, then $\\rho_{12} = \\pm1$, $\\overline{\\varepsilon^2} = 0$.\n\nIf $f_1(t)$ is orthogonal to $f_2(t)$, then $\\rho_{12} = 0$, $\\overline{\\varepsilon^2}$ is maximized.\n\n* Describe the correlation of two signals from the perspective of energy difference.\n* Quantitatively measure the correlation of two signals in terms of inner product. \n\n**Correlation Function**\n\nThe similarity between one signal with a delayed version of another signal.\n\n(1) $f_1(t)$ and $f_2(t)$ are both real and energy signals\n\n$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}(-\\tau)\n$$\n\n(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals\n\nIf $f_1(t) = f_2(t) = f(t)$\n\nAutocorrelation:\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f(t)\\mathrm dt\\\\\n$$\n\n(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals\n\n$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2^*(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1^*(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}^*(-\\tau)\n$$\n\nAutocorrelation:\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f^*(t)\\mathrm dt\\\\\nR(\\tau) = R^*(-\\tau)\n$$\n\n\n(3) $f_1(t)$ and $f_2(t)$ are both real and power signals\n\n$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\nAutocorrelation\n\n$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\n(4) $f_1(t)$ and $f_2(t)$ are both complex and power signals\n\n$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2^*(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\nAutocorrelation\n\n$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\n**Correlation Theorem**\n\n$$\n\\mathcal F(x(t)) = X(\\omega)\\\\\n\\mathcal F(y(t)) = Y(\\omega)\\\\\n\\mathcal F(R_{xy}(\\tau)) = X(\\omega)Y^*(\\omega)\\\\\n$$\n\nIf $x(t) = y(t)$, The FT of the autocorrelation function is $\\mathcal F[{R_{xx}(\\tau)}] = |X(\\omega)|^2$\n\nIf $y(t)$ is a real and even function: $Y^*(\\omega) = Y(\\omega)$\n\n Then the correlation theorem is equivalent to the convolution theorem\n\n$$\n\\mathcal F(\\int_{-\\infty}^\\infty x(t)y(t-\\tau)\\mathrm dt) = X(\\omega)Y(\\omega)\\\\\n$$\n\nGenerally, \n\n$$\nR_{12}(t) = f_1(t) * f_2(-t)\n$$\n\n### Energy & Power Spectral Density\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt\\\\\n$$\n\n$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2 e^{j\\omega\\tau}\\mathrm d\\omega\\\\\n|F(\\omega)|^2 = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\n$$\n$$\nR(0) = \\int_{-\\infty}^{\\infty}f(t)f^*(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt\\\\\nR(0) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\\\\\n$$\n\n$$\n\\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\n$$\n\n**Energy Spectral Density**\n\n$$\n\\mathcal{E}(\\omega) = \\lvert F(\\omega)\\rvert^2\\\\\n$$\n\n$$\n\\mathcal{E}(\\omega) = \\mathcal{F}[R(\\tau)]\\\\\nR(\\tau) = \\mathcal{F}^{-1}[\\mathcal{E}(\\omega)]\\\\\n$$\n\n**Power Spectral Density**\n\n$$\n\\mathcal F[ R(\\tau)] = \\mathcal P(\\omega)\\\\\n$$\n\nIt is called Power Spectral Density (PSD).\n\nWiener-Khinchin Theorem\n\n$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\mathcal P(\\omega)e^{j\\omega\\tau}\\mathrm d\\tau\\\\\n\\mathcal P(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\omega\\\\\n$$\n\n### ESD/PSD of the System Response\n\n$$\n|R(j\\omega)|^2 = |H(j\\omega)|^2|E(j\\omega)|^2\\\\\n\\mathcal{E}_r(\\omega) = |H(j\\omega)|^2\\mathcal{E}_e(\\omega)\\\\\n\\mathcal{P}_r(\\omega) = |H(j\\omega)|^2\\mathcal{P}_e(\\omega)\\\\\n$$\n\n![](../images/ss/lec16_1.jpg)\n\nThe last line of this table is wrong. The correct is:\n\n$$\nR_h(\\tau) = h(\\tau) * h^*(-\\tau)\n$$\n\n### Match Filters\n\n$$\nH(j\\omega) = kS(-j\\omega)e^{-j\\omega t_m}\\\\\nh(t) = ks(t_m - t)\\\\\n$$\n\n$t_m$ is the signal width in TD.\n\n## Discrete time signals\n\nDiscrete time-axis, but continuous amplitude-axis\n\n### Sequence operation\n\n**Addition** $z(n) = x(n) + y(n)$\n\n**Multiplication** $z(n) = x(n) * y(n)$\n\n**Multiplied a coefficient** $z(n) = a * x(n)$\n\n**Shift** $z(n) = x(n - m)$ right shift($m>0$), $z(n) = x(n +m)$ left shift\n\n**Reflection** $z(n) = x(-n)$\n\n**Difference** $\\Delta x(n) = x(n + 1) - x(n)$ Forawrd difference, \n\n$\\nabla x(n) = x(n) - x(n - 1)$ Backward difference\n\n$\\nabla^mx(n) = \\nabla(\\nabla^{m-1}x(n))$\n\n**Summation** $z(n) = \\sum_{k = -\\infty}^{n}x(k)$\n\n**Scaling** $z(n) = z(2n)$ squeeze, \n\n$z(n) = x(n/2)$, extend\n\n### Typical sequences\n\n![](../images/ss/lec16_2.jpg)\n\n![](../images/ss/lec16_3.jpg)\n\nRelations of several singal waveforms\n\n$$\nu(n) = \\sum_{k = 0}^{\\infty}\\delta(n - k)\\\\\n\\delta(n) = u(n) - u(n - 1)\\\\\nR_N(n) = u(n) - u(n - N)\\\\\n$$\n\n### Signal Decomposition\n\n$$\nx(n) = \\sum_{m = -\\infty}^{\\infty}x_m\\delta(n - m)\\\\\n$$\n\n$$\n\\delta(n - m) = \\begin{cases}\n1, & n = m\\\\\n0, & n \\neq m\n\\end{cases}\n$$\n\n### Difference equations\n\n![](../images/ss/lec16_4.jpg)\n\nNumerical solution of difference equations\n\nGeneral form of difference equation:\n\n$$\n\\sum_{k = 0}^N a_ky(n - k) = \\sum_{r = 0}^M b_ry(n - r)\\\\\n$$\n\n**Methods:**\n- Recursive method\n- - Intuitive, difficult to formulate the closed-form solutions\n- Time-domain classical method\n- - Obtain homogeneous and particular solutions and using the  boundary condition to determine the coefficients. \n- The sum of the zero-input and zero-state responses\n- - Convolution (next class) \n- Z-transform (Chapter 8)\n- State variable method (Chapter 11)\n\n**Homogeneous Solution**\n\n$$\n\\sum_{k = 0}^N a_ky(n - k) = 0\\\\\n$$\n\nThe **characteristic root** $\\alpha_k$ satisfies:\n\n$$\na_0\\alpha^N + a_1\\alpha^{N-1} + \\cdots + a_N = 0\\\\\n$$\n\nThe homogeneous solution is:\n\n$$\ny(n) = c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n\\\\\n$$\n\n**Particular Solutions**:\n\n![](../images/ss/lec16_.jpg)\n\n**General steps**\n\n1. Obtain homogeneous solutions from characteristic equation $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n$\n2. Determine the form of the particular solution $D(n)$\n3. The complete solution $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n + D(n)$\n4. Introduce the boundary condition and set up equations\n$$\ny(0) = C_1 +C_2 + \\cdots + C_N + D(0)\\\\\ny(1) = C_1\\alpha_1 +C_2\\alpha_2 + \\cdots + C_N\\alpha_N + D(1)\\\\\n\\vdots\\\\\ny(N - 1) = C_1\\alpha_1^{N - 1} + C_2\\alpha_2^{N - 1} + \\cdots + C_N\\alpha_N^{N - 1} + D(N - 1)\\\\\n\\Rightarrow\\\\\nY(k) - D(k) = VC\\\\\nC = V^{-1}(Y(k) - D(k))\\\\\n$$\n\n### Zero-input and zero-state responses\n\n$$\ny(k) = y_{zi}(k) + y_{zs}(k)\n$$\n\n**Zero-Input Response**\n$D(k) = 0 \\Rightarrow C_{zi} = V^{-1}Y_{zi}(k)$\n\n**Zero-State Response**\n\n$$\n\\begin{align*}\n  C_{zs} &= V^{-1}[Y_{zs}(k) - D(k)]\\\\\nC_{zs} &= V^{-1}[Y(k) - Y_{zi}(k) - D(k)]\\\\\nC &= C_{zi} + C_{zs}\\\\\n\\end{align*}\n$$\n\n**Natural Response** $\\sum_{k = 1}^NC_k\\alpha_k^n$\n\n**Forced Response** $D(n)$\n\nCharacteristics of the boundary condition for difference equations\n\nN-th order difference equation should have N independent boundary conditions.\n\nCompared with continuous systems, there are no big differences between $0_+$ and $0_-$ in discrete systems. \n\n$y(-1), y(-2), \\dots, y(-N)$ are the system memory (storage) before the excitation is added: $0_-$\n\nDerive (together with the excitation) $y(0), y(1), …, y(N-1): 0_+$\n\nUsing Z-transform can avoid mistakes－similar to the Laplace transform in continuous systems.\n\n### Impulse response of DT systems\n\nSimilar to CT System, h(n) reflects system’s property\n\n**Causality** $h(n) = h(n) u(n)$ (unlateral, $n\\lt 0$ no response)\n\n**Stability** $\\sum_{n=-\\infty}^\\infty |h(n)| \\lt \\infty$ (absolutely summable)\n\n     NOTE:  critical stability can be considered as either stable or unstable, e.g.,  system whose impulse response is a sine sequence\n\n\nNot all practical discrete systems are necessarily causal：\n\n* Variable is not time, like image processing\n* Variable is time, but data has been recorded and processed, like voice processing, meteorology, stock systems.\n\nExample: Smooth windowing\n\n$$\ny(n) = \\frac{1}{2M+1}\\sum_{k=-M}^M x(n-k)\n$$\n\nDiscrete non-causal system\n\n### Convolution Sum\n\n$$\ny(n) = \\sum_{m = -\\infty}^\\infty x(m)h(n - m) = h(n) * x(n)\n$$\n\nSimilar to CT system, also satisfies both distributive and associative laws \n\nCalculation of convolution：\nFour steps: reflection, shift, multiplication and summation. \n\nCalculation of correlation：\nCross- & auto-correlation: shift, multiplication & summation. \n\nExample:\n\n$$\nx(n) = u(n) - u(n - N)\\\\\nh(n) = a^nu(n)\\\\\ny(n) = x(n) * h(n)\n$$\n\n$$\ny(n) = \\sum_{m = -\\infty}^\\infty [u(m) - u(m - N)]a^{n - m}u(n - m)\n$$\n\nif $n < 0$, then $y(n) = 0$\n\nif $0 \\le n \\lt N - 1$, $y(n) = \\sum_{m = 0}^na^{n-m} = \\frac{1}{1 - a}[1 - a^{n+1}]$\n\nif $n \\ge N - 1$, $y(n) = \\frac{1 - a^{-N}}{1 - a^{-1}}a^n$\n\n**Deconvolution**\n\n**Signal retrieval** y(n) and h(n) are known, how to derive x(n)?\n\n*Measurement equipment (linear system), like sensor for measuring blood pressure*\n\n**System identification** y(n) and x(n) are known, how to derive h(n)?\n\n*Earthquake signal, like geological survey, oil exploration, etc.*\n\n$$\n\\begin{bmatrix*}\n   y(0)\\\\\n   y(1)\\\\\n   y(2)\\\\\n   \\vdots\\\\\n   y(n)\n\\end{bmatrix*} = \n\\begin{bmatrix*}\n  h(0) & 0 & 0 & \\dotsb & 0\\\\\n  h(1) & h(0) & 0 & \\dotsb & 0\\\\\n  h(2) & h(1) & h(0) & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  h(n) & h(n-1) & h(n-2) & \\dotsb & h(0)\\\\\n\\end{bmatrix*}\\begin{bmatrix*}\n   x(0)\\\\\n   x(1)\\\\\n   x(2)\\\\\n   \\vdots\\\\\n   x(n)\n\\end{bmatrix*}\n$$\n\nThus, \n\n$$\nx(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} x(m) h(n - m)\\right]/h(0)\\\\\nh(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} h(m) x(n - m)\\right]/x(0)\n$$\n\n### Important Concepts\n\n![](../images/ss/lec17_1.jpg)\n\n1. Symbol rate :  clock period is $T$, signal symbol rate is $f = 1/T$.\n2. Information rate: information rate equals to symbol rate for binary encoding, otherwise, equal to multiplication between symbol rate and number of information bits per symbol.\n3. Signal bandwidth: the first zero of non-return-to-zero (NRZ) signal’s spectrum is $1/T$,  so the signal bandwidth is $B=1/T =f$.\n\n> 这句话是在介绍非归零码（Non-Return-to-Zero，简称NRZ）信号的带宽计算方式。\n> \n> 在信号处理和通信中，信号的频谱表示了信号在不同频率上的能量分布。对于一个NRZ信号，它的频谱图中第一个零点（也就是在零周围出现的第一个极小值点）出现在频率为$1/T$处，其中$T$是NRZ信号中一个脉冲的时间长度。这是因为NRZ信号的频谱是由一个周期为$T$的方波产生的，其频率成分只包含正弦函数的奇次谐波。其中，最低的一个谐波频率是$f=\\frac{1}{T}$，对应的是频率为$f$的正弦波。所以，NRZ信号的带宽$B$就被定义为$f=1/T$。\n> \n> 简而言之，NRZ信号的带宽是由脉冲的时间长度决定的，具体来说，带宽等于脉冲频率的一半，即带宽等于$f=1/T$。\n\nNOTE:\n\nWhen NRZ code is used, signal bandwidth = symbol rate\n\nWhen return-to-zero (RZ) code is used, signal bandwidth > symbol rate\n\nUsing NRZ code can save bandwidth yet high frequency components of the rectangular signal will suffer from the severe inter-symbol interference (ISI). So the raised cosine or Sa function is preferred.\n> ChatGPT:\n> \n> 归零码和非归零码都是数字通信中常用的编码方式。\n> \n> 归零码（Return-to-Zero，简称RZ）是一种二进制码，其中一个信号所代表的位是由一个脉冲表示的。发送二进制“1”时，脉冲电平为高电平，发送二进制“0”时，脉冲电平为低电平。在归零码中，一个信号位所代表的脉冲之后，信号在下一时刻会回到零电平。由于归零码中每个脉冲结束时信号回到零电平，因此这种编码方式具有稳定可靠的特点，但是传输的带宽相对较大。\n> \n> 非归零码（Non-Return-to-Zero，简称NRZ）的编码方式与归零码不同之处在于，在NRZ信号中，一个信号所代表的位是由一个固定电平表示的。当信号所代表的位是二进制“1”时，固定电平为高电平；当信号所代表的位是二进制“0”时，固定电平为低电平。这种编码方式的好处是带宽更小，但是却存在着在多个二进制“1”连续发送时，出现误解的情况。\n> \n> 综上所述，归零码是二进制码中脉冲与幅度的双重编码，不易产生传输误码，但其对于通信带宽需求较大；而非归零码不需要对脉冲进行编码，在带宽方面具有一定的优势，但长时间连续发送相同信息时会产生误解。\n\n### Z-Transform\n\nSimilar to the L-Tranform.\n\n**Definition**\n\n$$\nX(z) = Z(x(n)) = \\sum_{n = -\\infty}^{\\infty} x(n) z^{-n}\n$$\n\n**Z-T of Typical Series**\n\n$z \\in \\Complex$\n\n$$\n\\delta(n) \\rightarrow 1\\\\\nu(n) \\rightarrow \\frac{1}{1-z^{-1}}(|z| \\gt 1)\\\\\nnu(n) \\rightarrow \\frac{z^{-1}}{(1-z^{-1})^2}(|z| \\gt 1)\\\\\na^n u(n) \\rightarrow \\frac{1}{1-az^{-1}}(|z| \\gt |a|)\\\\\n\\cos(\\omega_0 n) u(n) \\rightarrow \\frac{1-z^{-1}\\cos(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n\\sin(\\omega_0 n) u(n) \\rightarrow \\frac{z^{-1}\\sin(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n$$\n\n**The Region of Convergence**\n\n![](../images/ss/lec18_1.jpg)\n\n**Inverse Z-Transform**\n\n$$\nx(n) = \\frac{1}{2\\pi j} \\oint_C X(z) z^{n-1} dz\n$$\n\n**Method**\n\n**Contour Integration(residue method)**\n\nRight-sided sequence\n\n$$\nx(n) = \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$\n\nLeft-sided sequence\n\n$$\nx(n) = - \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$\n\n**Power series expansion(Long division)**\n\n![](../images/ss/lec18_2.jpg)\n\nIf it is right sided, \n\n$$\nX(z) = \\sum_{n = 0}^\\infty x(n)z^{-n}\n$$\n\nIf it is left sided,\n\n$$\nX(z) = \\sum_{n = -\\infty}^{-1}x(n)z^{-n}\n$$\n\n**Partial Fraction Expansion**\n\n$$\n\\frac{z}{z - a} \\lrarr \\begin{cases}\n a^nu(n), &|z|\\gt |a|\\\\\n -a^nu(-n-1), &|z|\\lt |a|\n\\end{cases}\n$$\n\n![](../images/ss/lec18_3.jpg)\n\n\n![](../images/ss/lec18_34jpg.jpg)\n\n![](../images/ss/lec18_6.jpg)\n\n**Properties of Z-T**\n\n**Linearity**\n\nAddition and homogeneity\n\n<font color=\"red\">ROC may change!</font>\n\ni.e. poles are cancelled when added: ROC will enlarge or and shrink.\n\n**Time shifting**\n\n(a) bilateral: If $\\mathcal Z[x(n)] = X(z), R_{X_1} < |z| < R_{X_2}$, then $\\mathcal{Z}[x(n-m)] = z^{-m}X(z), R_{X_1} < |z| < R_{X_2}$.\n\n(b) unilateral: if $\\mathcal{Z}[x(n)] = X(z), R_{X_1} < |z|$, then $\\mathcal{Z}[x(n-m)] = z^{-m}[X(z) + \\sum_{k = -m}^{-1}x(k)z^{-k}], R_{X_1}\\lt |z|$, and $\\mathcal{Z}[x(n+m)] = z^{m}[X(z) - \\sum_{k = 0}^{m-1}x(k)z^{-k}], R_{X_1}\\lt |z|$\n\nFor casual sequence, $n < 0, x(n) = 0$, the unilateral is also $\\mathcal{Z}[x(n-m)] = z^{-m}X(z)$.\n\nThe reason is that the unilateral z transform doesn't contain the $n<0$ parts of sequence, but after shifting, sometimes must be counted(right shift), sometimes must be discarded(left shift).\n\n**Linear weighting on sequence(Z domain differentiation)**\n\n$$\n\\mathcal{Z}[x(n)] = X(z) \\Rightarrow nx(n)\\lrarr -z\\frac{dX(z)}{dz}\n$$\n\nGeneralization:\n\n$$\nn^mx(n)\\lrarr \\bigg[-z\\frac{d}{dz}\\bigg]^m X(z)\n$$\n\n**Geometric progression(Z-domain scaling)**\n\n$$\na^n(x^n) \\lrarr X(\\frac{z}{a})\\\\\n(R_{x1} \\lt \\bigg|\\frac{z}{a}\\bigg| \\le R_{x2})\n$$\n\n$$\na^{-n}x(n) \\lrarr X(az)\\\\\n(-1)^nx(n) \\lrarr X(-z)\n$$\n\n**Initial-value theorem**\n\n$$\nx(0) = \\lim_{z \\rightarrow \\infty }X(z)\n$$\n\n**Final-value theorem**\n\n$$\n\\lim_{n \\rightarrow \\infty } x(n) = \\lim_{z \\rightarrow 1}[(z-1)X(z)]\n$$\n\ncondition: when $n \\rightarrow \\infty$, $x(n)$ converge \n\nThus, the poles of $X(z)$ are inside the unit circle, the radius of ROC is less than 1.\n\nFor $a^nu(n), |a| \\lt 1$, the final value is 0.\n\nOr, if the pole is on the unit circle, it should be 1, and is of the 1st order.\n\n$u(n)$'s final value is 1.\n\n![](../images/ss/lec19_1jpg.jpg)\n\n**Time-domain convolution theorem**\n\nIf $\\mathcal{Z}{x(n)} = X(z), (R_{x1} \\lt |z| \\lt R_{x2}), \\mathcal{Z}{h(n)} = H(z), (R_{h1} \\lt |z| \\lt R_{h2})$\n\n$$\n\\mathcal{Z}[x(n) * h(n)] = X(z)H(z)\\\\\n\\max(R_{x1}, R_{h1}) \\lt |z| \\lt \\min(R_{x2}, R_{h2})\n$$\n\nIf poles are cancelled in multiplication, ROC is enlarged.\n\nConclusion: (Z Transform) convolution in time-domain is equivalent to multiplication (of Z Transform) in Z-domain.\n\n**Z domain convolution theorem**\n\n$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(\\frac{z}{v})H(v)v^{-1}dv\n$$\n\nor \n\n$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(v)H(\\frac{z}{v})v^{-1}dv\n$$\n\nwhere $C$ is a closed contour in the intersection of ROCs of $X(\\frac{z}{v})$ and $H(v)$ or $X(v)$ and $H(\\frac z v)$.\n\nlet $v = \\rho e^{j\\theta}, z = r e^{j\\varphi}$, \n\nthen \n\n$$\n\\mathcal Z[x(n)h(n)] = \\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(\\rho e^{j\\theta})H(\\frac r\\rho e^{-j(\\varphi - \\theta)})d\\theta\n$$\n\n### Mapping of ZT and LT\n\n$$\nz = e^{sT} ,\\omega_s = \\frac{2\\pi}{T}\n\\\\\nre^{j\\theta} = e^{(\\sigma + j\\omega)T}\\\\\n$$\n\nthen, \n\n$$\nr = e^{\\sigma T} = e^{2\\pi\\frac{\\sigma}{\\omega_s}}\\\\\n\\theta = \\omega T = 2\\pi\\frac{\\omega}{\\omega_s}\n$$\n\nwhen $\\sigma$ is constant, \n\nvertical line in $s$-plane maps the circle in $z$-plane.\n\n$s$-plane imaginary axis maps the unit circle in $z$-plane.\n\nwhen $\\omega$ is constant,\n\n![](../images/ss/lec19_2jpg.jpg)\n\n**Correspondence of ZT and LT**\n\n![](../images/ss/lec19_3.jpg)\n\n### Solving difference equation by Z-T\n\n$$\n\\sum_{k = 0}^N a_ky(n-k) = \\sum_{r = 0}^M b_rx(n-r)\n$$\n\nTwo methods:\n\n* TD method\n* Z-T method (notice the ROC)\n\n**ZT method**\n\n1. perform unilateral Z-T on both sides.\n\n$x(n-r), y(n-k)$ are both right shifted series\n\n$$\n\\sum_{k = 0}^N a_kz^{-k}[Y(z) + \\sum_{l = -k}^{-1}y(l)z^{-l} ]= \\sum_{r = 0}^M b_rz^{-r}[X(z) + \\sum_{m = -r}^{-1}x(m)z^{-m} ]\n$$\n\n2. Derive $Y(z)$\n3. Perform inverse transform on $Y(z)$ to get $y(n)$(ROC!)\n\n**Zero input response**\n\n$$\nx(n) = 0\\\\\nY(z) = \\frac{-\\sum_{k = 0}^M[a_kz^{-k}\\cdot \\sum_{l = -k}^{-1}y(l)z^{-l}]}{\\sum_{k = 0}^Na_kz^{-k}}\n$$\n\n**Zero state response**\n\n$$\ny(l) = 0\\\\\n\\text{ casual sequence }: x(m) = 0\\\\\n\\sum_{k = 0}a_kz^{-k}Y(z) = \\sum_{r = 0}^M b_rz^{-r}X(z)\\\\\nY(z) = X(z)\\cdot\\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}} = X(z)\\cdot H(z)\n$$\n\n### System function of DT system\n\n**Unit Impulse/sample response $h(n)$ and system function H(z)**\n\n$$\ny(n) = x(n) * h(n)\\\\\nY(z) = H(z)\\cdot X(z)\n$$\n\n$$\nH(z) = \\frac{Y(z)}{X(z)} = \\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}}\n$$\n\nFactorization\n\n$$\nH(z) = \\frac{\\prod_{r = 1}^M(1-z_rz^{-1})}{\\prod_{k=1}^N1-p_kz^{-1}}\n$$\n\nWe can draw the conclusions directly from the relationship between Z-T and L-T\n\n||||||\n|----|----|----|----|----|\n| Imaginary axis | $\\sigma=0$ | Constant amplitude | $r = 1$ | Unit circle |\nRight half plane |  | | | \nLeft half plane\nReal axis\n\n![](../images/ss/lec20_1.jpg)\n\n![](../images/ss/lec20_2.jpg)\n\n**Stability and Causality**\n\nStable: iff\n\n$$\n\\sum_{n=-\\infty}^\\infty |h(n)|\\lt \\infty\n$$\n\n$$\nz = 1, H(z) = \\sum_{n=-\\infty}^\\infty h(n)\\lt \\infty\n$$\n\nThe condition is ROC of stable system includes the unit circle.\n\nCausal:\n\n$$\nh(n) = h(n)u(n)\n$$\n\nCondition is ROC includes $\\infty$: $R_{X_1}\\lt |z|$\n\n**Stable and causal**\n\n$$\na\\le |z| \\le \\infty, a\\le 1\n$$\n\n### Discrete-time Fourier Transform(DTFT)\n\n**Definition**\n\n$$\n\\mathcal{F}[x(t)\\delta_T(t)] = \\int_{-\\infty}^\\infty x(t)\\delta_T(t)e^{-j\\omega t}dt = \\sum_{n=-\\infty}^\\infty x(nT)e^{-j\\omega nT}\n$$\n\ntake $T = 1$\n\n$$\n\\sum_{n=-\\infty}^\\infty x(n)e^{-j\\omega n} = \\text{DTFT[x(n)]}\n$$\n\nThe relation ship with Z-T:\n\n$$\nX(z) = \\sum_{n = -\\infty}^\\infty x(n)z^{-n}, z = e^{j\\omega}\\\\\n$$\n\n$$\nDTFT[x(n)] = X(z)|_{|z|=1} = X(z)|_{z = e^{j\\omega}} = X(e^{j\\omega})\n$$\n\nInverse transform\n\n$$\nx(n) = \\frac{1}{2\\pi j}\\oint_{|z| = 1}X(z)z^{n-1}\\mathrm dz=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$\n\n### Frequency Response of DT system\n\nThe steady-state response to sine sequence\n\n$$\nx(n) = A\\sin(n\\omega)(n\\ge 0)\\\\\ny_{ss}(n) = A|H(e^{j\\omega})|\\sin(n\\omega + \\varphi)\\\\\nH(e^{j\\omega}) = \\sum_{n=-\\infty}^\\infty h(n)e^{-jn\\omega}\n$$\n\nThe FT of $h(n)$, $H(e^{j\\omega})$ is a periodic function with period of $\\omega_s = 2\\pi /T = 2\\pi$.\n\nIf $h(n)$ is real, then the amplitude/phase response is even/odd function.\n\nThe amplitude is determined within $[0, \\omega_s/2]$\n\n![](../images/ss/lec20_3.jpg)\n\n![](../images/ss/lec20_4.jpg)\n\nNOTE:\n\n* We can derive the frequency response (function of $\\omega$) by letting $D$ move along the unit circle once.\n* $H(j\\omega)$ is periodic. The frequency response from 0 to $\\omega_s/2$ can be determined by letting $D$ move along half circle.\n* If pole $p_i$ is close to the unit circle, there will be a peak in the frequency response. If zero $z_i$ is close to the unit circle, there will be a notch in the frequency response.\n* For statble systems, $p_i$ should be inside the unit circle, while $z_i$ could be inside or outside the unit circle.\n* poles and zeros at origin have no influence on amplitude.\n\n### Analog and digital Filter\n\n**Fundamental Principles**\n\n![](../images/ss/lec20_5.jpg)\n\nThe spectrum of $x(t)$ is strictly inside $\\pm \\omega_m$.\n\nWe choose the sampling frequency:$\\omega_s = \\frac{2\\pi}{T} \\ge 2\\omega_m$\n\n![](../images/ss/lec20_6.jpg)\n\n**Classifications of digital filters**\n\n$$\ny(n) = \\sum_{k=0}^M b_kx(n-k) - \\sum_{k=1}^N a_ky(n-k)\n$$\n\nIn terms of structure\n\nrecursive: $a_k\\ne 0$ at least for one $k$\n\nnon-recursive: $a_k=0$, for all $k$\n\nIn terms of the characteristics of $h(n)$\n\nInfinite impulse response(IIR): recursive, non-linear phase\n\nFinite impulse response(FIR): non-recursive, linear phase.\n\n**IIR filter**\n\nImpulse invariance\n\nBased on the s-domain analog filters.\n\nDesign method 1: **冲激响应不变法**\n\nReplace $\\frac{1}{s-s_k}$ with $\\frac{1}{1-e^{s_kT}z^{-1}}$. Then $H_a(s)$ become $H(z)$.\n\nThe relationship between the continuous and discrete filters:\n\n$$\nH(z)|_{z = e^{sT}} = \\frac{1}{T}\\sum_{k=-\\infty}^\\infty H_a(s + j\\frac{2\\pi}{T}k)\n$$\n\nThe result is just repeat the original filter at sampling frequency, thus it attenuates slower.\n\nNOTE:The digital filter implemented this way has aliasing.\n\nThe frequency response of analog filter must be attenuated enough within $\\omega_s$.\n\nThis approach can only realize LP and BP filter, but not HP and band-stop one. \n\n**method 2: Bilinear transformation** emerges to address this problem (you can study it by yourself)\n\n$$\ns = \\frac{2}{T}\\left(\\frac{1 - z^{-1}}{1 + z^{-1}}\\right)\\\\\nz = \\frac{1 + \\frac{sT}{2}}{1 - \\frac{sT}{2}}\n$$\n\nBilinear transformation is non-linear transformation.\n\nTo implement digital filter, A/D and D/A are required, along with ROM, RAM, ALU, delay units (shift registers), etc.\n\n\n**FIR filter**\n\n$$\nH(z) = \\sum_{k = 0}^{N-1}b_kz^{-k} = \\sum_{n=0}^{N-1}h(n)z^{-n}\n$$\n\nPoles are at $z=0$. $N - 1$ zeros.\n\nFIR filter has linear-phase iff\n\n$$\nh(n) = h(N - 1 - n)(\\text{evenly symmetric})\\\\\nh(n) = -h(N - 1 - n)(\\text{oddly symmetric})\n$$\n\n![](../images/ss/lec20_7.jpg)\n\n![](../images/ss/lec20_8.jpg)\n\n### Feedback System: Signal Flow Graphs\n\n**Operator and Transfer Operator:**\n\n$$\np = \\frac{d}{dt}\\\\\n\\frac{1}{p} = \\int_{-\\infty}^t(\\cdot)d\\tau\n$$\n\n$$\n(C_0p^n + C_1p^{n-1} + \\dotsb + C_n)r(t) = (E_0p^m + E_1p^{m - 1} + \\dotsb + E_m)e(t)\\\\\nD(p)r(t) = N(p)e(t)\n$$\n\nRules:\n\n* Common factors can't be eliminated.\n* Be careful when changing the order of operation($\\frac{d}{dt}\\int_{-\\infty}^tx(\\tau)d\\tau = x(t)$, $\\int_{-\\infty}^t\\frac{d}{d\\tau}x(\\tau)d\\tau = x(t) - x(-\\infty)$)\n\ntransfer operator:\n\n$$\nr(t) = \\frac{N(t)}{D(t)}e(t) = H(p)e(t)\n$$\n\n**Brief introduction to the signal flow graphs(SFG)**\n\n![](../images/digital/lec_11_1.jpg)\n\n![](../images/ss/lec21_4.jpg)\n\nTerminnologies in SFG\n\nNode, Transfer function, Branch(The branch gain is the transfer function), Source node, Sink node, Mixed node.\n\n**Properties of SFG**\n\n1. Signal only passes through a branch with the direction indicated by the arrowhead.\n2. Signals of incoming branches are added at a node, and the added signal appears on the all outgoing branches.\n3. A sink node can be separated from a mixed node.\n4. For a given system, the SFGs can be different.(equations for a system can be different)\n5. After the SFG being inversed, the transfer function keeps invariant, but the signals represented by the inner nodes will be different.\n\n\nNote: Inversion is done by inversing the transfer direction of each branch, and exchanging the source and sink nodes as well.\n\nAlgebra of SFG\n\n![](../images/ss/lec21_5.jpg)\n\n![](../images/ss/lec21_6.jpg)\n\nSimplify:\n\nNOTE: The SFG can be simplified using the following steps:\n\na. Merge the cascaded branches to decrease the number of nodes;\n\nb. Merge the parallel branches to decrease the number of branches;\n\nc. Eliminate all the loops. \n\nThen, the system function can be readily derived.\n\n![](../images/ss/lec21_7.jpg)\n\n**Mason's Formula**\n\n$$\nH = \\frac{1}{\\Delta} \\sum_k g_k\\Delta_k\n$$\n![](../images/ss/lec21_9.jpg)\n\n## State-variable analysis of system\n\n$$\n\\mathbf {\\lambda = A\\lambda + Be}\\\\\n\\mathbf{r = C\\lambda + De}\n$$\n\nFeatures of the state-variable analytical method \n\n* (1)Provide internal characteristics of the system\n* (2) Convenient to represent and analyze the multi-input, multi-output (MIMO) cases\n* (3) Easy to be extended to time-variant or nonlinear cases\n* (4) Introduce two important concepts: controllability and observability\n* (5) Convenient for numerical computation\n\n### General form and setup method (CT)\n\n$$\n\\frac{d}{dt}\\mathbf{\\lambda}(t)_{k \\times 1} = \\mathbf{A}_{k \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{B}_{k \\times m}\\mathbf{e}(t)_{m \\times 1}\\\\\n\\mathbf{r}(t)_{r \\times 1} = \\mathbf{C}_{r \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{D}_{r \\times m}\\mathbf{e}(t)_{m \\times 1}\n$$\n\n$r$ responses, $k$ state variables, $m$ inputs.\n\nFor time-variant system, $\\mathbf{A, B, C, D}$ are fuction of $t$.\n\nDirect methods:\n* observation\n* Topological analysis\n\nUsed in curcuit analysis.\n\nIndirect methods:\n* From block diagram or flow graph\n* From input-output equation\n* From transfer function\n\nUsed in controlled system analysis.\n\n**From input-output equation**\n\n$$\n\\frac{r(t)}{e(t)} = \\frac{b_0p^k + \\dotsb + b_k}{p^k + \\dotsb + a_k}\n$$\n\nNOTE : under the zero-state condition, $p$ is equivalent to $s$ \n\n$$\nH(p) = \\frac{b_0 + b_1p^{-1} + \\dotsb + b_kp^{-k}}{1 + a_1p^{-1} + \\dotsb + a_kp^{-k}}\n$$\n\nThe SFG is:\n\n![](../images/ss/lec22_11.jpg)\n\n$$\n\\dot{\\lambda}_1 = \\lambda_2\\\\\n\\dot{\\lambda}_2 = \\lambda_3\\\\\n\\vdots\\\\\n\\dot{\\lambda}_k = -a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t)\\\\\nr(t) = b_k\\lambda_1 + b_{k-1}\\lambda_2 + \\dotsb + b_1\\lambda_k + b_0(-a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t))\\\\\n=(b_k - a_kb_0)\\lambda_1 + (b_{k-1} - a_{k-1}b_0)\\lambda_2 + \\dotsb + (b_1 - a_1b_0)\\lambda_k + b_0e(t)\n$$\n\n$$\n\\mathbf A = \\begin{bmatrix}\n  0 & 1 & 0 & \\dotsb & 0\\\\\n  0 & 0 & 1 & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  0 & 0 & 0 & \\dotsb & 1\\\\\n  -a_k & -a_{k-1} & -a_{k-2} & \\dotsb & -a_1\n\\end{bmatrix}\\\\\nB = \\begin{bmatrix}\n  0\\\\\n  0\\\\\n  \\vdots\\\\\n  0\\\\\n  1\n\\end{bmatrix}\\\\\n\\mathbf C = \\begin{bmatrix}\n  b_k - a_kb_0 & b_{k-1} - a_{k-1}b_0 & \\dotsb & b_1 - a_1b_0\n\\end{bmatrix}\\\\\nD = b_0\n$$\n\nIf  the order of differential equation on the left side is higher than that on the right side:\n\n$$\nb_0 = 0, \\mathbf{D} = 0\n$$\n\nIf the derivatives of the excitation on the right side are absent,\n\n$$\n\\mathbf{C} = [b_k, 0, \\dotsb, 0], \\mathbf{D} = 0\n$$\n\n**Factorizing Transfer operator**\n\n![](../images/ss/lec22_12.jpg)\n\n![](../images/ss/lec22_13.jpg)\n\n![](../images/ss/lec22_14.jpg)\n\n![](../images/ss/lec22_15.jpg)\n\n![](../images/ss/lec22_16.jpg)\n\n![](../images/ss/lec22_17.jpg)\n\n![](../images/ss/lec22_18.jpg)\n\n### Solving CT system's state equations\n\n**Time domain method** using computer.\n\n**Transform-domain(Laplace-tranform) method**\n\n$$\n\\frac{d}{dt}\\mathbf{}{\\lambda}(t) = \\mathbf{A\\lambda}(t) + \\mathbf{Be}(t)\\\\\n\\mathbf{r}(t) = \\mathbf{C\\lambda}(t) + \\mathbf{De}(t)\\\\\n\\mathbf{\\lambda}(0_-) = \\begin{bmatrix}\n\\lambda_1(0_-)\\\\\n\\lambda_2(0_-)\\\\\n\\vdots\\\\\n\\lambda_k(0_-)\\\\\n\\end{bmatrix}\n$$\n\n$$\ns\\mathbf \\Lambda(s) - \\mathbf{\\lambda}(0_-) = \\mathbf{A\\Lambda}(s) + \\mathbf{BE}(s)\\\\\n\\mathbf{R}(s) = \\mathbf{C\\Lambda}(s) + \\mathbf{DE}(s)\n$$\n\n$$\n\\mathbf{\\Lambda}(s) = (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{BE}(s)\\\\\n\\mathbf R(s) =\\mathbf{C} (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (\\mathbf C(s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{B + D)E}(s) \n$$\n\nLet $\\Psi(s) = (s\\mathbf I - \\mathbf A)^{-1}$, which is called **characteristic matrix**.\n\n$$\n\\mathbf\\lambda(t) = \\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\mathcal{L}^{-1}[\\Psi(s)\\mathbf{B}] * e(t)\\\\\n\\mathbf r(t) = \\mathbf{C}\\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\lbrace\\mathbf{C}\\mathcal{L}^{-1}[\\mathbf\\Psi(s)\\mathbf{B] + D}\\delta(t)\\rbrace * e(t)\n$$\n\n**Time-domain method**\n\n$$\ne^{\\mathbf At} = \\sum_{k = 0}^\\infty \\frac{1}{k!}A^kt^k\n$$\n\nproperties\n\n$$\ne^{\\mathbf At}e^{-\\mathbf At} = \\mathbf I\\\\\ne^{\\mathbf At} = [e^{-\\mathbf At}]^{-1}\\\\\n\\frac{d}{dt}e^{\\mathbf At} = \\mathbf Ae^{\\mathbf At} = e^{\\mathbf At} \\mathbf A\\\\\n$$\n\n$$\n\\frac{d}{dt}\\mathbf \\lambda(t) = \\mathbf A\\mathbf \\lambda(t) + \\mathbf B\\mathbf e(t)\\\\\ne^{-\\mathbf At}\\frac{d}{dt}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf A\\mathbf \\lambda(t) + e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\frac{d}{dt}e^{-\\mathbf At}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\lambda(t) = e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\int_0^te^{\\mathbf A(t - \\tau)}\\mathbf B\\mathbf e(\\tau)d\\tau\\\\\n=e^{\\mathbf At}\\lambda(0_-) + e^{\\mathbf At} \\mathbf B * \\mathbf e(t)\n$$\n\noutput\n\n$$\n\\mathbf r(t) = \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\mathbf C e^{\\mathbf At} \\mathbf B * \\mathbf e(t) + \\mathbf D\\mathbf e(t)\\\\\n= \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + [\\mathbf C e^{\\mathbf At} \\mathbf B + \\mathbf D\\delta(t)] * \\mathbf e(t)\n$$\n\nCorrespond to LT:\n\n$$\n\\mathcal{L}[e^{\\mathbf At}] = (s\\mathbf I - \\mathbf A)^{-1}\n$$\n\n**Derive System Functions**\n\n![](../images/ss/lec22_19.jpg)\n\n![](../images/ss/lec22_20.jpg)\n\n### That for DT system\n\n**State equation setup**\n\n$$\n\\begin{align*}\n  \\mathrm\\lambda(n + 1) &= \\mathbf A\\mathrm\\lambda(n) + \\mathbf B\\mathrm x(n)\\\\\n  \\mathrm y(n) &= \\mathbf C\\mathrm\\lambda(n) + \\mathbf D\\mathrm x(n)\n\\end{align*}\n$$\n\nSolving:\n\n$$\n\\lambda(n) = \\underbrace{A^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}A^{n-1-i}Bx(i)\\right]u(n-1)}_{\\text{Zero State}}\\\\\ny(n) = \\underbrace{CA^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}CA^{n-1-i}Bx(i)\\right]u(n-1) + Dx(n)u(n)}_{\\text{Zero State}}\n$$\n\nThe Impulse response is:\n\n$$\nh(n) = CA^{n-1}Bu(n-1) + D\\delta(n)\n$$\n\nCalculate $A^n$: Cayley-Hamilton Theorem\n\n**ZT Solution**\n\n$$\n\\begin{align*}\n  z\\mathrm\\Lambda(z) - z\\lambda(0) &= \\mathbf A\\mathrm\\Lambda(z) + \\mathbf B\\mathrm X(z)\\\\\n  \\mathrm Y(z) &= \\mathbf C\\mathrm\\Lambda(z) + \\mathbf D\\mathrm X(z)\n\\end{align*}\n$$\n\n$$\n\\mathrm \\Lambda(z) = (z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + (z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\mathrm X(z)\\\\\n\\mathrm Y(z) = \\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + \\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right]\\mathrm X(z)\n$$\n\nthen \n\n$$\n\\lambda(n) = \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\\\\\ny(n) = \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\n$$\n\nComparing this with CT solution, we find\n\n$$\nA^n = \\mathcal{Z}^{-1}\\left[(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\right]\\\\\n$$\n\n$$\nH(z) = C(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\mathbf B + D\n$$\n\n### Linear Transform on state vectors\n\n$$\n\\mathbf{\\gamma} = \\mathbf P\\mathbf \\lambda\n$$\n\nThe equations become:\n\n$$\n\\frac{d}{dt}\\gamma(t) =\\mathbf{PAP}^{-1}\\mathbf \\gamma(t) + \\mathbf{PB}e(t)\\\\\n\\mathbf y(t) = \\mathbf {CP}^{-1}\\gamma(t) + \\mathbf D\\mathbf e(t)\n$$\n\nSimilarity transform doesn't change the eigenvalues.\n\n**Transform function matrix keeps invariant under linear transformation.**\n\nWe can **diagonalize** the matrix A.\n\nCalculate eigenvalues $\\alpha$ -> calulate eigenvectors $\\xi$ -> $\\mathbf P^{-1} = [\\xi_i]$, $\\hat A = \\text{diag}(\\alpha_i)$\n\n### Controllable & Observable\n\nControllable is \n\n$$\n\\text{rank} [A\\ AB\\ \\dots\\ A^{k-1}B] \\text{ is full}\n$$\n\nUncontrollabilty is the input can't change the response.\n\nObeservability is \n\n$$\n\\text{rank} \\begin{bmatrix}\n  C\\\\\n  CA\\\\\n  \\vdots\\\\\n  CA^{k-1}\n  \\end{bmatrix}\n  \\text{ is full}\n$$\n\nUnobserverbility is the response is not affected by the input.\n\nAfter the diagonalization of A: \n\nB doesnt contain zero $\\Leftrightarrow$ completely controllable. Otherwise, the 0s is coresponding to the uncontrollable state variables.\n\nC doesnt contain zero $\\Leftrightarrow$ completely observable. Otherwise, the 0s is coresponding to the unobservable state variables.\n\nIn fact:\n\n$$\nH(s) = C(s\\mathbf I - \\mathbf A)^{-1}\\mathbf B + D \\stackrel{D = 0}{=} \\sum_{i=1}^n \\frac{C_iB_i}{s - \\alpha_i}\n$$\n\nThe $H(s)$ only contains the controllable and observable state variables. So the state and output equations contains more information than the $H(s)$.\n\n![](../images/ss/lec23_1.jpg)\n\n## CDMA\n\nUse a set of orthogonal codes to support multiple users by orthorgonal multiplexing.\n\n### Example\n\nAssume K users need to connect with the base station simultaneously for CDMA system.\n\n1. Design a set of orthogonal codes\n2. Design on the transmitter\n3. Design on the receiver\n\nAn example of Code 4:\n\n$$\n\\begin{align*}\n  \\mathbf c_1 &= [1\\ 1\\ 1\\ 1\\ -1\\ -1\\ -1\\ -1]\\\\\n  \\mathbf c_2 &= [1\\ 1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1]\\\\\n  \\mathbf c_3 &= [1\\ -1\\ 1\\ -1\\ 1\\ -1\\ 1\\ -1]\\\\\n  \\mathbf c_4 &= [1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1\\ 1]\n\\end{align*}\n$$\n\n$$\nR_{x, y}(j) = \\begin{cases}\n  \\sum_{k = 0}^{N - 1 - j} x(k)y(k + j), &0 \\le j \\le N - 1\\\\\n  \\sum_{k = 0}^{N - 1 + j} x(k - j)y(k), &-N + 1 \\le j \\le 0\\\\\n  0, & |j| \\ge N\n\\end{cases}\n$$\n\nMust satisfy:\n\n$$\nR_{k, i}  \\begin{cases}\n  =T, &k = i, \\tau=0\\\\\n  \\ll T, &k \\ne i \\text{ or } \\tau \\ne 0\n  \\end{cases}\n$$\n\nsecond:\n\n(1) frequency shifting: $d_k(t)\\cos(\\omega t)$\n\n(2) spreading: $s_k(t) = d_k(t)c_k(t)\\cos(\\omega t)$\n\nthird: coherent detection/de-spreading\n\nCore:\n\n* Orthogonal code design(signal design)\n* Code capturing and tracking(signal processing and system design)\n* Multi-use  detection and channel estimation(singal processing and system design)\n\n### Code design\n\nrequirements:\n\n* sharp auto-correlation curve\n* zero cross-correlation\n* largest possible orthogonal code set\n* highest possible complexity for security performance\n\nCommonly used codes:\n\n* Walsh code\n* PN sequence\n* GOLD codes\n\n$$\nH_1 = (0)\\\\\nH_2 = \\begin{pmatrix}\n  H_1 & H_1\\\\\n  H_1 & \\overline{H_1}\n\\end{pmatrix} = \\begin{pmatrix}\n  0 & 0\\\\\n  0 & 1\n\\end{pmatrix}\\\\\nH_4 = \\begin{pmatrix}\n  H_2 & H_2\\\\\n  H_2 & \\overline{H_2}\n  \\end{pmatrix}\n$$\n\n* sliding window capturing\n* multiple correlators to detect phase match\n\nThe period of address code is much shorter than the period of data code: $T_c < T_d$, so the modulated signal is much wider in FD, whose spectrum is called **spread spectrum**.","source":"_posts/Signal-and-Systems.md","raw":"---\ntitle: Signals and Systems\ndate: 2023-02-22 09:46:36\ntags: note\nkatex: true\n---\n\nMarch 15\n## Basic\n### Classification\nDeterministic & random\n\nPeriodic/non-periodic\n\nContinuous/Discrete(time)\n\nAnalog/Digital(Amplitude & time)\n\n### Operations\n\nShifting\n\nReflection\n\nScaling\n\nDiffrential\n\nIntegral\n\nAddition\n\nMultiplication\n\nConvolution\n\n$$\nf_1(t) * f_2(t) = \\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$\n\n### Singularity Signals\n\n#### Unit ramp function\n$$\nR(t) = 0, t\\lt 0; t, t>0\n$$\n\n#### Unit step function\n$$\nu(t) = 0, t<0;1/2, t=0;1, t>0\n$$\n\n#### Rectangular pulse\n$$\nu(t) - u(t-t_0)\n$$\n\n#### Sign function\n$$\nsgn(t) = 1, t>0;-1, t<0\n$$\ndefine $sgn(0)=0$, then $sgn(t)=2u(t)-1$\n\n#### Unit impulse function\nDirac definition\n$$\n\\int_{-\\infty}^{\\infty}\\delta(t)\\mathrm dt=1\\\\\n\\delta(t)=0(t\\ne 0)\n$$\n$$\n\\delta(t)=\\lim_{\\tau \\rightarrow0}\\left[U(t+\\frac\\tau2)-U(t-\\frac \\tau 2)\\right]\n$$\n\n$$\n\\int_{-\\infty}^{\\infty}\\delta(t)f(t)=f(0)\\\\\n\\int_{-\\infty}^{\\infty}\\delta(t - t_0)f(t)=f(t_0)\\\\\n\\delta(t)=\\delta(-t)\\\\\n\\frac{d}{dt}u(t)=\\delta(t)\n$$\n\n#### Impulse doublet function\n\n$\\delta^\\prime(t)$\nDouble impulses at t=0 which are mirror-imaged with their amplitude of infinite. \n\n$$\n\\int^{\\infty}_{-\\infty}\\delta^\\prime(t)\\mathrm dt=0\\\\\n\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t)\\mathrm dt=-f^{\\prime}(0)\\\\\n\\text{shifted:}\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t-t_0)\\mathrm dt=-f^{\\prime}(t_0)\\\\\n$$\n![](../images/ss/lec2_.jpg)\n\n### Signal Decomposition\n\n$$\nf(t) = f_D+f_A(t)\\\\\nf(t)=f_e(t)+f_o(t)\\\\\nf(t)=f_r(t)+jf_i(t)\\\\\nf_r(t)=\\frac{1}{2}\\left[f(t)+f^*(t)\\right]\\\\\nf_i(t)=\\frac{1}{2}\\left[f(t)-f^*(t)\\right]\n$$\n\n#### Pulse Component\n\n$$\nf(t)=\\int_{-\\infty}^{\\infty}f(t_1)\\delta(t-t_1)\\mathrm dt_1\n$$\n\nWe also have orthogonal function decomposition(Chap.3, Chap.6).\n\n### System modeling and Classification\n\nSystem model can be represented by math equation(including input-output description and state variables or state equation) graphic symbol and block diagrams.\n\nWe use the input-output description mostly. If controling something internal is needed, state euqtion is useful.\n\nBlock diagram: \n\n![](../images/ss/lec2_2.jpg)\n![](../images/ss/lec2_3.jpg)\n\n### System classification\n\n#### Linear or Non-linear\n\n$$\ne_1(t)\\rightarrow r_1(t),\ne_2(t)\\rightarrow r_2(t)\\Rightarrow\\\\\na_1e_1(t)+a_2e_2(t)\\rightarrow a_1r_1(t)+a_2r_2(t)\n$$\n\n#### Time-variant or Time-invariant\n\n#### Memory or Memoryless\n\nwith memory: dynamic system, differential equation\n\nwithout memory: instant system, algebraic equation\n\n#### Continuous or Discrete\n\nContinuous  Differential equation\n\nDiscrete  Difference equation\n\n#### Lumped- or Distributed-Parameter\n\nLumped: constant coefficient differential equation\n\nDistributed: partial equation\n\n#### Causal or Non-Causal\n\nwhen $t<0, e(t)=0 \\Rightarrow t<0, r(t)=0$ Generic definition?\n\nthe future state cannot have effect on now state. The state of causal system can only be determined by now and past states.\n\n#### Reversible or irreversible\n\ndifferent input to different output, otherwise irreversible.\n\n### LTI System\n\n#### Linearity\n\nLinearity leads to superposition and homogeneity.\n\n#### Time-Invariant\n\na time shift in the input results in a same time shift in the output.\n\n$$\ne(t)\\rightarrow r(t)\\Rightarrow e(t-t_0)\\rightarrow r(t-t_0)\\\\\n\\lim_{\\Delta t\\rightarrow 0}\\frac{e(t)-e(t-\\Delta t)}{\\Delta t}\\rightarrow \\lim_{\\Delta t\\rightarrow 0}\\frac{r(t)-r(t-\\Delta t)}{\\Delta t}\\\\\n\\frac{\\mathrm de(t)}{dt}\\rightarrow \\frac{\\mathrm dr(t)}{dt}\n$$\n\nIf every coefficient is time independent, the system is time invariant.\n\n## Time-Domain(TD) Analysis\n\n$$\nC_0\\frac{d^nr(t)}{dt^n}+C_1\\frac{d^{n-1}r(t)}{dt^{n-1}} + ... + C_nr(t)\\\\\n=E_0\\frac{d^me(t)}{dt^m}+E_1\\frac{d^{m-1}e(t)}{dt^{m-1}}+...+E_me(t)\n$$\n\n**Three Steps**\n\n* Homogeneous\n* Particular\n* Calculation on coefficients\n\n### Determining Coefficients\n\nIf functions are continuous, we can get their boundary conditions by determining the derivatives.\n\nThen the coefficients can be solved by multipling the inverse of Vandermonde matrix with the boundary condition matrix.\n\n#### Zero-input and -state Responses\n\n**Zero-input response** The response caused by the initial state (i.e., energy originally stored in the system), and it is denoted by $r_{zi}(t)$\n\n**Zero-state response** $r(0_-)\\equiv 0$, the response caused only by the external excitation and it is denoted by $r_{zs}(t)$\n\n![](../images/ss/lec3_1.jpg)\n\n![](../images/ss/lec3_2.jpg)\n\nThe combination of zero-input response and the zero-state response is not necessarily linear, since the existence of constant. If one of them vanishes, the other is linear.\n\n### Impulse and Step Responses\n\n**Impulse Response** the zero-state response $h(t)$ to $\\delta (t)$, which can be equalized to the initial condition.\n\nNote: normally $n>m$.\n\n**Unit Step Response** The zero-state response $g(t)$ to $u(t)$\n\nThere might be a forced term in $g(t)$.\n\n$$\ng(t) = \\int_0^th(\\tau)d\\tau\n$$\n\n### Convolution\n\nZero-state required\n\n$$\ne(t) = \\int_{-\\infty}^{\\infty}e(\\tau)\\delta(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=\\int_{-\\infty}^{\\infty}e(\\tau)h(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=e(t)*h(t)\n$$\n\nthe definition of convoluiton:\n\n$$\nf_1(t)*f_2(t)=\\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$\n\n**Integral interval** $e(t)=0, \\forall t<0$, $h(t)=0,\\forall t<0$, so $r(t)=\\int_0^t{e(\\tau)h(t-\\tau)\\mathrm d\\tau}$\n\nThe condition for applying convolution:\n\n* For linear system ONLY\n* For time variant systems, $h(t, \\tau)$ means response at time $t$ generated by the impulse at time $\\tau$, then $r(t)=\\int_0^th(t,\\tau)e(\\tau)\\mathrm d \\tau$; for time-invariant system is a special case, $h(t,\\tau)=h(t-\\tau)$.\n\n**The Properties of Convolution** The commutative property, the distributive property, the associative property\n\nDifferential:\n\n$$\n(f_1(t)*f_2(t))^\\prime=f_1^\\prime(t)*f_2(t)\n$$\n\nIntegral\n\n$$\n\\int f_1(t)*f_2(t)=f_1(t) * \\int f_2(t)\n$$\n\n$$\n(f_1(t) * f_2(t))^{(i)}=f_1^{(j)}(t) * f_2^{(i-j)}(t)\n$$\n\n**Convolution with $\\delta (t)$ or $u(t)$**\n\n(1) $f(t) * \\delta(t) = f(t)$\n\n(2) $f(t) * \\delta(t - t_0) = f(t-t_0)$\n\n(3) $f(t) * u(t) = \\int_{\\infty}^{t}f(\\tau)\\mathrm d\\tau$\n\n(4) $f(t) * \\delta^\\prime(t) = f^\\prime(t)$\n\n## Fourier Transform\n\n### Fourier Series\n\nrequirements:\n\n* has finite number of discontinuities\n* has finite number of maxima and minima\n* $\\int_{t_0}^{t_0+T_1} |f(t)|\\mathrm dt < \\infty$\n\n$$\n\\begin{align*}\nf(t)&=a_0+\\sum_{n=1}^\\infty \\left[a_n\\cos(n\\omega_1)t + b_n\\sin(n\\omega_1t)\\right]\\\\\n&=c_0 + \\sum_{n=1}^\\infty c_n\\cos \\left(n\\omega_1t+\\varphi_n \\right)\\\\\n&=\\sum_{n=-\\infty}^{\\infty}F_ne^{jn\\omega_1 t}\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n    a_0&=\\frac{1}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\mathrm dt=c_0\\\\\n    a_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\cos(n\\omega_1t)\\mathrm dt\\\\\n    b_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\sin(n\\omega_1t)\\mathrm dt\\\\\n    c_n&=\\sqrt{a_n^2+b_n^2}\\\\\n    \\varphi_n&=-\\tg^{-1}\\frac{b_n}{a_n}\\\\\n    F_n&=\\frac 1{T_1}\\int_{t_0}^{t_0+T_1}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\n    &=\\frac 12e^{j\\varphi_n}\\\\\n    &=\\frac 12(a_n-jb_n)\n\\end{align*}\n$$\n\n**note** When $b_n=0$, $\\varphi_n = a_n > 0\\ ?\\ 0:\\pi$\n\nIn the last part, the negative frequency is introduced for the convenience of the signal analysis. Therefore the amplitude is reduced to half.\n\n\n**FS for special functions**\n\n1. Even function $c_n=a_n, \\varphi_n = 0, F_n=F_{-n}=\\frac 12 a_n$\n2. Odd function $a_0=0, a_n=0, \\varphi_n=-\\frac{\\pi}{2}, F_n=F_{-n}=-\\frac{1}{2}jb_n$\n3. Half-wave Odd (odd harmonic) function, $f(t)=-f\\left(t\\pm \\frac{T_1}2{}\\right)$, contains only odd harmonics(both sine and cosine)\n4. Finite term series\n\n### FS for typical periodic signals\n\n**Periodic square wave**\n\n$$\nf(t)=\\frac{E\\tau}{T_1}+\\sum_{n=1}^{\\infty}\\frac{2E\\tau}{T_1}\\text{Sa}(\\frac{n\\omega_1\\tau}{2})\n$$\n\n1. Spectrum is discrete with frequency spacing $\\omega_1 = \\frac{2\\pi}{T_1}$. When $T_1 \\rightarrow \\infty$, the spectrum will be continuous.\n2. Amplitude: $\\text{Sa}\\left(\\frac{n\\pi\\tau}{T_1}\\right)$ or $\\text{Sa} \\left(\\frac{n\\omega_1\\tau}{2}\\right)$, cross zero when $\\omega_1 = \\frac{2m\\pi}{\\tau}$\n3. Non-zero FS coefficients of a aperiodic signal are infinite with most energy concentrated at low frequency components (within $\\left(-\\frac{2\\pi}{\\tau},\\frac{2\\pi}{\\tau}\\right)$). Thus we define the bandwith $B_{\\omega} = \\frac{2\\pi}{\\tau}$\n\n**Periodic symmetric square wave**\n\nSince the spectrum crosses zero when $\\omega_1 = \\frac{2m\\pi}{\\tau}$, the even harmonic vanishes. Also the sine component vanishes.\n\n$$\nc_n = \\frac{2E\\tau}{T_1}\\left|\\text{Sa}\\left(\\frac{n\\omega_1\\tau}{2}\\right)\\right|\\\\\nf(t) = \\frac{2E}{\\pi}\\left[\\cos(\\omega_1t) - \\frac{1}3\\cos(3\\omega_1t) + \\frac{1}{5}\\cos(5\\omega_1t)-...\\right]\n$$\n\n**Periodic Serrated Pulse**\n\n$$\nf(t) = \\sum_{n = 1}^\\infty \\frac{E}{n\\pi}(-1)^{n+1}\\sin (n\\omega_1t)\n$$\n\n**Periodic Triangular Pulse**\n\n$$\nf(t)=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{n^2}\\sin^2\\left(\\frac{n\\pi}{2}\\right)\\cos(n\\omega_1t)\\\\=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{(2n-1)^2}\\cos((2n-1)\\omega_1t)\n$$\n\n**consine of non-negative values**\n\n$$\nf(t) = \\frac E\\pi - \\frac{2E}{\\pi}\\sum_{n=1}^\\infty\\frac{1}{n^2-1}\\cos(\\frac {n\\pi}2)\\cos(n\\omega_1t)\n$$\n\n**cosine of absoulute values**\n\n$$\nf(t) = \\frac{2E}{\\pi} + \\frac{4E}{\\pi}\\sum_{n=1}^\\infty (-1)^{n+1}\\frac{1}{4n^2-1}\\cos(2n\\omega_0t)\n$$\n\n其中$\\omega_0$ = $2\\omega_1$\n\n### Fourier Transform\n\nThe case where $T_1\\rightarrow \\infty$. Signal becomes aperiodic.\n\nAlso, $\\omega_1\\rightarrow 0$ results in the continuous frequency axis. For square wave the magnitude $\\frac{E\\tau}{T_1}\\rightarrow 0$.\n\n$$\nf(t) =\\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)e^{jn\\omega_1 t}\\\\\nF(n\\omega_1) = \\frac 1T_1\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\n$$\n\nWe use spectrum density to replace spectrum, making the magnitude dropping to zero remain its meaning.\n\n$$\n\\frac{F(n\\omega_1)}{\\omega_1} = \\frac{1}{2\\pi}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\nF(\\omega) = \\lim_{\\omega_1\\rightarrow 0}\\frac{2\\pi F(n\\omega_1)}{\\omega_1}=\\lim_{T_1\\rightarrow \\infty}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm d t=\\int_{-\\infty}^\\infty f(t)e^{-j\\omega t}\\mathrm d t\\\\\nf(t) = \\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)\\cdot \\frac{1}{\\omega_1}e^{jn\\omega_1 t} \\Delta(n\\omega_1) = \\frac{1}{2\\pi}\\int_{-\\infty}^\\infty F(\\omega)e^{j\\omega t}\\mathrm d\\omega\n$$\n\n$$\nF(\\omega) = |F(\\omega)|e^{j\\varphi(\\omega)}\n$$\n\nThe fourier transfrom is continuous waveform, where every frequency has no energy but energy density, used to analyse aperiodic function.\n\nSufficient condition, but not necessary.\n\n$$\n\\int_{-\\infty}^\\infty |f(t)|\\mathrm dt<\\infty\n$$\n\n### FT for typical aperiodic signals\n\n**Rectangular pulses**\n\n$$\nF(\\omega) = \\int_{-\\tau/2}^{\\tau/2} Ee^{-j\\omega t}\\mathrm dt = E\\tau \\text{Sa}\\left(\\frac{\\omega \\tau}{2}\\right)\n$$\n\n**Raised Cosine Signal**\n\n$$\nf(t) = \\frac{E}{2}(1+\\cos\\frac{\\pi t}{\\tau})(u(t+\\tau) - u(t - \\tau))\\\\\nF(\\omega) = \\int_{-\\tau}^{\\tau}(1+\\cos\\frac{\\pi t}{\\tau})\\mathrm dt = \\frac{E\\tau}{1 - \\left(\\frac{\\omega \\tau}{\\pi}\\right)^2}\\text{Sa}({\\omega \\tau})\n$$\n\nMore compacted than square signal($|F(\\omega)|\\propto \\frac 1{\\omega^3}$). An explanation is that the raised cosine has no discontinuities.\n\nGenerally:\n\n1. $f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega}$\n2. $\\frac{d}{dt}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^2}$\n3. $\\frac{d^2}{dt^2}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^3}$\n\nThe **width** $\\tau$ of the raised cosine signal is defined at $\\frac E2$ rather than at the bottom, making it easy to compare with \n     the rectangular pulse of same width. The first zeros of the \n   frequency spectrum are identical.\n\n\nraised consine is energy-concentrative and has been widely used in digital communications.\n\n**Single-sided exponential singal** \n\n$$\nf(t) = e^{-at}u(t)\\\\\nF(\\omega) = \\frac{1}{a+j\\omega}\n$$\n\n**Two-sided, anti-symmetric exponential signal**\n\n$$\nf(t) = -e^{at}u(-t) + e^{-at}u(t)\\\\\nF(\\omega) = \\frac{-2j\\omega}{a^2+\\omega^2}\n$$\n\n**Sign function**\n\n$$\n\\text{sgn}(t) = u(t) - u(-t)\\\\\nF(\\omega) = \\lim_{a\\rightarrow 0}\\frac{-2j\\omega}{a^2+\\omega^2}= \\frac{2}{j\\omega}\n$$\n\n**Gaussian singal**\n\n$$\nf(t) = Ee^{-\\left(\\frac{t}{\\tau}\\right)^2}\\\\\nF(\\omega) = \\sqrt \\pi E\\tau e^{-\\left(\\frac{\\omega\\tau}{2}\\right)^2}\n$$\n\n**Sinc Function**\n\n$$\nf(t) = \\frac{E}{\\pi}\\frac{\\sin(\\omega_c t)}{t}\\\\\nF(\\omega) = E(u(\\omega - \\omega_c ) + u(\\omega + \\omega_c ))\\\\\n$$\n\n\n### FT on impulse and step functions\n\n$$\n\\mathcal F[\\delta(t)] = 1\\\\\n\\mathcal F[1] = 2\\pi \\delta(\\omega)\n$$\n\nThe spectrum of impulse function covers the entire frequency range. The interferences caused by a variety of electric sparks always cover the full frequency range.\n\n$$\n\\mathcal F[\\delta^\\prime (t)]= j\\omega\\\\\n\\mathcal F[\\delta^{(n)}(t)] = (j\\omega)^n\n$$\n\n$$\n\\mathcal F[u(t)] = \\pi \\delta(\\omega) + \\frac{1}{j\\omega}\n$$\n\nDue to the DC component in u(t), an impulse exists.\n\n### Properties of FT\n\n**Symmetry** $\\mathcal F[F(t)]= 2\\pi f(-\\omega)$ , if $f(t)$ is a even function, $\\mathcal F[F(t)]= 2\\pi f(\\omega)$\n\n**Linearity** $\\mathcal{F}[\\Sigma_{i=1}^{n}a_if_i(t)] = \\Sigma_{i=1}^{n}a_iF_i(\\omega)$\n\n**Odd-Even, Imaginary-Real** $f(t) = f_e(t)+f_o(t)$, then\n\n$$\n\\begin{align*}\n  F(\\omega) &= \\int_{-\\infty}^\\infty f(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f(t)\\sin \\omega t \\mathrm dt\\\\\n  &=R(\\omega)+jX(\\omega)\\\\\n  &=\\int_{-\\infty}^\\infty f_e(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f_o(t)\\sin \\omega t \\mathrm dt\\\\\n\\end{align*}.\n$$\n\n$R(\\omega)$ is an even function of $\\omega$, $X(\\omega)$ is an odd function of $\\omega$.\n\n$|F(\\omega) = \\sqrt{R^2(\\omega)+F^2(\\omega)}|$ is even function.\n\n$\\varphi(\\omega) = \\tg^{-1}\\frac{R(\\omega)}{X(\\omega)}$\n\nif $f(t)$ is real and even, then $f(t)=f_e(t), F(\\omega)=R(\\omega)$, the phase shift is $0$ or $\\pi$.\n\nif $f(t)$ is real and odd, $f(t) = f_o(t)$, then $F(\\omega)=jX(\\omega)$, $F(\\omega)$ has only imaginary part and is odd, the phase shift is $\\pm \\frac{\\pi}{2}$\n\n**Scaling** $\\mathcal{F}[f(at)]=\\frac 1{|a|}F\\left(\\frac{\\omega}a\\right)$ Expansion in TD results in Compression in FD.\n\n**Time Shifting** $\\mathcal{F}[f(t\\pm t_0)] = F(\\omega)e^{\\pm j\\omega t_0}$\n\n**Frequency Shifting** $\\mathcal F[f(t)e^{\\pm j\\omega_0t}] = F(\\omega\\mp\\omega_0)$\n\n**Differentiation property**$\\mathcal F\\left[\\frac{\\mathrm d}{\\mathrm dt}f(t)\\right] = j\\omega F(\\omega)$\n\n$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm dt^n}f(t)\\right] = (j\\omega)^n F(\\omega)$\n\n$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm d\\omega^n}F(\\omega)\\right] = (-jt)^nf(t)$\n\n\n**Integration Property** $\\mathcal{F}\\left[\\int_{-\\infty}^t f(\\tau)\\mathrm{d} \\tau\\right] = \\frac{F(\\omega)}{j\\omega} + \\pi F(0)\\delta(\\omega)$\n\n### Convolution theorem\n\n$$\n\\mathcal F[f_1(t)* f_2(t)] = F_1(\\omega)F_2(\\omega)\\\\\n\\mathcal F[f_1(t)\\cdot f_2(t)] = \\frac 1{2\\pi} F_1(\\omega) * F_2(\\omega)\n$$\n\n### FT for Periodic Signals\n\n$$\n\\mathcal F[\\cos (\\omega_0 t)] = \\pi [\\delta(\\omega + \\omega_0) + \\delta(\\omega - \\omega_0)]\\\\\n\\mathcal{F} [\\sin (\\omega_0 t)] = j\\pi [\\delta(\\omega+\\omega_0) + \\delta(\\omega - \\omega_0)]\n$$\n\nFT for periodic of $T_1$ & $\\omega_1=2\\pi/T_1$\n\n$$\n\\mathcal F[f(t)] = 2\\pi\\sum_{n=-\\infty}^{+\\infty} F_n\\delta(\\omega - n\\omega_1)\\\\\nF_n = \\frac 1{T_1}\\int_{-T_1/2}^{T_1/2}f(t)e^{-jn\\omega_1 t}\\mathrm dt = \\frac{1}{T_1}F_0(\\omega)\\vert_{\\omega =n\\omega_1}\n$$\n\nWhere $F_0(\\omega)$ is the FT considering waveform of $f(t)$ only in $|t|\\le T_1/2$.\n\nexample: \n\n$$\nf(t) = \\sum_{n=0}^{\\infty}\\delta(t-nT_1), F_n=\\frac{1}{T_1}\\\\\nF(\\omega) = \\frac{2\\pi}{T_1}\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)=\\omega_1\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)\n$$\n\n$$\nF_0(ω) \\text{ determines the profile of } F(ω)\\\\\nT_1\\text{ determines the density of the impulses\n}\\\\\nT_1↑, ω_1↓\\text{, intensity of harmonics}↓\\\\\nT_1↓,ω_1↑\\text{, intensity of harmonics}↑\\\\\n$$\n\n![](../images/ss/lec7_1.jpg)\n\nIn the same way: \n\n![](../images/ss/lec7_2.jpg)\n\n### FT for periodically sampled signals\n\n$$\nF(\\omega) = \\mathcal F[f(t)]\\\\\nP(\\omega) = \\mathcal F[p(t)]\\\\\nf_s(t) = f(t)p(t)\\\\\nF_s(\\omega) =\\frac{1}{2\\pi} F(\\omega) * P(\\omega)\n$$\n\nThen, \n\n$$\nP(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_n\\delta(\\omega - \\omega_s)\\\\\nF(\\omega) * P(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\\\\\nF_s(\\omega) = \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\n$$\n\n![](../images/ss/lec7_3.jpg)\n\nFor the frequency-domain sampling: \n\n$$\nF_1(\\omega) = F(\\omega)P(\\omega)\\\\\nP(\\omega) = \\sum_{n=-\\infty}^{+\\infty} \\delta(\\omega - n\\omega_1)\\\\\nf_1(t) = f(t) *  \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{+\\infty} \\delta(t - nT_1) = \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{\\infty} f(t-nT_1)\n$$\n\n**The Sampling Theorem**\n\n$$\n\\omega_s \\ge 2\\omega_m\n$$\n\nA band-limited signal whose spectrum is strictly within $[0, f_m]$ could be uniquely determined by the samples on itself, if and only if the sampling interval $T_s \\le 1/(2f_m)$.\n\n$T_s = \\frac{1}{2f_m}$ is called the **Nyquist interval**.\n\n$2f_m$ is called the **Nyquist frequency**.\n\n对于单频信号，奈奎斯特频率的采样可能会出现问题。例如正弦信号，每次采样都采在零点上，那就没法复现信号。单频信号没法描述带宽。\n\nA FD verison:\n\n![](../images/ss/lec7_4.jpg)\n\n\n\n## L Transform\n\n### Unilateral L-transform\n\n$$\nF(s) = \\int^{\\infty}_{0}f(t)e^{-st}\\mathrm dt, s=\\sigma+j\\omega\\\\\nf(t)=\\frac{1}{2\\pi j}\\int_{\\sigma-j\\infty}^{\\sigma+j\\infty}F(s)e^{st}\\mathrm ds\n$$\n\n$F(s) = \\mathcal{L}[f(t)]$ is called image function, $f(t) = \\mathcal{L}^{-1}[F(s)]$ is called primitive function.\n\nassuming that $f(t)$ is causal and always 0 if $t<0$.\n\n$$\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0) + sF(s)\n$$\n\nThe initial state is automatically included in differential equation.\n\nWe define the **unilateral** L-Transform as: \n\n$$\nF(s) = \\int_{0_-}^{\\infty}f(t)e^{-st}\\mathrm dt\\\\\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0_-) + sF(s)\n$$\n\nConditions for L-Transform: \n\n1. Limited discontinuities\n2. Exponential order\n\nThe strong attenuation factor can make the function convergent.\n\nRegion of Convergence (ROC)\n\nAxis of convergence\n\nCoordinate of convergence $\\sigma_0$\n\n### Comman LT Pairs\n\n$$\n\\begin{align*}\nf(t)&\\Rightarrow F(s)\\\\  \n\\delta(t) &\\Rightarrow 1\\\\\nu(t) &\\Rightarrow \\frac 1s\\\\\ne^{-at} &\\Rightarrow \\frac{1}{s+a}\\\\\nt^n & \\Rightarrow \\frac{n!}{s^{n+1}}\\\\\n\\sin (\\omega t)&\\Rightarrow \\frac{\\omega}{s^2 + \\omega^2}\\\\\n\\cos (\\omega t)&\\Rightarrow \\frac{s}{s^2+\\omega^2}\\\\\n\\end{align*}\n$$\n\n### Properties of LT\n\n**Linarity**\n\n$$\n\\mathcal L [k_1f_1(t) + k_2f_2(t)] = k_1F_1(s) + k_2F_2(s)\\\\\n$$\n\n**Differentiation**\n\n$$\n\\mathcal L \\left[\\frac{\\mathrm d f(t)}{\\mathrm d t}\\right] = sF(s) - f(0_-)\n$$\n\n**Intergration**\n\n$$\n\\mathcal L\\left[\\int_{-\\infty}^t f(\\tau)\\mathcal d\\tau\\right]=\\frac{F(s)}{s} + \\frac{f^{(-1)}(0)}{s}\n$$\n\n**Time Shifting**\n\n$$\n\\mathcal L\\left[f(t-t_0)u(t-t_0)\\right] = e^{-st_0}F(s)\n$$\n\nUse $u(t-t_0)$ to avoid nagative part of $f(t)$ emerges.\n\n**Frequency Shifting**\n\n$$\n\\mathcal L[f(t)e^{-at}] = F(s+a)\n$$\n\n**Scaling**\n\n$$\n\\mathcal L[f(at)] = \\frac 1a F\\left(\\frac{s}{a}\\right)\n$$\n\n**s-Domain Differentiation**\n\n$$\n\\frac{\\mathrm d}{\\mathrm ds}\\mathcal L[f(t)] = \\mathcal L[-tf(t)]\n$$\n\n**s-Domain Differentiation**\n\n$$\n\\int_s^\\infty F(s) = \\mathcal{L}\\left[\\frac{f(t)}{t}\\right]\n$$\n\n**Initial value**\n\n$$\nf(0_+) = \\lim_{s\\rightarrow\\infty}sF(s)\n$$\n\n**Final value**\n\n$$\n\\lim_{t\\rightarrow\\infty} f(t) = \\lim_{s\\rightarrow0} sF(s)\n$$\n\nGeneralized limit: $\\lim_{t\\rightarrow\\infty} \\sin(\\omega t)=0$\n\n**Convolution**\n\n$$\n\\mathcal L[f_1(t)*f_2(t)] = F_1(s)F_2(s)\n$$\n\n### Applications\n\n**Differential Equations**\n\n$$\n  F(s) = \\frac{A(s)}{B(s)} = \\frac{a_ns^n + a_{n-1}s^{n-1} + \\cdots + a_1s + a_0}{b_ms^m + b_{m-1}s^{m-1} + \\cdots + b_1s + b_0} % The division of two polynomials\n$$\n\n(assume that $n<m$)\n\nThe roots of numerator is called zeros, while the roots of denominator is called poles.\n\nUnknown function F(s) can be represented by the ratio of two polynomials if all initial states are 0.\n\n1. real poles\n\n$$\nF(s) = \\frac{A(s)}{(s-p_1)(s-p_2)(s-p_3)}\n$$\n\n2. complex conjugate poles\n\n$$\nF(s) = \\frac{A(s)}{D(s)[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{(s+\\alpha - j\\beta)(s+\\alpha + j\\beta)} + \\dots\n$$\n\n$$\nk_1 = (s+\\alpha - j\\beta)F(s)|_{s = -\\alpha + j\\beta} = \\frac {F_1(-\\alpha + j\\beta)}{2j\\beta}\\\\\nk_2 = (s+\\alpha + j\\beta)F(s)|_{s = -\\alpha - j\\beta} = \\frac {F_1(-\\alpha - j\\beta)}{-2j\\beta}\n$$\n\n3. Multiple poles\n\n$$\nF(s) = \\frac {A(s)}{B(s)} = \\frac{A(s)}{(s-p_1)^k D(s)}\\\\\n= \\frac{K_{11}}{(s-p_1)^k}+\\frac{K_{12}}{(s-p_1)^{k-1}}+\\dotsb+\\frac{K_{1k}}{s-p_1} + \\frac{E(s)}{D(s)}(s-p_1)^k\n$$\n\n![](../images/ss/lec9_1.jpg)\n\n![](../images/ss/lec9_2.jpg)\n\n\nCircuit model:\n\n![](../images/ss/lec9_3.jpg)\n\n![](../images/ss/lec9_4.jpg)\n\n![](../images/ss/lec9_5.jpg)\n\nUse initial value and final value to verify it.\n\n### System Function\n\n$$\n\\begin{cases}\n  R(s) = H(s) \\cdot E(s)\\\\\n  r(t) = h(t) * e(t)\n\\end{cases}\n\\Rightarrow H(s) = L[h(t)]\n$$\n\n**Driving point function & transfer function**\n\n![](../images/ss/lec9_6.jpg)\n\nL-transform can be used in the following analysis:\n\n* TD characteristics (response decomposition)\n* FD characteristics (steady-state with sine signal input,applications such as filtering) \n* Stability (active network, feedback, oscillator, control system)\n\n\n### TD characteristics by 0-point distribution\n\nThree cases: \n\n* Real poles\n* Complex conjugate poles\n* Real pole of high-order\n\n1. Zero pole of H(s)\n\n\n\n![](../images/ss/lec10_1.jpg)\n\n![](../images/ss/lec10_2.jpg)\n\nZero only affects the phase and amplitude, while the shape and type of waveform is determined by the poles.\n\n2. pole distribution $\\Leftrightarrow$ corresponding natural/forced responses\n\n$$\nH(s) = \\frac{\\prod_{i = 1}^m(s-z_{hj})}{\\prod_{i = 1}^n(s-p_{hi})}\\\\\nE(s) = \\frac{\\prod_{i = 1}^u(s-z_{el})}{\\prod_{i = 1}^v(s-p_{ek})}\\\\\n\\text{if } m + u < n + v\\\\\nR(s) = E(s)H(s) = \\sum_{k=1}^n\\frac{K_{hk}}{s - p_{hk}} + \\sum_{k=1}^v\\frac{K_{ek}}{s-p_{ek}}\n$$\n\nThe natural response of $r(t)$ is only related to $p_{hk}$, while the forced response is only related to $p_{ek}$.\n\n$K_{hk}$, $K_{ek}$ are related to both $H(s)$ and $E(s)$.\n\nHowever natural and forced responses could not be completely separated, if there exists $k, k^\\prime$ satisfying $p_{hk}=p_{ek^\\prime}$.\n\n$p_{hi}$ are called natural frequency of the system.\n\nHowever, some common factors may be eliminated: \n\n$$\n\\frac{(s+1)}{(s+1)(s+2)} = \\frac{1}{(s+2)}\n$$\n\n$$\nH(s) = \\frac{\\Delta_{jk}}{\\Delta}\n$$\n\nAll the poles of $H(s)$ are the natural frequencies of the system, but $h(t)$ may not include all the natural frequencies(but the root of $\\Delta$ contains all natural frequencies).\n\nIn most cases:\n\n$$\n\\text{Re}(p_{hi}) < 0, \\text{Re}(p_{ei}) = 0\n$$\n\nThus the natural response is transient, while the forced response is steady-state.\n\nHowever, some natural response can be steady-state(conjugate poles of $Re(p_{hi})$), while some forced response can be transient.\n\n![](../images/ss/lec10_3.jpg)\n\n![](../images/ss/lec10_4.jpg)\n\n![](../images/ss/lec10_5.jpg)\n\n$$\nE_m|H(j\\omega)|\\sin (\\omega_0t + \\varphi_0)\n$$\n\n$$\nH(j\\omega) =K\\cdot \\frac{\\prod(j\\omega - z_j)}{\\prod (j\\omega - p_i)}\n$$\n\n![](../images/ss/lec10_7.jpg)\n\n![](../images/ss/lec10_6.jpg)\n\n![](../images/ss/lec10_8.jpg)\n\nfor band-pass filter, \n\nBW is where Peak(dB) - 3dB\n\nfor low-pass filter,\n\nBW = $f_{\\text{cut-off}}$\n\nAccording to the sampling theorem, the signal bandwith is often determined by the first zero of the spectrum.\n\n**All Pass Systems**\n\n$$\nR_e(p_i) = -R_e(z_i)\\\\\nI_m(p_i) = I_m(z_i)\n$$\n\nThe Amplitude is const., while the phase can change.\n\n**Minimum-phase system/function**\n\nDefinition: A stable system with poles on left-half s-plane is called minimum-phase system/function, if all the zeros are also on left-half s-plane or at the jω-axis. Otherwise is a non-minimum-phase system/function. \n![](../images/ss/lec11_1.jpg)\n\n\nProperty: A non-minimum-phase function can be represented as the product of  a minimum-phase function and an all-pass function.\n\n### Stability of Linear System\n\nA system is considered to be stable if bounded input always leads to bounded output.\n\nBounded-input, Bounded-output(BIBO)\n\nThe necessary & sufficient conditions for BIBO:\n\n$$\n\\int_{-\\infty}^\\infty|h(t)|\\mathrm dt \\le M\n$$\n\nPoles are: \n\n* on the left half-plane: $\\lim_{t\\rightarrow \\infty}[h(t)] = 0$, stable system\n* on the right half-plane, or at $j\\omega$-axis with order of more than one: $\\lim_{t\\rightarrow \\infty}[h(t)] = \\infty$, unstable system\n* at $j\\omega$-axis with order of one: $h(t)$ is non-zero or oscillated with equal amplitude, critical stable system\n\n### Two-sided (Bilateral) LT\n\n$$\nF_B(s) = \\int_{-\\infty}^\\infty f(t)e^{-st}\\mathrm{d} t\n$$\n\n * t starts from −∞, i.e., non-causal signal as the input\n       or regarding the initial condition as the input.\n*  Easily to be associated with F-transform and Z-   \n       transforms\n\nWe determine the ROC by:\n\n$$\n\\lim_{t\\rightarrow \\infty} f(t)e^{-\\sigma t} = 0\\\\\n\\lim_{t\\rightarrow -\\infty} f(t)e^{-\\sigma t} = 0\n$$\n\nNOTE: \n\n* If no overlap between the two constraints, then $F_B(s)$ does not exist.\n* $F_B(s)$ and $f(t)$ are not uniquely corresponding to each other.($\\int_{-\\infty}^\\infty u(t)e^{-st}\\mathrm{d} t = \\frac{1}{s}$, $\\int_{-\\infty}^\\infty -u(-t)e^{-st}\\mathrm{d} t=\\frac{1}{s}$)\n* Two-sided L-Transform shares almost all the properties with its single-sided counterpart except for the initial-value theorem.\n* Two-sided L-Transform has very limited applications as most continuous-time systems are causal.\n\n**Relationship between LT and FT **\n\n* $\\sigma_0 > 0$, $F(\\omega)$ does not exist\n* $\\sigma_0 = 0$, impulse appears in $F(\\omega)$\n* $\\sigma_0 < 0$, $F(\\omega)$ exists, $F(\\omega) = F(s)|_{s=j\\omega}$\n\n![](../images/ss/lec11_2.jpg)\n(The LT above is unilateral LT.)\n\n\n![](../images/ss/lec11_3.jpg)\n\n### Extra Attention\n\n$1 + e^{-s}$ also has zero(many!). Note that if it is on the denominator.\n\n## FT in Telecom. Systems\n\nSystem discussed in this chapter are strictly stable: \n\n$$\n\\mathcal{F}[f(t)] = F(s)|_{s=j\\omega}\n$$\n\nBecause even for critical stable system, FT is not  the same as LT(containing $\\delta$), there will be ambiguity between $H(j\\omega)$ and $H(s)|_{s=j\\omega}$.\n\nFor every freq. component, it is reshaped in its phase and amplitude by the system function when passing through the system, related with its frequency. Thus the system can distort the original signal.\n\n**Distortion**\n\n2 types of distortion:\n\n* Non-linear distortion (new frequency components)\n* Linear distortion (without new frequency components), just the amplitude and/or phase distortion.\n\n **Distortionless transmission**\n\n$$\ne(t)\\rightarrow ke(t - t_0)\n$$\n\n$$\nR(j\\omega) = \\int_{-\\infty}^\\infty ke(t -t_0)e^{-j\\omega t}\\mathrm dt=ke^{-j\\omega t_0}\\int_{-\\infty}^\\infty e(x)e^{-j\\omega x}\\mathrm dx=ke^{-j\\omega t_0} E(j\\omega)\n$$\n\nSo, $H(j\\omega) = ke^{-j\\omega t_0}$, $h(t)=K\\delta(t - t_0)$.\n\nThe Amplitude is frequency independent, $BW\\rightarrow \\infty$.\n\nPhase response is linear at negative slope.\n\nThe impulse response of a distortionless linear system is  \n     also an impulse.\n\nThe physical scenario: group delay.\n\n$$\n\\tau = -\\frac{\\mathrm d\\varphi (\\omega)}{\\mathrm d\\omega}\n$$\n\nCondition for phase distortionless property: the group delay remains a constant.\n\n### Filter\n\n**Ideal Low pass (LP) Filter**\n\n$$\nH(j\\omega) = \\begin{cases}\n  1 \\cdot e^{-j\\omega t_0}, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$\n\n![](../images/ss/lec12_1.jpg)\n\n**The Impulse response of Ideal LP**\n\n![](../images/ss/lec12_2.jpg)\n\n* Severe distortion. $BW_{\\delta(t)}\\rightarrow \\infty$, but $BW_{\\text{Lowpass}}=\\omega_c$, the higier frequency is eliminated.\n* Non-causal. When $t\\lt 0$, $h(t)\\ne 0$.\n\n**Unit-step response of Ideal LP**\n\n![](../images/ss/lec12_3.jpg)\n\n![](../images/ss/lec12_4.jpg)\n\n![](../images/ss/lec12_5.jpg)\n\nThe response is similar to the input if $\\frac{1}{2}=\\frac{\\pi}{\\omega_c}\\llless \\tau$. \n\n**Gibbs phenomenon**: 9% overshoot at discontinuity. Use other window functions can eliminate this, e.g. raised-cosine window.\n\n### Modulation and demodulation\n\nMeans of modulation:\n\n**Spectrum shifting** \n\n$f(t) = g(t)\\cos(\\omega_0t)$, $F(\\omega) =\\frac{1}{2\\pi} G(\\omega) * \\pi[\\delta(\\omega - \\omega_0) + \\delta (\\omega + \\omega_0)] = \\frac{1}{2}[G(\\omega + \\omega_0) + G(\\omega - \\omega_0)]$.\n\n![](../images/ss/lec12_6.jpg)\n\nDemodulation: \n\n**coherent demodulation**\n\n$g_0(t)=[g(t)\\cos(\\omega_0 t)]\\cos(\\omega_0t) = \\frac{1}{2}g(t) + \\frac{1}{2}g(t)\\cos2\\omega_0t$\n\n![](../images/ss/lec12_7.jpg)\n\n**Envelope Detection**\n\n![](../images/ss/lec12_8.jpg)\n\n### Applications of BPF\n\n**Window Function**\n(Page 304)\n$$\nh_a(t) = \\frac{\\sqrt a \\sin\\left(\\frac{\\pi t}{a}\\right)\\cos \\left(\\frac{3\\pi t}{a}\\right)}{\\sqrt{ \\pi} \\pi t}\\\\\nH_a(\\omega) = \\begin{cases}\n  \\frac{1}{2}\\sqrt{\\frac{a}{\\pi}}, \\text{if } \\frac{2\\pi}{a}\\le |\\omega| \\le \\frac{4\\pi}{a},\\\\\n  0, \\text{otherwise}.\n\\end{cases}\n$$\n\n![](../images/ss/lec13_1.jpg)\n\n### Recover Continuous Time signal from its Samples\n\n**Analysis on signal after band-pass filter**\n\nPage 301\n\n**Sampling with impulse func.**\n\nFD analysis:\n\nSampled signal(By impulse function):\n\n$$\nF_s(\\omega) = \\frac{1}{T_s}\\sum_{n=-\\infty}^\\infty F(\\omega - n\\omega_s)\n$$\n\nIdeal LP Filter:\n\n$$\nH(j\\omega) = \\begin{cases}\n  T_s, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$\n\nRecovered signal: \n\n$$\nF(\\omega) = F_s(\\omega) \\cdot H(\\omega)\n$$\n\nTD analysis:\n\nSampled signal:\n\n$$\nf_s(t) = \\sum_{n=-\\infty}^\\infty f(nT_s)\\delta(t - nT_s)\n$$\n\nIdeal LP Filter:\n\n$$\nh(t) = T_s\\frac{\\omega_c}\\pi \\text{Sa}(\\omega_c t)\n$$\n\nRecovered signal:\n\n$$\nf(t) = f_s(t) * h(t) = T_s\\frac{\\omega_c}\\pi  \\sum_{n=-\\infty}^\\infty f(nT_s) \\text{Sa}(\\omega_c (t-nT_s))\n$$\n\n![](../images/ss/lec14_1.jpg)\n\n![](../images/ss/lec14_2.jpg)\n\n**Sampling with a zero-order hold**\n\n![](../images/ss/lec14_3.jpg)\n\n$$\nh_0(t) = u(t) - u(t - T_s)\\\\\nf_{s0}(t) = f_s(t)* h_0(t)\n$$\n\n$$\n\\begin{align*} \n&\\mathcal F\\{f_{s0}(t)\\} \\\\&=\\mathcal F\\{f_s(t)\\} \\cdot \\mathcal F\\{h_0(t)\\} \\\\ &=F_s(\\omega) \\cdot H_0(\\omega)\\\\\n&=\\sum_{-\\infty}^{\\infty}F(\\omega - n\\omega_s) \\cdot  \\text{Sa}(\\frac{\\omega_c T_s}{2})e^{-j\\frac{\\omega T_s}{2}}\\\\\n\\end{align*}\n$$\n\nLP Filter for compensation\n\n$$\nH_{0r}(\\omega) = \\begin{cases}\n  \\frac{1}{\\text{Sa}(\\frac{\\omega T_s}{2})}e^{j\\omega T_s/2}, &|\\omega| \\le \\omega_s/2,\\\\\n  0, &|\\omega|> \\omega_s/2.\n\\end{cases}\n$$\n\nLinear phase response is OK! No needed for delay compensation. \n\n**1st-order hold Sampling**\n\n![](../images/ss/lec14_4.jpg)\n\n### Mulitplexing FDM and TDM\n\nTransmit mulitple singals over a single channel concurrently.\n\nFrequency Division Multiplexing (FDM) － OFDM (Orthogonal FDM)\n\nTime Division Multiplexing (TDM)－sharing slot, statistical multiplexing\n\nCode Division Multiplexing (CDM)－ Code division, logical multiplexing\n\nWavelength Division Multiplexing (WDM)－ Optical carrier\n\n![](../images/ss/lec14_5.jpg)\n\n![](../images/ss/lec14_6.jpg)\n\n![](../images/ss/lec14_7.jpg)\n\n## Vector Analysis of Signals\n\n### Vector Space\n\n![](../images/ss/lec15_1.jpg)\n\n![](../images/ss/lec15_2.jpg)\n\n![](../images/ss/lec15_3.jpg)\n\n![](../images/ss/lec15_4.jpg)\n\n![](../images/ss/lec15_5.jpg)\n\n### Objective for singal decomposition\n\n$$\nr(t) = H[e(t)] = H\\left[\\sum_{i=0}^ne_i(t)\\right] = \\sum_{i=0}^nH[e_i(t)]\n$$\n\n### Basics\n\n**Orthogonal Vector**\n\n![](../images/ss/lec15_6.jpg)\n\n**Orthogonal Function**\n\nRepresend $f_1(t)$ in terms of $f_2(t)$(both real), for $t_1<t<t_2$\n\n$$\nf_1(t)\\approx c_{12}f_2(t)\n$$\n\nResidual error $\\overline{\\varepsilon^2} = \\overline{f_e^2(t)} = \\frac{1}{t_2 - t_1}\\int_{t_1}^{t_2}[f_1(t) - c_{12}f_2(t)]^2\\mathrm dt$\n\nLet $\\frac{\\mathrm d \\overline{\\varepsilon^2}}{\\mathrm d c_{12}} = 0$, then $\\overline{\\varepsilon^2}$ is minimized.\n\nThe coefficient can be determined as\n\n$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt} = \\frac{\\langle f_1, f_2\\rangle}{\\langle f_2, f_2\\rangle}\n$$\n\nIf $c_{12} = 0$, then $f_1(t), f_2(t)$ are called **Orthogonal Functions**.\n\nAnd \n\n$$\n\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt = 0\n$$\n\n**Orthogonal Function Set**\n\nAny real function $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.\n\n$$\nf(t) = \\sum_{r=1}^n c_rg_r(t)\n$$\n\nAccording to the minimal mean square error, the coefficient can be determined as\n\n$$\nc_r = \\frac{\\int_{t_1}^{t_2}f(t)g_r(t)\\mathrm dt}{\\int_{t_1}^{t_2}g_r^2(t)\\mathrm dt} = \\frac{\\langle f, g_r\\rangle}{\\langle g_r, g_r\\rangle}\n$$\n\nIf $g_1(t), g_2(t), ..., g_n(t)$ are orthogonal to each other, i.e.\n\n$$\n\\int_{t_1}^{t_2}g_r(t)g_s(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$\n\nThen $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.\n\nThen $g_1(t), g_2(t), ..., g_n(t)$ are called **Orthogonal Function Set**.\n\nIf $\\int_{t_1}^{t_2}g_i^2(t)\\mathrm dt = 1$, the orthogonal function set is called **Orthonormal Function Set**.\n\n**Orthogonality of Complex Function**\n\n$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2(t)f_2^*(t)\\mathrm dt} = \\frac{\\langle f_1, f_2^*\\rangle}{\\langle f_2, f_2^*\\rangle}\n$$\n\n**Orthogonal Function Set** satisfies\n\n$$\n\\int_{t_1}^{t_2}g_r(t)g_s^*(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$\n\nThe definition of Orthogonal is\n\n$$\n\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt = \\int_{t_1}^{t_2}f_2(t)f_1^*(t)\\mathrm dt = 0\n$$\n\nNOTE:\n\n* If two signals are orthogonal within a given interval, they are not necessarily orthogonal within other intervals.\n\n* If two signals are not orthogonal, they must be correlated.\n\n### Complete Orthogonal Function and Parseval's Theorem\n\n**Complete Orthogonal Funtion Set**\n\n$$\n\\overline{\\varepsilon^2} = \\frac{1}{t_2-t_1}\\left[\\int_{t_1}^{t_2}f^2(t)\\mathrm dt  - \\sum_{r = 1}^nc_r^2K_r\\right]\n$$\n\nIf $\\lim_{t_2 \\to \\infty}\\overline{\\varepsilon^2} = 0$, then $\\{g_r(t)\\}$ is said to be a **Complete Orthogonal Function Set**.\n\nAlternative definition of complete orthogonal set\n\nOther than the elements in $\\{g_r(t)\\}$, there is no finite-energy signal $x(t)$, which satisfies\n\n$$\n\\int_{t_1}^{t_2}x(t)g_r(t)\\mathrm dt = 0, \\forall r\\\\\n\\text{or } \\int_{t_1}^{t_2}x(t)g_r^*(t)\\mathrm dt = 0, \\forall r\n$$\n\n\nTrigonometric Set\n\n$$\n\\left\\{\\cos n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\\\\\n\\left\\{\\sin n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\n$$\n\nComplex exponential set\n\n$$\n\\left\\{e^{jn\\omega_1 t}\\right\\}_{n\\rightarrow\\infty}\n$$\n\n**Parseval's Theorem**\n\n$$\n\\int_{t_1}^{t_2}f(t)^2\\mathrm dt = \\sum_{r=1}^\\infty c_r^2K_r = \\sum_{r=1}^\\infty\\int_{t_1}^{t_2}[c_rg_r(t)]^2\\mathrm dt\n$$\n\nPhysical interpretation:\n\nThe energy (power) of a signal always equals to the sum of the energy (power) of all its components in a complete orthogonal function set. \n\nMathematical interpretation:\n\nThe norm of vector signals keeps invariant under orthogonal transform.\n\n### Correlation\n\nPhysical interpretation:\n\nGauge of the similarity of two signals \n\n**Energy and Power Signals**\n\nInstaneous Power $p(t) = i^2(t) R$\n\nThe energy consumed by $R$ in a period\n\n$$\nE = \\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$\n\nAverage Power:\n\n$$\nP = \\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = \\frac{1}{T_0}R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$\n\nThe energy signals and power signals:\n\n$$\nE = \\lim_{T_0 \\to \\infty}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\\\\\nP = \\lim_{T_0 \\to \\infty}\\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\n$$\n\n**Correlation Coefficient**\n\n$$\n\\rho_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\sqrt{\\int_{t_1}^{t_2}f_1^2(t)\\mathrm dt}\\sqrt{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt}} = \\frac{\\langle f_1, f_2\\rangle}{\\sqrt{\\langle f_1, f_1\\rangle}\\sqrt{\\langle f_2, f_2\\rangle}} = \\frac{\\langle f_1, f_2\\rangle}{\\|f_1\\|_2\\|f_2\\|_2} \n$$\n\nIf $f_1(t)$ is a linear function of $f_2(t)$, then $\\rho_{12} = \\pm1$, $\\overline{\\varepsilon^2} = 0$.\n\nIf $f_1(t)$ is orthogonal to $f_2(t)$, then $\\rho_{12} = 0$, $\\overline{\\varepsilon^2}$ is maximized.\n\n* Describe the correlation of two signals from the perspective of energy difference.\n* Quantitatively measure the correlation of two signals in terms of inner product. \n\n**Correlation Function**\n\nThe similarity between one signal with a delayed version of another signal.\n\n(1) $f_1(t)$ and $f_2(t)$ are both real and energy signals\n\n$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}(-\\tau)\n$$\n\n(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals\n\nIf $f_1(t) = f_2(t) = f(t)$\n\nAutocorrelation:\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f(t)\\mathrm dt\\\\\n$$\n\n(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals\n\n$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2^*(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1^*(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}^*(-\\tau)\n$$\n\nAutocorrelation:\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f^*(t)\\mathrm dt\\\\\nR(\\tau) = R^*(-\\tau)\n$$\n\n\n(3) $f_1(t)$ and $f_2(t)$ are both real and power signals\n\n$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\nAutocorrelation\n\n$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\n(4) $f_1(t)$ and $f_2(t)$ are both complex and power signals\n\n$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2^*(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\nAutocorrelation\n\n$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$\n\n**Correlation Theorem**\n\n$$\n\\mathcal F(x(t)) = X(\\omega)\\\\\n\\mathcal F(y(t)) = Y(\\omega)\\\\\n\\mathcal F(R_{xy}(\\tau)) = X(\\omega)Y^*(\\omega)\\\\\n$$\n\nIf $x(t) = y(t)$, The FT of the autocorrelation function is $\\mathcal F[{R_{xx}(\\tau)}] = |X(\\omega)|^2$\n\nIf $y(t)$ is a real and even function: $Y^*(\\omega) = Y(\\omega)$\n\n Then the correlation theorem is equivalent to the convolution theorem\n\n$$\n\\mathcal F(\\int_{-\\infty}^\\infty x(t)y(t-\\tau)\\mathrm dt) = X(\\omega)Y(\\omega)\\\\\n$$\n\nGenerally, \n\n$$\nR_{12}(t) = f_1(t) * f_2(-t)\n$$\n\n### Energy & Power Spectral Density\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt\\\\\n$$\n\n$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2 e^{j\\omega\\tau}\\mathrm d\\omega\\\\\n|F(\\omega)|^2 = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\n$$\n$$\nR(0) = \\int_{-\\infty}^{\\infty}f(t)f^*(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt\\\\\nR(0) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\\\\\n$$\n\n$$\n\\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\n$$\n\n**Energy Spectral Density**\n\n$$\n\\mathcal{E}(\\omega) = \\lvert F(\\omega)\\rvert^2\\\\\n$$\n\n$$\n\\mathcal{E}(\\omega) = \\mathcal{F}[R(\\tau)]\\\\\nR(\\tau) = \\mathcal{F}^{-1}[\\mathcal{E}(\\omega)]\\\\\n$$\n\n**Power Spectral Density**\n\n$$\n\\mathcal F[ R(\\tau)] = \\mathcal P(\\omega)\\\\\n$$\n\nIt is called Power Spectral Density (PSD).\n\nWiener-Khinchin Theorem\n\n$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\mathcal P(\\omega)e^{j\\omega\\tau}\\mathrm d\\tau\\\\\n\\mathcal P(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\omega\\\\\n$$\n\n### ESD/PSD of the System Response\n\n$$\n|R(j\\omega)|^2 = |H(j\\omega)|^2|E(j\\omega)|^2\\\\\n\\mathcal{E}_r(\\omega) = |H(j\\omega)|^2\\mathcal{E}_e(\\omega)\\\\\n\\mathcal{P}_r(\\omega) = |H(j\\omega)|^2\\mathcal{P}_e(\\omega)\\\\\n$$\n\n![](../images/ss/lec16_1.jpg)\n\nThe last line of this table is wrong. The correct is:\n\n$$\nR_h(\\tau) = h(\\tau) * h^*(-\\tau)\n$$\n\n### Match Filters\n\n$$\nH(j\\omega) = kS(-j\\omega)e^{-j\\omega t_m}\\\\\nh(t) = ks(t_m - t)\\\\\n$$\n\n$t_m$ is the signal width in TD.\n\n## Discrete time signals\n\nDiscrete time-axis, but continuous amplitude-axis\n\n### Sequence operation\n\n**Addition** $z(n) = x(n) + y(n)$\n\n**Multiplication** $z(n) = x(n) * y(n)$\n\n**Multiplied a coefficient** $z(n) = a * x(n)$\n\n**Shift** $z(n) = x(n - m)$ right shift($m>0$), $z(n) = x(n +m)$ left shift\n\n**Reflection** $z(n) = x(-n)$\n\n**Difference** $\\Delta x(n) = x(n + 1) - x(n)$ Forawrd difference, \n\n$\\nabla x(n) = x(n) - x(n - 1)$ Backward difference\n\n$\\nabla^mx(n) = \\nabla(\\nabla^{m-1}x(n))$\n\n**Summation** $z(n) = \\sum_{k = -\\infty}^{n}x(k)$\n\n**Scaling** $z(n) = z(2n)$ squeeze, \n\n$z(n) = x(n/2)$, extend\n\n### Typical sequences\n\n![](../images/ss/lec16_2.jpg)\n\n![](../images/ss/lec16_3.jpg)\n\nRelations of several singal waveforms\n\n$$\nu(n) = \\sum_{k = 0}^{\\infty}\\delta(n - k)\\\\\n\\delta(n) = u(n) - u(n - 1)\\\\\nR_N(n) = u(n) - u(n - N)\\\\\n$$\n\n### Signal Decomposition\n\n$$\nx(n) = \\sum_{m = -\\infty}^{\\infty}x_m\\delta(n - m)\\\\\n$$\n\n$$\n\\delta(n - m) = \\begin{cases}\n1, & n = m\\\\\n0, & n \\neq m\n\\end{cases}\n$$\n\n### Difference equations\n\n![](../images/ss/lec16_4.jpg)\n\nNumerical solution of difference equations\n\nGeneral form of difference equation:\n\n$$\n\\sum_{k = 0}^N a_ky(n - k) = \\sum_{r = 0}^M b_ry(n - r)\\\\\n$$\n\n**Methods:**\n- Recursive method\n- - Intuitive, difficult to formulate the closed-form solutions\n- Time-domain classical method\n- - Obtain homogeneous and particular solutions and using the  boundary condition to determine the coefficients. \n- The sum of the zero-input and zero-state responses\n- - Convolution (next class) \n- Z-transform (Chapter 8)\n- State variable method (Chapter 11)\n\n**Homogeneous Solution**\n\n$$\n\\sum_{k = 0}^N a_ky(n - k) = 0\\\\\n$$\n\nThe **characteristic root** $\\alpha_k$ satisfies:\n\n$$\na_0\\alpha^N + a_1\\alpha^{N-1} + \\cdots + a_N = 0\\\\\n$$\n\nThe homogeneous solution is:\n\n$$\ny(n) = c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n\\\\\n$$\n\n**Particular Solutions**:\n\n![](../images/ss/lec16_.jpg)\n\n**General steps**\n\n1. Obtain homogeneous solutions from characteristic equation $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n$\n2. Determine the form of the particular solution $D(n)$\n3. The complete solution $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n + D(n)$\n4. Introduce the boundary condition and set up equations\n$$\ny(0) = C_1 +C_2 + \\cdots + C_N + D(0)\\\\\ny(1) = C_1\\alpha_1 +C_2\\alpha_2 + \\cdots + C_N\\alpha_N + D(1)\\\\\n\\vdots\\\\\ny(N - 1) = C_1\\alpha_1^{N - 1} + C_2\\alpha_2^{N - 1} + \\cdots + C_N\\alpha_N^{N - 1} + D(N - 1)\\\\\n\\Rightarrow\\\\\nY(k) - D(k) = VC\\\\\nC = V^{-1}(Y(k) - D(k))\\\\\n$$\n\n### Zero-input and zero-state responses\n\n$$\ny(k) = y_{zi}(k) + y_{zs}(k)\n$$\n\n**Zero-Input Response**\n$D(k) = 0 \\Rightarrow C_{zi} = V^{-1}Y_{zi}(k)$\n\n**Zero-State Response**\n\n$$\n\\begin{align*}\n  C_{zs} &= V^{-1}[Y_{zs}(k) - D(k)]\\\\\nC_{zs} &= V^{-1}[Y(k) - Y_{zi}(k) - D(k)]\\\\\nC &= C_{zi} + C_{zs}\\\\\n\\end{align*}\n$$\n\n**Natural Response** $\\sum_{k = 1}^NC_k\\alpha_k^n$\n\n**Forced Response** $D(n)$\n\nCharacteristics of the boundary condition for difference equations\n\nN-th order difference equation should have N independent boundary conditions.\n\nCompared with continuous systems, there are no big differences between $0_+$ and $0_-$ in discrete systems. \n\n$y(-1), y(-2), \\dots, y(-N)$ are the system memory (storage) before the excitation is added: $0_-$\n\nDerive (together with the excitation) $y(0), y(1), …, y(N-1): 0_+$\n\nUsing Z-transform can avoid mistakes－similar to the Laplace transform in continuous systems.\n\n### Impulse response of DT systems\n\nSimilar to CT System, h(n) reflects system’s property\n\n**Causality** $h(n) = h(n) u(n)$ (unlateral, $n\\lt 0$ no response)\n\n**Stability** $\\sum_{n=-\\infty}^\\infty |h(n)| \\lt \\infty$ (absolutely summable)\n\n     NOTE:  critical stability can be considered as either stable or unstable, e.g.,  system whose impulse response is a sine sequence\n\n\nNot all practical discrete systems are necessarily causal：\n\n* Variable is not time, like image processing\n* Variable is time, but data has been recorded and processed, like voice processing, meteorology, stock systems.\n\nExample: Smooth windowing\n\n$$\ny(n) = \\frac{1}{2M+1}\\sum_{k=-M}^M x(n-k)\n$$\n\nDiscrete non-causal system\n\n### Convolution Sum\n\n$$\ny(n) = \\sum_{m = -\\infty}^\\infty x(m)h(n - m) = h(n) * x(n)\n$$\n\nSimilar to CT system, also satisfies both distributive and associative laws \n\nCalculation of convolution：\nFour steps: reflection, shift, multiplication and summation. \n\nCalculation of correlation：\nCross- & auto-correlation: shift, multiplication & summation. \n\nExample:\n\n$$\nx(n) = u(n) - u(n - N)\\\\\nh(n) = a^nu(n)\\\\\ny(n) = x(n) * h(n)\n$$\n\n$$\ny(n) = \\sum_{m = -\\infty}^\\infty [u(m) - u(m - N)]a^{n - m}u(n - m)\n$$\n\nif $n < 0$, then $y(n) = 0$\n\nif $0 \\le n \\lt N - 1$, $y(n) = \\sum_{m = 0}^na^{n-m} = \\frac{1}{1 - a}[1 - a^{n+1}]$\n\nif $n \\ge N - 1$, $y(n) = \\frac{1 - a^{-N}}{1 - a^{-1}}a^n$\n\n**Deconvolution**\n\n**Signal retrieval** y(n) and h(n) are known, how to derive x(n)?\n\n*Measurement equipment (linear system), like sensor for measuring blood pressure*\n\n**System identification** y(n) and x(n) are known, how to derive h(n)?\n\n*Earthquake signal, like geological survey, oil exploration, etc.*\n\n$$\n\\begin{bmatrix*}\n   y(0)\\\\\n   y(1)\\\\\n   y(2)\\\\\n   \\vdots\\\\\n   y(n)\n\\end{bmatrix*} = \n\\begin{bmatrix*}\n  h(0) & 0 & 0 & \\dotsb & 0\\\\\n  h(1) & h(0) & 0 & \\dotsb & 0\\\\\n  h(2) & h(1) & h(0) & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  h(n) & h(n-1) & h(n-2) & \\dotsb & h(0)\\\\\n\\end{bmatrix*}\\begin{bmatrix*}\n   x(0)\\\\\n   x(1)\\\\\n   x(2)\\\\\n   \\vdots\\\\\n   x(n)\n\\end{bmatrix*}\n$$\n\nThus, \n\n$$\nx(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} x(m) h(n - m)\\right]/h(0)\\\\\nh(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} h(m) x(n - m)\\right]/x(0)\n$$\n\n### Important Concepts\n\n![](../images/ss/lec17_1.jpg)\n\n1. Symbol rate :  clock period is $T$, signal symbol rate is $f = 1/T$.\n2. Information rate: information rate equals to symbol rate for binary encoding, otherwise, equal to multiplication between symbol rate and number of information bits per symbol.\n3. Signal bandwidth: the first zero of non-return-to-zero (NRZ) signal’s spectrum is $1/T$,  so the signal bandwidth is $B=1/T =f$.\n\n> 这句话是在介绍非归零码（Non-Return-to-Zero，简称NRZ）信号的带宽计算方式。\n> \n> 在信号处理和通信中，信号的频谱表示了信号在不同频率上的能量分布。对于一个NRZ信号，它的频谱图中第一个零点（也就是在零周围出现的第一个极小值点）出现在频率为$1/T$处，其中$T$是NRZ信号中一个脉冲的时间长度。这是因为NRZ信号的频谱是由一个周期为$T$的方波产生的，其频率成分只包含正弦函数的奇次谐波。其中，最低的一个谐波频率是$f=\\frac{1}{T}$，对应的是频率为$f$的正弦波。所以，NRZ信号的带宽$B$就被定义为$f=1/T$。\n> \n> 简而言之，NRZ信号的带宽是由脉冲的时间长度决定的，具体来说，带宽等于脉冲频率的一半，即带宽等于$f=1/T$。\n\nNOTE:\n\nWhen NRZ code is used, signal bandwidth = symbol rate\n\nWhen return-to-zero (RZ) code is used, signal bandwidth > symbol rate\n\nUsing NRZ code can save bandwidth yet high frequency components of the rectangular signal will suffer from the severe inter-symbol interference (ISI). So the raised cosine or Sa function is preferred.\n> ChatGPT:\n> \n> 归零码和非归零码都是数字通信中常用的编码方式。\n> \n> 归零码（Return-to-Zero，简称RZ）是一种二进制码，其中一个信号所代表的位是由一个脉冲表示的。发送二进制“1”时，脉冲电平为高电平，发送二进制“0”时，脉冲电平为低电平。在归零码中，一个信号位所代表的脉冲之后，信号在下一时刻会回到零电平。由于归零码中每个脉冲结束时信号回到零电平，因此这种编码方式具有稳定可靠的特点，但是传输的带宽相对较大。\n> \n> 非归零码（Non-Return-to-Zero，简称NRZ）的编码方式与归零码不同之处在于，在NRZ信号中，一个信号所代表的位是由一个固定电平表示的。当信号所代表的位是二进制“1”时，固定电平为高电平；当信号所代表的位是二进制“0”时，固定电平为低电平。这种编码方式的好处是带宽更小，但是却存在着在多个二进制“1”连续发送时，出现误解的情况。\n> \n> 综上所述，归零码是二进制码中脉冲与幅度的双重编码，不易产生传输误码，但其对于通信带宽需求较大；而非归零码不需要对脉冲进行编码，在带宽方面具有一定的优势，但长时间连续发送相同信息时会产生误解。\n\n### Z-Transform\n\nSimilar to the L-Tranform.\n\n**Definition**\n\n$$\nX(z) = Z(x(n)) = \\sum_{n = -\\infty}^{\\infty} x(n) z^{-n}\n$$\n\n**Z-T of Typical Series**\n\n$z \\in \\Complex$\n\n$$\n\\delta(n) \\rightarrow 1\\\\\nu(n) \\rightarrow \\frac{1}{1-z^{-1}}(|z| \\gt 1)\\\\\nnu(n) \\rightarrow \\frac{z^{-1}}{(1-z^{-1})^2}(|z| \\gt 1)\\\\\na^n u(n) \\rightarrow \\frac{1}{1-az^{-1}}(|z| \\gt |a|)\\\\\n\\cos(\\omega_0 n) u(n) \\rightarrow \\frac{1-z^{-1}\\cos(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n\\sin(\\omega_0 n) u(n) \\rightarrow \\frac{z^{-1}\\sin(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n$$\n\n**The Region of Convergence**\n\n![](../images/ss/lec18_1.jpg)\n\n**Inverse Z-Transform**\n\n$$\nx(n) = \\frac{1}{2\\pi j} \\oint_C X(z) z^{n-1} dz\n$$\n\n**Method**\n\n**Contour Integration(residue method)**\n\nRight-sided sequence\n\n$$\nx(n) = \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$\n\nLeft-sided sequence\n\n$$\nx(n) = - \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$\n\n**Power series expansion(Long division)**\n\n![](../images/ss/lec18_2.jpg)\n\nIf it is right sided, \n\n$$\nX(z) = \\sum_{n = 0}^\\infty x(n)z^{-n}\n$$\n\nIf it is left sided,\n\n$$\nX(z) = \\sum_{n = -\\infty}^{-1}x(n)z^{-n}\n$$\n\n**Partial Fraction Expansion**\n\n$$\n\\frac{z}{z - a} \\lrarr \\begin{cases}\n a^nu(n), &|z|\\gt |a|\\\\\n -a^nu(-n-1), &|z|\\lt |a|\n\\end{cases}\n$$\n\n![](../images/ss/lec18_3.jpg)\n\n\n![](../images/ss/lec18_34jpg.jpg)\n\n![](../images/ss/lec18_6.jpg)\n\n**Properties of Z-T**\n\n**Linearity**\n\nAddition and homogeneity\n\n<font color=\"red\">ROC may change!</font>\n\ni.e. poles are cancelled when added: ROC will enlarge or and shrink.\n\n**Time shifting**\n\n(a) bilateral: If $\\mathcal Z[x(n)] = X(z), R_{X_1} < |z| < R_{X_2}$, then $\\mathcal{Z}[x(n-m)] = z^{-m}X(z), R_{X_1} < |z| < R_{X_2}$.\n\n(b) unilateral: if $\\mathcal{Z}[x(n)] = X(z), R_{X_1} < |z|$, then $\\mathcal{Z}[x(n-m)] = z^{-m}[X(z) + \\sum_{k = -m}^{-1}x(k)z^{-k}], R_{X_1}\\lt |z|$, and $\\mathcal{Z}[x(n+m)] = z^{m}[X(z) - \\sum_{k = 0}^{m-1}x(k)z^{-k}], R_{X_1}\\lt |z|$\n\nFor casual sequence, $n < 0, x(n) = 0$, the unilateral is also $\\mathcal{Z}[x(n-m)] = z^{-m}X(z)$.\n\nThe reason is that the unilateral z transform doesn't contain the $n<0$ parts of sequence, but after shifting, sometimes must be counted(right shift), sometimes must be discarded(left shift).\n\n**Linear weighting on sequence(Z domain differentiation)**\n\n$$\n\\mathcal{Z}[x(n)] = X(z) \\Rightarrow nx(n)\\lrarr -z\\frac{dX(z)}{dz}\n$$\n\nGeneralization:\n\n$$\nn^mx(n)\\lrarr \\bigg[-z\\frac{d}{dz}\\bigg]^m X(z)\n$$\n\n**Geometric progression(Z-domain scaling)**\n\n$$\na^n(x^n) \\lrarr X(\\frac{z}{a})\\\\\n(R_{x1} \\lt \\bigg|\\frac{z}{a}\\bigg| \\le R_{x2})\n$$\n\n$$\na^{-n}x(n) \\lrarr X(az)\\\\\n(-1)^nx(n) \\lrarr X(-z)\n$$\n\n**Initial-value theorem**\n\n$$\nx(0) = \\lim_{z \\rightarrow \\infty }X(z)\n$$\n\n**Final-value theorem**\n\n$$\n\\lim_{n \\rightarrow \\infty } x(n) = \\lim_{z \\rightarrow 1}[(z-1)X(z)]\n$$\n\ncondition: when $n \\rightarrow \\infty$, $x(n)$ converge \n\nThus, the poles of $X(z)$ are inside the unit circle, the radius of ROC is less than 1.\n\nFor $a^nu(n), |a| \\lt 1$, the final value is 0.\n\nOr, if the pole is on the unit circle, it should be 1, and is of the 1st order.\n\n$u(n)$'s final value is 1.\n\n![](../images/ss/lec19_1jpg.jpg)\n\n**Time-domain convolution theorem**\n\nIf $\\mathcal{Z}{x(n)} = X(z), (R_{x1} \\lt |z| \\lt R_{x2}), \\mathcal{Z}{h(n)} = H(z), (R_{h1} \\lt |z| \\lt R_{h2})$\n\n$$\n\\mathcal{Z}[x(n) * h(n)] = X(z)H(z)\\\\\n\\max(R_{x1}, R_{h1}) \\lt |z| \\lt \\min(R_{x2}, R_{h2})\n$$\n\nIf poles are cancelled in multiplication, ROC is enlarged.\n\nConclusion: (Z Transform) convolution in time-domain is equivalent to multiplication (of Z Transform) in Z-domain.\n\n**Z domain convolution theorem**\n\n$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(\\frac{z}{v})H(v)v^{-1}dv\n$$\n\nor \n\n$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(v)H(\\frac{z}{v})v^{-1}dv\n$$\n\nwhere $C$ is a closed contour in the intersection of ROCs of $X(\\frac{z}{v})$ and $H(v)$ or $X(v)$ and $H(\\frac z v)$.\n\nlet $v = \\rho e^{j\\theta}, z = r e^{j\\varphi}$, \n\nthen \n\n$$\n\\mathcal Z[x(n)h(n)] = \\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(\\rho e^{j\\theta})H(\\frac r\\rho e^{-j(\\varphi - \\theta)})d\\theta\n$$\n\n### Mapping of ZT and LT\n\n$$\nz = e^{sT} ,\\omega_s = \\frac{2\\pi}{T}\n\\\\\nre^{j\\theta} = e^{(\\sigma + j\\omega)T}\\\\\n$$\n\nthen, \n\n$$\nr = e^{\\sigma T} = e^{2\\pi\\frac{\\sigma}{\\omega_s}}\\\\\n\\theta = \\omega T = 2\\pi\\frac{\\omega}{\\omega_s}\n$$\n\nwhen $\\sigma$ is constant, \n\nvertical line in $s$-plane maps the circle in $z$-plane.\n\n$s$-plane imaginary axis maps the unit circle in $z$-plane.\n\nwhen $\\omega$ is constant,\n\n![](../images/ss/lec19_2jpg.jpg)\n\n**Correspondence of ZT and LT**\n\n![](../images/ss/lec19_3.jpg)\n\n### Solving difference equation by Z-T\n\n$$\n\\sum_{k = 0}^N a_ky(n-k) = \\sum_{r = 0}^M b_rx(n-r)\n$$\n\nTwo methods:\n\n* TD method\n* Z-T method (notice the ROC)\n\n**ZT method**\n\n1. perform unilateral Z-T on both sides.\n\n$x(n-r), y(n-k)$ are both right shifted series\n\n$$\n\\sum_{k = 0}^N a_kz^{-k}[Y(z) + \\sum_{l = -k}^{-1}y(l)z^{-l} ]= \\sum_{r = 0}^M b_rz^{-r}[X(z) + \\sum_{m = -r}^{-1}x(m)z^{-m} ]\n$$\n\n2. Derive $Y(z)$\n3. Perform inverse transform on $Y(z)$ to get $y(n)$(ROC!)\n\n**Zero input response**\n\n$$\nx(n) = 0\\\\\nY(z) = \\frac{-\\sum_{k = 0}^M[a_kz^{-k}\\cdot \\sum_{l = -k}^{-1}y(l)z^{-l}]}{\\sum_{k = 0}^Na_kz^{-k}}\n$$\n\n**Zero state response**\n\n$$\ny(l) = 0\\\\\n\\text{ casual sequence }: x(m) = 0\\\\\n\\sum_{k = 0}a_kz^{-k}Y(z) = \\sum_{r = 0}^M b_rz^{-r}X(z)\\\\\nY(z) = X(z)\\cdot\\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}} = X(z)\\cdot H(z)\n$$\n\n### System function of DT system\n\n**Unit Impulse/sample response $h(n)$ and system function H(z)**\n\n$$\ny(n) = x(n) * h(n)\\\\\nY(z) = H(z)\\cdot X(z)\n$$\n\n$$\nH(z) = \\frac{Y(z)}{X(z)} = \\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}}\n$$\n\nFactorization\n\n$$\nH(z) = \\frac{\\prod_{r = 1}^M(1-z_rz^{-1})}{\\prod_{k=1}^N1-p_kz^{-1}}\n$$\n\nWe can draw the conclusions directly from the relationship between Z-T and L-T\n\n||||||\n|----|----|----|----|----|\n| Imaginary axis | $\\sigma=0$ | Constant amplitude | $r = 1$ | Unit circle |\nRight half plane |  | | | \nLeft half plane\nReal axis\n\n![](../images/ss/lec20_1.jpg)\n\n![](../images/ss/lec20_2.jpg)\n\n**Stability and Causality**\n\nStable: iff\n\n$$\n\\sum_{n=-\\infty}^\\infty |h(n)|\\lt \\infty\n$$\n\n$$\nz = 1, H(z) = \\sum_{n=-\\infty}^\\infty h(n)\\lt \\infty\n$$\n\nThe condition is ROC of stable system includes the unit circle.\n\nCausal:\n\n$$\nh(n) = h(n)u(n)\n$$\n\nCondition is ROC includes $\\infty$: $R_{X_1}\\lt |z|$\n\n**Stable and causal**\n\n$$\na\\le |z| \\le \\infty, a\\le 1\n$$\n\n### Discrete-time Fourier Transform(DTFT)\n\n**Definition**\n\n$$\n\\mathcal{F}[x(t)\\delta_T(t)] = \\int_{-\\infty}^\\infty x(t)\\delta_T(t)e^{-j\\omega t}dt = \\sum_{n=-\\infty}^\\infty x(nT)e^{-j\\omega nT}\n$$\n\ntake $T = 1$\n\n$$\n\\sum_{n=-\\infty}^\\infty x(n)e^{-j\\omega n} = \\text{DTFT[x(n)]}\n$$\n\nThe relation ship with Z-T:\n\n$$\nX(z) = \\sum_{n = -\\infty}^\\infty x(n)z^{-n}, z = e^{j\\omega}\\\\\n$$\n\n$$\nDTFT[x(n)] = X(z)|_{|z|=1} = X(z)|_{z = e^{j\\omega}} = X(e^{j\\omega})\n$$\n\nInverse transform\n\n$$\nx(n) = \\frac{1}{2\\pi j}\\oint_{|z| = 1}X(z)z^{n-1}\\mathrm dz=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$\n\n### Frequency Response of DT system\n\nThe steady-state response to sine sequence\n\n$$\nx(n) = A\\sin(n\\omega)(n\\ge 0)\\\\\ny_{ss}(n) = A|H(e^{j\\omega})|\\sin(n\\omega + \\varphi)\\\\\nH(e^{j\\omega}) = \\sum_{n=-\\infty}^\\infty h(n)e^{-jn\\omega}\n$$\n\nThe FT of $h(n)$, $H(e^{j\\omega})$ is a periodic function with period of $\\omega_s = 2\\pi /T = 2\\pi$.\n\nIf $h(n)$ is real, then the amplitude/phase response is even/odd function.\n\nThe amplitude is determined within $[0, \\omega_s/2]$\n\n![](../images/ss/lec20_3.jpg)\n\n![](../images/ss/lec20_4.jpg)\n\nNOTE:\n\n* We can derive the frequency response (function of $\\omega$) by letting $D$ move along the unit circle once.\n* $H(j\\omega)$ is periodic. The frequency response from 0 to $\\omega_s/2$ can be determined by letting $D$ move along half circle.\n* If pole $p_i$ is close to the unit circle, there will be a peak in the frequency response. If zero $z_i$ is close to the unit circle, there will be a notch in the frequency response.\n* For statble systems, $p_i$ should be inside the unit circle, while $z_i$ could be inside or outside the unit circle.\n* poles and zeros at origin have no influence on amplitude.\n\n### Analog and digital Filter\n\n**Fundamental Principles**\n\n![](../images/ss/lec20_5.jpg)\n\nThe spectrum of $x(t)$ is strictly inside $\\pm \\omega_m$.\n\nWe choose the sampling frequency:$\\omega_s = \\frac{2\\pi}{T} \\ge 2\\omega_m$\n\n![](../images/ss/lec20_6.jpg)\n\n**Classifications of digital filters**\n\n$$\ny(n) = \\sum_{k=0}^M b_kx(n-k) - \\sum_{k=1}^N a_ky(n-k)\n$$\n\nIn terms of structure\n\nrecursive: $a_k\\ne 0$ at least for one $k$\n\nnon-recursive: $a_k=0$, for all $k$\n\nIn terms of the characteristics of $h(n)$\n\nInfinite impulse response(IIR): recursive, non-linear phase\n\nFinite impulse response(FIR): non-recursive, linear phase.\n\n**IIR filter**\n\nImpulse invariance\n\nBased on the s-domain analog filters.\n\nDesign method 1: **冲激响应不变法**\n\nReplace $\\frac{1}{s-s_k}$ with $\\frac{1}{1-e^{s_kT}z^{-1}}$. Then $H_a(s)$ become $H(z)$.\n\nThe relationship between the continuous and discrete filters:\n\n$$\nH(z)|_{z = e^{sT}} = \\frac{1}{T}\\sum_{k=-\\infty}^\\infty H_a(s + j\\frac{2\\pi}{T}k)\n$$\n\nThe result is just repeat the original filter at sampling frequency, thus it attenuates slower.\n\nNOTE:The digital filter implemented this way has aliasing.\n\nThe frequency response of analog filter must be attenuated enough within $\\omega_s$.\n\nThis approach can only realize LP and BP filter, but not HP and band-stop one. \n\n**method 2: Bilinear transformation** emerges to address this problem (you can study it by yourself)\n\n$$\ns = \\frac{2}{T}\\left(\\frac{1 - z^{-1}}{1 + z^{-1}}\\right)\\\\\nz = \\frac{1 + \\frac{sT}{2}}{1 - \\frac{sT}{2}}\n$$\n\nBilinear transformation is non-linear transformation.\n\nTo implement digital filter, A/D and D/A are required, along with ROM, RAM, ALU, delay units (shift registers), etc.\n\n\n**FIR filter**\n\n$$\nH(z) = \\sum_{k = 0}^{N-1}b_kz^{-k} = \\sum_{n=0}^{N-1}h(n)z^{-n}\n$$\n\nPoles are at $z=0$. $N - 1$ zeros.\n\nFIR filter has linear-phase iff\n\n$$\nh(n) = h(N - 1 - n)(\\text{evenly symmetric})\\\\\nh(n) = -h(N - 1 - n)(\\text{oddly symmetric})\n$$\n\n![](../images/ss/lec20_7.jpg)\n\n![](../images/ss/lec20_8.jpg)\n\n### Feedback System: Signal Flow Graphs\n\n**Operator and Transfer Operator:**\n\n$$\np = \\frac{d}{dt}\\\\\n\\frac{1}{p} = \\int_{-\\infty}^t(\\cdot)d\\tau\n$$\n\n$$\n(C_0p^n + C_1p^{n-1} + \\dotsb + C_n)r(t) = (E_0p^m + E_1p^{m - 1} + \\dotsb + E_m)e(t)\\\\\nD(p)r(t) = N(p)e(t)\n$$\n\nRules:\n\n* Common factors can't be eliminated.\n* Be careful when changing the order of operation($\\frac{d}{dt}\\int_{-\\infty}^tx(\\tau)d\\tau = x(t)$, $\\int_{-\\infty}^t\\frac{d}{d\\tau}x(\\tau)d\\tau = x(t) - x(-\\infty)$)\n\ntransfer operator:\n\n$$\nr(t) = \\frac{N(t)}{D(t)}e(t) = H(p)e(t)\n$$\n\n**Brief introduction to the signal flow graphs(SFG)**\n\n![](../images/digital/lec_11_1.jpg)\n\n![](../images/ss/lec21_4.jpg)\n\nTerminnologies in SFG\n\nNode, Transfer function, Branch(The branch gain is the transfer function), Source node, Sink node, Mixed node.\n\n**Properties of SFG**\n\n1. Signal only passes through a branch with the direction indicated by the arrowhead.\n2. Signals of incoming branches are added at a node, and the added signal appears on the all outgoing branches.\n3. A sink node can be separated from a mixed node.\n4. For a given system, the SFGs can be different.(equations for a system can be different)\n5. After the SFG being inversed, the transfer function keeps invariant, but the signals represented by the inner nodes will be different.\n\n\nNote: Inversion is done by inversing the transfer direction of each branch, and exchanging the source and sink nodes as well.\n\nAlgebra of SFG\n\n![](../images/ss/lec21_5.jpg)\n\n![](../images/ss/lec21_6.jpg)\n\nSimplify:\n\nNOTE: The SFG can be simplified using the following steps:\n\na. Merge the cascaded branches to decrease the number of nodes;\n\nb. Merge the parallel branches to decrease the number of branches;\n\nc. Eliminate all the loops. \n\nThen, the system function can be readily derived.\n\n![](../images/ss/lec21_7.jpg)\n\n**Mason's Formula**\n\n$$\nH = \\frac{1}{\\Delta} \\sum_k g_k\\Delta_k\n$$\n![](../images/ss/lec21_9.jpg)\n\n## State-variable analysis of system\n\n$$\n\\mathbf {\\lambda = A\\lambda + Be}\\\\\n\\mathbf{r = C\\lambda + De}\n$$\n\nFeatures of the state-variable analytical method \n\n* (1)Provide internal characteristics of the system\n* (2) Convenient to represent and analyze the multi-input, multi-output (MIMO) cases\n* (3) Easy to be extended to time-variant or nonlinear cases\n* (4) Introduce two important concepts: controllability and observability\n* (5) Convenient for numerical computation\n\n### General form and setup method (CT)\n\n$$\n\\frac{d}{dt}\\mathbf{\\lambda}(t)_{k \\times 1} = \\mathbf{A}_{k \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{B}_{k \\times m}\\mathbf{e}(t)_{m \\times 1}\\\\\n\\mathbf{r}(t)_{r \\times 1} = \\mathbf{C}_{r \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{D}_{r \\times m}\\mathbf{e}(t)_{m \\times 1}\n$$\n\n$r$ responses, $k$ state variables, $m$ inputs.\n\nFor time-variant system, $\\mathbf{A, B, C, D}$ are fuction of $t$.\n\nDirect methods:\n* observation\n* Topological analysis\n\nUsed in curcuit analysis.\n\nIndirect methods:\n* From block diagram or flow graph\n* From input-output equation\n* From transfer function\n\nUsed in controlled system analysis.\n\n**From input-output equation**\n\n$$\n\\frac{r(t)}{e(t)} = \\frac{b_0p^k + \\dotsb + b_k}{p^k + \\dotsb + a_k}\n$$\n\nNOTE : under the zero-state condition, $p$ is equivalent to $s$ \n\n$$\nH(p) = \\frac{b_0 + b_1p^{-1} + \\dotsb + b_kp^{-k}}{1 + a_1p^{-1} + \\dotsb + a_kp^{-k}}\n$$\n\nThe SFG is:\n\n![](../images/ss/lec22_11.jpg)\n\n$$\n\\dot{\\lambda}_1 = \\lambda_2\\\\\n\\dot{\\lambda}_2 = \\lambda_3\\\\\n\\vdots\\\\\n\\dot{\\lambda}_k = -a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t)\\\\\nr(t) = b_k\\lambda_1 + b_{k-1}\\lambda_2 + \\dotsb + b_1\\lambda_k + b_0(-a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t))\\\\\n=(b_k - a_kb_0)\\lambda_1 + (b_{k-1} - a_{k-1}b_0)\\lambda_2 + \\dotsb + (b_1 - a_1b_0)\\lambda_k + b_0e(t)\n$$\n\n$$\n\\mathbf A = \\begin{bmatrix}\n  0 & 1 & 0 & \\dotsb & 0\\\\\n  0 & 0 & 1 & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  0 & 0 & 0 & \\dotsb & 1\\\\\n  -a_k & -a_{k-1} & -a_{k-2} & \\dotsb & -a_1\n\\end{bmatrix}\\\\\nB = \\begin{bmatrix}\n  0\\\\\n  0\\\\\n  \\vdots\\\\\n  0\\\\\n  1\n\\end{bmatrix}\\\\\n\\mathbf C = \\begin{bmatrix}\n  b_k - a_kb_0 & b_{k-1} - a_{k-1}b_0 & \\dotsb & b_1 - a_1b_0\n\\end{bmatrix}\\\\\nD = b_0\n$$\n\nIf  the order of differential equation on the left side is higher than that on the right side:\n\n$$\nb_0 = 0, \\mathbf{D} = 0\n$$\n\nIf the derivatives of the excitation on the right side are absent,\n\n$$\n\\mathbf{C} = [b_k, 0, \\dotsb, 0], \\mathbf{D} = 0\n$$\n\n**Factorizing Transfer operator**\n\n![](../images/ss/lec22_12.jpg)\n\n![](../images/ss/lec22_13.jpg)\n\n![](../images/ss/lec22_14.jpg)\n\n![](../images/ss/lec22_15.jpg)\n\n![](../images/ss/lec22_16.jpg)\n\n![](../images/ss/lec22_17.jpg)\n\n![](../images/ss/lec22_18.jpg)\n\n### Solving CT system's state equations\n\n**Time domain method** using computer.\n\n**Transform-domain(Laplace-tranform) method**\n\n$$\n\\frac{d}{dt}\\mathbf{}{\\lambda}(t) = \\mathbf{A\\lambda}(t) + \\mathbf{Be}(t)\\\\\n\\mathbf{r}(t) = \\mathbf{C\\lambda}(t) + \\mathbf{De}(t)\\\\\n\\mathbf{\\lambda}(0_-) = \\begin{bmatrix}\n\\lambda_1(0_-)\\\\\n\\lambda_2(0_-)\\\\\n\\vdots\\\\\n\\lambda_k(0_-)\\\\\n\\end{bmatrix}\n$$\n\n$$\ns\\mathbf \\Lambda(s) - \\mathbf{\\lambda}(0_-) = \\mathbf{A\\Lambda}(s) + \\mathbf{BE}(s)\\\\\n\\mathbf{R}(s) = \\mathbf{C\\Lambda}(s) + \\mathbf{DE}(s)\n$$\n\n$$\n\\mathbf{\\Lambda}(s) = (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{BE}(s)\\\\\n\\mathbf R(s) =\\mathbf{C} (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (\\mathbf C(s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{B + D)E}(s) \n$$\n\nLet $\\Psi(s) = (s\\mathbf I - \\mathbf A)^{-1}$, which is called **characteristic matrix**.\n\n$$\n\\mathbf\\lambda(t) = \\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\mathcal{L}^{-1}[\\Psi(s)\\mathbf{B}] * e(t)\\\\\n\\mathbf r(t) = \\mathbf{C}\\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\lbrace\\mathbf{C}\\mathcal{L}^{-1}[\\mathbf\\Psi(s)\\mathbf{B] + D}\\delta(t)\\rbrace * e(t)\n$$\n\n**Time-domain method**\n\n$$\ne^{\\mathbf At} = \\sum_{k = 0}^\\infty \\frac{1}{k!}A^kt^k\n$$\n\nproperties\n\n$$\ne^{\\mathbf At}e^{-\\mathbf At} = \\mathbf I\\\\\ne^{\\mathbf At} = [e^{-\\mathbf At}]^{-1}\\\\\n\\frac{d}{dt}e^{\\mathbf At} = \\mathbf Ae^{\\mathbf At} = e^{\\mathbf At} \\mathbf A\\\\\n$$\n\n$$\n\\frac{d}{dt}\\mathbf \\lambda(t) = \\mathbf A\\mathbf \\lambda(t) + \\mathbf B\\mathbf e(t)\\\\\ne^{-\\mathbf At}\\frac{d}{dt}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf A\\mathbf \\lambda(t) + e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\frac{d}{dt}e^{-\\mathbf At}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\lambda(t) = e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\int_0^te^{\\mathbf A(t - \\tau)}\\mathbf B\\mathbf e(\\tau)d\\tau\\\\\n=e^{\\mathbf At}\\lambda(0_-) + e^{\\mathbf At} \\mathbf B * \\mathbf e(t)\n$$\n\noutput\n\n$$\n\\mathbf r(t) = \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\mathbf C e^{\\mathbf At} \\mathbf B * \\mathbf e(t) + \\mathbf D\\mathbf e(t)\\\\\n= \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + [\\mathbf C e^{\\mathbf At} \\mathbf B + \\mathbf D\\delta(t)] * \\mathbf e(t)\n$$\n\nCorrespond to LT:\n\n$$\n\\mathcal{L}[e^{\\mathbf At}] = (s\\mathbf I - \\mathbf A)^{-1}\n$$\n\n**Derive System Functions**\n\n![](../images/ss/lec22_19.jpg)\n\n![](../images/ss/lec22_20.jpg)\n\n### That for DT system\n\n**State equation setup**\n\n$$\n\\begin{align*}\n  \\mathrm\\lambda(n + 1) &= \\mathbf A\\mathrm\\lambda(n) + \\mathbf B\\mathrm x(n)\\\\\n  \\mathrm y(n) &= \\mathbf C\\mathrm\\lambda(n) + \\mathbf D\\mathrm x(n)\n\\end{align*}\n$$\n\nSolving:\n\n$$\n\\lambda(n) = \\underbrace{A^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}A^{n-1-i}Bx(i)\\right]u(n-1)}_{\\text{Zero State}}\\\\\ny(n) = \\underbrace{CA^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}CA^{n-1-i}Bx(i)\\right]u(n-1) + Dx(n)u(n)}_{\\text{Zero State}}\n$$\n\nThe Impulse response is:\n\n$$\nh(n) = CA^{n-1}Bu(n-1) + D\\delta(n)\n$$\n\nCalculate $A^n$: Cayley-Hamilton Theorem\n\n**ZT Solution**\n\n$$\n\\begin{align*}\n  z\\mathrm\\Lambda(z) - z\\lambda(0) &= \\mathbf A\\mathrm\\Lambda(z) + \\mathbf B\\mathrm X(z)\\\\\n  \\mathrm Y(z) &= \\mathbf C\\mathrm\\Lambda(z) + \\mathbf D\\mathrm X(z)\n\\end{align*}\n$$\n\n$$\n\\mathrm \\Lambda(z) = (z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + (z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\mathrm X(z)\\\\\n\\mathrm Y(z) = \\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + \\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right]\\mathrm X(z)\n$$\n\nthen \n\n$$\n\\lambda(n) = \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\\\\\ny(n) = \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\n$$\n\nComparing this with CT solution, we find\n\n$$\nA^n = \\mathcal{Z}^{-1}\\left[(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\right]\\\\\n$$\n\n$$\nH(z) = C(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\mathbf B + D\n$$\n\n### Linear Transform on state vectors\n\n$$\n\\mathbf{\\gamma} = \\mathbf P\\mathbf \\lambda\n$$\n\nThe equations become:\n\n$$\n\\frac{d}{dt}\\gamma(t) =\\mathbf{PAP}^{-1}\\mathbf \\gamma(t) + \\mathbf{PB}e(t)\\\\\n\\mathbf y(t) = \\mathbf {CP}^{-1}\\gamma(t) + \\mathbf D\\mathbf e(t)\n$$\n\nSimilarity transform doesn't change the eigenvalues.\n\n**Transform function matrix keeps invariant under linear transformation.**\n\nWe can **diagonalize** the matrix A.\n\nCalculate eigenvalues $\\alpha$ -> calulate eigenvectors $\\xi$ -> $\\mathbf P^{-1} = [\\xi_i]$, $\\hat A = \\text{diag}(\\alpha_i)$\n\n### Controllable & Observable\n\nControllable is \n\n$$\n\\text{rank} [A\\ AB\\ \\dots\\ A^{k-1}B] \\text{ is full}\n$$\n\nUncontrollabilty is the input can't change the response.\n\nObeservability is \n\n$$\n\\text{rank} \\begin{bmatrix}\n  C\\\\\n  CA\\\\\n  \\vdots\\\\\n  CA^{k-1}\n  \\end{bmatrix}\n  \\text{ is full}\n$$\n\nUnobserverbility is the response is not affected by the input.\n\nAfter the diagonalization of A: \n\nB doesnt contain zero $\\Leftrightarrow$ completely controllable. Otherwise, the 0s is coresponding to the uncontrollable state variables.\n\nC doesnt contain zero $\\Leftrightarrow$ completely observable. Otherwise, the 0s is coresponding to the unobservable state variables.\n\nIn fact:\n\n$$\nH(s) = C(s\\mathbf I - \\mathbf A)^{-1}\\mathbf B + D \\stackrel{D = 0}{=} \\sum_{i=1}^n \\frac{C_iB_i}{s - \\alpha_i}\n$$\n\nThe $H(s)$ only contains the controllable and observable state variables. So the state and output equations contains more information than the $H(s)$.\n\n![](../images/ss/lec23_1.jpg)\n\n## CDMA\n\nUse a set of orthogonal codes to support multiple users by orthorgonal multiplexing.\n\n### Example\n\nAssume K users need to connect with the base station simultaneously for CDMA system.\n\n1. Design a set of orthogonal codes\n2. Design on the transmitter\n3. Design on the receiver\n\nAn example of Code 4:\n\n$$\n\\begin{align*}\n  \\mathbf c_1 &= [1\\ 1\\ 1\\ 1\\ -1\\ -1\\ -1\\ -1]\\\\\n  \\mathbf c_2 &= [1\\ 1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1]\\\\\n  \\mathbf c_3 &= [1\\ -1\\ 1\\ -1\\ 1\\ -1\\ 1\\ -1]\\\\\n  \\mathbf c_4 &= [1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1\\ 1]\n\\end{align*}\n$$\n\n$$\nR_{x, y}(j) = \\begin{cases}\n  \\sum_{k = 0}^{N - 1 - j} x(k)y(k + j), &0 \\le j \\le N - 1\\\\\n  \\sum_{k = 0}^{N - 1 + j} x(k - j)y(k), &-N + 1 \\le j \\le 0\\\\\n  0, & |j| \\ge N\n\\end{cases}\n$$\n\nMust satisfy:\n\n$$\nR_{k, i}  \\begin{cases}\n  =T, &k = i, \\tau=0\\\\\n  \\ll T, &k \\ne i \\text{ or } \\tau \\ne 0\n  \\end{cases}\n$$\n\nsecond:\n\n(1) frequency shifting: $d_k(t)\\cos(\\omega t)$\n\n(2) spreading: $s_k(t) = d_k(t)c_k(t)\\cos(\\omega t)$\n\nthird: coherent detection/de-spreading\n\nCore:\n\n* Orthogonal code design(signal design)\n* Code capturing and tracking(signal processing and system design)\n* Multi-use  detection and channel estimation(singal processing and system design)\n\n### Code design\n\nrequirements:\n\n* sharp auto-correlation curve\n* zero cross-correlation\n* largest possible orthogonal code set\n* highest possible complexity for security performance\n\nCommonly used codes:\n\n* Walsh code\n* PN sequence\n* GOLD codes\n\n$$\nH_1 = (0)\\\\\nH_2 = \\begin{pmatrix}\n  H_1 & H_1\\\\\n  H_1 & \\overline{H_1}\n\\end{pmatrix} = \\begin{pmatrix}\n  0 & 0\\\\\n  0 & 1\n\\end{pmatrix}\\\\\nH_4 = \\begin{pmatrix}\n  H_2 & H_2\\\\\n  H_2 & \\overline{H_2}\n  \\end{pmatrix}\n$$\n\n* sliding window capturing\n* multiple correlators to detect phase match\n\nThe period of address code is much shorter than the period of data code: $T_c < T_d$, so the modulated signal is much wider in FD, whose spectrum is called **spread spectrum**.","slug":"Signal-and-Systems","published":1,"updated":"2024-03-19T06:01:16.162Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhy000krsug67af63bt","content":"<p>March 15</p>\n<h2 id=\"Basic\"><a href=\"#Basic\" class=\"headerlink\" title=\"Basic\"></a>Basic</h2><h3 id=\"Classification\"><a href=\"#Classification\" class=\"headerlink\" title=\"Classification\"></a>Classification</h3><p>Deterministic &amp; random</p>\n<p>Periodic&#x2F;non-periodic</p>\n<p>Continuous&#x2F;Discrete(time)</p>\n<p>Analog&#x2F;Digital(Amplitude &amp; time)</p>\n<h3 id=\"Operations\"><a href=\"#Operations\" class=\"headerlink\" title=\"Operations\"></a>Operations</h3><p>Shifting</p>\n<p>Reflection</p>\n<p>Scaling</p>\n<p>Diffrential</p>\n<p>Integral</p>\n<p>Addition</p>\n<p>Multiplication</p>\n<p>Convolution</p>\n<div>$$\nf_1(t) * f_2(t) = \\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$</div>\n\n<h3 id=\"Singularity-Signals\"><a href=\"#Singularity-Signals\" class=\"headerlink\" title=\"Singularity Signals\"></a>Singularity Signals</h3><h4 id=\"Unit-ramp-function\"><a href=\"#Unit-ramp-function\" class=\"headerlink\" title=\"Unit ramp function\"></a>Unit ramp function</h4><div>$$\nR(t) = 0, t\\lt 0; t, t>0\n$$</div>\n\n<h4 id=\"Unit-step-function\"><a href=\"#Unit-step-function\" class=\"headerlink\" title=\"Unit step function\"></a>Unit step function</h4><div>$$\nu(t) = 0, t<0;1/2, t=0;1, t>0\n$$</div>\n\n<h4 id=\"Rectangular-pulse\"><a href=\"#Rectangular-pulse\" class=\"headerlink\" title=\"Rectangular pulse\"></a>Rectangular pulse</h4><div>$$\nu(t) - u(t-t_0)\n$$</div>\n\n<h4 id=\"Sign-function\"><a href=\"#Sign-function\" class=\"headerlink\" title=\"Sign function\"></a>Sign function</h4><div>$$\nsgn(t) = 1, t>0;-1, t<0\n$$</div>\ndefine $sgn(0)=0$, then $sgn(t)=2u(t)-1$\n\n<h4 id=\"Unit-impulse-function\"><a href=\"#Unit-impulse-function\" class=\"headerlink\" title=\"Unit impulse function\"></a>Unit impulse function</h4><p>Dirac definition</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}\\delta(t)\\mathrm dt=1\\\\\n\\delta(t)=0(t\\ne 0)\n$$</div>\n<div>$$\n\\delta(t)=\\lim_{\\tau \\rightarrow0}\\left[U(t+\\frac\\tau2)-U(t-\\frac \\tau 2)\\right]\n$$</div>\n\n<div>$$\n\\int_{-\\infty}^{\\infty}\\delta(t)f(t)=f(0)\\\\\n\\int_{-\\infty}^{\\infty}\\delta(t - t_0)f(t)=f(t_0)\\\\\n\\delta(t)=\\delta(-t)\\\\\n\\frac{d}{dt}u(t)=\\delta(t)\n$$</div>\n\n<h4 id=\"Impulse-doublet-function\"><a href=\"#Impulse-doublet-function\" class=\"headerlink\" title=\"Impulse doublet function\"></a>Impulse doublet function</h4><p>$\\delta^\\prime(t)$<br>Double impulses at t&#x3D;0 which are mirror-imaged with their amplitude of infinite. </p>\n<div>$$\n\\int^{\\infty}_{-\\infty}\\delta^\\prime(t)\\mathrm dt=0\\\\\n\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t)\\mathrm dt=-f^{\\prime}(0)\\\\\n\\text{shifted:}\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t-t_0)\\mathrm dt=-f^{\\prime}(t_0)\\\\\n$$</div>\n![](../images/ss/lec2_.jpg)\n\n<h3 id=\"Signal-Decomposition\"><a href=\"#Signal-Decomposition\" class=\"headerlink\" title=\"Signal Decomposition\"></a>Signal Decomposition</h3><div>$$\nf(t) = f_D+f_A(t)\\\\\nf(t)=f_e(t)+f_o(t)\\\\\nf(t)=f_r(t)+jf_i(t)\\\\\nf_r(t)=\\frac{1}{2}\\left[f(t)+f^*(t)\\right]\\\\\nf_i(t)=\\frac{1}{2}\\left[f(t)-f^*(t)\\right]\n$$</div>\n\n<h4 id=\"Pulse-Component\"><a href=\"#Pulse-Component\" class=\"headerlink\" title=\"Pulse Component\"></a>Pulse Component</h4><div>$$\nf(t)=\\int_{-\\infty}^{\\infty}f(t_1)\\delta(t-t_1)\\mathrm dt_1\n$$</div>\n\n<p>We also have orthogonal function decomposition(Chap.3, Chap.6).</p>\n<h3 id=\"System-modeling-and-Classification\"><a href=\"#System-modeling-and-Classification\" class=\"headerlink\" title=\"System modeling and Classification\"></a>System modeling and Classification</h3><p>System model can be represented by math equation(including input-output description and state variables or state equation) graphic symbol and block diagrams.</p>\n<p>We use the input-output description mostly. If controling something internal is needed, state euqtion is useful.</p>\n<p>Block diagram: </p>\n<p><img src=\"/../images/ss/lec2_2.jpg\" loading=\"lazy\"><br><img src=\"/../images/ss/lec2_3.jpg\" loading=\"lazy\"></p>\n<h3 id=\"System-classification\"><a href=\"#System-classification\" class=\"headerlink\" title=\"System classification\"></a>System classification</h3><h4 id=\"Linear-or-Non-linear\"><a href=\"#Linear-or-Non-linear\" class=\"headerlink\" title=\"Linear or Non-linear\"></a>Linear or Non-linear</h4><div>$$\ne_1(t)\\rightarrow r_1(t),\ne_2(t)\\rightarrow r_2(t)\\Rightarrow\\\\\na_1e_1(t)+a_2e_2(t)\\rightarrow a_1r_1(t)+a_2r_2(t)\n$$</div>\n\n<h4 id=\"Time-variant-or-Time-invariant\"><a href=\"#Time-variant-or-Time-invariant\" class=\"headerlink\" title=\"Time-variant or Time-invariant\"></a>Time-variant or Time-invariant</h4><h4 id=\"Memory-or-Memoryless\"><a href=\"#Memory-or-Memoryless\" class=\"headerlink\" title=\"Memory or Memoryless\"></a>Memory or Memoryless</h4><p>with memory: dynamic system, differential equation</p>\n<p>without memory: instant system, algebraic equation</p>\n<h4 id=\"Continuous-or-Discrete\"><a href=\"#Continuous-or-Discrete\" class=\"headerlink\" title=\"Continuous or Discrete\"></a>Continuous or Discrete</h4><p>Continuous  Differential equation</p>\n<p>Discrete  Difference equation</p>\n<h4 id=\"Lumped-or-Distributed-Parameter\"><a href=\"#Lumped-or-Distributed-Parameter\" class=\"headerlink\" title=\"Lumped- or Distributed-Parameter\"></a>Lumped- or Distributed-Parameter</h4><p>Lumped: constant coefficient differential equation</p>\n<p>Distributed: partial equation</p>\n<h4 id=\"Causal-or-Non-Causal\"><a href=\"#Causal-or-Non-Causal\" class=\"headerlink\" title=\"Causal or Non-Causal\"></a>Causal or Non-Causal</h4><p>when $t&lt;0, e(t)&#x3D;0 \\Rightarrow t&lt;0, r(t)&#x3D;0$ Generic definition?</p>\n<p>the future state cannot have effect on now state. The state of causal system can only be determined by now and past states.</p>\n<h4 id=\"Reversible-or-irreversible\"><a href=\"#Reversible-or-irreversible\" class=\"headerlink\" title=\"Reversible or irreversible\"></a>Reversible or irreversible</h4><p>different input to different output, otherwise irreversible.</p>\n<h3 id=\"LTI-System\"><a href=\"#LTI-System\" class=\"headerlink\" title=\"LTI System\"></a>LTI System</h3><h4 id=\"Linearity\"><a href=\"#Linearity\" class=\"headerlink\" title=\"Linearity\"></a>Linearity</h4><p>Linearity leads to superposition and homogeneity.</p>\n<h4 id=\"Time-Invariant\"><a href=\"#Time-Invariant\" class=\"headerlink\" title=\"Time-Invariant\"></a>Time-Invariant</h4><p>a time shift in the input results in a same time shift in the output.</p>\n<div>$$\ne(t)\\rightarrow r(t)\\Rightarrow e(t-t_0)\\rightarrow r(t-t_0)\\\\\n\\lim_{\\Delta t\\rightarrow 0}\\frac{e(t)-e(t-\\Delta t)}{\\Delta t}\\rightarrow \\lim_{\\Delta t\\rightarrow 0}\\frac{r(t)-r(t-\\Delta t)}{\\Delta t}\\\\\n\\frac{\\mathrm de(t)}{dt}\\rightarrow \\frac{\\mathrm dr(t)}{dt}\n$$</div>\n\n<p>If every coefficient is time independent, the system is time invariant.</p>\n<h2 id=\"Time-Domain-TD-Analysis\"><a href=\"#Time-Domain-TD-Analysis\" class=\"headerlink\" title=\"Time-Domain(TD) Analysis\"></a>Time-Domain(TD) Analysis</h2><div>$$\nC_0\\frac{d^nr(t)}{dt^n}+C_1\\frac{d^{n-1}r(t)}{dt^{n-1}} + ... + C_nr(t)\\\\\n=E_0\\frac{d^me(t)}{dt^m}+E_1\\frac{d^{m-1}e(t)}{dt^{m-1}}+...+E_me(t)\n$$</div>\n\n<p><strong>Three Steps</strong></p>\n<ul>\n<li>Homogeneous</li>\n<li>Particular</li>\n<li>Calculation on coefficients</li>\n</ul>\n<h3 id=\"Determining-Coefficients\"><a href=\"#Determining-Coefficients\" class=\"headerlink\" title=\"Determining Coefficients\"></a>Determining Coefficients</h3><p>If functions are continuous, we can get their boundary conditions by determining the derivatives.</p>\n<p>Then the coefficients can be solved by multipling the inverse of Vandermonde matrix with the boundary condition matrix.</p>\n<h4 id=\"Zero-input-and-state-Responses\"><a href=\"#Zero-input-and-state-Responses\" class=\"headerlink\" title=\"Zero-input and -state Responses\"></a>Zero-input and -state Responses</h4><p><strong>Zero-input response</strong> The response caused by the initial state (i.e., energy originally stored in the system), and it is denoted by $r_{zi}(t)$</p>\n<p><strong>Zero-state response</strong> $r(0_-)\\equiv 0$, the response caused only by the external excitation and it is denoted by $r_{zs}(t)$</p>\n<p><img src=\"/../images/ss/lec3_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec3_2.jpg\" loading=\"lazy\"></p>\n<p>The combination of zero-input response and the zero-state response is not necessarily linear, since the existence of constant. If one of them vanishes, the other is linear.</p>\n<h3 id=\"Impulse-and-Step-Responses\"><a href=\"#Impulse-and-Step-Responses\" class=\"headerlink\" title=\"Impulse and Step Responses\"></a>Impulse and Step Responses</h3><p><strong>Impulse Response</strong> the zero-state response $h(t)$ to $\\delta (t)$, which can be equalized to the initial condition.</p>\n<p>Note: normally $n&gt;m$.</p>\n<p><strong>Unit Step Response</strong> The zero-state response $g(t)$ to $u(t)$</p>\n<p>There might be a forced term in $g(t)$.</p>\n<div>$$\ng(t) = \\int_0^th(\\tau)d\\tau\n$$</div>\n\n<h3 id=\"Convolution\"><a href=\"#Convolution\" class=\"headerlink\" title=\"Convolution\"></a>Convolution</h3><p>Zero-state required</p>\n<div>$$\ne(t) = \\int_{-\\infty}^{\\infty}e(\\tau)\\delta(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=\\int_{-\\infty}^{\\infty}e(\\tau)h(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=e(t)*h(t)\n$$</div>\n\n<p>the definition of convoluiton:</p>\n<div>$$\nf_1(t)*f_2(t)=\\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$</div>\n\n<p><strong>Integral interval</strong> $e(t)&#x3D;0, \\forall t&lt;0$, $h(t)&#x3D;0,\\forall t&lt;0$, so $r(t)&#x3D;\\int_0^t{e(\\tau)h(t-\\tau)\\mathrm d\\tau}$</p>\n<p>The condition for applying convolution:</p>\n<ul>\n<li>For linear system ONLY</li>\n<li>For time variant systems, $h(t, \\tau)$ means response at time $t$ generated by the impulse at time $\\tau$, then $r(t)&#x3D;\\int_0^th(t,\\tau)e(\\tau)\\mathrm d \\tau$; for time-invariant system is a special case, $h(t,\\tau)&#x3D;h(t-\\tau)$.</li>\n</ul>\n<p><strong>The Properties of Convolution</strong> The commutative property, the distributive property, the associative property</p>\n<p>Differential:</p>\n<div>$$\n(f_1(t)*f_2(t))^\\prime=f_1^\\prime(t)*f_2(t)\n$$</div>\n\n<p>Integral</p>\n<div>$$\n\\int f_1(t)*f_2(t)=f_1(t) * \\int f_2(t)\n$$</div>\n\n<div>$$\n(f_1(t) * f_2(t))^{(i)}=f_1^{(j)}(t) * f_2^{(i-j)}(t)\n$$</div>\n\n<p><strong>Convolution with $\\delta (t)$ or $u(t)$</strong></p>\n<p>(1) $f(t) * \\delta(t) &#x3D; f(t)$</p>\n<p>(2) $f(t) * \\delta(t - t_0) &#x3D; f(t-t_0)$</p>\n<p>(3) $f(t) * u(t) &#x3D; \\int_{\\infty}^{t}f(\\tau)\\mathrm d\\tau$</p>\n<p>(4) $f(t) * \\delta^\\prime(t) &#x3D; f^\\prime(t)$</p>\n<h2 id=\"Fourier-Transform\"><a href=\"#Fourier-Transform\" class=\"headerlink\" title=\"Fourier Transform\"></a>Fourier Transform</h2><h3 id=\"Fourier-Series\"><a href=\"#Fourier-Series\" class=\"headerlink\" title=\"Fourier Series\"></a>Fourier Series</h3><p>requirements:</p>\n<ul>\n<li>has finite number of discontinuities</li>\n<li>has finite number of maxima and minima</li>\n<li>$\\int_{t_0}^{t_0+T_1} |f(t)|\\mathrm dt &lt; \\infty$</li>\n</ul>\n<div>$$\n\\begin{align*}\nf(t)&=a_0+\\sum_{n=1}^\\infty \\left[a_n\\cos(n\\omega_1)t + b_n\\sin(n\\omega_1t)\\right]\\\\\n&=c_0 + \\sum_{n=1}^\\infty c_n\\cos \\left(n\\omega_1t+\\varphi_n \\right)\\\\\n&=\\sum_{n=-\\infty}^{\\infty}F_ne^{jn\\omega_1 t}\n\\end{align*}\n$$</div>\n\n<div>$$\n\\begin{align*}\n    a_0&=\\frac{1}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\mathrm dt=c_0\\\\\n    a_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\cos(n\\omega_1t)\\mathrm dt\\\\\n    b_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\sin(n\\omega_1t)\\mathrm dt\\\\\n    c_n&=\\sqrt{a_n^2+b_n^2}\\\\\n    \\varphi_n&=-\\tg^{-1}\\frac{b_n}{a_n}\\\\\n    F_n&=\\frac 1{T_1}\\int_{t_0}^{t_0+T_1}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\n    &=\\frac 12e^{j\\varphi_n}\\\\\n    &=\\frac 12(a_n-jb_n)\n\\end{align*}\n$$</div>\n\n<p><strong>note</strong> When $b_n&#x3D;0$, $\\varphi_n &#x3D; a_n &gt; 0\\ ?\\ 0:\\pi$</p>\n<p>In the last part, the negative frequency is introduced for the convenience of the signal analysis. Therefore the amplitude is reduced to half.</p>\n<p><strong>FS for special functions</strong></p>\n<ol>\n<li>Even function $c_n&#x3D;a_n, \\varphi_n &#x3D; 0, F_n&#x3D;F_{-n}&#x3D;\\frac 12 a_n$</li>\n<li>Odd function $a_0&#x3D;0, a_n&#x3D;0, \\varphi_n&#x3D;-\\frac{\\pi}{2}, F_n&#x3D;F_{-n}&#x3D;-\\frac{1}{2}jb_n$</li>\n<li>Half-wave Odd (odd harmonic) function, $f(t)&#x3D;-f\\left(t\\pm \\frac{T_1}2{}\\right)$, contains only odd harmonics(both sine and cosine)</li>\n<li>Finite term series</li>\n</ol>\n<h3 id=\"FS-for-typical-periodic-signals\"><a href=\"#FS-for-typical-periodic-signals\" class=\"headerlink\" title=\"FS for typical periodic signals\"></a>FS for typical periodic signals</h3><p><strong>Periodic square wave</strong></p>\n<div>$$\nf(t)=\\frac{E\\tau}{T_1}+\\sum_{n=1}^{\\infty}\\frac{2E\\tau}{T_1}\\text{Sa}(\\frac{n\\omega_1\\tau}{2})\n$$</div>\n\n<ol>\n<li>Spectrum is discrete with frequency spacing $\\omega_1 &#x3D; \\frac{2\\pi}{T_1}$. When $T_1 \\rightarrow \\infty$, the spectrum will be continuous.</li>\n<li>Amplitude: $\\text{Sa}\\left(\\frac{n\\pi\\tau}{T_1}\\right)$ or $\\text{Sa} \\left(\\frac{n\\omega_1\\tau}{2}\\right)$, cross zero when $\\omega_1 &#x3D; \\frac{2m\\pi}{\\tau}$</li>\n<li>Non-zero FS coefficients of a aperiodic signal are infinite with most energy concentrated at low frequency components (within $\\left(-\\frac{2\\pi}{\\tau},\\frac{2\\pi}{\\tau}\\right)$). Thus we define the bandwith $B_{\\omega} &#x3D; \\frac{2\\pi}{\\tau}$</li>\n</ol>\n<p><strong>Periodic symmetric square wave</strong></p>\n<p>Since the spectrum crosses zero when $\\omega_1 &#x3D; \\frac{2m\\pi}{\\tau}$, the even harmonic vanishes. Also the sine component vanishes.</p>\n<div>$$\nc_n = \\frac{2E\\tau}{T_1}\\left|\\text{Sa}\\left(\\frac{n\\omega_1\\tau}{2}\\right)\\right|\\\\\nf(t) = \\frac{2E}{\\pi}\\left[\\cos(\\omega_1t) - \\frac{1}3\\cos(3\\omega_1t) + \\frac{1}{5}\\cos(5\\omega_1t)-...\\right]\n$$</div>\n\n<p><strong>Periodic Serrated Pulse</strong></p>\n<div>$$\nf(t) = \\sum_{n = 1}^\\infty \\frac{E}{n\\pi}(-1)^{n+1}\\sin (n\\omega_1t)\n$$</div>\n\n<p><strong>Periodic Triangular Pulse</strong></p>\n<div>$$\nf(t)=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{n^2}\\sin^2\\left(\\frac{n\\pi}{2}\\right)\\cos(n\\omega_1t)\\\\=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{(2n-1)^2}\\cos((2n-1)\\omega_1t)\n$$</div>\n\n<p><strong>consine of non-negative values</strong></p>\n<div>$$\nf(t) = \\frac E\\pi - \\frac{2E}{\\pi}\\sum_{n=1}^\\infty\\frac{1}{n^2-1}\\cos(\\frac {n\\pi}2)\\cos(n\\omega_1t)\n$$</div>\n\n<p><strong>cosine of absoulute values</strong></p>\n<div>$$\nf(t) = \\frac{2E}{\\pi} + \\frac{4E}{\\pi}\\sum_{n=1}^\\infty (-1)^{n+1}\\frac{1}{4n^2-1}\\cos(2n\\omega_0t)\n$$</div>\n\n<p>其中$\\omega_0$ &#x3D; $2\\omega_1$</p>\n<h3 id=\"Fourier-Transform-1\"><a href=\"#Fourier-Transform-1\" class=\"headerlink\" title=\"Fourier Transform\"></a>Fourier Transform</h3><p>The case where $T_1\\rightarrow \\infty$. Signal becomes aperiodic.</p>\n<p>Also, $\\omega_1\\rightarrow 0$ results in the continuous frequency axis. For square wave the magnitude $\\frac{E\\tau}{T_1}\\rightarrow 0$.</p>\n<div>$$\nf(t) =\\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)e^{jn\\omega_1 t}\\\\\nF(n\\omega_1) = \\frac 1T_1\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\n$$</div>\n\n<p>We use spectrum density to replace spectrum, making the magnitude dropping to zero remain its meaning.</p>\n<div>$$\n\\frac{F(n\\omega_1)}{\\omega_1} = \\frac{1}{2\\pi}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\nF(\\omega) = \\lim_{\\omega_1\\rightarrow 0}\\frac{2\\pi F(n\\omega_1)}{\\omega_1}=\\lim_{T_1\\rightarrow \\infty}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm d t=\\int_{-\\infty}^\\infty f(t)e^{-j\\omega t}\\mathrm d t\\\\\nf(t) = \\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)\\cdot \\frac{1}{\\omega_1}e^{jn\\omega_1 t} \\Delta(n\\omega_1) = \\frac{1}{2\\pi}\\int_{-\\infty}^\\infty F(\\omega)e^{j\\omega t}\\mathrm d\\omega\n$$</div>\n\n<div>$$\nF(\\omega) = |F(\\omega)|e^{j\\varphi(\\omega)}\n$$</div>\n\n<p>The fourier transfrom is continuous waveform, where every frequency has no energy but energy density, used to analyse aperiodic function.</p>\n<p>Sufficient condition, but not necessary.</p>\n<div>$$\n\\int_{-\\infty}^\\infty |f(t)|\\mathrm dt<\\infty\n$$</div>\n\n<h3 id=\"FT-for-typical-aperiodic-signals\"><a href=\"#FT-for-typical-aperiodic-signals\" class=\"headerlink\" title=\"FT for typical aperiodic signals\"></a>FT for typical aperiodic signals</h3><p><strong>Rectangular pulses</strong></p>\n<div>$$\nF(\\omega) = \\int_{-\\tau/2}^{\\tau/2} Ee^{-j\\omega t}\\mathrm dt = E\\tau \\text{Sa}\\left(\\frac{\\omega \\tau}{2}\\right)\n$$</div>\n\n<p><strong>Raised Cosine Signal</strong></p>\n<div>$$\nf(t) = \\frac{E}{2}(1+\\cos\\frac{\\pi t}{\\tau})(u(t+\\tau) - u(t - \\tau))\\\\\nF(\\omega) = \\int_{-\\tau}^{\\tau}(1+\\cos\\frac{\\pi t}{\\tau})\\mathrm dt = \\frac{E\\tau}{1 - \\left(\\frac{\\omega \\tau}{\\pi}\\right)^2}\\text{Sa}({\\omega \\tau})\n$$</div>\n\n<p>More compacted than square signal($|F(\\omega)|\\propto \\frac 1{\\omega^3}$). An explanation is that the raised cosine has no discontinuities.</p>\n<p>Generally:</p>\n<ol>\n<li>$f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega}$</li>\n<li>$\\frac{d}{dt}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^2}$</li>\n<li>$\\frac{d^2}{dt^2}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^3}$</li>\n</ol>\n<p>The <strong>width</strong> $\\tau$ of the raised cosine signal is defined at $\\frac E2$ rather than at the bottom, making it easy to compare with<br>     the rectangular pulse of same width. The first zeros of the<br>   frequency spectrum are identical.</p>\n<p>raised consine is energy-concentrative and has been widely used in digital communications.</p>\n<p><strong>Single-sided exponential singal</strong> </p>\n<div>$$\nf(t) = e^{-at}u(t)\\\\\nF(\\omega) = \\frac{1}{a+j\\omega}\n$$</div>\n\n<p><strong>Two-sided, anti-symmetric exponential signal</strong></p>\n<div>$$\nf(t) = -e^{at}u(-t) + e^{-at}u(t)\\\\\nF(\\omega) = \\frac{-2j\\omega}{a^2+\\omega^2}\n$$</div>\n\n<p><strong>Sign function</strong></p>\n<div>$$\n\\text{sgn}(t) = u(t) - u(-t)\\\\\nF(\\omega) = \\lim_{a\\rightarrow 0}\\frac{-2j\\omega}{a^2+\\omega^2}= \\frac{2}{j\\omega}\n$$</div>\n\n<p><strong>Gaussian singal</strong></p>\n<div>$$\nf(t) = Ee^{-\\left(\\frac{t}{\\tau}\\right)^2}\\\\\nF(\\omega) = \\sqrt \\pi E\\tau e^{-\\left(\\frac{\\omega\\tau}{2}\\right)^2}\n$$</div>\n\n<p><strong>Sinc Function</strong></p>\n<div>$$\nf(t) = \\frac{E}{\\pi}\\frac{\\sin(\\omega_c t)}{t}\\\\\nF(\\omega) = E(u(\\omega - \\omega_c ) + u(\\omega + \\omega_c ))\\\\\n$$</div>\n\n\n<h3 id=\"FT-on-impulse-and-step-functions\"><a href=\"#FT-on-impulse-and-step-functions\" class=\"headerlink\" title=\"FT on impulse and step functions\"></a>FT on impulse and step functions</h3><div>$$\n\\mathcal F[\\delta(t)] = 1\\\\\n\\mathcal F[1] = 2\\pi \\delta(\\omega)\n$$</div>\n\n<p>The spectrum of impulse function covers the entire frequency range. The interferences caused by a variety of electric sparks always cover the full frequency range.</p>\n<div>$$\n\\mathcal F[\\delta^\\prime (t)]= j\\omega\\\\\n\\mathcal F[\\delta^{(n)}(t)] = (j\\omega)^n\n$$</div>\n\n<div>$$\n\\mathcal F[u(t)] = \\pi \\delta(\\omega) + \\frac{1}{j\\omega}\n$$</div>\n\n<p>Due to the DC component in u(t), an impulse exists.</p>\n<h3 id=\"Properties-of-FT\"><a href=\"#Properties-of-FT\" class=\"headerlink\" title=\"Properties of FT\"></a>Properties of FT</h3><p><strong>Symmetry</strong> $\\mathcal F[F(t)]&#x3D; 2\\pi f(-\\omega)$ , if $f(t)$ is a even function, $\\mathcal F[F(t)]&#x3D; 2\\pi f(\\omega)$</p>\n<p><strong>Linearity</strong> $\\mathcal{F}[\\Sigma_{i&#x3D;1}^{n}a_if_i(t)] &#x3D; \\Sigma_{i&#x3D;1}^{n}a_iF_i(\\omega)$</p>\n<p><strong>Odd-Even, Imaginary-Real</strong> $f(t) &#x3D; f_e(t)+f_o(t)$, then</p>\n<div>$$\n\\begin{align*}\n  F(\\omega) &= \\int_{-\\infty}^\\infty f(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f(t)\\sin \\omega t \\mathrm dt\\\\\n  &=R(\\omega)+jX(\\omega)\\\\\n  &=\\int_{-\\infty}^\\infty f_e(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f_o(t)\\sin \\omega t \\mathrm dt\\\\\n\\end{align*}.\n$$</div>\n\n<p>$R(\\omega)$ is an even function of $\\omega$, $X(\\omega)$ is an odd function of $\\omega$.</p>\n<p>$|F(\\omega) &#x3D; \\sqrt{R^2(\\omega)+F^2(\\omega)}|$ is even function.</p>\n<p>$\\varphi(\\omega) &#x3D; \\tg^{-1}\\frac{R(\\omega)}{X(\\omega)}$</p>\n<p>if $f(t)$ is real and even, then $f(t)&#x3D;f_e(t), F(\\omega)&#x3D;R(\\omega)$, the phase shift is $0$ or $\\pi$.</p>\n<p>if $f(t)$ is real and odd, $f(t) &#x3D; f_o(t)$, then $F(\\omega)&#x3D;jX(\\omega)$, $F(\\omega)$ has only imaginary part and is odd, the phase shift is $\\pm \\frac{\\pi}{2}$</p>\n<p><strong>Scaling</strong> $\\mathcal{F}[f(at)]&#x3D;\\frac 1{|a|}F\\left(\\frac{\\omega}a\\right)$ Expansion in TD results in Compression in FD.</p>\n<p><strong>Time Shifting</strong> $\\mathcal{F}[f(t\\pm t_0)] &#x3D; F(\\omega)e^{\\pm j\\omega t_0}$</p>\n<p><strong>Frequency Shifting</strong> $\\mathcal F[f(t)e^{\\pm j\\omega_0t}] &#x3D; F(\\omega\\mp\\omega_0)$</p>\n<p><strong>Differentiation property</strong>$\\mathcal F\\left[\\frac{\\mathrm d}{\\mathrm dt}f(t)\\right] &#x3D; j\\omega F(\\omega)$</p>\n<p>$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm dt^n}f(t)\\right] &#x3D; (j\\omega)^n F(\\omega)$</p>\n<p>$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm d\\omega^n}F(\\omega)\\right] &#x3D; (-jt)^nf(t)$</p>\n<p><strong>Integration Property</strong> $\\mathcal{F}\\left[\\int_{-\\infty}^t f(\\tau)\\mathrm{d} \\tau\\right] &#x3D; \\frac{F(\\omega)}{j\\omega} + \\pi F(0)\\delta(\\omega)$</p>\n<h3 id=\"Convolution-theorem\"><a href=\"#Convolution-theorem\" class=\"headerlink\" title=\"Convolution theorem\"></a>Convolution theorem</h3><div>$$\n\\mathcal F[f_1(t)* f_2(t)] = F_1(\\omega)F_2(\\omega)\\\\\n\\mathcal F[f_1(t)\\cdot f_2(t)] = \\frac 1{2\\pi} F_1(\\omega) * F_2(\\omega)\n$$</div>\n\n<h3 id=\"FT-for-Periodic-Signals\"><a href=\"#FT-for-Periodic-Signals\" class=\"headerlink\" title=\"FT for Periodic Signals\"></a>FT for Periodic Signals</h3><div>$$\n\\mathcal F[\\cos (\\omega_0 t)] = \\pi [\\delta(\\omega + \\omega_0) + \\delta(\\omega - \\omega_0)]\\\\\n\\mathcal{F} [\\sin (\\omega_0 t)] = j\\pi [\\delta(\\omega+\\omega_0) + \\delta(\\omega - \\omega_0)]\n$$</div>\n\n<p>FT for periodic of $T_1$ &amp; $\\omega_1&#x3D;2\\pi&#x2F;T_1$</p>\n<div>$$\n\\mathcal F[f(t)] = 2\\pi\\sum_{n=-\\infty}^{+\\infty} F_n\\delta(\\omega - n\\omega_1)\\\\\nF_n = \\frac 1{T_1}\\int_{-T_1/2}^{T_1/2}f(t)e^{-jn\\omega_1 t}\\mathrm dt = \\frac{1}{T_1}F_0(\\omega)\\vert_{\\omega =n\\omega_1}\n$$</div>\n\n<p>Where $F_0(\\omega)$ is the FT considering waveform of $f(t)$ only in $|t|\\le T_1&#x2F;2$.</p>\n<p>example: </p>\n<div>$$\nf(t) = \\sum_{n=0}^{\\infty}\\delta(t-nT_1), F_n=\\frac{1}{T_1}\\\\\nF(\\omega) = \\frac{2\\pi}{T_1}\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)=\\omega_1\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)\n$$</div>\n\n<div>$$\nF_0(ω) \\text{ determines the profile of } F(ω)\\\\\nT_1\\text{ determines the density of the impulses\n}\\\\\nT_1↑, ω_1↓\\text{, intensity of harmonics}↓\\\\\nT_1↓,ω_1↑\\text{, intensity of harmonics}↑\\\\\n$$</div>\n\n<p><img src=\"/../images/ss/lec7_1.jpg\" loading=\"lazy\"></p>\n<p>In the same way: </p>\n<p><img src=\"/../images/ss/lec7_2.jpg\" loading=\"lazy\"></p>\n<h3 id=\"FT-for-periodically-sampled-signals\"><a href=\"#FT-for-periodically-sampled-signals\" class=\"headerlink\" title=\"FT for periodically sampled signals\"></a>FT for periodically sampled signals</h3><div>$$\nF(\\omega) = \\mathcal F[f(t)]\\\\\nP(\\omega) = \\mathcal F[p(t)]\\\\\nf_s(t) = f(t)p(t)\\\\\nF_s(\\omega) =\\frac{1}{2\\pi} F(\\omega) * P(\\omega)\n$$</div>\n\n<p>Then, </p>\n<div>$$\nP(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_n\\delta(\\omega - \\omega_s)\\\\\nF(\\omega) * P(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\\\\\nF_s(\\omega) = \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\n$$</div>\n\n<p><img src=\"/../images/ss/lec7_3.jpg\" loading=\"lazy\"></p>\n<p>For the frequency-domain sampling: </p>\n<div>$$\nF_1(\\omega) = F(\\omega)P(\\omega)\\\\\nP(\\omega) = \\sum_{n=-\\infty}^{+\\infty} \\delta(\\omega - n\\omega_1)\\\\\nf_1(t) = f(t) *  \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{+\\infty} \\delta(t - nT_1) = \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{\\infty} f(t-nT_1)\n$$</div>\n\n<p><strong>The Sampling Theorem</strong></p>\n<div>$$\n\\omega_s \\ge 2\\omega_m\n$$</div>\n\n<p>A band-limited signal whose spectrum is strictly within $[0, f_m]$ could be uniquely determined by the samples on itself, if and only if the sampling interval $T_s \\le 1&#x2F;(2f_m)$.</p>\n<p>$T_s &#x3D; \\frac{1}{2f_m}$ is called the <strong>Nyquist interval</strong>.</p>\n<p>$2f_m$ is called the <strong>Nyquist frequency</strong>.</p>\n<p>对于单频信号，奈奎斯特频率的采样可能会出现问题。例如正弦信号，每次采样都采在零点上，那就没法复现信号。单频信号没法描述带宽。</p>\n<p>A FD verison:</p>\n<p><img src=\"/../images/ss/lec7_4.jpg\" loading=\"lazy\"></p>\n<h2 id=\"L-Transform\"><a href=\"#L-Transform\" class=\"headerlink\" title=\"L Transform\"></a>L Transform</h2><h3 id=\"Unilateral-L-transform\"><a href=\"#Unilateral-L-transform\" class=\"headerlink\" title=\"Unilateral L-transform\"></a>Unilateral L-transform</h3><div>$$\nF(s) = \\int^{\\infty}_{0}f(t)e^{-st}\\mathrm dt, s=\\sigma+j\\omega\\\\\nf(t)=\\frac{1}{2\\pi j}\\int_{\\sigma-j\\infty}^{\\sigma+j\\infty}F(s)e^{st}\\mathrm ds\n$$</div>\n\n<p>$F(s) &#x3D; \\mathcal{L}[f(t)]$ is called image function, $f(t) &#x3D; \\mathcal{L}^{-1}[F(s)]$ is called primitive function.</p>\n<p>assuming that $f(t)$ is causal and always 0 if $t&lt;0$.</p>\n<div>$$\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0) + sF(s)\n$$</div>\n\n<p>The initial state is automatically included in differential equation.</p>\n<p>We define the <strong>unilateral</strong> L-Transform as: </p>\n<div>$$\nF(s) = \\int_{0_-}^{\\infty}f(t)e^{-st}\\mathrm dt\\\\\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0_-) + sF(s)\n$$</div>\n\n<p>Conditions for L-Transform: </p>\n<ol>\n<li>Limited discontinuities</li>\n<li>Exponential order</li>\n</ol>\n<p>The strong attenuation factor can make the function convergent.</p>\n<p>Region of Convergence (ROC)</p>\n<p>Axis of convergence</p>\n<p>Coordinate of convergence $\\sigma_0$</p>\n<h3 id=\"Comman-LT-Pairs\"><a href=\"#Comman-LT-Pairs\" class=\"headerlink\" title=\"Comman LT Pairs\"></a>Comman LT Pairs</h3><div>$$\n\\begin{align*}\nf(t)&\\Rightarrow F(s)\\\\  \n\\delta(t) &\\Rightarrow 1\\\\\nu(t) &\\Rightarrow \\frac 1s\\\\\ne^{-at} &\\Rightarrow \\frac{1}{s+a}\\\\\nt^n & \\Rightarrow \\frac{n!}{s^{n+1}}\\\\\n\\sin (\\omega t)&\\Rightarrow \\frac{\\omega}{s^2 + \\omega^2}\\\\\n\\cos (\\omega t)&\\Rightarrow \\frac{s}{s^2+\\omega^2}\\\\\n\\end{align*}\n$$</div>\n\n<h3 id=\"Properties-of-LT\"><a href=\"#Properties-of-LT\" class=\"headerlink\" title=\"Properties of LT\"></a>Properties of LT</h3><p><strong>Linarity</strong></p>\n<div>$$\n\\mathcal L [k_1f_1(t) + k_2f_2(t)] = k_1F_1(s) + k_2F_2(s)\\\\\n$$</div>\n\n<p><strong>Differentiation</strong></p>\n<div>$$\n\\mathcal L \\left[\\frac{\\mathrm d f(t)}{\\mathrm d t}\\right] = sF(s) - f(0_-)\n$$</div>\n\n<p><strong>Intergration</strong></p>\n<div>$$\n\\mathcal L\\left[\\int_{-\\infty}^t f(\\tau)\\mathcal d\\tau\\right]=\\frac{F(s)}{s} + \\frac{f^{(-1)}(0)}{s}\n$$</div>\n\n<p><strong>Time Shifting</strong></p>\n<div>$$\n\\mathcal L\\left[f(t-t_0)u(t-t_0)\\right] = e^{-st_0}F(s)\n$$</div>\n\n<p>Use $u(t-t_0)$ to avoid nagative part of $f(t)$ emerges.</p>\n<p><strong>Frequency Shifting</strong></p>\n<div>$$\n\\mathcal L[f(t)e^{-at}] = F(s+a)\n$$</div>\n\n<p><strong>Scaling</strong></p>\n<div>$$\n\\mathcal L[f(at)] = \\frac 1a F\\left(\\frac{s}{a}\\right)\n$$</div>\n\n<p><strong>s-Domain Differentiation</strong></p>\n<div>$$\n\\frac{\\mathrm d}{\\mathrm ds}\\mathcal L[f(t)] = \\mathcal L[-tf(t)]\n$$</div>\n\n<p><strong>s-Domain Differentiation</strong></p>\n<div>$$\n\\int_s^\\infty F(s) = \\mathcal{L}\\left[\\frac{f(t)}{t}\\right]\n$$</div>\n\n<p><strong>Initial value</strong></p>\n<div>$$\nf(0_+) = \\lim_{s\\rightarrow\\infty}sF(s)\n$$</div>\n\n<p><strong>Final value</strong></p>\n<div>$$\n\\lim_{t\\rightarrow\\infty} f(t) = \\lim_{s\\rightarrow0} sF(s)\n$$</div>\n\n<p>Generalized limit: $\\lim_{t\\rightarrow\\infty} \\sin(\\omega t)&#x3D;0$</p>\n<p><strong>Convolution</strong></p>\n<div>$$\n\\mathcal L[f_1(t)*f_2(t)] = F_1(s)F_2(s)\n$$</div>\n\n<h3 id=\"Applications\"><a href=\"#Applications\" class=\"headerlink\" title=\"Applications\"></a>Applications</h3><p><strong>Differential Equations</strong></p>\n<div>$$\n  F(s) = \\frac{A(s)}{B(s)} = \\frac{a_ns^n + a_{n-1}s^{n-1} + \\cdots + a_1s + a_0}{b_ms^m + b_{m-1}s^{m-1} + \\cdots + b_1s + b_0} % The division of two polynomials\n$$</div>\n\n<p>(assume that $n&lt;m$)</p>\n<p>The roots of numerator is called zeros, while the roots of denominator is called poles.</p>\n<p>Unknown function F(s) can be represented by the ratio of two polynomials if all initial states are 0.</p>\n<ol>\n<li>real poles</li>\n</ol>\n<div>$$\nF(s) = \\frac{A(s)}{(s-p_1)(s-p_2)(s-p_3)}\n$$</div>\n\n<ol start=\"2\">\n<li>complex conjugate poles</li>\n</ol>\n<div>$$\nF(s) = \\frac{A(s)}{D(s)[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{(s+\\alpha - j\\beta)(s+\\alpha + j\\beta)} + \\dots\n$$</div>\n\n<div>$$\nk_1 = (s+\\alpha - j\\beta)F(s)|_{s = -\\alpha + j\\beta} = \\frac {F_1(-\\alpha + j\\beta)}{2j\\beta}\\\\\nk_2 = (s+\\alpha + j\\beta)F(s)|_{s = -\\alpha - j\\beta} = \\frac {F_1(-\\alpha - j\\beta)}{-2j\\beta}\n$$</div>\n\n<ol start=\"3\">\n<li>Multiple poles</li>\n</ol>\n<div>$$\nF(s) = \\frac {A(s)}{B(s)} = \\frac{A(s)}{(s-p_1)^k D(s)}\\\\\n= \\frac{K_{11}}{(s-p_1)^k}+\\frac{K_{12}}{(s-p_1)^{k-1}}+\\dotsb+\\frac{K_{1k}}{s-p_1} + \\frac{E(s)}{D(s)}(s-p_1)^k\n$$</div>\n\n<p><img src=\"/../images/ss/lec9_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec9_2.jpg\" loading=\"lazy\"></p>\n<p>Circuit model:</p>\n<p><img src=\"/../images/ss/lec9_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec9_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec9_5.jpg\" loading=\"lazy\"></p>\n<p>Use initial value and final value to verify it.</p>\n<h3 id=\"System-Function\"><a href=\"#System-Function\" class=\"headerlink\" title=\"System Function\"></a>System Function</h3><div>$$\n\\begin{cases}\n  R(s) = H(s) \\cdot E(s)\\\\\n  r(t) = h(t) * e(t)\n\\end{cases}\n\\Rightarrow H(s) = L[h(t)]\n$$</div>\n\n<p><strong>Driving point function &amp; transfer function</strong></p>\n<p><img src=\"/../images/ss/lec9_6.jpg\" loading=\"lazy\"></p>\n<p>L-transform can be used in the following analysis:</p>\n<ul>\n<li>TD characteristics (response decomposition)</li>\n<li>FD characteristics (steady-state with sine signal input,applications such as filtering) </li>\n<li>Stability (active network, feedback, oscillator, control system)</li>\n</ul>\n<h3 id=\"TD-characteristics-by-0-point-distribution\"><a href=\"#TD-characteristics-by-0-point-distribution\" class=\"headerlink\" title=\"TD characteristics by 0-point distribution\"></a>TD characteristics by 0-point distribution</h3><p>Three cases: </p>\n<ul>\n<li>Real poles</li>\n<li>Complex conjugate poles</li>\n<li>Real pole of high-order</li>\n</ul>\n<ol>\n<li>Zero pole of H(s)</li>\n</ol>\n<p><img src=\"/../images/ss/lec10_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec10_2.jpg\" loading=\"lazy\"></p>\n<p>Zero only affects the phase and amplitude, while the shape and type of waveform is determined by the poles.</p>\n<ol start=\"2\">\n<li>pole distribution $\\Leftrightarrow$ corresponding natural&#x2F;forced responses</li>\n</ol>\n<div>$$\nH(s) = \\frac{\\prod_{i = 1}^m(s-z_{hj})}{\\prod_{i = 1}^n(s-p_{hi})}\\\\\nE(s) = \\frac{\\prod_{i = 1}^u(s-z_{el})}{\\prod_{i = 1}^v(s-p_{ek})}\\\\\n\\text{if } m + u < n + v\\\\\nR(s) = E(s)H(s) = \\sum_{k=1}^n\\frac{K_{hk}}{s - p_{hk}} + \\sum_{k=1}^v\\frac{K_{ek}}{s-p_{ek}}\n$$</div>\n\n<p>The natural response of $r(t)$ is only related to $p_{hk}$, while the forced response is only related to $p_{ek}$.</p>\n<p>$K_{hk}$, $K_{ek}$ are related to both $H(s)$ and $E(s)$.</p>\n<p>However natural and forced responses could not be completely separated, if there exists $k, k^\\prime$ satisfying $p_{hk}&#x3D;p_{ek^\\prime}$.</p>\n<p>$p_{hi}$ are called natural frequency of the system.</p>\n<p>However, some common factors may be eliminated: </p>\n<div>$$\n\\frac{(s+1)}{(s+1)(s+2)} = \\frac{1}{(s+2)}\n$$</div>\n\n<div>$$\nH(s) = \\frac{\\Delta_{jk}}{\\Delta}\n$$</div>\n\n<p>All the poles of $H(s)$ are the natural frequencies of the system, but $h(t)$ may not include all the natural frequencies(but the root of $\\Delta$ contains all natural frequencies).</p>\n<p>In most cases:</p>\n<div>$$\n\\text{Re}(p_{hi}) < 0, \\text{Re}(p_{ei}) = 0\n$$</div>\n\n<p>Thus the natural response is transient, while the forced response is steady-state.</p>\n<p>However, some natural response can be steady-state(conjugate poles of $Re(p_{hi})$), while some forced response can be transient.</p>\n<p><img src=\"/../images/ss/lec10_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec10_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec10_5.jpg\" loading=\"lazy\"></p>\n<div>$$\nE_m|H(j\\omega)|\\sin (\\omega_0t + \\varphi_0)\n$$</div>\n\n<div>$$\nH(j\\omega) =K\\cdot \\frac{\\prod(j\\omega - z_j)}{\\prod (j\\omega - p_i)}\n$$</div>\n\n<p><img src=\"/../images/ss/lec10_7.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec10_6.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec10_8.jpg\" loading=\"lazy\"></p>\n<p>for band-pass filter, </p>\n<p>BW is where Peak(dB) - 3dB</p>\n<p>for low-pass filter,</p>\n<p>BW &#x3D; $f_{\\text{cut-off}}$</p>\n<p>According to the sampling theorem, the signal bandwith is often determined by the first zero of the spectrum.</p>\n<p><strong>All Pass Systems</strong></p>\n<div>$$\nR_e(p_i) = -R_e(z_i)\\\\\nI_m(p_i) = I_m(z_i)\n$$</div>\n\n<p>The Amplitude is const., while the phase can change.</p>\n<p><strong>Minimum-phase system&#x2F;function</strong></p>\n<p>Definition: A stable system with poles on left-half s-plane is called minimum-phase system&#x2F;function, if all the zeros are also on left-half s-plane or at the jω-axis. Otherwise is a non-minimum-phase system&#x2F;function.<br><img src=\"/../images/ss/lec11_1.jpg\" loading=\"lazy\"></p>\n<p>Property: A non-minimum-phase function can be represented as the product of  a minimum-phase function and an all-pass function.</p>\n<h3 id=\"Stability-of-Linear-System\"><a href=\"#Stability-of-Linear-System\" class=\"headerlink\" title=\"Stability of Linear System\"></a>Stability of Linear System</h3><p>A system is considered to be stable if bounded input always leads to bounded output.</p>\n<p>Bounded-input, Bounded-output(BIBO)</p>\n<p>The necessary &amp; sufficient conditions for BIBO:</p>\n<div>$$\n\\int_{-\\infty}^\\infty|h(t)|\\mathrm dt \\le M\n$$</div>\n\n<p>Poles are: </p>\n<ul>\n<li>on the left half-plane: $\\lim_{t\\rightarrow \\infty}[h(t)] &#x3D; 0$, stable system</li>\n<li>on the right half-plane, or at $j\\omega$-axis with order of more than one: $\\lim_{t\\rightarrow \\infty}[h(t)] &#x3D; \\infty$, unstable system</li>\n<li>at $j\\omega$-axis with order of one: $h(t)$ is non-zero or oscillated with equal amplitude, critical stable system</li>\n</ul>\n<h3 id=\"Two-sided-Bilateral-LT\"><a href=\"#Two-sided-Bilateral-LT\" class=\"headerlink\" title=\"Two-sided (Bilateral) LT\"></a>Two-sided (Bilateral) LT</h3><div>$$\nF_B(s) = \\int_{-\\infty}^\\infty f(t)e^{-st}\\mathrm{d} t\n$$</div>\n\n<ul>\n<li>t starts from −∞, i.e., non-causal signal as the input<br>or regarding the initial condition as the input.</li>\n<li>Easily to be associated with F-transform and Z-<br>transforms</li>\n</ul>\n<p>We determine the ROC by:</p>\n<div>$$\n\\lim_{t\\rightarrow \\infty} f(t)e^{-\\sigma t} = 0\\\\\n\\lim_{t\\rightarrow -\\infty} f(t)e^{-\\sigma t} = 0\n$$</div>\n\n<p>NOTE: </p>\n<ul>\n<li>If no overlap between the two constraints, then $F_B(s)$ does not exist.</li>\n<li>$F_B(s)$ and $f(t)$ are not uniquely corresponding to each other.($\\int_{-\\infty}^\\infty u(t)e^{-st}\\mathrm{d} t &#x3D; \\frac{1}{s}$, $\\int_{-\\infty}^\\infty -u(-t)e^{-st}\\mathrm{d} t&#x3D;\\frac{1}{s}$)</li>\n<li>Two-sided L-Transform shares almost all the properties with its single-sided counterpart except for the initial-value theorem.</li>\n<li>Two-sided L-Transform has very limited applications as most continuous-time systems are causal.</li>\n</ul>\n<p>**Relationship between LT and FT **</p>\n<ul>\n<li>$\\sigma_0 &gt; 0$, $F(\\omega)$ does not exist</li>\n<li>$\\sigma_0 &#x3D; 0$, impulse appears in $F(\\omega)$</li>\n<li>$\\sigma_0 &lt; 0$, $F(\\omega)$ exists, $F(\\omega) &#x3D; F(s)|_{s&#x3D;j\\omega}$</li>\n</ul>\n<p><img src=\"/../images/ss/lec11_2.jpg\" loading=\"lazy\"><br>(The LT above is unilateral LT.)</p>\n<p><img src=\"/../images/ss/lec11_3.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Extra-Attention\"><a href=\"#Extra-Attention\" class=\"headerlink\" title=\"Extra Attention\"></a>Extra Attention</h3><p>$1 + e^{-s}$ also has zero(many!). Note that if it is on the denominator.</p>\n<h2 id=\"FT-in-Telecom-Systems\"><a href=\"#FT-in-Telecom-Systems\" class=\"headerlink\" title=\"FT in Telecom. Systems\"></a>FT in Telecom. Systems</h2><p>System discussed in this chapter are strictly stable: </p>\n<div>$$\n\\mathcal{F}[f(t)] = F(s)|_{s=j\\omega}\n$$</div>\n\n<p>Because even for critical stable system, FT is not  the same as LT(containing $\\delta$), there will be ambiguity between $H(j\\omega)$ and $H(s)|_{s&#x3D;j\\omega}$.</p>\n<p>For every freq. component, it is reshaped in its phase and amplitude by the system function when passing through the system, related with its frequency. Thus the system can distort the original signal.</p>\n<p><strong>Distortion</strong></p>\n<p>2 types of distortion:</p>\n<ul>\n<li>Non-linear distortion (new frequency components)</li>\n<li>Linear distortion (without new frequency components), just the amplitude and&#x2F;or phase distortion.</li>\n</ul>\n<p> <strong>Distortionless transmission</strong></p>\n<div>$$\ne(t)\\rightarrow ke(t - t_0)\n$$</div>\n\n<div>$$\nR(j\\omega) = \\int_{-\\infty}^\\infty ke(t -t_0)e^{-j\\omega t}\\mathrm dt=ke^{-j\\omega t_0}\\int_{-\\infty}^\\infty e(x)e^{-j\\omega x}\\mathrm dx=ke^{-j\\omega t_0} E(j\\omega)\n$$</div>\n\n<p>So, $H(j\\omega) &#x3D; ke^{-j\\omega t_0}$, $h(t)&#x3D;K\\delta(t - t_0)$.</p>\n<p>The Amplitude is frequency independent, $BW\\rightarrow \\infty$.</p>\n<p>Phase response is linear at negative slope.</p>\n<p>The impulse response of a distortionless linear system is<br>     also an impulse.</p>\n<p>The physical scenario: group delay.</p>\n<div>$$\n\\tau = -\\frac{\\mathrm d\\varphi (\\omega)}{\\mathrm d\\omega}\n$$</div>\n\n<p>Condition for phase distortionless property: the group delay remains a constant.</p>\n<h3 id=\"Filter\"><a href=\"#Filter\" class=\"headerlink\" title=\"Filter\"></a>Filter</h3><p><strong>Ideal Low pass (LP) Filter</strong></p>\n<div>$$\nH(j\\omega) = \\begin{cases}\n  1 \\cdot e^{-j\\omega t_0}, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$</div>\n\n<p><img src=\"/../images/ss/lec12_1.jpg\" loading=\"lazy\"></p>\n<p><strong>The Impulse response of Ideal LP</strong></p>\n<p><img src=\"/../images/ss/lec12_2.jpg\" loading=\"lazy\"></p>\n<ul>\n<li>Severe distortion. $BW_{\\delta(t)}\\rightarrow \\infty$, but $BW_{\\text{Lowpass}}&#x3D;\\omega_c$, the higier frequency is eliminated.</li>\n<li>Non-causal. When $t\\lt 0$, $h(t)\\ne 0$.</li>\n</ul>\n<p><strong>Unit-step response of Ideal LP</strong></p>\n<p><img src=\"/../images/ss/lec12_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec12_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec12_5.jpg\" loading=\"lazy\"></p>\n<p>The response is similar to the input if $\\frac{1}{2}&#x3D;\\frac{\\pi}{\\omega_c}\\llless \\tau$. </p>\n<p><strong>Gibbs phenomenon</strong>: 9% overshoot at discontinuity. Use other window functions can eliminate this, e.g. raised-cosine window.</p>\n<h3 id=\"Modulation-and-demodulation\"><a href=\"#Modulation-and-demodulation\" class=\"headerlink\" title=\"Modulation and demodulation\"></a>Modulation and demodulation</h3><p>Means of modulation:</p>\n<p><strong>Spectrum shifting</strong> </p>\n<p>$f(t) &#x3D; g(t)\\cos(\\omega_0t)$, $F(\\omega) &#x3D;\\frac{1}{2\\pi} G(\\omega) * \\pi[\\delta(\\omega - \\omega_0) + \\delta (\\omega + \\omega_0)] &#x3D; \\frac{1}{2}[G(\\omega + \\omega_0) + G(\\omega - \\omega_0)]$.</p>\n<p><img src=\"/../images/ss/lec12_6.jpg\" loading=\"lazy\"></p>\n<p>Demodulation: </p>\n<p><strong>coherent demodulation</strong></p>\n<p>$g_0(t)&#x3D;[g(t)\\cos(\\omega_0 t)]\\cos(\\omega_0t) &#x3D; \\frac{1}{2}g(t) + \\frac{1}{2}g(t)\\cos2\\omega_0t$</p>\n<p><img src=\"/../images/ss/lec12_7.jpg\" loading=\"lazy\"></p>\n<p><strong>Envelope Detection</strong></p>\n<p><img src=\"/../images/ss/lec12_8.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Applications-of-BPF\"><a href=\"#Applications-of-BPF\" class=\"headerlink\" title=\"Applications of BPF\"></a>Applications of BPF</h3><p><strong>Window Function</strong><br>(Page 304)</p>\n<div>$$\nh_a(t) = \\frac{\\sqrt a \\sin\\left(\\frac{\\pi t}{a}\\right)\\cos \\left(\\frac{3\\pi t}{a}\\right)}{\\sqrt{ \\pi} \\pi t}\\\\\nH_a(\\omega) = \\begin{cases}\n  \\frac{1}{2}\\sqrt{\\frac{a}{\\pi}}, \\text{if } \\frac{2\\pi}{a}\\le |\\omega| \\le \\frac{4\\pi}{a},\\\\\n  0, \\text{otherwise}.\n\\end{cases}\n$$</div>\n\n<p><img src=\"/../images/ss/lec13_1.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Recover-Continuous-Time-signal-from-its-Samples\"><a href=\"#Recover-Continuous-Time-signal-from-its-Samples\" class=\"headerlink\" title=\"Recover Continuous Time signal from its Samples\"></a>Recover Continuous Time signal from its Samples</h3><p><strong>Analysis on signal after band-pass filter</strong></p>\n<p>Page 301</p>\n<p><strong>Sampling with impulse func.</strong></p>\n<p>FD analysis:</p>\n<p>Sampled signal(By impulse function):</p>\n<div>$$\nF_s(\\omega) = \\frac{1}{T_s}\\sum_{n=-\\infty}^\\infty F(\\omega - n\\omega_s)\n$$</div>\n\n<p>Ideal LP Filter:</p>\n<div>$$\nH(j\\omega) = \\begin{cases}\n  T_s, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$</div>\n\n<p>Recovered signal: </p>\n<div>$$\nF(\\omega) = F_s(\\omega) \\cdot H(\\omega)\n$$</div>\n\n<p>TD analysis:</p>\n<p>Sampled signal:</p>\n<div>$$\nf_s(t) = \\sum_{n=-\\infty}^\\infty f(nT_s)\\delta(t - nT_s)\n$$</div>\n\n<p>Ideal LP Filter:</p>\n<div>$$\nh(t) = T_s\\frac{\\omega_c}\\pi \\text{Sa}(\\omega_c t)\n$$</div>\n\n<p>Recovered signal:</p>\n<div>$$\nf(t) = f_s(t) * h(t) = T_s\\frac{\\omega_c}\\pi  \\sum_{n=-\\infty}^\\infty f(nT_s) \\text{Sa}(\\omega_c (t-nT_s))\n$$</div>\n\n<p><img src=\"/../images/ss/lec14_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec14_2.jpg\" loading=\"lazy\"></p>\n<p><strong>Sampling with a zero-order hold</strong></p>\n<p><img src=\"/../images/ss/lec14_3.jpg\" loading=\"lazy\"></p>\n<div>$$\nh_0(t) = u(t) - u(t - T_s)\\\\\nf_{s0}(t) = f_s(t)* h_0(t)\n$$</div>\n\n<div>$$\n\\begin{align*} \n&\\mathcal F\\{f_{s0}(t)\\} \\\\&=\\mathcal F\\{f_s(t)\\} \\cdot \\mathcal F\\{h_0(t)\\} \\\\ &=F_s(\\omega) \\cdot H_0(\\omega)\\\\\n&=\\sum_{-\\infty}^{\\infty}F(\\omega - n\\omega_s) \\cdot  \\text{Sa}(\\frac{\\omega_c T_s}{2})e^{-j\\frac{\\omega T_s}{2}}\\\\\n\\end{align*}\n$$</div>\n\n<p>LP Filter for compensation</p>\n<div>$$\nH_{0r}(\\omega) = \\begin{cases}\n  \\frac{1}{\\text{Sa}(\\frac{\\omega T_s}{2})}e^{j\\omega T_s/2}, &|\\omega| \\le \\omega_s/2,\\\\\n  0, &|\\omega|> \\omega_s/2.\n\\end{cases}\n$$</div>\n\n<p>Linear phase response is OK! No needed for delay compensation. </p>\n<p><strong>1st-order hold Sampling</strong></p>\n<p><img src=\"/../images/ss/lec14_4.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Mulitplexing-FDM-and-TDM\"><a href=\"#Mulitplexing-FDM-and-TDM\" class=\"headerlink\" title=\"Mulitplexing FDM and TDM\"></a>Mulitplexing FDM and TDM</h3><p>Transmit mulitple singals over a single channel concurrently.</p>\n<p>Frequency Division Multiplexing (FDM) － OFDM (Orthogonal FDM)</p>\n<p>Time Division Multiplexing (TDM)－sharing slot, statistical multiplexing</p>\n<p>Code Division Multiplexing (CDM)－ Code division, logical multiplexing</p>\n<p>Wavelength Division Multiplexing (WDM)－ Optical carrier</p>\n<p><img src=\"/../images/ss/lec14_5.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec14_6.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec14_7.jpg\" loading=\"lazy\"></p>\n<h2 id=\"Vector-Analysis-of-Signals\"><a href=\"#Vector-Analysis-of-Signals\" class=\"headerlink\" title=\"Vector Analysis of Signals\"></a>Vector Analysis of Signals</h2><h3 id=\"Vector-Space\"><a href=\"#Vector-Space\" class=\"headerlink\" title=\"Vector Space\"></a>Vector Space</h3><p><img src=\"/../images/ss/lec15_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec15_2.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec15_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec15_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec15_5.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Objective-for-singal-decomposition\"><a href=\"#Objective-for-singal-decomposition\" class=\"headerlink\" title=\"Objective for singal decomposition\"></a>Objective for singal decomposition</h3><div>$$\nr(t) = H[e(t)] = H\\left[\\sum_{i=0}^ne_i(t)\\right] = \\sum_{i=0}^nH[e_i(t)]\n$$</div>\n\n<h3 id=\"Basics\"><a href=\"#Basics\" class=\"headerlink\" title=\"Basics\"></a>Basics</h3><p><strong>Orthogonal Vector</strong></p>\n<p><img src=\"/../images/ss/lec15_6.jpg\" loading=\"lazy\"></p>\n<p><strong>Orthogonal Function</strong></p>\n<p>Represend $f_1(t)$ in terms of $f_2(t)$(both real), for $t_1&lt;t&lt;t_2$</p>\n<div>$$\nf_1(t)\\approx c_{12}f_2(t)\n$$</div>\n\n<p>Residual error $\\overline{\\varepsilon^2} &#x3D; \\overline{f_e^2(t)} &#x3D; \\frac{1}{t_2 - t_1}\\int_{t_1}^{t_2}[f_1(t) - c_{12}f_2(t)]^2\\mathrm dt$</p>\n<p>Let $\\frac{\\mathrm d \\overline{\\varepsilon^2}}{\\mathrm d c_{12}} &#x3D; 0$, then $\\overline{\\varepsilon^2}$ is minimized.</p>\n<p>The coefficient can be determined as</p>\n<div>$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt} = \\frac{\\langle f_1, f_2\\rangle}{\\langle f_2, f_2\\rangle}\n$$</div>\n\n<p>If $c_{12} &#x3D; 0$, then $f_1(t), f_2(t)$ are called <strong>Orthogonal Functions</strong>.</p>\n<p>And </p>\n<div>$$\n\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt = 0\n$$</div>\n\n<p><strong>Orthogonal Function Set</strong></p>\n<p>Any real function $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.</p>\n<div>$$\nf(t) = \\sum_{r=1}^n c_rg_r(t)\n$$</div>\n\n<p>According to the minimal mean square error, the coefficient can be determined as</p>\n<div>$$\nc_r = \\frac{\\int_{t_1}^{t_2}f(t)g_r(t)\\mathrm dt}{\\int_{t_1}^{t_2}g_r^2(t)\\mathrm dt} = \\frac{\\langle f, g_r\\rangle}{\\langle g_r, g_r\\rangle}\n$$</div>\n\n<p>If $g_1(t), g_2(t), …, g_n(t)$ are orthogonal to each other, i.e.</p>\n<div>$$\n\\int_{t_1}^{t_2}g_r(t)g_s(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$</div>\n\n<p>Then $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.</p>\n<p>Then $g_1(t), g_2(t), …, g_n(t)$ are called <strong>Orthogonal Function Set</strong>.</p>\n<p>If $\\int_{t_1}^{t_2}g_i^2(t)\\mathrm dt &#x3D; 1$, the orthogonal function set is called <strong>Orthonormal Function Set</strong>.</p>\n<p><strong>Orthogonality of Complex Function</strong></p>\n<div>$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2(t)f_2^*(t)\\mathrm dt} = \\frac{\\langle f_1, f_2^*\\rangle}{\\langle f_2, f_2^*\\rangle}\n$$</div>\n\n<p><strong>Orthogonal Function Set</strong> satisfies</p>\n<div>$$\n\\int_{t_1}^{t_2}g_r(t)g_s^*(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$</div>\n\n<p>The definition of Orthogonal is</p>\n<div>$$\n\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt = \\int_{t_1}^{t_2}f_2(t)f_1^*(t)\\mathrm dt = 0\n$$</div>\n\n<p>NOTE:</p>\n<ul>\n<li><p>If two signals are orthogonal within a given interval, they are not necessarily orthogonal within other intervals.</p>\n</li>\n<li><p>If two signals are not orthogonal, they must be correlated.</p>\n</li>\n</ul>\n<h3 id=\"Complete-Orthogonal-Function-and-Parseval’s-Theorem\"><a href=\"#Complete-Orthogonal-Function-and-Parseval’s-Theorem\" class=\"headerlink\" title=\"Complete Orthogonal Function and Parseval’s Theorem\"></a>Complete Orthogonal Function and Parseval’s Theorem</h3><p><strong>Complete Orthogonal Funtion Set</strong></p>\n<div>$$\n\\overline{\\varepsilon^2} = \\frac{1}{t_2-t_1}\\left[\\int_{t_1}^{t_2}f^2(t)\\mathrm dt  - \\sum_{r = 1}^nc_r^2K_r\\right]\n$$</div>\n\n<p>If $\\lim_{t_2 \\to \\infty}\\overline{\\varepsilon^2} &#x3D; 0$, then ${g_r(t)}$ is said to be a <strong>Complete Orthogonal Function Set</strong>.</p>\n<p>Alternative definition of complete orthogonal set</p>\n<p>Other than the elements in ${g_r(t)}$, there is no finite-energy signal $x(t)$, which satisfies</p>\n<div>$$\n\\int_{t_1}^{t_2}x(t)g_r(t)\\mathrm dt = 0, \\forall r\\\\\n\\text{or } \\int_{t_1}^{t_2}x(t)g_r^*(t)\\mathrm dt = 0, \\forall r\n$$</div>\n\n\n<p>Trigonometric Set</p>\n<div>$$\n\\left\\{\\cos n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\\\\\n\\left\\{\\sin n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\n$$</div>\n\n<p>Complex exponential set</p>\n<div>$$\n\\left\\{e^{jn\\omega_1 t}\\right\\}_{n\\rightarrow\\infty}\n$$</div>\n\n<p><strong>Parseval’s Theorem</strong></p>\n<div>$$\n\\int_{t_1}^{t_2}f(t)^2\\mathrm dt = \\sum_{r=1}^\\infty c_r^2K_r = \\sum_{r=1}^\\infty\\int_{t_1}^{t_2}[c_rg_r(t)]^2\\mathrm dt\n$$</div>\n\n<p>Physical interpretation:</p>\n<p>The energy (power) of a signal always equals to the sum of the energy (power) of all its components in a complete orthogonal function set. </p>\n<p>Mathematical interpretation:</p>\n<p>The norm of vector signals keeps invariant under orthogonal transform.</p>\n<h3 id=\"Correlation\"><a href=\"#Correlation\" class=\"headerlink\" title=\"Correlation\"></a>Correlation</h3><p>Physical interpretation:</p>\n<p>Gauge of the similarity of two signals </p>\n<p><strong>Energy and Power Signals</strong></p>\n<p>Instaneous Power $p(t) &#x3D; i^2(t) R$</p>\n<p>The energy consumed by $R$ in a period</p>\n<div>$$\nE = \\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$</div>\n\n<p>Average Power:</p>\n<div>$$\nP = \\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = \\frac{1}{T_0}R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$</div>\n\n<p>The energy signals and power signals:</p>\n<div>$$\nE = \\lim_{T_0 \\to \\infty}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\\\\\nP = \\lim_{T_0 \\to \\infty}\\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\n$$</div>\n\n<p><strong>Correlation Coefficient</strong></p>\n<div>$$\n\\rho_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\sqrt{\\int_{t_1}^{t_2}f_1^2(t)\\mathrm dt}\\sqrt{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt}} = \\frac{\\langle f_1, f_2\\rangle}{\\sqrt{\\langle f_1, f_1\\rangle}\\sqrt{\\langle f_2, f_2\\rangle}} = \\frac{\\langle f_1, f_2\\rangle}{\\|f_1\\|_2\\|f_2\\|_2} \n$$</div>\n\n<p>If $f_1(t)$ is a linear function of $f_2(t)$, then $\\rho_{12} &#x3D; \\pm1$, $\\overline{\\varepsilon^2} &#x3D; 0$.</p>\n<p>If $f_1(t)$ is orthogonal to $f_2(t)$, then $\\rho_{12} &#x3D; 0$, $\\overline{\\varepsilon^2}$ is maximized.</p>\n<ul>\n<li>Describe the correlation of two signals from the perspective of energy difference.</li>\n<li>Quantitatively measure the correlation of two signals in terms of inner product.</li>\n</ul>\n<p><strong>Correlation Function</strong></p>\n<p>The similarity between one signal with a delayed version of another signal.</p>\n<p>(1) $f_1(t)$ and $f_2(t)$ are both real and energy signals</p>\n<div>$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}(-\\tau)\n$$</div>\n\n<p>(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals</p>\n<p>If $f_1(t) &#x3D; f_2(t) &#x3D; f(t)$</p>\n<p>Autocorrelation:</p>\n<div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f(t)\\mathrm dt\\\\\n$$</div>\n\n<p>(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals</p>\n<div>$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2^*(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1^*(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}^*(-\\tau)\n$$</div>\n\n<p>Autocorrelation:</p>\n<div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f^*(t)\\mathrm dt\\\\\nR(\\tau) = R^*(-\\tau)\n$$</div>\n\n\n<p>(3) $f_1(t)$ and $f_2(t)$ are both real and power signals</p>\n<div>$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p>Autocorrelation</p>\n<div>$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p>(4) $f_1(t)$ and $f_2(t)$ are both complex and power signals</p>\n<div>$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2^*(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p>Autocorrelation</p>\n<div>$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p><strong>Correlation Theorem</strong></p>\n<div>$$\n\\mathcal F(x(t)) = X(\\omega)\\\\\n\\mathcal F(y(t)) = Y(\\omega)\\\\\n\\mathcal F(R_{xy}(\\tau)) = X(\\omega)Y^*(\\omega)\\\\\n$$</div>\n\n<p>If $x(t) &#x3D; y(t)$, The FT of the autocorrelation function is $\\mathcal F[{R_{xx}(\\tau)}] &#x3D; |X(\\omega)|^2$</p>\n<p>If $y(t)$ is a real and even function: $Y^*(\\omega) &#x3D; Y(\\omega)$</p>\n<p> Then the correlation theorem is equivalent to the convolution theorem</p>\n<div>$$\n\\mathcal F(\\int_{-\\infty}^\\infty x(t)y(t-\\tau)\\mathrm dt) = X(\\omega)Y(\\omega)\\\\\n$$</div>\n\n<p>Generally, </p>\n<div>$$\nR_{12}(t) = f_1(t) * f_2(-t)\n$$</div>\n\n<h3 id=\"Energy-amp-Power-Spectral-Density\"><a href=\"#Energy-amp-Power-Spectral-Density\" class=\"headerlink\" title=\"Energy &amp; Power Spectral Density\"></a>Energy &amp; Power Spectral Density</h3><div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt\\\\\n$$</div>\n\n<div>$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2 e^{j\\omega\\tau}\\mathrm d\\omega\\\\\n|F(\\omega)|^2 = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\n$$</div>\n<div>$$\nR(0) = \\int_{-\\infty}^{\\infty}f(t)f^*(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt\\\\\nR(0) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\\\\\n$$</div>\n\n<div>$$\n\\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\n$$</div>\n\n<p><strong>Energy Spectral Density</strong></p>\n<div>$$\n\\mathcal{E}(\\omega) = \\lvert F(\\omega)\\rvert^2\\\\\n$$</div>\n\n<div>$$\n\\mathcal{E}(\\omega) = \\mathcal{F}[R(\\tau)]\\\\\nR(\\tau) = \\mathcal{F}^{-1}[\\mathcal{E}(\\omega)]\\\\\n$$</div>\n\n<p><strong>Power Spectral Density</strong></p>\n<div>$$\n\\mathcal F[ R(\\tau)] = \\mathcal P(\\omega)\\\\\n$$</div>\n\n<p>It is called Power Spectral Density (PSD).</p>\n<p>Wiener-Khinchin Theorem</p>\n<div>$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\mathcal P(\\omega)e^{j\\omega\\tau}\\mathrm d\\tau\\\\\n\\mathcal P(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\omega\\\\\n$$</div>\n\n<h3 id=\"ESD-x2F-PSD-of-the-System-Response\"><a href=\"#ESD-x2F-PSD-of-the-System-Response\" class=\"headerlink\" title=\"ESD&#x2F;PSD of the System Response\"></a>ESD&#x2F;PSD of the System Response</h3><div>$$\n|R(j\\omega)|^2 = |H(j\\omega)|^2|E(j\\omega)|^2\\\\\n\\mathcal{E}_r(\\omega) = |H(j\\omega)|^2\\mathcal{E}_e(\\omega)\\\\\n\\mathcal{P}_r(\\omega) = |H(j\\omega)|^2\\mathcal{P}_e(\\omega)\\\\\n$$</div>\n\n<p><img src=\"/../images/ss/lec16_1.jpg\" loading=\"lazy\"></p>\n<p>The last line of this table is wrong. The correct is:</p>\n<div>$$\nR_h(\\tau) = h(\\tau) * h^*(-\\tau)\n$$</div>\n\n<h3 id=\"Match-Filters\"><a href=\"#Match-Filters\" class=\"headerlink\" title=\"Match Filters\"></a>Match Filters</h3><div>$$\nH(j\\omega) = kS(-j\\omega)e^{-j\\omega t_m}\\\\\nh(t) = ks(t_m - t)\\\\\n$$</div>\n\n<p>$t_m$ is the signal width in TD.</p>\n<h2 id=\"Discrete-time-signals\"><a href=\"#Discrete-time-signals\" class=\"headerlink\" title=\"Discrete time signals\"></a>Discrete time signals</h2><p>Discrete time-axis, but continuous amplitude-axis</p>\n<h3 id=\"Sequence-operation\"><a href=\"#Sequence-operation\" class=\"headerlink\" title=\"Sequence operation\"></a>Sequence operation</h3><p><strong>Addition</strong> $z(n) &#x3D; x(n) + y(n)$</p>\n<p><strong>Multiplication</strong> $z(n) &#x3D; x(n) * y(n)$</p>\n<p><strong>Multiplied a coefficient</strong> $z(n) &#x3D; a * x(n)$</p>\n<p><strong>Shift</strong> $z(n) &#x3D; x(n - m)$ right shift($m&gt;0$), $z(n) &#x3D; x(n +m)$ left shift</p>\n<p><strong>Reflection</strong> $z(n) &#x3D; x(-n)$</p>\n<p><strong>Difference</strong> $\\Delta x(n) &#x3D; x(n + 1) - x(n)$ Forawrd difference, </p>\n<p>$\\nabla x(n) &#x3D; x(n) - x(n - 1)$ Backward difference</p>\n<p>$\\nabla^mx(n) &#x3D; \\nabla(\\nabla^{m-1}x(n))$</p>\n<p><strong>Summation</strong> $z(n) &#x3D; \\sum_{k &#x3D; -\\infty}^{n}x(k)$</p>\n<p><strong>Scaling</strong> $z(n) &#x3D; z(2n)$ squeeze, </p>\n<p>$z(n) &#x3D; x(n&#x2F;2)$, extend</p>\n<h3 id=\"Typical-sequences\"><a href=\"#Typical-sequences\" class=\"headerlink\" title=\"Typical sequences\"></a>Typical sequences</h3><p><img src=\"/../images/ss/lec16_2.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec16_3.jpg\" loading=\"lazy\"></p>\n<p>Relations of several singal waveforms</p>\n<div>$$\nu(n) = \\sum_{k = 0}^{\\infty}\\delta(n - k)\\\\\n\\delta(n) = u(n) - u(n - 1)\\\\\nR_N(n) = u(n) - u(n - N)\\\\\n$$</div>\n\n<h3 id=\"Signal-Decomposition-1\"><a href=\"#Signal-Decomposition-1\" class=\"headerlink\" title=\"Signal Decomposition\"></a>Signal Decomposition</h3><div>$$\nx(n) = \\sum_{m = -\\infty}^{\\infty}x_m\\delta(n - m)\\\\\n$$</div>\n\n<div>$$\n\\delta(n - m) = \\begin{cases}\n1, & n = m\\\\\n0, & n \\neq m\n\\end{cases}\n$$</div>\n\n<h3 id=\"Difference-equations\"><a href=\"#Difference-equations\" class=\"headerlink\" title=\"Difference equations\"></a>Difference equations</h3><p><img src=\"/../images/ss/lec16_4.jpg\" loading=\"lazy\"></p>\n<p>Numerical solution of difference equations</p>\n<p>General form of difference equation:</p>\n<div>$$\n\\sum_{k = 0}^N a_ky(n - k) = \\sum_{r = 0}^M b_ry(n - r)\\\\\n$$</div>\n\n<p><strong>Methods:</strong></p>\n<ul>\n<li>Recursive method</li>\n<li><ul>\n<li>Intuitive, difficult to formulate the closed-form solutions</li>\n</ul>\n</li>\n<li>Time-domain classical method</li>\n<li><ul>\n<li>Obtain homogeneous and particular solutions and using the  boundary condition to determine the coefficients.</li>\n</ul>\n</li>\n<li>The sum of the zero-input and zero-state responses</li>\n<li><ul>\n<li>Convolution (next class)</li>\n</ul>\n</li>\n<li>Z-transform (Chapter 8)</li>\n<li>State variable method (Chapter 11)</li>\n</ul>\n<p><strong>Homogeneous Solution</strong></p>\n<div>$$\n\\sum_{k = 0}^N a_ky(n - k) = 0\\\\\n$$</div>\n\n<p>The <strong>characteristic root</strong> $\\alpha_k$ satisfies:</p>\n<div>$$\na_0\\alpha^N + a_1\\alpha^{N-1} + \\cdots + a_N = 0\\\\\n$$</div>\n\n<p>The homogeneous solution is:</p>\n<div>$$\ny(n) = c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n\\\\\n$$</div>\n\n<p><strong>Particular Solutions</strong>:</p>\n<p><img src=\"/../images/ss/lec16_.jpg\" loading=\"lazy\"></p>\n<p><strong>General steps</strong></p>\n<ol>\n<li>Obtain homogeneous solutions from characteristic equation $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n$</li>\n<li>Determine the form of the particular solution $D(n)$</li>\n<li>The complete solution $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n + D(n)$</li>\n<li>Introduce the boundary condition and set up equations<div>$$\ny(0) = C_1 +C_2 + \\cdots + C_N + D(0)\\\\\ny(1) = C_1\\alpha_1 +C_2\\alpha_2 + \\cdots + C_N\\alpha_N + D(1)\\\\\n\\vdots\\\\\ny(N - 1) = C_1\\alpha_1^{N - 1} + C_2\\alpha_2^{N - 1} + \\cdots + C_N\\alpha_N^{N - 1} + D(N - 1)\\\\\n\\Rightarrow\\\\\nY(k) - D(k) = VC\\\\\nC = V^{-1}(Y(k) - D(k))\\\\\n$$</div></li>\n</ol>\n<h3 id=\"Zero-input-and-zero-state-responses\"><a href=\"#Zero-input-and-zero-state-responses\" class=\"headerlink\" title=\"Zero-input and zero-state responses\"></a>Zero-input and zero-state responses</h3><div>$$\ny(k) = y_{zi}(k) + y_{zs}(k)\n$$</div>\n\n<p><strong>Zero-Input Response</strong><br>$D(k) &#x3D; 0 \\Rightarrow C_{zi} &#x3D; V^{-1}Y_{zi}(k)$</p>\n<p><strong>Zero-State Response</strong></p>\n<div>$$\n\\begin{align*}\n  C_{zs} &= V^{-1}[Y_{zs}(k) - D(k)]\\\\\nC_{zs} &= V^{-1}[Y(k) - Y_{zi}(k) - D(k)]\\\\\nC &= C_{zi} + C_{zs}\\\\\n\\end{align*}\n$$</div>\n\n<p><strong>Natural Response</strong> $\\sum_{k &#x3D; 1}^NC_k\\alpha_k^n$</p>\n<p><strong>Forced Response</strong> $D(n)$</p>\n<p>Characteristics of the boundary condition for difference equations</p>\n<p>N-th order difference equation should have N independent boundary conditions.</p>\n<p>Compared with continuous systems, there are no big differences between $0_+$ and $0_-$ in discrete systems. </p>\n<p>$y(-1), y(-2), \\dots, y(-N)$ are the system memory (storage) before the excitation is added: $0_-$</p>\n<p>Derive (together with the excitation) $y(0), y(1), …, y(N-1): 0_+$</p>\n<p>Using Z-transform can avoid mistakes－similar to the Laplace transform in continuous systems.</p>\n<h3 id=\"Impulse-response-of-DT-systems\"><a href=\"#Impulse-response-of-DT-systems\" class=\"headerlink\" title=\"Impulse response of DT systems\"></a>Impulse response of DT systems</h3><p>Similar to CT System, h(n) reflects system’s property</p>\n<p><strong>Causality</strong> $h(n) &#x3D; h(n) u(n)$ (unlateral, $n\\lt 0$ no response)</p>\n<p><strong>Stability</strong> $\\sum_{n&#x3D;-\\infty}^\\infty |h(n)| \\lt \\infty$ (absolutely summable)</p>\n<pre><code> NOTE:  critical stability can be considered as either stable or unstable, e.g.,  system whose impulse response is a sine sequence\n</code></pre>\n<p>Not all practical discrete systems are necessarily causal：</p>\n<ul>\n<li>Variable is not time, like image processing</li>\n<li>Variable is time, but data has been recorded and processed, like voice processing, meteorology, stock systems.</li>\n</ul>\n<p>Example: Smooth windowing</p>\n<div>$$\ny(n) = \\frac{1}{2M+1}\\sum_{k=-M}^M x(n-k)\n$$</div>\n\n<p>Discrete non-causal system</p>\n<h3 id=\"Convolution-Sum\"><a href=\"#Convolution-Sum\" class=\"headerlink\" title=\"Convolution Sum\"></a>Convolution Sum</h3><div>$$\ny(n) = \\sum_{m = -\\infty}^\\infty x(m)h(n - m) = h(n) * x(n)\n$$</div>\n\n<p>Similar to CT system, also satisfies both distributive and associative laws </p>\n<p>Calculation of convolution：<br>Four steps: reflection, shift, multiplication and summation. </p>\n<p>Calculation of correlation：<br>Cross- &amp; auto-correlation: shift, multiplication &amp; summation. </p>\n<p>Example:</p>\n<div>$$\nx(n) = u(n) - u(n - N)\\\\\nh(n) = a^nu(n)\\\\\ny(n) = x(n) * h(n)\n$$</div>\n\n<div>$$\ny(n) = \\sum_{m = -\\infty}^\\infty [u(m) - u(m - N)]a^{n - m}u(n - m)\n$$</div>\n\n<p>if $n &lt; 0$, then $y(n) &#x3D; 0$</p>\n<p>if $0 \\le n \\lt N - 1$, $y(n) &#x3D; \\sum_{m &#x3D; 0}^na^{n-m} &#x3D; \\frac{1}{1 - a}[1 - a^{n+1}]$</p>\n<p>if $n \\ge N - 1$, $y(n) &#x3D; \\frac{1 - a^{-N}}{1 - a^{-1}}a^n$</p>\n<p><strong>Deconvolution</strong></p>\n<p><strong>Signal retrieval</strong> y(n) and h(n) are known, how to derive x(n)?</p>\n<p><em>Measurement equipment (linear system), like sensor for measuring blood pressure</em></p>\n<p><strong>System identification</strong> y(n) and x(n) are known, how to derive h(n)?</p>\n<p><em>Earthquake signal, like geological survey, oil exploration, etc.</em></p>\n<div>$$\n\\begin{bmatrix*}\n   y(0)\\\\\n   y(1)\\\\\n   y(2)\\\\\n   \\vdots\\\\\n   y(n)\n\\end{bmatrix*} = \n\\begin{bmatrix*}\n  h(0) & 0 & 0 & \\dotsb & 0\\\\\n  h(1) & h(0) & 0 & \\dotsb & 0\\\\\n  h(2) & h(1) & h(0) & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  h(n) & h(n-1) & h(n-2) & \\dotsb & h(0)\\\\\n\\end{bmatrix*}\\begin{bmatrix*}\n   x(0)\\\\\n   x(1)\\\\\n   x(2)\\\\\n   \\vdots\\\\\n   x(n)\n\\end{bmatrix*}\n$$</div>\n\n<p>Thus, </p>\n<div>$$\nx(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} x(m) h(n - m)\\right]/h(0)\\\\\nh(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} h(m) x(n - m)\\right]/x(0)\n$$</div>\n\n<h3 id=\"Important-Concepts\"><a href=\"#Important-Concepts\" class=\"headerlink\" title=\"Important Concepts\"></a>Important Concepts</h3><p><img src=\"/../images/ss/lec17_1.jpg\" loading=\"lazy\"></p>\n<ol>\n<li>Symbol rate :  clock period is $T$, signal symbol rate is $f &#x3D; 1&#x2F;T$.</li>\n<li>Information rate: information rate equals to symbol rate for binary encoding, otherwise, equal to multiplication between symbol rate and number of information bits per symbol.</li>\n<li>Signal bandwidth: the first zero of non-return-to-zero (NRZ) signal’s spectrum is $1&#x2F;T$,  so the signal bandwidth is $B&#x3D;1&#x2F;T &#x3D;f$.</li>\n</ol>\n<blockquote>\n<p>这句话是在介绍非归零码（Non-Return-to-Zero，简称NRZ）信号的带宽计算方式。</p>\n<p>在信号处理和通信中，信号的频谱表示了信号在不同频率上的能量分布。对于一个NRZ信号，它的频谱图中第一个零点（也就是在零周围出现的第一个极小值点）出现在频率为$1&#x2F;T$处，其中$T$是NRZ信号中一个脉冲的时间长度。这是因为NRZ信号的频谱是由一个周期为$T$的方波产生的，其频率成分只包含正弦函数的奇次谐波。其中，最低的一个谐波频率是$f&#x3D;\\frac{1}{T}$，对应的是频率为$f$的正弦波。所以，NRZ信号的带宽$B$就被定义为$f&#x3D;1&#x2F;T$。</p>\n<p>简而言之，NRZ信号的带宽是由脉冲的时间长度决定的，具体来说，带宽等于脉冲频率的一半，即带宽等于$f&#x3D;1&#x2F;T$。</p>\n</blockquote>\n<p>NOTE:</p>\n<p>When NRZ code is used, signal bandwidth &#x3D; symbol rate</p>\n<p>When return-to-zero (RZ) code is used, signal bandwidth &gt; symbol rate</p>\n<p>Using NRZ code can save bandwidth yet high frequency components of the rectangular signal will suffer from the severe inter-symbol interference (ISI). So the raised cosine or Sa function is preferred.</p>\n<blockquote>\n<p>ChatGPT:</p>\n<p>归零码和非归零码都是数字通信中常用的编码方式。</p>\n<p>归零码（Return-to-Zero，简称RZ）是一种二进制码，其中一个信号所代表的位是由一个脉冲表示的。发送二进制“1”时，脉冲电平为高电平，发送二进制“0”时，脉冲电平为低电平。在归零码中，一个信号位所代表的脉冲之后，信号在下一时刻会回到零电平。由于归零码中每个脉冲结束时信号回到零电平，因此这种编码方式具有稳定可靠的特点，但是传输的带宽相对较大。</p>\n<p>非归零码（Non-Return-to-Zero，简称NRZ）的编码方式与归零码不同之处在于，在NRZ信号中，一个信号所代表的位是由一个固定电平表示的。当信号所代表的位是二进制“1”时，固定电平为高电平；当信号所代表的位是二进制“0”时，固定电平为低电平。这种编码方式的好处是带宽更小，但是却存在着在多个二进制“1”连续发送时，出现误解的情况。</p>\n<p>综上所述，归零码是二进制码中脉冲与幅度的双重编码，不易产生传输误码，但其对于通信带宽需求较大；而非归零码不需要对脉冲进行编码，在带宽方面具有一定的优势，但长时间连续发送相同信息时会产生误解。</p>\n</blockquote>\n<h3 id=\"Z-Transform\"><a href=\"#Z-Transform\" class=\"headerlink\" title=\"Z-Transform\"></a>Z-Transform</h3><p>Similar to the L-Tranform.</p>\n<p><strong>Definition</strong></p>\n<div>$$\nX(z) = Z(x(n)) = \\sum_{n = -\\infty}^{\\infty} x(n) z^{-n}\n$$</div>\n\n<p><strong>Z-T of Typical Series</strong></p>\n<p>$z \\in \\Complex$</p>\n<div>$$\n\\delta(n) \\rightarrow 1\\\\\nu(n) \\rightarrow \\frac{1}{1-z^{-1}}(|z| \\gt 1)\\\\\nnu(n) \\rightarrow \\frac{z^{-1}}{(1-z^{-1})^2}(|z| \\gt 1)\\\\\na^n u(n) \\rightarrow \\frac{1}{1-az^{-1}}(|z| \\gt |a|)\\\\\n\\cos(\\omega_0 n) u(n) \\rightarrow \\frac{1-z^{-1}\\cos(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n\\sin(\\omega_0 n) u(n) \\rightarrow \\frac{z^{-1}\\sin(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n$$</div>\n\n<p><strong>The Region of Convergence</strong></p>\n<p><img src=\"/../images/ss/lec18_1.jpg\" loading=\"lazy\"></p>\n<p><strong>Inverse Z-Transform</strong></p>\n<div>$$\nx(n) = \\frac{1}{2\\pi j} \\oint_C X(z) z^{n-1} dz\n$$</div>\n\n<p><strong>Method</strong></p>\n<p><strong>Contour Integration(residue method)</strong></p>\n<p>Right-sided sequence</p>\n<div>$$\nx(n) = \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$</div>\n\n<p>Left-sided sequence</p>\n<div>$$\nx(n) = - \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$</div>\n\n<p><strong>Power series expansion(Long division)</strong></p>\n<p><img src=\"/../images/ss/lec18_2.jpg\" loading=\"lazy\"></p>\n<p>If it is right sided, </p>\n<div>$$\nX(z) = \\sum_{n = 0}^\\infty x(n)z^{-n}\n$$</div>\n\n<p>If it is left sided,</p>\n<div>$$\nX(z) = \\sum_{n = -\\infty}^{-1}x(n)z^{-n}\n$$</div>\n\n<p><strong>Partial Fraction Expansion</strong></p>\n<div>$$\n\\frac{z}{z - a} \\lrarr \\begin{cases}\n a^nu(n), &|z|\\gt |a|\\\\\n -a^nu(-n-1), &|z|\\lt |a|\n\\end{cases}\n$$</div>\n\n<p><img src=\"/../images/ss/lec18_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec18_34jpg.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec18_6.jpg\" loading=\"lazy\"></p>\n<p><strong>Properties of Z-T</strong></p>\n<p><strong>Linearity</strong></p>\n<p>Addition and homogeneity</p>\n<p><font color=\"red\">ROC may change!</font></p>\n<p>i.e. poles are cancelled when added: ROC will enlarge or and shrink.</p>\n<p><strong>Time shifting</strong></p>\n<p>(a) bilateral: If $\\mathcal Z[x(n)] &#x3D; X(z), R_{X_1} &lt; |z| &lt; R_{X_2}$, then $\\mathcal{Z}[x(n-m)] &#x3D; z^{-m}X(z), R_{X_1} &lt; |z| &lt; R_{X_2}$.</p>\n<p>(b) unilateral: if $\\mathcal{Z}[x(n)] &#x3D; X(z), R_{X_1} &lt; |z|$, then $\\mathcal{Z}[x(n-m)] &#x3D; z^{-m}[X(z) + \\sum_{k &#x3D; -m}^{-1}x(k)z^{-k}], R_{X_1}\\lt |z|$, and $\\mathcal{Z}[x(n+m)] &#x3D; z^{m}[X(z) - \\sum_{k &#x3D; 0}^{m-1}x(k)z^{-k}], R_{X_1}\\lt |z|$</p>\n<p>For casual sequence, $n &lt; 0, x(n) &#x3D; 0$, the unilateral is also $\\mathcal{Z}[x(n-m)] &#x3D; z^{-m}X(z)$.</p>\n<p>The reason is that the unilateral z transform doesn’t contain the $n&lt;0$ parts of sequence, but after shifting, sometimes must be counted(right shift), sometimes must be discarded(left shift).</p>\n<p><strong>Linear weighting on sequence(Z domain differentiation)</strong></p>\n<div>$$\n\\mathcal{Z}[x(n)] = X(z) \\Rightarrow nx(n)\\lrarr -z\\frac{dX(z)}{dz}\n$$</div>\n\n<p>Generalization:</p>\n<div>$$\nn^mx(n)\\lrarr \\bigg[-z\\frac{d}{dz}\\bigg]^m X(z)\n$$</div>\n\n<p><strong>Geometric progression(Z-domain scaling)</strong></p>\n<div>$$\na^n(x^n) \\lrarr X(\\frac{z}{a})\\\\\n(R_{x1} \\lt \\bigg|\\frac{z}{a}\\bigg| \\le R_{x2})\n$$</div>\n\n<div>$$\na^{-n}x(n) \\lrarr X(az)\\\\\n(-1)^nx(n) \\lrarr X(-z)\n$$</div>\n\n<p><strong>Initial-value theorem</strong></p>\n<div>$$\nx(0) = \\lim_{z \\rightarrow \\infty }X(z)\n$$</div>\n\n<p><strong>Final-value theorem</strong></p>\n<div>$$\n\\lim_{n \\rightarrow \\infty } x(n) = \\lim_{z \\rightarrow 1}[(z-1)X(z)]\n$$</div>\n\n<p>condition: when $n \\rightarrow \\infty$, $x(n)$ converge </p>\n<p>Thus, the poles of $X(z)$ are inside the unit circle, the radius of ROC is less than 1.</p>\n<p>For $a^nu(n), |a| \\lt 1$, the final value is 0.</p>\n<p>Or, if the pole is on the unit circle, it should be 1, and is of the 1st order.</p>\n<p>$u(n)$’s final value is 1.</p>\n<p><img src=\"/../images/ss/lec19_1jpg.jpg\" loading=\"lazy\"></p>\n<p><strong>Time-domain convolution theorem</strong></p>\n<p>If $\\mathcal{Z}{x(n)} &#x3D; X(z), (R_{x1} \\lt |z| \\lt R_{x2}), \\mathcal{Z}{h(n)} &#x3D; H(z), (R_{h1} \\lt |z| \\lt R_{h2})$</p>\n<div>$$\n\\mathcal{Z}[x(n) * h(n)] = X(z)H(z)\\\\\n\\max(R_{x1}, R_{h1}) \\lt |z| \\lt \\min(R_{x2}, R_{h2})\n$$</div>\n\n<p>If poles are cancelled in multiplication, ROC is enlarged.</p>\n<p>Conclusion: (Z Transform) convolution in time-domain is equivalent to multiplication (of Z Transform) in Z-domain.</p>\n<p><strong>Z domain convolution theorem</strong></p>\n<div>$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(\\frac{z}{v})H(v)v^{-1}dv\n$$</div>\n\n<p>or </p>\n<div>$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(v)H(\\frac{z}{v})v^{-1}dv\n$$</div>\n\n<p>where $C$ is a closed contour in the intersection of ROCs of $X(\\frac{z}{v})$ and $H(v)$ or $X(v)$ and $H(\\frac z v)$.</p>\n<p>let $v &#x3D; \\rho e^{j\\theta}, z &#x3D; r e^{j\\varphi}$, </p>\n<p>then </p>\n<div>$$\n\\mathcal Z[x(n)h(n)] = \\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(\\rho e^{j\\theta})H(\\frac r\\rho e^{-j(\\varphi - \\theta)})d\\theta\n$$</div>\n\n<h3 id=\"Mapping-of-ZT-and-LT\"><a href=\"#Mapping-of-ZT-and-LT\" class=\"headerlink\" title=\"Mapping of ZT and LT\"></a>Mapping of ZT and LT</h3><div>$$\nz = e^{sT} ,\\omega_s = \\frac{2\\pi}{T}\n\\\\\nre^{j\\theta} = e^{(\\sigma + j\\omega)T}\\\\\n$$</div>\n\n<p>then, </p>\n<div>$$\nr = e^{\\sigma T} = e^{2\\pi\\frac{\\sigma}{\\omega_s}}\\\\\n\\theta = \\omega T = 2\\pi\\frac{\\omega}{\\omega_s}\n$$</div>\n\n<p>when $\\sigma$ is constant, </p>\n<p>vertical line in $s$-plane maps the circle in $z$-plane.</p>\n<p>$s$-plane imaginary axis maps the unit circle in $z$-plane.</p>\n<p>when $\\omega$ is constant,</p>\n<p><img src=\"/../images/ss/lec19_2jpg.jpg\" loading=\"lazy\"></p>\n<p><strong>Correspondence of ZT and LT</strong></p>\n<p><img src=\"/../images/ss/lec19_3.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Solving-difference-equation-by-Z-T\"><a href=\"#Solving-difference-equation-by-Z-T\" class=\"headerlink\" title=\"Solving difference equation by Z-T\"></a>Solving difference equation by Z-T</h3><div>$$\n\\sum_{k = 0}^N a_ky(n-k) = \\sum_{r = 0}^M b_rx(n-r)\n$$</div>\n\n<p>Two methods:</p>\n<ul>\n<li>TD method</li>\n<li>Z-T method (notice the ROC)</li>\n</ul>\n<p><strong>ZT method</strong></p>\n<ol>\n<li>perform unilateral Z-T on both sides.</li>\n</ol>\n<p>$x(n-r), y(n-k)$ are both right shifted series</p>\n<div>$$\n\\sum_{k = 0}^N a_kz^{-k}[Y(z) + \\sum_{l = -k}^{-1}y(l)z^{-l} ]= \\sum_{r = 0}^M b_rz^{-r}[X(z) + \\sum_{m = -r}^{-1}x(m)z^{-m} ]\n$$</div>\n\n<ol start=\"2\">\n<li>Derive $Y(z)$</li>\n<li>Perform inverse transform on $Y(z)$ to get $y(n)$(ROC!)</li>\n</ol>\n<p><strong>Zero input response</strong></p>\n<div>$$\nx(n) = 0\\\\\nY(z) = \\frac{-\\sum_{k = 0}^M[a_kz^{-k}\\cdot \\sum_{l = -k}^{-1}y(l)z^{-l}]}{\\sum_{k = 0}^Na_kz^{-k}}\n$$</div>\n\n<p><strong>Zero state response</strong></p>\n<div>$$\ny(l) = 0\\\\\n\\text{ casual sequence }: x(m) = 0\\\\\n\\sum_{k = 0}a_kz^{-k}Y(z) = \\sum_{r = 0}^M b_rz^{-r}X(z)\\\\\nY(z) = X(z)\\cdot\\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}} = X(z)\\cdot H(z)\n$$</div>\n\n<h3 id=\"System-function-of-DT-system\"><a href=\"#System-function-of-DT-system\" class=\"headerlink\" title=\"System function of DT system\"></a>System function of DT system</h3><p><strong>Unit Impulse&#x2F;sample response $h(n)$ and system function H(z)</strong></p>\n<div>$$\ny(n) = x(n) * h(n)\\\\\nY(z) = H(z)\\cdot X(z)\n$$</div>\n\n<div>$$\nH(z) = \\frac{Y(z)}{X(z)} = \\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}}\n$$</div>\n\n<p>Factorization</p>\n<div>$$\nH(z) = \\frac{\\prod_{r = 1}^M(1-z_rz^{-1})}{\\prod_{k=1}^N1-p_kz^{-1}}\n$$</div>\n\n<p>We can draw the conclusions directly from the relationship between Z-T and L-T</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Imaginary axis</td>\n<td>$\\sigma&#x3D;0$</td>\n<td>Constant amplitude</td>\n<td>$r &#x3D; 1$</td>\n<td>Unit circle</td>\n</tr>\n<tr>\n<td>Right half plane</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Left half plane</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Real axis</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><img src=\"/../images/ss/lec20_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec20_2.jpg\" loading=\"lazy\"></p>\n<p><strong>Stability and Causality</strong></p>\n<p>Stable: iff</p>\n<div>$$\n\\sum_{n=-\\infty}^\\infty |h(n)|\\lt \\infty\n$$</div>\n\n<div>$$\nz = 1, H(z) = \\sum_{n=-\\infty}^\\infty h(n)\\lt \\infty\n$$</div>\n\n<p>The condition is ROC of stable system includes the unit circle.</p>\n<p>Causal:</p>\n<div>$$\nh(n) = h(n)u(n)\n$$</div>\n\n<p>Condition is ROC includes $\\infty$: $R_{X_1}\\lt |z|$</p>\n<p><strong>Stable and causal</strong></p>\n<div>$$\na\\le |z| \\le \\infty, a\\le 1\n$$</div>\n\n<h3 id=\"Discrete-time-Fourier-Transform-DTFT\"><a href=\"#Discrete-time-Fourier-Transform-DTFT\" class=\"headerlink\" title=\"Discrete-time Fourier Transform(DTFT)\"></a>Discrete-time Fourier Transform(DTFT)</h3><p><strong>Definition</strong></p>\n<div>$$\n\\mathcal{F}[x(t)\\delta_T(t)] = \\int_{-\\infty}^\\infty x(t)\\delta_T(t)e^{-j\\omega t}dt = \\sum_{n=-\\infty}^\\infty x(nT)e^{-j\\omega nT}\n$$</div>\n\n<p>take $T &#x3D; 1$</p>\n<div>$$\n\\sum_{n=-\\infty}^\\infty x(n)e^{-j\\omega n} = \\text{DTFT[x(n)]}\n$$</div>\n\n<p>The relation ship with Z-T:</p>\n<div>$$\nX(z) = \\sum_{n = -\\infty}^\\infty x(n)z^{-n}, z = e^{j\\omega}\\\\\n$$</div>\n\n<div>$$\nDTFT[x(n)] = X(z)|_{|z|=1} = X(z)|_{z = e^{j\\omega}} = X(e^{j\\omega})\n$$</div>\n\n<p>Inverse transform</p>\n<div>$$\nx(n) = \\frac{1}{2\\pi j}\\oint_{|z| = 1}X(z)z^{n-1}\\mathrm dz=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$</div>\n\n<h3 id=\"Frequency-Response-of-DT-system\"><a href=\"#Frequency-Response-of-DT-system\" class=\"headerlink\" title=\"Frequency Response of DT system\"></a>Frequency Response of DT system</h3><p>The steady-state response to sine sequence</p>\n<div>$$\nx(n) = A\\sin(n\\omega)(n\\ge 0)\\\\\ny_{ss}(n) = A|H(e^{j\\omega})|\\sin(n\\omega + \\varphi)\\\\\nH(e^{j\\omega}) = \\sum_{n=-\\infty}^\\infty h(n)e^{-jn\\omega}\n$$</div>\n\n<p>The FT of $h(n)$, $H(e^{j\\omega})$ is a periodic function with period of $\\omega_s &#x3D; 2\\pi &#x2F;T &#x3D; 2\\pi$.</p>\n<p>If $h(n)$ is real, then the amplitude&#x2F;phase response is even&#x2F;odd function.</p>\n<p>The amplitude is determined within $[0, \\omega_s&#x2F;2]$</p>\n<p><img src=\"/../images/ss/lec20_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec20_4.jpg\" loading=\"lazy\"></p>\n<p>NOTE:</p>\n<ul>\n<li>We can derive the frequency response (function of $\\omega$) by letting $D$ move along the unit circle once.</li>\n<li>$H(j\\omega)$ is periodic. The frequency response from 0 to $\\omega_s&#x2F;2$ can be determined by letting $D$ move along half circle.</li>\n<li>If pole $p_i$ is close to the unit circle, there will be a peak in the frequency response. If zero $z_i$ is close to the unit circle, there will be a notch in the frequency response.</li>\n<li>For statble systems, $p_i$ should be inside the unit circle, while $z_i$ could be inside or outside the unit circle.</li>\n<li>poles and zeros at origin have no influence on amplitude.</li>\n</ul>\n<h3 id=\"Analog-and-digital-Filter\"><a href=\"#Analog-and-digital-Filter\" class=\"headerlink\" title=\"Analog and digital Filter\"></a>Analog and digital Filter</h3><p><strong>Fundamental Principles</strong></p>\n<p><img src=\"/../images/ss/lec20_5.jpg\" loading=\"lazy\"></p>\n<p>The spectrum of $x(t)$ is strictly inside $\\pm \\omega_m$.</p>\n<p>We choose the sampling frequency:$\\omega_s &#x3D; \\frac{2\\pi}{T} \\ge 2\\omega_m$</p>\n<p><img src=\"/../images/ss/lec20_6.jpg\" loading=\"lazy\"></p>\n<p><strong>Classifications of digital filters</strong></p>\n<div>$$\ny(n) = \\sum_{k=0}^M b_kx(n-k) - \\sum_{k=1}^N a_ky(n-k)\n$$</div>\n\n<p>In terms of structure</p>\n<p>recursive: $a_k\\ne 0$ at least for one $k$</p>\n<p>non-recursive: $a_k&#x3D;0$, for all $k$</p>\n<p>In terms of the characteristics of $h(n)$</p>\n<p>Infinite impulse response(IIR): recursive, non-linear phase</p>\n<p>Finite impulse response(FIR): non-recursive, linear phase.</p>\n<p><strong>IIR filter</strong></p>\n<p>Impulse invariance</p>\n<p>Based on the s-domain analog filters.</p>\n<p>Design method 1: <strong>冲激响应不变法</strong></p>\n<p>Replace $\\frac{1}{s-s_k}$ with $\\frac{1}{1-e^{s_kT}z^{-1}}$. Then $H_a(s)$ become $H(z)$.</p>\n<p>The relationship between the continuous and discrete filters:</p>\n<div>$$\nH(z)|_{z = e^{sT}} = \\frac{1}{T}\\sum_{k=-\\infty}^\\infty H_a(s + j\\frac{2\\pi}{T}k)\n$$</div>\n\n<p>The result is just repeat the original filter at sampling frequency, thus it attenuates slower.</p>\n<p>NOTE:The digital filter implemented this way has aliasing.</p>\n<p>The frequency response of analog filter must be attenuated enough within $\\omega_s$.</p>\n<p>This approach can only realize LP and BP filter, but not HP and band-stop one. </p>\n<p><strong>method 2: Bilinear transformation</strong> emerges to address this problem (you can study it by yourself)</p>\n<div>$$\ns = \\frac{2}{T}\\left(\\frac{1 - z^{-1}}{1 + z^{-1}}\\right)\\\\\nz = \\frac{1 + \\frac{sT}{2}}{1 - \\frac{sT}{2}}\n$$</div>\n\n<p>Bilinear transformation is non-linear transformation.</p>\n<p>To implement digital filter, A&#x2F;D and D&#x2F;A are required, along with ROM, RAM, ALU, delay units (shift registers), etc.</p>\n<p><strong>FIR filter</strong></p>\n<div>$$\nH(z) = \\sum_{k = 0}^{N-1}b_kz^{-k} = \\sum_{n=0}^{N-1}h(n)z^{-n}\n$$</div>\n\n<p>Poles are at $z&#x3D;0$. $N - 1$ zeros.</p>\n<p>FIR filter has linear-phase iff</p>\n<div>$$\nh(n) = h(N - 1 - n)(\\text{evenly symmetric})\\\\\nh(n) = -h(N - 1 - n)(\\text{oddly symmetric})\n$$</div>\n\n<p><img src=\"/../images/ss/lec20_7.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec20_8.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Feedback-System-Signal-Flow-Graphs\"><a href=\"#Feedback-System-Signal-Flow-Graphs\" class=\"headerlink\" title=\"Feedback System: Signal Flow Graphs\"></a>Feedback System: Signal Flow Graphs</h3><p><strong>Operator and Transfer Operator:</strong></p>\n<div>$$\np = \\frac{d}{dt}\\\\\n\\frac{1}{p} = \\int_{-\\infty}^t(\\cdot)d\\tau\n$$</div>\n\n<div>$$\n(C_0p^n + C_1p^{n-1} + \\dotsb + C_n)r(t) = (E_0p^m + E_1p^{m - 1} + \\dotsb + E_m)e(t)\\\\\nD(p)r(t) = N(p)e(t)\n$$</div>\n\n<p>Rules:</p>\n<ul>\n<li>Common factors can’t be eliminated.</li>\n<li>Be careful when changing the order of operation($\\frac{d}{dt}\\int_{-\\infty}^tx(\\tau)d\\tau &#x3D; x(t)$, $\\int_{-\\infty}^t\\frac{d}{d\\tau}x(\\tau)d\\tau &#x3D; x(t) - x(-\\infty)$)</li>\n</ul>\n<p>transfer operator:</p>\n<div>$$\nr(t) = \\frac{N(t)}{D(t)}e(t) = H(p)e(t)\n$$</div>\n\n<p><strong>Brief introduction to the signal flow graphs(SFG)</strong></p>\n<p><img src=\"/../images/digital/lec_11_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec21_4.jpg\" loading=\"lazy\"></p>\n<p>Terminnologies in SFG</p>\n<p>Node, Transfer function, Branch(The branch gain is the transfer function), Source node, Sink node, Mixed node.</p>\n<p><strong>Properties of SFG</strong></p>\n<ol>\n<li>Signal only passes through a branch with the direction indicated by the arrowhead.</li>\n<li>Signals of incoming branches are added at a node, and the added signal appears on the all outgoing branches.</li>\n<li>A sink node can be separated from a mixed node.</li>\n<li>For a given system, the SFGs can be different.(equations for a system can be different)</li>\n<li>After the SFG being inversed, the transfer function keeps invariant, but the signals represented by the inner nodes will be different.</li>\n</ol>\n<p>Note: Inversion is done by inversing the transfer direction of each branch, and exchanging the source and sink nodes as well.</p>\n<p>Algebra of SFG</p>\n<p><img src=\"/../images/ss/lec21_5.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec21_6.jpg\" loading=\"lazy\"></p>\n<p>Simplify:</p>\n<p>NOTE: The SFG can be simplified using the following steps:</p>\n<p>a. Merge the cascaded branches to decrease the number of nodes;</p>\n<p>b. Merge the parallel branches to decrease the number of branches;</p>\n<p>c. Eliminate all the loops. </p>\n<p>Then, the system function can be readily derived.</p>\n<p><img src=\"/../images/ss/lec21_7.jpg\" loading=\"lazy\"></p>\n<p><strong>Mason’s Formula</strong></p>\n<div>$$\nH = \\frac{1}{\\Delta} \\sum_k g_k\\Delta_k\n$$</div>\n![](../images/ss/lec21_9.jpg)\n\n<h2 id=\"State-variable-analysis-of-system\"><a href=\"#State-variable-analysis-of-system\" class=\"headerlink\" title=\"State-variable analysis of system\"></a>State-variable analysis of system</h2><div>$$\n\\mathbf {\\lambda = A\\lambda + Be}\\\\\n\\mathbf{r = C\\lambda + De}\n$$</div>\n\n<p>Features of the state-variable analytical method </p>\n<ul>\n<li>(1)Provide internal characteristics of the system</li>\n<li>(2) Convenient to represent and analyze the multi-input, multi-output (MIMO) cases</li>\n<li>(3) Easy to be extended to time-variant or nonlinear cases</li>\n<li>(4) Introduce two important concepts: controllability and observability</li>\n<li>(5) Convenient for numerical computation</li>\n</ul>\n<h3 id=\"General-form-and-setup-method-CT\"><a href=\"#General-form-and-setup-method-CT\" class=\"headerlink\" title=\"General form and setup method (CT)\"></a>General form and setup method (CT)</h3><div>$$\n\\frac{d}{dt}\\mathbf{\\lambda}(t)_{k \\times 1} = \\mathbf{A}_{k \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{B}_{k \\times m}\\mathbf{e}(t)_{m \\times 1}\\\\\n\\mathbf{r}(t)_{r \\times 1} = \\mathbf{C}_{r \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{D}_{r \\times m}\\mathbf{e}(t)_{m \\times 1}\n$$</div>\n\n<p>$r$ responses, $k$ state variables, $m$ inputs.</p>\n<p>For time-variant system, $\\mathbf{A, B, C, D}$ are fuction of $t$.</p>\n<p>Direct methods:</p>\n<ul>\n<li>observation</li>\n<li>Topological analysis</li>\n</ul>\n<p>Used in curcuit analysis.</p>\n<p>Indirect methods:</p>\n<ul>\n<li>From block diagram or flow graph</li>\n<li>From input-output equation</li>\n<li>From transfer function</li>\n</ul>\n<p>Used in controlled system analysis.</p>\n<p><strong>From input-output equation</strong></p>\n<div>$$\n\\frac{r(t)}{e(t)} = \\frac{b_0p^k + \\dotsb + b_k}{p^k + \\dotsb + a_k}\n$$</div>\n\n<p>NOTE : under the zero-state condition, $p$ is equivalent to $s$ </p>\n<div>$$\nH(p) = \\frac{b_0 + b_1p^{-1} + \\dotsb + b_kp^{-k}}{1 + a_1p^{-1} + \\dotsb + a_kp^{-k}}\n$$</div>\n\n<p>The SFG is:</p>\n<p><img src=\"/../images/ss/lec22_11.jpg\" loading=\"lazy\"></p>\n<div>$$\n\\dot{\\lambda}_1 = \\lambda_2\\\\\n\\dot{\\lambda}_2 = \\lambda_3\\\\\n\\vdots\\\\\n\\dot{\\lambda}_k = -a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t)\\\\\nr(t) = b_k\\lambda_1 + b_{k-1}\\lambda_2 + \\dotsb + b_1\\lambda_k + b_0(-a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t))\\\\\n=(b_k - a_kb_0)\\lambda_1 + (b_{k-1} - a_{k-1}b_0)\\lambda_2 + \\dotsb + (b_1 - a_1b_0)\\lambda_k + b_0e(t)\n$$</div>\n\n<div>$$\n\\mathbf A = \\begin{bmatrix}\n  0 & 1 & 0 & \\dotsb & 0\\\\\n  0 & 0 & 1 & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  0 & 0 & 0 & \\dotsb & 1\\\\\n  -a_k & -a_{k-1} & -a_{k-2} & \\dotsb & -a_1\n\\end{bmatrix}\\\\\nB = \\begin{bmatrix}\n  0\\\\\n  0\\\\\n  \\vdots\\\\\n  0\\\\\n  1\n\\end{bmatrix}\\\\\n\\mathbf C = \\begin{bmatrix}\n  b_k - a_kb_0 & b_{k-1} - a_{k-1}b_0 & \\dotsb & b_1 - a_1b_0\n\\end{bmatrix}\\\\\nD = b_0\n$$</div>\n\n<p>If  the order of differential equation on the left side is higher than that on the right side:</p>\n<div>$$\nb_0 = 0, \\mathbf{D} = 0\n$$</div>\n\n<p>If the derivatives of the excitation on the right side are absent,</p>\n<div>$$\n\\mathbf{C} = [b_k, 0, \\dotsb, 0], \\mathbf{D} = 0\n$$</div>\n\n<p><strong>Factorizing Transfer operator</strong></p>\n<p><img src=\"/../images/ss/lec22_12.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec22_13.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec22_14.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec22_15.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec22_16.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec22_17.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec22_18.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Solving-CT-system’s-state-equations\"><a href=\"#Solving-CT-system’s-state-equations\" class=\"headerlink\" title=\"Solving CT system’s state equations\"></a>Solving CT system’s state equations</h3><p><strong>Time domain method</strong> using computer.</p>\n<p><strong>Transform-domain(Laplace-tranform) method</strong></p>\n<div>$$\n\\frac{d}{dt}\\mathbf{}{\\lambda}(t) = \\mathbf{A\\lambda}(t) + \\mathbf{Be}(t)\\\\\n\\mathbf{r}(t) = \\mathbf{C\\lambda}(t) + \\mathbf{De}(t)\\\\\n\\mathbf{\\lambda}(0_-) = \\begin{bmatrix}\n\\lambda_1(0_-)\\\\\n\\lambda_2(0_-)\\\\\n\\vdots\\\\\n\\lambda_k(0_-)\\\\\n\\end{bmatrix}\n$$</div>\n\n<div>$$\ns\\mathbf \\Lambda(s) - \\mathbf{\\lambda}(0_-) = \\mathbf{A\\Lambda}(s) + \\mathbf{BE}(s)\\\\\n\\mathbf{R}(s) = \\mathbf{C\\Lambda}(s) + \\mathbf{DE}(s)\n$$</div>\n\n<div>$$\n\\mathbf{\\Lambda}(s) = (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{BE}(s)\\\\\n\\mathbf R(s) =\\mathbf{C} (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (\\mathbf C(s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{B + D)E}(s) \n$$</div>\n\n<p>Let $\\Psi(s) &#x3D; (s\\mathbf I - \\mathbf A)^{-1}$, which is called <strong>characteristic matrix</strong>.</p>\n<div>$$\n\\mathbf\\lambda(t) = \\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\mathcal{L}^{-1}[\\Psi(s)\\mathbf{B}] * e(t)\\\\\n\\mathbf r(t) = \\mathbf{C}\\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\lbrace\\mathbf{C}\\mathcal{L}^{-1}[\\mathbf\\Psi(s)\\mathbf{B] + D}\\delta(t)\\rbrace * e(t)\n$$</div>\n\n<p><strong>Time-domain method</strong></p>\n<div>$$\ne^{\\mathbf At} = \\sum_{k = 0}^\\infty \\frac{1}{k!}A^kt^k\n$$</div>\n\n<p>properties</p>\n<div>$$\ne^{\\mathbf At}e^{-\\mathbf At} = \\mathbf I\\\\\ne^{\\mathbf At} = [e^{-\\mathbf At}]^{-1}\\\\\n\\frac{d}{dt}e^{\\mathbf At} = \\mathbf Ae^{\\mathbf At} = e^{\\mathbf At} \\mathbf A\\\\\n$$</div>\n\n<div>$$\n\\frac{d}{dt}\\mathbf \\lambda(t) = \\mathbf A\\mathbf \\lambda(t) + \\mathbf B\\mathbf e(t)\\\\\ne^{-\\mathbf At}\\frac{d}{dt}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf A\\mathbf \\lambda(t) + e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\frac{d}{dt}e^{-\\mathbf At}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\lambda(t) = e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\int_0^te^{\\mathbf A(t - \\tau)}\\mathbf B\\mathbf e(\\tau)d\\tau\\\\\n=e^{\\mathbf At}\\lambda(0_-) + e^{\\mathbf At} \\mathbf B * \\mathbf e(t)\n$$</div>\n\n<p>output</p>\n<div>$$\n\\mathbf r(t) = \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\mathbf C e^{\\mathbf At} \\mathbf B * \\mathbf e(t) + \\mathbf D\\mathbf e(t)\\\\\n= \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + [\\mathbf C e^{\\mathbf At} \\mathbf B + \\mathbf D\\delta(t)] * \\mathbf e(t)\n$$</div>\n\n<p>Correspond to LT:</p>\n<div>$$\n\\mathcal{L}[e^{\\mathbf At}] = (s\\mathbf I - \\mathbf A)^{-1}\n$$</div>\n\n<p><strong>Derive System Functions</strong></p>\n<p><img src=\"/../images/ss/lec22_19.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec22_20.jpg\" loading=\"lazy\"></p>\n<h3 id=\"That-for-DT-system\"><a href=\"#That-for-DT-system\" class=\"headerlink\" title=\"That for DT system\"></a>That for DT system</h3><p><strong>State equation setup</strong></p>\n<div>$$\n\\begin{align*}\n  \\mathrm\\lambda(n + 1) &= \\mathbf A\\mathrm\\lambda(n) + \\mathbf B\\mathrm x(n)\\\\\n  \\mathrm y(n) &= \\mathbf C\\mathrm\\lambda(n) + \\mathbf D\\mathrm x(n)\n\\end{align*}\n$$</div>\n\n<p>Solving:</p>\n<div>$$\n\\lambda(n) = \\underbrace{A^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}A^{n-1-i}Bx(i)\\right]u(n-1)}_{\\text{Zero State}}\\\\\ny(n) = \\underbrace{CA^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}CA^{n-1-i}Bx(i)\\right]u(n-1) + Dx(n)u(n)}_{\\text{Zero State}}\n$$</div>\n\n<p>The Impulse response is:</p>\n<div>$$\nh(n) = CA^{n-1}Bu(n-1) + D\\delta(n)\n$$</div>\n\n<p>Calculate $A^n$: Cayley-Hamilton Theorem</p>\n<p><strong>ZT Solution</strong></p>\n<div>$$\n\\begin{align*}\n  z\\mathrm\\Lambda(z) - z\\lambda(0) &= \\mathbf A\\mathrm\\Lambda(z) + \\mathbf B\\mathrm X(z)\\\\\n  \\mathrm Y(z) &= \\mathbf C\\mathrm\\Lambda(z) + \\mathbf D\\mathrm X(z)\n\\end{align*}\n$$</div>\n\n<div>$$\n\\mathrm \\Lambda(z) = (z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + (z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\mathrm X(z)\\\\\n\\mathrm Y(z) = \\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + \\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right]\\mathrm X(z)\n$$</div>\n\n<p>then </p>\n<div>$$\n\\lambda(n) = \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\\\\\ny(n) = \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\n$$</div>\n\n<p>Comparing this with CT solution, we find</p>\n<div>$$\nA^n = \\mathcal{Z}^{-1}\\left[(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\right]\\\\\n$$</div>\n\n<div>$$\nH(z) = C(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\mathbf B + D\n$$</div>\n\n<h3 id=\"Linear-Transform-on-state-vectors\"><a href=\"#Linear-Transform-on-state-vectors\" class=\"headerlink\" title=\"Linear Transform on state vectors\"></a>Linear Transform on state vectors</h3><div>$$\n\\mathbf{\\gamma} = \\mathbf P\\mathbf \\lambda\n$$</div>\n\n<p>The equations become:</p>\n<div>$$\n\\frac{d}{dt}\\gamma(t) =\\mathbf{PAP}^{-1}\\mathbf \\gamma(t) + \\mathbf{PB}e(t)\\\\\n\\mathbf y(t) = \\mathbf {CP}^{-1}\\gamma(t) + \\mathbf D\\mathbf e(t)\n$$</div>\n\n<p>Similarity transform doesn’t change the eigenvalues.</p>\n<p><strong>Transform function matrix keeps invariant under linear transformation.</strong></p>\n<p>We can <strong>diagonalize</strong> the matrix A.</p>\n<p>Calculate eigenvalues $\\alpha$ -&gt; calulate eigenvectors $\\xi$ -&gt; $\\mathbf P^{-1} &#x3D; [\\xi_i]$, $\\hat A &#x3D; \\text{diag}(\\alpha_i)$</p>\n<h3 id=\"Controllable-amp-Observable\"><a href=\"#Controllable-amp-Observable\" class=\"headerlink\" title=\"Controllable &amp; Observable\"></a>Controllable &amp; Observable</h3><p>Controllable is </p>\n<div>$$\n\\text{rank} [A\\ AB\\ \\dots\\ A^{k-1}B] \\text{ is full}\n$$</div>\n\n<p>Uncontrollabilty is the input can’t change the response.</p>\n<p>Obeservability is </p>\n<div>$$\n\\text{rank} \\begin{bmatrix}\n  C\\\\\n  CA\\\\\n  \\vdots\\\\\n  CA^{k-1}\n  \\end{bmatrix}\n  \\text{ is full}\n$$</div>\n\n<p>Unobserverbility is the response is not affected by the input.</p>\n<p>After the diagonalization of A: </p>\n<p>B doesnt contain zero $\\Leftrightarrow$ completely controllable. Otherwise, the 0s is coresponding to the uncontrollable state variables.</p>\n<p>C doesnt contain zero $\\Leftrightarrow$ completely observable. Otherwise, the 0s is coresponding to the unobservable state variables.</p>\n<p>In fact:</p>\n<div>$$\nH(s) = C(s\\mathbf I - \\mathbf A)^{-1}\\mathbf B + D \\stackrel{D = 0}{=} \\sum_{i=1}^n \\frac{C_iB_i}{s - \\alpha_i}\n$$</div>\n\n<p>The $H(s)$ only contains the controllable and observable state variables. So the state and output equations contains more information than the $H(s)$.</p>\n<p><img src=\"/../images/ss/lec23_1.jpg\" loading=\"lazy\"></p>\n<h2 id=\"CDMA\"><a href=\"#CDMA\" class=\"headerlink\" title=\"CDMA\"></a>CDMA</h2><p>Use a set of orthogonal codes to support multiple users by orthorgonal multiplexing.</p>\n<h3 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h3><p>Assume K users need to connect with the base station simultaneously for CDMA system.</p>\n<ol>\n<li>Design a set of orthogonal codes</li>\n<li>Design on the transmitter</li>\n<li>Design on the receiver</li>\n</ol>\n<p>An example of Code 4:</p>\n<div>$$\n\\begin{align*}\n  \\mathbf c_1 &= [1\\ 1\\ 1\\ 1\\ -1\\ -1\\ -1\\ -1]\\\\\n  \\mathbf c_2 &= [1\\ 1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1]\\\\\n  \\mathbf c_3 &= [1\\ -1\\ 1\\ -1\\ 1\\ -1\\ 1\\ -1]\\\\\n  \\mathbf c_4 &= [1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1\\ 1]\n\\end{align*}\n$$</div>\n\n<div>$$\nR_{x, y}(j) = \\begin{cases}\n  \\sum_{k = 0}^{N - 1 - j} x(k)y(k + j), &0 \\le j \\le N - 1\\\\\n  \\sum_{k = 0}^{N - 1 + j} x(k - j)y(k), &-N + 1 \\le j \\le 0\\\\\n  0, & |j| \\ge N\n\\end{cases}\n$$</div>\n\n<p>Must satisfy:</p>\n<div>$$\nR_{k, i}  \\begin{cases}\n  =T, &k = i, \\tau=0\\\\\n  \\ll T, &k \\ne i \\text{ or } \\tau \\ne 0\n  \\end{cases}\n$$</div>\n\n<p>second:</p>\n<p>(1) frequency shifting: $d_k(t)\\cos(\\omega t)$</p>\n<p>(2) spreading: $s_k(t) &#x3D; d_k(t)c_k(t)\\cos(\\omega t)$</p>\n<p>third: coherent detection&#x2F;de-spreading</p>\n<p>Core:</p>\n<ul>\n<li>Orthogonal code design(signal design)</li>\n<li>Code capturing and tracking(signal processing and system design)</li>\n<li>Multi-use  detection and channel estimation(singal processing and system design)</li>\n</ul>\n<h3 id=\"Code-design\"><a href=\"#Code-design\" class=\"headerlink\" title=\"Code design\"></a>Code design</h3><p>requirements:</p>\n<ul>\n<li>sharp auto-correlation curve</li>\n<li>zero cross-correlation</li>\n<li>largest possible orthogonal code set</li>\n<li>highest possible complexity for security performance</li>\n</ul>\n<p>Commonly used codes:</p>\n<ul>\n<li>Walsh code</li>\n<li>PN sequence</li>\n<li>GOLD codes</li>\n</ul>\n<div>$$\nH_1 = (0)\\\\\nH_2 = \\begin{pmatrix}\n  H_1 & H_1\\\\\n  H_1 & \\overline{H_1}\n\\end{pmatrix} = \\begin{pmatrix}\n  0 & 0\\\\\n  0 & 1\n\\end{pmatrix}\\\\\nH_4 = \\begin{pmatrix}\n  H_2 & H_2\\\\\n  H_2 & \\overline{H_2}\n  \\end{pmatrix}\n$$</div>\n\n<ul>\n<li>sliding window capturing</li>\n<li>multiple correlators to detect phase match</li>\n</ul>\n<p>The period of address code is much shorter than the period of data code: $T_c &lt; T_d$, so the modulated signal is much wider in FD, whose spectrum is called <strong>spread spectrum</strong>.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>March 15</p>\n<h2 id=\"Basic\"><a href=\"#Basic\" class=\"headerlink\" title=\"Basic\"></a>Basic</h2><h3 id=\"Classification\"><a href=\"#Classification\" class=\"headerlink\" title=\"Classification\"></a>Classification</h3><p>Deterministic &amp; random</p>\n<p>Periodic&#x2F;non-periodic</p>\n<p>Continuous&#x2F;Discrete(time)</p>\n<p>Analog&#x2F;Digital(Amplitude &amp; time)</p>\n<h3 id=\"Operations\"><a href=\"#Operations\" class=\"headerlink\" title=\"Operations\"></a>Operations</h3><p>Shifting</p>\n<p>Reflection</p>\n<p>Scaling</p>\n<p>Diffrential</p>\n<p>Integral</p>\n<p>Addition</p>\n<p>Multiplication</p>\n<p>Convolution</p>\n<div>$$\nf_1(t) * f_2(t) = \\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$</div>\n\n<h3 id=\"Singularity-Signals\"><a href=\"#Singularity-Signals\" class=\"headerlink\" title=\"Singularity Signals\"></a>Singularity Signals</h3><h4 id=\"Unit-ramp-function\"><a href=\"#Unit-ramp-function\" class=\"headerlink\" title=\"Unit ramp function\"></a>Unit ramp function</h4><div>$$\nR(t) = 0, t\\lt 0; t, t>0\n$$</div>\n\n<h4 id=\"Unit-step-function\"><a href=\"#Unit-step-function\" class=\"headerlink\" title=\"Unit step function\"></a>Unit step function</h4><div>$$\nu(t) = 0, t<0;1/2, t=0;1, t>0\n$$</div>\n\n<h4 id=\"Rectangular-pulse\"><a href=\"#Rectangular-pulse\" class=\"headerlink\" title=\"Rectangular pulse\"></a>Rectangular pulse</h4><div>$$\nu(t) - u(t-t_0)\n$$</div>\n\n<h4 id=\"Sign-function\"><a href=\"#Sign-function\" class=\"headerlink\" title=\"Sign function\"></a>Sign function</h4><div>$$\nsgn(t) = 1, t>0;-1, t<0\n$$</div>\ndefine $sgn(0)=0$, then $sgn(t)=2u(t)-1$\n\n<h4 id=\"Unit-impulse-function\"><a href=\"#Unit-impulse-function\" class=\"headerlink\" title=\"Unit impulse function\"></a>Unit impulse function</h4><p>Dirac definition</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}\\delta(t)\\mathrm dt=1\\\\\n\\delta(t)=0(t\\ne 0)\n$$</div>\n<div>$$\n\\delta(t)=\\lim_{\\tau \\rightarrow0}\\left[U(t+\\frac\\tau2)-U(t-\\frac \\tau 2)\\right]\n$$</div>\n\n<div>$$\n\\int_{-\\infty}^{\\infty}\\delta(t)f(t)=f(0)\\\\\n\\int_{-\\infty}^{\\infty}\\delta(t - t_0)f(t)=f(t_0)\\\\\n\\delta(t)=\\delta(-t)\\\\\n\\frac{d}{dt}u(t)=\\delta(t)\n$$</div>\n\n<h4 id=\"Impulse-doublet-function\"><a href=\"#Impulse-doublet-function\" class=\"headerlink\" title=\"Impulse doublet function\"></a>Impulse doublet function</h4><p>$\\delta^\\prime(t)$<br>Double impulses at t&#x3D;0 which are mirror-imaged with their amplitude of infinite. </p>\n<div>$$\n\\int^{\\infty}_{-\\infty}\\delta^\\prime(t)\\mathrm dt=0\\\\\n\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t)\\mathrm dt=-f^{\\prime}(0)\\\\\n\\text{shifted:}\\int^{\\infty}_{-\\infty}f(t)\\delta^\\prime(t-t_0)\\mathrm dt=-f^{\\prime}(t_0)\\\\\n$$</div>\n![](../images/ss/lec2_.jpg)\n\n<h3 id=\"Signal-Decomposition\"><a href=\"#Signal-Decomposition\" class=\"headerlink\" title=\"Signal Decomposition\"></a>Signal Decomposition</h3><div>$$\nf(t) = f_D+f_A(t)\\\\\nf(t)=f_e(t)+f_o(t)\\\\\nf(t)=f_r(t)+jf_i(t)\\\\\nf_r(t)=\\frac{1}{2}\\left[f(t)+f^*(t)\\right]\\\\\nf_i(t)=\\frac{1}{2}\\left[f(t)-f^*(t)\\right]\n$$</div>\n\n<h4 id=\"Pulse-Component\"><a href=\"#Pulse-Component\" class=\"headerlink\" title=\"Pulse Component\"></a>Pulse Component</h4><div>$$\nf(t)=\\int_{-\\infty}^{\\infty}f(t_1)\\delta(t-t_1)\\mathrm dt_1\n$$</div>\n\n<p>We also have orthogonal function decomposition(Chap.3, Chap.6).</p>\n<h3 id=\"System-modeling-and-Classification\"><a href=\"#System-modeling-and-Classification\" class=\"headerlink\" title=\"System modeling and Classification\"></a>System modeling and Classification</h3><p>System model can be represented by math equation(including input-output description and state variables or state equation) graphic symbol and block diagrams.</p>\n<p>We use the input-output description mostly. If controling something internal is needed, state euqtion is useful.</p>\n<p>Block diagram: </p>\n<p><img src=\"/../images/ss/lec2_2.jpg\"><br><img src=\"/../images/ss/lec2_3.jpg\"></p>\n<h3 id=\"System-classification\"><a href=\"#System-classification\" class=\"headerlink\" title=\"System classification\"></a>System classification</h3><h4 id=\"Linear-or-Non-linear\"><a href=\"#Linear-or-Non-linear\" class=\"headerlink\" title=\"Linear or Non-linear\"></a>Linear or Non-linear</h4><div>$$\ne_1(t)\\rightarrow r_1(t),\ne_2(t)\\rightarrow r_2(t)\\Rightarrow\\\\\na_1e_1(t)+a_2e_2(t)\\rightarrow a_1r_1(t)+a_2r_2(t)\n$$</div>\n\n<h4 id=\"Time-variant-or-Time-invariant\"><a href=\"#Time-variant-or-Time-invariant\" class=\"headerlink\" title=\"Time-variant or Time-invariant\"></a>Time-variant or Time-invariant</h4><h4 id=\"Memory-or-Memoryless\"><a href=\"#Memory-or-Memoryless\" class=\"headerlink\" title=\"Memory or Memoryless\"></a>Memory or Memoryless</h4><p>with memory: dynamic system, differential equation</p>\n<p>without memory: instant system, algebraic equation</p>\n<h4 id=\"Continuous-or-Discrete\"><a href=\"#Continuous-or-Discrete\" class=\"headerlink\" title=\"Continuous or Discrete\"></a>Continuous or Discrete</h4><p>Continuous  Differential equation</p>\n<p>Discrete  Difference equation</p>\n<h4 id=\"Lumped-or-Distributed-Parameter\"><a href=\"#Lumped-or-Distributed-Parameter\" class=\"headerlink\" title=\"Lumped- or Distributed-Parameter\"></a>Lumped- or Distributed-Parameter</h4><p>Lumped: constant coefficient differential equation</p>\n<p>Distributed: partial equation</p>\n<h4 id=\"Causal-or-Non-Causal\"><a href=\"#Causal-or-Non-Causal\" class=\"headerlink\" title=\"Causal or Non-Causal\"></a>Causal or Non-Causal</h4><p>when $t&lt;0, e(t)&#x3D;0 \\Rightarrow t&lt;0, r(t)&#x3D;0$ Generic definition?</p>\n<p>the future state cannot have effect on now state. The state of causal system can only be determined by now and past states.</p>\n<h4 id=\"Reversible-or-irreversible\"><a href=\"#Reversible-or-irreversible\" class=\"headerlink\" title=\"Reversible or irreversible\"></a>Reversible or irreversible</h4><p>different input to different output, otherwise irreversible.</p>\n<h3 id=\"LTI-System\"><a href=\"#LTI-System\" class=\"headerlink\" title=\"LTI System\"></a>LTI System</h3><h4 id=\"Linearity\"><a href=\"#Linearity\" class=\"headerlink\" title=\"Linearity\"></a>Linearity</h4><p>Linearity leads to superposition and homogeneity.</p>\n<h4 id=\"Time-Invariant\"><a href=\"#Time-Invariant\" class=\"headerlink\" title=\"Time-Invariant\"></a>Time-Invariant</h4><p>a time shift in the input results in a same time shift in the output.</p>\n<div>$$\ne(t)\\rightarrow r(t)\\Rightarrow e(t-t_0)\\rightarrow r(t-t_0)\\\\\n\\lim_{\\Delta t\\rightarrow 0}\\frac{e(t)-e(t-\\Delta t)}{\\Delta t}\\rightarrow \\lim_{\\Delta t\\rightarrow 0}\\frac{r(t)-r(t-\\Delta t)}{\\Delta t}\\\\\n\\frac{\\mathrm de(t)}{dt}\\rightarrow \\frac{\\mathrm dr(t)}{dt}\n$$</div>\n\n<p>If every coefficient is time independent, the system is time invariant.</p>\n<h2 id=\"Time-Domain-TD-Analysis\"><a href=\"#Time-Domain-TD-Analysis\" class=\"headerlink\" title=\"Time-Domain(TD) Analysis\"></a>Time-Domain(TD) Analysis</h2><div>$$\nC_0\\frac{d^nr(t)}{dt^n}+C_1\\frac{d^{n-1}r(t)}{dt^{n-1}} + ... + C_nr(t)\\\\\n=E_0\\frac{d^me(t)}{dt^m}+E_1\\frac{d^{m-1}e(t)}{dt^{m-1}}+...+E_me(t)\n$$</div>\n\n<p><strong>Three Steps</strong></p>\n<ul>\n<li>Homogeneous</li>\n<li>Particular</li>\n<li>Calculation on coefficients</li>\n</ul>\n<h3 id=\"Determining-Coefficients\"><a href=\"#Determining-Coefficients\" class=\"headerlink\" title=\"Determining Coefficients\"></a>Determining Coefficients</h3><p>If functions are continuous, we can get their boundary conditions by determining the derivatives.</p>\n<p>Then the coefficients can be solved by multipling the inverse of Vandermonde matrix with the boundary condition matrix.</p>\n<h4 id=\"Zero-input-and-state-Responses\"><a href=\"#Zero-input-and-state-Responses\" class=\"headerlink\" title=\"Zero-input and -state Responses\"></a>Zero-input and -state Responses</h4><p><strong>Zero-input response</strong> The response caused by the initial state (i.e., energy originally stored in the system), and it is denoted by $r_{zi}(t)$</p>\n<p><strong>Zero-state response</strong> $r(0_-)\\equiv 0$, the response caused only by the external excitation and it is denoted by $r_{zs}(t)$</p>\n<p><img src=\"/../images/ss/lec3_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec3_2.jpg\"></p>\n<p>The combination of zero-input response and the zero-state response is not necessarily linear, since the existence of constant. If one of them vanishes, the other is linear.</p>\n<h3 id=\"Impulse-and-Step-Responses\"><a href=\"#Impulse-and-Step-Responses\" class=\"headerlink\" title=\"Impulse and Step Responses\"></a>Impulse and Step Responses</h3><p><strong>Impulse Response</strong> the zero-state response $h(t)$ to $\\delta (t)$, which can be equalized to the initial condition.</p>\n<p>Note: normally $n&gt;m$.</p>\n<p><strong>Unit Step Response</strong> The zero-state response $g(t)$ to $u(t)$</p>\n<p>There might be a forced term in $g(t)$.</p>\n<div>$$\ng(t) = \\int_0^th(\\tau)d\\tau\n$$</div>\n\n<h3 id=\"Convolution\"><a href=\"#Convolution\" class=\"headerlink\" title=\"Convolution\"></a>Convolution</h3><p>Zero-state required</p>\n<div>$$\ne(t) = \\int_{-\\infty}^{\\infty}e(\\tau)\\delta(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=\\int_{-\\infty}^{\\infty}e(\\tau)h(t-\\tau)\\mathrm d\\tau\\\\\n\\Rightarrow r(t)=e(t)*h(t)\n$$</div>\n\n<p>the definition of convoluiton:</p>\n<div>$$\nf_1(t)*f_2(t)=\\int_{-\\infty}^{\\infty}f_1(\\tau)f_2(t-\\tau)\\mathrm d\\tau\n$$</div>\n\n<p><strong>Integral interval</strong> $e(t)&#x3D;0, \\forall t&lt;0$, $h(t)&#x3D;0,\\forall t&lt;0$, so $r(t)&#x3D;\\int_0^t{e(\\tau)h(t-\\tau)\\mathrm d\\tau}$</p>\n<p>The condition for applying convolution:</p>\n<ul>\n<li>For linear system ONLY</li>\n<li>For time variant systems, $h(t, \\tau)$ means response at time $t$ generated by the impulse at time $\\tau$, then $r(t)&#x3D;\\int_0^th(t,\\tau)e(\\tau)\\mathrm d \\tau$; for time-invariant system is a special case, $h(t,\\tau)&#x3D;h(t-\\tau)$.</li>\n</ul>\n<p><strong>The Properties of Convolution</strong> The commutative property, the distributive property, the associative property</p>\n<p>Differential:</p>\n<div>$$\n(f_1(t)*f_2(t))^\\prime=f_1^\\prime(t)*f_2(t)\n$$</div>\n\n<p>Integral</p>\n<div>$$\n\\int f_1(t)*f_2(t)=f_1(t) * \\int f_2(t)\n$$</div>\n\n<div>$$\n(f_1(t) * f_2(t))^{(i)}=f_1^{(j)}(t) * f_2^{(i-j)}(t)\n$$</div>\n\n<p><strong>Convolution with $\\delta (t)$ or $u(t)$</strong></p>\n<p>(1) $f(t) * \\delta(t) &#x3D; f(t)$</p>\n<p>(2) $f(t) * \\delta(t - t_0) &#x3D; f(t-t_0)$</p>\n<p>(3) $f(t) * u(t) &#x3D; \\int_{\\infty}^{t}f(\\tau)\\mathrm d\\tau$</p>\n<p>(4) $f(t) * \\delta^\\prime(t) &#x3D; f^\\prime(t)$</p>\n<h2 id=\"Fourier-Transform\"><a href=\"#Fourier-Transform\" class=\"headerlink\" title=\"Fourier Transform\"></a>Fourier Transform</h2><h3 id=\"Fourier-Series\"><a href=\"#Fourier-Series\" class=\"headerlink\" title=\"Fourier Series\"></a>Fourier Series</h3><p>requirements:</p>\n<ul>\n<li>has finite number of discontinuities</li>\n<li>has finite number of maxima and minima</li>\n<li>$\\int_{t_0}^{t_0+T_1} |f(t)|\\mathrm dt &lt; \\infty$</li>\n</ul>\n<div>$$\n\\begin{align*}\nf(t)&=a_0+\\sum_{n=1}^\\infty \\left[a_n\\cos(n\\omega_1)t + b_n\\sin(n\\omega_1t)\\right]\\\\\n&=c_0 + \\sum_{n=1}^\\infty c_n\\cos \\left(n\\omega_1t+\\varphi_n \\right)\\\\\n&=\\sum_{n=-\\infty}^{\\infty}F_ne^{jn\\omega_1 t}\n\\end{align*}\n$$</div>\n\n<div>$$\n\\begin{align*}\n    a_0&=\\frac{1}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\mathrm dt=c_0\\\\\n    a_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\cos(n\\omega_1t)\\mathrm dt\\\\\n    b_n&=\\frac{2}{T_1}\\int_{t_0}^{t_0+T_1}f(t)\\sin(n\\omega_1t)\\mathrm dt\\\\\n    c_n&=\\sqrt{a_n^2+b_n^2}\\\\\n    \\varphi_n&=-\\tg^{-1}\\frac{b_n}{a_n}\\\\\n    F_n&=\\frac 1{T_1}\\int_{t_0}^{t_0+T_1}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\n    &=\\frac 12e^{j\\varphi_n}\\\\\n    &=\\frac 12(a_n-jb_n)\n\\end{align*}\n$$</div>\n\n<p><strong>note</strong> When $b_n&#x3D;0$, $\\varphi_n &#x3D; a_n &gt; 0\\ ?\\ 0:\\pi$</p>\n<p>In the last part, the negative frequency is introduced for the convenience of the signal analysis. Therefore the amplitude is reduced to half.</p>\n<p><strong>FS for special functions</strong></p>\n<ol>\n<li>Even function $c_n&#x3D;a_n, \\varphi_n &#x3D; 0, F_n&#x3D;F_{-n}&#x3D;\\frac 12 a_n$</li>\n<li>Odd function $a_0&#x3D;0, a_n&#x3D;0, \\varphi_n&#x3D;-\\frac{\\pi}{2}, F_n&#x3D;F_{-n}&#x3D;-\\frac{1}{2}jb_n$</li>\n<li>Half-wave Odd (odd harmonic) function, $f(t)&#x3D;-f\\left(t\\pm \\frac{T_1}2{}\\right)$, contains only odd harmonics(both sine and cosine)</li>\n<li>Finite term series</li>\n</ol>\n<h3 id=\"FS-for-typical-periodic-signals\"><a href=\"#FS-for-typical-periodic-signals\" class=\"headerlink\" title=\"FS for typical periodic signals\"></a>FS for typical periodic signals</h3><p><strong>Periodic square wave</strong></p>\n<div>$$\nf(t)=\\frac{E\\tau}{T_1}+\\sum_{n=1}^{\\infty}\\frac{2E\\tau}{T_1}\\text{Sa}(\\frac{n\\omega_1\\tau}{2})\n$$</div>\n\n<ol>\n<li>Spectrum is discrete with frequency spacing $\\omega_1 &#x3D; \\frac{2\\pi}{T_1}$. When $T_1 \\rightarrow \\infty$, the spectrum will be continuous.</li>\n<li>Amplitude: $\\text{Sa}\\left(\\frac{n\\pi\\tau}{T_1}\\right)$ or $\\text{Sa} \\left(\\frac{n\\omega_1\\tau}{2}\\right)$, cross zero when $\\omega_1 &#x3D; \\frac{2m\\pi}{\\tau}$</li>\n<li>Non-zero FS coefficients of a aperiodic signal are infinite with most energy concentrated at low frequency components (within $\\left(-\\frac{2\\pi}{\\tau},\\frac{2\\pi}{\\tau}\\right)$). Thus we define the bandwith $B_{\\omega} &#x3D; \\frac{2\\pi}{\\tau}$</li>\n</ol>\n<p><strong>Periodic symmetric square wave</strong></p>\n<p>Since the spectrum crosses zero when $\\omega_1 &#x3D; \\frac{2m\\pi}{\\tau}$, the even harmonic vanishes. Also the sine component vanishes.</p>\n<div>$$\nc_n = \\frac{2E\\tau}{T_1}\\left|\\text{Sa}\\left(\\frac{n\\omega_1\\tau}{2}\\right)\\right|\\\\\nf(t) = \\frac{2E}{\\pi}\\left[\\cos(\\omega_1t) - \\frac{1}3\\cos(3\\omega_1t) + \\frac{1}{5}\\cos(5\\omega_1t)-...\\right]\n$$</div>\n\n<p><strong>Periodic Serrated Pulse</strong></p>\n<div>$$\nf(t) = \\sum_{n = 1}^\\infty \\frac{E}{n\\pi}(-1)^{n+1}\\sin (n\\omega_1t)\n$$</div>\n\n<p><strong>Periodic Triangular Pulse</strong></p>\n<div>$$\nf(t)=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{n^2}\\sin^2\\left(\\frac{n\\pi}{2}\\right)\\cos(n\\omega_1t)\\\\=\\frac E2 + \\frac{4E}{\\pi^2}\\sum_{n=1}^\\infty\\frac{1}{(2n-1)^2}\\cos((2n-1)\\omega_1t)\n$$</div>\n\n<p><strong>consine of non-negative values</strong></p>\n<div>$$\nf(t) = \\frac E\\pi - \\frac{2E}{\\pi}\\sum_{n=1}^\\infty\\frac{1}{n^2-1}\\cos(\\frac {n\\pi}2)\\cos(n\\omega_1t)\n$$</div>\n\n<p><strong>cosine of absoulute values</strong></p>\n<div>$$\nf(t) = \\frac{2E}{\\pi} + \\frac{4E}{\\pi}\\sum_{n=1}^\\infty (-1)^{n+1}\\frac{1}{4n^2-1}\\cos(2n\\omega_0t)\n$$</div>\n\n<p>其中$\\omega_0$ &#x3D; $2\\omega_1$</p>\n<h3 id=\"Fourier-Transform-1\"><a href=\"#Fourier-Transform-1\" class=\"headerlink\" title=\"Fourier Transform\"></a>Fourier Transform</h3><p>The case where $T_1\\rightarrow \\infty$. Signal becomes aperiodic.</p>\n<p>Also, $\\omega_1\\rightarrow 0$ results in the continuous frequency axis. For square wave the magnitude $\\frac{E\\tau}{T_1}\\rightarrow 0$.</p>\n<div>$$\nf(t) =\\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)e^{jn\\omega_1 t}\\\\\nF(n\\omega_1) = \\frac 1T_1\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\n$$</div>\n\n<p>We use spectrum density to replace spectrum, making the magnitude dropping to zero remain its meaning.</p>\n<div>$$\n\\frac{F(n\\omega_1)}{\\omega_1} = \\frac{1}{2\\pi}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm dt\\\\\nF(\\omega) = \\lim_{\\omega_1\\rightarrow 0}\\frac{2\\pi F(n\\omega_1)}{\\omega_1}=\\lim_{T_1\\rightarrow \\infty}\\int_{-\\frac {T_1}2}^{\\frac {T_1}2}f(t)e^{-jn\\omega_1t}\\mathrm d t=\\int_{-\\infty}^\\infty f(t)e^{-j\\omega t}\\mathrm d t\\\\\nf(t) = \\sum_{n=-\\infty}^{\\infty}F(n\\omega_1)\\cdot \\frac{1}{\\omega_1}e^{jn\\omega_1 t} \\Delta(n\\omega_1) = \\frac{1}{2\\pi}\\int_{-\\infty}^\\infty F(\\omega)e^{j\\omega t}\\mathrm d\\omega\n$$</div>\n\n<div>$$\nF(\\omega) = |F(\\omega)|e^{j\\varphi(\\omega)}\n$$</div>\n\n<p>The fourier transfrom is continuous waveform, where every frequency has no energy but energy density, used to analyse aperiodic function.</p>\n<p>Sufficient condition, but not necessary.</p>\n<div>$$\n\\int_{-\\infty}^\\infty |f(t)|\\mathrm dt<\\infty\n$$</div>\n\n<h3 id=\"FT-for-typical-aperiodic-signals\"><a href=\"#FT-for-typical-aperiodic-signals\" class=\"headerlink\" title=\"FT for typical aperiodic signals\"></a>FT for typical aperiodic signals</h3><p><strong>Rectangular pulses</strong></p>\n<div>$$\nF(\\omega) = \\int_{-\\tau/2}^{\\tau/2} Ee^{-j\\omega t}\\mathrm dt = E\\tau \\text{Sa}\\left(\\frac{\\omega \\tau}{2}\\right)\n$$</div>\n\n<p><strong>Raised Cosine Signal</strong></p>\n<div>$$\nf(t) = \\frac{E}{2}(1+\\cos\\frac{\\pi t}{\\tau})(u(t+\\tau) - u(t - \\tau))\\\\\nF(\\omega) = \\int_{-\\tau}^{\\tau}(1+\\cos\\frac{\\pi t}{\\tau})\\mathrm dt = \\frac{E\\tau}{1 - \\left(\\frac{\\omega \\tau}{\\pi}\\right)^2}\\text{Sa}({\\omega \\tau})\n$$</div>\n\n<p>More compacted than square signal($|F(\\omega)|\\propto \\frac 1{\\omega^3}$). An explanation is that the raised cosine has no discontinuities.</p>\n<p>Generally:</p>\n<ol>\n<li>$f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega}$</li>\n<li>$\\frac{d}{dt}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^2}$</li>\n<li>$\\frac{d^2}{dt^2}f(t)$ has discontinuities, $|F(\\omega)|\\propto \\frac 1{\\omega^3}$</li>\n</ol>\n<p>The <strong>width</strong> $\\tau$ of the raised cosine signal is defined at $\\frac E2$ rather than at the bottom, making it easy to compare with<br>     the rectangular pulse of same width. The first zeros of the<br>   frequency spectrum are identical.</p>\n<p>raised consine is energy-concentrative and has been widely used in digital communications.</p>\n<p><strong>Single-sided exponential singal</strong> </p>\n<div>$$\nf(t) = e^{-at}u(t)\\\\\nF(\\omega) = \\frac{1}{a+j\\omega}\n$$</div>\n\n<p><strong>Two-sided, anti-symmetric exponential signal</strong></p>\n<div>$$\nf(t) = -e^{at}u(-t) + e^{-at}u(t)\\\\\nF(\\omega) = \\frac{-2j\\omega}{a^2+\\omega^2}\n$$</div>\n\n<p><strong>Sign function</strong></p>\n<div>$$\n\\text{sgn}(t) = u(t) - u(-t)\\\\\nF(\\omega) = \\lim_{a\\rightarrow 0}\\frac{-2j\\omega}{a^2+\\omega^2}= \\frac{2}{j\\omega}\n$$</div>\n\n<p><strong>Gaussian singal</strong></p>\n<div>$$\nf(t) = Ee^{-\\left(\\frac{t}{\\tau}\\right)^2}\\\\\nF(\\omega) = \\sqrt \\pi E\\tau e^{-\\left(\\frac{\\omega\\tau}{2}\\right)^2}\n$$</div>\n\n<p><strong>Sinc Function</strong></p>\n<div>$$\nf(t) = \\frac{E}{\\pi}\\frac{\\sin(\\omega_c t)}{t}\\\\\nF(\\omega) = E(u(\\omega - \\omega_c ) + u(\\omega + \\omega_c ))\\\\\n$$</div>\n\n\n<h3 id=\"FT-on-impulse-and-step-functions\"><a href=\"#FT-on-impulse-and-step-functions\" class=\"headerlink\" title=\"FT on impulse and step functions\"></a>FT on impulse and step functions</h3><div>$$\n\\mathcal F[\\delta(t)] = 1\\\\\n\\mathcal F[1] = 2\\pi \\delta(\\omega)\n$$</div>\n\n<p>The spectrum of impulse function covers the entire frequency range. The interferences caused by a variety of electric sparks always cover the full frequency range.</p>\n<div>$$\n\\mathcal F[\\delta^\\prime (t)]= j\\omega\\\\\n\\mathcal F[\\delta^{(n)}(t)] = (j\\omega)^n\n$$</div>\n\n<div>$$\n\\mathcal F[u(t)] = \\pi \\delta(\\omega) + \\frac{1}{j\\omega}\n$$</div>\n\n<p>Due to the DC component in u(t), an impulse exists.</p>\n<h3 id=\"Properties-of-FT\"><a href=\"#Properties-of-FT\" class=\"headerlink\" title=\"Properties of FT\"></a>Properties of FT</h3><p><strong>Symmetry</strong> $\\mathcal F[F(t)]&#x3D; 2\\pi f(-\\omega)$ , if $f(t)$ is a even function, $\\mathcal F[F(t)]&#x3D; 2\\pi f(\\omega)$</p>\n<p><strong>Linearity</strong> $\\mathcal{F}[\\Sigma_{i&#x3D;1}^{n}a_if_i(t)] &#x3D; \\Sigma_{i&#x3D;1}^{n}a_iF_i(\\omega)$</p>\n<p><strong>Odd-Even, Imaginary-Real</strong> $f(t) &#x3D; f_e(t)+f_o(t)$, then</p>\n<div>$$\n\\begin{align*}\n  F(\\omega) &= \\int_{-\\infty}^\\infty f(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f(t)\\sin \\omega t \\mathrm dt\\\\\n  &=R(\\omega)+jX(\\omega)\\\\\n  &=\\int_{-\\infty}^\\infty f_e(t)\\cos \\omega t \\mathrm dt -j\\int_{-\\infty}^\\infty f_o(t)\\sin \\omega t \\mathrm dt\\\\\n\\end{align*}.\n$$</div>\n\n<p>$R(\\omega)$ is an even function of $\\omega$, $X(\\omega)$ is an odd function of $\\omega$.</p>\n<p>$|F(\\omega) &#x3D; \\sqrt{R^2(\\omega)+F^2(\\omega)}|$ is even function.</p>\n<p>$\\varphi(\\omega) &#x3D; \\tg^{-1}\\frac{R(\\omega)}{X(\\omega)}$</p>\n<p>if $f(t)$ is real and even, then $f(t)&#x3D;f_e(t), F(\\omega)&#x3D;R(\\omega)$, the phase shift is $0$ or $\\pi$.</p>\n<p>if $f(t)$ is real and odd, $f(t) &#x3D; f_o(t)$, then $F(\\omega)&#x3D;jX(\\omega)$, $F(\\omega)$ has only imaginary part and is odd, the phase shift is $\\pm \\frac{\\pi}{2}$</p>\n<p><strong>Scaling</strong> $\\mathcal{F}[f(at)]&#x3D;\\frac 1{|a|}F\\left(\\frac{\\omega}a\\right)$ Expansion in TD results in Compression in FD.</p>\n<p><strong>Time Shifting</strong> $\\mathcal{F}[f(t\\pm t_0)] &#x3D; F(\\omega)e^{\\pm j\\omega t_0}$</p>\n<p><strong>Frequency Shifting</strong> $\\mathcal F[f(t)e^{\\pm j\\omega_0t}] &#x3D; F(\\omega\\mp\\omega_0)$</p>\n<p><strong>Differentiation property</strong>$\\mathcal F\\left[\\frac{\\mathrm d}{\\mathrm dt}f(t)\\right] &#x3D; j\\omega F(\\omega)$</p>\n<p>$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm dt^n}f(t)\\right] &#x3D; (j\\omega)^n F(\\omega)$</p>\n<p>$\\mathcal F\\left[\\frac{\\mathrm d^n}{\\mathrm d\\omega^n}F(\\omega)\\right] &#x3D; (-jt)^nf(t)$</p>\n<p><strong>Integration Property</strong> $\\mathcal{F}\\left[\\int_{-\\infty}^t f(\\tau)\\mathrm{d} \\tau\\right] &#x3D; \\frac{F(\\omega)}{j\\omega} + \\pi F(0)\\delta(\\omega)$</p>\n<h3 id=\"Convolution-theorem\"><a href=\"#Convolution-theorem\" class=\"headerlink\" title=\"Convolution theorem\"></a>Convolution theorem</h3><div>$$\n\\mathcal F[f_1(t)* f_2(t)] = F_1(\\omega)F_2(\\omega)\\\\\n\\mathcal F[f_1(t)\\cdot f_2(t)] = \\frac 1{2\\pi} F_1(\\omega) * F_2(\\omega)\n$$</div>\n\n<h3 id=\"FT-for-Periodic-Signals\"><a href=\"#FT-for-Periodic-Signals\" class=\"headerlink\" title=\"FT for Periodic Signals\"></a>FT for Periodic Signals</h3><div>$$\n\\mathcal F[\\cos (\\omega_0 t)] = \\pi [\\delta(\\omega + \\omega_0) + \\delta(\\omega - \\omega_0)]\\\\\n\\mathcal{F} [\\sin (\\omega_0 t)] = j\\pi [\\delta(\\omega+\\omega_0) + \\delta(\\omega - \\omega_0)]\n$$</div>\n\n<p>FT for periodic of $T_1$ &amp; $\\omega_1&#x3D;2\\pi&#x2F;T_1$</p>\n<div>$$\n\\mathcal F[f(t)] = 2\\pi\\sum_{n=-\\infty}^{+\\infty} F_n\\delta(\\omega - n\\omega_1)\\\\\nF_n = \\frac 1{T_1}\\int_{-T_1/2}^{T_1/2}f(t)e^{-jn\\omega_1 t}\\mathrm dt = \\frac{1}{T_1}F_0(\\omega)\\vert_{\\omega =n\\omega_1}\n$$</div>\n\n<p>Where $F_0(\\omega)$ is the FT considering waveform of $f(t)$ only in $|t|\\le T_1&#x2F;2$.</p>\n<p>example: </p>\n<div>$$\nf(t) = \\sum_{n=0}^{\\infty}\\delta(t-nT_1), F_n=\\frac{1}{T_1}\\\\\nF(\\omega) = \\frac{2\\pi}{T_1}\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)=\\omega_1\\sum_{n=0}^{\\infty}\\delta(\\omega - n\\omega_1)\n$$</div>\n\n<div>$$\nF_0(ω) \\text{ determines the profile of } F(ω)\\\\\nT_1\\text{ determines the density of the impulses\n}\\\\\nT_1↑, ω_1↓\\text{, intensity of harmonics}↓\\\\\nT_1↓,ω_1↑\\text{, intensity of harmonics}↑\\\\\n$$</div>\n\n<p><img src=\"/../images/ss/lec7_1.jpg\"></p>\n<p>In the same way: </p>\n<p><img src=\"/../images/ss/lec7_2.jpg\"></p>\n<h3 id=\"FT-for-periodically-sampled-signals\"><a href=\"#FT-for-periodically-sampled-signals\" class=\"headerlink\" title=\"FT for periodically sampled signals\"></a>FT for periodically sampled signals</h3><div>$$\nF(\\omega) = \\mathcal F[f(t)]\\\\\nP(\\omega) = \\mathcal F[p(t)]\\\\\nf_s(t) = f(t)p(t)\\\\\nF_s(\\omega) =\\frac{1}{2\\pi} F(\\omega) * P(\\omega)\n$$</div>\n\n<p>Then, </p>\n<div>$$\nP(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_n\\delta(\\omega - \\omega_s)\\\\\nF(\\omega) * P(\\omega) = 2\\pi \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\\\\\nF_s(\\omega) = \\sum_{n = -\\infty}^{+\\infty} P_nF(\\omega - n\\omega_s)\n$$</div>\n\n<p><img src=\"/../images/ss/lec7_3.jpg\"></p>\n<p>For the frequency-domain sampling: </p>\n<div>$$\nF_1(\\omega) = F(\\omega)P(\\omega)\\\\\nP(\\omega) = \\sum_{n=-\\infty}^{+\\infty} \\delta(\\omega - n\\omega_1)\\\\\nf_1(t) = f(t) *  \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{+\\infty} \\delta(t - nT_1) = \\frac{1}{\\omega_1}\\sum_{n=-\\infty}^{\\infty} f(t-nT_1)\n$$</div>\n\n<p><strong>The Sampling Theorem</strong></p>\n<div>$$\n\\omega_s \\ge 2\\omega_m\n$$</div>\n\n<p>A band-limited signal whose spectrum is strictly within $[0, f_m]$ could be uniquely determined by the samples on itself, if and only if the sampling interval $T_s \\le 1&#x2F;(2f_m)$.</p>\n<p>$T_s &#x3D; \\frac{1}{2f_m}$ is called the <strong>Nyquist interval</strong>.</p>\n<p>$2f_m$ is called the <strong>Nyquist frequency</strong>.</p>\n<p>对于单频信号，奈奎斯特频率的采样可能会出现问题。例如正弦信号，每次采样都采在零点上，那就没法复现信号。单频信号没法描述带宽。</p>\n<p>A FD verison:</p>\n<p><img src=\"/../images/ss/lec7_4.jpg\"></p>\n<h2 id=\"L-Transform\"><a href=\"#L-Transform\" class=\"headerlink\" title=\"L Transform\"></a>L Transform</h2><h3 id=\"Unilateral-L-transform\"><a href=\"#Unilateral-L-transform\" class=\"headerlink\" title=\"Unilateral L-transform\"></a>Unilateral L-transform</h3><div>$$\nF(s) = \\int^{\\infty}_{0}f(t)e^{-st}\\mathrm dt, s=\\sigma+j\\omega\\\\\nf(t)=\\frac{1}{2\\pi j}\\int_{\\sigma-j\\infty}^{\\sigma+j\\infty}F(s)e^{st}\\mathrm ds\n$$</div>\n\n<p>$F(s) &#x3D; \\mathcal{L}[f(t)]$ is called image function, $f(t) &#x3D; \\mathcal{L}^{-1}[F(s)]$ is called primitive function.</p>\n<p>assuming that $f(t)$ is causal and always 0 if $t&lt;0$.</p>\n<div>$$\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0) + sF(s)\n$$</div>\n\n<p>The initial state is automatically included in differential equation.</p>\n<p>We define the <strong>unilateral</strong> L-Transform as: </p>\n<div>$$\nF(s) = \\int_{0_-}^{\\infty}f(t)e^{-st}\\mathrm dt\\\\\n\\mathcal L \\left[\\frac{\\mathrm df(t)}{\\mathrm dt}\\right] = -f(0_-) + sF(s)\n$$</div>\n\n<p>Conditions for L-Transform: </p>\n<ol>\n<li>Limited discontinuities</li>\n<li>Exponential order</li>\n</ol>\n<p>The strong attenuation factor can make the function convergent.</p>\n<p>Region of Convergence (ROC)</p>\n<p>Axis of convergence</p>\n<p>Coordinate of convergence $\\sigma_0$</p>\n<h3 id=\"Comman-LT-Pairs\"><a href=\"#Comman-LT-Pairs\" class=\"headerlink\" title=\"Comman LT Pairs\"></a>Comman LT Pairs</h3><div>$$\n\\begin{align*}\nf(t)&\\Rightarrow F(s)\\\\  \n\\delta(t) &\\Rightarrow 1\\\\\nu(t) &\\Rightarrow \\frac 1s\\\\\ne^{-at} &\\Rightarrow \\frac{1}{s+a}\\\\\nt^n & \\Rightarrow \\frac{n!}{s^{n+1}}\\\\\n\\sin (\\omega t)&\\Rightarrow \\frac{\\omega}{s^2 + \\omega^2}\\\\\n\\cos (\\omega t)&\\Rightarrow \\frac{s}{s^2+\\omega^2}\\\\\n\\end{align*}\n$$</div>\n\n<h3 id=\"Properties-of-LT\"><a href=\"#Properties-of-LT\" class=\"headerlink\" title=\"Properties of LT\"></a>Properties of LT</h3><p><strong>Linarity</strong></p>\n<div>$$\n\\mathcal L [k_1f_1(t) + k_2f_2(t)] = k_1F_1(s) + k_2F_2(s)\\\\\n$$</div>\n\n<p><strong>Differentiation</strong></p>\n<div>$$\n\\mathcal L \\left[\\frac{\\mathrm d f(t)}{\\mathrm d t}\\right] = sF(s) - f(0_-)\n$$</div>\n\n<p><strong>Intergration</strong></p>\n<div>$$\n\\mathcal L\\left[\\int_{-\\infty}^t f(\\tau)\\mathcal d\\tau\\right]=\\frac{F(s)}{s} + \\frac{f^{(-1)}(0)}{s}\n$$</div>\n\n<p><strong>Time Shifting</strong></p>\n<div>$$\n\\mathcal L\\left[f(t-t_0)u(t-t_0)\\right] = e^{-st_0}F(s)\n$$</div>\n\n<p>Use $u(t-t_0)$ to avoid nagative part of $f(t)$ emerges.</p>\n<p><strong>Frequency Shifting</strong></p>\n<div>$$\n\\mathcal L[f(t)e^{-at}] = F(s+a)\n$$</div>\n\n<p><strong>Scaling</strong></p>\n<div>$$\n\\mathcal L[f(at)] = \\frac 1a F\\left(\\frac{s}{a}\\right)\n$$</div>\n\n<p><strong>s-Domain Differentiation</strong></p>\n<div>$$\n\\frac{\\mathrm d}{\\mathrm ds}\\mathcal L[f(t)] = \\mathcal L[-tf(t)]\n$$</div>\n\n<p><strong>s-Domain Differentiation</strong></p>\n<div>$$\n\\int_s^\\infty F(s) = \\mathcal{L}\\left[\\frac{f(t)}{t}\\right]\n$$</div>\n\n<p><strong>Initial value</strong></p>\n<div>$$\nf(0_+) = \\lim_{s\\rightarrow\\infty}sF(s)\n$$</div>\n\n<p><strong>Final value</strong></p>\n<div>$$\n\\lim_{t\\rightarrow\\infty} f(t) = \\lim_{s\\rightarrow0} sF(s)\n$$</div>\n\n<p>Generalized limit: $\\lim_{t\\rightarrow\\infty} \\sin(\\omega t)&#x3D;0$</p>\n<p><strong>Convolution</strong></p>\n<div>$$\n\\mathcal L[f_1(t)*f_2(t)] = F_1(s)F_2(s)\n$$</div>\n\n<h3 id=\"Applications\"><a href=\"#Applications\" class=\"headerlink\" title=\"Applications\"></a>Applications</h3><p><strong>Differential Equations</strong></p>\n<div>$$\n  F(s) = \\frac{A(s)}{B(s)} = \\frac{a_ns^n + a_{n-1}s^{n-1} + \\cdots + a_1s + a_0}{b_ms^m + b_{m-1}s^{m-1} + \\cdots + b_1s + b_0} % The division of two polynomials\n$$</div>\n\n<p>(assume that $n&lt;m$)</p>\n<p>The roots of numerator is called zeros, while the roots of denominator is called poles.</p>\n<p>Unknown function F(s) can be represented by the ratio of two polynomials if all initial states are 0.</p>\n<ol>\n<li>real poles</li>\n</ol>\n<div>$$\nF(s) = \\frac{A(s)}{(s-p_1)(s-p_2)(s-p_3)}\n$$</div>\n\n<ol start=\"2\">\n<li>complex conjugate poles</li>\n</ol>\n<div>$$\nF(s) = \\frac{A(s)}{D(s)[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{[(s+\\alpha)^2 + \\beta^2]} = \\frac{F_1(s)}{(s+\\alpha - j\\beta)(s+\\alpha + j\\beta)} + \\dots\n$$</div>\n\n<div>$$\nk_1 = (s+\\alpha - j\\beta)F(s)|_{s = -\\alpha + j\\beta} = \\frac {F_1(-\\alpha + j\\beta)}{2j\\beta}\\\\\nk_2 = (s+\\alpha + j\\beta)F(s)|_{s = -\\alpha - j\\beta} = \\frac {F_1(-\\alpha - j\\beta)}{-2j\\beta}\n$$</div>\n\n<ol start=\"3\">\n<li>Multiple poles</li>\n</ol>\n<div>$$\nF(s) = \\frac {A(s)}{B(s)} = \\frac{A(s)}{(s-p_1)^k D(s)}\\\\\n= \\frac{K_{11}}{(s-p_1)^k}+\\frac{K_{12}}{(s-p_1)^{k-1}}+\\dotsb+\\frac{K_{1k}}{s-p_1} + \\frac{E(s)}{D(s)}(s-p_1)^k\n$$</div>\n\n<p><img src=\"/../images/ss/lec9_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec9_2.jpg\"></p>\n<p>Circuit model:</p>\n<p><img src=\"/../images/ss/lec9_3.jpg\"></p>\n<p><img src=\"/../images/ss/lec9_4.jpg\"></p>\n<p><img src=\"/../images/ss/lec9_5.jpg\"></p>\n<p>Use initial value and final value to verify it.</p>\n<h3 id=\"System-Function\"><a href=\"#System-Function\" class=\"headerlink\" title=\"System Function\"></a>System Function</h3><div>$$\n\\begin{cases}\n  R(s) = H(s) \\cdot E(s)\\\\\n  r(t) = h(t) * e(t)\n\\end{cases}\n\\Rightarrow H(s) = L[h(t)]\n$$</div>\n\n<p><strong>Driving point function &amp; transfer function</strong></p>\n<p><img src=\"/../images/ss/lec9_6.jpg\"></p>\n<p>L-transform can be used in the following analysis:</p>\n<ul>\n<li>TD characteristics (response decomposition)</li>\n<li>FD characteristics (steady-state with sine signal input,applications such as filtering) </li>\n<li>Stability (active network, feedback, oscillator, control system)</li>\n</ul>\n<h3 id=\"TD-characteristics-by-0-point-distribution\"><a href=\"#TD-characteristics-by-0-point-distribution\" class=\"headerlink\" title=\"TD characteristics by 0-point distribution\"></a>TD characteristics by 0-point distribution</h3><p>Three cases: </p>\n<ul>\n<li>Real poles</li>\n<li>Complex conjugate poles</li>\n<li>Real pole of high-order</li>\n</ul>\n<ol>\n<li>Zero pole of H(s)</li>\n</ol>\n<p><img src=\"/../images/ss/lec10_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec10_2.jpg\"></p>\n<p>Zero only affects the phase and amplitude, while the shape and type of waveform is determined by the poles.</p>\n<ol start=\"2\">\n<li>pole distribution $\\Leftrightarrow$ corresponding natural&#x2F;forced responses</li>\n</ol>\n<div>$$\nH(s) = \\frac{\\prod_{i = 1}^m(s-z_{hj})}{\\prod_{i = 1}^n(s-p_{hi})}\\\\\nE(s) = \\frac{\\prod_{i = 1}^u(s-z_{el})}{\\prod_{i = 1}^v(s-p_{ek})}\\\\\n\\text{if } m + u < n + v\\\\\nR(s) = E(s)H(s) = \\sum_{k=1}^n\\frac{K_{hk}}{s - p_{hk}} + \\sum_{k=1}^v\\frac{K_{ek}}{s-p_{ek}}\n$$</div>\n\n<p>The natural response of $r(t)$ is only related to $p_{hk}$, while the forced response is only related to $p_{ek}$.</p>\n<p>$K_{hk}$, $K_{ek}$ are related to both $H(s)$ and $E(s)$.</p>\n<p>However natural and forced responses could not be completely separated, if there exists $k, k^\\prime$ satisfying $p_{hk}&#x3D;p_{ek^\\prime}$.</p>\n<p>$p_{hi}$ are called natural frequency of the system.</p>\n<p>However, some common factors may be eliminated: </p>\n<div>$$\n\\frac{(s+1)}{(s+1)(s+2)} = \\frac{1}{(s+2)}\n$$</div>\n\n<div>$$\nH(s) = \\frac{\\Delta_{jk}}{\\Delta}\n$$</div>\n\n<p>All the poles of $H(s)$ are the natural frequencies of the system, but $h(t)$ may not include all the natural frequencies(but the root of $\\Delta$ contains all natural frequencies).</p>\n<p>In most cases:</p>\n<div>$$\n\\text{Re}(p_{hi}) < 0, \\text{Re}(p_{ei}) = 0\n$$</div>\n\n<p>Thus the natural response is transient, while the forced response is steady-state.</p>\n<p>However, some natural response can be steady-state(conjugate poles of $Re(p_{hi})$), while some forced response can be transient.</p>\n<p><img src=\"/../images/ss/lec10_3.jpg\"></p>\n<p><img src=\"/../images/ss/lec10_4.jpg\"></p>\n<p><img src=\"/../images/ss/lec10_5.jpg\"></p>\n<div>$$\nE_m|H(j\\omega)|\\sin (\\omega_0t + \\varphi_0)\n$$</div>\n\n<div>$$\nH(j\\omega) =K\\cdot \\frac{\\prod(j\\omega - z_j)}{\\prod (j\\omega - p_i)}\n$$</div>\n\n<p><img src=\"/../images/ss/lec10_7.jpg\"></p>\n<p><img src=\"/../images/ss/lec10_6.jpg\"></p>\n<p><img src=\"/../images/ss/lec10_8.jpg\"></p>\n<p>for band-pass filter, </p>\n<p>BW is where Peak(dB) - 3dB</p>\n<p>for low-pass filter,</p>\n<p>BW &#x3D; $f_{\\text{cut-off}}$</p>\n<p>According to the sampling theorem, the signal bandwith is often determined by the first zero of the spectrum.</p>\n<p><strong>All Pass Systems</strong></p>\n<div>$$\nR_e(p_i) = -R_e(z_i)\\\\\nI_m(p_i) = I_m(z_i)\n$$</div>\n\n<p>The Amplitude is const., while the phase can change.</p>\n<p><strong>Minimum-phase system&#x2F;function</strong></p>\n<p>Definition: A stable system with poles on left-half s-plane is called minimum-phase system&#x2F;function, if all the zeros are also on left-half s-plane or at the jω-axis. Otherwise is a non-minimum-phase system&#x2F;function.<br><img src=\"/../images/ss/lec11_1.jpg\"></p>\n<p>Property: A non-minimum-phase function can be represented as the product of  a minimum-phase function and an all-pass function.</p>\n<h3 id=\"Stability-of-Linear-System\"><a href=\"#Stability-of-Linear-System\" class=\"headerlink\" title=\"Stability of Linear System\"></a>Stability of Linear System</h3><p>A system is considered to be stable if bounded input always leads to bounded output.</p>\n<p>Bounded-input, Bounded-output(BIBO)</p>\n<p>The necessary &amp; sufficient conditions for BIBO:</p>\n<div>$$\n\\int_{-\\infty}^\\infty|h(t)|\\mathrm dt \\le M\n$$</div>\n\n<p>Poles are: </p>\n<ul>\n<li>on the left half-plane: $\\lim_{t\\rightarrow \\infty}[h(t)] &#x3D; 0$, stable system</li>\n<li>on the right half-plane, or at $j\\omega$-axis with order of more than one: $\\lim_{t\\rightarrow \\infty}[h(t)] &#x3D; \\infty$, unstable system</li>\n<li>at $j\\omega$-axis with order of one: $h(t)$ is non-zero or oscillated with equal amplitude, critical stable system</li>\n</ul>\n<h3 id=\"Two-sided-Bilateral-LT\"><a href=\"#Two-sided-Bilateral-LT\" class=\"headerlink\" title=\"Two-sided (Bilateral) LT\"></a>Two-sided (Bilateral) LT</h3><div>$$\nF_B(s) = \\int_{-\\infty}^\\infty f(t)e^{-st}\\mathrm{d} t\n$$</div>\n\n<ul>\n<li>t starts from −∞, i.e., non-causal signal as the input<br>or regarding the initial condition as the input.</li>\n<li>Easily to be associated with F-transform and Z-<br>transforms</li>\n</ul>\n<p>We determine the ROC by:</p>\n<div>$$\n\\lim_{t\\rightarrow \\infty} f(t)e^{-\\sigma t} = 0\\\\\n\\lim_{t\\rightarrow -\\infty} f(t)e^{-\\sigma t} = 0\n$$</div>\n\n<p>NOTE: </p>\n<ul>\n<li>If no overlap between the two constraints, then $F_B(s)$ does not exist.</li>\n<li>$F_B(s)$ and $f(t)$ are not uniquely corresponding to each other.($\\int_{-\\infty}^\\infty u(t)e^{-st}\\mathrm{d} t &#x3D; \\frac{1}{s}$, $\\int_{-\\infty}^\\infty -u(-t)e^{-st}\\mathrm{d} t&#x3D;\\frac{1}{s}$)</li>\n<li>Two-sided L-Transform shares almost all the properties with its single-sided counterpart except for the initial-value theorem.</li>\n<li>Two-sided L-Transform has very limited applications as most continuous-time systems are causal.</li>\n</ul>\n<p>**Relationship between LT and FT **</p>\n<ul>\n<li>$\\sigma_0 &gt; 0$, $F(\\omega)$ does not exist</li>\n<li>$\\sigma_0 &#x3D; 0$, impulse appears in $F(\\omega)$</li>\n<li>$\\sigma_0 &lt; 0$, $F(\\omega)$ exists, $F(\\omega) &#x3D; F(s)|_{s&#x3D;j\\omega}$</li>\n</ul>\n<p><img src=\"/../images/ss/lec11_2.jpg\"><br>(The LT above is unilateral LT.)</p>\n<p><img src=\"/../images/ss/lec11_3.jpg\"></p>\n<h3 id=\"Extra-Attention\"><a href=\"#Extra-Attention\" class=\"headerlink\" title=\"Extra Attention\"></a>Extra Attention</h3><p>$1 + e^{-s}$ also has zero(many!). Note that if it is on the denominator.</p>\n<h2 id=\"FT-in-Telecom-Systems\"><a href=\"#FT-in-Telecom-Systems\" class=\"headerlink\" title=\"FT in Telecom. Systems\"></a>FT in Telecom. Systems</h2><p>System discussed in this chapter are strictly stable: </p>\n<div>$$\n\\mathcal{F}[f(t)] = F(s)|_{s=j\\omega}\n$$</div>\n\n<p>Because even for critical stable system, FT is not  the same as LT(containing $\\delta$), there will be ambiguity between $H(j\\omega)$ and $H(s)|_{s&#x3D;j\\omega}$.</p>\n<p>For every freq. component, it is reshaped in its phase and amplitude by the system function when passing through the system, related with its frequency. Thus the system can distort the original signal.</p>\n<p><strong>Distortion</strong></p>\n<p>2 types of distortion:</p>\n<ul>\n<li>Non-linear distortion (new frequency components)</li>\n<li>Linear distortion (without new frequency components), just the amplitude and&#x2F;or phase distortion.</li>\n</ul>\n<p> <strong>Distortionless transmission</strong></p>\n<div>$$\ne(t)\\rightarrow ke(t - t_0)\n$$</div>\n\n<div>$$\nR(j\\omega) = \\int_{-\\infty}^\\infty ke(t -t_0)e^{-j\\omega t}\\mathrm dt=ke^{-j\\omega t_0}\\int_{-\\infty}^\\infty e(x)e^{-j\\omega x}\\mathrm dx=ke^{-j\\omega t_0} E(j\\omega)\n$$</div>\n\n<p>So, $H(j\\omega) &#x3D; ke^{-j\\omega t_0}$, $h(t)&#x3D;K\\delta(t - t_0)$.</p>\n<p>The Amplitude is frequency independent, $BW\\rightarrow \\infty$.</p>\n<p>Phase response is linear at negative slope.</p>\n<p>The impulse response of a distortionless linear system is<br>     also an impulse.</p>\n<p>The physical scenario: group delay.</p>\n<div>$$\n\\tau = -\\frac{\\mathrm d\\varphi (\\omega)}{\\mathrm d\\omega}\n$$</div>\n\n<p>Condition for phase distortionless property: the group delay remains a constant.</p>\n<h3 id=\"Filter\"><a href=\"#Filter\" class=\"headerlink\" title=\"Filter\"></a>Filter</h3><p><strong>Ideal Low pass (LP) Filter</strong></p>\n<div>$$\nH(j\\omega) = \\begin{cases}\n  1 \\cdot e^{-j\\omega t_0}, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$</div>\n\n<p><img src=\"/../images/ss/lec12_1.jpg\"></p>\n<p><strong>The Impulse response of Ideal LP</strong></p>\n<p><img src=\"/../images/ss/lec12_2.jpg\"></p>\n<ul>\n<li>Severe distortion. $BW_{\\delta(t)}\\rightarrow \\infty$, but $BW_{\\text{Lowpass}}&#x3D;\\omega_c$, the higier frequency is eliminated.</li>\n<li>Non-causal. When $t\\lt 0$, $h(t)\\ne 0$.</li>\n</ul>\n<p><strong>Unit-step response of Ideal LP</strong></p>\n<p><img src=\"/../images/ss/lec12_3.jpg\"></p>\n<p><img src=\"/../images/ss/lec12_4.jpg\"></p>\n<p><img src=\"/../images/ss/lec12_5.jpg\"></p>\n<p>The response is similar to the input if $\\frac{1}{2}&#x3D;\\frac{\\pi}{\\omega_c}\\llless \\tau$. </p>\n<p><strong>Gibbs phenomenon</strong>: 9% overshoot at discontinuity. Use other window functions can eliminate this, e.g. raised-cosine window.</p>\n<h3 id=\"Modulation-and-demodulation\"><a href=\"#Modulation-and-demodulation\" class=\"headerlink\" title=\"Modulation and demodulation\"></a>Modulation and demodulation</h3><p>Means of modulation:</p>\n<p><strong>Spectrum shifting</strong> </p>\n<p>$f(t) &#x3D; g(t)\\cos(\\omega_0t)$, $F(\\omega) &#x3D;\\frac{1}{2\\pi} G(\\omega) * \\pi[\\delta(\\omega - \\omega_0) + \\delta (\\omega + \\omega_0)] &#x3D; \\frac{1}{2}[G(\\omega + \\omega_0) + G(\\omega - \\omega_0)]$.</p>\n<p><img src=\"/../images/ss/lec12_6.jpg\"></p>\n<p>Demodulation: </p>\n<p><strong>coherent demodulation</strong></p>\n<p>$g_0(t)&#x3D;[g(t)\\cos(\\omega_0 t)]\\cos(\\omega_0t) &#x3D; \\frac{1}{2}g(t) + \\frac{1}{2}g(t)\\cos2\\omega_0t$</p>\n<p><img src=\"/../images/ss/lec12_7.jpg\"></p>\n<p><strong>Envelope Detection</strong></p>\n<p><img src=\"/../images/ss/lec12_8.jpg\"></p>\n<h3 id=\"Applications-of-BPF\"><a href=\"#Applications-of-BPF\" class=\"headerlink\" title=\"Applications of BPF\"></a>Applications of BPF</h3><p><strong>Window Function</strong><br>(Page 304)</p>\n<div>$$\nh_a(t) = \\frac{\\sqrt a \\sin\\left(\\frac{\\pi t}{a}\\right)\\cos \\left(\\frac{3\\pi t}{a}\\right)}{\\sqrt{ \\pi} \\pi t}\\\\\nH_a(\\omega) = \\begin{cases}\n  \\frac{1}{2}\\sqrt{\\frac{a}{\\pi}}, \\text{if } \\frac{2\\pi}{a}\\le |\\omega| \\le \\frac{4\\pi}{a},\\\\\n  0, \\text{otherwise}.\n\\end{cases}\n$$</div>\n\n<p><img src=\"/../images/ss/lec13_1.jpg\"></p>\n<h3 id=\"Recover-Continuous-Time-signal-from-its-Samples\"><a href=\"#Recover-Continuous-Time-signal-from-its-Samples\" class=\"headerlink\" title=\"Recover Continuous Time signal from its Samples\"></a>Recover Continuous Time signal from its Samples</h3><p><strong>Analysis on signal after band-pass filter</strong></p>\n<p>Page 301</p>\n<p><strong>Sampling with impulse func.</strong></p>\n<p>FD analysis:</p>\n<p>Sampled signal(By impulse function):</p>\n<div>$$\nF_s(\\omega) = \\frac{1}{T_s}\\sum_{n=-\\infty}^\\infty F(\\omega - n\\omega_s)\n$$</div>\n\n<p>Ideal LP Filter:</p>\n<div>$$\nH(j\\omega) = \\begin{cases}\n  T_s, &|\\omega|< \\omega_c,\\\\\n  0, &|\\omega|> \\omega_c.\n\\end{cases}\n$$</div>\n\n<p>Recovered signal: </p>\n<div>$$\nF(\\omega) = F_s(\\omega) \\cdot H(\\omega)\n$$</div>\n\n<p>TD analysis:</p>\n<p>Sampled signal:</p>\n<div>$$\nf_s(t) = \\sum_{n=-\\infty}^\\infty f(nT_s)\\delta(t - nT_s)\n$$</div>\n\n<p>Ideal LP Filter:</p>\n<div>$$\nh(t) = T_s\\frac{\\omega_c}\\pi \\text{Sa}(\\omega_c t)\n$$</div>\n\n<p>Recovered signal:</p>\n<div>$$\nf(t) = f_s(t) * h(t) = T_s\\frac{\\omega_c}\\pi  \\sum_{n=-\\infty}^\\infty f(nT_s) \\text{Sa}(\\omega_c (t-nT_s))\n$$</div>\n\n<p><img src=\"/../images/ss/lec14_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec14_2.jpg\"></p>\n<p><strong>Sampling with a zero-order hold</strong></p>\n<p><img src=\"/../images/ss/lec14_3.jpg\"></p>\n<div>$$\nh_0(t) = u(t) - u(t - T_s)\\\\\nf_{s0}(t) = f_s(t)* h_0(t)\n$$</div>\n\n<div>$$\n\\begin{align*} \n&\\mathcal F\\{f_{s0}(t)\\} \\\\&=\\mathcal F\\{f_s(t)\\} \\cdot \\mathcal F\\{h_0(t)\\} \\\\ &=F_s(\\omega) \\cdot H_0(\\omega)\\\\\n&=\\sum_{-\\infty}^{\\infty}F(\\omega - n\\omega_s) \\cdot  \\text{Sa}(\\frac{\\omega_c T_s}{2})e^{-j\\frac{\\omega T_s}{2}}\\\\\n\\end{align*}\n$$</div>\n\n<p>LP Filter for compensation</p>\n<div>$$\nH_{0r}(\\omega) = \\begin{cases}\n  \\frac{1}{\\text{Sa}(\\frac{\\omega T_s}{2})}e^{j\\omega T_s/2}, &|\\omega| \\le \\omega_s/2,\\\\\n  0, &|\\omega|> \\omega_s/2.\n\\end{cases}\n$$</div>\n\n<p>Linear phase response is OK! No needed for delay compensation. </p>\n<p><strong>1st-order hold Sampling</strong></p>\n<p><img src=\"/../images/ss/lec14_4.jpg\"></p>\n<h3 id=\"Mulitplexing-FDM-and-TDM\"><a href=\"#Mulitplexing-FDM-and-TDM\" class=\"headerlink\" title=\"Mulitplexing FDM and TDM\"></a>Mulitplexing FDM and TDM</h3><p>Transmit mulitple singals over a single channel concurrently.</p>\n<p>Frequency Division Multiplexing (FDM) － OFDM (Orthogonal FDM)</p>\n<p>Time Division Multiplexing (TDM)－sharing slot, statistical multiplexing</p>\n<p>Code Division Multiplexing (CDM)－ Code division, logical multiplexing</p>\n<p>Wavelength Division Multiplexing (WDM)－ Optical carrier</p>\n<p><img src=\"/../images/ss/lec14_5.jpg\"></p>\n<p><img src=\"/../images/ss/lec14_6.jpg\"></p>\n<p><img src=\"/../images/ss/lec14_7.jpg\"></p>\n<h2 id=\"Vector-Analysis-of-Signals\"><a href=\"#Vector-Analysis-of-Signals\" class=\"headerlink\" title=\"Vector Analysis of Signals\"></a>Vector Analysis of Signals</h2><h3 id=\"Vector-Space\"><a href=\"#Vector-Space\" class=\"headerlink\" title=\"Vector Space\"></a>Vector Space</h3><p><img src=\"/../images/ss/lec15_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec15_2.jpg\"></p>\n<p><img src=\"/../images/ss/lec15_3.jpg\"></p>\n<p><img src=\"/../images/ss/lec15_4.jpg\"></p>\n<p><img src=\"/../images/ss/lec15_5.jpg\"></p>\n<h3 id=\"Objective-for-singal-decomposition\"><a href=\"#Objective-for-singal-decomposition\" class=\"headerlink\" title=\"Objective for singal decomposition\"></a>Objective for singal decomposition</h3><div>$$\nr(t) = H[e(t)] = H\\left[\\sum_{i=0}^ne_i(t)\\right] = \\sum_{i=0}^nH[e_i(t)]\n$$</div>\n\n<h3 id=\"Basics\"><a href=\"#Basics\" class=\"headerlink\" title=\"Basics\"></a>Basics</h3><p><strong>Orthogonal Vector</strong></p>\n<p><img src=\"/../images/ss/lec15_6.jpg\"></p>\n<p><strong>Orthogonal Function</strong></p>\n<p>Represend $f_1(t)$ in terms of $f_2(t)$(both real), for $t_1&lt;t&lt;t_2$</p>\n<div>$$\nf_1(t)\\approx c_{12}f_2(t)\n$$</div>\n\n<p>Residual error $\\overline{\\varepsilon^2} &#x3D; \\overline{f_e^2(t)} &#x3D; \\frac{1}{t_2 - t_1}\\int_{t_1}^{t_2}[f_1(t) - c_{12}f_2(t)]^2\\mathrm dt$</p>\n<p>Let $\\frac{\\mathrm d \\overline{\\varepsilon^2}}{\\mathrm d c_{12}} &#x3D; 0$, then $\\overline{\\varepsilon^2}$ is minimized.</p>\n<p>The coefficient can be determined as</p>\n<div>$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt} = \\frac{\\langle f_1, f_2\\rangle}{\\langle f_2, f_2\\rangle}\n$$</div>\n\n<p>If $c_{12} &#x3D; 0$, then $f_1(t), f_2(t)$ are called <strong>Orthogonal Functions</strong>.</p>\n<p>And </p>\n<div>$$\n\\int_{t_1}^{t_2}f_1(t)f_2(t)\\mathrm dt = 0\n$$</div>\n\n<p><strong>Orthogonal Function Set</strong></p>\n<p>Any real function $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.</p>\n<div>$$\nf(t) = \\sum_{r=1}^n c_rg_r(t)\n$$</div>\n\n<p>According to the minimal mean square error, the coefficient can be determined as</p>\n<div>$$\nc_r = \\frac{\\int_{t_1}^{t_2}f(t)g_r(t)\\mathrm dt}{\\int_{t_1}^{t_2}g_r^2(t)\\mathrm dt} = \\frac{\\langle f, g_r\\rangle}{\\langle g_r, g_r\\rangle}\n$$</div>\n\n<p>If $g_1(t), g_2(t), …, g_n(t)$ are orthogonal to each other, i.e.</p>\n<div>$$\n\\int_{t_1}^{t_2}g_r(t)g_s(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$</div>\n\n<p>Then $f(t)$ can be represented as the sum of $n$-D orthogonal real functions.</p>\n<p>Then $g_1(t), g_2(t), …, g_n(t)$ are called <strong>Orthogonal Function Set</strong>.</p>\n<p>If $\\int_{t_1}^{t_2}g_i^2(t)\\mathrm dt &#x3D; 1$, the orthogonal function set is called <strong>Orthonormal Function Set</strong>.</p>\n<p><strong>Orthogonality of Complex Function</strong></p>\n<div>$$\nc_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\int_{t_1}^{t_2}f_2(t)f_2^*(t)\\mathrm dt} = \\frac{\\langle f_1, f_2^*\\rangle}{\\langle f_2, f_2^*\\rangle}\n$$</div>\n\n<p><strong>Orthogonal Function Set</strong> satisfies</p>\n<div>$$\n\\int_{t_1}^{t_2}g_r(t)g_s^*(t)\\mathrm dt =\\begin{cases}\n  K_i, &r = s,\\\\\n  0, &r \\ne s\n\\end{cases}\n$$</div>\n\n<p>The definition of Orthogonal is</p>\n<div>$$\n\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt = \\int_{t_1}^{t_2}f_2(t)f_1^*(t)\\mathrm dt = 0\n$$</div>\n\n<p>NOTE:</p>\n<ul>\n<li><p>If two signals are orthogonal within a given interval, they are not necessarily orthogonal within other intervals.</p>\n</li>\n<li><p>If two signals are not orthogonal, they must be correlated.</p>\n</li>\n</ul>\n<h3 id=\"Complete-Orthogonal-Function-and-Parseval’s-Theorem\"><a href=\"#Complete-Orthogonal-Function-and-Parseval’s-Theorem\" class=\"headerlink\" title=\"Complete Orthogonal Function and Parseval’s Theorem\"></a>Complete Orthogonal Function and Parseval’s Theorem</h3><p><strong>Complete Orthogonal Funtion Set</strong></p>\n<div>$$\n\\overline{\\varepsilon^2} = \\frac{1}{t_2-t_1}\\left[\\int_{t_1}^{t_2}f^2(t)\\mathrm dt  - \\sum_{r = 1}^nc_r^2K_r\\right]\n$$</div>\n\n<p>If $\\lim_{t_2 \\to \\infty}\\overline{\\varepsilon^2} &#x3D; 0$, then ${g_r(t)}$ is said to be a <strong>Complete Orthogonal Function Set</strong>.</p>\n<p>Alternative definition of complete orthogonal set</p>\n<p>Other than the elements in ${g_r(t)}$, there is no finite-energy signal $x(t)$, which satisfies</p>\n<div>$$\n\\int_{t_1}^{t_2}x(t)g_r(t)\\mathrm dt = 0, \\forall r\\\\\n\\text{or } \\int_{t_1}^{t_2}x(t)g_r^*(t)\\mathrm dt = 0, \\forall r\n$$</div>\n\n\n<p>Trigonometric Set</p>\n<div>$$\n\\left\\{\\cos n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\\\\\n\\left\\{\\sin n\\omega_1 t\\right\\}_{n\\rightarrow\\infty}\n$$</div>\n\n<p>Complex exponential set</p>\n<div>$$\n\\left\\{e^{jn\\omega_1 t}\\right\\}_{n\\rightarrow\\infty}\n$$</div>\n\n<p><strong>Parseval’s Theorem</strong></p>\n<div>$$\n\\int_{t_1}^{t_2}f(t)^2\\mathrm dt = \\sum_{r=1}^\\infty c_r^2K_r = \\sum_{r=1}^\\infty\\int_{t_1}^{t_2}[c_rg_r(t)]^2\\mathrm dt\n$$</div>\n\n<p>Physical interpretation:</p>\n<p>The energy (power) of a signal always equals to the sum of the energy (power) of all its components in a complete orthogonal function set. </p>\n<p>Mathematical interpretation:</p>\n<p>The norm of vector signals keeps invariant under orthogonal transform.</p>\n<h3 id=\"Correlation\"><a href=\"#Correlation\" class=\"headerlink\" title=\"Correlation\"></a>Correlation</h3><p>Physical interpretation:</p>\n<p>Gauge of the similarity of two signals </p>\n<p><strong>Energy and Power Signals</strong></p>\n<p>Instaneous Power $p(t) &#x3D; i^2(t) R$</p>\n<p>The energy consumed by $R$ in a period</p>\n<div>$$\nE = \\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$</div>\n\n<p>Average Power:</p>\n<div>$$\nP = \\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}p(t)\\mathrm dt = \\frac{1}{T_0}R\\int_{-T_0/2}^{T_0/2}i^2(t) \\mathrm dt\n$$</div>\n\n<p>The energy signals and power signals:</p>\n<div>$$\nE = \\lim_{T_0 \\to \\infty}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\\\\\nP = \\lim_{T_0 \\to \\infty}\\frac{1}{T_0}\\int_{-T_0/2}^{T_0/2}f^2(t)\\mathrm dt\n$$</div>\n\n<p><strong>Correlation Coefficient</strong></p>\n<div>$$\n\\rho_{12} = \\frac{\\int_{t_1}^{t_2}f_1(t)f_2^*(t)\\mathrm dt}{\\sqrt{\\int_{t_1}^{t_2}f_1^2(t)\\mathrm dt}\\sqrt{\\int_{t_1}^{t_2}f_2^2(t)\\mathrm dt}} = \\frac{\\langle f_1, f_2\\rangle}{\\sqrt{\\langle f_1, f_1\\rangle}\\sqrt{\\langle f_2, f_2\\rangle}} = \\frac{\\langle f_1, f_2\\rangle}{\\|f_1\\|_2\\|f_2\\|_2} \n$$</div>\n\n<p>If $f_1(t)$ is a linear function of $f_2(t)$, then $\\rho_{12} &#x3D; \\pm1$, $\\overline{\\varepsilon^2} &#x3D; 0$.</p>\n<p>If $f_1(t)$ is orthogonal to $f_2(t)$, then $\\rho_{12} &#x3D; 0$, $\\overline{\\varepsilon^2}$ is maximized.</p>\n<ul>\n<li>Describe the correlation of two signals from the perspective of energy difference.</li>\n<li>Quantitatively measure the correlation of two signals in terms of inner product.</li>\n</ul>\n<p><strong>Correlation Function</strong></p>\n<p>The similarity between one signal with a delayed version of another signal.</p>\n<p>(1) $f_1(t)$ and $f_2(t)$ are both real and energy signals</p>\n<div>$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}(-\\tau)\n$$</div>\n\n<p>(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals</p>\n<p>If $f_1(t) &#x3D; f_2(t) &#x3D; f(t)$</p>\n<p>Autocorrelation:</p>\n<div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f(t)\\mathrm dt\\\\\n$$</div>\n\n<p>(2) $f_1(t)$ and $f_2(t)$ are both complex and energy signals</p>\n<div>$$\nR_{12}(\\tau) = \\int_{-\\infty}^{\\infty}f_1(t)f_2^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_1(t + \\tau)f_2^*(t)\\mathrm dt\\\\\nR_{21}(\\tau) = \\int_{-\\infty}^{\\infty}f_2(t)f_1^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f_2(t + \\tau)f_1^*(t)\\mathrm dt\\\\\nR_{12}(\\tau) = R_{21}^*(-\\tau)\n$$</div>\n\n<p>Autocorrelation:</p>\n<div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt = \\int_{-\\infty}^{\\infty}f(t + \\tau)f^*(t)\\mathrm dt\\\\\nR(\\tau) = R^*(-\\tau)\n$$</div>\n\n\n<p>(3) $f_1(t)$ and $f_2(t)$ are both real and power signals</p>\n<div>$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p>Autocorrelation</p>\n<div>$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p>(4) $f_1(t)$ and $f_2(t)$ are both complex and power signals</p>\n<div>$$\nR_{12}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_1(t)f_2^*(t-\\tau)\\mathrm dt \\right]\\\\\nR_{21}(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f_2(t)f_1^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p>Autocorrelation</p>\n<div>$$\nR(\\tau) = \\lim_{T\\rightarrow\\infty}\\left[\\frac1T\\int_{-T/2}^{T/2}f(t)f^*(t-\\tau)\\mathrm dt \\right]\\\\\n$$</div>\n\n<p><strong>Correlation Theorem</strong></p>\n<div>$$\n\\mathcal F(x(t)) = X(\\omega)\\\\\n\\mathcal F(y(t)) = Y(\\omega)\\\\\n\\mathcal F(R_{xy}(\\tau)) = X(\\omega)Y^*(\\omega)\\\\\n$$</div>\n\n<p>If $x(t) &#x3D; y(t)$, The FT of the autocorrelation function is $\\mathcal F[{R_{xx}(\\tau)}] &#x3D; |X(\\omega)|^2$</p>\n<p>If $y(t)$ is a real and even function: $Y^*(\\omega) &#x3D; Y(\\omega)$</p>\n<p> Then the correlation theorem is equivalent to the convolution theorem</p>\n<div>$$\n\\mathcal F(\\int_{-\\infty}^\\infty x(t)y(t-\\tau)\\mathrm dt) = X(\\omega)Y(\\omega)\\\\\n$$</div>\n\n<p>Generally, </p>\n<div>$$\nR_{12}(t) = f_1(t) * f_2(-t)\n$$</div>\n\n<h3 id=\"Energy-amp-Power-Spectral-Density\"><a href=\"#Energy-amp-Power-Spectral-Density\" class=\"headerlink\" title=\"Energy &amp; Power Spectral Density\"></a>Energy &amp; Power Spectral Density</h3><div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}f(t)f^*(t-\\tau)\\mathrm dt\\\\\n$$</div>\n\n<div>$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2 e^{j\\omega\\tau}\\mathrm d\\omega\\\\\n|F(\\omega)|^2 = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\n$$</div>\n<div>$$\nR(0) = \\int_{-\\infty}^{\\infty}f(t)f^*(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt\\\\\nR(0) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\\\\\n$$</div>\n\n<div>$$\n\\int_{-\\infty}^{\\infty}\\lvert f(t)\\rvert^2\\mathrm dt = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert F(\\omega)\\rvert^2\\mathrm d\\omega\n$$</div>\n\n<p><strong>Energy Spectral Density</strong></p>\n<div>$$\n\\mathcal{E}(\\omega) = \\lvert F(\\omega)\\rvert^2\\\\\n$$</div>\n\n<div>$$\n\\mathcal{E}(\\omega) = \\mathcal{F}[R(\\tau)]\\\\\nR(\\tau) = \\mathcal{F}^{-1}[\\mathcal{E}(\\omega)]\\\\\n$$</div>\n\n<p><strong>Power Spectral Density</strong></p>\n<div>$$\n\\mathcal F[ R(\\tau)] = \\mathcal P(\\omega)\\\\\n$$</div>\n\n<p>It is called Power Spectral Density (PSD).</p>\n<p>Wiener-Khinchin Theorem</p>\n<div>$$\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\mathcal P(\\omega)e^{j\\omega\\tau}\\mathrm d\\tau\\\\\n\\mathcal P(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\omega\\\\\n$$</div>\n\n<h3 id=\"ESD-x2F-PSD-of-the-System-Response\"><a href=\"#ESD-x2F-PSD-of-the-System-Response\" class=\"headerlink\" title=\"ESD&#x2F;PSD of the System Response\"></a>ESD&#x2F;PSD of the System Response</h3><div>$$\n|R(j\\omega)|^2 = |H(j\\omega)|^2|E(j\\omega)|^2\\\\\n\\mathcal{E}_r(\\omega) = |H(j\\omega)|^2\\mathcal{E}_e(\\omega)\\\\\n\\mathcal{P}_r(\\omega) = |H(j\\omega)|^2\\mathcal{P}_e(\\omega)\\\\\n$$</div>\n\n<p><img src=\"/../images/ss/lec16_1.jpg\"></p>\n<p>The last line of this table is wrong. The correct is:</p>\n<div>$$\nR_h(\\tau) = h(\\tau) * h^*(-\\tau)\n$$</div>\n\n<h3 id=\"Match-Filters\"><a href=\"#Match-Filters\" class=\"headerlink\" title=\"Match Filters\"></a>Match Filters</h3><div>$$\nH(j\\omega) = kS(-j\\omega)e^{-j\\omega t_m}\\\\\nh(t) = ks(t_m - t)\\\\\n$$</div>\n\n<p>$t_m$ is the signal width in TD.</p>\n<h2 id=\"Discrete-time-signals\"><a href=\"#Discrete-time-signals\" class=\"headerlink\" title=\"Discrete time signals\"></a>Discrete time signals</h2><p>Discrete time-axis, but continuous amplitude-axis</p>\n<h3 id=\"Sequence-operation\"><a href=\"#Sequence-operation\" class=\"headerlink\" title=\"Sequence operation\"></a>Sequence operation</h3><p><strong>Addition</strong> $z(n) &#x3D; x(n) + y(n)$</p>\n<p><strong>Multiplication</strong> $z(n) &#x3D; x(n) * y(n)$</p>\n<p><strong>Multiplied a coefficient</strong> $z(n) &#x3D; a * x(n)$</p>\n<p><strong>Shift</strong> $z(n) &#x3D; x(n - m)$ right shift($m&gt;0$), $z(n) &#x3D; x(n +m)$ left shift</p>\n<p><strong>Reflection</strong> $z(n) &#x3D; x(-n)$</p>\n<p><strong>Difference</strong> $\\Delta x(n) &#x3D; x(n + 1) - x(n)$ Forawrd difference, </p>\n<p>$\\nabla x(n) &#x3D; x(n) - x(n - 1)$ Backward difference</p>\n<p>$\\nabla^mx(n) &#x3D; \\nabla(\\nabla^{m-1}x(n))$</p>\n<p><strong>Summation</strong> $z(n) &#x3D; \\sum_{k &#x3D; -\\infty}^{n}x(k)$</p>\n<p><strong>Scaling</strong> $z(n) &#x3D; z(2n)$ squeeze, </p>\n<p>$z(n) &#x3D; x(n&#x2F;2)$, extend</p>\n<h3 id=\"Typical-sequences\"><a href=\"#Typical-sequences\" class=\"headerlink\" title=\"Typical sequences\"></a>Typical sequences</h3><p><img src=\"/../images/ss/lec16_2.jpg\"></p>\n<p><img src=\"/../images/ss/lec16_3.jpg\"></p>\n<p>Relations of several singal waveforms</p>\n<div>$$\nu(n) = \\sum_{k = 0}^{\\infty}\\delta(n - k)\\\\\n\\delta(n) = u(n) - u(n - 1)\\\\\nR_N(n) = u(n) - u(n - N)\\\\\n$$</div>\n\n<h3 id=\"Signal-Decomposition-1\"><a href=\"#Signal-Decomposition-1\" class=\"headerlink\" title=\"Signal Decomposition\"></a>Signal Decomposition</h3><div>$$\nx(n) = \\sum_{m = -\\infty}^{\\infty}x_m\\delta(n - m)\\\\\n$$</div>\n\n<div>$$\n\\delta(n - m) = \\begin{cases}\n1, & n = m\\\\\n0, & n \\neq m\n\\end{cases}\n$$</div>\n\n<h3 id=\"Difference-equations\"><a href=\"#Difference-equations\" class=\"headerlink\" title=\"Difference equations\"></a>Difference equations</h3><p><img src=\"/../images/ss/lec16_4.jpg\"></p>\n<p>Numerical solution of difference equations</p>\n<p>General form of difference equation:</p>\n<div>$$\n\\sum_{k = 0}^N a_ky(n - k) = \\sum_{r = 0}^M b_ry(n - r)\\\\\n$$</div>\n\n<p><strong>Methods:</strong></p>\n<ul>\n<li>Recursive method</li>\n<li><ul>\n<li>Intuitive, difficult to formulate the closed-form solutions</li>\n</ul>\n</li>\n<li>Time-domain classical method</li>\n<li><ul>\n<li>Obtain homogeneous and particular solutions and using the  boundary condition to determine the coefficients.</li>\n</ul>\n</li>\n<li>The sum of the zero-input and zero-state responses</li>\n<li><ul>\n<li>Convolution (next class)</li>\n</ul>\n</li>\n<li>Z-transform (Chapter 8)</li>\n<li>State variable method (Chapter 11)</li>\n</ul>\n<p><strong>Homogeneous Solution</strong></p>\n<div>$$\n\\sum_{k = 0}^N a_ky(n - k) = 0\\\\\n$$</div>\n\n<p>The <strong>characteristic root</strong> $\\alpha_k$ satisfies:</p>\n<div>$$\na_0\\alpha^N + a_1\\alpha^{N-1} + \\cdots + a_N = 0\\\\\n$$</div>\n\n<p>The homogeneous solution is:</p>\n<div>$$\ny(n) = c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n\\\\\n$$</div>\n\n<p><strong>Particular Solutions</strong>:</p>\n<p><img src=\"/../images/ss/lec16_.jpg\"></p>\n<p><strong>General steps</strong></p>\n<ol>\n<li>Obtain homogeneous solutions from characteristic equation $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n$</li>\n<li>Determine the form of the particular solution $D(n)$</li>\n<li>The complete solution $c_1\\alpha_1^n + c_2\\alpha_2^n + \\cdots + c_N\\alpha_N^n + D(n)$</li>\n<li>Introduce the boundary condition and set up equations<div>$$\ny(0) = C_1 +C_2 + \\cdots + C_N + D(0)\\\\\ny(1) = C_1\\alpha_1 +C_2\\alpha_2 + \\cdots + C_N\\alpha_N + D(1)\\\\\n\\vdots\\\\\ny(N - 1) = C_1\\alpha_1^{N - 1} + C_2\\alpha_2^{N - 1} + \\cdots + C_N\\alpha_N^{N - 1} + D(N - 1)\\\\\n\\Rightarrow\\\\\nY(k) - D(k) = VC\\\\\nC = V^{-1}(Y(k) - D(k))\\\\\n$$</div></li>\n</ol>\n<h3 id=\"Zero-input-and-zero-state-responses\"><a href=\"#Zero-input-and-zero-state-responses\" class=\"headerlink\" title=\"Zero-input and zero-state responses\"></a>Zero-input and zero-state responses</h3><div>$$\ny(k) = y_{zi}(k) + y_{zs}(k)\n$$</div>\n\n<p><strong>Zero-Input Response</strong><br>$D(k) &#x3D; 0 \\Rightarrow C_{zi} &#x3D; V^{-1}Y_{zi}(k)$</p>\n<p><strong>Zero-State Response</strong></p>\n<div>$$\n\\begin{align*}\n  C_{zs} &= V^{-1}[Y_{zs}(k) - D(k)]\\\\\nC_{zs} &= V^{-1}[Y(k) - Y_{zi}(k) - D(k)]\\\\\nC &= C_{zi} + C_{zs}\\\\\n\\end{align*}\n$$</div>\n\n<p><strong>Natural Response</strong> $\\sum_{k &#x3D; 1}^NC_k\\alpha_k^n$</p>\n<p><strong>Forced Response</strong> $D(n)$</p>\n<p>Characteristics of the boundary condition for difference equations</p>\n<p>N-th order difference equation should have N independent boundary conditions.</p>\n<p>Compared with continuous systems, there are no big differences between $0_+$ and $0_-$ in discrete systems. </p>\n<p>$y(-1), y(-2), \\dots, y(-N)$ are the system memory (storage) before the excitation is added: $0_-$</p>\n<p>Derive (together with the excitation) $y(0), y(1), …, y(N-1): 0_+$</p>\n<p>Using Z-transform can avoid mistakes－similar to the Laplace transform in continuous systems.</p>\n<h3 id=\"Impulse-response-of-DT-systems\"><a href=\"#Impulse-response-of-DT-systems\" class=\"headerlink\" title=\"Impulse response of DT systems\"></a>Impulse response of DT systems</h3><p>Similar to CT System, h(n) reflects system’s property</p>\n<p><strong>Causality</strong> $h(n) &#x3D; h(n) u(n)$ (unlateral, $n\\lt 0$ no response)</p>\n<p><strong>Stability</strong> $\\sum_{n&#x3D;-\\infty}^\\infty |h(n)| \\lt \\infty$ (absolutely summable)</p>\n<pre><code> NOTE:  critical stability can be considered as either stable or unstable, e.g.,  system whose impulse response is a sine sequence\n</code></pre>\n<p>Not all practical discrete systems are necessarily causal：</p>\n<ul>\n<li>Variable is not time, like image processing</li>\n<li>Variable is time, but data has been recorded and processed, like voice processing, meteorology, stock systems.</li>\n</ul>\n<p>Example: Smooth windowing</p>\n<div>$$\ny(n) = \\frac{1}{2M+1}\\sum_{k=-M}^M x(n-k)\n$$</div>\n\n<p>Discrete non-causal system</p>\n<h3 id=\"Convolution-Sum\"><a href=\"#Convolution-Sum\" class=\"headerlink\" title=\"Convolution Sum\"></a>Convolution Sum</h3><div>$$\ny(n) = \\sum_{m = -\\infty}^\\infty x(m)h(n - m) = h(n) * x(n)\n$$</div>\n\n<p>Similar to CT system, also satisfies both distributive and associative laws </p>\n<p>Calculation of convolution：<br>Four steps: reflection, shift, multiplication and summation. </p>\n<p>Calculation of correlation：<br>Cross- &amp; auto-correlation: shift, multiplication &amp; summation. </p>\n<p>Example:</p>\n<div>$$\nx(n) = u(n) - u(n - N)\\\\\nh(n) = a^nu(n)\\\\\ny(n) = x(n) * h(n)\n$$</div>\n\n<div>$$\ny(n) = \\sum_{m = -\\infty}^\\infty [u(m) - u(m - N)]a^{n - m}u(n - m)\n$$</div>\n\n<p>if $n &lt; 0$, then $y(n) &#x3D; 0$</p>\n<p>if $0 \\le n \\lt N - 1$, $y(n) &#x3D; \\sum_{m &#x3D; 0}^na^{n-m} &#x3D; \\frac{1}{1 - a}[1 - a^{n+1}]$</p>\n<p>if $n \\ge N - 1$, $y(n) &#x3D; \\frac{1 - a^{-N}}{1 - a^{-1}}a^n$</p>\n<p><strong>Deconvolution</strong></p>\n<p><strong>Signal retrieval</strong> y(n) and h(n) are known, how to derive x(n)?</p>\n<p><em>Measurement equipment (linear system), like sensor for measuring blood pressure</em></p>\n<p><strong>System identification</strong> y(n) and x(n) are known, how to derive h(n)?</p>\n<p><em>Earthquake signal, like geological survey, oil exploration, etc.</em></p>\n<div>$$\n\\begin{bmatrix*}\n   y(0)\\\\\n   y(1)\\\\\n   y(2)\\\\\n   \\vdots\\\\\n   y(n)\n\\end{bmatrix*} = \n\\begin{bmatrix*}\n  h(0) & 0 & 0 & \\dotsb & 0\\\\\n  h(1) & h(0) & 0 & \\dotsb & 0\\\\\n  h(2) & h(1) & h(0) & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  h(n) & h(n-1) & h(n-2) & \\dotsb & h(0)\\\\\n\\end{bmatrix*}\\begin{bmatrix*}\n   x(0)\\\\\n   x(1)\\\\\n   x(2)\\\\\n   \\vdots\\\\\n   x(n)\n\\end{bmatrix*}\n$$</div>\n\n<p>Thus, </p>\n<div>$$\nx(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} x(m) h(n - m)\\right]/h(0)\\\\\nh(n) = \\left[y(n) - \\sum_{m = 0}^{n-1} h(m) x(n - m)\\right]/x(0)\n$$</div>\n\n<h3 id=\"Important-Concepts\"><a href=\"#Important-Concepts\" class=\"headerlink\" title=\"Important Concepts\"></a>Important Concepts</h3><p><img src=\"/../images/ss/lec17_1.jpg\"></p>\n<ol>\n<li>Symbol rate :  clock period is $T$, signal symbol rate is $f &#x3D; 1&#x2F;T$.</li>\n<li>Information rate: information rate equals to symbol rate for binary encoding, otherwise, equal to multiplication between symbol rate and number of information bits per symbol.</li>\n<li>Signal bandwidth: the first zero of non-return-to-zero (NRZ) signal’s spectrum is $1&#x2F;T$,  so the signal bandwidth is $B&#x3D;1&#x2F;T &#x3D;f$.</li>\n</ol>\n<blockquote>\n<p>这句话是在介绍非归零码（Non-Return-to-Zero，简称NRZ）信号的带宽计算方式。</p>\n<p>在信号处理和通信中，信号的频谱表示了信号在不同频率上的能量分布。对于一个NRZ信号，它的频谱图中第一个零点（也就是在零周围出现的第一个极小值点）出现在频率为$1&#x2F;T$处，其中$T$是NRZ信号中一个脉冲的时间长度。这是因为NRZ信号的频谱是由一个周期为$T$的方波产生的，其频率成分只包含正弦函数的奇次谐波。其中，最低的一个谐波频率是$f&#x3D;\\frac{1}{T}$，对应的是频率为$f$的正弦波。所以，NRZ信号的带宽$B$就被定义为$f&#x3D;1&#x2F;T$。</p>\n<p>简而言之，NRZ信号的带宽是由脉冲的时间长度决定的，具体来说，带宽等于脉冲频率的一半，即带宽等于$f&#x3D;1&#x2F;T$。</p>\n</blockquote>\n<p>NOTE:</p>\n<p>When NRZ code is used, signal bandwidth &#x3D; symbol rate</p>\n<p>When return-to-zero (RZ) code is used, signal bandwidth &gt; symbol rate</p>\n<p>Using NRZ code can save bandwidth yet high frequency components of the rectangular signal will suffer from the severe inter-symbol interference (ISI). So the raised cosine or Sa function is preferred.</p>\n<blockquote>\n<p>ChatGPT:</p>\n<p>归零码和非归零码都是数字通信中常用的编码方式。</p>\n<p>归零码（Return-to-Zero，简称RZ）是一种二进制码，其中一个信号所代表的位是由一个脉冲表示的。发送二进制“1”时，脉冲电平为高电平，发送二进制“0”时，脉冲电平为低电平。在归零码中，一个信号位所代表的脉冲之后，信号在下一时刻会回到零电平。由于归零码中每个脉冲结束时信号回到零电平，因此这种编码方式具有稳定可靠的特点，但是传输的带宽相对较大。</p>\n<p>非归零码（Non-Return-to-Zero，简称NRZ）的编码方式与归零码不同之处在于，在NRZ信号中，一个信号所代表的位是由一个固定电平表示的。当信号所代表的位是二进制“1”时，固定电平为高电平；当信号所代表的位是二进制“0”时，固定电平为低电平。这种编码方式的好处是带宽更小，但是却存在着在多个二进制“1”连续发送时，出现误解的情况。</p>\n<p>综上所述，归零码是二进制码中脉冲与幅度的双重编码，不易产生传输误码，但其对于通信带宽需求较大；而非归零码不需要对脉冲进行编码，在带宽方面具有一定的优势，但长时间连续发送相同信息时会产生误解。</p>\n</blockquote>\n<h3 id=\"Z-Transform\"><a href=\"#Z-Transform\" class=\"headerlink\" title=\"Z-Transform\"></a>Z-Transform</h3><p>Similar to the L-Tranform.</p>\n<p><strong>Definition</strong></p>\n<div>$$\nX(z) = Z(x(n)) = \\sum_{n = -\\infty}^{\\infty} x(n) z^{-n}\n$$</div>\n\n<p><strong>Z-T of Typical Series</strong></p>\n<p>$z \\in \\Complex$</p>\n<div>$$\n\\delta(n) \\rightarrow 1\\\\\nu(n) \\rightarrow \\frac{1}{1-z^{-1}}(|z| \\gt 1)\\\\\nnu(n) \\rightarrow \\frac{z^{-1}}{(1-z^{-1})^2}(|z| \\gt 1)\\\\\na^n u(n) \\rightarrow \\frac{1}{1-az^{-1}}(|z| \\gt |a|)\\\\\n\\cos(\\omega_0 n) u(n) \\rightarrow \\frac{1-z^{-1}\\cos(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n\\sin(\\omega_0 n) u(n) \\rightarrow \\frac{z^{-1}\\sin(\\omega_0)}{1-2z^{-1}\\cos(\\omega_0) + z^{-2}}\\\\\n$$</div>\n\n<p><strong>The Region of Convergence</strong></p>\n<p><img src=\"/../images/ss/lec18_1.jpg\"></p>\n<p><strong>Inverse Z-Transform</strong></p>\n<div>$$\nx(n) = \\frac{1}{2\\pi j} \\oint_C X(z) z^{n-1} dz\n$$</div>\n\n<p><strong>Method</strong></p>\n<p><strong>Contour Integration(residue method)</strong></p>\n<p>Right-sided sequence</p>\n<div>$$\nx(n) = \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$</div>\n\n<p>Left-sided sequence</p>\n<div>$$\nx(n) = - \\sum_{k = 1}^{N} Res\\{X(z)z^{n-1}\\}|_{z = z_k}\n$$</div>\n\n<p><strong>Power series expansion(Long division)</strong></p>\n<p><img src=\"/../images/ss/lec18_2.jpg\"></p>\n<p>If it is right sided, </p>\n<div>$$\nX(z) = \\sum_{n = 0}^\\infty x(n)z^{-n}\n$$</div>\n\n<p>If it is left sided,</p>\n<div>$$\nX(z) = \\sum_{n = -\\infty}^{-1}x(n)z^{-n}\n$$</div>\n\n<p><strong>Partial Fraction Expansion</strong></p>\n<div>$$\n\\frac{z}{z - a} \\lrarr \\begin{cases}\n a^nu(n), &|z|\\gt |a|\\\\\n -a^nu(-n-1), &|z|\\lt |a|\n\\end{cases}\n$$</div>\n\n<p><img src=\"/../images/ss/lec18_3.jpg\"></p>\n<p><img src=\"/../images/ss/lec18_34jpg.jpg\"></p>\n<p><img src=\"/../images/ss/lec18_6.jpg\"></p>\n<p><strong>Properties of Z-T</strong></p>\n<p><strong>Linearity</strong></p>\n<p>Addition and homogeneity</p>\n<p><font color=\"red\">ROC may change!</font></p>\n<p>i.e. poles are cancelled when added: ROC will enlarge or and shrink.</p>\n<p><strong>Time shifting</strong></p>\n<p>(a) bilateral: If $\\mathcal Z[x(n)] &#x3D; X(z), R_{X_1} &lt; |z| &lt; R_{X_2}$, then $\\mathcal{Z}[x(n-m)] &#x3D; z^{-m}X(z), R_{X_1} &lt; |z| &lt; R_{X_2}$.</p>\n<p>(b) unilateral: if $\\mathcal{Z}[x(n)] &#x3D; X(z), R_{X_1} &lt; |z|$, then $\\mathcal{Z}[x(n-m)] &#x3D; z^{-m}[X(z) + \\sum_{k &#x3D; -m}^{-1}x(k)z^{-k}], R_{X_1}\\lt |z|$, and $\\mathcal{Z}[x(n+m)] &#x3D; z^{m}[X(z) - \\sum_{k &#x3D; 0}^{m-1}x(k)z^{-k}], R_{X_1}\\lt |z|$</p>\n<p>For casual sequence, $n &lt; 0, x(n) &#x3D; 0$, the unilateral is also $\\mathcal{Z}[x(n-m)] &#x3D; z^{-m}X(z)$.</p>\n<p>The reason is that the unilateral z transform doesn’t contain the $n&lt;0$ parts of sequence, but after shifting, sometimes must be counted(right shift), sometimes must be discarded(left shift).</p>\n<p><strong>Linear weighting on sequence(Z domain differentiation)</strong></p>\n<div>$$\n\\mathcal{Z}[x(n)] = X(z) \\Rightarrow nx(n)\\lrarr -z\\frac{dX(z)}{dz}\n$$</div>\n\n<p>Generalization:</p>\n<div>$$\nn^mx(n)\\lrarr \\bigg[-z\\frac{d}{dz}\\bigg]^m X(z)\n$$</div>\n\n<p><strong>Geometric progression(Z-domain scaling)</strong></p>\n<div>$$\na^n(x^n) \\lrarr X(\\frac{z}{a})\\\\\n(R_{x1} \\lt \\bigg|\\frac{z}{a}\\bigg| \\le R_{x2})\n$$</div>\n\n<div>$$\na^{-n}x(n) \\lrarr X(az)\\\\\n(-1)^nx(n) \\lrarr X(-z)\n$$</div>\n\n<p><strong>Initial-value theorem</strong></p>\n<div>$$\nx(0) = \\lim_{z \\rightarrow \\infty }X(z)\n$$</div>\n\n<p><strong>Final-value theorem</strong></p>\n<div>$$\n\\lim_{n \\rightarrow \\infty } x(n) = \\lim_{z \\rightarrow 1}[(z-1)X(z)]\n$$</div>\n\n<p>condition: when $n \\rightarrow \\infty$, $x(n)$ converge </p>\n<p>Thus, the poles of $X(z)$ are inside the unit circle, the radius of ROC is less than 1.</p>\n<p>For $a^nu(n), |a| \\lt 1$, the final value is 0.</p>\n<p>Or, if the pole is on the unit circle, it should be 1, and is of the 1st order.</p>\n<p>$u(n)$’s final value is 1.</p>\n<p><img src=\"/../images/ss/lec19_1jpg.jpg\"></p>\n<p><strong>Time-domain convolution theorem</strong></p>\n<p>If $\\mathcal{Z}{x(n)} &#x3D; X(z), (R_{x1} \\lt |z| \\lt R_{x2}), \\mathcal{Z}{h(n)} &#x3D; H(z), (R_{h1} \\lt |z| \\lt R_{h2})$</p>\n<div>$$\n\\mathcal{Z}[x(n) * h(n)] = X(z)H(z)\\\\\n\\max(R_{x1}, R_{h1}) \\lt |z| \\lt \\min(R_{x2}, R_{h2})\n$$</div>\n\n<p>If poles are cancelled in multiplication, ROC is enlarged.</p>\n<p>Conclusion: (Z Transform) convolution in time-domain is equivalent to multiplication (of Z Transform) in Z-domain.</p>\n<p><strong>Z domain convolution theorem</strong></p>\n<div>$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(\\frac{z}{v})H(v)v^{-1}dv\n$$</div>\n\n<p>or </p>\n<div>$$\n\\mathcal{Z}[x(n)h(n)] = \\frac{1}{2\\pi j} \\oint_C X(v)H(\\frac{z}{v})v^{-1}dv\n$$</div>\n\n<p>where $C$ is a closed contour in the intersection of ROCs of $X(\\frac{z}{v})$ and $H(v)$ or $X(v)$ and $H(\\frac z v)$.</p>\n<p>let $v &#x3D; \\rho e^{j\\theta}, z &#x3D; r e^{j\\varphi}$, </p>\n<p>then </p>\n<div>$$\n\\mathcal Z[x(n)h(n)] = \\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(\\rho e^{j\\theta})H(\\frac r\\rho e^{-j(\\varphi - \\theta)})d\\theta\n$$</div>\n\n<h3 id=\"Mapping-of-ZT-and-LT\"><a href=\"#Mapping-of-ZT-and-LT\" class=\"headerlink\" title=\"Mapping of ZT and LT\"></a>Mapping of ZT and LT</h3><div>$$\nz = e^{sT} ,\\omega_s = \\frac{2\\pi}{T}\n\\\\\nre^{j\\theta} = e^{(\\sigma + j\\omega)T}\\\\\n$$</div>\n\n<p>then, </p>\n<div>$$\nr = e^{\\sigma T} = e^{2\\pi\\frac{\\sigma}{\\omega_s}}\\\\\n\\theta = \\omega T = 2\\pi\\frac{\\omega}{\\omega_s}\n$$</div>\n\n<p>when $\\sigma$ is constant, </p>\n<p>vertical line in $s$-plane maps the circle in $z$-plane.</p>\n<p>$s$-plane imaginary axis maps the unit circle in $z$-plane.</p>\n<p>when $\\omega$ is constant,</p>\n<p><img src=\"/../images/ss/lec19_2jpg.jpg\"></p>\n<p><strong>Correspondence of ZT and LT</strong></p>\n<p><img src=\"/../images/ss/lec19_3.jpg\"></p>\n<h3 id=\"Solving-difference-equation-by-Z-T\"><a href=\"#Solving-difference-equation-by-Z-T\" class=\"headerlink\" title=\"Solving difference equation by Z-T\"></a>Solving difference equation by Z-T</h3><div>$$\n\\sum_{k = 0}^N a_ky(n-k) = \\sum_{r = 0}^M b_rx(n-r)\n$$</div>\n\n<p>Two methods:</p>\n<ul>\n<li>TD method</li>\n<li>Z-T method (notice the ROC)</li>\n</ul>\n<p><strong>ZT method</strong></p>\n<ol>\n<li>perform unilateral Z-T on both sides.</li>\n</ol>\n<p>$x(n-r), y(n-k)$ are both right shifted series</p>\n<div>$$\n\\sum_{k = 0}^N a_kz^{-k}[Y(z) + \\sum_{l = -k}^{-1}y(l)z^{-l} ]= \\sum_{r = 0}^M b_rz^{-r}[X(z) + \\sum_{m = -r}^{-1}x(m)z^{-m} ]\n$$</div>\n\n<ol start=\"2\">\n<li>Derive $Y(z)$</li>\n<li>Perform inverse transform on $Y(z)$ to get $y(n)$(ROC!)</li>\n</ol>\n<p><strong>Zero input response</strong></p>\n<div>$$\nx(n) = 0\\\\\nY(z) = \\frac{-\\sum_{k = 0}^M[a_kz^{-k}\\cdot \\sum_{l = -k}^{-1}y(l)z^{-l}]}{\\sum_{k = 0}^Na_kz^{-k}}\n$$</div>\n\n<p><strong>Zero state response</strong></p>\n<div>$$\ny(l) = 0\\\\\n\\text{ casual sequence }: x(m) = 0\\\\\n\\sum_{k = 0}a_kz^{-k}Y(z) = \\sum_{r = 0}^M b_rz^{-r}X(z)\\\\\nY(z) = X(z)\\cdot\\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}} = X(z)\\cdot H(z)\n$$</div>\n\n<h3 id=\"System-function-of-DT-system\"><a href=\"#System-function-of-DT-system\" class=\"headerlink\" title=\"System function of DT system\"></a>System function of DT system</h3><p><strong>Unit Impulse&#x2F;sample response $h(n)$ and system function H(z)</strong></p>\n<div>$$\ny(n) = x(n) * h(n)\\\\\nY(z) = H(z)\\cdot X(z)\n$$</div>\n\n<div>$$\nH(z) = \\frac{Y(z)}{X(z)} = \\frac{\\sum_{r = 0}^M b_rz^{-r}}{\\sum_{k = 0}^Na_kz^{-k}}\n$$</div>\n\n<p>Factorization</p>\n<div>$$\nH(z) = \\frac{\\prod_{r = 1}^M(1-z_rz^{-1})}{\\prod_{k=1}^N1-p_kz^{-1}}\n$$</div>\n\n<p>We can draw the conclusions directly from the relationship between Z-T and L-T</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Imaginary axis</td>\n<td>$\\sigma&#x3D;0$</td>\n<td>Constant amplitude</td>\n<td>$r &#x3D; 1$</td>\n<td>Unit circle</td>\n</tr>\n<tr>\n<td>Right half plane</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Left half plane</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Real axis</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><img src=\"/../images/ss/lec20_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec20_2.jpg\"></p>\n<p><strong>Stability and Causality</strong></p>\n<p>Stable: iff</p>\n<div>$$\n\\sum_{n=-\\infty}^\\infty |h(n)|\\lt \\infty\n$$</div>\n\n<div>$$\nz = 1, H(z) = \\sum_{n=-\\infty}^\\infty h(n)\\lt \\infty\n$$</div>\n\n<p>The condition is ROC of stable system includes the unit circle.</p>\n<p>Causal:</p>\n<div>$$\nh(n) = h(n)u(n)\n$$</div>\n\n<p>Condition is ROC includes $\\infty$: $R_{X_1}\\lt |z|$</p>\n<p><strong>Stable and causal</strong></p>\n<div>$$\na\\le |z| \\le \\infty, a\\le 1\n$$</div>\n\n<h3 id=\"Discrete-time-Fourier-Transform-DTFT\"><a href=\"#Discrete-time-Fourier-Transform-DTFT\" class=\"headerlink\" title=\"Discrete-time Fourier Transform(DTFT)\"></a>Discrete-time Fourier Transform(DTFT)</h3><p><strong>Definition</strong></p>\n<div>$$\n\\mathcal{F}[x(t)\\delta_T(t)] = \\int_{-\\infty}^\\infty x(t)\\delta_T(t)e^{-j\\omega t}dt = \\sum_{n=-\\infty}^\\infty x(nT)e^{-j\\omega nT}\n$$</div>\n\n<p>take $T &#x3D; 1$</p>\n<div>$$\n\\sum_{n=-\\infty}^\\infty x(n)e^{-j\\omega n} = \\text{DTFT[x(n)]}\n$$</div>\n\n<p>The relation ship with Z-T:</p>\n<div>$$\nX(z) = \\sum_{n = -\\infty}^\\infty x(n)z^{-n}, z = e^{j\\omega}\\\\\n$$</div>\n\n<div>$$\nDTFT[x(n)] = X(z)|_{|z|=1} = X(z)|_{z = e^{j\\omega}} = X(e^{j\\omega})\n$$</div>\n\n<p>Inverse transform</p>\n<div>$$\nx(n) = \\frac{1}{2\\pi j}\\oint_{|z| = 1}X(z)z^{n-1}\\mathrm dz=\\frac{1}{2\\pi}\\int_{-\\pi}^\\pi X(e^{j\\omega})e^{j\\omega n}\\mathrm d\\omega\n$$</div>\n\n<h3 id=\"Frequency-Response-of-DT-system\"><a href=\"#Frequency-Response-of-DT-system\" class=\"headerlink\" title=\"Frequency Response of DT system\"></a>Frequency Response of DT system</h3><p>The steady-state response to sine sequence</p>\n<div>$$\nx(n) = A\\sin(n\\omega)(n\\ge 0)\\\\\ny_{ss}(n) = A|H(e^{j\\omega})|\\sin(n\\omega + \\varphi)\\\\\nH(e^{j\\omega}) = \\sum_{n=-\\infty}^\\infty h(n)e^{-jn\\omega}\n$$</div>\n\n<p>The FT of $h(n)$, $H(e^{j\\omega})$ is a periodic function with period of $\\omega_s &#x3D; 2\\pi &#x2F;T &#x3D; 2\\pi$.</p>\n<p>If $h(n)$ is real, then the amplitude&#x2F;phase response is even&#x2F;odd function.</p>\n<p>The amplitude is determined within $[0, \\omega_s&#x2F;2]$</p>\n<p><img src=\"/../images/ss/lec20_3.jpg\"></p>\n<p><img src=\"/../images/ss/lec20_4.jpg\"></p>\n<p>NOTE:</p>\n<ul>\n<li>We can derive the frequency response (function of $\\omega$) by letting $D$ move along the unit circle once.</li>\n<li>$H(j\\omega)$ is periodic. The frequency response from 0 to $\\omega_s&#x2F;2$ can be determined by letting $D$ move along half circle.</li>\n<li>If pole $p_i$ is close to the unit circle, there will be a peak in the frequency response. If zero $z_i$ is close to the unit circle, there will be a notch in the frequency response.</li>\n<li>For statble systems, $p_i$ should be inside the unit circle, while $z_i$ could be inside or outside the unit circle.</li>\n<li>poles and zeros at origin have no influence on amplitude.</li>\n</ul>\n<h3 id=\"Analog-and-digital-Filter\"><a href=\"#Analog-and-digital-Filter\" class=\"headerlink\" title=\"Analog and digital Filter\"></a>Analog and digital Filter</h3><p><strong>Fundamental Principles</strong></p>\n<p><img src=\"/../images/ss/lec20_5.jpg\"></p>\n<p>The spectrum of $x(t)$ is strictly inside $\\pm \\omega_m$.</p>\n<p>We choose the sampling frequency:$\\omega_s &#x3D; \\frac{2\\pi}{T} \\ge 2\\omega_m$</p>\n<p><img src=\"/../images/ss/lec20_6.jpg\"></p>\n<p><strong>Classifications of digital filters</strong></p>\n<div>$$\ny(n) = \\sum_{k=0}^M b_kx(n-k) - \\sum_{k=1}^N a_ky(n-k)\n$$</div>\n\n<p>In terms of structure</p>\n<p>recursive: $a_k\\ne 0$ at least for one $k$</p>\n<p>non-recursive: $a_k&#x3D;0$, for all $k$</p>\n<p>In terms of the characteristics of $h(n)$</p>\n<p>Infinite impulse response(IIR): recursive, non-linear phase</p>\n<p>Finite impulse response(FIR): non-recursive, linear phase.</p>\n<p><strong>IIR filter</strong></p>\n<p>Impulse invariance</p>\n<p>Based on the s-domain analog filters.</p>\n<p>Design method 1: <strong>冲激响应不变法</strong></p>\n<p>Replace $\\frac{1}{s-s_k}$ with $\\frac{1}{1-e^{s_kT}z^{-1}}$. Then $H_a(s)$ become $H(z)$.</p>\n<p>The relationship between the continuous and discrete filters:</p>\n<div>$$\nH(z)|_{z = e^{sT}} = \\frac{1}{T}\\sum_{k=-\\infty}^\\infty H_a(s + j\\frac{2\\pi}{T}k)\n$$</div>\n\n<p>The result is just repeat the original filter at sampling frequency, thus it attenuates slower.</p>\n<p>NOTE:The digital filter implemented this way has aliasing.</p>\n<p>The frequency response of analog filter must be attenuated enough within $\\omega_s$.</p>\n<p>This approach can only realize LP and BP filter, but not HP and band-stop one. </p>\n<p><strong>method 2: Bilinear transformation</strong> emerges to address this problem (you can study it by yourself)</p>\n<div>$$\ns = \\frac{2}{T}\\left(\\frac{1 - z^{-1}}{1 + z^{-1}}\\right)\\\\\nz = \\frac{1 + \\frac{sT}{2}}{1 - \\frac{sT}{2}}\n$$</div>\n\n<p>Bilinear transformation is non-linear transformation.</p>\n<p>To implement digital filter, A&#x2F;D and D&#x2F;A are required, along with ROM, RAM, ALU, delay units (shift registers), etc.</p>\n<p><strong>FIR filter</strong></p>\n<div>$$\nH(z) = \\sum_{k = 0}^{N-1}b_kz^{-k} = \\sum_{n=0}^{N-1}h(n)z^{-n}\n$$</div>\n\n<p>Poles are at $z&#x3D;0$. $N - 1$ zeros.</p>\n<p>FIR filter has linear-phase iff</p>\n<div>$$\nh(n) = h(N - 1 - n)(\\text{evenly symmetric})\\\\\nh(n) = -h(N - 1 - n)(\\text{oddly symmetric})\n$$</div>\n\n<p><img src=\"/../images/ss/lec20_7.jpg\"></p>\n<p><img src=\"/../images/ss/lec20_8.jpg\"></p>\n<h3 id=\"Feedback-System-Signal-Flow-Graphs\"><a href=\"#Feedback-System-Signal-Flow-Graphs\" class=\"headerlink\" title=\"Feedback System: Signal Flow Graphs\"></a>Feedback System: Signal Flow Graphs</h3><p><strong>Operator and Transfer Operator:</strong></p>\n<div>$$\np = \\frac{d}{dt}\\\\\n\\frac{1}{p} = \\int_{-\\infty}^t(\\cdot)d\\tau\n$$</div>\n\n<div>$$\n(C_0p^n + C_1p^{n-1} + \\dotsb + C_n)r(t) = (E_0p^m + E_1p^{m - 1} + \\dotsb + E_m)e(t)\\\\\nD(p)r(t) = N(p)e(t)\n$$</div>\n\n<p>Rules:</p>\n<ul>\n<li>Common factors can’t be eliminated.</li>\n<li>Be careful when changing the order of operation($\\frac{d}{dt}\\int_{-\\infty}^tx(\\tau)d\\tau &#x3D; x(t)$, $\\int_{-\\infty}^t\\frac{d}{d\\tau}x(\\tau)d\\tau &#x3D; x(t) - x(-\\infty)$)</li>\n</ul>\n<p>transfer operator:</p>\n<div>$$\nr(t) = \\frac{N(t)}{D(t)}e(t) = H(p)e(t)\n$$</div>\n\n<p><strong>Brief introduction to the signal flow graphs(SFG)</strong></p>\n<p><img src=\"/../images/digital/lec_11_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec21_4.jpg\"></p>\n<p>Terminnologies in SFG</p>\n<p>Node, Transfer function, Branch(The branch gain is the transfer function), Source node, Sink node, Mixed node.</p>\n<p><strong>Properties of SFG</strong></p>\n<ol>\n<li>Signal only passes through a branch with the direction indicated by the arrowhead.</li>\n<li>Signals of incoming branches are added at a node, and the added signal appears on the all outgoing branches.</li>\n<li>A sink node can be separated from a mixed node.</li>\n<li>For a given system, the SFGs can be different.(equations for a system can be different)</li>\n<li>After the SFG being inversed, the transfer function keeps invariant, but the signals represented by the inner nodes will be different.</li>\n</ol>\n<p>Note: Inversion is done by inversing the transfer direction of each branch, and exchanging the source and sink nodes as well.</p>\n<p>Algebra of SFG</p>\n<p><img src=\"/../images/ss/lec21_5.jpg\"></p>\n<p><img src=\"/../images/ss/lec21_6.jpg\"></p>\n<p>Simplify:</p>\n<p>NOTE: The SFG can be simplified using the following steps:</p>\n<p>a. Merge the cascaded branches to decrease the number of nodes;</p>\n<p>b. Merge the parallel branches to decrease the number of branches;</p>\n<p>c. Eliminate all the loops. </p>\n<p>Then, the system function can be readily derived.</p>\n<p><img src=\"/../images/ss/lec21_7.jpg\"></p>\n<p><strong>Mason’s Formula</strong></p>\n<div>$$\nH = \\frac{1}{\\Delta} \\sum_k g_k\\Delta_k\n$$</div>\n![](../images/ss/lec21_9.jpg)\n\n<h2 id=\"State-variable-analysis-of-system\"><a href=\"#State-variable-analysis-of-system\" class=\"headerlink\" title=\"State-variable analysis of system\"></a>State-variable analysis of system</h2><div>$$\n\\mathbf {\\lambda = A\\lambda + Be}\\\\\n\\mathbf{r = C\\lambda + De}\n$$</div>\n\n<p>Features of the state-variable analytical method </p>\n<ul>\n<li>(1)Provide internal characteristics of the system</li>\n<li>(2) Convenient to represent and analyze the multi-input, multi-output (MIMO) cases</li>\n<li>(3) Easy to be extended to time-variant or nonlinear cases</li>\n<li>(4) Introduce two important concepts: controllability and observability</li>\n<li>(5) Convenient for numerical computation</li>\n</ul>\n<h3 id=\"General-form-and-setup-method-CT\"><a href=\"#General-form-and-setup-method-CT\" class=\"headerlink\" title=\"General form and setup method (CT)\"></a>General form and setup method (CT)</h3><div>$$\n\\frac{d}{dt}\\mathbf{\\lambda}(t)_{k \\times 1} = \\mathbf{A}_{k \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{B}_{k \\times m}\\mathbf{e}(t)_{m \\times 1}\\\\\n\\mathbf{r}(t)_{r \\times 1} = \\mathbf{C}_{r \\times k}\\mathbf{\\lambda}(t)_{k \\times 1} + \\mathbf{D}_{r \\times m}\\mathbf{e}(t)_{m \\times 1}\n$$</div>\n\n<p>$r$ responses, $k$ state variables, $m$ inputs.</p>\n<p>For time-variant system, $\\mathbf{A, B, C, D}$ are fuction of $t$.</p>\n<p>Direct methods:</p>\n<ul>\n<li>observation</li>\n<li>Topological analysis</li>\n</ul>\n<p>Used in curcuit analysis.</p>\n<p>Indirect methods:</p>\n<ul>\n<li>From block diagram or flow graph</li>\n<li>From input-output equation</li>\n<li>From transfer function</li>\n</ul>\n<p>Used in controlled system analysis.</p>\n<p><strong>From input-output equation</strong></p>\n<div>$$\n\\frac{r(t)}{e(t)} = \\frac{b_0p^k + \\dotsb + b_k}{p^k + \\dotsb + a_k}\n$$</div>\n\n<p>NOTE : under the zero-state condition, $p$ is equivalent to $s$ </p>\n<div>$$\nH(p) = \\frac{b_0 + b_1p^{-1} + \\dotsb + b_kp^{-k}}{1 + a_1p^{-1} + \\dotsb + a_kp^{-k}}\n$$</div>\n\n<p>The SFG is:</p>\n<p><img src=\"/../images/ss/lec22_11.jpg\"></p>\n<div>$$\n\\dot{\\lambda}_1 = \\lambda_2\\\\\n\\dot{\\lambda}_2 = \\lambda_3\\\\\n\\vdots\\\\\n\\dot{\\lambda}_k = -a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t)\\\\\nr(t) = b_k\\lambda_1 + b_{k-1}\\lambda_2 + \\dotsb + b_1\\lambda_k + b_0(-a_k\\lambda_1 - a_{k-1}\\lambda_2 - \\dotsb - a_1\\lambda_k + e(t))\\\\\n=(b_k - a_kb_0)\\lambda_1 + (b_{k-1} - a_{k-1}b_0)\\lambda_2 + \\dotsb + (b_1 - a_1b_0)\\lambda_k + b_0e(t)\n$$</div>\n\n<div>$$\n\\mathbf A = \\begin{bmatrix}\n  0 & 1 & 0 & \\dotsb & 0\\\\\n  0 & 0 & 1 & \\dotsb & 0\\\\\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n  0 & 0 & 0 & \\dotsb & 1\\\\\n  -a_k & -a_{k-1} & -a_{k-2} & \\dotsb & -a_1\n\\end{bmatrix}\\\\\nB = \\begin{bmatrix}\n  0\\\\\n  0\\\\\n  \\vdots\\\\\n  0\\\\\n  1\n\\end{bmatrix}\\\\\n\\mathbf C = \\begin{bmatrix}\n  b_k - a_kb_0 & b_{k-1} - a_{k-1}b_0 & \\dotsb & b_1 - a_1b_0\n\\end{bmatrix}\\\\\nD = b_0\n$$</div>\n\n<p>If  the order of differential equation on the left side is higher than that on the right side:</p>\n<div>$$\nb_0 = 0, \\mathbf{D} = 0\n$$</div>\n\n<p>If the derivatives of the excitation on the right side are absent,</p>\n<div>$$\n\\mathbf{C} = [b_k, 0, \\dotsb, 0], \\mathbf{D} = 0\n$$</div>\n\n<p><strong>Factorizing Transfer operator</strong></p>\n<p><img src=\"/../images/ss/lec22_12.jpg\"></p>\n<p><img src=\"/../images/ss/lec22_13.jpg\"></p>\n<p><img src=\"/../images/ss/lec22_14.jpg\"></p>\n<p><img src=\"/../images/ss/lec22_15.jpg\"></p>\n<p><img src=\"/../images/ss/lec22_16.jpg\"></p>\n<p><img src=\"/../images/ss/lec22_17.jpg\"></p>\n<p><img src=\"/../images/ss/lec22_18.jpg\"></p>\n<h3 id=\"Solving-CT-system’s-state-equations\"><a href=\"#Solving-CT-system’s-state-equations\" class=\"headerlink\" title=\"Solving CT system’s state equations\"></a>Solving CT system’s state equations</h3><p><strong>Time domain method</strong> using computer.</p>\n<p><strong>Transform-domain(Laplace-tranform) method</strong></p>\n<div>$$\n\\frac{d}{dt}\\mathbf{}{\\lambda}(t) = \\mathbf{A\\lambda}(t) + \\mathbf{Be}(t)\\\\\n\\mathbf{r}(t) = \\mathbf{C\\lambda}(t) + \\mathbf{De}(t)\\\\\n\\mathbf{\\lambda}(0_-) = \\begin{bmatrix}\n\\lambda_1(0_-)\\\\\n\\lambda_2(0_-)\\\\\n\\vdots\\\\\n\\lambda_k(0_-)\\\\\n\\end{bmatrix}\n$$</div>\n\n<div>$$\ns\\mathbf \\Lambda(s) - \\mathbf{\\lambda}(0_-) = \\mathbf{A\\Lambda}(s) + \\mathbf{BE}(s)\\\\\n\\mathbf{R}(s) = \\mathbf{C\\Lambda}(s) + \\mathbf{DE}(s)\n$$</div>\n\n<div>$$\n\\mathbf{\\Lambda}(s) = (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{BE}(s)\\\\\n\\mathbf R(s) =\\mathbf{C} (s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{\\lambda}(0_-) + (\\mathbf C(s\\mathbf {I} - \\mathbf{A})^{-1}\\mathbf{B + D)E}(s) \n$$</div>\n\n<p>Let $\\Psi(s) &#x3D; (s\\mathbf I - \\mathbf A)^{-1}$, which is called <strong>characteristic matrix</strong>.</p>\n<div>$$\n\\mathbf\\lambda(t) = \\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\mathcal{L}^{-1}[\\Psi(s)\\mathbf{B}] * e(t)\\\\\n\\mathbf r(t) = \\mathbf{C}\\mathcal{L}^{-1}[\\Psi(s)\\lambda(0_-)] + \\lbrace\\mathbf{C}\\mathcal{L}^{-1}[\\mathbf\\Psi(s)\\mathbf{B] + D}\\delta(t)\\rbrace * e(t)\n$$</div>\n\n<p><strong>Time-domain method</strong></p>\n<div>$$\ne^{\\mathbf At} = \\sum_{k = 0}^\\infty \\frac{1}{k!}A^kt^k\n$$</div>\n\n<p>properties</p>\n<div>$$\ne^{\\mathbf At}e^{-\\mathbf At} = \\mathbf I\\\\\ne^{\\mathbf At} = [e^{-\\mathbf At}]^{-1}\\\\\n\\frac{d}{dt}e^{\\mathbf At} = \\mathbf Ae^{\\mathbf At} = e^{\\mathbf At} \\mathbf A\\\\\n$$</div>\n\n<div>$$\n\\frac{d}{dt}\\mathbf \\lambda(t) = \\mathbf A\\mathbf \\lambda(t) + \\mathbf B\\mathbf e(t)\\\\\ne^{-\\mathbf At}\\frac{d}{dt}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf A\\mathbf \\lambda(t) + e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\frac{d}{dt}e^{-\\mathbf At}\\mathbf \\lambda(t) = e^{-\\mathbf At}\\mathbf B\\mathbf e(t)\\\\\n\\lambda(t) = e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\int_0^te^{\\mathbf A(t - \\tau)}\\mathbf B\\mathbf e(\\tau)d\\tau\\\\\n=e^{\\mathbf At}\\lambda(0_-) + e^{\\mathbf At} \\mathbf B * \\mathbf e(t)\n$$</div>\n\n<p>output</p>\n<div>$$\n\\mathbf r(t) = \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + \\mathbf C e^{\\mathbf At} \\mathbf B * \\mathbf e(t) + \\mathbf D\\mathbf e(t)\\\\\n= \\mathbf C e^{\\mathbf At}\\mathbf \\lambda(0_-) + [\\mathbf C e^{\\mathbf At} \\mathbf B + \\mathbf D\\delta(t)] * \\mathbf e(t)\n$$</div>\n\n<p>Correspond to LT:</p>\n<div>$$\n\\mathcal{L}[e^{\\mathbf At}] = (s\\mathbf I - \\mathbf A)^{-1}\n$$</div>\n\n<p><strong>Derive System Functions</strong></p>\n<p><img src=\"/../images/ss/lec22_19.jpg\"></p>\n<p><img src=\"/../images/ss/lec22_20.jpg\"></p>\n<h3 id=\"That-for-DT-system\"><a href=\"#That-for-DT-system\" class=\"headerlink\" title=\"That for DT system\"></a>That for DT system</h3><p><strong>State equation setup</strong></p>\n<div>$$\n\\begin{align*}\n  \\mathrm\\lambda(n + 1) &= \\mathbf A\\mathrm\\lambda(n) + \\mathbf B\\mathrm x(n)\\\\\n  \\mathrm y(n) &= \\mathbf C\\mathrm\\lambda(n) + \\mathbf D\\mathrm x(n)\n\\end{align*}\n$$</div>\n\n<p>Solving:</p>\n<div>$$\n\\lambda(n) = \\underbrace{A^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}A^{n-1-i}Bx(i)\\right]u(n-1)}_{\\text{Zero State}}\\\\\ny(n) = \\underbrace{CA^n\\lambda(0)u(n)}_{\\text{Zero Input}} + \\underbrace{\\left[\\sum_{i=0}^{n-1}CA^{n-1-i}Bx(i)\\right]u(n-1) + Dx(n)u(n)}_{\\text{Zero State}}\n$$</div>\n\n<p>The Impulse response is:</p>\n<div>$$\nh(n) = CA^{n-1}Bu(n-1) + D\\delta(n)\n$$</div>\n\n<p>Calculate $A^n$: Cayley-Hamilton Theorem</p>\n<p><strong>ZT Solution</strong></p>\n<div>$$\n\\begin{align*}\n  z\\mathrm\\Lambda(z) - z\\lambda(0) &= \\mathbf A\\mathrm\\Lambda(z) + \\mathbf B\\mathrm X(z)\\\\\n  \\mathrm Y(z) &= \\mathbf C\\mathrm\\Lambda(z) + \\mathbf D\\mathrm X(z)\n\\end{align*}\n$$</div>\n\n<div>$$\n\\mathrm \\Lambda(z) = (z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + (z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\mathrm X(z)\\\\\n\\mathrm Y(z) = \\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\lambda(0) + \\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right]\\mathrm X(z)\n$$</div>\n\n<p>then </p>\n<div>$$\n\\lambda(n) = \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\\\\\ny(n) = \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}z\\right]\\lambda(0) + \\mathcal{Z}^{-1}\\left[\\mathbf C(z\\mathbf I - \\mathbf A)^{-1}\\mathbf B + \\mathbf D\\right] * \\mathcal{Z}^{-1}\\left[\\mathrm X(z)\\right]\n$$</div>\n\n<p>Comparing this with CT solution, we find</p>\n<div>$$\nA^n = \\mathcal{Z}^{-1}\\left[(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\right]\\\\\n$$</div>\n\n<div>$$\nH(z) = C(\\mathbf I - z^{-1}\\mathbf A)^{-1}\\mathbf B + D\n$$</div>\n\n<h3 id=\"Linear-Transform-on-state-vectors\"><a href=\"#Linear-Transform-on-state-vectors\" class=\"headerlink\" title=\"Linear Transform on state vectors\"></a>Linear Transform on state vectors</h3><div>$$\n\\mathbf{\\gamma} = \\mathbf P\\mathbf \\lambda\n$$</div>\n\n<p>The equations become:</p>\n<div>$$\n\\frac{d}{dt}\\gamma(t) =\\mathbf{PAP}^{-1}\\mathbf \\gamma(t) + \\mathbf{PB}e(t)\\\\\n\\mathbf y(t) = \\mathbf {CP}^{-1}\\gamma(t) + \\mathbf D\\mathbf e(t)\n$$</div>\n\n<p>Similarity transform doesn’t change the eigenvalues.</p>\n<p><strong>Transform function matrix keeps invariant under linear transformation.</strong></p>\n<p>We can <strong>diagonalize</strong> the matrix A.</p>\n<p>Calculate eigenvalues $\\alpha$ -&gt; calulate eigenvectors $\\xi$ -&gt; $\\mathbf P^{-1} &#x3D; [\\xi_i]$, $\\hat A &#x3D; \\text{diag}(\\alpha_i)$</p>\n<h3 id=\"Controllable-amp-Observable\"><a href=\"#Controllable-amp-Observable\" class=\"headerlink\" title=\"Controllable &amp; Observable\"></a>Controllable &amp; Observable</h3><p>Controllable is </p>\n<div>$$\n\\text{rank} [A\\ AB\\ \\dots\\ A^{k-1}B] \\text{ is full}\n$$</div>\n\n<p>Uncontrollabilty is the input can’t change the response.</p>\n<p>Obeservability is </p>\n<div>$$\n\\text{rank} \\begin{bmatrix}\n  C\\\\\n  CA\\\\\n  \\vdots\\\\\n  CA^{k-1}\n  \\end{bmatrix}\n  \\text{ is full}\n$$</div>\n\n<p>Unobserverbility is the response is not affected by the input.</p>\n<p>After the diagonalization of A: </p>\n<p>B doesnt contain zero $\\Leftrightarrow$ completely controllable. Otherwise, the 0s is coresponding to the uncontrollable state variables.</p>\n<p>C doesnt contain zero $\\Leftrightarrow$ completely observable. Otherwise, the 0s is coresponding to the unobservable state variables.</p>\n<p>In fact:</p>\n<div>$$\nH(s) = C(s\\mathbf I - \\mathbf A)^{-1}\\mathbf B + D \\stackrel{D = 0}{=} \\sum_{i=1}^n \\frac{C_iB_i}{s - \\alpha_i}\n$$</div>\n\n<p>The $H(s)$ only contains the controllable and observable state variables. So the state and output equations contains more information than the $H(s)$.</p>\n<p><img src=\"/../images/ss/lec23_1.jpg\"></p>\n<h2 id=\"CDMA\"><a href=\"#CDMA\" class=\"headerlink\" title=\"CDMA\"></a>CDMA</h2><p>Use a set of orthogonal codes to support multiple users by orthorgonal multiplexing.</p>\n<h3 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h3><p>Assume K users need to connect with the base station simultaneously for CDMA system.</p>\n<ol>\n<li>Design a set of orthogonal codes</li>\n<li>Design on the transmitter</li>\n<li>Design on the receiver</li>\n</ol>\n<p>An example of Code 4:</p>\n<div>$$\n\\begin{align*}\n  \\mathbf c_1 &= [1\\ 1\\ 1\\ 1\\ -1\\ -1\\ -1\\ -1]\\\\\n  \\mathbf c_2 &= [1\\ 1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1]\\\\\n  \\mathbf c_3 &= [1\\ -1\\ 1\\ -1\\ 1\\ -1\\ 1\\ -1]\\\\\n  \\mathbf c_4 &= [1\\ -1\\ -1\\ 1\\ 1\\ -1\\ -1\\ 1]\n\\end{align*}\n$$</div>\n\n<div>$$\nR_{x, y}(j) = \\begin{cases}\n  \\sum_{k = 0}^{N - 1 - j} x(k)y(k + j), &0 \\le j \\le N - 1\\\\\n  \\sum_{k = 0}^{N - 1 + j} x(k - j)y(k), &-N + 1 \\le j \\le 0\\\\\n  0, & |j| \\ge N\n\\end{cases}\n$$</div>\n\n<p>Must satisfy:</p>\n<div>$$\nR_{k, i}  \\begin{cases}\n  =T, &k = i, \\tau=0\\\\\n  \\ll T, &k \\ne i \\text{ or } \\tau \\ne 0\n  \\end{cases}\n$$</div>\n\n<p>second:</p>\n<p>(1) frequency shifting: $d_k(t)\\cos(\\omega t)$</p>\n<p>(2) spreading: $s_k(t) &#x3D; d_k(t)c_k(t)\\cos(\\omega t)$</p>\n<p>third: coherent detection&#x2F;de-spreading</p>\n<p>Core:</p>\n<ul>\n<li>Orthogonal code design(signal design)</li>\n<li>Code capturing and tracking(signal processing and system design)</li>\n<li>Multi-use  detection and channel estimation(singal processing and system design)</li>\n</ul>\n<h3 id=\"Code-design\"><a href=\"#Code-design\" class=\"headerlink\" title=\"Code design\"></a>Code design</h3><p>requirements:</p>\n<ul>\n<li>sharp auto-correlation curve</li>\n<li>zero cross-correlation</li>\n<li>largest possible orthogonal code set</li>\n<li>highest possible complexity for security performance</li>\n</ul>\n<p>Commonly used codes:</p>\n<ul>\n<li>Walsh code</li>\n<li>PN sequence</li>\n<li>GOLD codes</li>\n</ul>\n<div>$$\nH_1 = (0)\\\\\nH_2 = \\begin{pmatrix}\n  H_1 & H_1\\\\\n  H_1 & \\overline{H_1}\n\\end{pmatrix} = \\begin{pmatrix}\n  0 & 0\\\\\n  0 & 1\n\\end{pmatrix}\\\\\nH_4 = \\begin{pmatrix}\n  H_2 & H_2\\\\\n  H_2 & \\overline{H_2}\n  \\end{pmatrix}\n$$</div>\n\n<ul>\n<li>sliding window capturing</li>\n<li>multiple correlators to detect phase match</li>\n</ul>\n<p>The period of address code is much shorter than the period of data code: $T_c &lt; T_d$, so the modulated signal is much wider in FD, whose spectrum is called <strong>spread spectrum</strong>.</p>\n"},{"title":"使用VSCode进行c++/c多文件开发","date":"2022-09-02T12:51:41.000Z","_content":"## 前言\nvscode是个非常优秀的跨平台编辑器，尤其在Linux上更为常用。在vscode上进行c++语言的编译、运行和调试已经有了很多教程，但是使用vscode进行多文件的c++编译、调试的教程却相对难找。以下整理出一个在VScode上搭建C++/C开发环境的全过程。\n## 原理\n在Linux上进行c++的多文件编译，主要依靠的是GNU的Makefile，使用make命令进行编译。而makefile的可读性差、语法复杂、跨平台性差等问题又催生了可以在多平台运行、语法简洁的CMake，用来自动生成Makefile。\n\nCMake是一个语法简单的跨平台编译工具。只要编写CMakeLists.txt文件，然后使用cmake命令，就可以根据不同的平台生成合适的Makefile文件，再利用make命令即可编译文件。\n\n问题是，Makefile是Linux的编译工具，怎么在Windows平台上使用呢？毫无疑问可以使用WSL，在Linux子系统中进行c++项目开发。\n\n但是在Windows上使用Makefile也不是没有可能，只要安装GNU在Windows上的移植版——mingw就行了。MinGW中的mingw64-make即为Linux中的make。\n## 实操\n### 前置工作\n没下载MinGW就去下一个。用处很多。\n\n然后下载CMake。\n\nLinux: `sudo apt-get install make`\n\nWindows: 上官网下最新版。\n\n### 配置CMakeLists.txt\n首先将文件夹设置为项目名称。\n\n然后在项目文件夹下添加CMakeLists.txt:\n\n~~~CMake\n# CMakeLists.txt\n# cmake最低版本号要求\ncmake_minimum_required (VERSION 3.0)\n# # 设置指定的C++编译器版本是必须的，如果不设置，或者为OFF，则指定版本不可用时，会使用上一版本。\n# set(CMAKE_CXX_STANDARD_REQUIRED ON)\n# # 指定为C++03 版本\n# set(CMAKE_CXX_STANDARD 03)\n\n# 设置gdb为调试工具\n# 构建模式设置为Debug\nSET(CMAKE_BUILD_TYPE \"Debug\")\n# 调试时使用gdb\nSET(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -Wall -g2 -ggdb\")\n# 发布时使用优化(1~3)\nSET(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O3 -Wall\")\n\n# 获取当前文件夹名称\nstring(REGEX REPLACE \".*/\\(.*\\)\" \"\\\\1\" CURDIR ${CMAKE_CURRENT_SOURCE_DIR})\n# 设置PROJECT_NAME变量\nset(PROJECT_NAME ${CURDIR})\n# 设置工程名\nproject (${PROJECT_NAME})\n# 查找./src目录下的所有源文件并存入DIR_SRCS变量\naux_source_directory(src DIR_SRCS)\n# 添加一个可编译的目标到工程\nadd_executable (${PROJECT_NAME} ${DIR_SRCS})\n# 从./include中添加静态库, 必须写在add_executable之后\ntarget_include_directories(${PROJECT_NAME} PUBLIC ./include)\nmessage(\"PROJECT_NAME: ${PROJECT_NAME}\")\nmessage(\"CMAKE_SOURCE_DIR: ${CMAKE_SOURCE_DIR}\")\nmessage(\"PROJECT_SOURCE_DIR: ${PROJECT_SOURCE_DIR}\")\n~~~\n\n从上面的配置中可以分析出：源文件应该写在`./src`文件夹下，而头文件应该写在`./include`文件夹下。也可以改成其他目录。\n\n代码什么意思在注释中写得很明白了，想要实现更多功能，可以上网查找CMake教程。\n\n### tasks.json配置--CMake构建，Makefile编译\n在/.vscode下添加tasks.json:\n~~~json\n{\n    \"tasks\": [\n        {\n            \"label\": \"CMake\",\n            \"detail\": \"运行CMake\",\n            \"type\": \"shell\",\n            \"command\": \"CMake\",\n            \"args\": [\n            \"-G \\\"MinGW Makefiles\\\"\",   //这个参数指定CMake在mingw下使用makefile进行构建，如果去掉则使用默认的vs进行构建\n                \"..\",\n            ],\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"echo\": true,\n                \"reveal\": \"always\",\n                \"focus\": false,\n                \"panel\": \"shared\",\n                \"showReuseMessage\": true,\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\",\n            \"dependsOn\": [\n                \"MkBuild\"\n            ]\n        },\n\n        {\n            \"label\": \"MkBuild\",\n            \"detail\": \"建立build文件夹\",\n            \"type\": \"shell\",\n            \"command\": \"mkdir\",\n            \"args\": [\n                \"-p\",\n                \"build\"\n            ],\n            \"windows\": {\n                \"args\": [\n                    \"-Force\",\n                    \"build\"\n                ]\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"echo\": true,\n                \"reveal\": \"always\",\n                \"focus\": false,\n                \"panel\": \"shared\",\n                \"showReuseMessage\": true,\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\"\n        },\n        \n        {\n            \"label\": \"Make\",\n            \"detail\": \"使用Makefile编译\",\n            \"type\": \"shell\",\n            \"command\": \"mingw32-make\",\n            \"args\": [\n            ],\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"reveal\": \"always\",\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\",\n        },\n\n        {\n            \"label\": \"Compile\",\n            \"detail\": \"仅编译。使用CMake --build编译，根据操作系统选择合适的编译器\",\n            \"type\": \"shell\",\n            \"command\": \"CMake --build .\",\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"reveal\": \"always\",\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\",\n        },\n\n        {\n            \"label\": \"Run\",\n            \"detail\": \"编译并运行程序\",\n            \"type\": \"shell\",\n            \"command\": \"start\",\n            \"args\": [\n                \"./${workspaceFolderBasename}.exe\"\n            ],\n            \"group\": \"build\",\n            \"presentation\": {\n                \"echo\": true,\n                \"reveal\": \"always\",\n                \"focus\": false,\n                \"panel\": \"shared\",\n                \"showReuseMessage\": true,\n                \"clear\": true\n            },\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"windows\": {\n                \"options\": {\n                    \"cwd\": \"build\"  //exe文件所在的目录\n                }\n            },\n            \"problemMatcher\": \"$msCompile\",\n            \"dependsOn\": [\n                \"Compile\"\n            ]\n        },\n        {\n            \"label\": \"CMake and Run\",\n            \"detail\": \"创建Makefile, 编译并运行程序\",\n            \"type\": \"shell\",\n            \"group\": \"build\",\n            \"dependsOn\": [\n                \"CMake\",\n                \"Run\"\n            ],\n            \"dependsOrder\": \"sequence\"\n        },\n        {\n            \"label\": \"CMake and Make\",\n            \"detail\": \"创建Makefile, 并编译\",\n            \"type\": \"shell\",\n            \"group\": \"build\",\n            \"dependsOn\": [\n                \"CMake\",\n                \"Make\"\n            ],\n            \"dependsOrder\": \"sequence\"\n        },\n    ],\n    \"version\": \"2.0.0\"\n}\n~~~\n这里面定义了一大堆Task，有的是编译并运行，有的是仅编译，有的是仅调用cmake，有的是调用CMake和make，使用时按下`Ctrl + Shift + B`选择合适的task, 看下中文解释就行。\n\n唯一需要解释的一个Task就是MkBuild。MkBuild实际上就是执行`mkdir -p build`。会创建一个叫做build的文件夹。项目的中间文件和最后的可执行文件都会生成在这个文件夹里。后面调试时的文件路径也依赖于build文件夹。\n\n推荐使用CMake and Make进行编译，使用Run进行运行。可以设置task的快捷键，参考网上资料。\n\n注意：按照CMake在原理中的描述，它仅仅是作为生成Makefile文件的工具使用，但是如果运行`cmake . --build`，CMake就可以不依赖Makefile，自己寻找合适的编译器进行编译。Tasks中的Compile就是这样。此时CMake会根据平台自动选择合适的编译器。在Linux的平台上，CMake会选择g++, make等工具。而在Windows平台上， CMake大概率是不知道你安装了MinGW的，它会选择微软著名的编译器Visual Studio进行编译，还会顺带生成一个Visual Studio解决方案方便你调试。不过我既然都生成Visual Studio的C++工程了，直接用Visual Studio开发不是更香吗（笑）。\n\n至此已经可以进行编译。\n\n### launch.json配置--gdb断点调试项目\n\n新建launch.json:\n\n~~~json\n{\n    // Use IntelliSense to learn about possible attributes.\n    // Hover to view descriptions of existing attributes.\n    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch Debug\", //名称\n            \"type\": \"cppdbg\", //调试类型，除使用msvc进行调试外，均为该类型\n            \"request\": \"launch\",\n            \"program\": \"${workspaceFolder}/build/${workspaceFolderBasename}\", //指定C/C++程序位置\n            \"args\": [], //指定运行参数\n            \"stopAtEntry\": false,\n            \"cwd\": \"${workspaceFolder}/build\", //指定工作目录\n            \"preLaunchTask\": \"CMake and Make\", //在调试前会先调用这个task编译构建程序\n            \"environment\": [],\n            \"externalConsole\": true,    \n            \"osx\": { //macOS的特定配置\n                // \"miDebuggerPath\": \"/Applications/Xcode.app/Contents/Developer/usr/bin/lldb-mi\", //修改使用的lldb-mi，一般不需要修改\n                \"MIMode\": \"lldb\" //指定使用lldb进行调试\n            },\n            \"linux\": { //linux的特定配置\n                \"MIMode\": \"gdb\", //指定使用gdb调试\n                \"setupCommands\": [\n                    {\n                        \"description\": \"Enable pretty-printing for gdb\",\n                        \"text\": \"-enable-pretty-printing\",\n                        \"ignoreFailures\": true\n                    }\n                ]\n            },\n            \"windows\": {\n                \"MIMode\": \"gdb\", //指定使用gdb调试\n                \"miDebuggerPath\": \"C:/mingw64/bin/gdb.exe\", //指定gdb的路径\n                \"setupCommands\": [\n                    {\n                        \"description\": \"Enable pretty-printing for gdb\",\n                        \"text\": \"-enable-pretty-printing\",\n                        \"ignoreFailures\": true\n                    }\n                ]\n            }\n        }\n    ]\n}\n~~~\n\n默认调试按键是`F5`。打上断点，按下`F5`，系统自动运行CMake and Make编译程序。会有点慢。\n\n注意：在CMakeLists.txt中有三句话：\n\n`SET(CMAKE_BUILD_TYPE \"Debug\")`\n\n`SET(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -Wall -g2 -ggdb\")`\n\n`SET(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O3 -Wall\")`\n\n分别是：项目构建方式设置为调试模式（如果是Release则是发布模式）、调试时使用gdb、发布时使用3级优化（有0~3级）。\n\n至此可以进行调试。\n\n## tasks.json内容解释\n\n待更新。\n\n## 更进一步\n\n手动配置文件虽然自由度高，但是还是挺麻烦。VSCode给我自动推荐了一个CMake插件叫做CMake Tools，好像也挺好用的，不知道后续能不能用插件一键生成多文件项目。\n\nTasks中的功能有点多了。之后尝试简化，方便使用。\n\ngdb调试有个问题，就是长时间挂在一边不动，或者在监视窗口贸然输入一个变量进行监视时就有可能突然停止调试，错误信息闪了一下就消失了。稳定性还不行，原因未知。\n\n这些配置还没有在Linux平台上尝试，可能需要进一步的测试和完善。\n\n## 参考资料\n\n[使用VSCode和CMake构建跨平台的C/C++开发环境](https://www.cnblogs.com/iwiniwin/p/13705456.html)\n\n[cmake gdb 编译调试详解](https://zhuanlan.zhihu.com/p/410219342)","source":"_posts/cpp-multi-file.md","raw":"---\ntitle: 使用VSCode进行c++/c多文件开发\ndate: 2022-09-02 20:51:41\ntags:\n---\n## 前言\nvscode是个非常优秀的跨平台编辑器，尤其在Linux上更为常用。在vscode上进行c++语言的编译、运行和调试已经有了很多教程，但是使用vscode进行多文件的c++编译、调试的教程却相对难找。以下整理出一个在VScode上搭建C++/C开发环境的全过程。\n## 原理\n在Linux上进行c++的多文件编译，主要依靠的是GNU的Makefile，使用make命令进行编译。而makefile的可读性差、语法复杂、跨平台性差等问题又催生了可以在多平台运行、语法简洁的CMake，用来自动生成Makefile。\n\nCMake是一个语法简单的跨平台编译工具。只要编写CMakeLists.txt文件，然后使用cmake命令，就可以根据不同的平台生成合适的Makefile文件，再利用make命令即可编译文件。\n\n问题是，Makefile是Linux的编译工具，怎么在Windows平台上使用呢？毫无疑问可以使用WSL，在Linux子系统中进行c++项目开发。\n\n但是在Windows上使用Makefile也不是没有可能，只要安装GNU在Windows上的移植版——mingw就行了。MinGW中的mingw64-make即为Linux中的make。\n## 实操\n### 前置工作\n没下载MinGW就去下一个。用处很多。\n\n然后下载CMake。\n\nLinux: `sudo apt-get install make`\n\nWindows: 上官网下最新版。\n\n### 配置CMakeLists.txt\n首先将文件夹设置为项目名称。\n\n然后在项目文件夹下添加CMakeLists.txt:\n\n~~~CMake\n# CMakeLists.txt\n# cmake最低版本号要求\ncmake_minimum_required (VERSION 3.0)\n# # 设置指定的C++编译器版本是必须的，如果不设置，或者为OFF，则指定版本不可用时，会使用上一版本。\n# set(CMAKE_CXX_STANDARD_REQUIRED ON)\n# # 指定为C++03 版本\n# set(CMAKE_CXX_STANDARD 03)\n\n# 设置gdb为调试工具\n# 构建模式设置为Debug\nSET(CMAKE_BUILD_TYPE \"Debug\")\n# 调试时使用gdb\nSET(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -Wall -g2 -ggdb\")\n# 发布时使用优化(1~3)\nSET(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O3 -Wall\")\n\n# 获取当前文件夹名称\nstring(REGEX REPLACE \".*/\\(.*\\)\" \"\\\\1\" CURDIR ${CMAKE_CURRENT_SOURCE_DIR})\n# 设置PROJECT_NAME变量\nset(PROJECT_NAME ${CURDIR})\n# 设置工程名\nproject (${PROJECT_NAME})\n# 查找./src目录下的所有源文件并存入DIR_SRCS变量\naux_source_directory(src DIR_SRCS)\n# 添加一个可编译的目标到工程\nadd_executable (${PROJECT_NAME} ${DIR_SRCS})\n# 从./include中添加静态库, 必须写在add_executable之后\ntarget_include_directories(${PROJECT_NAME} PUBLIC ./include)\nmessage(\"PROJECT_NAME: ${PROJECT_NAME}\")\nmessage(\"CMAKE_SOURCE_DIR: ${CMAKE_SOURCE_DIR}\")\nmessage(\"PROJECT_SOURCE_DIR: ${PROJECT_SOURCE_DIR}\")\n~~~\n\n从上面的配置中可以分析出：源文件应该写在`./src`文件夹下，而头文件应该写在`./include`文件夹下。也可以改成其他目录。\n\n代码什么意思在注释中写得很明白了，想要实现更多功能，可以上网查找CMake教程。\n\n### tasks.json配置--CMake构建，Makefile编译\n在/.vscode下添加tasks.json:\n~~~json\n{\n    \"tasks\": [\n        {\n            \"label\": \"CMake\",\n            \"detail\": \"运行CMake\",\n            \"type\": \"shell\",\n            \"command\": \"CMake\",\n            \"args\": [\n            \"-G \\\"MinGW Makefiles\\\"\",   //这个参数指定CMake在mingw下使用makefile进行构建，如果去掉则使用默认的vs进行构建\n                \"..\",\n            ],\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"echo\": true,\n                \"reveal\": \"always\",\n                \"focus\": false,\n                \"panel\": \"shared\",\n                \"showReuseMessage\": true,\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\",\n            \"dependsOn\": [\n                \"MkBuild\"\n            ]\n        },\n\n        {\n            \"label\": \"MkBuild\",\n            \"detail\": \"建立build文件夹\",\n            \"type\": \"shell\",\n            \"command\": \"mkdir\",\n            \"args\": [\n                \"-p\",\n                \"build\"\n            ],\n            \"windows\": {\n                \"args\": [\n                    \"-Force\",\n                    \"build\"\n                ]\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"echo\": true,\n                \"reveal\": \"always\",\n                \"focus\": false,\n                \"panel\": \"shared\",\n                \"showReuseMessage\": true,\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\"\n        },\n        \n        {\n            \"label\": \"Make\",\n            \"detail\": \"使用Makefile编译\",\n            \"type\": \"shell\",\n            \"command\": \"mingw32-make\",\n            \"args\": [\n            ],\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"reveal\": \"always\",\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\",\n        },\n\n        {\n            \"label\": \"Compile\",\n            \"detail\": \"仅编译。使用CMake --build编译，根据操作系统选择合适的编译器\",\n            \"type\": \"shell\",\n            \"command\": \"CMake --build .\",\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"group\": \"build\",\n            \"presentation\": {\n                \"reveal\": \"always\",\n                \"clear\": true\n            },\n            \"problemMatcher\": \"$msCompile\",\n        },\n\n        {\n            \"label\": \"Run\",\n            \"detail\": \"编译并运行程序\",\n            \"type\": \"shell\",\n            \"command\": \"start\",\n            \"args\": [\n                \"./${workspaceFolderBasename}.exe\"\n            ],\n            \"group\": \"build\",\n            \"presentation\": {\n                \"echo\": true,\n                \"reveal\": \"always\",\n                \"focus\": false,\n                \"panel\": \"shared\",\n                \"showReuseMessage\": true,\n                \"clear\": true\n            },\n            \"options\": {\n                \"cwd\": \"build\"\n            },\n            \"windows\": {\n                \"options\": {\n                    \"cwd\": \"build\"  //exe文件所在的目录\n                }\n            },\n            \"problemMatcher\": \"$msCompile\",\n            \"dependsOn\": [\n                \"Compile\"\n            ]\n        },\n        {\n            \"label\": \"CMake and Run\",\n            \"detail\": \"创建Makefile, 编译并运行程序\",\n            \"type\": \"shell\",\n            \"group\": \"build\",\n            \"dependsOn\": [\n                \"CMake\",\n                \"Run\"\n            ],\n            \"dependsOrder\": \"sequence\"\n        },\n        {\n            \"label\": \"CMake and Make\",\n            \"detail\": \"创建Makefile, 并编译\",\n            \"type\": \"shell\",\n            \"group\": \"build\",\n            \"dependsOn\": [\n                \"CMake\",\n                \"Make\"\n            ],\n            \"dependsOrder\": \"sequence\"\n        },\n    ],\n    \"version\": \"2.0.0\"\n}\n~~~\n这里面定义了一大堆Task，有的是编译并运行，有的是仅编译，有的是仅调用cmake，有的是调用CMake和make，使用时按下`Ctrl + Shift + B`选择合适的task, 看下中文解释就行。\n\n唯一需要解释的一个Task就是MkBuild。MkBuild实际上就是执行`mkdir -p build`。会创建一个叫做build的文件夹。项目的中间文件和最后的可执行文件都会生成在这个文件夹里。后面调试时的文件路径也依赖于build文件夹。\n\n推荐使用CMake and Make进行编译，使用Run进行运行。可以设置task的快捷键，参考网上资料。\n\n注意：按照CMake在原理中的描述，它仅仅是作为生成Makefile文件的工具使用，但是如果运行`cmake . --build`，CMake就可以不依赖Makefile，自己寻找合适的编译器进行编译。Tasks中的Compile就是这样。此时CMake会根据平台自动选择合适的编译器。在Linux的平台上，CMake会选择g++, make等工具。而在Windows平台上， CMake大概率是不知道你安装了MinGW的，它会选择微软著名的编译器Visual Studio进行编译，还会顺带生成一个Visual Studio解决方案方便你调试。不过我既然都生成Visual Studio的C++工程了，直接用Visual Studio开发不是更香吗（笑）。\n\n至此已经可以进行编译。\n\n### launch.json配置--gdb断点调试项目\n\n新建launch.json:\n\n~~~json\n{\n    // Use IntelliSense to learn about possible attributes.\n    // Hover to view descriptions of existing attributes.\n    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch Debug\", //名称\n            \"type\": \"cppdbg\", //调试类型，除使用msvc进行调试外，均为该类型\n            \"request\": \"launch\",\n            \"program\": \"${workspaceFolder}/build/${workspaceFolderBasename}\", //指定C/C++程序位置\n            \"args\": [], //指定运行参数\n            \"stopAtEntry\": false,\n            \"cwd\": \"${workspaceFolder}/build\", //指定工作目录\n            \"preLaunchTask\": \"CMake and Make\", //在调试前会先调用这个task编译构建程序\n            \"environment\": [],\n            \"externalConsole\": true,    \n            \"osx\": { //macOS的特定配置\n                // \"miDebuggerPath\": \"/Applications/Xcode.app/Contents/Developer/usr/bin/lldb-mi\", //修改使用的lldb-mi，一般不需要修改\n                \"MIMode\": \"lldb\" //指定使用lldb进行调试\n            },\n            \"linux\": { //linux的特定配置\n                \"MIMode\": \"gdb\", //指定使用gdb调试\n                \"setupCommands\": [\n                    {\n                        \"description\": \"Enable pretty-printing for gdb\",\n                        \"text\": \"-enable-pretty-printing\",\n                        \"ignoreFailures\": true\n                    }\n                ]\n            },\n            \"windows\": {\n                \"MIMode\": \"gdb\", //指定使用gdb调试\n                \"miDebuggerPath\": \"C:/mingw64/bin/gdb.exe\", //指定gdb的路径\n                \"setupCommands\": [\n                    {\n                        \"description\": \"Enable pretty-printing for gdb\",\n                        \"text\": \"-enable-pretty-printing\",\n                        \"ignoreFailures\": true\n                    }\n                ]\n            }\n        }\n    ]\n}\n~~~\n\n默认调试按键是`F5`。打上断点，按下`F5`，系统自动运行CMake and Make编译程序。会有点慢。\n\n注意：在CMakeLists.txt中有三句话：\n\n`SET(CMAKE_BUILD_TYPE \"Debug\")`\n\n`SET(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -Wall -g2 -ggdb\")`\n\n`SET(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O3 -Wall\")`\n\n分别是：项目构建方式设置为调试模式（如果是Release则是发布模式）、调试时使用gdb、发布时使用3级优化（有0~3级）。\n\n至此可以进行调试。\n\n## tasks.json内容解释\n\n待更新。\n\n## 更进一步\n\n手动配置文件虽然自由度高，但是还是挺麻烦。VSCode给我自动推荐了一个CMake插件叫做CMake Tools，好像也挺好用的，不知道后续能不能用插件一键生成多文件项目。\n\nTasks中的功能有点多了。之后尝试简化，方便使用。\n\ngdb调试有个问题，就是长时间挂在一边不动，或者在监视窗口贸然输入一个变量进行监视时就有可能突然停止调试，错误信息闪了一下就消失了。稳定性还不行，原因未知。\n\n这些配置还没有在Linux平台上尝试，可能需要进一步的测试和完善。\n\n## 参考资料\n\n[使用VSCode和CMake构建跨平台的C/C++开发环境](https://www.cnblogs.com/iwiniwin/p/13705456.html)\n\n[cmake gdb 编译调试详解](https://zhuanlan.zhihu.com/p/410219342)","slug":"cpp-multi-file","published":1,"updated":"2024-03-19T06:01:16.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhz000mrsugbrsbe9n5","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>vscode是个非常优秀的跨平台编辑器，尤其在Linux上更为常用。在vscode上进行c++语言的编译、运行和调试已经有了很多教程，但是使用vscode进行多文件的c++编译、调试的教程却相对难找。以下整理出一个在VScode上搭建C++&#x2F;C开发环境的全过程。</p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>在Linux上进行c++的多文件编译，主要依靠的是GNU的Makefile，使用make命令进行编译。而makefile的可读性差、语法复杂、跨平台性差等问题又催生了可以在多平台运行、语法简洁的CMake，用来自动生成Makefile。</p>\n<p>CMake是一个语法简单的跨平台编译工具。只要编写CMakeLists.txt文件，然后使用cmake命令，就可以根据不同的平台生成合适的Makefile文件，再利用make命令即可编译文件。</p>\n<p>问题是，Makefile是Linux的编译工具，怎么在Windows平台上使用呢？毫无疑问可以使用WSL，在Linux子系统中进行c++项目开发。</p>\n<p>但是在Windows上使用Makefile也不是没有可能，只要安装GNU在Windows上的移植版——mingw就行了。MinGW中的mingw64-make即为Linux中的make。</p>\n<h2 id=\"实操\"><a href=\"#实操\" class=\"headerlink\" title=\"实操\"></a>实操</h2><h3 id=\"前置工作\"><a href=\"#前置工作\" class=\"headerlink\" title=\"前置工作\"></a>前置工作</h3><p>没下载MinGW就去下一个。用处很多。</p>\n<p>然后下载CMake。</p>\n<p>Linux: <code>sudo apt-get install make</code></p>\n<p>Windows: 上官网下最新版。</p>\n<h3 id=\"配置CMakeLists-txt\"><a href=\"#配置CMakeLists-txt\" class=\"headerlink\" title=\"配置CMakeLists.txt\"></a>配置CMakeLists.txt</h3><p>首先将文件夹设置为项目名称。</p>\n<p>然后在项目文件夹下添加CMakeLists.txt:</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"comment\"># cmake最低版本号要求</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span> (VERSION <span class=\"number\">3.0</span>)</span><br><span class=\"line\"><span class=\"comment\"># # 设置指定的C++编译器版本是必须的，如果不设置，或者为OFF，则指定版本不可用时，会使用上一版本。</span></span><br><span class=\"line\"><span class=\"comment\"># set(CMAKE_CXX_STANDARD_REQUIRED ON)</span></span><br><span class=\"line\"><span class=\"comment\"># # 指定为C++03 版本</span></span><br><span class=\"line\"><span class=\"comment\"># set(CMAKE_CXX_STANDARD 03)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置gdb为调试工具</span></span><br><span class=\"line\"><span class=\"comment\"># 构建模式设置为Debug</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_BUILD_TYPE <span class=\"string\">&quot;Debug&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 调试时使用gdb</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_CXX_FLAGS_DEBUG <span class=\"string\">&quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g2 -ggdb&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 发布时使用优化(1~3)</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_CXX_FLAGS_RELEASE <span class=\"string\">&quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取当前文件夹名称</span></span><br><span class=\"line\"><span class=\"keyword\">string</span>(REGEX REPLACE <span class=\"string\">&quot;.*/\\(.*\\)&quot;</span> <span class=\"string\">&quot;\\\\1&quot;</span> CURDIR <span class=\"variable\">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 设置PROJECT_NAME变量</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(PROJECT_NAME <span class=\"variable\">$&#123;CURDIR&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 设置工程名</span></span><br><span class=\"line\"><span class=\"keyword\">project</span> (<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 查找./src目录下的所有源文件并存入DIR_SRCS变量</span></span><br><span class=\"line\"><span class=\"keyword\">aux_source_directory</span>(src DIR_SRCS)</span><br><span class=\"line\"><span class=\"comment\"># 添加一个可编译的目标到工程</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span> (<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> <span class=\"variable\">$&#123;DIR_SRCS&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 从./include中添加静态库, 必须写在add_executable之后</span></span><br><span class=\"line\"><span class=\"keyword\">target_include_directories</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> PUBLIC ./<span class=\"keyword\">include</span>)</span><br><span class=\"line\"><span class=\"keyword\">message</span>(<span class=\"string\">&quot;PROJECT_NAME: $&#123;PROJECT_NAME&#125;&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">message</span>(<span class=\"string\">&quot;CMAKE_SOURCE_DIR: $&#123;CMAKE_SOURCE_DIR&#125;&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">message</span>(<span class=\"string\">&quot;PROJECT_SOURCE_DIR: $&#123;PROJECT_SOURCE_DIR&#125;&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>从上面的配置中可以分析出：源文件应该写在<code>./src</code>文件夹下，而头文件应该写在<code>./include</code>文件夹下。也可以改成其他目录。</p>\n<p>代码什么意思在注释中写得很明白了，想要实现更多功能，可以上网查找CMake教程。</p>\n<h3 id=\"tasks-json配置–CMake构建，Makefile编译\"><a href=\"#tasks-json配置–CMake构建，Makefile编译\" class=\"headerlink\" title=\"tasks.json配置–CMake构建，Makefile编译\"></a>tasks.json配置–CMake构建，Makefile编译</h3><p>在&#x2F;.vscode下添加tasks.json:</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;tasks&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;运行CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"string\">&quot;-G \\&quot;MinGW Makefiles\\&quot;&quot;</span><span class=\"punctuation\">,</span>   <span class=\"comment\">//这个参数指定CMake在mingw下使用makefile进行构建，如果去掉则使用默认的vs进行构建</span></span><br><span class=\"line\">                <span class=\"string\">&quot;..&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;echo&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;focus&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;panel&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shared&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;showReuseMessage&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;MkBuild&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;MkBuild&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;建立build文件夹&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;mkdir&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;-p&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;windows&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                    <span class=\"string\">&quot;-Force&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                    <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">                <span class=\"punctuation\">]</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;echo&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;focus&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;panel&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shared&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;showReuseMessage&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Make&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;使用Makefile编译&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;mingw32-make&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Compile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;仅编译。使用CMake --build编译，根据操作系统选择合适的编译器&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake --build .&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Run&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;编译并运行程序&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;start&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;./$&#123;workspaceFolderBasename&#125;.exe&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;echo&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;focus&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;panel&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shared&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;showReuseMessage&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;windows&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                    <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span>  <span class=\"comment\">//exe文件所在的目录</span></span><br><span class=\"line\">                <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;Compile&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake and Run&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;创建Makefile, 编译并运行程序&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"string\">&quot;Run&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOrder&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;sequence&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake and Make&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;创建Makefile, 并编译&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"string\">&quot;Make&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOrder&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;sequence&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2.0.0&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n<p>这里面定义了一大堆Task，有的是编译并运行，有的是仅编译，有的是仅调用cmake，有的是调用CMake和make，使用时按下<code>Ctrl + Shift + B</code>选择合适的task, 看下中文解释就行。</p>\n<p>唯一需要解释的一个Task就是MkBuild。MkBuild实际上就是执行<code>mkdir -p build</code>。会创建一个叫做build的文件夹。项目的中间文件和最后的可执行文件都会生成在这个文件夹里。后面调试时的文件路径也依赖于build文件夹。</p>\n<p>推荐使用CMake and Make进行编译，使用Run进行运行。可以设置task的快捷键，参考网上资料。</p>\n<p>注意：按照CMake在原理中的描述，它仅仅是作为生成Makefile文件的工具使用，但是如果运行<code>cmake . --build</code>，CMake就可以不依赖Makefile，自己寻找合适的编译器进行编译。Tasks中的Compile就是这样。此时CMake会根据平台自动选择合适的编译器。在Linux的平台上，CMake会选择g++, make等工具。而在Windows平台上， CMake大概率是不知道你安装了MinGW的，它会选择微软著名的编译器Visual Studio进行编译，还会顺带生成一个Visual Studio解决方案方便你调试。不过我既然都生成Visual Studio的C++工程了，直接用Visual Studio开发不是更香吗（笑）。</p>\n<p>至此已经可以进行编译。</p>\n<h3 id=\"launch-json配置–gdb断点调试项目\"><a href=\"#launch-json配置–gdb断点调试项目\" class=\"headerlink\" title=\"launch.json配置–gdb断点调试项目\"></a>launch.json配置–gdb断点调试项目</h3><p>新建launch.json:</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// Use IntelliSense to learn about possible attributes.</span></span><br><span class=\"line\">    <span class=\"comment\">// Hover to view descriptions of existing attributes.</span></span><br><span class=\"line\">    <span class=\"comment\">// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;0.2.0&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;configurations&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Launch Debug&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//名称</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;cppdbg&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//调试类型，除使用msvc进行调试外，均为该类型</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;request&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;launch&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;program&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$&#123;workspaceFolder&#125;/build/$&#123;workspaceFolderBasename&#125;&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定C/C++程序位置</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定运行参数</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;stopAtEntry&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$&#123;workspaceFolder&#125;/build&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定工作目录</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;preLaunchTask&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake and Make&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//在调试前会先调用这个task编译构建程序</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;environment&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;externalConsole&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span>    </span><br><span class=\"line\">            <span class=\"attr\">&quot;osx&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span> <span class=\"comment\">//macOS的特定配置</span></span><br><span class=\"line\">                <span class=\"comment\">// &quot;miDebuggerPath&quot;: &quot;/Applications/Xcode.app/Contents/Developer/usr/bin/lldb-mi&quot;, //修改使用的lldb-mi，一般不需要修改</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;MIMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;lldb&quot;</span> <span class=\"comment\">//指定使用lldb进行调试</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;linux&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span> <span class=\"comment\">//linux的特定配置</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;MIMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;gdb&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定使用gdb调试</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;setupCommands&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Enable pretty-printing for gdb&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;text&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;-enable-pretty-printing&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;ignoreFailures&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">                <span class=\"punctuation\">]</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;windows&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;MIMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;gdb&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定使用gdb调试</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;miDebuggerPath&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;C:/mingw64/bin/gdb.exe&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定gdb的路径</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;setupCommands&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Enable pretty-printing for gdb&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;text&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;-enable-pretty-printing&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;ignoreFailures&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">                <span class=\"punctuation\">]</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>默认调试按键是<code>F5</code>。打上断点，按下<code>F5</code>，系统自动运行CMake and Make编译程序。会有点慢。</p>\n<p>注意：在CMakeLists.txt中有三句话：</p>\n<p><code>SET(CMAKE_BUILD_TYPE &quot;Debug&quot;)</code></p>\n<p><code>SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g2 -ggdb&quot;)</code></p>\n<p><code>SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</code></p>\n<p>分别是：项目构建方式设置为调试模式（如果是Release则是发布模式）、调试时使用gdb、发布时使用3级优化（有0~3级）。</p>\n<p>至此可以进行调试。</p>\n<h2 id=\"tasks-json内容解释\"><a href=\"#tasks-json内容解释\" class=\"headerlink\" title=\"tasks.json内容解释\"></a>tasks.json内容解释</h2><p>待更新。</p>\n<h2 id=\"更进一步\"><a href=\"#更进一步\" class=\"headerlink\" title=\"更进一步\"></a>更进一步</h2><p>手动配置文件虽然自由度高，但是还是挺麻烦。VSCode给我自动推荐了一个CMake插件叫做CMake Tools，好像也挺好用的，不知道后续能不能用插件一键生成多文件项目。</p>\n<p>Tasks中的功能有点多了。之后尝试简化，方便使用。</p>\n<p>gdb调试有个问题，就是长时间挂在一边不动，或者在监视窗口贸然输入一个变量进行监视时就有可能突然停止调试，错误信息闪了一下就消失了。稳定性还不行，原因未知。</p>\n<p>这些配置还没有在Linux平台上尝试，可能需要进一步的测试和完善。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://www.cnblogs.com/iwiniwin/p/13705456.html\">使用VSCode和CMake构建跨平台的C&#x2F;C++开发环境</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/410219342\">cmake gdb 编译调试详解</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>vscode是个非常优秀的跨平台编辑器，尤其在Linux上更为常用。在vscode上进行c++语言的编译、运行和调试已经有了很多教程，但是使用vscode进行多文件的c++编译、调试的教程却相对难找。以下整理出一个在VScode上搭建C++&#x2F;C开发环境的全过程。</p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>在Linux上进行c++的多文件编译，主要依靠的是GNU的Makefile，使用make命令进行编译。而makefile的可读性差、语法复杂、跨平台性差等问题又催生了可以在多平台运行、语法简洁的CMake，用来自动生成Makefile。</p>\n<p>CMake是一个语法简单的跨平台编译工具。只要编写CMakeLists.txt文件，然后使用cmake命令，就可以根据不同的平台生成合适的Makefile文件，再利用make命令即可编译文件。</p>\n<p>问题是，Makefile是Linux的编译工具，怎么在Windows平台上使用呢？毫无疑问可以使用WSL，在Linux子系统中进行c++项目开发。</p>\n<p>但是在Windows上使用Makefile也不是没有可能，只要安装GNU在Windows上的移植版——mingw就行了。MinGW中的mingw64-make即为Linux中的make。</p>\n<h2 id=\"实操\"><a href=\"#实操\" class=\"headerlink\" title=\"实操\"></a>实操</h2><h3 id=\"前置工作\"><a href=\"#前置工作\" class=\"headerlink\" title=\"前置工作\"></a>前置工作</h3><p>没下载MinGW就去下一个。用处很多。</p>\n<p>然后下载CMake。</p>\n<p>Linux: <code>sudo apt-get install make</code></p>\n<p>Windows: 上官网下最新版。</p>\n<h3 id=\"配置CMakeLists-txt\"><a href=\"#配置CMakeLists-txt\" class=\"headerlink\" title=\"配置CMakeLists.txt\"></a>配置CMakeLists.txt</h3><p>首先将文件夹设置为项目名称。</p>\n<p>然后在项目文件夹下添加CMakeLists.txt:</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CMakeLists.txt</span></span><br><span class=\"line\"><span class=\"comment\"># cmake最低版本号要求</span></span><br><span class=\"line\"><span class=\"keyword\">cmake_minimum_required</span> (VERSION <span class=\"number\">3.0</span>)</span><br><span class=\"line\"><span class=\"comment\"># # 设置指定的C++编译器版本是必须的，如果不设置，或者为OFF，则指定版本不可用时，会使用上一版本。</span></span><br><span class=\"line\"><span class=\"comment\"># set(CMAKE_CXX_STANDARD_REQUIRED ON)</span></span><br><span class=\"line\"><span class=\"comment\"># # 指定为C++03 版本</span></span><br><span class=\"line\"><span class=\"comment\"># set(CMAKE_CXX_STANDARD 03)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置gdb为调试工具</span></span><br><span class=\"line\"><span class=\"comment\"># 构建模式设置为Debug</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_BUILD_TYPE <span class=\"string\">&quot;Debug&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 调试时使用gdb</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_CXX_FLAGS_DEBUG <span class=\"string\">&quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g2 -ggdb&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 发布时使用优化(1~3)</span></span><br><span class=\"line\"><span class=\"keyword\">SET</span>(CMAKE_CXX_FLAGS_RELEASE <span class=\"string\">&quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取当前文件夹名称</span></span><br><span class=\"line\"><span class=\"keyword\">string</span>(REGEX REPLACE <span class=\"string\">&quot;.*/\\(.*\\)&quot;</span> <span class=\"string\">&quot;\\\\1&quot;</span> CURDIR <span class=\"variable\">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 设置PROJECT_NAME变量</span></span><br><span class=\"line\"><span class=\"keyword\">set</span>(PROJECT_NAME <span class=\"variable\">$&#123;CURDIR&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 设置工程名</span></span><br><span class=\"line\"><span class=\"keyword\">project</span> (<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 查找./src目录下的所有源文件并存入DIR_SRCS变量</span></span><br><span class=\"line\"><span class=\"keyword\">aux_source_directory</span>(src DIR_SRCS)</span><br><span class=\"line\"><span class=\"comment\"># 添加一个可编译的目标到工程</span></span><br><span class=\"line\"><span class=\"keyword\">add_executable</span> (<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> <span class=\"variable\">$&#123;DIR_SRCS&#125;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 从./include中添加静态库, 必须写在add_executable之后</span></span><br><span class=\"line\"><span class=\"keyword\">target_include_directories</span>(<span class=\"variable\">$&#123;PROJECT_NAME&#125;</span> PUBLIC ./<span class=\"keyword\">include</span>)</span><br><span class=\"line\"><span class=\"keyword\">message</span>(<span class=\"string\">&quot;PROJECT_NAME: $&#123;PROJECT_NAME&#125;&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">message</span>(<span class=\"string\">&quot;CMAKE_SOURCE_DIR: $&#123;CMAKE_SOURCE_DIR&#125;&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">message</span>(<span class=\"string\">&quot;PROJECT_SOURCE_DIR: $&#123;PROJECT_SOURCE_DIR&#125;&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>从上面的配置中可以分析出：源文件应该写在<code>./src</code>文件夹下，而头文件应该写在<code>./include</code>文件夹下。也可以改成其他目录。</p>\n<p>代码什么意思在注释中写得很明白了，想要实现更多功能，可以上网查找CMake教程。</p>\n<h3 id=\"tasks-json配置–CMake构建，Makefile编译\"><a href=\"#tasks-json配置–CMake构建，Makefile编译\" class=\"headerlink\" title=\"tasks.json配置–CMake构建，Makefile编译\"></a>tasks.json配置–CMake构建，Makefile编译</h3><p>在&#x2F;.vscode下添加tasks.json:</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;tasks&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;运行CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"string\">&quot;-G \\&quot;MinGW Makefiles\\&quot;&quot;</span><span class=\"punctuation\">,</span>   <span class=\"comment\">//这个参数指定CMake在mingw下使用makefile进行构建，如果去掉则使用默认的vs进行构建</span></span><br><span class=\"line\">                <span class=\"string\">&quot;..&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;echo&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;focus&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;panel&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shared&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;showReuseMessage&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;MkBuild&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;MkBuild&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;建立build文件夹&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;mkdir&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;-p&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;windows&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                    <span class=\"string\">&quot;-Force&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                    <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">                <span class=\"punctuation\">]</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;echo&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;focus&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;panel&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shared&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;showReuseMessage&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Make&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;使用Makefile编译&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;mingw32-make&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Compile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;仅编译。使用CMake --build编译，根据操作系统选择合适的编译器&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake --build .&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Run&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;编译并运行程序&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;command&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;start&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;./$&#123;workspaceFolderBasename&#125;.exe&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;presentation&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;echo&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;reveal&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;always&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;focus&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;panel&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shared&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;showReuseMessage&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;clear&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;windows&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;options&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                    <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span>  <span class=\"comment\">//exe文件所在的目录</span></span><br><span class=\"line\">                <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;problemMatcher&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$msCompile&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;Compile&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake and Run&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;创建Makefile, 编译并运行程序&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"string\">&quot;Run&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOrder&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;sequence&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;label&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake and Make&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;detail&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;创建Makefile, 并编译&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;shell&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;group&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;build&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOn&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                <span class=\"string\">&quot;CMake&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                <span class=\"string\">&quot;Make&quot;</span></span><br><span class=\"line\">            <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;dependsOrder&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;sequence&quot;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;2.0.0&quot;</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n<p>这里面定义了一大堆Task，有的是编译并运行，有的是仅编译，有的是仅调用cmake，有的是调用CMake和make，使用时按下<code>Ctrl + Shift + B</code>选择合适的task, 看下中文解释就行。</p>\n<p>唯一需要解释的一个Task就是MkBuild。MkBuild实际上就是执行<code>mkdir -p build</code>。会创建一个叫做build的文件夹。项目的中间文件和最后的可执行文件都会生成在这个文件夹里。后面调试时的文件路径也依赖于build文件夹。</p>\n<p>推荐使用CMake and Make进行编译，使用Run进行运行。可以设置task的快捷键，参考网上资料。</p>\n<p>注意：按照CMake在原理中的描述，它仅仅是作为生成Makefile文件的工具使用，但是如果运行<code>cmake . --build</code>，CMake就可以不依赖Makefile，自己寻找合适的编译器进行编译。Tasks中的Compile就是这样。此时CMake会根据平台自动选择合适的编译器。在Linux的平台上，CMake会选择g++, make等工具。而在Windows平台上， CMake大概率是不知道你安装了MinGW的，它会选择微软著名的编译器Visual Studio进行编译，还会顺带生成一个Visual Studio解决方案方便你调试。不过我既然都生成Visual Studio的C++工程了，直接用Visual Studio开发不是更香吗（笑）。</p>\n<p>至此已经可以进行编译。</p>\n<h3 id=\"launch-json配置–gdb断点调试项目\"><a href=\"#launch-json配置–gdb断点调试项目\" class=\"headerlink\" title=\"launch.json配置–gdb断点调试项目\"></a>launch.json配置–gdb断点调试项目</h3><p>新建launch.json:</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">    <span class=\"comment\">// Use IntelliSense to learn about possible attributes.</span></span><br><span class=\"line\">    <span class=\"comment\">// Hover to view descriptions of existing attributes.</span></span><br><span class=\"line\">    <span class=\"comment\">// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;0.2.0&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">    <span class=\"attr\">&quot;configurations&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;name&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Launch Debug&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//名称</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;type&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;cppdbg&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//调试类型，除使用msvc进行调试外，均为该类型</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;request&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;launch&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;program&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$&#123;workspaceFolder&#125;/build/$&#123;workspaceFolderBasename&#125;&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定C/C++程序位置</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;args&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定运行参数</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;stopAtEntry&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">false</span></span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;cwd&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;$&#123;workspaceFolder&#125;/build&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定工作目录</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;preLaunchTask&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;CMake and Make&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//在调试前会先调用这个task编译构建程序</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;environment&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;externalConsole&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span><span class=\"punctuation\">,</span>    </span><br><span class=\"line\">            <span class=\"attr\">&quot;osx&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span> <span class=\"comment\">//macOS的特定配置</span></span><br><span class=\"line\">                <span class=\"comment\">// &quot;miDebuggerPath&quot;: &quot;/Applications/Xcode.app/Contents/Developer/usr/bin/lldb-mi&quot;, //修改使用的lldb-mi，一般不需要修改</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;MIMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;lldb&quot;</span> <span class=\"comment\">//指定使用lldb进行调试</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;linux&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span> <span class=\"comment\">//linux的特定配置</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;MIMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;gdb&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定使用gdb调试</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;setupCommands&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Enable pretty-printing for gdb&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;text&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;-enable-pretty-printing&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;ignoreFailures&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">                <span class=\"punctuation\">]</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">            <span class=\"attr\">&quot;windows&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;MIMode&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;gdb&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定使用gdb调试</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;miDebuggerPath&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;C:/mingw64/bin/gdb.exe&quot;</span><span class=\"punctuation\">,</span> <span class=\"comment\">//指定gdb的路径</span></span><br><span class=\"line\">                <span class=\"attr\">&quot;setupCommands&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#123;</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;description&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;Enable pretty-printing for gdb&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;text&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;-enable-pretty-printing&quot;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\">                        <span class=\"attr\">&quot;ignoreFailures&quot;</span><span class=\"punctuation\">:</span> <span class=\"literal\"><span class=\"keyword\">true</span></span></span><br><span class=\"line\">                    <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">                <span class=\"punctuation\">]</span></span><br><span class=\"line\">            <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">        <span class=\"punctuation\">&#125;</span></span><br><span class=\"line\">    <span class=\"punctuation\">]</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>默认调试按键是<code>F5</code>。打上断点，按下<code>F5</code>，系统自动运行CMake and Make编译程序。会有点慢。</p>\n<p>注意：在CMakeLists.txt中有三句话：</p>\n<p><code>SET(CMAKE_BUILD_TYPE &quot;Debug&quot;)</code></p>\n<p><code>SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g2 -ggdb&quot;)</code></p>\n<p><code>SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)</code></p>\n<p>分别是：项目构建方式设置为调试模式（如果是Release则是发布模式）、调试时使用gdb、发布时使用3级优化（有0~3级）。</p>\n<p>至此可以进行调试。</p>\n<h2 id=\"tasks-json内容解释\"><a href=\"#tasks-json内容解释\" class=\"headerlink\" title=\"tasks.json内容解释\"></a>tasks.json内容解释</h2><p>待更新。</p>\n<h2 id=\"更进一步\"><a href=\"#更进一步\" class=\"headerlink\" title=\"更进一步\"></a>更进一步</h2><p>手动配置文件虽然自由度高，但是还是挺麻烦。VSCode给我自动推荐了一个CMake插件叫做CMake Tools，好像也挺好用的，不知道后续能不能用插件一键生成多文件项目。</p>\n<p>Tasks中的功能有点多了。之后尝试简化，方便使用。</p>\n<p>gdb调试有个问题，就是长时间挂在一边不动，或者在监视窗口贸然输入一个变量进行监视时就有可能突然停止调试，错误信息闪了一下就消失了。稳定性还不行，原因未知。</p>\n<p>这些配置还没有在Linux平台上尝试，可能需要进一步的测试和完善。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://www.cnblogs.com/iwiniwin/p/13705456.html\">使用VSCode和CMake构建跨平台的C&#x2F;C++开发环境</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/410219342\">cmake gdb 编译调试详解</a></p>\n"},{"title":"github的一些命令","date":"2022-09-28T07:46:08.000Z","_content":"\n# 如何删除某些提交？\n\n## 删除最新的提交 \n`git reset --hard HEAD^`\n\n可以删除最新的一次提交。若要删除多次提交，可以在HEAD后多加几个^。\n\n## 删除/合并中间的某次提交\n`git rebase -i <commit_id>`\n\n填写要删除的提交的**之前**的那次提交的id。\n\n之后会打开一个vim界面，显示\n\n```bash\npick aaa\npick bbb\npick ccc\n# Rebase xxx onto xxx (xxx command)\n#\n# Commands:\n# p, pick <commit> = use commit\n# r, reword <commit> = use commit, but edit the commit message\n# e, edit <commit> = use commit, but stop for amending\n# s, squash <commit> = use commit, but meld into previous commit\n# f, fixup [-C | -c] <commit> = like \"squash\" but keep only the previous\n#                    commit's log message, unless -C is used, in which case\n#                    keep only this commit's message; -c is same as -C but\n#                    opens the editor\n# x, exec <command> = run command (the rest of the line) using shell\n# b, break = stop here (continue rebase later with 'git rebase --continue')\n# d, drop <commit> = remove commit\n# l, label <label> = label current HEAD with a name\n# t, reset <label> = reset HEAD to a label\n# m, merge [-C <commit> | -c <commit>] <label> [# <oneline>]\n# .       create a merge commit using the original merge commit's\n# .       message (or the oneline, if no original merge commit was\n# .       specified); use -c <commit> to reword the commit message\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n```\n\n根据提示，使用`drop`会弃用那次commit的修改，使用`squash`则会将修改融合至上一条commit。根据个人需要进行操作。\n\n## 同步到远程仓库\n\n上述都是针对本地提交。如果已经提交到github了怎么办？本地删除后直接`git push`会显示提交数低于远程仓库，不能执行。\n\n`git push origin HEAD --force`\n\n强制将当前所在的HEAD所在的提交push到远程仓库，并且使远程仓库的提交记录和本地保持同步。","source":"_posts/github-command.md","raw":"---\ntitle: github的一些命令\ndate: 2022-09-28 15:46:08\ntags:\n---\n\n# 如何删除某些提交？\n\n## 删除最新的提交 \n`git reset --hard HEAD^`\n\n可以删除最新的一次提交。若要删除多次提交，可以在HEAD后多加几个^。\n\n## 删除/合并中间的某次提交\n`git rebase -i <commit_id>`\n\n填写要删除的提交的**之前**的那次提交的id。\n\n之后会打开一个vim界面，显示\n\n```bash\npick aaa\npick bbb\npick ccc\n# Rebase xxx onto xxx (xxx command)\n#\n# Commands:\n# p, pick <commit> = use commit\n# r, reword <commit> = use commit, but edit the commit message\n# e, edit <commit> = use commit, but stop for amending\n# s, squash <commit> = use commit, but meld into previous commit\n# f, fixup [-C | -c] <commit> = like \"squash\" but keep only the previous\n#                    commit's log message, unless -C is used, in which case\n#                    keep only this commit's message; -c is same as -C but\n#                    opens the editor\n# x, exec <command> = run command (the rest of the line) using shell\n# b, break = stop here (continue rebase later with 'git rebase --continue')\n# d, drop <commit> = remove commit\n# l, label <label> = label current HEAD with a name\n# t, reset <label> = reset HEAD to a label\n# m, merge [-C <commit> | -c <commit>] <label> [# <oneline>]\n# .       create a merge commit using the original merge commit's\n# .       message (or the oneline, if no original merge commit was\n# .       specified); use -c <commit> to reword the commit message\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n```\n\n根据提示，使用`drop`会弃用那次commit的修改，使用`squash`则会将修改融合至上一条commit。根据个人需要进行操作。\n\n## 同步到远程仓库\n\n上述都是针对本地提交。如果已经提交到github了怎么办？本地删除后直接`git push`会显示提交数低于远程仓库，不能执行。\n\n`git push origin HEAD --force`\n\n强制将当前所在的HEAD所在的提交push到远程仓库，并且使远程仓库的提交记录和本地保持同步。","slug":"github-command","published":1,"updated":"2024-03-19T06:01:16.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhz000orsug2ii43qy1","content":"<h1 id=\"如何删除某些提交？\"><a href=\"#如何删除某些提交？\" class=\"headerlink\" title=\"如何删除某些提交？\"></a>如何删除某些提交？</h1><h2 id=\"删除最新的提交\"><a href=\"#删除最新的提交\" class=\"headerlink\" title=\"删除最新的提交\"></a>删除最新的提交</h2><p><code>git reset --hard HEAD^</code></p>\n<p>可以删除最新的一次提交。若要删除多次提交，可以在HEAD后多加几个^。</p>\n<h2 id=\"删除-x2F-合并中间的某次提交\"><a href=\"#删除-x2F-合并中间的某次提交\" class=\"headerlink\" title=\"删除&#x2F;合并中间的某次提交\"></a>删除&#x2F;合并中间的某次提交</h2><p><code>git rebase -i &lt;commit_id&gt;</code></p>\n<p>填写要删除的提交的<strong>之前</strong>的那次提交的id。</p>\n<p>之后会打开一个vim界面，显示</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pick aaa</span><br><span class=\"line\">pick bbb</span><br><span class=\"line\">pick ccc</span><br><span class=\"line\"><span class=\"comment\"># Rebase xxx onto xxx (xxx command)</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Commands:</span></span><br><span class=\"line\"><span class=\"comment\"># p, pick &lt;commit&gt; = use commit</span></span><br><span class=\"line\"><span class=\"comment\"># r, reword &lt;commit&gt; = use commit, but edit the commit message</span></span><br><span class=\"line\"><span class=\"comment\"># e, edit &lt;commit&gt; = use commit, but stop for amending</span></span><br><span class=\"line\"><span class=\"comment\"># s, squash &lt;commit&gt; = use commit, but meld into previous commit</span></span><br><span class=\"line\"><span class=\"comment\"># f, fixup [-C | -c] &lt;commit&gt; = like &quot;squash&quot; but keep only the previous</span></span><br><span class=\"line\"><span class=\"comment\">#                    commit&#x27;s log message, unless -C is used, in which case</span></span><br><span class=\"line\"><span class=\"comment\">#                    keep only this commit&#x27;s message; -c is same as -C but</span></span><br><span class=\"line\"><span class=\"comment\">#                    opens the editor</span></span><br><span class=\"line\"><span class=\"comment\"># x, exec &lt;command&gt; = run command (the rest of the line) using shell</span></span><br><span class=\"line\"><span class=\"comment\"># b, break = stop here (continue rebase later with &#x27;git rebase --continue&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># d, drop &lt;commit&gt; = remove commit</span></span><br><span class=\"line\"><span class=\"comment\"># l, label &lt;label&gt; = label current HEAD with a name</span></span><br><span class=\"line\"><span class=\"comment\"># t, reset &lt;label&gt; = reset HEAD to a label</span></span><br><span class=\"line\"><span class=\"comment\"># m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]</span></span><br><span class=\"line\"><span class=\"comment\"># .       create a merge commit using the original merge commit&#x27;s</span></span><br><span class=\"line\"><span class=\"comment\"># .       message (or the oneline, if no original merge commit was</span></span><br><span class=\"line\"><span class=\"comment\"># .       specified); use -c &lt;commit&gt; to reword the commit message</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># These lines can be re-ordered; they are executed from top to bottom.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># If you remove a line here THAT COMMIT WILL BE LOST.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># However, if you remove everything, the rebase will be aborted.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<p>根据提示，使用<code>drop</code>会弃用那次commit的修改，使用<code>squash</code>则会将修改融合至上一条commit。根据个人需要进行操作。</p>\n<h2 id=\"同步到远程仓库\"><a href=\"#同步到远程仓库\" class=\"headerlink\" title=\"同步到远程仓库\"></a>同步到远程仓库</h2><p>上述都是针对本地提交。如果已经提交到github了怎么办？本地删除后直接<code>git push</code>会显示提交数低于远程仓库，不能执行。</p>\n<p><code>git push origin HEAD --force</code></p>\n<p>强制将当前所在的HEAD所在的提交push到远程仓库，并且使远程仓库的提交记录和本地保持同步。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"如何删除某些提交？\"><a href=\"#如何删除某些提交？\" class=\"headerlink\" title=\"如何删除某些提交？\"></a>如何删除某些提交？</h1><h2 id=\"删除最新的提交\"><a href=\"#删除最新的提交\" class=\"headerlink\" title=\"删除最新的提交\"></a>删除最新的提交</h2><p><code>git reset --hard HEAD^</code></p>\n<p>可以删除最新的一次提交。若要删除多次提交，可以在HEAD后多加几个^。</p>\n<h2 id=\"删除-x2F-合并中间的某次提交\"><a href=\"#删除-x2F-合并中间的某次提交\" class=\"headerlink\" title=\"删除&#x2F;合并中间的某次提交\"></a>删除&#x2F;合并中间的某次提交</h2><p><code>git rebase -i &lt;commit_id&gt;</code></p>\n<p>填写要删除的提交的<strong>之前</strong>的那次提交的id。</p>\n<p>之后会打开一个vim界面，显示</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pick aaa</span><br><span class=\"line\">pick bbb</span><br><span class=\"line\">pick ccc</span><br><span class=\"line\"><span class=\"comment\"># Rebase xxx onto xxx (xxx command)</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># Commands:</span></span><br><span class=\"line\"><span class=\"comment\"># p, pick &lt;commit&gt; = use commit</span></span><br><span class=\"line\"><span class=\"comment\"># r, reword &lt;commit&gt; = use commit, but edit the commit message</span></span><br><span class=\"line\"><span class=\"comment\"># e, edit &lt;commit&gt; = use commit, but stop for amending</span></span><br><span class=\"line\"><span class=\"comment\"># s, squash &lt;commit&gt; = use commit, but meld into previous commit</span></span><br><span class=\"line\"><span class=\"comment\"># f, fixup [-C | -c] &lt;commit&gt; = like &quot;squash&quot; but keep only the previous</span></span><br><span class=\"line\"><span class=\"comment\">#                    commit&#x27;s log message, unless -C is used, in which case</span></span><br><span class=\"line\"><span class=\"comment\">#                    keep only this commit&#x27;s message; -c is same as -C but</span></span><br><span class=\"line\"><span class=\"comment\">#                    opens the editor</span></span><br><span class=\"line\"><span class=\"comment\"># x, exec &lt;command&gt; = run command (the rest of the line) using shell</span></span><br><span class=\"line\"><span class=\"comment\"># b, break = stop here (continue rebase later with &#x27;git rebase --continue&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># d, drop &lt;commit&gt; = remove commit</span></span><br><span class=\"line\"><span class=\"comment\"># l, label &lt;label&gt; = label current HEAD with a name</span></span><br><span class=\"line\"><span class=\"comment\"># t, reset &lt;label&gt; = reset HEAD to a label</span></span><br><span class=\"line\"><span class=\"comment\"># m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]</span></span><br><span class=\"line\"><span class=\"comment\"># .       create a merge commit using the original merge commit&#x27;s</span></span><br><span class=\"line\"><span class=\"comment\"># .       message (or the oneline, if no original merge commit was</span></span><br><span class=\"line\"><span class=\"comment\"># .       specified); use -c &lt;commit&gt; to reword the commit message</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># These lines can be re-ordered; they are executed from top to bottom.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># If you remove a line here THAT COMMIT WILL BE LOST.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># However, if you remove everything, the rebase will be aborted.</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<p>根据提示，使用<code>drop</code>会弃用那次commit的修改，使用<code>squash</code>则会将修改融合至上一条commit。根据个人需要进行操作。</p>\n<h2 id=\"同步到远程仓库\"><a href=\"#同步到远程仓库\" class=\"headerlink\" title=\"同步到远程仓库\"></a>同步到远程仓库</h2><p>上述都是针对本地提交。如果已经提交到github了怎么办？本地删除后直接<code>git push</code>会显示提交数低于远程仓库，不能执行。</p>\n<p><code>git push origin HEAD --force</code></p>\n<p>强制将当前所在的HEAD所在的提交push到远程仓库，并且使远程仓库的提交记录和本地保持同步。</p>\n"},{"title":"Stochastic-Process","katex":true,"date":"2023-09-21T02:10:49.000Z","_content":"\n## 随机过程随机过\n\n信号与系统：研究确定信号随着时间、空间的变化\n\n概率论：研究随机信号，但是不随时间、空间变化\n\n随机过程：研究随机的信号随着时间、空间的变化\n\n> 期末70分梭哈\n> \n> 考试题目不随机，就跟不上这门课的要求。\n\n### 概率与随机变量回顾\n\n样本空间$\\Omega$\n\n性质：\n* 非负性：$P(A) \\ge 0$\n* 规范性：$P(\\Omega), P(\\emptyset) = 0$\n* 可加性：$P(\\bigcup\\limits_{k = 1}^{\\infty}A_k) = \\sum\\limits_{k=1}^{\\infty}P(A_k)$\n\n贝叶斯：\n\n$$\nP(B_i|A) = \\frac{P(A|B_i)P(B_i)}{\\sum\\limits_{j = 1}^{k}P(B_j)P(A|B_j)}\n$$\n\n随机变量：\n\n分布函数，概率密度函数\n\n期望，方差，协方差，相关系数\n\n伯努利分布，高斯分布，泊松分布，瑞利分布\n\n伯努利分布的概率密度函数：\n\n当$k=1$时，$P(X=1) = p$\n当$k=0$时，$P(X=0) = 1-p$\n\n高斯分布的概率密度函数：\n$P(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$\n\n二维高斯分布的概率密度函数：\n\n$P(x,y) = \\frac{1}{2\\pi\\sigma_x\\sigma_y\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left[\\frac{(x-\\mu_x)^2}{\\sigma_x^2}-2\\rho\\frac{(x-\\mu_x)(y-\\mu_y)}{\\sigma_x\\sigma_y}+\\frac{(y-\\mu_y)^2}{\\sigma_y^2}\\right]\\right)$\n\n其中，$\\mu_x$和$\\mu_y$是均值，$\\sigma_x$和$\\sigma_y$是标准差，$\\rho$是相关系数。\n\n泊松分布的概率密度函数：\n$P(k;\\lambda) = \\frac{\\lambda^k}{k!}\\exp(-\\lambda)$\n\n瑞利分布的概率密度函数：\n$P(x;\\sigma) = \\frac{x}{\\sigma^2}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$\n\n### 随机过程的基本概念\n\n定义：\n\n给定概率空间$(\\Omega, \\mathcal{F}, P)$，定义参数集$T \\subset R$，$t \\in T$\n\n$$\nX = \\lbrace X(t, \\omega), t \\in T, \\omega \\in \\Omega \\rbrace\n$$\n\n简记为$X(t)$: $X = \\lbrace X(t), t \\in T\\rbrace$\n\n解释：\n\n* 二元单值函数\n* 对每个固定t，$X(t, \\omega)$是一个随机变量\n* 每个$\\omega_0 \\in \\Omega$, $X(t, \\omega_0)$是定义在T上的函数，记为$x(t, \\omega_0)$\n\n单样本为随机变量：均值、方差、协方差、有限维联合分布等\n\n随机过程的函数特性：时间的相关性，连续性和离散性，随机过程的导数、微分、积分、卷积、级数展开、微分方程、积分方程等\n\n二重性的联合特征：\n\n分类：\n\n离散时间，离散分布：Bernouli过程\n\n离散时间，连续分布：自回归过程\n\n连续参数离散随机过程：Poission过程\n\n连续参数连续型随机过程：Brown运动\n\n数学特征：\n\n相互独立和不相关是两个概念，无必然因果联系。\n\n根据数字特征分类：\n\n* 独立增量过程\n* 平稳过程及二阶矩过程\n* 马尔可夫过程\n* 更新过程\n\n独立增量过程是一种随机过程，具有以下特性：\n\n1. 零起点：独立增量过程在零时刻（通常表示为$t=0$）的取值为零，即$X(0) = 0$。\n\n2. 独立增量：对于任意时刻$t_1 < t_2 < \\cdots < t_n$，随机变量$X(t_2)-X(t_1), X(t_3)-X(t_2), \\cdots, X(t_n)-X(t_{n-1})$是相互独立的。\n\n若对一切$0\\le s \\lt t$，增量$X(t) - X(s)$的分布仅依赖于$t - s$，则称之为平稳增量，具有平稳增量的独立增量过程称为独立平稳增量过程，例如泊松和布朗。\n\n二阶矩过程：$D(X(t))$\n\n宽平稳过程：\n\n宽平稳过程可以用以下简单的数学表达式表示：\n\n1. 均值平稳性：对于宽平稳过程 $X(t)$，其均值满足 $E[X(t)] = \\mu$，其中 $\\mu$ 是一个常数。\n\n2. 自相关平稳性：宽平稳过程的自相关函数在时间差 $\\tau$ 下为常数，可以表示为 $R_X(\\tau) = R_X(t,t+\\tau) = \\text{常数}$，其中 $R_X(\\tau)$ 表示宽平稳过程的自相关函数。\n\n严平稳过程（Strict-sense stationary process），也称为严格平稳过程或强平稳过程，是一种具有更强平稳性质的随机过程。它满足以下两个条件：\n\n1. 时移不变性：严平稳过程的统计性质在时间上任意平移保持不变。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，随机变量 $X(t)$ 和 $X(t+\\tau)$ 的联合分布相同，即联合分布满足 $P(X(t) \\in A, X(t+\\tau) \\in B) = P(X(0) \\in A, X(\\tau) \\in B)$，其中 $A,B$ 是任意集合。\n\n2. 自相关平稳性：严平稳过程的自相关函数只与时间差有关，与参考时刻无关。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，自相关函数满足 $R_X(t,t+\\tau) = R_X(\\tau)$，其中 $R_X(\\tau)$ 表示严平稳过程的自相关函数。\n\n马尔可夫过程是一种具有马尔可夫性质的随机过程。它可以用以下公式和概念来定义：\n\n1. 状态空间：马尔可夫过程的状态空间是一个离散集合，表示可能的状态集合。通常用符号 $S$ 表示，$S = \\{s_1, s_2, \\ldots\\}$。\n\n2. 马尔可夫性质：马尔可夫过程具有马尔可夫性质，也称为无后效性。即，在给定当前时刻的状态 $X(t)$ 之下，未来的状态 $X(t+\\Delta t)$ 只依赖于当前的状态 $X(t)$，与过去的状态 $X(t-1), X(t-2), \\ldots$ 无关。\n\n3. 转移概率：转移概率描述了在给定当前状态 $s_i$ 的情况下，马尔可夫过程在下一个时刻转移到状态 $s_j$ 的概率。转移概率通常用符号 $P_{ij}$ 表示，即 $P_{ij} = P(X(t+\\Delta t) = s_j \\mid X(t) = s_i)$。\n\n通过状态空间和转移概率，可以构建一个马尔可夫过程的状态转移矩阵（Transition Matrix），它描述了从一个状态到另一个状态的转移概率情况。\n\n更新过程：\n\n更新过程可以使用以下公式来描述：\n\n1. 到达时间：假设到达时间的随机变量序列为 $T_1, T_2, T_3, \\ldots$，其中 $T_i$ 表示事件 $i$ 的到达时间。\n\n2. 描述参数：更新过程的到达率（或强度）表示单位时间内平均发生事件的次数。通常用符号 $\\lambda$ 表示，即 $\\lambda = \\lim_{t \\to \\infty} \\frac{N(t)}{t}$，其中 $N(t)$ 表示时间 $t$ 之前（包括 $t$）发生的事件次数。\n\n3. 插值函数：更新过程的插值函数（或插值过程）表示给定时间 $t$ 时，最近的到达时间是多久之前。记为 $S(t)$，即 $S(t) = \\sup\\{T_i \\leq t\\}$，表示最近的到达时间小于等于 $t$ 的时间点。\n\n\n可以定义复随机过程：\n\n\n复随机过程是一组复数值随机变量的集合 $\\{X(t), t \\in T\\}$，其中 $X(t)$ 是定义在概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数值随机变量，表示在时间点 $t$ 上的取值。\n\n具体而言，对于每个时间点 $t \\in T$，$X(t)$ 是一个复数值随机变量，可以表示为 $X(t) = R(t) + iI(t)$，其中 $R(t)$ 和 $I(t)$ 分别表示实部和虚部。\n\n复随机过程可以通过概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数随机变量以及时间参数 $T$ 来描述，并且在不同时间点上表现出复数值随机变量的随机性质。\n\n数学特征：\n\n均值函数（一阶原点矩）：$\\mu_X(t) = E[X(t)]$\n\n方差函数：$\\text{Var}[X(t)] = E[(X(t) - \\mu_X(t))(X(t) - \\overline{\\mu_X(t)} )]$\n\n自相关函数：$R_X(t_1, t_2) = E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$\n\n自协方差函数：$\\text{Cov}[X(t_1), X(t_2)] = E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$\n\n均方值函数：$E[|X(t)|^2] = \\int_{-\\infty}^{\\infty} |x|^2 f_X(x,t)dx$\n\n### 基本研究方法\n\n* 相关方法\n* Markov 方法\n\n**相关**\n\n若随机过程在任意时刻的均值和方差都存在，则称之为二阶矩过程（second order process），即均方可积空间上的随机变量。\n\n均方可积空间是内积空间。相关运算是均方可积的内积运算：\n\n$$\n\\langle X, Y \\rangle = E(X\\overline Y)\n$$\n\n\n宽平稳（wide-sense stationary）:\n\n$$\nR_X(t, s) = R_X(t + D, s + D) = R(t - s)\n$$\n\n功率谱密度：\n\n$$\nS_X(\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\exp(-j\\omega\\tau)\\mathrm d\\tau\n$$\n\n最优线性估计\n\n**Markov**\n\n\n有限维联合分布可以由各阶的条件分布表示出来：\n\n$$\n\\begin{align*}\n    &F_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n) \\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)F_{X(t_{n - 1}), \\dots, X(t_1)}(x_1, \\dots, x_{n - 1})\\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n\\end{align*}\n$$\n\n无后效性的 markov 过程：\n\n$$\nF_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1) = F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\n$$\n\n从而所有高阶依赖关系都可以简化为二阶依赖：\n\n$$\nF_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n)=F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n$$\n\n## 相关理论与二阶矩过程——时域分析\n\n### 自相关函数\n\n由二阶矩过程的定义可知，均方可积空间的自相关函数、自协方差函数、互相关函数、互协方差函数均存在。\n\n均值函数（一阶原点矩）：$\\mu_X(t) = E[X(t)]$\n\n方差函数：$\\text{Var}[X(t)] = E[(X(t) - \\mu_X(t))^2]$\n\n自相关函数：$R_X(t_1, t_2) = E[(X(t_1))(X^*(t_2))]$\n\n自协方差函数：$C_X(t_1, t_2) = \\text{Cov}[X(t_1), X(t_2)] = E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\mu_X(t_2))^*]$\n\n均方值函数：$E[X^2(t)] = \\int_{-\\infty}^{\\infty} x^2 f_X(x,t)dx$\n\n互相关函数和互协方差函数：\n\n* 如果$E[X(s)Y(t)]存在$，记为$R_{XY}(s, t)$\n* 如果$\\text{cov}(X(s), Y(t))存在$，记为$C_{XY}(s, t)$\n\n$$\nR_{XY}(t_1, t_2) = E[(X(t_1))(Y^*(t_2))]\n$$\n\n$$\nC_{XY}(t_1, t_2) = E[(X(t_1) - \\mu_X(t_1))(Y(t_2) - \\mu_Y(t_2))^*]\n$$\n\n$$\nC_{XY}(s, t) = R_{XY}(s,t) - \\mu_X(s)\\mu_Y(t)\n$$\n\n不相关：\n\n$$\nC_{XY}(s, t) = 0\n$$\n\n$$\nR_{XY}(s,t) = m_X(s)m_Y(t)\n$$\n\n\n自相关函数具有共轭对称性：\n\n$$\nR(t_1, t_2) = R^*(t_2, t_1)\n$$\n\n离散化的自相关矩阵同样是共轭对称的：\n\n$$\nR = E[XX^H]\\\\\nR_{ij} = R^*_{ji}\n$$\n\n自相关矩阵是非负定的：\n\n$$\n\\lambda R \\lambda^H = \\lambda XX^H\\lambda^H \\ge 0\n$$\n\n当 $P(\\lambda X = 0) = 1$ 时等号成立。\n\n非负定性是自相关函数的一种特征性质。如果一个二元函数满足非负定性质，则一定可以构造出一个随机过程，使得其自相关函数为给定的二元函数。\n\n自相关矩阵非负定，分解的特征值均非负。其物理意义是信号的能量或者功率。\n\n自相关函数对加法和乘法的封闭性：\n\n$$\nR(t, s) = \\alpha R_1(t, s) + \\beta R_2(t, s)\n$$\n\n仍然是某一随机过程的自相关函数。\n\n证明：取 $Z(t) = \\alpha^{1/2} X(t) + \\beta^{1/2} Y(t)$。这里 $X(t), Y(t)$是独立的。\n\n$$\nR(t, s) = R_1(t, s)R_2(t, s)\n$$\n\n也是自相关函数。取 $Z(t) = X(t)Y(t)$。\n\n### 宽平稳随机过程\n\n**宽平稳**\n\n对于随机过程 $X(t), t \\in T$，若 $\\forall t, s\\in T$\n\n$$\nE(X(t)) = E(X(s))\\\\\nR_X(t, s) = R_X(t + D, s + D)\n$$\n\n称随机过程 $X(t)$ 具有宽平稳性。\n\n宽平稳过程的均值是常数，自相关函数与相对时间差有关。故宽平稳过程的自相关函数可以写成一元函数：$R_X(\\tau), \\tau = t - s$。\n\n**严平稳**\n\n对于随机过程 $X(t), t \\in T$，若 $\\forall n, \\forall t_1, t_2, \\dots, t_n \\in T$，$\\forall D \\in T$，都有\n\n$$\nF_{t_1, t_2, \\dots, t_n}(x_1, x_2, \\dots, x_n) = F_{t_1 + D, t_2+D, \\dots, t_n + D}(x_1, x_2, \\dots, x_n)\n$$\n\n则称随机过程 $X(t), t\\in T$具有严平稳性。\n\n在二阶矩存在的条件下，严平稳蕴含宽平稳，而反过来，宽平稳一般无法得到严平稳。\n\n高斯过程的严平稳与宽平稳等价。\n\n**联合宽平稳**\n\n$$\nR_{X, Y}(t, s) = R_{XY}(t + D, s + D), \\forall D \\in T\n$$\n\n**宽平稳过程的性质**\n\n设 $R_X(\\tau)$ 为宽平稳过程的自相关函数， $m_X$ 为该过程的均值。\n\n$$\n\\begin{align}\n    R_X(\\tau) = \\overline{R_X(-\\tau)}\\\\\n    R_X(0)\\ge |m_X|^2\\\\\n    |R_X(\\tau)| \\le R_X(0)\\\\\n    R_X(\\tau) \\text{是一元非负定函数。}\n\\end{align}\n$$\n\n### 正交增量过程\n\n**正交增量过程**\n\n对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，满足\n\n$$\nE(X(t_4) - X(t_3))(\\overline{X(t_2) - X(t_1)}) = 0\n$$\n\n则称 $X(t), t \\in \\R$ 为正交增量过程。\n\n**独立增量过程**\n\n对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，$X(t_4) - X(t_3)$ 和 $X(t_2) - X(t_1)$ 统计独立，则称为独立增量过程。\n\n均值为0的独立增量过程是正交增量过程。\n\n**平稳增量过程**\n\n对于随机过程 $X(t), t \\in \\R$，若 $X(t) - X(s)$ 的分布仅仅依赖于 $t - s$，则称为平稳增量过程。\n\n定理：\n\n随机过程 $X(t), t \\in [0, \\infty]$，满足 $X(0) = 0$，则其为正交增量过程的充要条件为\n\n$$\nR_X(s, t) = F(\\min(s, t))\n$$\n\n其中，$F(\\cdot)$是单调不减的函数。\n\n### 随机过程的极限、连续、导数、积分\n\n**均方极限**\n\n$$\nE(|ka|^2)\n$$\n\n\n\n唯一性：若 $X_n \\xrightarrow{m.s} X, X_n \\xrightarrow{m.s}Y$，则 $E(|X - Y|^2) = 0$.\n\n可加性：\n\n数字特征相同：\n\n如何判定 ${X_n}$ 是否收敛？\n\nCauchy 准则\n\n$$\nX_n \\xrightarrow{m.s}{X} \\Leftrightarrow E(|X_m - X_n|^2) = 0, m, n \\rightarrow \\infty\n$$\n\n洛伊夫准则：\n\n$$\nX_n \\xrightarrow{m.s} X \\lrArr E\\lbrace X_n X_m^*\\rbrace \\rightarrow \\text{constant}\n$$\n\n**均方连续**\n\n二阶矩过程，$t \\rightarrow t_0, X(t) \\xrightarrow{m.s.} X(t_0)$，则称 $X(t)$ 在 $t_0$ 处连续\n\n定理\n\n以下命题等价：\n\n1. $R(t, s)$ 在 $(t_0, t_0)$ 上连续，$\\forall t_0 \\in T$\n2. $X(t)$ 在 $T$ 上均方连续\n3. $R(t, s)$ 在 $T \\times T$ 上连续\n\n推论\n\n对于宽平稳过程 $X(t)$，$R(\\tau)$ 为自相关函数，以下命题等价：\n\n1. $R(\\tau)$ 在 $\\tau = 0$ 处连续；\n2. $X(t)$ 在 $T$ 上均方连续；\n3. $R(\\tau)$ 在 T 上连续。\n\n**均方导数**\n\n若 $\\frac{X(t_0 + h) - X(t_0)}{h}\\xrightarrow{m.s.}Y(t_0), \\forall t_0 \\in T, h \\rightarrow 0$，则称$\\lbrace X(t) \\rbrace$ 在均方意义下的导数为 $Y(t)$。\n\n如何判断 $X(t)$ 是否均方可导？\n\nCauchy 准则\n\n$$\nE\\left(|\\frac{X(t_0 + h) - X(t_0)}{h} - \\frac{X(t_0 + g) - X(t_0)}{g}|^2\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$\n\n洛伊夫准则\n\n$$\nE\\left(\\left(\\frac{X(t_0 + h) - X(t_0)}{h}\\right)\\left(\\frac{X(t_0 + g) - X(t_0)}{g}\\right)^*\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$\n\n均方导数判定定理\n\n$$\n\\frac{\\partial^2 R(t, s)}{\\partial t \\partial s} 在 (t_0, t_0) 存在且连续，则 X(t) 在 t_0 处存在均方倒数\n$$\n\n均方导数的性质：\n\n$f(t)$ 为线性函数\n\n* $E(X^\\prime(t)) = \\frac{\\mathrm d }{\\mathrm dt} E(X(t))$\n* $E(X^\\prime(t)\\overline{X(s)}) =\\frac{\\partial }{\\partial t}R_x(t, s)$\n* $E(X(t)\\overline{X^\\prime(s)}) =\\frac{\\partial }{\\partial s}R_x(t, s)$\n* $E(X^\\prime(t)\\overline{X^\\prime(s)}) =\\frac{\\partial^2 }{\\partial t\\partial s}R_x(t, s)$\n\n\n**均方积分**\n\n若黎曼和 $\\sum\\limits_{k=1}^{n}X(v_k)h(v_k)(t_k - t_{k - 1})$ 在 $n \\rightarrow \\infty, \\max\\lbrace t_k - t_{k - 1}\\rbrace \\rightarrow 0$ 时均方收敛，其中 $h(t)$ 为确定的可积函数，则称$\\lbrace X(t)\\rbrace$ 为均方可积，记为 $\\int_{a}^{b}X(t)h(t)\\mathrm dt$。\n\n判定定理\n\n$$\n\\lbrace X(t)h(t) \\rbrace 均方可积 \\Leftrightarrow \\int_{a}^{b}\\int_{a}^{b}R_X(t, s)h(t)h^*(s)\\mathrm dt\\mathrm ds 存在\n$$\n\n均方积分的性质：\n\n* $E\\left( \\int_{a}^{b}X(t)h(t)\\mathrm dt\\right) = \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$\n* $E\\left( \\left(\\int_{a}^{b}X(t)h(t)\\mathrm dt\\right)\\left(\\int_{a}^{b}X(s)h(s)\\mathrm ds\\right)^*\\right) = \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$\n* 三角不等式：$\\sqrt{ E \\left(|\\int_{a}^{b}X(t)h(t)\\mathrm dt|^2\\right) } \\le \\int_{a}^{b}\\sqrt{E\\left(|X(t) - h(t)|^2\\right)}\\mathrm dt$\n* 均方积分与均方导数：$X(t)$ 在 $[a, b]$ 上均方连续，$Y(t) = \\int_{a}^{t}X(s)\\mathrm ds$，其中等号代表均方相等，则 $\\lbrace Y(t)\\rbrace$ 在 $[a, b]$ 可导，并称在均方意义下 $\\lbrace Y(t) \\rbrace$ 的导数为 $\\lbrace X(t) \\rbrace$\n\n### 随机过程的遍历性\n\n统计平均：对样本空间取平均\n\n$$\nE\\lbrace X(t_0) \\rbrace = \\int_{}^{}x\\mathrm dF_X(x;t_0)\n$$\n\n时间平均：\n\n$$\n\\langle X(t) \\rangle = \\frac{1}{T} \\int_{-T/2}^{T/2}X(t)\\mathrm dt\n$$\n\n统计平均和时间平均的关系？\n\n时间平均更容易获得。如果我们可以通过时间平均来获得统计平均？\n\n**遍历性**\n\n\n定义-宽平稳过程均值遍历：\n\n$$\n\\langle X(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} E \\lbrace X(t) \\rbrace = \\mu\n$$\n\na.s. = with probability 1\n\n左边是随机变量，右边是一个确定的数。这样的相等，意味着左边的随机变量的均值确定，方差为0.\n\n定义：宽平稳过程自相关遍历\n\n$$\n\\langle X(t + \\tau)X^*(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t + \\tau)X^*(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} R_X(\\tau) = E \\lbrace X(t + \\tau)X^*(t)\\rbrace\n$$\n\na.s. = with probability 1\n\n定理：\n\n宽平稳过程 $X(t)$ 满足均值遍历 $\\lrArr$ \n\n$$\nD(\\langle X(t) \\rangle) = \\lim\\limits_{T \\rightarrow\\infty} \\frac{1}{2T}\\int_{-2T}^{2T}\\left(1 - \\frac{|\\tau|}{2T}\\right)(R_X(\\tau) - |\\mu|^2)\\mathrm d\\tau = 0\n$$\n\n定理：\n\n宽平稳过程具有均值遍历性的充要条件是：\n\n$$\n\\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T}\\int_{-T}^{T}C_X(\\tau)\\mathrm d\\tau = 0 或者 \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{T}\\int_{0}^{T}C_X(\\tau)\\mathrm d\\tau = 0\n$$\n\n时间比较长的时候相关性消失了，也就是说过了一段时间同一轨道的样本就独立了，等价于多个轨道的样本，时间平均和统计平均就相等了。\n\n2个推论：\n\n* 若实数宽平稳过程的协方差函数满足 $\\int_{0}^{+\\infty}C_x(\\tau)\\mathrm d\\tau\\lt +\\infty$，则该过程具有均值遍历性\n* 若实数宽平稳过程的协方差函数满足 $C_x(\\tau) \\rightarrow 0, \\tau \\rightarrow +\\infty$，则该过程具有均值遍历性\n\n### 随机过程的线性展开\n\n**卡胡曼-洛伊夫展开**\n\n在平方可积空间上\n\n定义范数\n\n定义内积，正交\n\n在 $L^2[a, b]$ 中一定有一组标准正交基函数 $\\phi_1(t), \\phi_2(t), \\phi_3(t)\\dots$ 满足\n\n$$\n\\begin{cases}\n    \\langle \\phi_i, \\phi_j \\rangle = 0, i\\ne j\\\\\n    \\langle \\phi_i, \\phi_i \\rangle = 1\n\\end{cases}\n$$\n\n* $f$ 可以用有限个基函数线性加和来逼近\n* $\\langle f, \\phi_n \\rangle$ 表示 $f$ 在 $\\phi_n$ 基上的坐标。\n\n周期性宽平稳随机过程可以用傅里叶级数展开\n\n$$\nE\\left(\\left |X(t) -\\sum\\limits_{n=-\\infty}^{\\infty}c_ne^{j\\omega_0t}  \\right |^2\\right) = 0\n$$\n\n一般的用 KL 展开\n\n随机向量的双正交展开：\n\n零均值的 $n$ 元随机向量 $\\mathbf X \\in R^n$ 可以如下展开：\n\n$$\nX = \\sum\\limits_{k=1}^{n} \\xi_k \\mathbf e_k\n$$\n\n基向量选择的是自相关矩阵 $\\mathbf R$ 的特征向量。\n\n如果我们用 $\\mathbf K$ 个维度来逼近 $\\mathbf X$，为了使得误差最小，选取最大的$\\mathbf K$个特征值： $\\mathbf X =\\sum\\limits_{k=1}^{K} \\alpha_k\\mathbf e_k$。这就是主成分分析（PCA）。\n\n## 谱分析\n\n### 周期函数的傅里叶级数\n\n$$\nx(t) =\\sum\\limits_{n=-\\infty}^{\\infty}a_n e^{j\\omega_0 t}, \\omega_0 = \\frac{2\\pi}{T}\\\\\na_n = \\frac{1}{T}\\int_{0}^{T}x(t)e^{-jn\\omega_0t}\\mathrm dt\n$$\n\n帕斯瓦尔定理\n\n$$\n\\frac{1}{T}\\int_{0}^{T}|x(t)|^2\\mathrm dt =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\n$$\n\n自相关函数\n\n$$\nR(\\tau) = \\frac{1}{T}\\int_{0}^{T}x(t + \\tau)x^*(t)\\mathrm dt\n$$\n\n功率谱密度\n\n$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\\delta(\\omega - n \\omega_0)\n$$\n\n从而有\n\n$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\n$$\n\n### 非周期函数的傅里叶变换\n\n#### 知识\n\n$$\nF(\\omega) = \\int_{-\\infty}^{\\infty}x(t)\\exp(-j\\omega t)\\mathrm dt\\\\\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}F(\\omega)\\exp(j\\omega t)\\mathrm d\\omega = \\int_{-\\infty}^{\\infty}F(f)\\exp(j2\\pi ft)\\mathrm df\n$$\n\n帕斯瓦尔定理\n\n$$\n\\int_{-\\infty}^{\\infty}|x(t)|^2\\mathrm dt = \\int_{-\\infty}^{\\infty}|F(f)|^2\\mathrm df\n$$\n\n$$\n时域采样 \\lrarr 频域周期延拓\\\\\n时域周期延拓 \\lrarr 频域采样\\\\\n$$\n\n自相关函数\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}x(t + \\tau)x^*(t)\\mathrm dt\n$$\n\n能量谱密度\n\n$$\nS(\\omega) = |F(\\omega)|^2 = \\left |\\int_{-\\infty}^{\\infty}x(t)e^{j\\omega t}\\mathrm dt  \\right|^2\\\\\n$$\n\n波赫纳尔——辛钦定理\n\n$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S(\\omega)e^{j\\omega\\tau}\\mathrm d\\omega, S(\\omega)\\ge 0\n$$\n\n实过程的 $S(\\omega)$ 为偶函数。\n\n离散随机过程的功率谱：\n\n只在整数点 k 采样\n\n$$\nS(\\omega) =\\sum\\limits_{k=-\\infty}^{\\infty}R(k)e^{-j\\omega k}\\\\\nR(k) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}S(\\omega)e^{j\\omega k}\\mathrm d\\omega\n$$\n\n周期过程（自相关函数有周期性）的功率谱\n\n$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}b_n\\delta(\\omega - n \\Delta \\omega)\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\sum\\limits_{n=-\\infty}^{\\infty}b_ne^{jn\\Delta\\omega\\tau}\n$$\n\n#### 例子\n\n白噪声 $E \\lbrace X(t) \\rbrace = 0$，\n\n$$\nS(\\omega) = N_0, -\\infty \\lt \\omega \\le \\infty\\\\\nR(\\tau) = N_0\\delta(\\tau)\n$$\n\n* 任意两个不同时刻 $X(t_1), X(t_2)$ 都不相关。\n* 在各个频率上都有分量，且强度一致。\n\n高斯白噪声：各时刻服从高斯分布的白噪声\n\n色噪声： $R(\\tau)$ 不是冲击函数。\n\n* 当某过程 $R(\\tau)$ 比较胖的时候，功率谱比较瘦\n  * 相隔较长时间 $X(t)$ 与 $X(t + \\tau)$ 还相关，说明信号变化慢，对应频域低频多\n分量多\n* 当某过程 $R(\\tau)$ 比较瘦时，功率谱比较胖\n* 相隔一点时间， $X(t)$ 与 $X(t + \\tau)$ 不太相关，说明信号变化快，对应频域高频分量多。\n\n互谱密度\n\n$$\nS_{XY}(\\omega) = \\int_{-\\infty}^{\\infty}R_{XY}(\\tau)e^{-j\\omega \\tau}\\mathrm d\\tau\n$$\n\n称为互谱密度，不具有功率的含义。\n\n$$\nS_{YX}(\\omega) = S_{XY}^*(\\omega)\\\\\nR_{XY}(\\tau) = 0, \\forall \\tau \\lrArr S_{XY}(\\omega) = 0, \\forall \\omega\n$$\n\n$$\nZ(t) = X(t) + Y(t)\\\\\nR_Z(\\tau) = E \\lbrace (X(t + \\tau) + Y(t + \\tau))\\overline{(X(t) + Y(t))} \\rbrace = R_X(\\tau) + R_{XY}(\\tau) + R_{XY}\n$$\n\n一个宽平稳过程分别通过两个 LTI 系统：\n\n$$\nY_1(t) = X(t) * h_1(t)\\\\\nY_2(t) = X(t) * h_2(t)\\\\\nR_{Y_1Y_2}(\\tau) = R_X(\\tau) * h_1(\\tau) * h_2^*(-\\tau)\\\\\nS_{Y_1Y_2}(\\omega) = S_X(\\omega)H_1(\\omega)H_2^*(\\omega)\\\\\n$$\n\n两个过程输入两个系统，输出过程的互谱（互相关函数的傅里叶变换）。怎么求？\n\n（输入为联合宽平稳）\n\n$$\n\\hat X(t) = X(t) * f(t)\\\\\n\\hat Y(t) = Y(t) * g(t)\\\\\nR_{\\hat X\\hat Y}(\\tau) = R_{XY}(\\tau) * f(\\tau) * g^*(-\\tau)\\\\\nS_{\\hat X\\hat Y}(\\omega) = S_{XY}(\\omega)F(\\omega)G^*(\\omega)\n$$\n\n\n### 宽平稳过程通过线性系统\n\n$$\nY(t) = \\int_{-\\infty}^{\\infty}h(t - \\tau)X(\\tau)\\mathrm d\\tau\n$$\n\n总结：\n* 输出过程的均值：易求，因为宽平稳过程的均值为常数\n* 输出过程的自相关函数：有点麻烦\n\n首先看输出与输入的自相关\n\n$$\nR_{YX}(\\tau) = \\int_{-\\infty}^{\\infty}h(v)R_x(\\tau - v)\\mathrm dv\\\\\nR_Y(\\tau) = \\int_{-\\infty}^{\\infty}h^*(-u)R_{YX}(\\tau - u)\\mathrm du\n$$\n\n$$\nR_Y(\\tau) = R_X(\\tau) * h(\\tau) * h^*(-\\tau)\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$\n\n因此，输出的自相关，也可以用功率谱求解。\n\n### 离散时间宽平稳序列\n\n$$\nR_{YX}(k) = h(k) * R_X(k)\\\\\nR_Y(k) = h^*(-k) * h(k) * R_X(k)\\\\\nS_Y(z) = H(z) H^*(\\frac{1}{z^*})S_X(z)\\\\\n其中 H(z) =\\sum\\limits_{}^{}h(k)z^{-k}\\\\\n令 z = e^{j\\omega}\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$\n\n理想白噪声通过低通滤波器：\n\n$$\nS_Y(f) = \\begin{cases}\n    k_0, -f_c \\le f \\le f_c,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\\\\\nR_Y(0) = 2f_ck_0\\\\\nR(\\tau) = R_Y(0)\\frac{\\sin(2\\pi f_c\\tau)}{2\\pi f_c\\tau}\n$$\n\n从自相关函数可看出，相隔 $\\frac{n}{2f_c}$ 的两个时刻不相关。因此，以 $2f_c$ 为采样频率的噪声采样数据彼此不相关。\n\n可以证明宽平稳过程功率谱非负：$S_X(f) \\ge 0$：\n\n$$\nE \\lbrace |Y(t)|^2 \\rbrace =  R_Y(0) = \\int_{-\\infty}^{\\infty}S_Y(f)\\mathrm df = \\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\ge 0\n$$\n\n如果 $S_X(f)$ 在某个地方小于0，可以设计对应的滤波器 $H(f)$将这个小于0的区域滤出来，从而 $\\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\le 0$，导致矛盾。\n\n线性系统例子：\n\n滑动平均\n\n$$\nY(t) = \\frac{1}{T}\\int_{t-T}^{t}X(s)\\mathrm ds\n$$\n\n转化为滤波器：\n\n$$\nR_Y(t) = R_X(t) * h(t) * h^*(-t)\\\\\nh(t) = \\begin{cases}\n    \\frac{1}{T}, 0 \\le t \\le T,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\n$$\n\n令 \n\n$$\ng(t) = h(t) * h^*(t) = \\begin{cases}\n    \\frac{1}{T}\\left ( 1 - \\frac{|t|}{T} \\right), t \\in [-T, T],\\\\\n    0,\\text{otherwise.}\n\\end{cases}\n$$\n\n理想的矩形窗\n\n$$\nR_Y(t) = \\int_{-\\infty}^{\\infty}g(t - \\tau)R_X(\\tau)\\mathrm d\\tau = \\int_{-T}^{T}\\frac{1}{T}\\left ( 1 - \\frac{|t - \\tau|}{T} \\right)R_X(\\tau)\\mathrm d\\tau\n$$\n\n从频域看\n\n$$\nH(\\omega) = \\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)e^{-j\\omega \\frac{T}{2}}\\\\\nS_Y(\\omega) = S_X(\\omega)\\left |\\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)  \\right|^2\n$$\n\n是一个低通滤波器。\n\n例子2：MTI 滤波\n\n静止目标反射信号相同，运动目标反射回波不同。因此设计滤波器消去静止目标。称为“对消”。\n\n$$\nY(t) = X(t) - X(t - T)\n$$\n\n在频域看：\n\n$$\nH(\\omega) = 1 - e^{j\\omega T}\n$$\n\n静止目标，多普勒频率为0，因此频域响应为0；运动目标，多普勒频率不为0，频域响应不为0。因此这是一个高通滤波器。\n\n还可以多次对消：\n\n$$\nY_1(t) = X(t) - X(t - T)\\\\\nY_2(t) = Y_1(t) - Y_1(t - T)\\\\\nY_3(t) = Y_2(t) - Y_2(t - T)\\\\\n\\vdots\\\\\nY_n(t) = Y_{n - 1}(t) - Y_{n - 1}(t - T)\n$$\n\n频率响应：\n\n$$\nH(\\omega) = (1 - e^{-j\\omega T})^n\n$$\n\n### 采样定理\n\n随机过程下的采样定理\n\n$|f| \\le f_0$, 当 $f_s \\le 2f_0$ 时，均方意义下有\n\n$$\nX(t) =\\sum\\limits_{k=-\\infty}^{\\infty}X(kT) \\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right)\n$$\n\n证明：\n\n$$\n\\begin{align*}\n    &要证明 N \\rightarrow \\infty 时,\\\\\n    &\\varepsilon_N = E \\left \\lbrace  \\left | X(t) -\\sum\\limits_{k=-N}^{N}X(kT)\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 \\right \\rbrace \\rightarrow 0\\\\\n    &利用E \\lbrace X(a) X^*(b) \\rbrace = R_X(a - b) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}e^{j\\omega a}e^{-j\\omega b}S_X(\\omega)\\mathrm d\\omega，展开上式\\\\\n    &\\varepsilon_N = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &= \\frac{1}{2\\pi}\\int_{-\\omega_s/2}^{\\omega_s/2}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &对 e^{j\\omega t}做周期延拓，周期为 \\omega_s，可以做频域傅里叶级数展开\\\\\n    &e^{j\\omega t} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega \\frac{2\\pi}{\\omega_s}} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega kT}\\\\\n    &\\alpha_k = \\frac{1}{\\omega_s}\\int_{-\\omega_s/2}^{\\omega_s/2}e^{j\\omega t}e^{-j\\omega kT}\\mathrm d\\omega = \\frac{\\sin(\\frac{\\omega}{2}(t - kT))}{\\frac{\\omega}{2}(t - kT)}\\\\\n    &从而\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 = \\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}\\alpha_k e^{j\\omega kT}\\right|^2 \\rightarrow 0, N \\rightarrow \\infty\n\\end{align*}\n$$\n\n* 采样定理两边是均方相等。\n* 当满足采样定理时，离散点包含全部信息，任意取值点可以恢复。\n* 频带边界点\n  * 当功率谱在 $\\pm \\omega_0$ 处有 $\\delta$ 函数时，以 $f_s = 2f_0$ 无法恢复信号。\n  * 例如：$X(t) = \\cos(\\omega_0 t + \\phi)$，$\\phi$ 为随机相位，在$[0, 2\\pi]$内均匀分布。\n  * $R(\\tau) = \\frac{1}{2}\\cos(\\omega_0\\tau)$\n  * $S(\\omega) = \\delta(\\omega - \\omega_0) + \\delta(\\omega + \\omega_0)$\n  * 采样点 $X(kT) = (-1)^kX(0)$，与 $X(0)$ 严重相关。\n\n欠采样\n\n$$\n\\begin{align*}\n    E \\lbrace |\\varepsilon(t)|^2 \\rbrace =& \\int_{\\omega_s/2}^{-\\omega_s/2}\\sum\\limits_{n=-\\infty}^{\\infty}|1 - e^{jn\\omega t}|S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}4\\sin^2(\\omega_snt/2) \\cdot \\int_{\\omega_s/2}^{-\\omega_s/2}S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n\\end{align*}\\\\\n\n上面的级数为积分的加权求和。 n = 0 时权重为0，对应[-\\omega_s/2, \\omega_s/2] 内的功率谱。\\\\\nn\\ne 0 时，权不为0，对应[-\\omega_s/2, \\omega_s/2]外的频谱，如果在这个区间外功率谱不是0，那 |\\varepsilon|^2 将大于0。\n\n$$\n\n### 带通采样\n\n$$\nX(\\omega) = 0, |\\omega - \\omega_c| > \\omega_0, |\\omega + \\omega_c| > \\omega_0\n$$\n\n一般研究实信号 $g(t)$，频谱具有共轭对称性，只需要考虑正半轴的频带就可以了：\n\n$$\nG(-\\omega) = G^*(\\omega)\\\\\nA(\\omega) = A(-\\omega), \\varphi(-\\omega) = -\\varphi(\\omega)\n$$\n\n希尔伯特变换：\n\n$$\nH(\\omega) = \\begin{cases}\n    -j, \\omega \\gt 0,\\\\\n    0, \\omega = 0,\\\\\n    j, \\omega \\lt 0.\n\\end{cases}\n$$\n\n$$\n\\lbrace G(\\omega)H(\\omega) \\rbrace^* = G(-\\omega)H(-\\omega)\n$$\n\n希尔伯特把正频率移相 $-90\\degree$，负频率移相 $+90\\degree$\n\n时域表示：\n\n滤波器的时域响应为\n\n$$\n\\hat h(t) = \\frac{1}{\\pi t}\n$$\n\ng(t) 做两次希尔伯特变换，相位转了 $180\\degree$：\n\n$$\ng(t)\\xrightarrow{H(\\omega)}\\hat g(t) \\xrightarrow{H(\\omega)} -g(t)\n$$\n\n正交性：\n\n$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = 0\n$$\n\n看成$\\hat g(t)$ 与 $g(-t)$ 的卷积：\n\n$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}g(- (u - t))\\hat g(t)\\mathrm dt|_{u = 0} = g(-t) * \\hat g(t) |_{t = 0}\\\\\ng(-t) \\rightarrow G^*(\\omega) = G(-\\omega), \\hat g(t) \\rightarrow G(\\omega)H(\\omega)\\\\\ng(-t) * \\hat g(t)|_{t = 0} = \\int_{-\\infty}^{\\infty}G^*(\\omega)G(\\omega)H(\\omega)e^{j\\omega t}\\mathrm d\\omega|_{t = 0} = 0\n$$\n\n希尔伯特变换与原信号相加得到单边的频谱：\n\n$$\ng(t) \\rightarrow A^* + A\\\\\nj\\hat g(t) \\rightarrow \\\\\ng(t) + j\\hat g(t) \\rightarrow 2A\\\\\n$$\n\n下变频：\n\n$$\n\\tilde{g}(t) = \\lbrace g(t) + j\\hat g(t) \\rbrace e^{-j\\omega_c t} = g_I(t) + jg_Q(t)\\\\\ng_I(t) = g(t) \\cos \\omega_c t + \\hat g(t) \\sin (\\omega_c t)\\\\\ng_Q(t) = - g(t) \\sin \\omega_c t + \\hat g(t) \\cos (\\omega_c t)\\\\\n$$\n\n实际上是一个旋转矩阵，把单边频信号 $\\tilde g(t)$ 顺时针旋转了 $\\omega_ct$变成了基带复信号。\n\n与原信号频谱的关系：\n\n$$\ng_I(t) \\rightarrow G(f - f_c) + G(f + f_c) \\\\\ng_Q(t) \\rightarrow G(f - f_c)(+j) + G(f + f_c)(-j)\\\\\n(f \\le |f_0|)\n$$\n\n调制和解调的流程\n* 调制：不需要得到 $\\hat g(t)$\n* 解调：通过低通滤波代替$\\hat g(t)$\n\n随机过程的希尔伯特变换\n\n$X(t)$为实的带通随机过程\n\n$$\nR_X(-\\tau) = E\\left \\lbrace  X(t - \\tau)X^*(t) \\right \\rbrace = E\\left \\lbrace  X(t)X^*(t + \\tau) \\right \\rbrace = E\\left \\lbrace  X(t + \\tau)X(t) \\right \\rbrace = R_X(\\tau)\\\\\nS_X(-\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)e^{-j(-\\omega) \\tau}\\mathrm d\\tau = \\int_{-\\infty}^{\\infty}R_X(-u)e^{-j\\omega\\tau}\\mathrm du = \\int_{-\\infty}^{\\infty}R_X(u)e^{-j\\omega\\tau}\\mathrm du = S_X(\\omega)\n$$\n\n通过希尔伯特滤波器后：\n\n$$\n\\hat X(t) = X(t) * h(t)\\\\\nR_{\\hat X}(\\tau) = R_X(\\tau) * h(t) * h^*(-t) = R_X(\\tau)\\\\\nS_{\\hat X}(\\omega) = S_X(\\omega)|H(\\omega)|^2 = S_X(\\omega)\n$$\n\n互相关：\n\n$$\n\\hat R_X(\\tau) = R_{\\hat XX}(\\tau) = E \\left \\lbrace \\int_{-\\infty}^{\\infty}X(t + \\tau - u)\\frac{1}{\\pi u}\\mathrm duX(t)   \\right\\rbrace = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\frac{1}{\\pi u}\\mathrm du\n$$\n\n$$\nR_{X\\hat X}(\\tau) = -\\hat R_X(\\tau)\n$$\n\n因此\n\n$$\nY = X + j\\hat X\\\\\nR_Y(\\tau) = R_X(\\tau) + R_{\\hat X}(\\tau) + jR_{\\hat XX}(\\tau) - jR_{X\\hat X}(\\tau) = 2R_X(\\tau) + 2j\\hat R_X(\\tau)\\\\\nS_Y(f) = \\begin{cases}\n    4S_X(f), &f \\gt 0\\\\\n    0, &f\\lt 0\n\\end{cases}\n$$\n\n实的带通随机过程配合虚部的希尔伯特变换，同样也是只有正频率\n\n反之，如果功率谱只有正频率有值，则实部和虚部互为希尔伯特变换，实部和虚部的信息是重复的。\n\n随机信号的下变频：\n\n$$\n\\tilde{X}(t) = \\lbrace X(t) + j\\hat X(t) \\rbrace e^{-j\\omega_c t} = X_I(t) + jX_Q(t)\\\\\nX_I(t) = X(t) \\cos \\omega_c t + \\hat X(t) \\sin (\\omega_c t)\\\\\nX_Q(t) = - X(t) \\sin \\omega_c t + \\hat X(t) \\cos (\\omega_c t)\\\\\n$$\n\n同样是顺时针旋转了 $2\\pi f_c t$ 之后得到了基带信号\n\n研究基带信号的实部、虚部的统计特性\n\n$\\tilde{X}(t)$ 还是一个平稳过程\n\n$$\nE \\lbrace \\tilde{X}(t) \\rbrace = E \\lbrace X_I(t) \\rbrace = E \\lbrace X_Q(t) \\rbrace = 0\\\\\nR_{X_I}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_Q}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_I}(\\tau) = R_{X_Q}(\\tau)\\\\\nR_{X_Q}(0) = R_{X_I}(0) = R_{X}(0)(三者方差一样)\\\\\n\\hat R_X(0) = 0(奇函数，不具备自相关函数的性质)\\\\\nS_{X_I}(f) = S_{X_Q}(f) = \\begin{cases}\n    S_X(f - f_c) + S_X(f + f_c), &|f| \\le f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n基带信号虚部和实部的互相关\n\n$$\nR_{X_IX_Q}(\\tau) = R_X(\\tau)\\sin(2\\pi f_c\\tau) - \\hat R_X(\\tau)\\cos (2\\pi f_c\\tau)，奇函数\n$$\n\n$$\nR_{X_IX_Q}(0) = 0\n$$\n\n因此同一时刻实部和虚部不相关。\n\n互谱密度\n\n$$\nS_{X_IX_Q}(f) = \\begin{cases}\n    jS_X(f + f_c) - jS_X(f - f_c), &|f| \\lt f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n只有当正频谱和负频谱分别跟 $f = \\pm f_c$ 对称时，互谱密度恒为0。此时，任意两个时间的虚部和实部信号都是不相关的。\n\n## 高斯过程\n\n### 定义\n\n随机向量$X = (X(t_1), \\dots, X(t_n))^T$ 服从 $n$ 元高斯分布，称为高斯过程。\n\n均值 $\\mu_k$ = $E \\lbrace X_k \\rbrace$\n\n协方差阵\n\n$$\n\\Sigma = E \\lbrace (X - \\mu)(X - \\mu)^T \\rbrace = \\begin{bmatrix}\n    b_{11}& \\dots &b_{1n}\\\\\n    \\vdots& \\ddots & \\vdots\\\\\n    b_{n1} & \\dots & b_{nn}\n\\end{bmatrix}\\\\\nb_{ij} = E \\lbrace (X_i - \\mu_i)(X_j - \\mu_j)^T \\rbrace\\\\\nb_{ij} = b_{ji}^* = b_{ji}\n$$\n\n做特征分解\n\n$$\n\\Sigma v_i = \\lambda_i v_i\\\\\nQ = (v_1, v_2, \\dots, v_n)正交阵, Q^{-1} = Q^T\\\\\n\\Sigma = Q\\text{diag}(\\lambda_1, \\dots, \\lambda_n)Q^T\\\\\n\\Sigma^{-1} = Q^T\\text{diag}(\\lambda_1^{-1}, \\dots, \\lambda_n^{-1})Q\n$$\n\n### 多元高斯分布\n\n$$\nf(x) = K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$\n\n线性变换以消去下标$ij$项：\n\n$$\n\\Sigma^{-1} = A^TA\\\\\ny = A(x - \\mu)\\\\\n(x - \\mu)\\Sigma^{-1}(x - \\mu)^T = y^Ty\n$$\n\n$$\n1 = K \\int \\dots \\int \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace \\mathrm dx_1 \\dots \\mathrm dx_n\\\\\nK = \\frac{1}{(\\sqrt{2\\pi})^n\\cdot \\sqrt{|\\Sigma|}}\n$$\n\n多元高斯矢量的特征函数\n\n$$\n\\omega = (\\omega_1, \\omega_2,\\dots, \\omega_n)^T\\\\\n\\Phi_X(\\omega) = E \\lbrace e^{j\\omega^TX} \\rbrace = E \\lbrace e^{j(\\omega_1 X_1 + \\omega_2 X_2 + \\dots + \\omega_n X_n)} \\rbrace = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T\\Sigma\\omega \\right \\rbrace\n$$\n\n特征函数不要求 $\\Sigma$ 可逆。概率密度函数要求 $\\Sigma$ 正定，特征值都大于0.\n\n当 $X$ 为高斯矢量时\n\n$$\n\\Phi_X(\\omega) = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu) \\right \\rbrace\\mathrm dx_1\\mathrm dx_2\\dots\\mathrm dx_n = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{y^Ty}{2} \\right \\rbrace \\sqrt{|\\Sigma|}\n$$\n\n高斯白噪声的协方差矩阵只有对角元，对角元为方差。\n\n可以用逼近处理 $|\\Sigma| = 0$：\n\n$$\n\\Sigma_K = \\Sigma + \\frac{1}{K}I\\\\\n\\Phi_X(\\omega) = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T \\left (\\Sigma + \\frac{1}{K}I  \\right)\\omega \\right \\rbrace\\\\\nf(x) = \\frac{1}{\\sqrt{2\\pi}^n \\sqrt{|\\Sigma_K|}} \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$\n\n然后再讨论 $K \\rightarrow \\infty$ 的情况。\n\n多元高斯矢量的边缘分布\n\n任取子矢量 $\\lbrace K_1, K_2, \\dots, K_m \\rbrace \\subseteq {1, 2, \\dots, n}$\n\n观察 $\\tilde{ X} = (X_{K_1}, X_{K_2}, \\dots, X_{K_m})^T$ 的分布\n\n$$\n\\tilde{\\Phi}(\\tilde\\omega) = E \\lbrace e^{j(\\omega_{K_1}\\tilde X_{K_1} + \\omega_{K_2}\\tilde X_{K_2} + \\dots + \\omega_{K_m}\\tilde X_{K_m})} \\rbrace = \\exp \\left \\lbrace  j\\tilde\\omega^T\\mu - \\frac{1}{2}\\tilde\\omega^T\\Sigma\\tilde\\omega \\right \\rbrace\n$$\n\n用置换矩阵 $P$ 将 $\\Sigma$ 的第 $K_1, K_2, \\dots, K_m$ 行、列移到 $\\Sigma$ 的左上角，对应的 $\\omega$ 也置换：\n\n$$\nP\\omega = \\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix}\\\\\nP^T\\Sigma P^T = \\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\n$$\n\n置换到左上角后，容易看出子矢量的特征函数可以通过将原矢量其他的$\\omega$置零得到，均值就是选择对应的均值，协方差矩阵就是把对应的行列元素抽出来：\n\n$$\n\\omega^T\\Sigma\\omega = (\\tilde{\\omega}, 0)^T\\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix} = \\tilde{\\omega}^T\\tilde{\\Sigma}\\tilde{\\omega}\n$$\n\n利用特征函数求数字特征：\n\n$$\n\\frac{\\partial^2\\Phi}{\\partial \\omega_k\\partial \\omega_l}|_{\\omega_k = \\omega_l = 0} = -(\\mu_l\\mu_k + b_{kl})\\\\\nE \\lbrace X_kX_l \\rbrace = \\mu_l\\mu_k + b_{kl}\n$$\n\n$$\nE \\lbrace X_1^{k_1}\\dots X_n^{k_n} \\rbrace = j^{\\sum\\limits_{i=1}^{n}k_i} \\frac{\\partial^{k_1 + k_2 + \\dots k_n}}{\\partial^{k_1}\\omega_1\\partial^{k_2}\\omega_2\\dots \\partial^{k_n}\\omega_n}\\bigg|_{\\omega_1 = \\omega_2 = \\dots = \\omega_n = 0}\n$$\n\n高斯的矢量分布的高阶矩完全由一阶矩 $\\mu$ 和二阶矩 $\\Sigma$ 决定。例如可以用特征函数推出：\n\n$$\n\\begin{align*}\n    &E \\left \\lbrace  X_1X_2X_3X_4 \\right \\rbrace \\\\\n    =& j^4 \\frac{\\partial^4\\Phi}{\\partial \\omega_1\\partial \\omega_2\\partial \\omega_3\\partial \\omega_4}\\bigg|_{\\omega_1 = \\omega_2 = \\omega_3 = \\omega_4 = 0} \\\\\n    =& E \\left \\lbrace  X_1X_2  \\right \\rbrace E \\left \\lbrace  X_3X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_3  \\right \\rbrace E \\left \\lbrace  X_2X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_4  \\right \\rbrace E \\left \\lbrace  X_2X_3  \\right \\rbrace\n\\end{align*}\n$$\n\n独立性\n\n独立性说的是统计，不相关说的是线性（二阶矩）\n\n一般来说\n\n$$\n独立 \\Rightarrow 不相关\\\\\n不相关 \\not \\Rightarrow 独立\n$$\n\n但是，对于高斯分布而言：\n\n$$\n独立 \\lrArr 不相关\n$$\n\n这是因为高斯分布完全由一阶和二阶矩决定。\n\n定理：\n\n$n$ 元向量 $X = \\binom{X_1}{X_2}$ 服从 $N(\\mu, \\Sigma)$，则 $X_1, X_2$ 独立 $\\lrArr$ $\\Sigma_{12} = 0$\n\n$$\n\\Sigma = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\n$$\n\n充分性：\n\n$$\n\\Sigma_{12} = E \\left \\lbrace (X_1 - \\mu_1)^T(X_2 - \\mu_2)  \\right \\rbrace = E \\left \\lbrace (X_1 - \\mu_1)\\right\\rbrace E\\left \\lbrace(X_2 - \\mu_2)  \\right \\rbrace = 0\n$$\n\n必要性：\n\n$$\nf(x_1, x_2) = \\frac{1}{(2\\pi)^{n/2}\\sqrt{|\\Sigma|}}\\exp \\left \\lbrace -\\frac{1}{2}\\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix}^T\\begin{pmatrix}\n    \\Sigma_{11}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix} \\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix} \\right  \\rbrace = f(x_1)f(x_2)\n$$\n\n可见 $X_1, X_2$ 统计独立。\n\n对于高斯过程：\n\n$$\n严平稳 \\lrArr 宽平稳\n$$\n\n即 $X(t_1), X(t_2), \\dots, X(t_n)$ 和 $X(t_1 + \\tau), X(t_2 + \\tau), \\dots, X(t_n + \\tau)$ 有相同的 $\\mu, \\Sigma$ 等价于具有相同的分布函数。\n\n线性变换\n\n定理： $X$ 服从高斯分布，矩阵 $C_{m\\times n}$， $Y = CX$，则 $Y$ 服从高斯分布 $N \\left(C\\mu, C \\Sigma C^T \\right)$。\n\n高斯过程经过微分，积分，滤波等线性操作，输出还是高斯过程。\n\n有一种重要的线性变换：去相关。\n\n$$\n\\Sigma_X = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\\\\\nY = \\begin{pmatrix}\n    Y_1\\\\Y_2\n\\end{pmatrix}= \\begin{pmatrix}\n    I & A\\\\\n    0 & I\n\\end{pmatrix}\\begin{pmatrix}\n    X_1\\\\X_2\n\\end{pmatrix}\\\\\nE \\left \\lbrace  (Y_1 - E(Y_1))(Y_2 - E(Y_2))^T \\right \\rbrace = \\Sigma_{12} + A\\Sigma_{22 } = 0\n$$\n\n需要\n\n$$\n-\\Sigma_{12}\\Sigma_{22}^{-1} = A\\\\\n$$\n\n计算协方差\n\n$$\nE \\left \\lbrace  (Y - E(Y))(Y - E(Y))^T \\right \\rbrace = \\begin{pmatrix}\n    \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix}\n$$\n\n去相关之后方差减小了。可以认为 $X_1 = Y_1 - AX_2$ 中，$- AX_2$是与 $Y$ “独立” 的“噪声项”，这个噪声导致了 $X_1$ 的方差大于去相关之后的 $Y$ 的方差。\n\n去相关与是否是高斯矢量无关。但是对于高斯矢量，去相关之后，两个矢量就独立了，具有重要的意义。\n\n对于一般的二阶矩过程，希望找到一个矩阵 $U$ ，使得 $Y = UX$ 的各个分量不相关：\n\n$$\nE \\left \\lbrace  (Y - \\mu_Y)(Y - \\mu_Y)^T \\right \\rbrace = \\text{diag}\\\\\nE \\left \\lbrace  U(X - \\mu_X)(X - \\mu_X)^TU^T \\right \\rbrace  = \\text{diag} = U\\Sigma U^T\n$$\n\n所以，本质上就是分析了协方差矩阵 $\\Sigma$ 的特征值。也就是二阶矩章节讲到的主成分分析：\n\n$$\n\\text{diag}(\\lambda_1, \\dots, \\lambda_n)\n$$\n\n选取 $\\lambda_i$ 大的特征矢量，张成主成分空间。\n\n信号处理中有信号空间（特征值大的）和噪声空间（特征值小的，被噪声掩盖了）。\n\n有时候 $Y$ 的各个分量不相关还不能完全消去元素之间的统计关系。只是线性不相关。不相关的约束实际上很弱。\n\n如果要设计 $U$，使得 $Y = UX$ 的各个分量独立，运算很复杂。\n\n但是，对于高斯矢量而言，不相关就是独立。所以对于高斯过程，主成分分析 $\\lrArr$ 独立成分分析。\n\n### 高斯变量的条件分布\n\n仍是高斯：\n\n$$\nf_{X_1|X_2}(x_1|x_2) = \\frac{1}{\\sqrt{\\tilde{\\Sigma}_{11}}(2\\pi)^{\\frac{n_1}{2}}}\\exp \\left \\lbrace -\\frac{1}{2}(x_1 - \\tilde{\\mu}_1)^T\\tilde{\\Sigma}_{11}^{-1}(x_1 - \\tilde{\\mu}_1)   \\right\\rbrace\\\\\nE \\lbrace X_1 | X_2 \\rbrace = \\mu_1 + \\Sigma_{12}\\Sigma_{22}^{-1}(X_2 - \\mu_2)\\\\\nE \\lbrace (X_1 - E(X_1 | X_2))(X_1 - E(X_1|X_2))^T|X_2 \\rbrace = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\n$$\n\n### 实高斯过程的若干性质\n\n实高斯过程完全由均值函数和协方差函数确定。\n\n严平稳等价于宽平稳。\n\n若实高斯过程均方可导，则 $\\lbrace X^\\prime(t) \\rbrace$ 也是高斯过程。\n\n高斯过程通过一般线性系统仍然是高斯过程。\n\n$$\nY(t) = \\int_{a}^{b}X(\\tau)h(t, \\tau)\\mathrm d\\tau\\\\\n更强的结论：\\left \\lbrace  \\binom{X(t)}{Y(t)} \\right \\rbrace 是高斯过程。\n$$\n\n### 零均值带通高斯过程\n\n$$\nZ(t) = X(t) + j \\hat X(t)\\\\\nX_B(t) = X_I(t) + j X_Q(t)\\\\\nV(t) = \\sqrt{X_I^2(t) + X_Q^2(t)}\\\\\n\\Theta(t) = \\arctan \\frac{X_Q(t)}{X_I(t)}\\\\\n$$\n\n此时有\n\n$$\nX(t) = V(t)\\cos(\\omega_ct + \\Theta(t))\\\\\n\\binom{X_I(t)}{X_Q(t)} = \\binom{\\ \\ \\ \\cos(\\omega_ct)\\quad \\sin(\\omega_c t)}{-\\sin(\\omega_ct)\\quad \\cos(\\omega_ct)}\\binom{X(t)}{\\hat X(t)}\n$$\n\n幅度为瑞利分布，相位为均匀分布，相互统计独立：\n\n$$\nf_V(v) = \\frac{v}{\\sigma^2}e^{-\\frac{v^2}{2\\sigma^2}}, v \\ge 0\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}, \\theta \\in [0, 2\\pi]\n$$\n\n### 随机相位正弦波信号叠加零均值带通高斯\n\n$$\nY(t) = A\\sin(\\omega_ct + \\Phi) + X(t)\n$$\n\n结果是幅度为莱斯分布，相位均匀分布，二者统计独立：\n\n$$\nf_{V(t)}(v) = \\frac{v}{\\sigma^2}\\exp(-\\frac{v^2 + A^2}{2\\sigma^2})I_0(\\frac{Av}{\\sigma^2})\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}\n$$\n\n### 高斯过程经过非线性函数\n\n限幅器\n\n$$\nh(x) = \\begin{cases}\n    1, x\\ge 0,\\\\\n    0, x \\lt 0\n\\end{cases}\n$$\n\n服从两点分布\n\n$$\nP(Y(t) = 1) = P(Y(t) = 0) = \\frac{1}{2}\\\\\nE_Y(t) = 0\\\\\nR_Y(t, s) = P \\lbrace X(t)X(s) \\ge 0 \\rbrace - P \\lbrace X(t)X(s) \\lt 0 \\rbrace\n$$\n\n$$\nP \\lbrace X(t)X(s) \\ge 0 \\rbrace = \\int_{0}^{\\infty}\\int_{0}^{\\infty}\\frac{1}{2\\pi\\sqrt{|\\Sigma|^{-1}}}\\exp((x_1\\ x_2)\\Sigma^{-1}\\binom{x_1}{x_2})\\mathrm dx_2\\mathrm dx_1 = \\frac{\\pi/2 + \\sin^{-1}(-\\rho)}{2\\pi}\n$$\n\n全线性检波（求绝对值）\n\n$$\nE(Y) = \\frac{2\\sigma}{2\\pi}\\int_{0}^{\\infty}\\frac{y}{\\sigma^2}\\exp(-\\frac{y^2}{2\\sigma^2})\\mathrm dy = \\sqrt{\\frac{2}{\\pi}}\\sigma\\\\\nR_Y(t, s) E \\lbrace |X(t)||X(s)| \\rbrace = \\frac{2\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace, \\rho = \\frac{R_X(t - s)}{\\sigma^2}\\\\\n\\int_{0}^{\\infty}\\int_{0}^{\\infty}x_1x_2\\frac{1}{2\\pi\\sigma^2\\sqrt{1 - \\rho^2}}\\exp(-\\frac{x_1^2 - 2\\rho x_1x_2 + x_2^2}{2\\sigma(1 - \\rho^2)})\\mathrm dx_1\\mathrm dx_2\n$$\n\n半波线性检波\n\n$$\nh(x) = \\begin{cases}\n    x, x\\ge 0,\\\\\n    0, x\\lt 0\n\\end{cases}\n$$\n\n$$\nR_Y(t, s) = \\frac{\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace\\\\\n$$\n\n平方率检波\n\n$$\nh(x) = x^2\n$$\n\n$$\nP(Y(t) \\le y) = P(-\\sqrt{y} \\le Y(t) \\le \\sqrt{y}) = 2\\Phi(\\frac{\\sqrt{y}}{\\sigma}) - 1\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\frac{1}{\\sqrt{y}}\\exp \\lbrace -\\frac{y}{2\\sigma^2} \\rbrace,\\ (y \\gt 0)\\\\\nE \\lbrace Y(t) \\rbrace = \\sigma^2\\\\\nR_Y(t,s) = E \\lbrace X^2(t_1)X^2(t_2) \\rbrace = \\sigma^2 + \\sigma^2 + \\rho\\sigma^2 + \\rho\\sigma^2 = 2(\\rho + 1)\\sigma^2\n$$\n\n基带信号的包络经过平方律检波\n\n$$\nX_I^2 + X_Q^2 = V^2 服从复指数分布\n$$\n\n### 高斯——马尔可夫性\n\n马尔可夫特性：\n\n$$\nf(x_n|x_1, \\dots, x_{n - 1}) = f(x_n|x_{n - 1})\n$$\n\n如果一个过程既是高斯的，又是马尔可夫的，会有很好的性质。\n\n对于零均值高斯分布：\n\n$$\nX(t) 是 \\text{Markov} \\lrArr R(t_1, t_3) = \\frac{R(t_1, t_2)R(t_2, t_3)}{R(t_2, t_2)}\n$$\n\n正向很好证明，反向证明的关键是计算均值和方差。\n\n$$\nX(t) 是 \\text{Markov} \\lrArr \\forall t_1\\le t_2\\le...\\le t_n, E \\lbrace X_n|X_1, X_2, \\dots, X_{n - 1} \\rbrace = E \\lbrace X_n|X_{n - 1} \\rbrace\n$$\n\n从右到左：条件协方差 $E\\lbrace (Y_1 - E \\lbrace Y_1|Y_2 \\rbrace)^2|Y_2\\rbrace = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}$ 跟 $Y_2$ 无关（这并不是说条件协方差和协方差具有相同的意义，只是数值上正好相等）\n\n$$\nE(X_n|X_{n - 1}) = \\frac{E(X_nX_{n - 1})}{E(X_{n - 1}^2)}X_{n - 1}\\\\\n$$\n\n残差与已有信息正交：\n\n$$\nE \\lbrace [X_n - E(X_n | X_{n - 1})] \\cdot X_k \\rbrace = 0, k = 1, 2, \\dots, n - 1\\\\\n$$\n\n类似于最小二乘估计：\n\n$$\nX_n - \\alpha_n X_{n - 1} 是一个高斯过程，与 X_1, X_2, \\dots, X_n 独立\n$$\n\n自回归方程：\n\n$$\nX_n = \\alpha_n X_{n - 1} + \\beta_nY_n\\\\\nY_n \\sim N(0, 1)\n$$\n\n### Brown 运动\n\n从一维随机游走开始：\n\n$$\nP \\lbrace X_i = a \\rbrace = P \\lbrace X_i = -a \\rbrace = \\frac{1}{2}\\\\\nY =\\sum\\limits_{i=1}^{\\infty}X_i\n$$\n\n令 $t = nT$，固定 $t$，令 $n \\rightarrow \\infty$，由 CLT 可知成为一个高斯分布：\n\n$$\nE(Y) = 0\\\\\nD(Y) = \\frac{t}{T}a^2\\\\\n\\frac{a^2}{T} = \\beta\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sqrt{\\beta t}}\\exp (-\\frac{y^2}{2\\beta t})\n$$\n\n随着时间增加，不确定性越来越大。\n\n标准布朗运动：\n\n（1）$B(t)$ 满足独立增量，平稳增量\n（2）$B(t)$ 的每个样本轨道都是连续的\n（3）$\\forall t, B(t)$ 遵循高斯分布，均值0，方差 $t$\n\n$$\nf_t(x) = \\frac{1}{\\sqrt{2\\pi t}}\\exp (-\\frac{x^2}{2t})\n$$\n\n布朗运动是高斯白噪声的积分：\n\n$$\nY(t) = \\int_{0}^{t}X(u)\\mathrm du\n$$\n\n可见布朗运动的不规则。\n\n## Markov 过程\n\n### Markov 链\n\n一种状态离散、时间离散的随机过程。\n\n### Markov 特性\n\n\n\n马尔可夫特性的一种表示：\n\n在已知现在的条件下，过去与将来独立。\n\n$$\nP(C,A | B) = P(C | B, A) \\cdot P(A|B) = P(C|B)P(A|B)\n$$\n\n其他表示：过去用集合事件表示\n\n$$\nP \\lbrace X_{n+1}=j|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}=j|X_n=i \\rbrace\n$$\n\n进一步，过去是一个集合，未来也是一个集合：\n\n$$\nP \\lbrace X_{n+1}\\in B|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}\\in B|X_n=i \\rbrace\n$$\n\n但是，变量“现在”必须取值为一个确定的值，不能是一个集合。对现在的状态一定要精确掌握，不能放宽约束。\n\n口号：从小事做起（泊松），从现在做起（马尔可夫）\n\n转移概率\n\n$$\nP_{ij}(m, n) = P \\lbrace X_n = a_j | X_m = a_i \\rbrace\n$$\n\n$$\nP_{ij}(m, n) \\ge 0\\\\\n\\sum\\limits_{j}^{}P_{ij}(m, n) = 1\n$$\n\n一步转移概率：\n\n$$\nP_{ij}(m, m + 1) 或 P_{ij}(m)\n$$\n\n状态转移矩阵\n\n观察变量族的联合分布\n\n### 齐次马尔科夫链的迭代表示\n\n$$\nX_0 \\xrightarrow{Z_1} X_1 \\xrightarrow{Z_2} X_2 \\dots \\xrightarrow{Z_n} X_{n}\n$$\n\n$$\nX_{n+1} = f(X_n,Z_{n+1}) = P \\lbrace X_{n+1} = j | X_n = i \\rbrace\n$$\n\n也称为新息过程\n\n### 一维随机游走\n\n吸收壁\n\n反射壁 - 完全反射壁\n\n成功逃跑\n\n等待服务人数\n\n$$\nX_{n + 1} = \\begin{cases}\n    X_n - 1 + Y_{n + 1}, X_n \\ne 0\\\\\n    Y_{n + 1}, X_0\n\\end{cases}\\\\\nP = \\begin{bmatrix}\n    a_0 & a_1 & a_2 & \\dots\\\\\n    a_0 & a_1 & a_2 & \\dots\\\\\n        & a_0 & a_1 & \\dots\\\\\n        &     & a_0 & \\dotsb\n\\end{bmatrix}\n$$\n\n### 柯尔莫格洛夫方程\n\n多步转移矩阵概率\n\n$$\nP_{ij}(m, n) = \\sum_k P(X_n = j | X_r = k) \\cdot P(X_r = k | X_m = i)\n$$\n\n或者表示为\n\n$$\nP_{ij}^{(p + q)} = \\sum_{k \\in \\Omega} P_{ik}^{(p)} P_{kj}^{(q)}\n$$\n\n由于上面转移阵步数 $p, q$ 的任意性，多步跳变矩阵可以转变为矩阵相乘：\n\n$$\nP^{(L)} = P^{(L - 1)}P^{(1)} = ... = P^L\n$$\n\n求多步转移矩阵：适用于齐次马尔可夫\n\n齐次马尔可夫链的 $P$ 与时间起点无关\n\n先求 $P^{(n)} = P^n$，再看 $[P^n]_{ij}$ 就是要求的转移概率。\n\n如何求 $P^n$ ？\n\n首先做特征分解 $PU = U\\Lambda$\n\n$$\nP^n = U \\Lambda^nU^{-1}\n$$\n\n二元通信信道\n\n$$\nP  = \\begin{pmatrix}\n    1 - \\alpha & \\alpha\\\\\n    \\beta & 1 - \\beta\n\\end{pmatrix}\\\\\nU = \\begin{pmatrix}\n    1 & -\\alpha\\\\\n    1 & \\beta\n\\end{pmatrix}\n$$\n\n\n$$\nP^n = \\frac{(1 - \\alpha - \\beta)^n}{\\alpha + \\beta}\\begin{pmatrix}\n    \\alpha & -\\alpha\\\\\n    -\\beta & \\beta\n\\end{pmatrix} + \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$\n\n在 $|1 - \\alpha - \\beta| < 1$ 的条件下，无穷步跳变后：\n\n$$\nP^n = \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$\n\n各列相等，说明这个马尔可夫链与初始状态无关，历史被淡忘——马尔可夫性。\n\n\n$1 - \\alpha - \\beta = -1$ 时，极限不存在\n\n$$\nP = \\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\\\\\n\\end{pmatrix}\n$$\n\n### 状态分类\n\n可达性：$\\exists m, s.t. P_{ij}^{(m)} > 0$\n\n互通性：$\\exist m, n, s.t. P_{ij}^{(m)} > 0, P_{ji}^{(n)} > 0$，是等价关系。\n\n不可约(irreducible)，不可分\n\n马尔可夫链中每两个状态都是互通的，也叫互通链。\n\n闭集：$\\forall i \\in C, j\\not \\in C, i \\not \\rightarrow j$\n\n不可约的另一定义：除了把整个链作为闭集，不存在取其中一些状态构成其他闭集了。\n\n激励状态\n\n稳定状态（闭集）\n\n一般情况，Markov 链的转移矩阵行列重排后可化为：\n\n$$\nP = \\begin{pmatrix}\n    u_1\\\\\n    &u_2\\\\\n    &&\\ddots\\\\\n    &&&u_k\\\\\n    v_1&v_2&\\dots&v_k&v_{k+1}\n\\end{pmatrix}\n$$\n\n对闭集而言，可以在闭集内使用柯尔莫格洛夫方程：\n\n$$\nP_{ij}^{(n + m)} =\\sum\\limits_{r\\in \\Omega_1}^{}P_{ir}^{(n)}P_{rj}^{(m)}\n$$\n\n首次达到时间：$T_{ij}(\\omega) = \\min \\lbrace n: X_0(\\omega) = i, X_n(\\omega) = j, n \\ge 1 \\rbrace$\n\n$$\nT_{ij} \\in [1, 2, ..., \\infty)\n$$\n\n首次到达概率\n\n$$\nf_{ij}^{(n)} = P \\lbrace T_{ij} = n| X_0 = i \\rbrace\n$$\n\n此时有\n$$\nf_{ij}^{(1)} = P_{ij}\n$$\n\n定义\n\n$$\nf_{ij} =\\sum\\limits_{k=1}^{\\infty^-} f_{ij}^{(k)}\n$$\n\n为迟早到达的概率。\n\n$$\nf_{ij}^{(\\infty)} = 1 - f_{ij}\n$$\n\n表示永远无法到达的概率。\n\n定理：\n\n$$\nP_{ij}^{(n)} =\\sum\\limits_{r=1}^{n} f_{ij}^{(r)}P_{jj}^{(n - r)}\n$$\n\n考虑 $P_{ij}^{(0)} = \\delta_{ij}$，上述可以写成卷积形式：\n\n$$\nF_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^r\\\\\nG_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^{r}\\\\\nG_{ij}(z) = \\delta_{ij} + F_{ij}(z)G_{jj}(z)\n$$\n\n$$\ni \\rightarrow j \\lrArr  f_{ij} \\gt 0\n$$\n\n### 常返性\n\n#### 常返与非常返\n\n若 $f_{ij} = 1$，称状态 i 为常返态\n\n令 $z = 1$：\n\n$$\nG_{ij}(1) = \\delta_{ij} + F_{ij}(1)G_{jj}(1)\\\\\ni = j \\rArr G_{ii}(1) = \\frac{1}{1 - F_{ii}(1)} \\rArr \\sum_{n = 0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}}\n$$\n\n常返性判别：\n\n$$\n常返态 \\lrArr f_{ii} = 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = +\\infty\\\\\n非常返态 \\lrArr f_{ii} \\lt 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}} < +\\infty\\\\\n$$\n\n后面会证明，这种返回的次数都是无穷大。\n\n常返的理解：\n\n$$\n\\forall n, A_n = \\begin{cases}\n    A_n = 1, X_n = i,\\\\\n    A_n = 0, X_n \\ne i.\n\\end{cases}\n$$\n\n$$\nE \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k | X_0 = i \\rbrace = \\sum\\limits_{k=0}^{\\infty}P_{ii}^{(0)}\\\\\n$$\n\n从判别定理可以看出，在期望意义上，常返态被无限次访问。\n\n推论1：既然常返态被无穷次返回，非常返态被有限次访问，则在有限状态的 Markov 链中一定存在常返态。\n\n反证法：如果全是有限返回次数，那所有态的访问次数加起来还是有限的，但是马尔可夫可以访问无限次，矛盾。所以一定有常返态。\n\n推论1.1：如果非常返态的个数有限，则足够长的时间后，状态一定会到达常返态。\n\n推论1.2：若 j 非常返，则$\\forall i$\n\n$$\n\\sum\\limits_{n=0}^{\\infty}P_{ij}^{(n)} < \\infty (i 到达 j的次数为有限值)\\\\\n\\lim_{n \\rightarrow \\infty} P_{ij}^{(n)} = 0\n$$\n\n推论2：若 $i$ 常返，$i \\lrarr j$，则 $j$ 也是常返的。\n\n推论3：若 $i$ 为常返，$i \\rarr j$，则 $j \\rarr i$\n\n#### 正常返与零常返\n\n$f_{ii}^n$ 可以视为首次返回时间 $T_{ii}$ 的概率分布。对于非常返态不能这么看，因为 $f_{ii} < 1$。\n\n对于常返态的 $T_{ii}$，可以计算期望\n\n$$\n\\mu_i = E \\lbrace T_{ii} \\rbrace = \\sum\\limits_{n = 1}^{\\infty} n f_{ii}^{(n)}\n$$\n\n若均值为无穷大，则称为零常返。\n\n零常返与非常返是有区别的。零常返是可以常返，只是大概率步数很多。\n\n定义返回的速率，可推导\n\n$$\n\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\sum\\limits_ {k=0}^{n - 1} P_{jj}^{(k)} = \\frac{1}{\\mu_j}\n$$\n\n正常返意味着速率为常数，零常返意味着速率为 0。\n\n判定定理：\n\n$$\nj 状态零常返 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{jj}^{(n)} = \\infty, 且 n \\rightarrow \\infty 时，P_{jj}^{(n)} = 0\n$$\n\n条件一就是常返的判定定理。条件二比较特殊：\n\n$$\n\\lim_{n \\rightarrow \\infty}P_{jj}^{(n)} = \\frac{1}{\\mu_j}\n$$\n\n如果是零常返，这个极限就是0。在条件二上，零常返和非常返是一样的。\n\n定理：常返态 $i$，$i \\rarr j$，则 $i, j$ 同为正常返或者零常返\n\n#### 补充性质\n\n$$\nq_{jj}(M) = P \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k \\ge M | X_0 = j \\rbrace\\\\\n\\lim_{M \\rarr \\infty}q_{jj}(M) = \\begin{cases}\n    1, f_{jj} = 1\\\\\n    0, f_{jj} < 1\\\\\n\\end{cases}\n$$\n\n下面研究常返态 $j$，不可约链\n\n“从常返态触发，返回次数为无穷大”这件事的概率为 1.\n\n$$\n\\lim_{M \\rarr \\infty} q_{rj}(M) = 1, \\forall\n$$\n\n“任意状态访问常返态的次数为无穷大”的概率为1.\n\n$$\nq_{ij}(M) = f_{ij}q_{jj}(M)\n$$\n\n两边取极限可得 $f_{ij} = 1$\n\n结论3： 从不可约链任何状态出发，迟早访问状态 $j$\n\n$$\n\\lim_{n \\rarr \\infty} P_{ij}^{(n)} = \\frac{1}{\\mu_j}\n$$\n\n结论4：极限概率与初始状态无关。\n\n分类方式\n\n对于每个常返态 i，存在一个 i 可达状态构成的状态集 C 。则这些状态彼此相通，构成一个不可约闭集，都常返\n\n马尔可夫链可以唯一划分为 $C_1, C_2, ..., T$，其中 $C_i$ 互为不相交的不可约闭集。T 为非常返态。每个闭集中，常返类型一致，不同闭集不互通。\n\n定理：马尔科夫链若有一个零常返，有无穷多个零常返。\n\n推论：有限状态马尔可夫链的常返态必然为正常返。\n\n#### 马尔可夫链的平稳分布和极限概率\n\n对于不可约链：\n\n$$\n\\lim_{n \\rarr \\infty}P_{ij}^{(n)} = 0，j非常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j} = 0，j零常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j}，j正常返\n$$\n\n极限概率用 $\\pi_j$表示\n\n对于非常返和零常返，极限概率都是0。零常返的链一定有无穷个状态。\n\n对于正常返，$\\pi_j \\gt 0, \\sum\\limits_{j\\in S}^{}\\pi_j = 1$\n\n从柯式方程得出：\n\n$$\n\\pi_j = \\sum\\limits_{i}^{}\\pi_iP_{ij}\n$$\n\n矩阵形式：\n$$\n\\lim_{n \\rarr \\infty} P^n = \\Pi = \\begin{bmatrix}\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n\\end{bmatrix}\n$$\n\n\n## 泊松过程\n\n### 定义\n\n#### 计数过程\n\n在 $[0, t]$ 内发生某类事件的次数记为 $\\lbrace N(t), t\\ge 0 \\rbrace$，则称 $\\lbrace N(t) \\rbrace$ 为计数过程。\n\n#### 泊松过程\n\n若满足以下条件：\n\n1. $N(0) = 0$\n2. 非负性：$N(t)$ 的取值非负整数；\n3. 非降性：$N(t)$ 是随时间单调不减的；\n4. 独立增量性：对于 $0 \\le t_1 < t_2 < \\ldots < t_n$，$N(t_2) - N(t_1), N(t_3) - N(t_2), \\ldots, N(t_n) - N(t_{n-1})$ 是相互独立的随机变量；\n5. 平稳增量性：对于 $0 \\le s < t$，$N(t) - N(s)$ 的分布只与时间间隔 $t-s$ 有关，而与具体的时刻 $s$ 无关。\n6. $P(N(t + \\Delta t) - N(t) = 1) = \\lambda\\Delta t + o(\\Delta t), P(N(t + \\Delta t) - N(t) \\ge 2) = o(\\Delta t)$\n则称 $\\lbrace N(t), t\\ge 0 \\rbrace$ 为泊松过程。\n\n### 性质\n\n泊松的表达式\n\n$$\nP_n(t) = P(N(t) = n) = \\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}\n$$\n\n泊松分布的特征函数\n\n$$\n\\phi_{N(t)}(\\omega) = \\exp \\left \\lbrace \\lambda t (e^{j\\omega} - 1) \\right \\rbrace\n$$\n\n泊松过程的数字特征\n\n$$\nE(N(t)) = \\lambda t\\\\\nR(t_1, t_2) = \\lambda t_1 + \\lambda^2 (t_1t_2) (t_1 \\le t_2)\\\\\nC(t_1, t_2) = \\min \\lbrace t_1, t_2 \\rbrace\n$$\n\n### 泊松与二项分布\n\n泊松分布是二项分布的极限。\n\n泊松脉冲串：\n\n$$\nX(t) = \\frac{\\mathrm dN(t)}{\\mathrm dt} = \\sum\\limits_{i}^{}\\delta(t - t_i)\\\\\nE(X(t)) = \\lambda\n$$\n\n### 泊松相关问题\n\n#### 事件间隔时间的分布\n\n$S_n$ 表示第 n 件事到达的时刻\n\n$T_n$ 表示相邻两件事发生的间隔\n\n$$\nP\\lbrace S_n \\gt t \\rbrace = P \\lbrace N(t) \\le n - 1 \\rbrace\n$$\n\n$$\nf_{T_n}(t) = \\lambda e^{-\\lambda t}\\\\\nE(T_n) = 1 / \\lambda\n$$\n\n$T_n$ 和 $T_m$ 是独立的。\n\n#### 等待时间的分布\n\n概率密度函数与特征函数互为傅里叶变换\n\n$$\n\\Phi_{T_i}(\\omega) = \\frac{\\lambda}{\\lambda - j\\omega}\\\\\n\\Phi_{S_n}(\\omega) = \\left (\\frac{\\lambda}{\\lambda - j\\omega}  \\right)^n\\\\\n$$\n\n要求 $S_n$ 的概率密度函数，可以看作 $T_n$ 的卷积：\n\n$$\nf_{S_n}(t) = \\frac{(\\lambda t)^{n - 1}}{(n - 1)!}\\lambda e^{-\\lambda t}\\\\\n$$\n\n称为 $\\Gamma$ 分布，参数 $\\lambda, n$。\n\n#### 相邻两次事件之间的计数\n\n两次公交车到来（速度 $\\mu$）之间，等车人数（速度 $\\lambda$）的计数：\n\n$$\nP(L = k) = (\\frac{\\mu}{\\mu + \\lambda})(\\frac{\\lambda}{\\mu + \\lambda})^k\n$$\n\n#### n个事件到达时间的的联合分布\n\n$$\nf_{S_1...S_n|N(t) = n}(u_1, u_2, ..., u_n) = \\frac{n!}{t^n}\n$$\n\n如果是有编号的（不是按顺序到达）：\n\n$$\nf_{V_1...V_n|N(t) = n}(t_1, t_2, ..., t_n) = \\frac{1}{t^n}\n$$\n\n以下分布的极限，就是泊松过程：\n\n$$\nP \\lbrace N(s) = k | N(t) = n \\rbrace = \\binom{n}{k}(\\frac{\\lambda s}{n})^k(1 - \\frac{\\lambda s}{n})^{n - k}\n$$\n\n#### 总结泊松过程的几种定义\n\n1. N(0) = 0，独立增量，平稳增量，$\\Delta t$ 内发生一个事件的概率 $\\lambda \\Delta t$，发生两件事以上的概率小\n2. 事件时间间隔独立同分布，服从复指数分布，则计数为泊松\n3. N 个客体随机地分布在 $[0, t]$ 区间上，每个客体的出现时间均匀分布，且相互时间独立，当 $n \\rightarrow \\infty, t \\rightarrow \\infty$，极限分布为泊松分布\n4. 二项分布的极限\n\n### 顺序统计量\n\n统计量是样本的某个函数 $g(X_1, ..., X_n)$。例如：最大值、中值、平均值、样本协方差阵\n\n顺序统计量：根据到达时刻排序。例如 $S_1, S_2, ..., S_n$ 就是 $V_1, V_2, ..., V_n$ 的顺序统计量\n\n$$\nf_{Y_k}(x) = \\binom{n}{k - 1}F(x)\\binom{n - k + 1}{1}f(x)(1 - F(x))^{n - k}\n$$\n\n有序的顺序统计量的分布：\n\n$$\nf_{Y_1...Y_n}(y_1, y_2, ..., y_n) = n!f(y_1)f(y_2)...f(y_n)\n$$\n\n### 非齐次泊松过程\n\n四个条件：\n\n$N(0) = 0$\n\n$N(t)$ 独立增量\n\n$P(N(t + \\Delta t) - N(t) = 1) = \\lambda(t)\\Delta t + o(\\Delta t)$\n\n$P(N(t + \\Delta t) - N(t) \\ge 2) = o(\\Delta t)$\n\n定理：\n\n$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{[m(t_0 + t) - m(t_0)]^n}{n!}e^{-[m(t_0 + t) - m(t_0)]}\n$$\n\n其中，\n\n$$\nm(t) = \\int_{0}^{t}\\mathrm \\lambda(u) du\n$$\n\n其意义可以理解为事件的个数。\n\n令 $m(t + t_0) - m(t_0) = \\alpha$\n\n$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{\\alpha^n}{n!}e^{-\\alpha}\n$$\n\n则期望和方差\n\n$$\nE(N(t_0 + t) - N(t_0)) = \\alpha\\\\\nV(N(t_0 + t) - N(t_0)) = \\alpha\n$$\n\n### 复合泊松\n\n$Y_n$ 随机变量族，$N(t)$ 泊松过程，称$X(t) = \\sum_{n = 1}^{N(t)}Y_n$ 为复合泊松。\n\n$$\nE \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i \\rbrace\\\\\nD \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i^2 \\rbrace\\\\\nG_X(z) = \\exp(\\lambda t G_Y(z) - 1)\\\\\n\\phi_X(\\omega) = \\exp(\\lambda t \\phi_Y(\\omega) - 1)\n$$\n\n### 随机参数泊松\n\n参数 $\\lambda$ 是随机变量，PDF为 $f(\\lambda)$\n\n* 是平稳增量\n* 不是独立增量\n\n$$\nP(Y(t) = n) = \\int^{+\\infty}_{0}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda\n$$\n\n母函数：\n\n$$\nG_{Y(t)}(z) = \\int_{0}^{\\infty}\\exp (\\lambda t(z - 1))f(\\lambda)\\mathrm d\\lambda\n$$\n\n$$\nE(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\nV(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\n$$\n\n数据统计的后验分布\n\n$$\nP(\\Lambda \\le x | Y(t) = n) = \\frac{\\int_{0}^{x}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\\\\\nf_\\Lambda(x|Y(t) = n) = \\frac{\\frac{(x t)^n}{n!}e^{-x t}f(x)}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\n$$\n\n### 过滤的泊松过程\n\n统计一段时间影响的总和\n\n$$\nY(t) = \\sum\\limits_{i=1}^{N(t)}h(t, S_i, A_i)\n$$\n\n特征函数：\n\n$$\n\\Phi_{Y(t)}(\\omega) = \\exp \\left ( \\lambda t \\left ( \\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv - 1\\right) \\right)\n$$\n\n均值：\n\n$$\nE(Y(t)) = \\frac{1}{j}\\frac{\\partial \\Phi_{Y(t)}}{\\partial \\omega} = \\underbrace{\\lambda t}_{平均到达个数} \\underbrace{\\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv}_{每个事件在 t 时刻的影响}\n$$\n\n## 生灭过程\n\n该过程状态可以用整数序列 $n = 0, 1, 2, 3, ...$ 来表示\n\n状态转移只能发生在临近状态之间\n\n在$[t, t + \\Delta t)$ 区间内，n状态转移到 $n + 1$ 状态的概率为 $\\lambda \\Delta t$， 转移到 $n - 1$ 状态的概率为 $\\mu \\Delta t$。\n\n### M/M/1\n\n系统平均顾客人数 $L = \\frac{\\lambda / \\mu}{1 - \\lambda / \\mu}$\n\n排队平均人数\n\n$$\nL_Q = \\sum\\limits_{n=1}^{\\infty}(n - 1)p_n = \\frac{\\lambda^2}{(\\mu - \\lambda)\\mu}\\\\\nL_Q \\ne L - 1\n$$\n\n前面有一个人，等待时间：负指数分布的无记忆性\n\n$$\nf_T(t|T > t_0) = \\mu e^{-\\mu (t - t_0)}\n$$\n\n从而不管你什么时候来，平均等待时间为 $1/\\mu$，和一个人被服务的时间是一样的。\n\n## 习题课\n\n![alt](../images/stochastic/exer_1.jpg)\n\n","source":"_posts/Stochastic-Process.md","raw":"---\ntitle: Stochastic-Process\nkatex: true\ndate: 2023-09-21 10:10:49\ntags: note\n---\n\n## 随机过程随机过\n\n信号与系统：研究确定信号随着时间、空间的变化\n\n概率论：研究随机信号，但是不随时间、空间变化\n\n随机过程：研究随机的信号随着时间、空间的变化\n\n> 期末70分梭哈\n> \n> 考试题目不随机，就跟不上这门课的要求。\n\n### 概率与随机变量回顾\n\n样本空间$\\Omega$\n\n性质：\n* 非负性：$P(A) \\ge 0$\n* 规范性：$P(\\Omega), P(\\emptyset) = 0$\n* 可加性：$P(\\bigcup\\limits_{k = 1}^{\\infty}A_k) = \\sum\\limits_{k=1}^{\\infty}P(A_k)$\n\n贝叶斯：\n\n$$\nP(B_i|A) = \\frac{P(A|B_i)P(B_i)}{\\sum\\limits_{j = 1}^{k}P(B_j)P(A|B_j)}\n$$\n\n随机变量：\n\n分布函数，概率密度函数\n\n期望，方差，协方差，相关系数\n\n伯努利分布，高斯分布，泊松分布，瑞利分布\n\n伯努利分布的概率密度函数：\n\n当$k=1$时，$P(X=1) = p$\n当$k=0$时，$P(X=0) = 1-p$\n\n高斯分布的概率密度函数：\n$P(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$\n\n二维高斯分布的概率密度函数：\n\n$P(x,y) = \\frac{1}{2\\pi\\sigma_x\\sigma_y\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left[\\frac{(x-\\mu_x)^2}{\\sigma_x^2}-2\\rho\\frac{(x-\\mu_x)(y-\\mu_y)}{\\sigma_x\\sigma_y}+\\frac{(y-\\mu_y)^2}{\\sigma_y^2}\\right]\\right)$\n\n其中，$\\mu_x$和$\\mu_y$是均值，$\\sigma_x$和$\\sigma_y$是标准差，$\\rho$是相关系数。\n\n泊松分布的概率密度函数：\n$P(k;\\lambda) = \\frac{\\lambda^k}{k!}\\exp(-\\lambda)$\n\n瑞利分布的概率密度函数：\n$P(x;\\sigma) = \\frac{x}{\\sigma^2}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$\n\n### 随机过程的基本概念\n\n定义：\n\n给定概率空间$(\\Omega, \\mathcal{F}, P)$，定义参数集$T \\subset R$，$t \\in T$\n\n$$\nX = \\lbrace X(t, \\omega), t \\in T, \\omega \\in \\Omega \\rbrace\n$$\n\n简记为$X(t)$: $X = \\lbrace X(t), t \\in T\\rbrace$\n\n解释：\n\n* 二元单值函数\n* 对每个固定t，$X(t, \\omega)$是一个随机变量\n* 每个$\\omega_0 \\in \\Omega$, $X(t, \\omega_0)$是定义在T上的函数，记为$x(t, \\omega_0)$\n\n单样本为随机变量：均值、方差、协方差、有限维联合分布等\n\n随机过程的函数特性：时间的相关性，连续性和离散性，随机过程的导数、微分、积分、卷积、级数展开、微分方程、积分方程等\n\n二重性的联合特征：\n\n分类：\n\n离散时间，离散分布：Bernouli过程\n\n离散时间，连续分布：自回归过程\n\n连续参数离散随机过程：Poission过程\n\n连续参数连续型随机过程：Brown运动\n\n数学特征：\n\n相互独立和不相关是两个概念，无必然因果联系。\n\n根据数字特征分类：\n\n* 独立增量过程\n* 平稳过程及二阶矩过程\n* 马尔可夫过程\n* 更新过程\n\n独立增量过程是一种随机过程，具有以下特性：\n\n1. 零起点：独立增量过程在零时刻（通常表示为$t=0$）的取值为零，即$X(0) = 0$。\n\n2. 独立增量：对于任意时刻$t_1 < t_2 < \\cdots < t_n$，随机变量$X(t_2)-X(t_1), X(t_3)-X(t_2), \\cdots, X(t_n)-X(t_{n-1})$是相互独立的。\n\n若对一切$0\\le s \\lt t$，增量$X(t) - X(s)$的分布仅依赖于$t - s$，则称之为平稳增量，具有平稳增量的独立增量过程称为独立平稳增量过程，例如泊松和布朗。\n\n二阶矩过程：$D(X(t))$\n\n宽平稳过程：\n\n宽平稳过程可以用以下简单的数学表达式表示：\n\n1. 均值平稳性：对于宽平稳过程 $X(t)$，其均值满足 $E[X(t)] = \\mu$，其中 $\\mu$ 是一个常数。\n\n2. 自相关平稳性：宽平稳过程的自相关函数在时间差 $\\tau$ 下为常数，可以表示为 $R_X(\\tau) = R_X(t,t+\\tau) = \\text{常数}$，其中 $R_X(\\tau)$ 表示宽平稳过程的自相关函数。\n\n严平稳过程（Strict-sense stationary process），也称为严格平稳过程或强平稳过程，是一种具有更强平稳性质的随机过程。它满足以下两个条件：\n\n1. 时移不变性：严平稳过程的统计性质在时间上任意平移保持不变。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，随机变量 $X(t)$ 和 $X(t+\\tau)$ 的联合分布相同，即联合分布满足 $P(X(t) \\in A, X(t+\\tau) \\in B) = P(X(0) \\in A, X(\\tau) \\in B)$，其中 $A,B$ 是任意集合。\n\n2. 自相关平稳性：严平稳过程的自相关函数只与时间差有关，与参考时刻无关。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，自相关函数满足 $R_X(t,t+\\tau) = R_X(\\tau)$，其中 $R_X(\\tau)$ 表示严平稳过程的自相关函数。\n\n马尔可夫过程是一种具有马尔可夫性质的随机过程。它可以用以下公式和概念来定义：\n\n1. 状态空间：马尔可夫过程的状态空间是一个离散集合，表示可能的状态集合。通常用符号 $S$ 表示，$S = \\{s_1, s_2, \\ldots\\}$。\n\n2. 马尔可夫性质：马尔可夫过程具有马尔可夫性质，也称为无后效性。即，在给定当前时刻的状态 $X(t)$ 之下，未来的状态 $X(t+\\Delta t)$ 只依赖于当前的状态 $X(t)$，与过去的状态 $X(t-1), X(t-2), \\ldots$ 无关。\n\n3. 转移概率：转移概率描述了在给定当前状态 $s_i$ 的情况下，马尔可夫过程在下一个时刻转移到状态 $s_j$ 的概率。转移概率通常用符号 $P_{ij}$ 表示，即 $P_{ij} = P(X(t+\\Delta t) = s_j \\mid X(t) = s_i)$。\n\n通过状态空间和转移概率，可以构建一个马尔可夫过程的状态转移矩阵（Transition Matrix），它描述了从一个状态到另一个状态的转移概率情况。\n\n更新过程：\n\n更新过程可以使用以下公式来描述：\n\n1. 到达时间：假设到达时间的随机变量序列为 $T_1, T_2, T_3, \\ldots$，其中 $T_i$ 表示事件 $i$ 的到达时间。\n\n2. 描述参数：更新过程的到达率（或强度）表示单位时间内平均发生事件的次数。通常用符号 $\\lambda$ 表示，即 $\\lambda = \\lim_{t \\to \\infty} \\frac{N(t)}{t}$，其中 $N(t)$ 表示时间 $t$ 之前（包括 $t$）发生的事件次数。\n\n3. 插值函数：更新过程的插值函数（或插值过程）表示给定时间 $t$ 时，最近的到达时间是多久之前。记为 $S(t)$，即 $S(t) = \\sup\\{T_i \\leq t\\}$，表示最近的到达时间小于等于 $t$ 的时间点。\n\n\n可以定义复随机过程：\n\n\n复随机过程是一组复数值随机变量的集合 $\\{X(t), t \\in T\\}$，其中 $X(t)$ 是定义在概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数值随机变量，表示在时间点 $t$ 上的取值。\n\n具体而言，对于每个时间点 $t \\in T$，$X(t)$ 是一个复数值随机变量，可以表示为 $X(t) = R(t) + iI(t)$，其中 $R(t)$ 和 $I(t)$ 分别表示实部和虚部。\n\n复随机过程可以通过概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数随机变量以及时间参数 $T$ 来描述，并且在不同时间点上表现出复数值随机变量的随机性质。\n\n数学特征：\n\n均值函数（一阶原点矩）：$\\mu_X(t) = E[X(t)]$\n\n方差函数：$\\text{Var}[X(t)] = E[(X(t) - \\mu_X(t))(X(t) - \\overline{\\mu_X(t)} )]$\n\n自相关函数：$R_X(t_1, t_2) = E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$\n\n自协方差函数：$\\text{Cov}[X(t_1), X(t_2)] = E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$\n\n均方值函数：$E[|X(t)|^2] = \\int_{-\\infty}^{\\infty} |x|^2 f_X(x,t)dx$\n\n### 基本研究方法\n\n* 相关方法\n* Markov 方法\n\n**相关**\n\n若随机过程在任意时刻的均值和方差都存在，则称之为二阶矩过程（second order process），即均方可积空间上的随机变量。\n\n均方可积空间是内积空间。相关运算是均方可积的内积运算：\n\n$$\n\\langle X, Y \\rangle = E(X\\overline Y)\n$$\n\n\n宽平稳（wide-sense stationary）:\n\n$$\nR_X(t, s) = R_X(t + D, s + D) = R(t - s)\n$$\n\n功率谱密度：\n\n$$\nS_X(\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\exp(-j\\omega\\tau)\\mathrm d\\tau\n$$\n\n最优线性估计\n\n**Markov**\n\n\n有限维联合分布可以由各阶的条件分布表示出来：\n\n$$\n\\begin{align*}\n    &F_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n) \\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)F_{X(t_{n - 1}), \\dots, X(t_1)}(x_1, \\dots, x_{n - 1})\\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n\\end{align*}\n$$\n\n无后效性的 markov 过程：\n\n$$\nF_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1) = F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\n$$\n\n从而所有高阶依赖关系都可以简化为二阶依赖：\n\n$$\nF_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n)=F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n$$\n\n## 相关理论与二阶矩过程——时域分析\n\n### 自相关函数\n\n由二阶矩过程的定义可知，均方可积空间的自相关函数、自协方差函数、互相关函数、互协方差函数均存在。\n\n均值函数（一阶原点矩）：$\\mu_X(t) = E[X(t)]$\n\n方差函数：$\\text{Var}[X(t)] = E[(X(t) - \\mu_X(t))^2]$\n\n自相关函数：$R_X(t_1, t_2) = E[(X(t_1))(X^*(t_2))]$\n\n自协方差函数：$C_X(t_1, t_2) = \\text{Cov}[X(t_1), X(t_2)] = E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\mu_X(t_2))^*]$\n\n均方值函数：$E[X^2(t)] = \\int_{-\\infty}^{\\infty} x^2 f_X(x,t)dx$\n\n互相关函数和互协方差函数：\n\n* 如果$E[X(s)Y(t)]存在$，记为$R_{XY}(s, t)$\n* 如果$\\text{cov}(X(s), Y(t))存在$，记为$C_{XY}(s, t)$\n\n$$\nR_{XY}(t_1, t_2) = E[(X(t_1))(Y^*(t_2))]\n$$\n\n$$\nC_{XY}(t_1, t_2) = E[(X(t_1) - \\mu_X(t_1))(Y(t_2) - \\mu_Y(t_2))^*]\n$$\n\n$$\nC_{XY}(s, t) = R_{XY}(s,t) - \\mu_X(s)\\mu_Y(t)\n$$\n\n不相关：\n\n$$\nC_{XY}(s, t) = 0\n$$\n\n$$\nR_{XY}(s,t) = m_X(s)m_Y(t)\n$$\n\n\n自相关函数具有共轭对称性：\n\n$$\nR(t_1, t_2) = R^*(t_2, t_1)\n$$\n\n离散化的自相关矩阵同样是共轭对称的：\n\n$$\nR = E[XX^H]\\\\\nR_{ij} = R^*_{ji}\n$$\n\n自相关矩阵是非负定的：\n\n$$\n\\lambda R \\lambda^H = \\lambda XX^H\\lambda^H \\ge 0\n$$\n\n当 $P(\\lambda X = 0) = 1$ 时等号成立。\n\n非负定性是自相关函数的一种特征性质。如果一个二元函数满足非负定性质，则一定可以构造出一个随机过程，使得其自相关函数为给定的二元函数。\n\n自相关矩阵非负定，分解的特征值均非负。其物理意义是信号的能量或者功率。\n\n自相关函数对加法和乘法的封闭性：\n\n$$\nR(t, s) = \\alpha R_1(t, s) + \\beta R_2(t, s)\n$$\n\n仍然是某一随机过程的自相关函数。\n\n证明：取 $Z(t) = \\alpha^{1/2} X(t) + \\beta^{1/2} Y(t)$。这里 $X(t), Y(t)$是独立的。\n\n$$\nR(t, s) = R_1(t, s)R_2(t, s)\n$$\n\n也是自相关函数。取 $Z(t) = X(t)Y(t)$。\n\n### 宽平稳随机过程\n\n**宽平稳**\n\n对于随机过程 $X(t), t \\in T$，若 $\\forall t, s\\in T$\n\n$$\nE(X(t)) = E(X(s))\\\\\nR_X(t, s) = R_X(t + D, s + D)\n$$\n\n称随机过程 $X(t)$ 具有宽平稳性。\n\n宽平稳过程的均值是常数，自相关函数与相对时间差有关。故宽平稳过程的自相关函数可以写成一元函数：$R_X(\\tau), \\tau = t - s$。\n\n**严平稳**\n\n对于随机过程 $X(t), t \\in T$，若 $\\forall n, \\forall t_1, t_2, \\dots, t_n \\in T$，$\\forall D \\in T$，都有\n\n$$\nF_{t_1, t_2, \\dots, t_n}(x_1, x_2, \\dots, x_n) = F_{t_1 + D, t_2+D, \\dots, t_n + D}(x_1, x_2, \\dots, x_n)\n$$\n\n则称随机过程 $X(t), t\\in T$具有严平稳性。\n\n在二阶矩存在的条件下，严平稳蕴含宽平稳，而反过来，宽平稳一般无法得到严平稳。\n\n高斯过程的严平稳与宽平稳等价。\n\n**联合宽平稳**\n\n$$\nR_{X, Y}(t, s) = R_{XY}(t + D, s + D), \\forall D \\in T\n$$\n\n**宽平稳过程的性质**\n\n设 $R_X(\\tau)$ 为宽平稳过程的自相关函数， $m_X$ 为该过程的均值。\n\n$$\n\\begin{align}\n    R_X(\\tau) = \\overline{R_X(-\\tau)}\\\\\n    R_X(0)\\ge |m_X|^2\\\\\n    |R_X(\\tau)| \\le R_X(0)\\\\\n    R_X(\\tau) \\text{是一元非负定函数。}\n\\end{align}\n$$\n\n### 正交增量过程\n\n**正交增量过程**\n\n对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，满足\n\n$$\nE(X(t_4) - X(t_3))(\\overline{X(t_2) - X(t_1)}) = 0\n$$\n\n则称 $X(t), t \\in \\R$ 为正交增量过程。\n\n**独立增量过程**\n\n对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，$X(t_4) - X(t_3)$ 和 $X(t_2) - X(t_1)$ 统计独立，则称为独立增量过程。\n\n均值为0的独立增量过程是正交增量过程。\n\n**平稳增量过程**\n\n对于随机过程 $X(t), t \\in \\R$，若 $X(t) - X(s)$ 的分布仅仅依赖于 $t - s$，则称为平稳增量过程。\n\n定理：\n\n随机过程 $X(t), t \\in [0, \\infty]$，满足 $X(0) = 0$，则其为正交增量过程的充要条件为\n\n$$\nR_X(s, t) = F(\\min(s, t))\n$$\n\n其中，$F(\\cdot)$是单调不减的函数。\n\n### 随机过程的极限、连续、导数、积分\n\n**均方极限**\n\n$$\nE(|ka|^2)\n$$\n\n\n\n唯一性：若 $X_n \\xrightarrow{m.s} X, X_n \\xrightarrow{m.s}Y$，则 $E(|X - Y|^2) = 0$.\n\n可加性：\n\n数字特征相同：\n\n如何判定 ${X_n}$ 是否收敛？\n\nCauchy 准则\n\n$$\nX_n \\xrightarrow{m.s}{X} \\Leftrightarrow E(|X_m - X_n|^2) = 0, m, n \\rightarrow \\infty\n$$\n\n洛伊夫准则：\n\n$$\nX_n \\xrightarrow{m.s} X \\lrArr E\\lbrace X_n X_m^*\\rbrace \\rightarrow \\text{constant}\n$$\n\n**均方连续**\n\n二阶矩过程，$t \\rightarrow t_0, X(t) \\xrightarrow{m.s.} X(t_0)$，则称 $X(t)$ 在 $t_0$ 处连续\n\n定理\n\n以下命题等价：\n\n1. $R(t, s)$ 在 $(t_0, t_0)$ 上连续，$\\forall t_0 \\in T$\n2. $X(t)$ 在 $T$ 上均方连续\n3. $R(t, s)$ 在 $T \\times T$ 上连续\n\n推论\n\n对于宽平稳过程 $X(t)$，$R(\\tau)$ 为自相关函数，以下命题等价：\n\n1. $R(\\tau)$ 在 $\\tau = 0$ 处连续；\n2. $X(t)$ 在 $T$ 上均方连续；\n3. $R(\\tau)$ 在 T 上连续。\n\n**均方导数**\n\n若 $\\frac{X(t_0 + h) - X(t_0)}{h}\\xrightarrow{m.s.}Y(t_0), \\forall t_0 \\in T, h \\rightarrow 0$，则称$\\lbrace X(t) \\rbrace$ 在均方意义下的导数为 $Y(t)$。\n\n如何判断 $X(t)$ 是否均方可导？\n\nCauchy 准则\n\n$$\nE\\left(|\\frac{X(t_0 + h) - X(t_0)}{h} - \\frac{X(t_0 + g) - X(t_0)}{g}|^2\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$\n\n洛伊夫准则\n\n$$\nE\\left(\\left(\\frac{X(t_0 + h) - X(t_0)}{h}\\right)\\left(\\frac{X(t_0 + g) - X(t_0)}{g}\\right)^*\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$\n\n均方导数判定定理\n\n$$\n\\frac{\\partial^2 R(t, s)}{\\partial t \\partial s} 在 (t_0, t_0) 存在且连续，则 X(t) 在 t_0 处存在均方倒数\n$$\n\n均方导数的性质：\n\n$f(t)$ 为线性函数\n\n* $E(X^\\prime(t)) = \\frac{\\mathrm d }{\\mathrm dt} E(X(t))$\n* $E(X^\\prime(t)\\overline{X(s)}) =\\frac{\\partial }{\\partial t}R_x(t, s)$\n* $E(X(t)\\overline{X^\\prime(s)}) =\\frac{\\partial }{\\partial s}R_x(t, s)$\n* $E(X^\\prime(t)\\overline{X^\\prime(s)}) =\\frac{\\partial^2 }{\\partial t\\partial s}R_x(t, s)$\n\n\n**均方积分**\n\n若黎曼和 $\\sum\\limits_{k=1}^{n}X(v_k)h(v_k)(t_k - t_{k - 1})$ 在 $n \\rightarrow \\infty, \\max\\lbrace t_k - t_{k - 1}\\rbrace \\rightarrow 0$ 时均方收敛，其中 $h(t)$ 为确定的可积函数，则称$\\lbrace X(t)\\rbrace$ 为均方可积，记为 $\\int_{a}^{b}X(t)h(t)\\mathrm dt$。\n\n判定定理\n\n$$\n\\lbrace X(t)h(t) \\rbrace 均方可积 \\Leftrightarrow \\int_{a}^{b}\\int_{a}^{b}R_X(t, s)h(t)h^*(s)\\mathrm dt\\mathrm ds 存在\n$$\n\n均方积分的性质：\n\n* $E\\left( \\int_{a}^{b}X(t)h(t)\\mathrm dt\\right) = \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$\n* $E\\left( \\left(\\int_{a}^{b}X(t)h(t)\\mathrm dt\\right)\\left(\\int_{a}^{b}X(s)h(s)\\mathrm ds\\right)^*\\right) = \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$\n* 三角不等式：$\\sqrt{ E \\left(|\\int_{a}^{b}X(t)h(t)\\mathrm dt|^2\\right) } \\le \\int_{a}^{b}\\sqrt{E\\left(|X(t) - h(t)|^2\\right)}\\mathrm dt$\n* 均方积分与均方导数：$X(t)$ 在 $[a, b]$ 上均方连续，$Y(t) = \\int_{a}^{t}X(s)\\mathrm ds$，其中等号代表均方相等，则 $\\lbrace Y(t)\\rbrace$ 在 $[a, b]$ 可导，并称在均方意义下 $\\lbrace Y(t) \\rbrace$ 的导数为 $\\lbrace X(t) \\rbrace$\n\n### 随机过程的遍历性\n\n统计平均：对样本空间取平均\n\n$$\nE\\lbrace X(t_0) \\rbrace = \\int_{}^{}x\\mathrm dF_X(x;t_0)\n$$\n\n时间平均：\n\n$$\n\\langle X(t) \\rangle = \\frac{1}{T} \\int_{-T/2}^{T/2}X(t)\\mathrm dt\n$$\n\n统计平均和时间平均的关系？\n\n时间平均更容易获得。如果我们可以通过时间平均来获得统计平均？\n\n**遍历性**\n\n\n定义-宽平稳过程均值遍历：\n\n$$\n\\langle X(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} E \\lbrace X(t) \\rbrace = \\mu\n$$\n\na.s. = with probability 1\n\n左边是随机变量，右边是一个确定的数。这样的相等，意味着左边的随机变量的均值确定，方差为0.\n\n定义：宽平稳过程自相关遍历\n\n$$\n\\langle X(t + \\tau)X^*(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t + \\tau)X^*(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} R_X(\\tau) = E \\lbrace X(t + \\tau)X^*(t)\\rbrace\n$$\n\na.s. = with probability 1\n\n定理：\n\n宽平稳过程 $X(t)$ 满足均值遍历 $\\lrArr$ \n\n$$\nD(\\langle X(t) \\rangle) = \\lim\\limits_{T \\rightarrow\\infty} \\frac{1}{2T}\\int_{-2T}^{2T}\\left(1 - \\frac{|\\tau|}{2T}\\right)(R_X(\\tau) - |\\mu|^2)\\mathrm d\\tau = 0\n$$\n\n定理：\n\n宽平稳过程具有均值遍历性的充要条件是：\n\n$$\n\\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T}\\int_{-T}^{T}C_X(\\tau)\\mathrm d\\tau = 0 或者 \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{T}\\int_{0}^{T}C_X(\\tau)\\mathrm d\\tau = 0\n$$\n\n时间比较长的时候相关性消失了，也就是说过了一段时间同一轨道的样本就独立了，等价于多个轨道的样本，时间平均和统计平均就相等了。\n\n2个推论：\n\n* 若实数宽平稳过程的协方差函数满足 $\\int_{0}^{+\\infty}C_x(\\tau)\\mathrm d\\tau\\lt +\\infty$，则该过程具有均值遍历性\n* 若实数宽平稳过程的协方差函数满足 $C_x(\\tau) \\rightarrow 0, \\tau \\rightarrow +\\infty$，则该过程具有均值遍历性\n\n### 随机过程的线性展开\n\n**卡胡曼-洛伊夫展开**\n\n在平方可积空间上\n\n定义范数\n\n定义内积，正交\n\n在 $L^2[a, b]$ 中一定有一组标准正交基函数 $\\phi_1(t), \\phi_2(t), \\phi_3(t)\\dots$ 满足\n\n$$\n\\begin{cases}\n    \\langle \\phi_i, \\phi_j \\rangle = 0, i\\ne j\\\\\n    \\langle \\phi_i, \\phi_i \\rangle = 1\n\\end{cases}\n$$\n\n* $f$ 可以用有限个基函数线性加和来逼近\n* $\\langle f, \\phi_n \\rangle$ 表示 $f$ 在 $\\phi_n$ 基上的坐标。\n\n周期性宽平稳随机过程可以用傅里叶级数展开\n\n$$\nE\\left(\\left |X(t) -\\sum\\limits_{n=-\\infty}^{\\infty}c_ne^{j\\omega_0t}  \\right |^2\\right) = 0\n$$\n\n一般的用 KL 展开\n\n随机向量的双正交展开：\n\n零均值的 $n$ 元随机向量 $\\mathbf X \\in R^n$ 可以如下展开：\n\n$$\nX = \\sum\\limits_{k=1}^{n} \\xi_k \\mathbf e_k\n$$\n\n基向量选择的是自相关矩阵 $\\mathbf R$ 的特征向量。\n\n如果我们用 $\\mathbf K$ 个维度来逼近 $\\mathbf X$，为了使得误差最小，选取最大的$\\mathbf K$个特征值： $\\mathbf X =\\sum\\limits_{k=1}^{K} \\alpha_k\\mathbf e_k$。这就是主成分分析（PCA）。\n\n## 谱分析\n\n### 周期函数的傅里叶级数\n\n$$\nx(t) =\\sum\\limits_{n=-\\infty}^{\\infty}a_n e^{j\\omega_0 t}, \\omega_0 = \\frac{2\\pi}{T}\\\\\na_n = \\frac{1}{T}\\int_{0}^{T}x(t)e^{-jn\\omega_0t}\\mathrm dt\n$$\n\n帕斯瓦尔定理\n\n$$\n\\frac{1}{T}\\int_{0}^{T}|x(t)|^2\\mathrm dt =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\n$$\n\n自相关函数\n\n$$\nR(\\tau) = \\frac{1}{T}\\int_{0}^{T}x(t + \\tau)x^*(t)\\mathrm dt\n$$\n\n功率谱密度\n\n$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\\delta(\\omega - n \\omega_0)\n$$\n\n从而有\n\n$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\n$$\n\n### 非周期函数的傅里叶变换\n\n#### 知识\n\n$$\nF(\\omega) = \\int_{-\\infty}^{\\infty}x(t)\\exp(-j\\omega t)\\mathrm dt\\\\\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}F(\\omega)\\exp(j\\omega t)\\mathrm d\\omega = \\int_{-\\infty}^{\\infty}F(f)\\exp(j2\\pi ft)\\mathrm df\n$$\n\n帕斯瓦尔定理\n\n$$\n\\int_{-\\infty}^{\\infty}|x(t)|^2\\mathrm dt = \\int_{-\\infty}^{\\infty}|F(f)|^2\\mathrm df\n$$\n\n$$\n时域采样 \\lrarr 频域周期延拓\\\\\n时域周期延拓 \\lrarr 频域采样\\\\\n$$\n\n自相关函数\n\n$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}x(t + \\tau)x^*(t)\\mathrm dt\n$$\n\n能量谱密度\n\n$$\nS(\\omega) = |F(\\omega)|^2 = \\left |\\int_{-\\infty}^{\\infty}x(t)e^{j\\omega t}\\mathrm dt  \\right|^2\\\\\n$$\n\n波赫纳尔——辛钦定理\n\n$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S(\\omega)e^{j\\omega\\tau}\\mathrm d\\omega, S(\\omega)\\ge 0\n$$\n\n实过程的 $S(\\omega)$ 为偶函数。\n\n离散随机过程的功率谱：\n\n只在整数点 k 采样\n\n$$\nS(\\omega) =\\sum\\limits_{k=-\\infty}^{\\infty}R(k)e^{-j\\omega k}\\\\\nR(k) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}S(\\omega)e^{j\\omega k}\\mathrm d\\omega\n$$\n\n周期过程（自相关函数有周期性）的功率谱\n\n$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}b_n\\delta(\\omega - n \\Delta \\omega)\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\sum\\limits_{n=-\\infty}^{\\infty}b_ne^{jn\\Delta\\omega\\tau}\n$$\n\n#### 例子\n\n白噪声 $E \\lbrace X(t) \\rbrace = 0$，\n\n$$\nS(\\omega) = N_0, -\\infty \\lt \\omega \\le \\infty\\\\\nR(\\tau) = N_0\\delta(\\tau)\n$$\n\n* 任意两个不同时刻 $X(t_1), X(t_2)$ 都不相关。\n* 在各个频率上都有分量，且强度一致。\n\n高斯白噪声：各时刻服从高斯分布的白噪声\n\n色噪声： $R(\\tau)$ 不是冲击函数。\n\n* 当某过程 $R(\\tau)$ 比较胖的时候，功率谱比较瘦\n  * 相隔较长时间 $X(t)$ 与 $X(t + \\tau)$ 还相关，说明信号变化慢，对应频域低频多\n分量多\n* 当某过程 $R(\\tau)$ 比较瘦时，功率谱比较胖\n* 相隔一点时间， $X(t)$ 与 $X(t + \\tau)$ 不太相关，说明信号变化快，对应频域高频分量多。\n\n互谱密度\n\n$$\nS_{XY}(\\omega) = \\int_{-\\infty}^{\\infty}R_{XY}(\\tau)e^{-j\\omega \\tau}\\mathrm d\\tau\n$$\n\n称为互谱密度，不具有功率的含义。\n\n$$\nS_{YX}(\\omega) = S_{XY}^*(\\omega)\\\\\nR_{XY}(\\tau) = 0, \\forall \\tau \\lrArr S_{XY}(\\omega) = 0, \\forall \\omega\n$$\n\n$$\nZ(t) = X(t) + Y(t)\\\\\nR_Z(\\tau) = E \\lbrace (X(t + \\tau) + Y(t + \\tau))\\overline{(X(t) + Y(t))} \\rbrace = R_X(\\tau) + R_{XY}(\\tau) + R_{XY}\n$$\n\n一个宽平稳过程分别通过两个 LTI 系统：\n\n$$\nY_1(t) = X(t) * h_1(t)\\\\\nY_2(t) = X(t) * h_2(t)\\\\\nR_{Y_1Y_2}(\\tau) = R_X(\\tau) * h_1(\\tau) * h_2^*(-\\tau)\\\\\nS_{Y_1Y_2}(\\omega) = S_X(\\omega)H_1(\\omega)H_2^*(\\omega)\\\\\n$$\n\n两个过程输入两个系统，输出过程的互谱（互相关函数的傅里叶变换）。怎么求？\n\n（输入为联合宽平稳）\n\n$$\n\\hat X(t) = X(t) * f(t)\\\\\n\\hat Y(t) = Y(t) * g(t)\\\\\nR_{\\hat X\\hat Y}(\\tau) = R_{XY}(\\tau) * f(\\tau) * g^*(-\\tau)\\\\\nS_{\\hat X\\hat Y}(\\omega) = S_{XY}(\\omega)F(\\omega)G^*(\\omega)\n$$\n\n\n### 宽平稳过程通过线性系统\n\n$$\nY(t) = \\int_{-\\infty}^{\\infty}h(t - \\tau)X(\\tau)\\mathrm d\\tau\n$$\n\n总结：\n* 输出过程的均值：易求，因为宽平稳过程的均值为常数\n* 输出过程的自相关函数：有点麻烦\n\n首先看输出与输入的自相关\n\n$$\nR_{YX}(\\tau) = \\int_{-\\infty}^{\\infty}h(v)R_x(\\tau - v)\\mathrm dv\\\\\nR_Y(\\tau) = \\int_{-\\infty}^{\\infty}h^*(-u)R_{YX}(\\tau - u)\\mathrm du\n$$\n\n$$\nR_Y(\\tau) = R_X(\\tau) * h(\\tau) * h^*(-\\tau)\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$\n\n因此，输出的自相关，也可以用功率谱求解。\n\n### 离散时间宽平稳序列\n\n$$\nR_{YX}(k) = h(k) * R_X(k)\\\\\nR_Y(k) = h^*(-k) * h(k) * R_X(k)\\\\\nS_Y(z) = H(z) H^*(\\frac{1}{z^*})S_X(z)\\\\\n其中 H(z) =\\sum\\limits_{}^{}h(k)z^{-k}\\\\\n令 z = e^{j\\omega}\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$\n\n理想白噪声通过低通滤波器：\n\n$$\nS_Y(f) = \\begin{cases}\n    k_0, -f_c \\le f \\le f_c,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\\\\\nR_Y(0) = 2f_ck_0\\\\\nR(\\tau) = R_Y(0)\\frac{\\sin(2\\pi f_c\\tau)}{2\\pi f_c\\tau}\n$$\n\n从自相关函数可看出，相隔 $\\frac{n}{2f_c}$ 的两个时刻不相关。因此，以 $2f_c$ 为采样频率的噪声采样数据彼此不相关。\n\n可以证明宽平稳过程功率谱非负：$S_X(f) \\ge 0$：\n\n$$\nE \\lbrace |Y(t)|^2 \\rbrace =  R_Y(0) = \\int_{-\\infty}^{\\infty}S_Y(f)\\mathrm df = \\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\ge 0\n$$\n\n如果 $S_X(f)$ 在某个地方小于0，可以设计对应的滤波器 $H(f)$将这个小于0的区域滤出来，从而 $\\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\le 0$，导致矛盾。\n\n线性系统例子：\n\n滑动平均\n\n$$\nY(t) = \\frac{1}{T}\\int_{t-T}^{t}X(s)\\mathrm ds\n$$\n\n转化为滤波器：\n\n$$\nR_Y(t) = R_X(t) * h(t) * h^*(-t)\\\\\nh(t) = \\begin{cases}\n    \\frac{1}{T}, 0 \\le t \\le T,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\n$$\n\n令 \n\n$$\ng(t) = h(t) * h^*(t) = \\begin{cases}\n    \\frac{1}{T}\\left ( 1 - \\frac{|t|}{T} \\right), t \\in [-T, T],\\\\\n    0,\\text{otherwise.}\n\\end{cases}\n$$\n\n理想的矩形窗\n\n$$\nR_Y(t) = \\int_{-\\infty}^{\\infty}g(t - \\tau)R_X(\\tau)\\mathrm d\\tau = \\int_{-T}^{T}\\frac{1}{T}\\left ( 1 - \\frac{|t - \\tau|}{T} \\right)R_X(\\tau)\\mathrm d\\tau\n$$\n\n从频域看\n\n$$\nH(\\omega) = \\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)e^{-j\\omega \\frac{T}{2}}\\\\\nS_Y(\\omega) = S_X(\\omega)\\left |\\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)  \\right|^2\n$$\n\n是一个低通滤波器。\n\n例子2：MTI 滤波\n\n静止目标反射信号相同，运动目标反射回波不同。因此设计滤波器消去静止目标。称为“对消”。\n\n$$\nY(t) = X(t) - X(t - T)\n$$\n\n在频域看：\n\n$$\nH(\\omega) = 1 - e^{j\\omega T}\n$$\n\n静止目标，多普勒频率为0，因此频域响应为0；运动目标，多普勒频率不为0，频域响应不为0。因此这是一个高通滤波器。\n\n还可以多次对消：\n\n$$\nY_1(t) = X(t) - X(t - T)\\\\\nY_2(t) = Y_1(t) - Y_1(t - T)\\\\\nY_3(t) = Y_2(t) - Y_2(t - T)\\\\\n\\vdots\\\\\nY_n(t) = Y_{n - 1}(t) - Y_{n - 1}(t - T)\n$$\n\n频率响应：\n\n$$\nH(\\omega) = (1 - e^{-j\\omega T})^n\n$$\n\n### 采样定理\n\n随机过程下的采样定理\n\n$|f| \\le f_0$, 当 $f_s \\le 2f_0$ 时，均方意义下有\n\n$$\nX(t) =\\sum\\limits_{k=-\\infty}^{\\infty}X(kT) \\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right)\n$$\n\n证明：\n\n$$\n\\begin{align*}\n    &要证明 N \\rightarrow \\infty 时,\\\\\n    &\\varepsilon_N = E \\left \\lbrace  \\left | X(t) -\\sum\\limits_{k=-N}^{N}X(kT)\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 \\right \\rbrace \\rightarrow 0\\\\\n    &利用E \\lbrace X(a) X^*(b) \\rbrace = R_X(a - b) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}e^{j\\omega a}e^{-j\\omega b}S_X(\\omega)\\mathrm d\\omega，展开上式\\\\\n    &\\varepsilon_N = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &= \\frac{1}{2\\pi}\\int_{-\\omega_s/2}^{\\omega_s/2}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &对 e^{j\\omega t}做周期延拓，周期为 \\omega_s，可以做频域傅里叶级数展开\\\\\n    &e^{j\\omega t} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega \\frac{2\\pi}{\\omega_s}} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega kT}\\\\\n    &\\alpha_k = \\frac{1}{\\omega_s}\\int_{-\\omega_s/2}^{\\omega_s/2}e^{j\\omega t}e^{-j\\omega kT}\\mathrm d\\omega = \\frac{\\sin(\\frac{\\omega}{2}(t - kT))}{\\frac{\\omega}{2}(t - kT)}\\\\\n    &从而\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 = \\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}\\alpha_k e^{j\\omega kT}\\right|^2 \\rightarrow 0, N \\rightarrow \\infty\n\\end{align*}\n$$\n\n* 采样定理两边是均方相等。\n* 当满足采样定理时，离散点包含全部信息，任意取值点可以恢复。\n* 频带边界点\n  * 当功率谱在 $\\pm \\omega_0$ 处有 $\\delta$ 函数时，以 $f_s = 2f_0$ 无法恢复信号。\n  * 例如：$X(t) = \\cos(\\omega_0 t + \\phi)$，$\\phi$ 为随机相位，在$[0, 2\\pi]$内均匀分布。\n  * $R(\\tau) = \\frac{1}{2}\\cos(\\omega_0\\tau)$\n  * $S(\\omega) = \\delta(\\omega - \\omega_0) + \\delta(\\omega + \\omega_0)$\n  * 采样点 $X(kT) = (-1)^kX(0)$，与 $X(0)$ 严重相关。\n\n欠采样\n\n$$\n\\begin{align*}\n    E \\lbrace |\\varepsilon(t)|^2 \\rbrace =& \\int_{\\omega_s/2}^{-\\omega_s/2}\\sum\\limits_{n=-\\infty}^{\\infty}|1 - e^{jn\\omega t}|S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}4\\sin^2(\\omega_snt/2) \\cdot \\int_{\\omega_s/2}^{-\\omega_s/2}S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n\\end{align*}\\\\\n\n上面的级数为积分的加权求和。 n = 0 时权重为0，对应[-\\omega_s/2, \\omega_s/2] 内的功率谱。\\\\\nn\\ne 0 时，权不为0，对应[-\\omega_s/2, \\omega_s/2]外的频谱，如果在这个区间外功率谱不是0，那 |\\varepsilon|^2 将大于0。\n\n$$\n\n### 带通采样\n\n$$\nX(\\omega) = 0, |\\omega - \\omega_c| > \\omega_0, |\\omega + \\omega_c| > \\omega_0\n$$\n\n一般研究实信号 $g(t)$，频谱具有共轭对称性，只需要考虑正半轴的频带就可以了：\n\n$$\nG(-\\omega) = G^*(\\omega)\\\\\nA(\\omega) = A(-\\omega), \\varphi(-\\omega) = -\\varphi(\\omega)\n$$\n\n希尔伯特变换：\n\n$$\nH(\\omega) = \\begin{cases}\n    -j, \\omega \\gt 0,\\\\\n    0, \\omega = 0,\\\\\n    j, \\omega \\lt 0.\n\\end{cases}\n$$\n\n$$\n\\lbrace G(\\omega)H(\\omega) \\rbrace^* = G(-\\omega)H(-\\omega)\n$$\n\n希尔伯特把正频率移相 $-90\\degree$，负频率移相 $+90\\degree$\n\n时域表示：\n\n滤波器的时域响应为\n\n$$\n\\hat h(t) = \\frac{1}{\\pi t}\n$$\n\ng(t) 做两次希尔伯特变换，相位转了 $180\\degree$：\n\n$$\ng(t)\\xrightarrow{H(\\omega)}\\hat g(t) \\xrightarrow{H(\\omega)} -g(t)\n$$\n\n正交性：\n\n$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = 0\n$$\n\n看成$\\hat g(t)$ 与 $g(-t)$ 的卷积：\n\n$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}g(- (u - t))\\hat g(t)\\mathrm dt|_{u = 0} = g(-t) * \\hat g(t) |_{t = 0}\\\\\ng(-t) \\rightarrow G^*(\\omega) = G(-\\omega), \\hat g(t) \\rightarrow G(\\omega)H(\\omega)\\\\\ng(-t) * \\hat g(t)|_{t = 0} = \\int_{-\\infty}^{\\infty}G^*(\\omega)G(\\omega)H(\\omega)e^{j\\omega t}\\mathrm d\\omega|_{t = 0} = 0\n$$\n\n希尔伯特变换与原信号相加得到单边的频谱：\n\n$$\ng(t) \\rightarrow A^* + A\\\\\nj\\hat g(t) \\rightarrow \\\\\ng(t) + j\\hat g(t) \\rightarrow 2A\\\\\n$$\n\n下变频：\n\n$$\n\\tilde{g}(t) = \\lbrace g(t) + j\\hat g(t) \\rbrace e^{-j\\omega_c t} = g_I(t) + jg_Q(t)\\\\\ng_I(t) = g(t) \\cos \\omega_c t + \\hat g(t) \\sin (\\omega_c t)\\\\\ng_Q(t) = - g(t) \\sin \\omega_c t + \\hat g(t) \\cos (\\omega_c t)\\\\\n$$\n\n实际上是一个旋转矩阵，把单边频信号 $\\tilde g(t)$ 顺时针旋转了 $\\omega_ct$变成了基带复信号。\n\n与原信号频谱的关系：\n\n$$\ng_I(t) \\rightarrow G(f - f_c) + G(f + f_c) \\\\\ng_Q(t) \\rightarrow G(f - f_c)(+j) + G(f + f_c)(-j)\\\\\n(f \\le |f_0|)\n$$\n\n调制和解调的流程\n* 调制：不需要得到 $\\hat g(t)$\n* 解调：通过低通滤波代替$\\hat g(t)$\n\n随机过程的希尔伯特变换\n\n$X(t)$为实的带通随机过程\n\n$$\nR_X(-\\tau) = E\\left \\lbrace  X(t - \\tau)X^*(t) \\right \\rbrace = E\\left \\lbrace  X(t)X^*(t + \\tau) \\right \\rbrace = E\\left \\lbrace  X(t + \\tau)X(t) \\right \\rbrace = R_X(\\tau)\\\\\nS_X(-\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)e^{-j(-\\omega) \\tau}\\mathrm d\\tau = \\int_{-\\infty}^{\\infty}R_X(-u)e^{-j\\omega\\tau}\\mathrm du = \\int_{-\\infty}^{\\infty}R_X(u)e^{-j\\omega\\tau}\\mathrm du = S_X(\\omega)\n$$\n\n通过希尔伯特滤波器后：\n\n$$\n\\hat X(t) = X(t) * h(t)\\\\\nR_{\\hat X}(\\tau) = R_X(\\tau) * h(t) * h^*(-t) = R_X(\\tau)\\\\\nS_{\\hat X}(\\omega) = S_X(\\omega)|H(\\omega)|^2 = S_X(\\omega)\n$$\n\n互相关：\n\n$$\n\\hat R_X(\\tau) = R_{\\hat XX}(\\tau) = E \\left \\lbrace \\int_{-\\infty}^{\\infty}X(t + \\tau - u)\\frac{1}{\\pi u}\\mathrm duX(t)   \\right\\rbrace = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\frac{1}{\\pi u}\\mathrm du\n$$\n\n$$\nR_{X\\hat X}(\\tau) = -\\hat R_X(\\tau)\n$$\n\n因此\n\n$$\nY = X + j\\hat X\\\\\nR_Y(\\tau) = R_X(\\tau) + R_{\\hat X}(\\tau) + jR_{\\hat XX}(\\tau) - jR_{X\\hat X}(\\tau) = 2R_X(\\tau) + 2j\\hat R_X(\\tau)\\\\\nS_Y(f) = \\begin{cases}\n    4S_X(f), &f \\gt 0\\\\\n    0, &f\\lt 0\n\\end{cases}\n$$\n\n实的带通随机过程配合虚部的希尔伯特变换，同样也是只有正频率\n\n反之，如果功率谱只有正频率有值，则实部和虚部互为希尔伯特变换，实部和虚部的信息是重复的。\n\n随机信号的下变频：\n\n$$\n\\tilde{X}(t) = \\lbrace X(t) + j\\hat X(t) \\rbrace e^{-j\\omega_c t} = X_I(t) + jX_Q(t)\\\\\nX_I(t) = X(t) \\cos \\omega_c t + \\hat X(t) \\sin (\\omega_c t)\\\\\nX_Q(t) = - X(t) \\sin \\omega_c t + \\hat X(t) \\cos (\\omega_c t)\\\\\n$$\n\n同样是顺时针旋转了 $2\\pi f_c t$ 之后得到了基带信号\n\n研究基带信号的实部、虚部的统计特性\n\n$\\tilde{X}(t)$ 还是一个平稳过程\n\n$$\nE \\lbrace \\tilde{X}(t) \\rbrace = E \\lbrace X_I(t) \\rbrace = E \\lbrace X_Q(t) \\rbrace = 0\\\\\nR_{X_I}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_Q}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_I}(\\tau) = R_{X_Q}(\\tau)\\\\\nR_{X_Q}(0) = R_{X_I}(0) = R_{X}(0)(三者方差一样)\\\\\n\\hat R_X(0) = 0(奇函数，不具备自相关函数的性质)\\\\\nS_{X_I}(f) = S_{X_Q}(f) = \\begin{cases}\n    S_X(f - f_c) + S_X(f + f_c), &|f| \\le f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n基带信号虚部和实部的互相关\n\n$$\nR_{X_IX_Q}(\\tau) = R_X(\\tau)\\sin(2\\pi f_c\\tau) - \\hat R_X(\\tau)\\cos (2\\pi f_c\\tau)，奇函数\n$$\n\n$$\nR_{X_IX_Q}(0) = 0\n$$\n\n因此同一时刻实部和虚部不相关。\n\n互谱密度\n\n$$\nS_{X_IX_Q}(f) = \\begin{cases}\n    jS_X(f + f_c) - jS_X(f - f_c), &|f| \\lt f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$\n\n只有当正频谱和负频谱分别跟 $f = \\pm f_c$ 对称时，互谱密度恒为0。此时，任意两个时间的虚部和实部信号都是不相关的。\n\n## 高斯过程\n\n### 定义\n\n随机向量$X = (X(t_1), \\dots, X(t_n))^T$ 服从 $n$ 元高斯分布，称为高斯过程。\n\n均值 $\\mu_k$ = $E \\lbrace X_k \\rbrace$\n\n协方差阵\n\n$$\n\\Sigma = E \\lbrace (X - \\mu)(X - \\mu)^T \\rbrace = \\begin{bmatrix}\n    b_{11}& \\dots &b_{1n}\\\\\n    \\vdots& \\ddots & \\vdots\\\\\n    b_{n1} & \\dots & b_{nn}\n\\end{bmatrix}\\\\\nb_{ij} = E \\lbrace (X_i - \\mu_i)(X_j - \\mu_j)^T \\rbrace\\\\\nb_{ij} = b_{ji}^* = b_{ji}\n$$\n\n做特征分解\n\n$$\n\\Sigma v_i = \\lambda_i v_i\\\\\nQ = (v_1, v_2, \\dots, v_n)正交阵, Q^{-1} = Q^T\\\\\n\\Sigma = Q\\text{diag}(\\lambda_1, \\dots, \\lambda_n)Q^T\\\\\n\\Sigma^{-1} = Q^T\\text{diag}(\\lambda_1^{-1}, \\dots, \\lambda_n^{-1})Q\n$$\n\n### 多元高斯分布\n\n$$\nf(x) = K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$\n\n线性变换以消去下标$ij$项：\n\n$$\n\\Sigma^{-1} = A^TA\\\\\ny = A(x - \\mu)\\\\\n(x - \\mu)\\Sigma^{-1}(x - \\mu)^T = y^Ty\n$$\n\n$$\n1 = K \\int \\dots \\int \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace \\mathrm dx_1 \\dots \\mathrm dx_n\\\\\nK = \\frac{1}{(\\sqrt{2\\pi})^n\\cdot \\sqrt{|\\Sigma|}}\n$$\n\n多元高斯矢量的特征函数\n\n$$\n\\omega = (\\omega_1, \\omega_2,\\dots, \\omega_n)^T\\\\\n\\Phi_X(\\omega) = E \\lbrace e^{j\\omega^TX} \\rbrace = E \\lbrace e^{j(\\omega_1 X_1 + \\omega_2 X_2 + \\dots + \\omega_n X_n)} \\rbrace = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T\\Sigma\\omega \\right \\rbrace\n$$\n\n特征函数不要求 $\\Sigma$ 可逆。概率密度函数要求 $\\Sigma$ 正定，特征值都大于0.\n\n当 $X$ 为高斯矢量时\n\n$$\n\\Phi_X(\\omega) = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu) \\right \\rbrace\\mathrm dx_1\\mathrm dx_2\\dots\\mathrm dx_n = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{y^Ty}{2} \\right \\rbrace \\sqrt{|\\Sigma|}\n$$\n\n高斯白噪声的协方差矩阵只有对角元，对角元为方差。\n\n可以用逼近处理 $|\\Sigma| = 0$：\n\n$$\n\\Sigma_K = \\Sigma + \\frac{1}{K}I\\\\\n\\Phi_X(\\omega) = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T \\left (\\Sigma + \\frac{1}{K}I  \\right)\\omega \\right \\rbrace\\\\\nf(x) = \\frac{1}{\\sqrt{2\\pi}^n \\sqrt{|\\Sigma_K|}} \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$\n\n然后再讨论 $K \\rightarrow \\infty$ 的情况。\n\n多元高斯矢量的边缘分布\n\n任取子矢量 $\\lbrace K_1, K_2, \\dots, K_m \\rbrace \\subseteq {1, 2, \\dots, n}$\n\n观察 $\\tilde{ X} = (X_{K_1}, X_{K_2}, \\dots, X_{K_m})^T$ 的分布\n\n$$\n\\tilde{\\Phi}(\\tilde\\omega) = E \\lbrace e^{j(\\omega_{K_1}\\tilde X_{K_1} + \\omega_{K_2}\\tilde X_{K_2} + \\dots + \\omega_{K_m}\\tilde X_{K_m})} \\rbrace = \\exp \\left \\lbrace  j\\tilde\\omega^T\\mu - \\frac{1}{2}\\tilde\\omega^T\\Sigma\\tilde\\omega \\right \\rbrace\n$$\n\n用置换矩阵 $P$ 将 $\\Sigma$ 的第 $K_1, K_2, \\dots, K_m$ 行、列移到 $\\Sigma$ 的左上角，对应的 $\\omega$ 也置换：\n\n$$\nP\\omega = \\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix}\\\\\nP^T\\Sigma P^T = \\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\n$$\n\n置换到左上角后，容易看出子矢量的特征函数可以通过将原矢量其他的$\\omega$置零得到，均值就是选择对应的均值，协方差矩阵就是把对应的行列元素抽出来：\n\n$$\n\\omega^T\\Sigma\\omega = (\\tilde{\\omega}, 0)^T\\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix} = \\tilde{\\omega}^T\\tilde{\\Sigma}\\tilde{\\omega}\n$$\n\n利用特征函数求数字特征：\n\n$$\n\\frac{\\partial^2\\Phi}{\\partial \\omega_k\\partial \\omega_l}|_{\\omega_k = \\omega_l = 0} = -(\\mu_l\\mu_k + b_{kl})\\\\\nE \\lbrace X_kX_l \\rbrace = \\mu_l\\mu_k + b_{kl}\n$$\n\n$$\nE \\lbrace X_1^{k_1}\\dots X_n^{k_n} \\rbrace = j^{\\sum\\limits_{i=1}^{n}k_i} \\frac{\\partial^{k_1 + k_2 + \\dots k_n}}{\\partial^{k_1}\\omega_1\\partial^{k_2}\\omega_2\\dots \\partial^{k_n}\\omega_n}\\bigg|_{\\omega_1 = \\omega_2 = \\dots = \\omega_n = 0}\n$$\n\n高斯的矢量分布的高阶矩完全由一阶矩 $\\mu$ 和二阶矩 $\\Sigma$ 决定。例如可以用特征函数推出：\n\n$$\n\\begin{align*}\n    &E \\left \\lbrace  X_1X_2X_3X_4 \\right \\rbrace \\\\\n    =& j^4 \\frac{\\partial^4\\Phi}{\\partial \\omega_1\\partial \\omega_2\\partial \\omega_3\\partial \\omega_4}\\bigg|_{\\omega_1 = \\omega_2 = \\omega_3 = \\omega_4 = 0} \\\\\n    =& E \\left \\lbrace  X_1X_2  \\right \\rbrace E \\left \\lbrace  X_3X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_3  \\right \\rbrace E \\left \\lbrace  X_2X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_4  \\right \\rbrace E \\left \\lbrace  X_2X_3  \\right \\rbrace\n\\end{align*}\n$$\n\n独立性\n\n独立性说的是统计，不相关说的是线性（二阶矩）\n\n一般来说\n\n$$\n独立 \\Rightarrow 不相关\\\\\n不相关 \\not \\Rightarrow 独立\n$$\n\n但是，对于高斯分布而言：\n\n$$\n独立 \\lrArr 不相关\n$$\n\n这是因为高斯分布完全由一阶和二阶矩决定。\n\n定理：\n\n$n$ 元向量 $X = \\binom{X_1}{X_2}$ 服从 $N(\\mu, \\Sigma)$，则 $X_1, X_2$ 独立 $\\lrArr$ $\\Sigma_{12} = 0$\n\n$$\n\\Sigma = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\n$$\n\n充分性：\n\n$$\n\\Sigma_{12} = E \\left \\lbrace (X_1 - \\mu_1)^T(X_2 - \\mu_2)  \\right \\rbrace = E \\left \\lbrace (X_1 - \\mu_1)\\right\\rbrace E\\left \\lbrace(X_2 - \\mu_2)  \\right \\rbrace = 0\n$$\n\n必要性：\n\n$$\nf(x_1, x_2) = \\frac{1}{(2\\pi)^{n/2}\\sqrt{|\\Sigma|}}\\exp \\left \\lbrace -\\frac{1}{2}\\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix}^T\\begin{pmatrix}\n    \\Sigma_{11}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix} \\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix} \\right  \\rbrace = f(x_1)f(x_2)\n$$\n\n可见 $X_1, X_2$ 统计独立。\n\n对于高斯过程：\n\n$$\n严平稳 \\lrArr 宽平稳\n$$\n\n即 $X(t_1), X(t_2), \\dots, X(t_n)$ 和 $X(t_1 + \\tau), X(t_2 + \\tau), \\dots, X(t_n + \\tau)$ 有相同的 $\\mu, \\Sigma$ 等价于具有相同的分布函数。\n\n线性变换\n\n定理： $X$ 服从高斯分布，矩阵 $C_{m\\times n}$， $Y = CX$，则 $Y$ 服从高斯分布 $N \\left(C\\mu, C \\Sigma C^T \\right)$。\n\n高斯过程经过微分，积分，滤波等线性操作，输出还是高斯过程。\n\n有一种重要的线性变换：去相关。\n\n$$\n\\Sigma_X = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\\\\\nY = \\begin{pmatrix}\n    Y_1\\\\Y_2\n\\end{pmatrix}= \\begin{pmatrix}\n    I & A\\\\\n    0 & I\n\\end{pmatrix}\\begin{pmatrix}\n    X_1\\\\X_2\n\\end{pmatrix}\\\\\nE \\left \\lbrace  (Y_1 - E(Y_1))(Y_2 - E(Y_2))^T \\right \\rbrace = \\Sigma_{12} + A\\Sigma_{22 } = 0\n$$\n\n需要\n\n$$\n-\\Sigma_{12}\\Sigma_{22}^{-1} = A\\\\\n$$\n\n计算协方差\n\n$$\nE \\left \\lbrace  (Y - E(Y))(Y - E(Y))^T \\right \\rbrace = \\begin{pmatrix}\n    \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix}\n$$\n\n去相关之后方差减小了。可以认为 $X_1 = Y_1 - AX_2$ 中，$- AX_2$是与 $Y$ “独立” 的“噪声项”，这个噪声导致了 $X_1$ 的方差大于去相关之后的 $Y$ 的方差。\n\n去相关与是否是高斯矢量无关。但是对于高斯矢量，去相关之后，两个矢量就独立了，具有重要的意义。\n\n对于一般的二阶矩过程，希望找到一个矩阵 $U$ ，使得 $Y = UX$ 的各个分量不相关：\n\n$$\nE \\left \\lbrace  (Y - \\mu_Y)(Y - \\mu_Y)^T \\right \\rbrace = \\text{diag}\\\\\nE \\left \\lbrace  U(X - \\mu_X)(X - \\mu_X)^TU^T \\right \\rbrace  = \\text{diag} = U\\Sigma U^T\n$$\n\n所以，本质上就是分析了协方差矩阵 $\\Sigma$ 的特征值。也就是二阶矩章节讲到的主成分分析：\n\n$$\n\\text{diag}(\\lambda_1, \\dots, \\lambda_n)\n$$\n\n选取 $\\lambda_i$ 大的特征矢量，张成主成分空间。\n\n信号处理中有信号空间（特征值大的）和噪声空间（特征值小的，被噪声掩盖了）。\n\n有时候 $Y$ 的各个分量不相关还不能完全消去元素之间的统计关系。只是线性不相关。不相关的约束实际上很弱。\n\n如果要设计 $U$，使得 $Y = UX$ 的各个分量独立，运算很复杂。\n\n但是，对于高斯矢量而言，不相关就是独立。所以对于高斯过程，主成分分析 $\\lrArr$ 独立成分分析。\n\n### 高斯变量的条件分布\n\n仍是高斯：\n\n$$\nf_{X_1|X_2}(x_1|x_2) = \\frac{1}{\\sqrt{\\tilde{\\Sigma}_{11}}(2\\pi)^{\\frac{n_1}{2}}}\\exp \\left \\lbrace -\\frac{1}{2}(x_1 - \\tilde{\\mu}_1)^T\\tilde{\\Sigma}_{11}^{-1}(x_1 - \\tilde{\\mu}_1)   \\right\\rbrace\\\\\nE \\lbrace X_1 | X_2 \\rbrace = \\mu_1 + \\Sigma_{12}\\Sigma_{22}^{-1}(X_2 - \\mu_2)\\\\\nE \\lbrace (X_1 - E(X_1 | X_2))(X_1 - E(X_1|X_2))^T|X_2 \\rbrace = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\n$$\n\n### 实高斯过程的若干性质\n\n实高斯过程完全由均值函数和协方差函数确定。\n\n严平稳等价于宽平稳。\n\n若实高斯过程均方可导，则 $\\lbrace X^\\prime(t) \\rbrace$ 也是高斯过程。\n\n高斯过程通过一般线性系统仍然是高斯过程。\n\n$$\nY(t) = \\int_{a}^{b}X(\\tau)h(t, \\tau)\\mathrm d\\tau\\\\\n更强的结论：\\left \\lbrace  \\binom{X(t)}{Y(t)} \\right \\rbrace 是高斯过程。\n$$\n\n### 零均值带通高斯过程\n\n$$\nZ(t) = X(t) + j \\hat X(t)\\\\\nX_B(t) = X_I(t) + j X_Q(t)\\\\\nV(t) = \\sqrt{X_I^2(t) + X_Q^2(t)}\\\\\n\\Theta(t) = \\arctan \\frac{X_Q(t)}{X_I(t)}\\\\\n$$\n\n此时有\n\n$$\nX(t) = V(t)\\cos(\\omega_ct + \\Theta(t))\\\\\n\\binom{X_I(t)}{X_Q(t)} = \\binom{\\ \\ \\ \\cos(\\omega_ct)\\quad \\sin(\\omega_c t)}{-\\sin(\\omega_ct)\\quad \\cos(\\omega_ct)}\\binom{X(t)}{\\hat X(t)}\n$$\n\n幅度为瑞利分布，相位为均匀分布，相互统计独立：\n\n$$\nf_V(v) = \\frac{v}{\\sigma^2}e^{-\\frac{v^2}{2\\sigma^2}}, v \\ge 0\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}, \\theta \\in [0, 2\\pi]\n$$\n\n### 随机相位正弦波信号叠加零均值带通高斯\n\n$$\nY(t) = A\\sin(\\omega_ct + \\Phi) + X(t)\n$$\n\n结果是幅度为莱斯分布，相位均匀分布，二者统计独立：\n\n$$\nf_{V(t)}(v) = \\frac{v}{\\sigma^2}\\exp(-\\frac{v^2 + A^2}{2\\sigma^2})I_0(\\frac{Av}{\\sigma^2})\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}\n$$\n\n### 高斯过程经过非线性函数\n\n限幅器\n\n$$\nh(x) = \\begin{cases}\n    1, x\\ge 0,\\\\\n    0, x \\lt 0\n\\end{cases}\n$$\n\n服从两点分布\n\n$$\nP(Y(t) = 1) = P(Y(t) = 0) = \\frac{1}{2}\\\\\nE_Y(t) = 0\\\\\nR_Y(t, s) = P \\lbrace X(t)X(s) \\ge 0 \\rbrace - P \\lbrace X(t)X(s) \\lt 0 \\rbrace\n$$\n\n$$\nP \\lbrace X(t)X(s) \\ge 0 \\rbrace = \\int_{0}^{\\infty}\\int_{0}^{\\infty}\\frac{1}{2\\pi\\sqrt{|\\Sigma|^{-1}}}\\exp((x_1\\ x_2)\\Sigma^{-1}\\binom{x_1}{x_2})\\mathrm dx_2\\mathrm dx_1 = \\frac{\\pi/2 + \\sin^{-1}(-\\rho)}{2\\pi}\n$$\n\n全线性检波（求绝对值）\n\n$$\nE(Y) = \\frac{2\\sigma}{2\\pi}\\int_{0}^{\\infty}\\frac{y}{\\sigma^2}\\exp(-\\frac{y^2}{2\\sigma^2})\\mathrm dy = \\sqrt{\\frac{2}{\\pi}}\\sigma\\\\\nR_Y(t, s) E \\lbrace |X(t)||X(s)| \\rbrace = \\frac{2\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace, \\rho = \\frac{R_X(t - s)}{\\sigma^2}\\\\\n\\int_{0}^{\\infty}\\int_{0}^{\\infty}x_1x_2\\frac{1}{2\\pi\\sigma^2\\sqrt{1 - \\rho^2}}\\exp(-\\frac{x_1^2 - 2\\rho x_1x_2 + x_2^2}{2\\sigma(1 - \\rho^2)})\\mathrm dx_1\\mathrm dx_2\n$$\n\n半波线性检波\n\n$$\nh(x) = \\begin{cases}\n    x, x\\ge 0,\\\\\n    0, x\\lt 0\n\\end{cases}\n$$\n\n$$\nR_Y(t, s) = \\frac{\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace\\\\\n$$\n\n平方率检波\n\n$$\nh(x) = x^2\n$$\n\n$$\nP(Y(t) \\le y) = P(-\\sqrt{y} \\le Y(t) \\le \\sqrt{y}) = 2\\Phi(\\frac{\\sqrt{y}}{\\sigma}) - 1\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\frac{1}{\\sqrt{y}}\\exp \\lbrace -\\frac{y}{2\\sigma^2} \\rbrace,\\ (y \\gt 0)\\\\\nE \\lbrace Y(t) \\rbrace = \\sigma^2\\\\\nR_Y(t,s) = E \\lbrace X^2(t_1)X^2(t_2) \\rbrace = \\sigma^2 + \\sigma^2 + \\rho\\sigma^2 + \\rho\\sigma^2 = 2(\\rho + 1)\\sigma^2\n$$\n\n基带信号的包络经过平方律检波\n\n$$\nX_I^2 + X_Q^2 = V^2 服从复指数分布\n$$\n\n### 高斯——马尔可夫性\n\n马尔可夫特性：\n\n$$\nf(x_n|x_1, \\dots, x_{n - 1}) = f(x_n|x_{n - 1})\n$$\n\n如果一个过程既是高斯的，又是马尔可夫的，会有很好的性质。\n\n对于零均值高斯分布：\n\n$$\nX(t) 是 \\text{Markov} \\lrArr R(t_1, t_3) = \\frac{R(t_1, t_2)R(t_2, t_3)}{R(t_2, t_2)}\n$$\n\n正向很好证明，反向证明的关键是计算均值和方差。\n\n$$\nX(t) 是 \\text{Markov} \\lrArr \\forall t_1\\le t_2\\le...\\le t_n, E \\lbrace X_n|X_1, X_2, \\dots, X_{n - 1} \\rbrace = E \\lbrace X_n|X_{n - 1} \\rbrace\n$$\n\n从右到左：条件协方差 $E\\lbrace (Y_1 - E \\lbrace Y_1|Y_2 \\rbrace)^2|Y_2\\rbrace = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}$ 跟 $Y_2$ 无关（这并不是说条件协方差和协方差具有相同的意义，只是数值上正好相等）\n\n$$\nE(X_n|X_{n - 1}) = \\frac{E(X_nX_{n - 1})}{E(X_{n - 1}^2)}X_{n - 1}\\\\\n$$\n\n残差与已有信息正交：\n\n$$\nE \\lbrace [X_n - E(X_n | X_{n - 1})] \\cdot X_k \\rbrace = 0, k = 1, 2, \\dots, n - 1\\\\\n$$\n\n类似于最小二乘估计：\n\n$$\nX_n - \\alpha_n X_{n - 1} 是一个高斯过程，与 X_1, X_2, \\dots, X_n 独立\n$$\n\n自回归方程：\n\n$$\nX_n = \\alpha_n X_{n - 1} + \\beta_nY_n\\\\\nY_n \\sim N(0, 1)\n$$\n\n### Brown 运动\n\n从一维随机游走开始：\n\n$$\nP \\lbrace X_i = a \\rbrace = P \\lbrace X_i = -a \\rbrace = \\frac{1}{2}\\\\\nY =\\sum\\limits_{i=1}^{\\infty}X_i\n$$\n\n令 $t = nT$，固定 $t$，令 $n \\rightarrow \\infty$，由 CLT 可知成为一个高斯分布：\n\n$$\nE(Y) = 0\\\\\nD(Y) = \\frac{t}{T}a^2\\\\\n\\frac{a^2}{T} = \\beta\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sqrt{\\beta t}}\\exp (-\\frac{y^2}{2\\beta t})\n$$\n\n随着时间增加，不确定性越来越大。\n\n标准布朗运动：\n\n（1）$B(t)$ 满足独立增量，平稳增量\n（2）$B(t)$ 的每个样本轨道都是连续的\n（3）$\\forall t, B(t)$ 遵循高斯分布，均值0，方差 $t$\n\n$$\nf_t(x) = \\frac{1}{\\sqrt{2\\pi t}}\\exp (-\\frac{x^2}{2t})\n$$\n\n布朗运动是高斯白噪声的积分：\n\n$$\nY(t) = \\int_{0}^{t}X(u)\\mathrm du\n$$\n\n可见布朗运动的不规则。\n\n## Markov 过程\n\n### Markov 链\n\n一种状态离散、时间离散的随机过程。\n\n### Markov 特性\n\n\n\n马尔可夫特性的一种表示：\n\n在已知现在的条件下，过去与将来独立。\n\n$$\nP(C,A | B) = P(C | B, A) \\cdot P(A|B) = P(C|B)P(A|B)\n$$\n\n其他表示：过去用集合事件表示\n\n$$\nP \\lbrace X_{n+1}=j|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}=j|X_n=i \\rbrace\n$$\n\n进一步，过去是一个集合，未来也是一个集合：\n\n$$\nP \\lbrace X_{n+1}\\in B|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}\\in B|X_n=i \\rbrace\n$$\n\n但是，变量“现在”必须取值为一个确定的值，不能是一个集合。对现在的状态一定要精确掌握，不能放宽约束。\n\n口号：从小事做起（泊松），从现在做起（马尔可夫）\n\n转移概率\n\n$$\nP_{ij}(m, n) = P \\lbrace X_n = a_j | X_m = a_i \\rbrace\n$$\n\n$$\nP_{ij}(m, n) \\ge 0\\\\\n\\sum\\limits_{j}^{}P_{ij}(m, n) = 1\n$$\n\n一步转移概率：\n\n$$\nP_{ij}(m, m + 1) 或 P_{ij}(m)\n$$\n\n状态转移矩阵\n\n观察变量族的联合分布\n\n### 齐次马尔科夫链的迭代表示\n\n$$\nX_0 \\xrightarrow{Z_1} X_1 \\xrightarrow{Z_2} X_2 \\dots \\xrightarrow{Z_n} X_{n}\n$$\n\n$$\nX_{n+1} = f(X_n,Z_{n+1}) = P \\lbrace X_{n+1} = j | X_n = i \\rbrace\n$$\n\n也称为新息过程\n\n### 一维随机游走\n\n吸收壁\n\n反射壁 - 完全反射壁\n\n成功逃跑\n\n等待服务人数\n\n$$\nX_{n + 1} = \\begin{cases}\n    X_n - 1 + Y_{n + 1}, X_n \\ne 0\\\\\n    Y_{n + 1}, X_0\n\\end{cases}\\\\\nP = \\begin{bmatrix}\n    a_0 & a_1 & a_2 & \\dots\\\\\n    a_0 & a_1 & a_2 & \\dots\\\\\n        & a_0 & a_1 & \\dots\\\\\n        &     & a_0 & \\dotsb\n\\end{bmatrix}\n$$\n\n### 柯尔莫格洛夫方程\n\n多步转移矩阵概率\n\n$$\nP_{ij}(m, n) = \\sum_k P(X_n = j | X_r = k) \\cdot P(X_r = k | X_m = i)\n$$\n\n或者表示为\n\n$$\nP_{ij}^{(p + q)} = \\sum_{k \\in \\Omega} P_{ik}^{(p)} P_{kj}^{(q)}\n$$\n\n由于上面转移阵步数 $p, q$ 的任意性，多步跳变矩阵可以转变为矩阵相乘：\n\n$$\nP^{(L)} = P^{(L - 1)}P^{(1)} = ... = P^L\n$$\n\n求多步转移矩阵：适用于齐次马尔可夫\n\n齐次马尔可夫链的 $P$ 与时间起点无关\n\n先求 $P^{(n)} = P^n$，再看 $[P^n]_{ij}$ 就是要求的转移概率。\n\n如何求 $P^n$ ？\n\n首先做特征分解 $PU = U\\Lambda$\n\n$$\nP^n = U \\Lambda^nU^{-1}\n$$\n\n二元通信信道\n\n$$\nP  = \\begin{pmatrix}\n    1 - \\alpha & \\alpha\\\\\n    \\beta & 1 - \\beta\n\\end{pmatrix}\\\\\nU = \\begin{pmatrix}\n    1 & -\\alpha\\\\\n    1 & \\beta\n\\end{pmatrix}\n$$\n\n\n$$\nP^n = \\frac{(1 - \\alpha - \\beta)^n}{\\alpha + \\beta}\\begin{pmatrix}\n    \\alpha & -\\alpha\\\\\n    -\\beta & \\beta\n\\end{pmatrix} + \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$\n\n在 $|1 - \\alpha - \\beta| < 1$ 的条件下，无穷步跳变后：\n\n$$\nP^n = \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$\n\n各列相等，说明这个马尔可夫链与初始状态无关，历史被淡忘——马尔可夫性。\n\n\n$1 - \\alpha - \\beta = -1$ 时，极限不存在\n\n$$\nP = \\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\\\\\n\\end{pmatrix}\n$$\n\n### 状态分类\n\n可达性：$\\exists m, s.t. P_{ij}^{(m)} > 0$\n\n互通性：$\\exist m, n, s.t. P_{ij}^{(m)} > 0, P_{ji}^{(n)} > 0$，是等价关系。\n\n不可约(irreducible)，不可分\n\n马尔可夫链中每两个状态都是互通的，也叫互通链。\n\n闭集：$\\forall i \\in C, j\\not \\in C, i \\not \\rightarrow j$\n\n不可约的另一定义：除了把整个链作为闭集，不存在取其中一些状态构成其他闭集了。\n\n激励状态\n\n稳定状态（闭集）\n\n一般情况，Markov 链的转移矩阵行列重排后可化为：\n\n$$\nP = \\begin{pmatrix}\n    u_1\\\\\n    &u_2\\\\\n    &&\\ddots\\\\\n    &&&u_k\\\\\n    v_1&v_2&\\dots&v_k&v_{k+1}\n\\end{pmatrix}\n$$\n\n对闭集而言，可以在闭集内使用柯尔莫格洛夫方程：\n\n$$\nP_{ij}^{(n + m)} =\\sum\\limits_{r\\in \\Omega_1}^{}P_{ir}^{(n)}P_{rj}^{(m)}\n$$\n\n首次达到时间：$T_{ij}(\\omega) = \\min \\lbrace n: X_0(\\omega) = i, X_n(\\omega) = j, n \\ge 1 \\rbrace$\n\n$$\nT_{ij} \\in [1, 2, ..., \\infty)\n$$\n\n首次到达概率\n\n$$\nf_{ij}^{(n)} = P \\lbrace T_{ij} = n| X_0 = i \\rbrace\n$$\n\n此时有\n$$\nf_{ij}^{(1)} = P_{ij}\n$$\n\n定义\n\n$$\nf_{ij} =\\sum\\limits_{k=1}^{\\infty^-} f_{ij}^{(k)}\n$$\n\n为迟早到达的概率。\n\n$$\nf_{ij}^{(\\infty)} = 1 - f_{ij}\n$$\n\n表示永远无法到达的概率。\n\n定理：\n\n$$\nP_{ij}^{(n)} =\\sum\\limits_{r=1}^{n} f_{ij}^{(r)}P_{jj}^{(n - r)}\n$$\n\n考虑 $P_{ij}^{(0)} = \\delta_{ij}$，上述可以写成卷积形式：\n\n$$\nF_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^r\\\\\nG_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^{r}\\\\\nG_{ij}(z) = \\delta_{ij} + F_{ij}(z)G_{jj}(z)\n$$\n\n$$\ni \\rightarrow j \\lrArr  f_{ij} \\gt 0\n$$\n\n### 常返性\n\n#### 常返与非常返\n\n若 $f_{ij} = 1$，称状态 i 为常返态\n\n令 $z = 1$：\n\n$$\nG_{ij}(1) = \\delta_{ij} + F_{ij}(1)G_{jj}(1)\\\\\ni = j \\rArr G_{ii}(1) = \\frac{1}{1 - F_{ii}(1)} \\rArr \\sum_{n = 0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}}\n$$\n\n常返性判别：\n\n$$\n常返态 \\lrArr f_{ii} = 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = +\\infty\\\\\n非常返态 \\lrArr f_{ii} \\lt 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}} < +\\infty\\\\\n$$\n\n后面会证明，这种返回的次数都是无穷大。\n\n常返的理解：\n\n$$\n\\forall n, A_n = \\begin{cases}\n    A_n = 1, X_n = i,\\\\\n    A_n = 0, X_n \\ne i.\n\\end{cases}\n$$\n\n$$\nE \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k | X_0 = i \\rbrace = \\sum\\limits_{k=0}^{\\infty}P_{ii}^{(0)}\\\\\n$$\n\n从判别定理可以看出，在期望意义上，常返态被无限次访问。\n\n推论1：既然常返态被无穷次返回，非常返态被有限次访问，则在有限状态的 Markov 链中一定存在常返态。\n\n反证法：如果全是有限返回次数，那所有态的访问次数加起来还是有限的，但是马尔可夫可以访问无限次，矛盾。所以一定有常返态。\n\n推论1.1：如果非常返态的个数有限，则足够长的时间后，状态一定会到达常返态。\n\n推论1.2：若 j 非常返，则$\\forall i$\n\n$$\n\\sum\\limits_{n=0}^{\\infty}P_{ij}^{(n)} < \\infty (i 到达 j的次数为有限值)\\\\\n\\lim_{n \\rightarrow \\infty} P_{ij}^{(n)} = 0\n$$\n\n推论2：若 $i$ 常返，$i \\lrarr j$，则 $j$ 也是常返的。\n\n推论3：若 $i$ 为常返，$i \\rarr j$，则 $j \\rarr i$\n\n#### 正常返与零常返\n\n$f_{ii}^n$ 可以视为首次返回时间 $T_{ii}$ 的概率分布。对于非常返态不能这么看，因为 $f_{ii} < 1$。\n\n对于常返态的 $T_{ii}$，可以计算期望\n\n$$\n\\mu_i = E \\lbrace T_{ii} \\rbrace = \\sum\\limits_{n = 1}^{\\infty} n f_{ii}^{(n)}\n$$\n\n若均值为无穷大，则称为零常返。\n\n零常返与非常返是有区别的。零常返是可以常返，只是大概率步数很多。\n\n定义返回的速率，可推导\n\n$$\n\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\sum\\limits_ {k=0}^{n - 1} P_{jj}^{(k)} = \\frac{1}{\\mu_j}\n$$\n\n正常返意味着速率为常数，零常返意味着速率为 0。\n\n判定定理：\n\n$$\nj 状态零常返 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{jj}^{(n)} = \\infty, 且 n \\rightarrow \\infty 时，P_{jj}^{(n)} = 0\n$$\n\n条件一就是常返的判定定理。条件二比较特殊：\n\n$$\n\\lim_{n \\rightarrow \\infty}P_{jj}^{(n)} = \\frac{1}{\\mu_j}\n$$\n\n如果是零常返，这个极限就是0。在条件二上，零常返和非常返是一样的。\n\n定理：常返态 $i$，$i \\rarr j$，则 $i, j$ 同为正常返或者零常返\n\n#### 补充性质\n\n$$\nq_{jj}(M) = P \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k \\ge M | X_0 = j \\rbrace\\\\\n\\lim_{M \\rarr \\infty}q_{jj}(M) = \\begin{cases}\n    1, f_{jj} = 1\\\\\n    0, f_{jj} < 1\\\\\n\\end{cases}\n$$\n\n下面研究常返态 $j$，不可约链\n\n“从常返态触发，返回次数为无穷大”这件事的概率为 1.\n\n$$\n\\lim_{M \\rarr \\infty} q_{rj}(M) = 1, \\forall\n$$\n\n“任意状态访问常返态的次数为无穷大”的概率为1.\n\n$$\nq_{ij}(M) = f_{ij}q_{jj}(M)\n$$\n\n两边取极限可得 $f_{ij} = 1$\n\n结论3： 从不可约链任何状态出发，迟早访问状态 $j$\n\n$$\n\\lim_{n \\rarr \\infty} P_{ij}^{(n)} = \\frac{1}{\\mu_j}\n$$\n\n结论4：极限概率与初始状态无关。\n\n分类方式\n\n对于每个常返态 i，存在一个 i 可达状态构成的状态集 C 。则这些状态彼此相通，构成一个不可约闭集，都常返\n\n马尔可夫链可以唯一划分为 $C_1, C_2, ..., T$，其中 $C_i$ 互为不相交的不可约闭集。T 为非常返态。每个闭集中，常返类型一致，不同闭集不互通。\n\n定理：马尔科夫链若有一个零常返，有无穷多个零常返。\n\n推论：有限状态马尔可夫链的常返态必然为正常返。\n\n#### 马尔可夫链的平稳分布和极限概率\n\n对于不可约链：\n\n$$\n\\lim_{n \\rarr \\infty}P_{ij}^{(n)} = 0，j非常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j} = 0，j零常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j}，j正常返\n$$\n\n极限概率用 $\\pi_j$表示\n\n对于非常返和零常返，极限概率都是0。零常返的链一定有无穷个状态。\n\n对于正常返，$\\pi_j \\gt 0, \\sum\\limits_{j\\in S}^{}\\pi_j = 1$\n\n从柯式方程得出：\n\n$$\n\\pi_j = \\sum\\limits_{i}^{}\\pi_iP_{ij}\n$$\n\n矩阵形式：\n$$\n\\lim_{n \\rarr \\infty} P^n = \\Pi = \\begin{bmatrix}\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n\\end{bmatrix}\n$$\n\n\n## 泊松过程\n\n### 定义\n\n#### 计数过程\n\n在 $[0, t]$ 内发生某类事件的次数记为 $\\lbrace N(t), t\\ge 0 \\rbrace$，则称 $\\lbrace N(t) \\rbrace$ 为计数过程。\n\n#### 泊松过程\n\n若满足以下条件：\n\n1. $N(0) = 0$\n2. 非负性：$N(t)$ 的取值非负整数；\n3. 非降性：$N(t)$ 是随时间单调不减的；\n4. 独立增量性：对于 $0 \\le t_1 < t_2 < \\ldots < t_n$，$N(t_2) - N(t_1), N(t_3) - N(t_2), \\ldots, N(t_n) - N(t_{n-1})$ 是相互独立的随机变量；\n5. 平稳增量性：对于 $0 \\le s < t$，$N(t) - N(s)$ 的分布只与时间间隔 $t-s$ 有关，而与具体的时刻 $s$ 无关。\n6. $P(N(t + \\Delta t) - N(t) = 1) = \\lambda\\Delta t + o(\\Delta t), P(N(t + \\Delta t) - N(t) \\ge 2) = o(\\Delta t)$\n则称 $\\lbrace N(t), t\\ge 0 \\rbrace$ 为泊松过程。\n\n### 性质\n\n泊松的表达式\n\n$$\nP_n(t) = P(N(t) = n) = \\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}\n$$\n\n泊松分布的特征函数\n\n$$\n\\phi_{N(t)}(\\omega) = \\exp \\left \\lbrace \\lambda t (e^{j\\omega} - 1) \\right \\rbrace\n$$\n\n泊松过程的数字特征\n\n$$\nE(N(t)) = \\lambda t\\\\\nR(t_1, t_2) = \\lambda t_1 + \\lambda^2 (t_1t_2) (t_1 \\le t_2)\\\\\nC(t_1, t_2) = \\min \\lbrace t_1, t_2 \\rbrace\n$$\n\n### 泊松与二项分布\n\n泊松分布是二项分布的极限。\n\n泊松脉冲串：\n\n$$\nX(t) = \\frac{\\mathrm dN(t)}{\\mathrm dt} = \\sum\\limits_{i}^{}\\delta(t - t_i)\\\\\nE(X(t)) = \\lambda\n$$\n\n### 泊松相关问题\n\n#### 事件间隔时间的分布\n\n$S_n$ 表示第 n 件事到达的时刻\n\n$T_n$ 表示相邻两件事发生的间隔\n\n$$\nP\\lbrace S_n \\gt t \\rbrace = P \\lbrace N(t) \\le n - 1 \\rbrace\n$$\n\n$$\nf_{T_n}(t) = \\lambda e^{-\\lambda t}\\\\\nE(T_n) = 1 / \\lambda\n$$\n\n$T_n$ 和 $T_m$ 是独立的。\n\n#### 等待时间的分布\n\n概率密度函数与特征函数互为傅里叶变换\n\n$$\n\\Phi_{T_i}(\\omega) = \\frac{\\lambda}{\\lambda - j\\omega}\\\\\n\\Phi_{S_n}(\\omega) = \\left (\\frac{\\lambda}{\\lambda - j\\omega}  \\right)^n\\\\\n$$\n\n要求 $S_n$ 的概率密度函数，可以看作 $T_n$ 的卷积：\n\n$$\nf_{S_n}(t) = \\frac{(\\lambda t)^{n - 1}}{(n - 1)!}\\lambda e^{-\\lambda t}\\\\\n$$\n\n称为 $\\Gamma$ 分布，参数 $\\lambda, n$。\n\n#### 相邻两次事件之间的计数\n\n两次公交车到来（速度 $\\mu$）之间，等车人数（速度 $\\lambda$）的计数：\n\n$$\nP(L = k) = (\\frac{\\mu}{\\mu + \\lambda})(\\frac{\\lambda}{\\mu + \\lambda})^k\n$$\n\n#### n个事件到达时间的的联合分布\n\n$$\nf_{S_1...S_n|N(t) = n}(u_1, u_2, ..., u_n) = \\frac{n!}{t^n}\n$$\n\n如果是有编号的（不是按顺序到达）：\n\n$$\nf_{V_1...V_n|N(t) = n}(t_1, t_2, ..., t_n) = \\frac{1}{t^n}\n$$\n\n以下分布的极限，就是泊松过程：\n\n$$\nP \\lbrace N(s) = k | N(t) = n \\rbrace = \\binom{n}{k}(\\frac{\\lambda s}{n})^k(1 - \\frac{\\lambda s}{n})^{n - k}\n$$\n\n#### 总结泊松过程的几种定义\n\n1. N(0) = 0，独立增量，平稳增量，$\\Delta t$ 内发生一个事件的概率 $\\lambda \\Delta t$，发生两件事以上的概率小\n2. 事件时间间隔独立同分布，服从复指数分布，则计数为泊松\n3. N 个客体随机地分布在 $[0, t]$ 区间上，每个客体的出现时间均匀分布，且相互时间独立，当 $n \\rightarrow \\infty, t \\rightarrow \\infty$，极限分布为泊松分布\n4. 二项分布的极限\n\n### 顺序统计量\n\n统计量是样本的某个函数 $g(X_1, ..., X_n)$。例如：最大值、中值、平均值、样本协方差阵\n\n顺序统计量：根据到达时刻排序。例如 $S_1, S_2, ..., S_n$ 就是 $V_1, V_2, ..., V_n$ 的顺序统计量\n\n$$\nf_{Y_k}(x) = \\binom{n}{k - 1}F(x)\\binom{n - k + 1}{1}f(x)(1 - F(x))^{n - k}\n$$\n\n有序的顺序统计量的分布：\n\n$$\nf_{Y_1...Y_n}(y_1, y_2, ..., y_n) = n!f(y_1)f(y_2)...f(y_n)\n$$\n\n### 非齐次泊松过程\n\n四个条件：\n\n$N(0) = 0$\n\n$N(t)$ 独立增量\n\n$P(N(t + \\Delta t) - N(t) = 1) = \\lambda(t)\\Delta t + o(\\Delta t)$\n\n$P(N(t + \\Delta t) - N(t) \\ge 2) = o(\\Delta t)$\n\n定理：\n\n$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{[m(t_0 + t) - m(t_0)]^n}{n!}e^{-[m(t_0 + t) - m(t_0)]}\n$$\n\n其中，\n\n$$\nm(t) = \\int_{0}^{t}\\mathrm \\lambda(u) du\n$$\n\n其意义可以理解为事件的个数。\n\n令 $m(t + t_0) - m(t_0) = \\alpha$\n\n$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{\\alpha^n}{n!}e^{-\\alpha}\n$$\n\n则期望和方差\n\n$$\nE(N(t_0 + t) - N(t_0)) = \\alpha\\\\\nV(N(t_0 + t) - N(t_0)) = \\alpha\n$$\n\n### 复合泊松\n\n$Y_n$ 随机变量族，$N(t)$ 泊松过程，称$X(t) = \\sum_{n = 1}^{N(t)}Y_n$ 为复合泊松。\n\n$$\nE \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i \\rbrace\\\\\nD \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i^2 \\rbrace\\\\\nG_X(z) = \\exp(\\lambda t G_Y(z) - 1)\\\\\n\\phi_X(\\omega) = \\exp(\\lambda t \\phi_Y(\\omega) - 1)\n$$\n\n### 随机参数泊松\n\n参数 $\\lambda$ 是随机变量，PDF为 $f(\\lambda)$\n\n* 是平稳增量\n* 不是独立增量\n\n$$\nP(Y(t) = n) = \\int^{+\\infty}_{0}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda\n$$\n\n母函数：\n\n$$\nG_{Y(t)}(z) = \\int_{0}^{\\infty}\\exp (\\lambda t(z - 1))f(\\lambda)\\mathrm d\\lambda\n$$\n\n$$\nE(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\nV(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\n$$\n\n数据统计的后验分布\n\n$$\nP(\\Lambda \\le x | Y(t) = n) = \\frac{\\int_{0}^{x}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\\\\\nf_\\Lambda(x|Y(t) = n) = \\frac{\\frac{(x t)^n}{n!}e^{-x t}f(x)}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\n$$\n\n### 过滤的泊松过程\n\n统计一段时间影响的总和\n\n$$\nY(t) = \\sum\\limits_{i=1}^{N(t)}h(t, S_i, A_i)\n$$\n\n特征函数：\n\n$$\n\\Phi_{Y(t)}(\\omega) = \\exp \\left ( \\lambda t \\left ( \\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv - 1\\right) \\right)\n$$\n\n均值：\n\n$$\nE(Y(t)) = \\frac{1}{j}\\frac{\\partial \\Phi_{Y(t)}}{\\partial \\omega} = \\underbrace{\\lambda t}_{平均到达个数} \\underbrace{\\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv}_{每个事件在 t 时刻的影响}\n$$\n\n## 生灭过程\n\n该过程状态可以用整数序列 $n = 0, 1, 2, 3, ...$ 来表示\n\n状态转移只能发生在临近状态之间\n\n在$[t, t + \\Delta t)$ 区间内，n状态转移到 $n + 1$ 状态的概率为 $\\lambda \\Delta t$， 转移到 $n - 1$ 状态的概率为 $\\mu \\Delta t$。\n\n### M/M/1\n\n系统平均顾客人数 $L = \\frac{\\lambda / \\mu}{1 - \\lambda / \\mu}$\n\n排队平均人数\n\n$$\nL_Q = \\sum\\limits_{n=1}^{\\infty}(n - 1)p_n = \\frac{\\lambda^2}{(\\mu - \\lambda)\\mu}\\\\\nL_Q \\ne L - 1\n$$\n\n前面有一个人，等待时间：负指数分布的无记忆性\n\n$$\nf_T(t|T > t_0) = \\mu e^{-\\mu (t - t_0)}\n$$\n\n从而不管你什么时候来，平均等待时间为 $1/\\mu$，和一个人被服务的时间是一样的。\n\n## 习题课\n\n![alt](../images/stochastic/exer_1.jpg)\n\n","slug":"Stochastic-Process","published":1,"updated":"2024-03-19T06:01:16.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfhz000prsug0s1ggyqq","content":"<h2 id=\"随机过程随机过\"><a href=\"#随机过程随机过\" class=\"headerlink\" title=\"随机过程随机过\"></a>随机过程随机过</h2><p>信号与系统：研究确定信号随着时间、空间的变化</p>\n<p>概率论：研究随机信号，但是不随时间、空间变化</p>\n<p>随机过程：研究随机的信号随着时间、空间的变化</p>\n<blockquote>\n<p>期末70分梭哈</p>\n<p>考试题目不随机，就跟不上这门课的要求。</p>\n</blockquote>\n<h3 id=\"概率与随机变量回顾\"><a href=\"#概率与随机变量回顾\" class=\"headerlink\" title=\"概率与随机变量回顾\"></a>概率与随机变量回顾</h3><p>样本空间$\\Omega$</p>\n<p>性质：</p>\n<ul>\n<li>非负性：$P(A) \\ge 0$</li>\n<li>规范性：$P(\\Omega), P(\\emptyset) &#x3D; 0$</li>\n<li>可加性：$P(\\bigcup\\limits_{k &#x3D; 1}^{\\infty}A_k) &#x3D; \\sum\\limits_{k&#x3D;1}^{\\infty}P(A_k)$</li>\n</ul>\n<p>贝叶斯：</p>\n<div>$$\nP(B_i|A) = \\frac{P(A|B_i)P(B_i)}{\\sum\\limits_{j = 1}^{k}P(B_j)P(A|B_j)}\n$$</div>\n\n<p>随机变量：</p>\n<p>分布函数，概率密度函数</p>\n<p>期望，方差，协方差，相关系数</p>\n<p>伯努利分布，高斯分布，泊松分布，瑞利分布</p>\n<p>伯努利分布的概率密度函数：</p>\n<p>当$k&#x3D;1$时，$P(X&#x3D;1) &#x3D; p$<br>当$k&#x3D;0$时，$P(X&#x3D;0) &#x3D; 1-p$</p>\n<p>高斯分布的概率密度函数：<br>$P(x) &#x3D; \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$</p>\n<p>二维高斯分布的概率密度函数：</p>\n<p>$P(x,y) &#x3D; \\frac{1}{2\\pi\\sigma_x\\sigma_y\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left[\\frac{(x-\\mu_x)^2}{\\sigma_x^2}-2\\rho\\frac{(x-\\mu_x)(y-\\mu_y)}{\\sigma_x\\sigma_y}+\\frac{(y-\\mu_y)^2}{\\sigma_y^2}\\right]\\right)$</p>\n<p>其中，$\\mu_x$和$\\mu_y$是均值，$\\sigma_x$和$\\sigma_y$是标准差，$\\rho$是相关系数。</p>\n<p>泊松分布的概率密度函数：<br>$P(k;\\lambda) &#x3D; \\frac{\\lambda^k}{k!}\\exp(-\\lambda)$</p>\n<p>瑞利分布的概率密度函数：<br>$P(x;\\sigma) &#x3D; \\frac{x}{\\sigma^2}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$</p>\n<h3 id=\"随机过程的基本概念\"><a href=\"#随机过程的基本概念\" class=\"headerlink\" title=\"随机过程的基本概念\"></a>随机过程的基本概念</h3><p>定义：</p>\n<p>给定概率空间$(\\Omega, \\mathcal{F}, P)$，定义参数集$T \\subset R$，$t \\in T$</p>\n<div>$$\nX = \\lbrace X(t, \\omega), t \\in T, \\omega \\in \\Omega \\rbrace\n$$</div>\n\n<p>简记为$X(t)$: $X &#x3D; \\lbrace X(t), t \\in T\\rbrace$</p>\n<p>解释：</p>\n<ul>\n<li>二元单值函数</li>\n<li>对每个固定t，$X(t, \\omega)$是一个随机变量</li>\n<li>每个$\\omega_0 \\in \\Omega$, $X(t, \\omega_0)$是定义在T上的函数，记为$x(t, \\omega_0)$</li>\n</ul>\n<p>单样本为随机变量：均值、方差、协方差、有限维联合分布等</p>\n<p>随机过程的函数特性：时间的相关性，连续性和离散性，随机过程的导数、微分、积分、卷积、级数展开、微分方程、积分方程等</p>\n<p>二重性的联合特征：</p>\n<p>分类：</p>\n<p>离散时间，离散分布：Bernouli过程</p>\n<p>离散时间，连续分布：自回归过程</p>\n<p>连续参数离散随机过程：Poission过程</p>\n<p>连续参数连续型随机过程：Brown运动</p>\n<p>数学特征：</p>\n<p>相互独立和不相关是两个概念，无必然因果联系。</p>\n<p>根据数字特征分类：</p>\n<ul>\n<li>独立增量过程</li>\n<li>平稳过程及二阶矩过程</li>\n<li>马尔可夫过程</li>\n<li>更新过程</li>\n</ul>\n<p>独立增量过程是一种随机过程，具有以下特性：</p>\n<ol>\n<li><p>零起点：独立增量过程在零时刻（通常表示为$t&#x3D;0$）的取值为零，即$X(0) &#x3D; 0$。</p>\n</li>\n<li><p>独立增量：对于任意时刻$t_1 &lt; t_2 &lt; \\cdots &lt; t_n$，随机变量$X(t_2)-X(t_1), X(t_3)-X(t_2), \\cdots, X(t_n)-X(t_{n-1})$是相互独立的。</p>\n</li>\n</ol>\n<p>若对一切$0\\le s \\lt t$，增量$X(t) - X(s)$的分布仅依赖于$t - s$，则称之为平稳增量，具有平稳增量的独立增量过程称为独立平稳增量过程，例如泊松和布朗。</p>\n<p>二阶矩过程：$D(X(t))$</p>\n<p>宽平稳过程：</p>\n<p>宽平稳过程可以用以下简单的数学表达式表示：</p>\n<ol>\n<li><p>均值平稳性：对于宽平稳过程 $X(t)$，其均值满足 $E[X(t)] &#x3D; \\mu$，其中 $\\mu$ 是一个常数。</p>\n</li>\n<li><p>自相关平稳性：宽平稳过程的自相关函数在时间差 $\\tau$ 下为常数，可以表示为 $R_X(\\tau) &#x3D; R_X(t,t+\\tau) &#x3D; \\text{常数}$，其中 $R_X(\\tau)$ 表示宽平稳过程的自相关函数。</p>\n</li>\n</ol>\n<p>严平稳过程（Strict-sense stationary process），也称为严格平稳过程或强平稳过程，是一种具有更强平稳性质的随机过程。它满足以下两个条件：</p>\n<ol>\n<li><p>时移不变性：严平稳过程的统计性质在时间上任意平移保持不变。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，随机变量 $X(t)$ 和 $X(t+\\tau)$ 的联合分布相同，即联合分布满足 $P(X(t) \\in A, X(t+\\tau) \\in B) &#x3D; P(X(0) \\in A, X(\\tau) \\in B)$，其中 $A,B$ 是任意集合。</p>\n</li>\n<li><p>自相关平稳性：严平稳过程的自相关函数只与时间差有关，与参考时刻无关。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，自相关函数满足 $R_X(t,t+\\tau) &#x3D; R_X(\\tau)$，其中 $R_X(\\tau)$ 表示严平稳过程的自相关函数。</p>\n</li>\n</ol>\n<p>马尔可夫过程是一种具有马尔可夫性质的随机过程。它可以用以下公式和概念来定义：</p>\n<ol>\n<li><p>状态空间：马尔可夫过程的状态空间是一个离散集合，表示可能的状态集合。通常用符号 $S$ 表示，$S &#x3D; {s_1, s_2, \\ldots}$。</p>\n</li>\n<li><p>马尔可夫性质：马尔可夫过程具有马尔可夫性质，也称为无后效性。即，在给定当前时刻的状态 $X(t)$ 之下，未来的状态 $X(t+\\Delta t)$ 只依赖于当前的状态 $X(t)$，与过去的状态 $X(t-1), X(t-2), \\ldots$ 无关。</p>\n</li>\n<li><p>转移概率：转移概率描述了在给定当前状态 $s_i$ 的情况下，马尔可夫过程在下一个时刻转移到状态 $s_j$ 的概率。转移概率通常用符号 $P_{ij}$ 表示，即 $P_{ij} &#x3D; P(X(t+\\Delta t) &#x3D; s_j \\mid X(t) &#x3D; s_i)$。</p>\n</li>\n</ol>\n<p>通过状态空间和转移概率，可以构建一个马尔可夫过程的状态转移矩阵（Transition Matrix），它描述了从一个状态到另一个状态的转移概率情况。</p>\n<p>更新过程：</p>\n<p>更新过程可以使用以下公式来描述：</p>\n<ol>\n<li><p>到达时间：假设到达时间的随机变量序列为 $T_1, T_2, T_3, \\ldots$，其中 $T_i$ 表示事件 $i$ 的到达时间。</p>\n</li>\n<li><p>描述参数：更新过程的到达率（或强度）表示单位时间内平均发生事件的次数。通常用符号 $\\lambda$ 表示，即 $\\lambda &#x3D; \\lim_{t \\to \\infty} \\frac{N(t)}{t}$，其中 $N(t)$ 表示时间 $t$ 之前（包括 $t$）发生的事件次数。</p>\n</li>\n<li><p>插值函数：更新过程的插值函数（或插值过程）表示给定时间 $t$ 时，最近的到达时间是多久之前。记为 $S(t)$，即 $S(t) &#x3D; \\sup{T_i \\leq t}$，表示最近的到达时间小于等于 $t$ 的时间点。</p>\n</li>\n</ol>\n<p>可以定义复随机过程：</p>\n<p>复随机过程是一组复数值随机变量的集合 ${X(t), t \\in T}$，其中 $X(t)$ 是定义在概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数值随机变量，表示在时间点 $t$ 上的取值。</p>\n<p>具体而言，对于每个时间点 $t \\in T$，$X(t)$ 是一个复数值随机变量，可以表示为 $X(t) &#x3D; R(t) + iI(t)$，其中 $R(t)$ 和 $I(t)$ 分别表示实部和虚部。</p>\n<p>复随机过程可以通过概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数随机变量以及时间参数 $T$ 来描述，并且在不同时间点上表现出复数值随机变量的随机性质。</p>\n<p>数学特征：</p>\n<p>均值函数（一阶原点矩）：$\\mu_X(t) &#x3D; E[X(t)]$</p>\n<p>方差函数：$\\text{Var}[X(t)] &#x3D; E[(X(t) - \\mu_X(t))(X(t) - \\overline{\\mu_X(t)} )]$</p>\n<p>自相关函数：$R_X(t_1, t_2) &#x3D; E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$</p>\n<p>自协方差函数：$\\text{Cov}[X(t_1), X(t_2)] &#x3D; E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$</p>\n<p>均方值函数：$E[|X(t)|^2] &#x3D; \\int_{-\\infty}^{\\infty} |x|^2 f_X(x,t)dx$</p>\n<h3 id=\"基本研究方法\"><a href=\"#基本研究方法\" class=\"headerlink\" title=\"基本研究方法\"></a>基本研究方法</h3><ul>\n<li>相关方法</li>\n<li>Markov 方法</li>\n</ul>\n<p><strong>相关</strong></p>\n<p>若随机过程在任意时刻的均值和方差都存在，则称之为二阶矩过程（second order process），即均方可积空间上的随机变量。</p>\n<p>均方可积空间是内积空间。相关运算是均方可积的内积运算：</p>\n<div>$$\n\\langle X, Y \\rangle = E(X\\overline Y)\n$$</div>\n\n\n<p>宽平稳（wide-sense stationary）:</p>\n<div>$$\nR_X(t, s) = R_X(t + D, s + D) = R(t - s)\n$$</div>\n\n<p>功率谱密度：</p>\n<div>$$\nS_X(\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\exp(-j\\omega\\tau)\\mathrm d\\tau\n$$</div>\n\n<p>最优线性估计</p>\n<p><strong>Markov</strong></p>\n<p>有限维联合分布可以由各阶的条件分布表示出来：</p>\n<div>$$\n\\begin{align*}\n    &F_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n) \\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)F_{X(t_{n - 1}), \\dots, X(t_1)}(x_1, \\dots, x_{n - 1})\\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n\\end{align*}\n$$</div>\n\n<p>无后效性的 markov 过程：</p>\n<div>$$\nF_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1) = F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\n$$</div>\n\n<p>从而所有高阶依赖关系都可以简化为二阶依赖：</p>\n<div>$$\nF_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n)=F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n$$</div>\n\n<h2 id=\"相关理论与二阶矩过程——时域分析\"><a href=\"#相关理论与二阶矩过程——时域分析\" class=\"headerlink\" title=\"相关理论与二阶矩过程——时域分析\"></a>相关理论与二阶矩过程——时域分析</h2><h3 id=\"自相关函数\"><a href=\"#自相关函数\" class=\"headerlink\" title=\"自相关函数\"></a>自相关函数</h3><p>由二阶矩过程的定义可知，均方可积空间的自相关函数、自协方差函数、互相关函数、互协方差函数均存在。</p>\n<p>均值函数（一阶原点矩）：$\\mu_X(t) &#x3D; E[X(t)]$</p>\n<p>方差函数：$\\text{Var}[X(t)] &#x3D; E[(X(t) - \\mu_X(t))^2]$</p>\n<p>自相关函数：$R_X(t_1, t_2) &#x3D; E[(X(t_1))(X^*(t_2))]$</p>\n<p>自协方差函数：$C_X(t_1, t_2) &#x3D; \\text{Cov}[X(t_1), X(t_2)] &#x3D; E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\mu_X(t_2))^*]$</p>\n<p>均方值函数：$E[X^2(t)] &#x3D; \\int_{-\\infty}^{\\infty} x^2 f_X(x,t)dx$</p>\n<p>互相关函数和互协方差函数：</p>\n<ul>\n<li>如果$E[X(s)Y(t)]存在$，记为$R_{XY}(s, t)$</li>\n<li>如果$\\text{cov}(X(s), Y(t))存在$，记为$C_{XY}(s, t)$</li>\n</ul>\n<div>$$\nR_{XY}(t_1, t_2) = E[(X(t_1))(Y^*(t_2))]\n$$</div>\n\n<div>$$\nC_{XY}(t_1, t_2) = E[(X(t_1) - \\mu_X(t_1))(Y(t_2) - \\mu_Y(t_2))^*]\n$$</div>\n\n<div>$$\nC_{XY}(s, t) = R_{XY}(s,t) - \\mu_X(s)\\mu_Y(t)\n$$</div>\n\n<p>不相关：</p>\n<div>$$\nC_{XY}(s, t) = 0\n$$</div>\n\n<div>$$\nR_{XY}(s,t) = m_X(s)m_Y(t)\n$$</div>\n\n\n<p>自相关函数具有共轭对称性：</p>\n<div>$$\nR(t_1, t_2) = R^*(t_2, t_1)\n$$</div>\n\n<p>离散化的自相关矩阵同样是共轭对称的：</p>\n<div>$$\nR = E[XX^H]\\\\\nR_{ij} = R^*_{ji}\n$$</div>\n\n<p>自相关矩阵是非负定的：</p>\n<div>$$\n\\lambda R \\lambda^H = \\lambda XX^H\\lambda^H \\ge 0\n$$</div>\n\n<p>当 $P(\\lambda X &#x3D; 0) &#x3D; 1$ 时等号成立。</p>\n<p>非负定性是自相关函数的一种特征性质。如果一个二元函数满足非负定性质，则一定可以构造出一个随机过程，使得其自相关函数为给定的二元函数。</p>\n<p>自相关矩阵非负定，分解的特征值均非负。其物理意义是信号的能量或者功率。</p>\n<p>自相关函数对加法和乘法的封闭性：</p>\n<div>$$\nR(t, s) = \\alpha R_1(t, s) + \\beta R_2(t, s)\n$$</div>\n\n<p>仍然是某一随机过程的自相关函数。</p>\n<p>证明：取 $Z(t) &#x3D; \\alpha^{1&#x2F;2} X(t) + \\beta^{1&#x2F;2} Y(t)$。这里 $X(t), Y(t)$是独立的。</p>\n<div>$$\nR(t, s) = R_1(t, s)R_2(t, s)\n$$</div>\n\n<p>也是自相关函数。取 $Z(t) &#x3D; X(t)Y(t)$。</p>\n<h3 id=\"宽平稳随机过程\"><a href=\"#宽平稳随机过程\" class=\"headerlink\" title=\"宽平稳随机过程\"></a>宽平稳随机过程</h3><p><strong>宽平稳</strong></p>\n<p>对于随机过程 $X(t), t \\in T$，若 $\\forall t, s\\in T$</p>\n<div>$$\nE(X(t)) = E(X(s))\\\\\nR_X(t, s) = R_X(t + D, s + D)\n$$</div>\n\n<p>称随机过程 $X(t)$ 具有宽平稳性。</p>\n<p>宽平稳过程的均值是常数，自相关函数与相对时间差有关。故宽平稳过程的自相关函数可以写成一元函数：$R_X(\\tau), \\tau &#x3D; t - s$。</p>\n<p><strong>严平稳</strong></p>\n<p>对于随机过程 $X(t), t \\in T$，若 $\\forall n, \\forall t_1, t_2, \\dots, t_n \\in T$，$\\forall D \\in T$，都有</p>\n<div>$$\nF_{t_1, t_2, \\dots, t_n}(x_1, x_2, \\dots, x_n) = F_{t_1 + D, t_2+D, \\dots, t_n + D}(x_1, x_2, \\dots, x_n)\n$$</div>\n\n<p>则称随机过程 $X(t), t\\in T$具有严平稳性。</p>\n<p>在二阶矩存在的条件下，严平稳蕴含宽平稳，而反过来，宽平稳一般无法得到严平稳。</p>\n<p>高斯过程的严平稳与宽平稳等价。</p>\n<p><strong>联合宽平稳</strong></p>\n<div>$$\nR_{X, Y}(t, s) = R_{XY}(t + D, s + D), \\forall D \\in T\n$$</div>\n\n<p><strong>宽平稳过程的性质</strong></p>\n<p>设 $R_X(\\tau)$ 为宽平稳过程的自相关函数， $m_X$ 为该过程的均值。</p>\n<div>$$\n\\begin{align}\n    R_X(\\tau) = \\overline{R_X(-\\tau)}\\\\\n    R_X(0)\\ge |m_X|^2\\\\\n    |R_X(\\tau)| \\le R_X(0)\\\\\n    R_X(\\tau) \\text{是一元非负定函数。}\n\\end{align}\n$$</div>\n\n<h3 id=\"正交增量过程\"><a href=\"#正交增量过程\" class=\"headerlink\" title=\"正交增量过程\"></a>正交增量过程</h3><p><strong>正交增量过程</strong></p>\n<p>对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，满足</p>\n<div>$$\nE(X(t_4) - X(t_3))(\\overline{X(t_2) - X(t_1)}) = 0\n$$</div>\n\n<p>则称 $X(t), t \\in \\R$ 为正交增量过程。</p>\n<p><strong>独立增量过程</strong></p>\n<p>对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，$X(t_4) - X(t_3)$ 和 $X(t_2) - X(t_1)$ 统计独立，则称为独立增量过程。</p>\n<p>均值为0的独立增量过程是正交增量过程。</p>\n<p><strong>平稳增量过程</strong></p>\n<p>对于随机过程 $X(t), t \\in \\R$，若 $X(t) - X(s)$ 的分布仅仅依赖于 $t - s$，则称为平稳增量过程。</p>\n<p>定理：</p>\n<p>随机过程 $X(t), t \\in [0, \\infty]$，满足 $X(0) &#x3D; 0$，则其为正交增量过程的充要条件为</p>\n<div>$$\nR_X(s, t) = F(\\min(s, t))\n$$</div>\n\n<p>其中，$F(\\cdot)$是单调不减的函数。</p>\n<h3 id=\"随机过程的极限、连续、导数、积分\"><a href=\"#随机过程的极限、连续、导数、积分\" class=\"headerlink\" title=\"随机过程的极限、连续、导数、积分\"></a>随机过程的极限、连续、导数、积分</h3><p><strong>均方极限</strong></p>\n<div>$$\nE(|ka|^2)\n$$</div>\n\n\n\n<p>唯一性：若 $X_n \\xrightarrow{m.s} X, X_n \\xrightarrow{m.s}Y$，则 $E(|X - Y|^2) &#x3D; 0$.</p>\n<p>可加性：</p>\n<p>数字特征相同：</p>\n<p>如何判定 ${X_n}$ 是否收敛？</p>\n<p>Cauchy 准则</p>\n<div>$$\nX_n \\xrightarrow{m.s}{X} \\Leftrightarrow E(|X_m - X_n|^2) = 0, m, n \\rightarrow \\infty\n$$</div>\n\n<p>洛伊夫准则：</p>\n<div>$$\nX_n \\xrightarrow{m.s} X \\lrArr E\\lbrace X_n X_m^*\\rbrace \\rightarrow \\text{constant}\n$$</div>\n\n<p><strong>均方连续</strong></p>\n<p>二阶矩过程，$t \\rightarrow t_0, X(t) \\xrightarrow{m.s.} X(t_0)$，则称 $X(t)$ 在 $t_0$ 处连续</p>\n<p>定理</p>\n<p>以下命题等价：</p>\n<ol>\n<li>$R(t, s)$ 在 $(t_0, t_0)$ 上连续，$\\forall t_0 \\in T$</li>\n<li>$X(t)$ 在 $T$ 上均方连续</li>\n<li>$R(t, s)$ 在 $T \\times T$ 上连续</li>\n</ol>\n<p>推论</p>\n<p>对于宽平稳过程 $X(t)$，$R(\\tau)$ 为自相关函数，以下命题等价：</p>\n<ol>\n<li>$R(\\tau)$ 在 $\\tau &#x3D; 0$ 处连续；</li>\n<li>$X(t)$ 在 $T$ 上均方连续；</li>\n<li>$R(\\tau)$ 在 T 上连续。</li>\n</ol>\n<p><strong>均方导数</strong></p>\n<p>若 $\\frac{X(t_0 + h) - X(t_0)}{h}\\xrightarrow{m.s.}Y(t_0), \\forall t_0 \\in T, h \\rightarrow 0$，则称$\\lbrace X(t) \\rbrace$ 在均方意义下的导数为 $Y(t)$。</p>\n<p>如何判断 $X(t)$ 是否均方可导？</p>\n<p>Cauchy 准则</p>\n<div>$$\nE\\left(|\\frac{X(t_0 + h) - X(t_0)}{h} - \\frac{X(t_0 + g) - X(t_0)}{g}|^2\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$</div>\n\n<p>洛伊夫准则</p>\n<div>$$\nE\\left(\\left(\\frac{X(t_0 + h) - X(t_0)}{h}\\right)\\left(\\frac{X(t_0 + g) - X(t_0)}{g}\\right)^*\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$</div>\n\n<p>均方导数判定定理</p>\n<div>$$\n\\frac{\\partial^2 R(t, s)}{\\partial t \\partial s} 在 (t_0, t_0) 存在且连续，则 X(t) 在 t_0 处存在均方倒数\n$$</div>\n\n<p>均方导数的性质：</p>\n<p>$f(t)$ 为线性函数</p>\n<ul>\n<li>$E(X^\\prime(t)) &#x3D; \\frac{\\mathrm d }{\\mathrm dt} E(X(t))$</li>\n<li>$E(X^\\prime(t)\\overline{X(s)}) &#x3D;\\frac{\\partial }{\\partial t}R_x(t, s)$</li>\n<li>$E(X(t)\\overline{X^\\prime(s)}) &#x3D;\\frac{\\partial }{\\partial s}R_x(t, s)$</li>\n<li>$E(X^\\prime(t)\\overline{X^\\prime(s)}) &#x3D;\\frac{\\partial^2 }{\\partial t\\partial s}R_x(t, s)$</li>\n</ul>\n<p><strong>均方积分</strong></p>\n<p>若黎曼和 $\\sum\\limits_{k&#x3D;1}^{n}X(v_k)h(v_k)(t_k - t_{k - 1})$ 在 $n \\rightarrow \\infty, \\max\\lbrace t_k - t_{k - 1}\\rbrace \\rightarrow 0$ 时均方收敛，其中 $h(t)$ 为确定的可积函数，则称$\\lbrace X(t)\\rbrace$ 为均方可积，记为 $\\int_{a}^{b}X(t)h(t)\\mathrm dt$。</p>\n<p>判定定理</p>\n<div>$$\n\\lbrace X(t)h(t) \\rbrace 均方可积 \\Leftrightarrow \\int_{a}^{b}\\int_{a}^{b}R_X(t, s)h(t)h^*(s)\\mathrm dt\\mathrm ds 存在\n$$</div>\n\n<p>均方积分的性质：</p>\n<ul>\n<li>$E\\left( \\int_{a}^{b}X(t)h(t)\\mathrm dt\\right) &#x3D; \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$</li>\n<li>$E\\left( \\left(\\int_{a}^{b}X(t)h(t)\\mathrm dt\\right)\\left(\\int_{a}^{b}X(s)h(s)\\mathrm ds\\right)^*\\right) &#x3D; \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$</li>\n<li>三角不等式：$\\sqrt{ E \\left(|\\int_{a}^{b}X(t)h(t)\\mathrm dt|^2\\right) } \\le \\int_{a}^{b}\\sqrt{E\\left(|X(t) - h(t)|^2\\right)}\\mathrm dt$</li>\n<li>均方积分与均方导数：$X(t)$ 在 $[a, b]$ 上均方连续，$Y(t) &#x3D; \\int_{a}^{t}X(s)\\mathrm ds$，其中等号代表均方相等，则 $\\lbrace Y(t)\\rbrace$ 在 $[a, b]$ 可导，并称在均方意义下 $\\lbrace Y(t) \\rbrace$ 的导数为 $\\lbrace X(t) \\rbrace$</li>\n</ul>\n<h3 id=\"随机过程的遍历性\"><a href=\"#随机过程的遍历性\" class=\"headerlink\" title=\"随机过程的遍历性\"></a>随机过程的遍历性</h3><p>统计平均：对样本空间取平均</p>\n<div>$$\nE\\lbrace X(t_0) \\rbrace = \\int_{}^{}x\\mathrm dF_X(x;t_0)\n$$</div>\n\n<p>时间平均：</p>\n<div>$$\n\\langle X(t) \\rangle = \\frac{1}{T} \\int_{-T/2}^{T/2}X(t)\\mathrm dt\n$$</div>\n\n<p>统计平均和时间平均的关系？</p>\n<p>时间平均更容易获得。如果我们可以通过时间平均来获得统计平均？</p>\n<p><strong>遍历性</strong></p>\n<p>定义-宽平稳过程均值遍历：</p>\n<div>$$\n\\langle X(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} E \\lbrace X(t) \\rbrace = \\mu\n$$</div>\n\n<p>a.s. &#x3D; with probability 1</p>\n<p>左边是随机变量，右边是一个确定的数。这样的相等，意味着左边的随机变量的均值确定，方差为0.</p>\n<p>定义：宽平稳过程自相关遍历</p>\n<div>$$\n\\langle X(t + \\tau)X^*(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t + \\tau)X^*(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} R_X(\\tau) = E \\lbrace X(t + \\tau)X^*(t)\\rbrace\n$$</div>\n\n<p>a.s. &#x3D; with probability 1</p>\n<p>定理：</p>\n<p>宽平稳过程 $X(t)$ 满足均值遍历 $\\lrArr$ </p>\n<div>$$\nD(\\langle X(t) \\rangle) = \\lim\\limits_{T \\rightarrow\\infty} \\frac{1}{2T}\\int_{-2T}^{2T}\\left(1 - \\frac{|\\tau|}{2T}\\right)(R_X(\\tau) - |\\mu|^2)\\mathrm d\\tau = 0\n$$</div>\n\n<p>定理：</p>\n<p>宽平稳过程具有均值遍历性的充要条件是：</p>\n<div>$$\n\\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T}\\int_{-T}^{T}C_X(\\tau)\\mathrm d\\tau = 0 或者 \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{T}\\int_{0}^{T}C_X(\\tau)\\mathrm d\\tau = 0\n$$</div>\n\n<p>时间比较长的时候相关性消失了，也就是说过了一段时间同一轨道的样本就独立了，等价于多个轨道的样本，时间平均和统计平均就相等了。</p>\n<p>2个推论：</p>\n<ul>\n<li>若实数宽平稳过程的协方差函数满足 $\\int_{0}^{+\\infty}C_x(\\tau)\\mathrm d\\tau\\lt +\\infty$，则该过程具有均值遍历性</li>\n<li>若实数宽平稳过程的协方差函数满足 $C_x(\\tau) \\rightarrow 0, \\tau \\rightarrow +\\infty$，则该过程具有均值遍历性</li>\n</ul>\n<h3 id=\"随机过程的线性展开\"><a href=\"#随机过程的线性展开\" class=\"headerlink\" title=\"随机过程的线性展开\"></a>随机过程的线性展开</h3><p><strong>卡胡曼-洛伊夫展开</strong></p>\n<p>在平方可积空间上</p>\n<p>定义范数</p>\n<p>定义内积，正交</p>\n<p>在 $L^2[a, b]$ 中一定有一组标准正交基函数 $\\phi_1(t), \\phi_2(t), \\phi_3(t)\\dots$ 满足</p>\n<div>$$\n\\begin{cases}\n    \\langle \\phi_i, \\phi_j \\rangle = 0, i\\ne j\\\\\n    \\langle \\phi_i, \\phi_i \\rangle = 1\n\\end{cases}\n$$</div>\n\n<ul>\n<li>$f$ 可以用有限个基函数线性加和来逼近</li>\n<li>$\\langle f, \\phi_n \\rangle$ 表示 $f$ 在 $\\phi_n$ 基上的坐标。</li>\n</ul>\n<p>周期性宽平稳随机过程可以用傅里叶级数展开</p>\n<div>$$\nE\\left(\\left |X(t) -\\sum\\limits_{n=-\\infty}^{\\infty}c_ne^{j\\omega_0t}  \\right |^2\\right) = 0\n$$</div>\n\n<p>一般的用 KL 展开</p>\n<p>随机向量的双正交展开：</p>\n<p>零均值的 $n$ 元随机向量 $\\mathbf X \\in R^n$ 可以如下展开：</p>\n<div>$$\nX = \\sum\\limits_{k=1}^{n} \\xi_k \\mathbf e_k\n$$</div>\n\n<p>基向量选择的是自相关矩阵 $\\mathbf R$ 的特征向量。</p>\n<p>如果我们用 $\\mathbf K$ 个维度来逼近 $\\mathbf X$，为了使得误差最小，选取最大的$\\mathbf K$个特征值： $\\mathbf X &#x3D;\\sum\\limits_{k&#x3D;1}^{K} \\alpha_k\\mathbf e_k$。这就是主成分分析（PCA）。</p>\n<h2 id=\"谱分析\"><a href=\"#谱分析\" class=\"headerlink\" title=\"谱分析\"></a>谱分析</h2><h3 id=\"周期函数的傅里叶级数\"><a href=\"#周期函数的傅里叶级数\" class=\"headerlink\" title=\"周期函数的傅里叶级数\"></a>周期函数的傅里叶级数</h3><div>$$\nx(t) =\\sum\\limits_{n=-\\infty}^{\\infty}a_n e^{j\\omega_0 t}, \\omega_0 = \\frac{2\\pi}{T}\\\\\na_n = \\frac{1}{T}\\int_{0}^{T}x(t)e^{-jn\\omega_0t}\\mathrm dt\n$$</div>\n\n<p>帕斯瓦尔定理</p>\n<div>$$\n\\frac{1}{T}\\int_{0}^{T}|x(t)|^2\\mathrm dt =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\n$$</div>\n\n<p>自相关函数</p>\n<div>$$\nR(\\tau) = \\frac{1}{T}\\int_{0}^{T}x(t + \\tau)x^*(t)\\mathrm dt\n$$</div>\n\n<p>功率谱密度</p>\n<div>$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\\delta(\\omega - n \\omega_0)\n$$</div>\n\n<p>从而有</p>\n<div>$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\n$$</div>\n\n<h3 id=\"非周期函数的傅里叶变换\"><a href=\"#非周期函数的傅里叶变换\" class=\"headerlink\" title=\"非周期函数的傅里叶变换\"></a>非周期函数的傅里叶变换</h3><h4 id=\"知识\"><a href=\"#知识\" class=\"headerlink\" title=\"知识\"></a>知识</h4><div>$$\nF(\\omega) = \\int_{-\\infty}^{\\infty}x(t)\\exp(-j\\omega t)\\mathrm dt\\\\\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}F(\\omega)\\exp(j\\omega t)\\mathrm d\\omega = \\int_{-\\infty}^{\\infty}F(f)\\exp(j2\\pi ft)\\mathrm df\n$$</div>\n\n<p>帕斯瓦尔定理</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}|x(t)|^2\\mathrm dt = \\int_{-\\infty}^{\\infty}|F(f)|^2\\mathrm df\n$$</div>\n\n<div>$$\n时域采样 \\lrarr 频域周期延拓\\\\\n时域周期延拓 \\lrarr 频域采样\\\\\n$$</div>\n\n<p>自相关函数</p>\n<div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}x(t + \\tau)x^*(t)\\mathrm dt\n$$</div>\n\n<p>能量谱密度</p>\n<div>$$\nS(\\omega) = |F(\\omega)|^2 = \\left |\\int_{-\\infty}^{\\infty}x(t)e^{j\\omega t}\\mathrm dt  \\right|^2\\\\\n$$</div>\n\n<p>波赫纳尔——辛钦定理</p>\n<div>$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S(\\omega)e^{j\\omega\\tau}\\mathrm d\\omega, S(\\omega)\\ge 0\n$$</div>\n\n<p>实过程的 $S(\\omega)$ 为偶函数。</p>\n<p>离散随机过程的功率谱：</p>\n<p>只在整数点 k 采样</p>\n<div>$$\nS(\\omega) =\\sum\\limits_{k=-\\infty}^{\\infty}R(k)e^{-j\\omega k}\\\\\nR(k) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}S(\\omega)e^{j\\omega k}\\mathrm d\\omega\n$$</div>\n\n<p>周期过程（自相关函数有周期性）的功率谱</p>\n<div>$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}b_n\\delta(\\omega - n \\Delta \\omega)\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\sum\\limits_{n=-\\infty}^{\\infty}b_ne^{jn\\Delta\\omega\\tau}\n$$</div>\n\n<h4 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h4><p>白噪声 $E \\lbrace X(t) \\rbrace &#x3D; 0$，</p>\n<div>$$\nS(\\omega) = N_0, -\\infty \\lt \\omega \\le \\infty\\\\\nR(\\tau) = N_0\\delta(\\tau)\n$$</div>\n\n<ul>\n<li>任意两个不同时刻 $X(t_1), X(t_2)$ 都不相关。</li>\n<li>在各个频率上都有分量，且强度一致。</li>\n</ul>\n<p>高斯白噪声：各时刻服从高斯分布的白噪声</p>\n<p>色噪声： $R(\\tau)$ 不是冲击函数。</p>\n<ul>\n<li>当某过程 $R(\\tau)$ 比较胖的时候，功率谱比较瘦<ul>\n<li>相隔较长时间 $X(t)$ 与 $X(t + \\tau)$ 还相关，说明信号变化慢，对应频域低频多<br>分量多</li>\n</ul>\n</li>\n<li>当某过程 $R(\\tau)$ 比较瘦时，功率谱比较胖</li>\n<li>相隔一点时间， $X(t)$ 与 $X(t + \\tau)$ 不太相关，说明信号变化快，对应频域高频分量多。</li>\n</ul>\n<p>互谱密度</p>\n<div>$$\nS_{XY}(\\omega) = \\int_{-\\infty}^{\\infty}R_{XY}(\\tau)e^{-j\\omega \\tau}\\mathrm d\\tau\n$$</div>\n\n<p>称为互谱密度，不具有功率的含义。</p>\n<div>$$\nS_{YX}(\\omega) = S_{XY}^*(\\omega)\\\\\nR_{XY}(\\tau) = 0, \\forall \\tau \\lrArr S_{XY}(\\omega) = 0, \\forall \\omega\n$$</div>\n\n<div>$$\nZ(t) = X(t) + Y(t)\\\\\nR_Z(\\tau) = E \\lbrace (X(t + \\tau) + Y(t + \\tau))\\overline{(X(t) + Y(t))} \\rbrace = R_X(\\tau) + R_{XY}(\\tau) + R_{XY}\n$$</div>\n\n<p>一个宽平稳过程分别通过两个 LTI 系统：</p>\n<div>$$\nY_1(t) = X(t) * h_1(t)\\\\\nY_2(t) = X(t) * h_2(t)\\\\\nR_{Y_1Y_2}(\\tau) = R_X(\\tau) * h_1(\\tau) * h_2^*(-\\tau)\\\\\nS_{Y_1Y_2}(\\omega) = S_X(\\omega)H_1(\\omega)H_2^*(\\omega)\\\\\n$$</div>\n\n<p>两个过程输入两个系统，输出过程的互谱（互相关函数的傅里叶变换）。怎么求？</p>\n<p>（输入为联合宽平稳）</p>\n<div>$$\n\\hat X(t) = X(t) * f(t)\\\\\n\\hat Y(t) = Y(t) * g(t)\\\\\nR_{\\hat X\\hat Y}(\\tau) = R_{XY}(\\tau) * f(\\tau) * g^*(-\\tau)\\\\\nS_{\\hat X\\hat Y}(\\omega) = S_{XY}(\\omega)F(\\omega)G^*(\\omega)\n$$</div>\n\n\n<h3 id=\"宽平稳过程通过线性系统\"><a href=\"#宽平稳过程通过线性系统\" class=\"headerlink\" title=\"宽平稳过程通过线性系统\"></a>宽平稳过程通过线性系统</h3><div>$$\nY(t) = \\int_{-\\infty}^{\\infty}h(t - \\tau)X(\\tau)\\mathrm d\\tau\n$$</div>\n\n<p>总结：</p>\n<ul>\n<li>输出过程的均值：易求，因为宽平稳过程的均值为常数</li>\n<li>输出过程的自相关函数：有点麻烦</li>\n</ul>\n<p>首先看输出与输入的自相关</p>\n<div>$$\nR_{YX}(\\tau) = \\int_{-\\infty}^{\\infty}h(v)R_x(\\tau - v)\\mathrm dv\\\\\nR_Y(\\tau) = \\int_{-\\infty}^{\\infty}h^*(-u)R_{YX}(\\tau - u)\\mathrm du\n$$</div>\n\n<div>$$\nR_Y(\\tau) = R_X(\\tau) * h(\\tau) * h^*(-\\tau)\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$</div>\n\n<p>因此，输出的自相关，也可以用功率谱求解。</p>\n<h3 id=\"离散时间宽平稳序列\"><a href=\"#离散时间宽平稳序列\" class=\"headerlink\" title=\"离散时间宽平稳序列\"></a>离散时间宽平稳序列</h3><div>$$\nR_{YX}(k) = h(k) * R_X(k)\\\\\nR_Y(k) = h^*(-k) * h(k) * R_X(k)\\\\\nS_Y(z) = H(z) H^*(\\frac{1}{z^*})S_X(z)\\\\\n其中 H(z) =\\sum\\limits_{}^{}h(k)z^{-k}\\\\\n令 z = e^{j\\omega}\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$</div>\n\n<p>理想白噪声通过低通滤波器：</p>\n<div>$$\nS_Y(f) = \\begin{cases}\n    k_0, -f_c \\le f \\le f_c,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\\\\\nR_Y(0) = 2f_ck_0\\\\\nR(\\tau) = R_Y(0)\\frac{\\sin(2\\pi f_c\\tau)}{2\\pi f_c\\tau}\n$$</div>\n\n<p>从自相关函数可看出，相隔 $\\frac{n}{2f_c}$ 的两个时刻不相关。因此，以 $2f_c$ 为采样频率的噪声采样数据彼此不相关。</p>\n<p>可以证明宽平稳过程功率谱非负：$S_X(f) \\ge 0$：</p>\n<div>$$\nE \\lbrace |Y(t)|^2 \\rbrace =  R_Y(0) = \\int_{-\\infty}^{\\infty}S_Y(f)\\mathrm df = \\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\ge 0\n$$</div>\n\n<p>如果 $S_X(f)$ 在某个地方小于0，可以设计对应的滤波器 $H(f)$将这个小于0的区域滤出来，从而 $\\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\le 0$，导致矛盾。</p>\n<p>线性系统例子：</p>\n<p>滑动平均</p>\n<div>$$\nY(t) = \\frac{1}{T}\\int_{t-T}^{t}X(s)\\mathrm ds\n$$</div>\n\n<p>转化为滤波器：</p>\n<div>$$\nR_Y(t) = R_X(t) * h(t) * h^*(-t)\\\\\nh(t) = \\begin{cases}\n    \\frac{1}{T}, 0 \\le t \\le T,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>令 </p>\n<div>$$\ng(t) = h(t) * h^*(t) = \\begin{cases}\n    \\frac{1}{T}\\left ( 1 - \\frac{|t|}{T} \\right), t \\in [-T, T],\\\\\n    0,\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>理想的矩形窗</p>\n<div>$$\nR_Y(t) = \\int_{-\\infty}^{\\infty}g(t - \\tau)R_X(\\tau)\\mathrm d\\tau = \\int_{-T}^{T}\\frac{1}{T}\\left ( 1 - \\frac{|t - \\tau|}{T} \\right)R_X(\\tau)\\mathrm d\\tau\n$$</div>\n\n<p>从频域看</p>\n<div>$$\nH(\\omega) = \\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)e^{-j\\omega \\frac{T}{2}}\\\\\nS_Y(\\omega) = S_X(\\omega)\\left |\\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)  \\right|^2\n$$</div>\n\n<p>是一个低通滤波器。</p>\n<p>例子2：MTI 滤波</p>\n<p>静止目标反射信号相同，运动目标反射回波不同。因此设计滤波器消去静止目标。称为“对消”。</p>\n<div>$$\nY(t) = X(t) - X(t - T)\n$$</div>\n\n<p>在频域看：</p>\n<div>$$\nH(\\omega) = 1 - e^{j\\omega T}\n$$</div>\n\n<p>静止目标，多普勒频率为0，因此频域响应为0；运动目标，多普勒频率不为0，频域响应不为0。因此这是一个高通滤波器。</p>\n<p>还可以多次对消：</p>\n<div>$$\nY_1(t) = X(t) - X(t - T)\\\\\nY_2(t) = Y_1(t) - Y_1(t - T)\\\\\nY_3(t) = Y_2(t) - Y_2(t - T)\\\\\n\\vdots\\\\\nY_n(t) = Y_{n - 1}(t) - Y_{n - 1}(t - T)\n$$</div>\n\n<p>频率响应：</p>\n<div>$$\nH(\\omega) = (1 - e^{-j\\omega T})^n\n$$</div>\n\n<h3 id=\"采样定理\"><a href=\"#采样定理\" class=\"headerlink\" title=\"采样定理\"></a>采样定理</h3><p>随机过程下的采样定理</p>\n<p>$|f| \\le f_0$, 当 $f_s \\le 2f_0$ 时，均方意义下有</p>\n<div>$$\nX(t) =\\sum\\limits_{k=-\\infty}^{\\infty}X(kT) \\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right)\n$$</div>\n\n<p>证明：</p>\n<div>$$\n\\begin{align*}\n    &要证明 N \\rightarrow \\infty 时,\\\\\n    &\\varepsilon_N = E \\left \\lbrace  \\left | X(t) -\\sum\\limits_{k=-N}^{N}X(kT)\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 \\right \\rbrace \\rightarrow 0\\\\\n    &利用E \\lbrace X(a) X^*(b) \\rbrace = R_X(a - b) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}e^{j\\omega a}e^{-j\\omega b}S_X(\\omega)\\mathrm d\\omega，展开上式\\\\\n    &\\varepsilon_N = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &= \\frac{1}{2\\pi}\\int_{-\\omega_s/2}^{\\omega_s/2}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &对 e^{j\\omega t}做周期延拓，周期为 \\omega_s，可以做频域傅里叶级数展开\\\\\n    &e^{j\\omega t} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega \\frac{2\\pi}{\\omega_s}} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega kT}\\\\\n    &\\alpha_k = \\frac{1}{\\omega_s}\\int_{-\\omega_s/2}^{\\omega_s/2}e^{j\\omega t}e^{-j\\omega kT}\\mathrm d\\omega = \\frac{\\sin(\\frac{\\omega}{2}(t - kT))}{\\frac{\\omega}{2}(t - kT)}\\\\\n    &从而\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 = \\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}\\alpha_k e^{j\\omega kT}\\right|^2 \\rightarrow 0, N \\rightarrow \\infty\n\\end{align*}\n$$</div>\n\n<ul>\n<li>采样定理两边是均方相等。</li>\n<li>当满足采样定理时，离散点包含全部信息，任意取值点可以恢复。</li>\n<li>频带边界点<ul>\n<li>当功率谱在 $\\pm \\omega_0$ 处有 $\\delta$ 函数时，以 $f_s &#x3D; 2f_0$ 无法恢复信号。</li>\n<li>例如：$X(t) &#x3D; \\cos(\\omega_0 t + \\phi)$，$\\phi$ 为随机相位，在$[0, 2\\pi]$内均匀分布。</li>\n<li>$R(\\tau) &#x3D; \\frac{1}{2}\\cos(\\omega_0\\tau)$</li>\n<li>$S(\\omega) &#x3D; \\delta(\\omega - \\omega_0) + \\delta(\\omega + \\omega_0)$</li>\n<li>采样点 $X(kT) &#x3D; (-1)^kX(0)$，与 $X(0)$ 严重相关。</li>\n</ul>\n</li>\n</ul>\n<p>欠采样</p>\n<div>$$\n\\begin{align*}\n    E \\lbrace |\\varepsilon(t)|^2 \\rbrace =& \\int_{\\omega_s/2}^{-\\omega_s/2}\\sum\\limits_{n=-\\infty}^{\\infty}|1 - e^{jn\\omega t}|S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}4\\sin^2(\\omega_snt/2) \\cdot \\int_{\\omega_s/2}^{-\\omega_s/2}S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n\\end{align*}\\\\\n\n<p>上面的级数为积分的加权求和。 n &#x3D; 0 时权重为0，对应[-\\omega_s&#x2F;2, \\omega_s&#x2F;2] 内的功率谱。\\<br>n\\ne 0 时，权不为0，对应[-\\omega_s&#x2F;2, \\omega_s&#x2F;2]外的频谱，如果在这个区间外功率谱不是0，那 |\\varepsilon|^2 将大于0。</p>\n<p>$$</div></p>\n<h3 id=\"带通采样\"><a href=\"#带通采样\" class=\"headerlink\" title=\"带通采样\"></a>带通采样</h3><div>$$\nX(\\omega) = 0, |\\omega - \\omega_c| > \\omega_0, |\\omega + \\omega_c| > \\omega_0\n$$</div>\n\n<p>一般研究实信号 $g(t)$，频谱具有共轭对称性，只需要考虑正半轴的频带就可以了：</p>\n<div>$$\nG(-\\omega) = G^*(\\omega)\\\\\nA(\\omega) = A(-\\omega), \\varphi(-\\omega) = -\\varphi(\\omega)\n$$</div>\n\n<p>希尔伯特变换：</p>\n<div>$$\nH(\\omega) = \\begin{cases}\n    -j, \\omega \\gt 0,\\\\\n    0, \\omega = 0,\\\\\n    j, \\omega \\lt 0.\n\\end{cases}\n$$</div>\n\n<div>$$\n\\lbrace G(\\omega)H(\\omega) \\rbrace^* = G(-\\omega)H(-\\omega)\n$$</div>\n\n<p>希尔伯特把正频率移相 $-90\\degree$，负频率移相 $+90\\degree$</p>\n<p>时域表示：</p>\n<p>滤波器的时域响应为</p>\n<div>$$\n\\hat h(t) = \\frac{1}{\\pi t}\n$$</div>\n\n<p>g(t) 做两次希尔伯特变换，相位转了 $180\\degree$：</p>\n<div>$$\ng(t)\\xrightarrow{H(\\omega)}\\hat g(t) \\xrightarrow{H(\\omega)} -g(t)\n$$</div>\n\n<p>正交性：</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = 0\n$$</div>\n\n<p>看成$\\hat g(t)$ 与 $g(-t)$ 的卷积：</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}g(- (u - t))\\hat g(t)\\mathrm dt|_{u = 0} = g(-t) * \\hat g(t) |_{t = 0}\\\\\ng(-t) \\rightarrow G^*(\\omega) = G(-\\omega), \\hat g(t) \\rightarrow G(\\omega)H(\\omega)\\\\\ng(-t) * \\hat g(t)|_{t = 0} = \\int_{-\\infty}^{\\infty}G^*(\\omega)G(\\omega)H(\\omega)e^{j\\omega t}\\mathrm d\\omega|_{t = 0} = 0\n$$</div>\n\n<p>希尔伯特变换与原信号相加得到单边的频谱：</p>\n<div>$$\ng(t) \\rightarrow A^* + A\\\\\nj\\hat g(t) \\rightarrow \\\\\ng(t) + j\\hat g(t) \\rightarrow 2A\\\\\n$$</div>\n\n<p>下变频：</p>\n<div>$$\n\\tilde{g}(t) = \\lbrace g(t) + j\\hat g(t) \\rbrace e^{-j\\omega_c t} = g_I(t) + jg_Q(t)\\\\\ng_I(t) = g(t) \\cos \\omega_c t + \\hat g(t) \\sin (\\omega_c t)\\\\\ng_Q(t) = - g(t) \\sin \\omega_c t + \\hat g(t) \\cos (\\omega_c t)\\\\\n$$</div>\n\n<p>实际上是一个旋转矩阵，把单边频信号 $\\tilde g(t)$ 顺时针旋转了 $\\omega_ct$变成了基带复信号。</p>\n<p>与原信号频谱的关系：</p>\n<div>$$\ng_I(t) \\rightarrow G(f - f_c) + G(f + f_c) \\\\\ng_Q(t) \\rightarrow G(f - f_c)(+j) + G(f + f_c)(-j)\\\\\n(f \\le |f_0|)\n$$</div>\n\n<p>调制和解调的流程</p>\n<ul>\n<li>调制：不需要得到 $\\hat g(t)$</li>\n<li>解调：通过低通滤波代替$\\hat g(t)$</li>\n</ul>\n<p>随机过程的希尔伯特变换</p>\n<p>$X(t)$为实的带通随机过程</p>\n<div>$$\nR_X(-\\tau) = E\\left \\lbrace  X(t - \\tau)X^*(t) \\right \\rbrace = E\\left \\lbrace  X(t)X^*(t + \\tau) \\right \\rbrace = E\\left \\lbrace  X(t + \\tau)X(t) \\right \\rbrace = R_X(\\tau)\\\\\nS_X(-\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)e^{-j(-\\omega) \\tau}\\mathrm d\\tau = \\int_{-\\infty}^{\\infty}R_X(-u)e^{-j\\omega\\tau}\\mathrm du = \\int_{-\\infty}^{\\infty}R_X(u)e^{-j\\omega\\tau}\\mathrm du = S_X(\\omega)\n$$</div>\n\n<p>通过希尔伯特滤波器后：</p>\n<div>$$\n\\hat X(t) = X(t) * h(t)\\\\\nR_{\\hat X}(\\tau) = R_X(\\tau) * h(t) * h^*(-t) = R_X(\\tau)\\\\\nS_{\\hat X}(\\omega) = S_X(\\omega)|H(\\omega)|^2 = S_X(\\omega)\n$$</div>\n\n<p>互相关：</p>\n<div>$$\n\\hat R_X(\\tau) = R_{\\hat XX}(\\tau) = E \\left \\lbrace \\int_{-\\infty}^{\\infty}X(t + \\tau - u)\\frac{1}{\\pi u}\\mathrm duX(t)   \\right\\rbrace = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\frac{1}{\\pi u}\\mathrm du\n$$</div>\n\n<div>$$\nR_{X\\hat X}(\\tau) = -\\hat R_X(\\tau)\n$$</div>\n\n<p>因此</p>\n<div>$$\nY = X + j\\hat X\\\\\nR_Y(\\tau) = R_X(\\tau) + R_{\\hat X}(\\tau) + jR_{\\hat XX}(\\tau) - jR_{X\\hat X}(\\tau) = 2R_X(\\tau) + 2j\\hat R_X(\\tau)\\\\\nS_Y(f) = \\begin{cases}\n    4S_X(f), &f \\gt 0\\\\\n    0, &f\\lt 0\n\\end{cases}\n$$</div>\n\n<p>实的带通随机过程配合虚部的希尔伯特变换，同样也是只有正频率</p>\n<p>反之，如果功率谱只有正频率有值，则实部和虚部互为希尔伯特变换，实部和虚部的信息是重复的。</p>\n<p>随机信号的下变频：</p>\n<div>$$\n\\tilde{X}(t) = \\lbrace X(t) + j\\hat X(t) \\rbrace e^{-j\\omega_c t} = X_I(t) + jX_Q(t)\\\\\nX_I(t) = X(t) \\cos \\omega_c t + \\hat X(t) \\sin (\\omega_c t)\\\\\nX_Q(t) = - X(t) \\sin \\omega_c t + \\hat X(t) \\cos (\\omega_c t)\\\\\n$$</div>\n\n<p>同样是顺时针旋转了 $2\\pi f_c t$ 之后得到了基带信号</p>\n<p>研究基带信号的实部、虚部的统计特性</p>\n<p>$\\tilde{X}(t)$ 还是一个平稳过程</p>\n<div>$$\nE \\lbrace \\tilde{X}(t) \\rbrace = E \\lbrace X_I(t) \\rbrace = E \\lbrace X_Q(t) \\rbrace = 0\\\\\nR_{X_I}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_Q}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_I}(\\tau) = R_{X_Q}(\\tau)\\\\\nR_{X_Q}(0) = R_{X_I}(0) = R_{X}(0)(三者方差一样)\\\\\n\\hat R_X(0) = 0(奇函数，不具备自相关函数的性质)\\\\\nS_{X_I}(f) = S_{X_Q}(f) = \\begin{cases}\n    S_X(f - f_c) + S_X(f + f_c), &|f| \\le f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>基带信号虚部和实部的互相关</p>\n<div>$$\nR_{X_IX_Q}(\\tau) = R_X(\\tau)\\sin(2\\pi f_c\\tau) - \\hat R_X(\\tau)\\cos (2\\pi f_c\\tau)，奇函数\n$$</div>\n\n<div>$$\nR_{X_IX_Q}(0) = 0\n$$</div>\n\n<p>因此同一时刻实部和虚部不相关。</p>\n<p>互谱密度</p>\n<div>$$\nS_{X_IX_Q}(f) = \\begin{cases}\n    jS_X(f + f_c) - jS_X(f - f_c), &|f| \\lt f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>只有当正频谱和负频谱分别跟 $f &#x3D; \\pm f_c$ 对称时，互谱密度恒为0。此时，任意两个时间的虚部和实部信号都是不相关的。</p>\n<h2 id=\"高斯过程\"><a href=\"#高斯过程\" class=\"headerlink\" title=\"高斯过程\"></a>高斯过程</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>随机向量$X &#x3D; (X(t_1), \\dots, X(t_n))^T$ 服从 $n$ 元高斯分布，称为高斯过程。</p>\n<p>均值 $\\mu_k$ &#x3D; $E \\lbrace X_k \\rbrace$</p>\n<p>协方差阵</p>\n<div>$$\n\\Sigma = E \\lbrace (X - \\mu)(X - \\mu)^T \\rbrace = \\begin{bmatrix}\n    b_{11}& \\dots &b_{1n}\\\\\n    \\vdots& \\ddots & \\vdots\\\\\n    b_{n1} & \\dots & b_{nn}\n\\end{bmatrix}\\\\\nb_{ij} = E \\lbrace (X_i - \\mu_i)(X_j - \\mu_j)^T \\rbrace\\\\\nb_{ij} = b_{ji}^* = b_{ji}\n$$</div>\n\n<p>做特征分解</p>\n<div>$$\n\\Sigma v_i = \\lambda_i v_i\\\\\nQ = (v_1, v_2, \\dots, v_n)正交阵, Q^{-1} = Q^T\\\\\n\\Sigma = Q\\text{diag}(\\lambda_1, \\dots, \\lambda_n)Q^T\\\\\n\\Sigma^{-1} = Q^T\\text{diag}(\\lambda_1^{-1}, \\dots, \\lambda_n^{-1})Q\n$$</div>\n\n<h3 id=\"多元高斯分布\"><a href=\"#多元高斯分布\" class=\"headerlink\" title=\"多元高斯分布\"></a>多元高斯分布</h3><div>$$\nf(x) = K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$</div>\n\n<p>线性变换以消去下标$ij$项：</p>\n<div>$$\n\\Sigma^{-1} = A^TA\\\\\ny = A(x - \\mu)\\\\\n(x - \\mu)\\Sigma^{-1}(x - \\mu)^T = y^Ty\n$$</div>\n\n<div>$$\n1 = K \\int \\dots \\int \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace \\mathrm dx_1 \\dots \\mathrm dx_n\\\\\nK = \\frac{1}{(\\sqrt{2\\pi})^n\\cdot \\sqrt{|\\Sigma|}}\n$$</div>\n\n<p>多元高斯矢量的特征函数</p>\n<div>$$\n\\omega = (\\omega_1, \\omega_2,\\dots, \\omega_n)^T\\\\\n\\Phi_X(\\omega) = E \\lbrace e^{j\\omega^TX} \\rbrace = E \\lbrace e^{j(\\omega_1 X_1 + \\omega_2 X_2 + \\dots + \\omega_n X_n)} \\rbrace = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T\\Sigma\\omega \\right \\rbrace\n$$</div>\n\n<p>特征函数不要求 $\\Sigma$ 可逆。概率密度函数要求 $\\Sigma$ 正定，特征值都大于0.</p>\n<p>当 $X$ 为高斯矢量时</p>\n<div>$$\n\\Phi_X(\\omega) = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu) \\right \\rbrace\\mathrm dx_1\\mathrm dx_2\\dots\\mathrm dx_n = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{y^Ty}{2} \\right \\rbrace \\sqrt{|\\Sigma|}\n$$</div>\n\n<p>高斯白噪声的协方差矩阵只有对角元，对角元为方差。</p>\n<p>可以用逼近处理 $|\\Sigma| &#x3D; 0$：</p>\n<div>$$\n\\Sigma_K = \\Sigma + \\frac{1}{K}I\\\\\n\\Phi_X(\\omega) = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T \\left (\\Sigma + \\frac{1}{K}I  \\right)\\omega \\right \\rbrace\\\\\nf(x) = \\frac{1}{\\sqrt{2\\pi}^n \\sqrt{|\\Sigma_K|}} \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$</div>\n\n<p>然后再讨论 $K \\rightarrow \\infty$ 的情况。</p>\n<p>多元高斯矢量的边缘分布</p>\n<p>任取子矢量 $\\lbrace K_1, K_2, \\dots, K_m \\rbrace \\subseteq {1, 2, \\dots, n}$</p>\n<p>观察 $\\tilde{ X} &#x3D; (X_{K_1}, X_{K_2}, \\dots, X_{K_m})^T$ 的分布</p>\n<div>$$\n\\tilde{\\Phi}(\\tilde\\omega) = E \\lbrace e^{j(\\omega_{K_1}\\tilde X_{K_1} + \\omega_{K_2}\\tilde X_{K_2} + \\dots + \\omega_{K_m}\\tilde X_{K_m})} \\rbrace = \\exp \\left \\lbrace  j\\tilde\\omega^T\\mu - \\frac{1}{2}\\tilde\\omega^T\\Sigma\\tilde\\omega \\right \\rbrace\n$$</div>\n\n<p>用置换矩阵 $P$ 将 $\\Sigma$ 的第 $K_1, K_2, \\dots, K_m$ 行、列移到 $\\Sigma$ 的左上角，对应的 $\\omega$ 也置换：</p>\n<div>$$\nP\\omega = \\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix}\\\\\nP^T\\Sigma P^T = \\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\n$$</div>\n\n<p>置换到左上角后，容易看出子矢量的特征函数可以通过将原矢量其他的$\\omega$置零得到，均值就是选择对应的均值，协方差矩阵就是把对应的行列元素抽出来：</p>\n<div>$$\n\\omega^T\\Sigma\\omega = (\\tilde{\\omega}, 0)^T\\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix} = \\tilde{\\omega}^T\\tilde{\\Sigma}\\tilde{\\omega}\n$$</div>\n\n<p>利用特征函数求数字特征：</p>\n<div>$$\n\\frac{\\partial^2\\Phi}{\\partial \\omega_k\\partial \\omega_l}|_{\\omega_k = \\omega_l = 0} = -(\\mu_l\\mu_k + b_{kl})\\\\\nE \\lbrace X_kX_l \\rbrace = \\mu_l\\mu_k + b_{kl}\n$$</div>\n\n<div>$$\nE \\lbrace X_1^{k_1}\\dots X_n^{k_n} \\rbrace = j^{\\sum\\limits_{i=1}^{n}k_i} \\frac{\\partial^{k_1 + k_2 + \\dots k_n}}{\\partial^{k_1}\\omega_1\\partial^{k_2}\\omega_2\\dots \\partial^{k_n}\\omega_n}\\bigg|_{\\omega_1 = \\omega_2 = \\dots = \\omega_n = 0}\n$$</div>\n\n<p>高斯的矢量分布的高阶矩完全由一阶矩 $\\mu$ 和二阶矩 $\\Sigma$ 决定。例如可以用特征函数推出：</p>\n<div>$$\n\\begin{align*}\n    &E \\left \\lbrace  X_1X_2X_3X_4 \\right \\rbrace \\\\\n    =& j^4 \\frac{\\partial^4\\Phi}{\\partial \\omega_1\\partial \\omega_2\\partial \\omega_3\\partial \\omega_4}\\bigg|_{\\omega_1 = \\omega_2 = \\omega_3 = \\omega_4 = 0} \\\\\n    =& E \\left \\lbrace  X_1X_2  \\right \\rbrace E \\left \\lbrace  X_3X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_3  \\right \\rbrace E \\left \\lbrace  X_2X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_4  \\right \\rbrace E \\left \\lbrace  X_2X_3  \\right \\rbrace\n\\end{align*}\n$$</div>\n\n<p>独立性</p>\n<p>独立性说的是统计，不相关说的是线性（二阶矩）</p>\n<p>一般来说</p>\n<div>$$\n独立 \\Rightarrow 不相关\\\\\n不相关 \\not \\Rightarrow 独立\n$$</div>\n\n<p>但是，对于高斯分布而言：</p>\n<div>$$\n独立 \\lrArr 不相关\n$$</div>\n\n<p>这是因为高斯分布完全由一阶和二阶矩决定。</p>\n<p>定理：</p>\n<p>$n$ 元向量 $X &#x3D; \\binom{X_1}{X_2}$ 服从 $N(\\mu, \\Sigma)$，则 $X_1, X_2$ 独立 $\\lrArr$ $\\Sigma_{12} &#x3D; 0$</p>\n<div>$$\n\\Sigma = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\n$$</div>\n\n<p>充分性：</p>\n<div>$$\n\\Sigma_{12} = E \\left \\lbrace (X_1 - \\mu_1)^T(X_2 - \\mu_2)  \\right \\rbrace = E \\left \\lbrace (X_1 - \\mu_1)\\right\\rbrace E\\left \\lbrace(X_2 - \\mu_2)  \\right \\rbrace = 0\n$$</div>\n\n<p>必要性：</p>\n<div>$$\nf(x_1, x_2) = \\frac{1}{(2\\pi)^{n/2}\\sqrt{|\\Sigma|}}\\exp \\left \\lbrace -\\frac{1}{2}\\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix}^T\\begin{pmatrix}\n    \\Sigma_{11}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix} \\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix} \\right  \\rbrace = f(x_1)f(x_2)\n$$</div>\n\n<p>可见 $X_1, X_2$ 统计独立。</p>\n<p>对于高斯过程：</p>\n<div>$$\n严平稳 \\lrArr 宽平稳\n$$</div>\n\n<p>即 $X(t_1), X(t_2), \\dots, X(t_n)$ 和 $X(t_1 + \\tau), X(t_2 + \\tau), \\dots, X(t_n + \\tau)$ 有相同的 $\\mu, \\Sigma$ 等价于具有相同的分布函数。</p>\n<p>线性变换</p>\n<p>定理： $X$ 服从高斯分布，矩阵 $C_{m\\times n}$， $Y &#x3D; CX$，则 $Y$ 服从高斯分布 $N \\left(C\\mu, C \\Sigma C^T \\right)$。</p>\n<p>高斯过程经过微分，积分，滤波等线性操作，输出还是高斯过程。</p>\n<p>有一种重要的线性变换：去相关。</p>\n<div>$$\n\\Sigma_X = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\\\\\nY = \\begin{pmatrix}\n    Y_1\\\\Y_2\n\\end{pmatrix}= \\begin{pmatrix}\n    I & A\\\\\n    0 & I\n\\end{pmatrix}\\begin{pmatrix}\n    X_1\\\\X_2\n\\end{pmatrix}\\\\\nE \\left \\lbrace  (Y_1 - E(Y_1))(Y_2 - E(Y_2))^T \\right \\rbrace = \\Sigma_{12} + A\\Sigma_{22 } = 0\n$$</div>\n\n<p>需要</p>\n<div>$$\n-\\Sigma_{12}\\Sigma_{22}^{-1} = A\\\\\n$$</div>\n\n<p>计算协方差</p>\n<div>$$\nE \\left \\lbrace  (Y - E(Y))(Y - E(Y))^T \\right \\rbrace = \\begin{pmatrix}\n    \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix}\n$$</div>\n\n<p>去相关之后方差减小了。可以认为 $X_1 &#x3D; Y_1 - AX_2$ 中，$- AX_2$是与 $Y$ “独立” 的“噪声项”，这个噪声导致了 $X_1$ 的方差大于去相关之后的 $Y$ 的方差。</p>\n<p>去相关与是否是高斯矢量无关。但是对于高斯矢量，去相关之后，两个矢量就独立了，具有重要的意义。</p>\n<p>对于一般的二阶矩过程，希望找到一个矩阵 $U$ ，使得 $Y &#x3D; UX$ 的各个分量不相关：</p>\n<div>$$\nE \\left \\lbrace  (Y - \\mu_Y)(Y - \\mu_Y)^T \\right \\rbrace = \\text{diag}\\\\\nE \\left \\lbrace  U(X - \\mu_X)(X - \\mu_X)^TU^T \\right \\rbrace  = \\text{diag} = U\\Sigma U^T\n$$</div>\n\n<p>所以，本质上就是分析了协方差矩阵 $\\Sigma$ 的特征值。也就是二阶矩章节讲到的主成分分析：</p>\n<div>$$\n\\text{diag}(\\lambda_1, \\dots, \\lambda_n)\n$$</div>\n\n<p>选取 $\\lambda_i$ 大的特征矢量，张成主成分空间。</p>\n<p>信号处理中有信号空间（特征值大的）和噪声空间（特征值小的，被噪声掩盖了）。</p>\n<p>有时候 $Y$ 的各个分量不相关还不能完全消去元素之间的统计关系。只是线性不相关。不相关的约束实际上很弱。</p>\n<p>如果要设计 $U$，使得 $Y &#x3D; UX$ 的各个分量独立，运算很复杂。</p>\n<p>但是，对于高斯矢量而言，不相关就是独立。所以对于高斯过程，主成分分析 $\\lrArr$ 独立成分分析。</p>\n<h3 id=\"高斯变量的条件分布\"><a href=\"#高斯变量的条件分布\" class=\"headerlink\" title=\"高斯变量的条件分布\"></a>高斯变量的条件分布</h3><p>仍是高斯：</p>\n<div>$$\nf_{X_1|X_2}(x_1|x_2) = \\frac{1}{\\sqrt{\\tilde{\\Sigma}_{11}}(2\\pi)^{\\frac{n_1}{2}}}\\exp \\left \\lbrace -\\frac{1}{2}(x_1 - \\tilde{\\mu}_1)^T\\tilde{\\Sigma}_{11}^{-1}(x_1 - \\tilde{\\mu}_1)   \\right\\rbrace\\\\\nE \\lbrace X_1 | X_2 \\rbrace = \\mu_1 + \\Sigma_{12}\\Sigma_{22}^{-1}(X_2 - \\mu_2)\\\\\nE \\lbrace (X_1 - E(X_1 | X_2))(X_1 - E(X_1|X_2))^T|X_2 \\rbrace = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\n$$</div>\n\n<h3 id=\"实高斯过程的若干性质\"><a href=\"#实高斯过程的若干性质\" class=\"headerlink\" title=\"实高斯过程的若干性质\"></a>实高斯过程的若干性质</h3><p>实高斯过程完全由均值函数和协方差函数确定。</p>\n<p>严平稳等价于宽平稳。</p>\n<p>若实高斯过程均方可导，则 $\\lbrace X^\\prime(t) \\rbrace$ 也是高斯过程。</p>\n<p>高斯过程通过一般线性系统仍然是高斯过程。</p>\n<div>$$\nY(t) = \\int_{a}^{b}X(\\tau)h(t, \\tau)\\mathrm d\\tau\\\\\n更强的结论：\\left \\lbrace  \\binom{X(t)}{Y(t)} \\right \\rbrace 是高斯过程。\n$$</div>\n\n<h3 id=\"零均值带通高斯过程\"><a href=\"#零均值带通高斯过程\" class=\"headerlink\" title=\"零均值带通高斯过程\"></a>零均值带通高斯过程</h3><div>$$\nZ(t) = X(t) + j \\hat X(t)\\\\\nX_B(t) = X_I(t) + j X_Q(t)\\\\\nV(t) = \\sqrt{X_I^2(t) + X_Q^2(t)}\\\\\n\\Theta(t) = \\arctan \\frac{X_Q(t)}{X_I(t)}\\\\\n$$</div>\n\n<p>此时有</p>\n<div>$$\nX(t) = V(t)\\cos(\\omega_ct + \\Theta(t))\\\\\n\\binom{X_I(t)}{X_Q(t)} = \\binom{\\ \\ \\ \\cos(\\omega_ct)\\quad \\sin(\\omega_c t)}{-\\sin(\\omega_ct)\\quad \\cos(\\omega_ct)}\\binom{X(t)}{\\hat X(t)}\n$$</div>\n\n<p>幅度为瑞利分布，相位为均匀分布，相互统计独立：</p>\n<div>$$\nf_V(v) = \\frac{v}{\\sigma^2}e^{-\\frac{v^2}{2\\sigma^2}}, v \\ge 0\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}, \\theta \\in [0, 2\\pi]\n$$</div>\n\n<h3 id=\"随机相位正弦波信号叠加零均值带通高斯\"><a href=\"#随机相位正弦波信号叠加零均值带通高斯\" class=\"headerlink\" title=\"随机相位正弦波信号叠加零均值带通高斯\"></a>随机相位正弦波信号叠加零均值带通高斯</h3><div>$$\nY(t) = A\\sin(\\omega_ct + \\Phi) + X(t)\n$$</div>\n\n<p>结果是幅度为莱斯分布，相位均匀分布，二者统计独立：</p>\n<div>$$\nf_{V(t)}(v) = \\frac{v}{\\sigma^2}\\exp(-\\frac{v^2 + A^2}{2\\sigma^2})I_0(\\frac{Av}{\\sigma^2})\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}\n$$</div>\n\n<h3 id=\"高斯过程经过非线性函数\"><a href=\"#高斯过程经过非线性函数\" class=\"headerlink\" title=\"高斯过程经过非线性函数\"></a>高斯过程经过非线性函数</h3><p>限幅器</p>\n<div>$$\nh(x) = \\begin{cases}\n    1, x\\ge 0,\\\\\n    0, x \\lt 0\n\\end{cases}\n$$</div>\n\n<p>服从两点分布</p>\n<div>$$\nP(Y(t) = 1) = P(Y(t) = 0) = \\frac{1}{2}\\\\\nE_Y(t) = 0\\\\\nR_Y(t, s) = P \\lbrace X(t)X(s) \\ge 0 \\rbrace - P \\lbrace X(t)X(s) \\lt 0 \\rbrace\n$$</div>\n\n<div>$$\nP \\lbrace X(t)X(s) \\ge 0 \\rbrace = \\int_{0}^{\\infty}\\int_{0}^{\\infty}\\frac{1}{2\\pi\\sqrt{|\\Sigma|^{-1}}}\\exp((x_1\\ x_2)\\Sigma^{-1}\\binom{x_1}{x_2})\\mathrm dx_2\\mathrm dx_1 = \\frac{\\pi/2 + \\sin^{-1}(-\\rho)}{2\\pi}\n$$</div>\n\n<p>全线性检波（求绝对值）</p>\n<div>$$\nE(Y) = \\frac{2\\sigma}{2\\pi}\\int_{0}^{\\infty}\\frac{y}{\\sigma^2}\\exp(-\\frac{y^2}{2\\sigma^2})\\mathrm dy = \\sqrt{\\frac{2}{\\pi}}\\sigma\\\\\nR_Y(t, s) E \\lbrace |X(t)||X(s)| \\rbrace = \\frac{2\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace, \\rho = \\frac{R_X(t - s)}{\\sigma^2}\\\\\n\\int_{0}^{\\infty}\\int_{0}^{\\infty}x_1x_2\\frac{1}{2\\pi\\sigma^2\\sqrt{1 - \\rho^2}}\\exp(-\\frac{x_1^2 - 2\\rho x_1x_2 + x_2^2}{2\\sigma(1 - \\rho^2)})\\mathrm dx_1\\mathrm dx_2\n$$</div>\n\n<p>半波线性检波</p>\n<div>$$\nh(x) = \\begin{cases}\n    x, x\\ge 0,\\\\\n    0, x\\lt 0\n\\end{cases}\n$$</div>\n\n<div>$$\nR_Y(t, s) = \\frac{\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace\\\\\n$$</div>\n\n<p>平方率检波</p>\n<div>$$\nh(x) = x^2\n$$</div>\n\n<div>$$\nP(Y(t) \\le y) = P(-\\sqrt{y} \\le Y(t) \\le \\sqrt{y}) = 2\\Phi(\\frac{\\sqrt{y}}{\\sigma}) - 1\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\frac{1}{\\sqrt{y}}\\exp \\lbrace -\\frac{y}{2\\sigma^2} \\rbrace,\\ (y \\gt 0)\\\\\nE \\lbrace Y(t) \\rbrace = \\sigma^2\\\\\nR_Y(t,s) = E \\lbrace X^2(t_1)X^2(t_2) \\rbrace = \\sigma^2 + \\sigma^2 + \\rho\\sigma^2 + \\rho\\sigma^2 = 2(\\rho + 1)\\sigma^2\n$$</div>\n\n<p>基带信号的包络经过平方律检波</p>\n<div>$$\nX_I^2 + X_Q^2 = V^2 服从复指数分布\n$$</div>\n\n<h3 id=\"高斯——马尔可夫性\"><a href=\"#高斯——马尔可夫性\" class=\"headerlink\" title=\"高斯——马尔可夫性\"></a>高斯——马尔可夫性</h3><p>马尔可夫特性：</p>\n<div>$$\nf(x_n|x_1, \\dots, x_{n - 1}) = f(x_n|x_{n - 1})\n$$</div>\n\n<p>如果一个过程既是高斯的，又是马尔可夫的，会有很好的性质。</p>\n<p>对于零均值高斯分布：</p>\n<div>$$\nX(t) 是 \\text{Markov} \\lrArr R(t_1, t_3) = \\frac{R(t_1, t_2)R(t_2, t_3)}{R(t_2, t_2)}\n$$</div>\n\n<p>正向很好证明，反向证明的关键是计算均值和方差。</p>\n<div>$$\nX(t) 是 \\text{Markov} \\lrArr \\forall t_1\\le t_2\\le...\\le t_n, E \\lbrace X_n|X_1, X_2, \\dots, X_{n - 1} \\rbrace = E \\lbrace X_n|X_{n - 1} \\rbrace\n$$</div>\n\n<p>从右到左：条件协方差 $E\\lbrace (Y_1 - E \\lbrace Y_1|Y_2 \\rbrace)^2|Y_2\\rbrace &#x3D; \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}$ 跟 $Y_2$ 无关（这并不是说条件协方差和协方差具有相同的意义，只是数值上正好相等）</p>\n<div>$$\nE(X_n|X_{n - 1}) = \\frac{E(X_nX_{n - 1})}{E(X_{n - 1}^2)}X_{n - 1}\\\\\n$$</div>\n\n<p>残差与已有信息正交：</p>\n<div>$$\nE \\lbrace [X_n - E(X_n | X_{n - 1})] \\cdot X_k \\rbrace = 0, k = 1, 2, \\dots, n - 1\\\\\n$$</div>\n\n<p>类似于最小二乘估计：</p>\n<div>$$\nX_n - \\alpha_n X_{n - 1} 是一个高斯过程，与 X_1, X_2, \\dots, X_n 独立\n$$</div>\n\n<p>自回归方程：</p>\n<div>$$\nX_n = \\alpha_n X_{n - 1} + \\beta_nY_n\\\\\nY_n \\sim N(0, 1)\n$$</div>\n\n<h3 id=\"Brown-运动\"><a href=\"#Brown-运动\" class=\"headerlink\" title=\"Brown 运动\"></a>Brown 运动</h3><p>从一维随机游走开始：</p>\n<div>$$\nP \\lbrace X_i = a \\rbrace = P \\lbrace X_i = -a \\rbrace = \\frac{1}{2}\\\\\nY =\\sum\\limits_{i=1}^{\\infty}X_i\n$$</div>\n\n<p>令 $t &#x3D; nT$，固定 $t$，令 $n \\rightarrow \\infty$，由 CLT 可知成为一个高斯分布：</p>\n<div>$$\nE(Y) = 0\\\\\nD(Y) = \\frac{t}{T}a^2\\\\\n\\frac{a^2}{T} = \\beta\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sqrt{\\beta t}}\\exp (-\\frac{y^2}{2\\beta t})\n$$</div>\n\n<p>随着时间增加，不确定性越来越大。</p>\n<p>标准布朗运动：</p>\n<p>（1）$B(t)$ 满足独立增量，平稳增量<br>（2）$B(t)$ 的每个样本轨道都是连续的<br>（3）$\\forall t, B(t)$ 遵循高斯分布，均值0，方差 $t$</p>\n<div>$$\nf_t(x) = \\frac{1}{\\sqrt{2\\pi t}}\\exp (-\\frac{x^2}{2t})\n$$</div>\n\n<p>布朗运动是高斯白噪声的积分：</p>\n<div>$$\nY(t) = \\int_{0}^{t}X(u)\\mathrm du\n$$</div>\n\n<p>可见布朗运动的不规则。</p>\n<h2 id=\"Markov-过程\"><a href=\"#Markov-过程\" class=\"headerlink\" title=\"Markov 过程\"></a>Markov 过程</h2><h3 id=\"Markov-链\"><a href=\"#Markov-链\" class=\"headerlink\" title=\"Markov 链\"></a>Markov 链</h3><p>一种状态离散、时间离散的随机过程。</p>\n<h3 id=\"Markov-特性\"><a href=\"#Markov-特性\" class=\"headerlink\" title=\"Markov 特性\"></a>Markov 特性</h3><p>马尔可夫特性的一种表示：</p>\n<p>在已知现在的条件下，过去与将来独立。</p>\n<div>$$\nP(C,A | B) = P(C | B, A) \\cdot P(A|B) = P(C|B)P(A|B)\n$$</div>\n\n<p>其他表示：过去用集合事件表示</p>\n<div>$$\nP \\lbrace X_{n+1}=j|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}=j|X_n=i \\rbrace\n$$</div>\n\n<p>进一步，过去是一个集合，未来也是一个集合：</p>\n<div>$$\nP \\lbrace X_{n+1}\\in B|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}\\in B|X_n=i \\rbrace\n$$</div>\n\n<p>但是，变量“现在”必须取值为一个确定的值，不能是一个集合。对现在的状态一定要精确掌握，不能放宽约束。</p>\n<p>口号：从小事做起（泊松），从现在做起（马尔可夫）</p>\n<p>转移概率</p>\n<div>$$\nP_{ij}(m, n) = P \\lbrace X_n = a_j | X_m = a_i \\rbrace\n$$</div>\n\n<div>$$\nP_{ij}(m, n) \\ge 0\\\\\n\\sum\\limits_{j}^{}P_{ij}(m, n) = 1\n$$</div>\n\n<p>一步转移概率：</p>\n<div>$$\nP_{ij}(m, m + 1) 或 P_{ij}(m)\n$$</div>\n\n<p>状态转移矩阵</p>\n<p>观察变量族的联合分布</p>\n<h3 id=\"齐次马尔科夫链的迭代表示\"><a href=\"#齐次马尔科夫链的迭代表示\" class=\"headerlink\" title=\"齐次马尔科夫链的迭代表示\"></a>齐次马尔科夫链的迭代表示</h3><div>$$\nX_0 \\xrightarrow{Z_1} X_1 \\xrightarrow{Z_2} X_2 \\dots \\xrightarrow{Z_n} X_{n}\n$$</div>\n\n<div>$$\nX_{n+1} = f(X_n,Z_{n+1}) = P \\lbrace X_{n+1} = j | X_n = i \\rbrace\n$$</div>\n\n<p>也称为新息过程</p>\n<h3 id=\"一维随机游走\"><a href=\"#一维随机游走\" class=\"headerlink\" title=\"一维随机游走\"></a>一维随机游走</h3><p>吸收壁</p>\n<p>反射壁 - 完全反射壁</p>\n<p>成功逃跑</p>\n<p>等待服务人数</p>\n<div>$$\nX_{n + 1} = \\begin{cases}\n    X_n - 1 + Y_{n + 1}, X_n \\ne 0\\\\\n    Y_{n + 1}, X_0\n\\end{cases}\\\\\nP = \\begin{bmatrix}\n    a_0 & a_1 & a_2 & \\dots\\\\\n    a_0 & a_1 & a_2 & \\dots\\\\\n        & a_0 & a_1 & \\dots\\\\\n        &     & a_0 & \\dotsb\n\\end{bmatrix}\n$$</div>\n\n<h3 id=\"柯尔莫格洛夫方程\"><a href=\"#柯尔莫格洛夫方程\" class=\"headerlink\" title=\"柯尔莫格洛夫方程\"></a>柯尔莫格洛夫方程</h3><p>多步转移矩阵概率</p>\n<div>$$\nP_{ij}(m, n) = \\sum_k P(X_n = j | X_r = k) \\cdot P(X_r = k | X_m = i)\n$$</div>\n\n<p>或者表示为</p>\n<div>$$\nP_{ij}^{(p + q)} = \\sum_{k \\in \\Omega} P_{ik}^{(p)} P_{kj}^{(q)}\n$$</div>\n\n<p>由于上面转移阵步数 $p, q$ 的任意性，多步跳变矩阵可以转变为矩阵相乘：</p>\n<div>$$\nP^{(L)} = P^{(L - 1)}P^{(1)} = ... = P^L\n$$</div>\n\n<p>求多步转移矩阵：适用于齐次马尔可夫</p>\n<p>齐次马尔可夫链的 $P$ 与时间起点无关</p>\n<p>先求 $P^{(n)} &#x3D; P^n$，再看 $[P^n]_{ij}$ 就是要求的转移概率。</p>\n<p>如何求 $P^n$ ？</p>\n<p>首先做特征分解 $PU &#x3D; U\\Lambda$</p>\n<div>$$\nP^n = U \\Lambda^nU^{-1}\n$$</div>\n\n<p>二元通信信道</p>\n<div>$$\nP  = \\begin{pmatrix}\n    1 - \\alpha & \\alpha\\\\\n    \\beta & 1 - \\beta\n\\end{pmatrix}\\\\\nU = \\begin{pmatrix}\n    1 & -\\alpha\\\\\n    1 & \\beta\n\\end{pmatrix}\n$$</div>\n\n\n<div>$$\nP^n = \\frac{(1 - \\alpha - \\beta)^n}{\\alpha + \\beta}\\begin{pmatrix}\n    \\alpha & -\\alpha\\\\\n    -\\beta & \\beta\n\\end{pmatrix} + \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$</div>\n\n<p>在 $|1 - \\alpha - \\beta| &lt; 1$ 的条件下，无穷步跳变后：</p>\n<div>$$\nP^n = \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$</div>\n\n<p>各列相等，说明这个马尔可夫链与初始状态无关，历史被淡忘——马尔可夫性。</p>\n<p>$1 - \\alpha - \\beta &#x3D; -1$ 时，极限不存在</p>\n<div>$$\nP = \\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\\\\\n\\end{pmatrix}\n$$</div>\n\n<h3 id=\"状态分类\"><a href=\"#状态分类\" class=\"headerlink\" title=\"状态分类\"></a>状态分类</h3><p>可达性：$\\exists m, s.t. P_{ij}^{(m)} &gt; 0$</p>\n<p>互通性：$\\exist m, n, s.t. P_{ij}^{(m)} &gt; 0, P_{ji}^{(n)} &gt; 0$，是等价关系。</p>\n<p>不可约(irreducible)，不可分</p>\n<p>马尔可夫链中每两个状态都是互通的，也叫互通链。</p>\n<p>闭集：$\\forall i \\in C, j\\not \\in C, i \\not \\rightarrow j$</p>\n<p>不可约的另一定义：除了把整个链作为闭集，不存在取其中一些状态构成其他闭集了。</p>\n<p>激励状态</p>\n<p>稳定状态（闭集）</p>\n<p>一般情况，Markov 链的转移矩阵行列重排后可化为：</p>\n<div>$$\nP = \\begin{pmatrix}\n    u_1\\\\\n    &u_2\\\\\n    &&\\ddots\\\\\n    &&&u_k\\\\\n    v_1&v_2&\\dots&v_k&v_{k+1}\n\\end{pmatrix}\n$$</div>\n\n<p>对闭集而言，可以在闭集内使用柯尔莫格洛夫方程：</p>\n<div>$$\nP_{ij}^{(n + m)} =\\sum\\limits_{r\\in \\Omega_1}^{}P_{ir}^{(n)}P_{rj}^{(m)}\n$$</div>\n\n<p>首次达到时间：$T_{ij}(\\omega) &#x3D; \\min \\lbrace n: X_0(\\omega) &#x3D; i, X_n(\\omega) &#x3D; j, n \\ge 1 \\rbrace$</p>\n<div>$$\nT_{ij} \\in [1, 2, ..., \\infty)\n$$</div>\n\n<p>首次到达概率</p>\n<div>$$\nf_{ij}^{(n)} = P \\lbrace T_{ij} = n| X_0 = i \\rbrace\n$$</div>\n\n<p>此时有</p>\n<div>$$\nf_{ij}^{(1)} = P_{ij}\n$$</div>\n\n<p>定义</p>\n<div>$$\nf_{ij} =\\sum\\limits_{k=1}^{\\infty^-} f_{ij}^{(k)}\n$$</div>\n\n<p>为迟早到达的概率。</p>\n<div>$$\nf_{ij}^{(\\infty)} = 1 - f_{ij}\n$$</div>\n\n<p>表示永远无法到达的概率。</p>\n<p>定理：</p>\n<div>$$\nP_{ij}^{(n)} =\\sum\\limits_{r=1}^{n} f_{ij}^{(r)}P_{jj}^{(n - r)}\n$$</div>\n\n<p>考虑 $P_{ij}^{(0)} &#x3D; \\delta_{ij}$，上述可以写成卷积形式：</p>\n<div>$$\nF_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^r\\\\\nG_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^{r}\\\\\nG_{ij}(z) = \\delta_{ij} + F_{ij}(z)G_{jj}(z)\n$$</div>\n\n<div>$$\ni \\rightarrow j \\lrArr  f_{ij} \\gt 0\n$$</div>\n\n<h3 id=\"常返性\"><a href=\"#常返性\" class=\"headerlink\" title=\"常返性\"></a>常返性</h3><h4 id=\"常返与非常返\"><a href=\"#常返与非常返\" class=\"headerlink\" title=\"常返与非常返\"></a>常返与非常返</h4><p>若 $f_{ij} &#x3D; 1$，称状态 i 为常返态</p>\n<p>令 $z &#x3D; 1$：</p>\n<div>$$\nG_{ij}(1) = \\delta_{ij} + F_{ij}(1)G_{jj}(1)\\\\\ni = j \\rArr G_{ii}(1) = \\frac{1}{1 - F_{ii}(1)} \\rArr \\sum_{n = 0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}}\n$$</div>\n\n<p>常返性判别：</p>\n<div>$$\n常返态 \\lrArr f_{ii} = 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = +\\infty\\\\\n非常返态 \\lrArr f_{ii} \\lt 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}} < +\\infty\\\\\n$$</div>\n\n<p>后面会证明，这种返回的次数都是无穷大。</p>\n<p>常返的理解：</p>\n<div>$$\n\\forall n, A_n = \\begin{cases}\n    A_n = 1, X_n = i,\\\\\n    A_n = 0, X_n \\ne i.\n\\end{cases}\n$$</div>\n\n<div>$$\nE \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k | X_0 = i \\rbrace = \\sum\\limits_{k=0}^{\\infty}P_{ii}^{(0)}\\\\\n$$</div>\n\n<p>从判别定理可以看出，在期望意义上，常返态被无限次访问。</p>\n<p>推论1：既然常返态被无穷次返回，非常返态被有限次访问，则在有限状态的 Markov 链中一定存在常返态。</p>\n<p>反证法：如果全是有限返回次数，那所有态的访问次数加起来还是有限的，但是马尔可夫可以访问无限次，矛盾。所以一定有常返态。</p>\n<p>推论1.1：如果非常返态的个数有限，则足够长的时间后，状态一定会到达常返态。</p>\n<p>推论1.2：若 j 非常返，则$\\forall i$</p>\n<div>$$\n\\sum\\limits_{n=0}^{\\infty}P_{ij}^{(n)} < \\infty (i 到达 j的次数为有限值)\\\\\n\\lim_{n \\rightarrow \\infty} P_{ij}^{(n)} = 0\n$$</div>\n\n<p>推论2：若 $i$ 常返，$i \\lrarr j$，则 $j$ 也是常返的。</p>\n<p>推论3：若 $i$ 为常返，$i \\rarr j$，则 $j \\rarr i$</p>\n<h4 id=\"正常返与零常返\"><a href=\"#正常返与零常返\" class=\"headerlink\" title=\"正常返与零常返\"></a>正常返与零常返</h4><p>$f_{ii}^n$ 可以视为首次返回时间 $T_{ii}$ 的概率分布。对于非常返态不能这么看，因为 $f_{ii} &lt; 1$。</p>\n<p>对于常返态的 $T_{ii}$，可以计算期望</p>\n<div>$$\n\\mu_i = E \\lbrace T_{ii} \\rbrace = \\sum\\limits_{n = 1}^{\\infty} n f_{ii}^{(n)}\n$$</div>\n\n<p>若均值为无穷大，则称为零常返。</p>\n<p>零常返与非常返是有区别的。零常返是可以常返，只是大概率步数很多。</p>\n<p>定义返回的速率，可推导</p>\n<div>$$\n\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\sum\\limits_ {k=0}^{n - 1} P_{jj}^{(k)} = \\frac{1}{\\mu_j}\n$$</div>\n\n<p>正常返意味着速率为常数，零常返意味着速率为 0。</p>\n<p>判定定理：</p>\n<div>$$\nj 状态零常返 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{jj}^{(n)} = \\infty, 且 n \\rightarrow \\infty 时，P_{jj}^{(n)} = 0\n$$</div>\n\n<p>条件一就是常返的判定定理。条件二比较特殊：</p>\n<div>$$\n\\lim_{n \\rightarrow \\infty}P_{jj}^{(n)} = \\frac{1}{\\mu_j}\n$$</div>\n\n<p>如果是零常返，这个极限就是0。在条件二上，零常返和非常返是一样的。</p>\n<p>定理：常返态 $i$，$i \\rarr j$，则 $i, j$ 同为正常返或者零常返</p>\n<h4 id=\"补充性质\"><a href=\"#补充性质\" class=\"headerlink\" title=\"补充性质\"></a>补充性质</h4><div>$$\nq_{jj}(M) = P \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k \\ge M | X_0 = j \\rbrace\\\\\n\\lim_{M \\rarr \\infty}q_{jj}(M) = \\begin{cases}\n    1, f_{jj} = 1\\\\\n    0, f_{jj} < 1\\\\\n\\end{cases}\n$$</div>\n\n<p>下面研究常返态 $j$，不可约链</p>\n<p>“从常返态触发，返回次数为无穷大”这件事的概率为 1.</p>\n<div>$$\n\\lim_{M \\rarr \\infty} q_{rj}(M) = 1, \\forall\n$$</div>\n\n<p>“任意状态访问常返态的次数为无穷大”的概率为1.</p>\n<div>$$\nq_{ij}(M) = f_{ij}q_{jj}(M)\n$$</div>\n\n<p>两边取极限可得 $f_{ij} &#x3D; 1$</p>\n<p>结论3： 从不可约链任何状态出发，迟早访问状态 $j$</p>\n<div>$$\n\\lim_{n \\rarr \\infty} P_{ij}^{(n)} = \\frac{1}{\\mu_j}\n$$</div>\n\n<p>结论4：极限概率与初始状态无关。</p>\n<p>分类方式</p>\n<p>对于每个常返态 i，存在一个 i 可达状态构成的状态集 C 。则这些状态彼此相通，构成一个不可约闭集，都常返</p>\n<p>马尔可夫链可以唯一划分为 $C_1, C_2, …, T$，其中 $C_i$ 互为不相交的不可约闭集。T 为非常返态。每个闭集中，常返类型一致，不同闭集不互通。</p>\n<p>定理：马尔科夫链若有一个零常返，有无穷多个零常返。</p>\n<p>推论：有限状态马尔可夫链的常返态必然为正常返。</p>\n<h4 id=\"马尔可夫链的平稳分布和极限概率\"><a href=\"#马尔可夫链的平稳分布和极限概率\" class=\"headerlink\" title=\"马尔可夫链的平稳分布和极限概率\"></a>马尔可夫链的平稳分布和极限概率</h4><p>对于不可约链：</p>\n<div>$$\n\\lim_{n \\rarr \\infty}P_{ij}^{(n)} = 0，j非常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j} = 0，j零常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j}，j正常返\n$$</div>\n\n<p>极限概率用 $\\pi_j$表示</p>\n<p>对于非常返和零常返，极限概率都是0。零常返的链一定有无穷个状态。</p>\n<p>对于正常返，$\\pi_j \\gt 0, \\sum\\limits_{j\\in S}^{}\\pi_j &#x3D; 1$</p>\n<p>从柯式方程得出：</p>\n<div>$$\n\\pi_j = \\sum\\limits_{i}^{}\\pi_iP_{ij}\n$$</div>\n\n<p>矩阵形式：</p>\n<div>$$\n\\lim_{n \\rarr \\infty} P^n = \\Pi = \\begin{bmatrix}\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n\\end{bmatrix}\n$$</div>\n\n\n<h2 id=\"泊松过程\"><a href=\"#泊松过程\" class=\"headerlink\" title=\"泊松过程\"></a>泊松过程</h2><h3 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h3><h4 id=\"计数过程\"><a href=\"#计数过程\" class=\"headerlink\" title=\"计数过程\"></a>计数过程</h4><p>在 $[0, t]$ 内发生某类事件的次数记为 $\\lbrace N(t), t\\ge 0 \\rbrace$，则称 $\\lbrace N(t) \\rbrace$ 为计数过程。</p>\n<h4 id=\"泊松过程-1\"><a href=\"#泊松过程-1\" class=\"headerlink\" title=\"泊松过程\"></a>泊松过程</h4><p>若满足以下条件：</p>\n<ol>\n<li>$N(0) &#x3D; 0$</li>\n<li>非负性：$N(t)$ 的取值非负整数；</li>\n<li>非降性：$N(t)$ 是随时间单调不减的；</li>\n<li>独立增量性：对于 $0 \\le t_1 &lt; t_2 &lt; \\ldots &lt; t_n$，$N(t_2) - N(t_1), N(t_3) - N(t_2), \\ldots, N(t_n) - N(t_{n-1})$ 是相互独立的随机变量；</li>\n<li>平稳增量性：对于 $0 \\le s &lt; t$，$N(t) - N(s)$ 的分布只与时间间隔 $t-s$ 有关，而与具体的时刻 $s$ 无关。</li>\n<li>$P(N(t + \\Delta t) - N(t) &#x3D; 1) &#x3D; \\lambda\\Delta t + o(\\Delta t), P(N(t + \\Delta t) - N(t) \\ge 2) &#x3D; o(\\Delta t)$<br>则称 $\\lbrace N(t), t\\ge 0 \\rbrace$ 为泊松过程。</li>\n</ol>\n<h3 id=\"性质\"><a href=\"#性质\" class=\"headerlink\" title=\"性质\"></a>性质</h3><p>泊松的表达式</p>\n<div>$$\nP_n(t) = P(N(t) = n) = \\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}\n$$</div>\n\n<p>泊松分布的特征函数</p>\n<div>$$\n\\phi_{N(t)}(\\omega) = \\exp \\left \\lbrace \\lambda t (e^{j\\omega} - 1) \\right \\rbrace\n$$</div>\n\n<p>泊松过程的数字特征</p>\n<div>$$\nE(N(t)) = \\lambda t\\\\\nR(t_1, t_2) = \\lambda t_1 + \\lambda^2 (t_1t_2) (t_1 \\le t_2)\\\\\nC(t_1, t_2) = \\min \\lbrace t_1, t_2 \\rbrace\n$$</div>\n\n<h3 id=\"泊松与二项分布\"><a href=\"#泊松与二项分布\" class=\"headerlink\" title=\"泊松与二项分布\"></a>泊松与二项分布</h3><p>泊松分布是二项分布的极限。</p>\n<p>泊松脉冲串：</p>\n<div>$$\nX(t) = \\frac{\\mathrm dN(t)}{\\mathrm dt} = \\sum\\limits_{i}^{}\\delta(t - t_i)\\\\\nE(X(t)) = \\lambda\n$$</div>\n\n<h3 id=\"泊松相关问题\"><a href=\"#泊松相关问题\" class=\"headerlink\" title=\"泊松相关问题\"></a>泊松相关问题</h3><h4 id=\"事件间隔时间的分布\"><a href=\"#事件间隔时间的分布\" class=\"headerlink\" title=\"事件间隔时间的分布\"></a>事件间隔时间的分布</h4><p>$S_n$ 表示第 n 件事到达的时刻</p>\n<p>$T_n$ 表示相邻两件事发生的间隔</p>\n<div>$$\nP\\lbrace S_n \\gt t \\rbrace = P \\lbrace N(t) \\le n - 1 \\rbrace\n$$</div>\n\n<div>$$\nf_{T_n}(t) = \\lambda e^{-\\lambda t}\\\\\nE(T_n) = 1 / \\lambda\n$$</div>\n\n<p>$T_n$ 和 $T_m$ 是独立的。</p>\n<h4 id=\"等待时间的分布\"><a href=\"#等待时间的分布\" class=\"headerlink\" title=\"等待时间的分布\"></a>等待时间的分布</h4><p>概率密度函数与特征函数互为傅里叶变换</p>\n<div>$$\n\\Phi_{T_i}(\\omega) = \\frac{\\lambda}{\\lambda - j\\omega}\\\\\n\\Phi_{S_n}(\\omega) = \\left (\\frac{\\lambda}{\\lambda - j\\omega}  \\right)^n\\\\\n$$</div>\n\n<p>要求 $S_n$ 的概率密度函数，可以看作 $T_n$ 的卷积：</p>\n<div>$$\nf_{S_n}(t) = \\frac{(\\lambda t)^{n - 1}}{(n - 1)!}\\lambda e^{-\\lambda t}\\\\\n$$</div>\n\n<p>称为 $\\Gamma$ 分布，参数 $\\lambda, n$。</p>\n<h4 id=\"相邻两次事件之间的计数\"><a href=\"#相邻两次事件之间的计数\" class=\"headerlink\" title=\"相邻两次事件之间的计数\"></a>相邻两次事件之间的计数</h4><p>两次公交车到来（速度 $\\mu$）之间，等车人数（速度 $\\lambda$）的计数：</p>\n<div>$$\nP(L = k) = (\\frac{\\mu}{\\mu + \\lambda})(\\frac{\\lambda}{\\mu + \\lambda})^k\n$$</div>\n\n<h4 id=\"n个事件到达时间的的联合分布\"><a href=\"#n个事件到达时间的的联合分布\" class=\"headerlink\" title=\"n个事件到达时间的的联合分布\"></a>n个事件到达时间的的联合分布</h4><div>$$\nf_{S_1...S_n|N(t) = n}(u_1, u_2, ..., u_n) = \\frac{n!}{t^n}\n$$</div>\n\n<p>如果是有编号的（不是按顺序到达）：</p>\n<div>$$\nf_{V_1...V_n|N(t) = n}(t_1, t_2, ..., t_n) = \\frac{1}{t^n}\n$$</div>\n\n<p>以下分布的极限，就是泊松过程：</p>\n<div>$$\nP \\lbrace N(s) = k | N(t) = n \\rbrace = \\binom{n}{k}(\\frac{\\lambda s}{n})^k(1 - \\frac{\\lambda s}{n})^{n - k}\n$$</div>\n\n<h4 id=\"总结泊松过程的几种定义\"><a href=\"#总结泊松过程的几种定义\" class=\"headerlink\" title=\"总结泊松过程的几种定义\"></a>总结泊松过程的几种定义</h4><ol>\n<li>N(0) &#x3D; 0，独立增量，平稳增量，$\\Delta t$ 内发生一个事件的概率 $\\lambda \\Delta t$，发生两件事以上的概率小</li>\n<li>事件时间间隔独立同分布，服从复指数分布，则计数为泊松</li>\n<li>N 个客体随机地分布在 $[0, t]$ 区间上，每个客体的出现时间均匀分布，且相互时间独立，当 $n \\rightarrow \\infty, t \\rightarrow \\infty$，极限分布为泊松分布</li>\n<li>二项分布的极限</li>\n</ol>\n<h3 id=\"顺序统计量\"><a href=\"#顺序统计量\" class=\"headerlink\" title=\"顺序统计量\"></a>顺序统计量</h3><p>统计量是样本的某个函数 $g(X_1, …, X_n)$。例如：最大值、中值、平均值、样本协方差阵</p>\n<p>顺序统计量：根据到达时刻排序。例如 $S_1, S_2, …, S_n$ 就是 $V_1, V_2, …, V_n$ 的顺序统计量</p>\n<div>$$\nf_{Y_k}(x) = \\binom{n}{k - 1}F(x)\\binom{n - k + 1}{1}f(x)(1 - F(x))^{n - k}\n$$</div>\n\n<p>有序的顺序统计量的分布：</p>\n<div>$$\nf_{Y_1...Y_n}(y_1, y_2, ..., y_n) = n!f(y_1)f(y_2)...f(y_n)\n$$</div>\n\n<h3 id=\"非齐次泊松过程\"><a href=\"#非齐次泊松过程\" class=\"headerlink\" title=\"非齐次泊松过程\"></a>非齐次泊松过程</h3><p>四个条件：</p>\n<p>$N(0) &#x3D; 0$</p>\n<p>$N(t)$ 独立增量</p>\n<p>$P(N(t + \\Delta t) - N(t) &#x3D; 1) &#x3D; \\lambda(t)\\Delta t + o(\\Delta t)$</p>\n<p>$P(N(t + \\Delta t) - N(t) \\ge 2) &#x3D; o(\\Delta t)$</p>\n<p>定理：</p>\n<div>$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{[m(t_0 + t) - m(t_0)]^n}{n!}e^{-[m(t_0 + t) - m(t_0)]}\n$$</div>\n\n<p>其中，</p>\n<div>$$\nm(t) = \\int_{0}^{t}\\mathrm \\lambda(u) du\n$$</div>\n\n<p>其意义可以理解为事件的个数。</p>\n<p>令 $m(t + t_0) - m(t_0) &#x3D; \\alpha$</p>\n<div>$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{\\alpha^n}{n!}e^{-\\alpha}\n$$</div>\n\n<p>则期望和方差</p>\n<div>$$\nE(N(t_0 + t) - N(t_0)) = \\alpha\\\\\nV(N(t_0 + t) - N(t_0)) = \\alpha\n$$</div>\n\n<h3 id=\"复合泊松\"><a href=\"#复合泊松\" class=\"headerlink\" title=\"复合泊松\"></a>复合泊松</h3><p>$Y_n$ 随机变量族，$N(t)$ 泊松过程，称$X(t) &#x3D; \\sum_{n &#x3D; 1}^{N(t)}Y_n$ 为复合泊松。</p>\n<div>$$\nE \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i \\rbrace\\\\\nD \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i^2 \\rbrace\\\\\nG_X(z) = \\exp(\\lambda t G_Y(z) - 1)\\\\\n\\phi_X(\\omega) = \\exp(\\lambda t \\phi_Y(\\omega) - 1)\n$$</div>\n\n<h3 id=\"随机参数泊松\"><a href=\"#随机参数泊松\" class=\"headerlink\" title=\"随机参数泊松\"></a>随机参数泊松</h3><p>参数 $\\lambda$ 是随机变量，PDF为 $f(\\lambda)$</p>\n<ul>\n<li>是平稳增量</li>\n<li>不是独立增量</li>\n</ul>\n<div>$$\nP(Y(t) = n) = \\int^{+\\infty}_{0}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda\n$$</div>\n\n<p>母函数：</p>\n<div>$$\nG_{Y(t)}(z) = \\int_{0}^{\\infty}\\exp (\\lambda t(z - 1))f(\\lambda)\\mathrm d\\lambda\n$$</div>\n\n<div>$$\nE(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\nV(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\n$$</div>\n\n<p>数据统计的后验分布</p>\n<div>$$\nP(\\Lambda \\le x | Y(t) = n) = \\frac{\\int_{0}^{x}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\\\\\nf_\\Lambda(x|Y(t) = n) = \\frac{\\frac{(x t)^n}{n!}e^{-x t}f(x)}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\n$$</div>\n\n<h3 id=\"过滤的泊松过程\"><a href=\"#过滤的泊松过程\" class=\"headerlink\" title=\"过滤的泊松过程\"></a>过滤的泊松过程</h3><p>统计一段时间影响的总和</p>\n<div>$$\nY(t) = \\sum\\limits_{i=1}^{N(t)}h(t, S_i, A_i)\n$$</div>\n\n<p>特征函数：</p>\n<div>$$\n\\Phi_{Y(t)}(\\omega) = \\exp \\left ( \\lambda t \\left ( \\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv - 1\\right) \\right)\n$$</div>\n\n<p>均值：</p>\n<div>$$\nE(Y(t)) = \\frac{1}{j}\\frac{\\partial \\Phi_{Y(t)}}{\\partial \\omega} = \\underbrace{\\lambda t}_{平均到达个数} \\underbrace{\\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv}_{每个事件在 t 时刻的影响}\n$$</div>\n\n<h2 id=\"生灭过程\"><a href=\"#生灭过程\" class=\"headerlink\" title=\"生灭过程\"></a>生灭过程</h2><p>该过程状态可以用整数序列 $n &#x3D; 0, 1, 2, 3, …$ 来表示</p>\n<p>状态转移只能发生在临近状态之间</p>\n<p>在$[t, t + \\Delta t)$ 区间内，n状态转移到 $n + 1$ 状态的概率为 $\\lambda \\Delta t$， 转移到 $n - 1$ 状态的概率为 $\\mu \\Delta t$。</p>\n<h3 id=\"M-x2F-M-x2F-1\"><a href=\"#M-x2F-M-x2F-1\" class=\"headerlink\" title=\"M&#x2F;M&#x2F;1\"></a>M&#x2F;M&#x2F;1</h3><p>系统平均顾客人数 $L &#x3D; \\frac{\\lambda &#x2F; \\mu}{1 - \\lambda &#x2F; \\mu}$</p>\n<p>排队平均人数</p>\n<div>$$\nL_Q = \\sum\\limits_{n=1}^{\\infty}(n - 1)p_n = \\frac{\\lambda^2}{(\\mu - \\lambda)\\mu}\\\\\nL_Q \\ne L - 1\n$$</div>\n\n<p>前面有一个人，等待时间：负指数分布的无记忆性</p>\n<div>$$\nf_T(t|T > t_0) = \\mu e^{-\\mu (t - t_0)}\n$$</div>\n\n<p>从而不管你什么时候来，平均等待时间为 $1&#x2F;\\mu$，和一个人被服务的时间是一样的。</p>\n<h2 id=\"习题课\"><a href=\"#习题课\" class=\"headerlink\" title=\"习题课\"></a>习题课</h2><p><img src=\"/../images/stochastic/exer_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"随机过程随机过\"><a href=\"#随机过程随机过\" class=\"headerlink\" title=\"随机过程随机过\"></a>随机过程随机过</h2><p>信号与系统：研究确定信号随着时间、空间的变化</p>\n<p>概率论：研究随机信号，但是不随时间、空间变化</p>\n<p>随机过程：研究随机的信号随着时间、空间的变化</p>\n<blockquote>\n<p>期末70分梭哈</p>\n<p>考试题目不随机，就跟不上这门课的要求。</p>\n</blockquote>\n<h3 id=\"概率与随机变量回顾\"><a href=\"#概率与随机变量回顾\" class=\"headerlink\" title=\"概率与随机变量回顾\"></a>概率与随机变量回顾</h3><p>样本空间$\\Omega$</p>\n<p>性质：</p>\n<ul>\n<li>非负性：$P(A) \\ge 0$</li>\n<li>规范性：$P(\\Omega), P(\\emptyset) &#x3D; 0$</li>\n<li>可加性：$P(\\bigcup\\limits_{k &#x3D; 1}^{\\infty}A_k) &#x3D; \\sum\\limits_{k&#x3D;1}^{\\infty}P(A_k)$</li>\n</ul>\n<p>贝叶斯：</p>\n<div>$$\nP(B_i|A) = \\frac{P(A|B_i)P(B_i)}{\\sum\\limits_{j = 1}^{k}P(B_j)P(A|B_j)}\n$$</div>\n\n<p>随机变量：</p>\n<p>分布函数，概率密度函数</p>\n<p>期望，方差，协方差，相关系数</p>\n<p>伯努利分布，高斯分布，泊松分布，瑞利分布</p>\n<p>伯努利分布的概率密度函数：</p>\n<p>当$k&#x3D;1$时，$P(X&#x3D;1) &#x3D; p$<br>当$k&#x3D;0$时，$P(X&#x3D;0) &#x3D; 1-p$</p>\n<p>高斯分布的概率密度函数：<br>$P(x) &#x3D; \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$</p>\n<p>二维高斯分布的概率密度函数：</p>\n<p>$P(x,y) &#x3D; \\frac{1}{2\\pi\\sigma_x\\sigma_y\\sqrt{1-\\rho^2}}\\exp\\left(-\\frac{1}{2(1-\\rho^2)}\\left[\\frac{(x-\\mu_x)^2}{\\sigma_x^2}-2\\rho\\frac{(x-\\mu_x)(y-\\mu_y)}{\\sigma_x\\sigma_y}+\\frac{(y-\\mu_y)^2}{\\sigma_y^2}\\right]\\right)$</p>\n<p>其中，$\\mu_x$和$\\mu_y$是均值，$\\sigma_x$和$\\sigma_y$是标准差，$\\rho$是相关系数。</p>\n<p>泊松分布的概率密度函数：<br>$P(k;\\lambda) &#x3D; \\frac{\\lambda^k}{k!}\\exp(-\\lambda)$</p>\n<p>瑞利分布的概率密度函数：<br>$P(x;\\sigma) &#x3D; \\frac{x}{\\sigma^2}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$</p>\n<h3 id=\"随机过程的基本概念\"><a href=\"#随机过程的基本概念\" class=\"headerlink\" title=\"随机过程的基本概念\"></a>随机过程的基本概念</h3><p>定义：</p>\n<p>给定概率空间$(\\Omega, \\mathcal{F}, P)$，定义参数集$T \\subset R$，$t \\in T$</p>\n<div>$$\nX = \\lbrace X(t, \\omega), t \\in T, \\omega \\in \\Omega \\rbrace\n$$</div>\n\n<p>简记为$X(t)$: $X &#x3D; \\lbrace X(t), t \\in T\\rbrace$</p>\n<p>解释：</p>\n<ul>\n<li>二元单值函数</li>\n<li>对每个固定t，$X(t, \\omega)$是一个随机变量</li>\n<li>每个$\\omega_0 \\in \\Omega$, $X(t, \\omega_0)$是定义在T上的函数，记为$x(t, \\omega_0)$</li>\n</ul>\n<p>单样本为随机变量：均值、方差、协方差、有限维联合分布等</p>\n<p>随机过程的函数特性：时间的相关性，连续性和离散性，随机过程的导数、微分、积分、卷积、级数展开、微分方程、积分方程等</p>\n<p>二重性的联合特征：</p>\n<p>分类：</p>\n<p>离散时间，离散分布：Bernouli过程</p>\n<p>离散时间，连续分布：自回归过程</p>\n<p>连续参数离散随机过程：Poission过程</p>\n<p>连续参数连续型随机过程：Brown运动</p>\n<p>数学特征：</p>\n<p>相互独立和不相关是两个概念，无必然因果联系。</p>\n<p>根据数字特征分类：</p>\n<ul>\n<li>独立增量过程</li>\n<li>平稳过程及二阶矩过程</li>\n<li>马尔可夫过程</li>\n<li>更新过程</li>\n</ul>\n<p>独立增量过程是一种随机过程，具有以下特性：</p>\n<ol>\n<li><p>零起点：独立增量过程在零时刻（通常表示为$t&#x3D;0$）的取值为零，即$X(0) &#x3D; 0$。</p>\n</li>\n<li><p>独立增量：对于任意时刻$t_1 &lt; t_2 &lt; \\cdots &lt; t_n$，随机变量$X(t_2)-X(t_1), X(t_3)-X(t_2), \\cdots, X(t_n)-X(t_{n-1})$是相互独立的。</p>\n</li>\n</ol>\n<p>若对一切$0\\le s \\lt t$，增量$X(t) - X(s)$的分布仅依赖于$t - s$，则称之为平稳增量，具有平稳增量的独立增量过程称为独立平稳增量过程，例如泊松和布朗。</p>\n<p>二阶矩过程：$D(X(t))$</p>\n<p>宽平稳过程：</p>\n<p>宽平稳过程可以用以下简单的数学表达式表示：</p>\n<ol>\n<li><p>均值平稳性：对于宽平稳过程 $X(t)$，其均值满足 $E[X(t)] &#x3D; \\mu$，其中 $\\mu$ 是一个常数。</p>\n</li>\n<li><p>自相关平稳性：宽平稳过程的自相关函数在时间差 $\\tau$ 下为常数，可以表示为 $R_X(\\tau) &#x3D; R_X(t,t+\\tau) &#x3D; \\text{常数}$，其中 $R_X(\\tau)$ 表示宽平稳过程的自相关函数。</p>\n</li>\n</ol>\n<p>严平稳过程（Strict-sense stationary process），也称为严格平稳过程或强平稳过程，是一种具有更强平稳性质的随机过程。它满足以下两个条件：</p>\n<ol>\n<li><p>时移不变性：严平稳过程的统计性质在时间上任意平移保持不变。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，随机变量 $X(t)$ 和 $X(t+\\tau)$ 的联合分布相同，即联合分布满足 $P(X(t) \\in A, X(t+\\tau) \\in B) &#x3D; P(X(0) \\in A, X(\\tau) \\in B)$，其中 $A,B$ 是任意集合。</p>\n</li>\n<li><p>自相关平稳性：严平稳过程的自相关函数只与时间差有关，与参考时刻无关。具体而言，对于任意时间差 $\\tau$ 和任意时间点 $t$，自相关函数满足 $R_X(t,t+\\tau) &#x3D; R_X(\\tau)$，其中 $R_X(\\tau)$ 表示严平稳过程的自相关函数。</p>\n</li>\n</ol>\n<p>马尔可夫过程是一种具有马尔可夫性质的随机过程。它可以用以下公式和概念来定义：</p>\n<ol>\n<li><p>状态空间：马尔可夫过程的状态空间是一个离散集合，表示可能的状态集合。通常用符号 $S$ 表示，$S &#x3D; {s_1, s_2, \\ldots}$。</p>\n</li>\n<li><p>马尔可夫性质：马尔可夫过程具有马尔可夫性质，也称为无后效性。即，在给定当前时刻的状态 $X(t)$ 之下，未来的状态 $X(t+\\Delta t)$ 只依赖于当前的状态 $X(t)$，与过去的状态 $X(t-1), X(t-2), \\ldots$ 无关。</p>\n</li>\n<li><p>转移概率：转移概率描述了在给定当前状态 $s_i$ 的情况下，马尔可夫过程在下一个时刻转移到状态 $s_j$ 的概率。转移概率通常用符号 $P_{ij}$ 表示，即 $P_{ij} &#x3D; P(X(t+\\Delta t) &#x3D; s_j \\mid X(t) &#x3D; s_i)$。</p>\n</li>\n</ol>\n<p>通过状态空间和转移概率，可以构建一个马尔可夫过程的状态转移矩阵（Transition Matrix），它描述了从一个状态到另一个状态的转移概率情况。</p>\n<p>更新过程：</p>\n<p>更新过程可以使用以下公式来描述：</p>\n<ol>\n<li><p>到达时间：假设到达时间的随机变量序列为 $T_1, T_2, T_3, \\ldots$，其中 $T_i$ 表示事件 $i$ 的到达时间。</p>\n</li>\n<li><p>描述参数：更新过程的到达率（或强度）表示单位时间内平均发生事件的次数。通常用符号 $\\lambda$ 表示，即 $\\lambda &#x3D; \\lim_{t \\to \\infty} \\frac{N(t)}{t}$，其中 $N(t)$ 表示时间 $t$ 之前（包括 $t$）发生的事件次数。</p>\n</li>\n<li><p>插值函数：更新过程的插值函数（或插值过程）表示给定时间 $t$ 时，最近的到达时间是多久之前。记为 $S(t)$，即 $S(t) &#x3D; \\sup{T_i \\leq t}$，表示最近的到达时间小于等于 $t$ 的时间点。</p>\n</li>\n</ol>\n<p>可以定义复随机过程：</p>\n<p>复随机过程是一组复数值随机变量的集合 ${X(t), t \\in T}$，其中 $X(t)$ 是定义在概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数值随机变量，表示在时间点 $t$ 上的取值。</p>\n<p>具体而言，对于每个时间点 $t \\in T$，$X(t)$ 是一个复数值随机变量，可以表示为 $X(t) &#x3D; R(t) + iI(t)$，其中 $R(t)$ 和 $I(t)$ 分别表示实部和虚部。</p>\n<p>复随机过程可以通过概率空间 $(\\Omega, \\mathcal{F}, P)$ 上的复数随机变量以及时间参数 $T$ 来描述，并且在不同时间点上表现出复数值随机变量的随机性质。</p>\n<p>数学特征：</p>\n<p>均值函数（一阶原点矩）：$\\mu_X(t) &#x3D; E[X(t)]$</p>\n<p>方差函数：$\\text{Var}[X(t)] &#x3D; E[(X(t) - \\mu_X(t))(X(t) - \\overline{\\mu_X(t)} )]$</p>\n<p>自相关函数：$R_X(t_1, t_2) &#x3D; E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$</p>\n<p>自协方差函数：$\\text{Cov}[X(t_1), X(t_2)] &#x3D; E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\overline{\\mu_X(t_2)} )]$</p>\n<p>均方值函数：$E[|X(t)|^2] &#x3D; \\int_{-\\infty}^{\\infty} |x|^2 f_X(x,t)dx$</p>\n<h3 id=\"基本研究方法\"><a href=\"#基本研究方法\" class=\"headerlink\" title=\"基本研究方法\"></a>基本研究方法</h3><ul>\n<li>相关方法</li>\n<li>Markov 方法</li>\n</ul>\n<p><strong>相关</strong></p>\n<p>若随机过程在任意时刻的均值和方差都存在，则称之为二阶矩过程（second order process），即均方可积空间上的随机变量。</p>\n<p>均方可积空间是内积空间。相关运算是均方可积的内积运算：</p>\n<div>$$\n\\langle X, Y \\rangle = E(X\\overline Y)\n$$</div>\n\n\n<p>宽平稳（wide-sense stationary）:</p>\n<div>$$\nR_X(t, s) = R_X(t + D, s + D) = R(t - s)\n$$</div>\n\n<p>功率谱密度：</p>\n<div>$$\nS_X(\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\exp(-j\\omega\\tau)\\mathrm d\\tau\n$$</div>\n\n<p>最优线性估计</p>\n<p><strong>Markov</strong></p>\n<p>有限维联合分布可以由各阶的条件分布表示出来：</p>\n<div>$$\n\\begin{align*}\n    &F_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n) \\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)F_{X(t_{n - 1}), \\dots, X(t_1)}(x_1, \\dots, x_{n - 1})\\\\\n    =&F_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1)\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n\\end{align*}\n$$</div>\n\n<p>无后效性的 markov 过程：</p>\n<div>$$\nF_{X(t_n)|X(t_{n - 1}), \\dots, X(t_1)}(x_n|x_{n - 1}, \\dots, x_1) = F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\n$$</div>\n\n<p>从而所有高阶依赖关系都可以简化为二阶依赖：</p>\n<div>$$\nF_{X(t_1), \\dots, X(t_n)}(x_1, \\dots, x_n)=F_{X(t_n)|X(t_{n - 1})}(x_n|x_{n - 1})\\dots F_{X(t_2)|X(t_1)}(x_2|x_1)F_{X(t_1)}(x_1)\n$$</div>\n\n<h2 id=\"相关理论与二阶矩过程——时域分析\"><a href=\"#相关理论与二阶矩过程——时域分析\" class=\"headerlink\" title=\"相关理论与二阶矩过程——时域分析\"></a>相关理论与二阶矩过程——时域分析</h2><h3 id=\"自相关函数\"><a href=\"#自相关函数\" class=\"headerlink\" title=\"自相关函数\"></a>自相关函数</h3><p>由二阶矩过程的定义可知，均方可积空间的自相关函数、自协方差函数、互相关函数、互协方差函数均存在。</p>\n<p>均值函数（一阶原点矩）：$\\mu_X(t) &#x3D; E[X(t)]$</p>\n<p>方差函数：$\\text{Var}[X(t)] &#x3D; E[(X(t) - \\mu_X(t))^2]$</p>\n<p>自相关函数：$R_X(t_1, t_2) &#x3D; E[(X(t_1))(X^*(t_2))]$</p>\n<p>自协方差函数：$C_X(t_1, t_2) &#x3D; \\text{Cov}[X(t_1), X(t_2)] &#x3D; E[(X(t_1) - \\mu_X(t_1))(X(t_2) - \\mu_X(t_2))^*]$</p>\n<p>均方值函数：$E[X^2(t)] &#x3D; \\int_{-\\infty}^{\\infty} x^2 f_X(x,t)dx$</p>\n<p>互相关函数和互协方差函数：</p>\n<ul>\n<li>如果$E[X(s)Y(t)]存在$，记为$R_{XY}(s, t)$</li>\n<li>如果$\\text{cov}(X(s), Y(t))存在$，记为$C_{XY}(s, t)$</li>\n</ul>\n<div>$$\nR_{XY}(t_1, t_2) = E[(X(t_1))(Y^*(t_2))]\n$$</div>\n\n<div>$$\nC_{XY}(t_1, t_2) = E[(X(t_1) - \\mu_X(t_1))(Y(t_2) - \\mu_Y(t_2))^*]\n$$</div>\n\n<div>$$\nC_{XY}(s, t) = R_{XY}(s,t) - \\mu_X(s)\\mu_Y(t)\n$$</div>\n\n<p>不相关：</p>\n<div>$$\nC_{XY}(s, t) = 0\n$$</div>\n\n<div>$$\nR_{XY}(s,t) = m_X(s)m_Y(t)\n$$</div>\n\n\n<p>自相关函数具有共轭对称性：</p>\n<div>$$\nR(t_1, t_2) = R^*(t_2, t_1)\n$$</div>\n\n<p>离散化的自相关矩阵同样是共轭对称的：</p>\n<div>$$\nR = E[XX^H]\\\\\nR_{ij} = R^*_{ji}\n$$</div>\n\n<p>自相关矩阵是非负定的：</p>\n<div>$$\n\\lambda R \\lambda^H = \\lambda XX^H\\lambda^H \\ge 0\n$$</div>\n\n<p>当 $P(\\lambda X &#x3D; 0) &#x3D; 1$ 时等号成立。</p>\n<p>非负定性是自相关函数的一种特征性质。如果一个二元函数满足非负定性质，则一定可以构造出一个随机过程，使得其自相关函数为给定的二元函数。</p>\n<p>自相关矩阵非负定，分解的特征值均非负。其物理意义是信号的能量或者功率。</p>\n<p>自相关函数对加法和乘法的封闭性：</p>\n<div>$$\nR(t, s) = \\alpha R_1(t, s) + \\beta R_2(t, s)\n$$</div>\n\n<p>仍然是某一随机过程的自相关函数。</p>\n<p>证明：取 $Z(t) &#x3D; \\alpha^{1&#x2F;2} X(t) + \\beta^{1&#x2F;2} Y(t)$。这里 $X(t), Y(t)$是独立的。</p>\n<div>$$\nR(t, s) = R_1(t, s)R_2(t, s)\n$$</div>\n\n<p>也是自相关函数。取 $Z(t) &#x3D; X(t)Y(t)$。</p>\n<h3 id=\"宽平稳随机过程\"><a href=\"#宽平稳随机过程\" class=\"headerlink\" title=\"宽平稳随机过程\"></a>宽平稳随机过程</h3><p><strong>宽平稳</strong></p>\n<p>对于随机过程 $X(t), t \\in T$，若 $\\forall t, s\\in T$</p>\n<div>$$\nE(X(t)) = E(X(s))\\\\\nR_X(t, s) = R_X(t + D, s + D)\n$$</div>\n\n<p>称随机过程 $X(t)$ 具有宽平稳性。</p>\n<p>宽平稳过程的均值是常数，自相关函数与相对时间差有关。故宽平稳过程的自相关函数可以写成一元函数：$R_X(\\tau), \\tau &#x3D; t - s$。</p>\n<p><strong>严平稳</strong></p>\n<p>对于随机过程 $X(t), t \\in T$，若 $\\forall n, \\forall t_1, t_2, \\dots, t_n \\in T$，$\\forall D \\in T$，都有</p>\n<div>$$\nF_{t_1, t_2, \\dots, t_n}(x_1, x_2, \\dots, x_n) = F_{t_1 + D, t_2+D, \\dots, t_n + D}(x_1, x_2, \\dots, x_n)\n$$</div>\n\n<p>则称随机过程 $X(t), t\\in T$具有严平稳性。</p>\n<p>在二阶矩存在的条件下，严平稳蕴含宽平稳，而反过来，宽平稳一般无法得到严平稳。</p>\n<p>高斯过程的严平稳与宽平稳等价。</p>\n<p><strong>联合宽平稳</strong></p>\n<div>$$\nR_{X, Y}(t, s) = R_{XY}(t + D, s + D), \\forall D \\in T\n$$</div>\n\n<p><strong>宽平稳过程的性质</strong></p>\n<p>设 $R_X(\\tau)$ 为宽平稳过程的自相关函数， $m_X$ 为该过程的均值。</p>\n<div>$$\n\\begin{align}\n    R_X(\\tau) = \\overline{R_X(-\\tau)}\\\\\n    R_X(0)\\ge |m_X|^2\\\\\n    |R_X(\\tau)| \\le R_X(0)\\\\\n    R_X(\\tau) \\text{是一元非负定函数。}\n\\end{align}\n$$</div>\n\n<h3 id=\"正交增量过程\"><a href=\"#正交增量过程\" class=\"headerlink\" title=\"正交增量过程\"></a>正交增量过程</h3><p><strong>正交增量过程</strong></p>\n<p>对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，满足</p>\n<div>$$\nE(X(t_4) - X(t_3))(\\overline{X(t_2) - X(t_1)}) = 0\n$$</div>\n\n<p>则称 $X(t), t \\in \\R$ 为正交增量过程。</p>\n<p><strong>独立增量过程</strong></p>\n<p>对于二阶矩过程 $X(t), t \\in \\R$，若 $\\forall t_1 \\lt t_2 \\le t_3 \\lt t_4$，$t_1, t_2, t_3, t_4 \\in \\R$，$X(t_4) - X(t_3)$ 和 $X(t_2) - X(t_1)$ 统计独立，则称为独立增量过程。</p>\n<p>均值为0的独立增量过程是正交增量过程。</p>\n<p><strong>平稳增量过程</strong></p>\n<p>对于随机过程 $X(t), t \\in \\R$，若 $X(t) - X(s)$ 的分布仅仅依赖于 $t - s$，则称为平稳增量过程。</p>\n<p>定理：</p>\n<p>随机过程 $X(t), t \\in [0, \\infty]$，满足 $X(0) &#x3D; 0$，则其为正交增量过程的充要条件为</p>\n<div>$$\nR_X(s, t) = F(\\min(s, t))\n$$</div>\n\n<p>其中，$F(\\cdot)$是单调不减的函数。</p>\n<h3 id=\"随机过程的极限、连续、导数、积分\"><a href=\"#随机过程的极限、连续、导数、积分\" class=\"headerlink\" title=\"随机过程的极限、连续、导数、积分\"></a>随机过程的极限、连续、导数、积分</h3><p><strong>均方极限</strong></p>\n<div>$$\nE(|ka|^2)\n$$</div>\n\n\n\n<p>唯一性：若 $X_n \\xrightarrow{m.s} X, X_n \\xrightarrow{m.s}Y$，则 $E(|X - Y|^2) &#x3D; 0$.</p>\n<p>可加性：</p>\n<p>数字特征相同：</p>\n<p>如何判定 ${X_n}$ 是否收敛？</p>\n<p>Cauchy 准则</p>\n<div>$$\nX_n \\xrightarrow{m.s}{X} \\Leftrightarrow E(|X_m - X_n|^2) = 0, m, n \\rightarrow \\infty\n$$</div>\n\n<p>洛伊夫准则：</p>\n<div>$$\nX_n \\xrightarrow{m.s} X \\lrArr E\\lbrace X_n X_m^*\\rbrace \\rightarrow \\text{constant}\n$$</div>\n\n<p><strong>均方连续</strong></p>\n<p>二阶矩过程，$t \\rightarrow t_0, X(t) \\xrightarrow{m.s.} X(t_0)$，则称 $X(t)$ 在 $t_0$ 处连续</p>\n<p>定理</p>\n<p>以下命题等价：</p>\n<ol>\n<li>$R(t, s)$ 在 $(t_0, t_0)$ 上连续，$\\forall t_0 \\in T$</li>\n<li>$X(t)$ 在 $T$ 上均方连续</li>\n<li>$R(t, s)$ 在 $T \\times T$ 上连续</li>\n</ol>\n<p>推论</p>\n<p>对于宽平稳过程 $X(t)$，$R(\\tau)$ 为自相关函数，以下命题等价：</p>\n<ol>\n<li>$R(\\tau)$ 在 $\\tau &#x3D; 0$ 处连续；</li>\n<li>$X(t)$ 在 $T$ 上均方连续；</li>\n<li>$R(\\tau)$ 在 T 上连续。</li>\n</ol>\n<p><strong>均方导数</strong></p>\n<p>若 $\\frac{X(t_0 + h) - X(t_0)}{h}\\xrightarrow{m.s.}Y(t_0), \\forall t_0 \\in T, h \\rightarrow 0$，则称$\\lbrace X(t) \\rbrace$ 在均方意义下的导数为 $Y(t)$。</p>\n<p>如何判断 $X(t)$ 是否均方可导？</p>\n<p>Cauchy 准则</p>\n<div>$$\nE\\left(|\\frac{X(t_0 + h) - X(t_0)}{h} - \\frac{X(t_0 + g) - X(t_0)}{g}|^2\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$</div>\n\n<p>洛伊夫准则</p>\n<div>$$\nE\\left(\\left(\\frac{X(t_0 + h) - X(t_0)}{h}\\right)\\left(\\frac{X(t_0 + g) - X(t_0)}{g}\\right)^*\\right) \\rightarrow 0, \\forall h, g \\rightarrow 0\n$$</div>\n\n<p>均方导数判定定理</p>\n<div>$$\n\\frac{\\partial^2 R(t, s)}{\\partial t \\partial s} 在 (t_0, t_0) 存在且连续，则 X(t) 在 t_0 处存在均方倒数\n$$</div>\n\n<p>均方导数的性质：</p>\n<p>$f(t)$ 为线性函数</p>\n<ul>\n<li>$E(X^\\prime(t)) &#x3D; \\frac{\\mathrm d }{\\mathrm dt} E(X(t))$</li>\n<li>$E(X^\\prime(t)\\overline{X(s)}) &#x3D;\\frac{\\partial }{\\partial t}R_x(t, s)$</li>\n<li>$E(X(t)\\overline{X^\\prime(s)}) &#x3D;\\frac{\\partial }{\\partial s}R_x(t, s)$</li>\n<li>$E(X^\\prime(t)\\overline{X^\\prime(s)}) &#x3D;\\frac{\\partial^2 }{\\partial t\\partial s}R_x(t, s)$</li>\n</ul>\n<p><strong>均方积分</strong></p>\n<p>若黎曼和 $\\sum\\limits_{k&#x3D;1}^{n}X(v_k)h(v_k)(t_k - t_{k - 1})$ 在 $n \\rightarrow \\infty, \\max\\lbrace t_k - t_{k - 1}\\rbrace \\rightarrow 0$ 时均方收敛，其中 $h(t)$ 为确定的可积函数，则称$\\lbrace X(t)\\rbrace$ 为均方可积，记为 $\\int_{a}^{b}X(t)h(t)\\mathrm dt$。</p>\n<p>判定定理</p>\n<div>$$\n\\lbrace X(t)h(t) \\rbrace 均方可积 \\Leftrightarrow \\int_{a}^{b}\\int_{a}^{b}R_X(t, s)h(t)h^*(s)\\mathrm dt\\mathrm ds 存在\n$$</div>\n\n<p>均方积分的性质：</p>\n<ul>\n<li>$E\\left( \\int_{a}^{b}X(t)h(t)\\mathrm dt\\right) &#x3D; \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$</li>\n<li>$E\\left( \\left(\\int_{a}^{b}X(t)h(t)\\mathrm dt\\right)\\left(\\int_{a}^{b}X(s)h(s)\\mathrm ds\\right)^*\\right) &#x3D; \\int_{a}^{b}E(X(t))h(t)\\mathrm dt$</li>\n<li>三角不等式：$\\sqrt{ E \\left(|\\int_{a}^{b}X(t)h(t)\\mathrm dt|^2\\right) } \\le \\int_{a}^{b}\\sqrt{E\\left(|X(t) - h(t)|^2\\right)}\\mathrm dt$</li>\n<li>均方积分与均方导数：$X(t)$ 在 $[a, b]$ 上均方连续，$Y(t) &#x3D; \\int_{a}^{t}X(s)\\mathrm ds$，其中等号代表均方相等，则 $\\lbrace Y(t)\\rbrace$ 在 $[a, b]$ 可导，并称在均方意义下 $\\lbrace Y(t) \\rbrace$ 的导数为 $\\lbrace X(t) \\rbrace$</li>\n</ul>\n<h3 id=\"随机过程的遍历性\"><a href=\"#随机过程的遍历性\" class=\"headerlink\" title=\"随机过程的遍历性\"></a>随机过程的遍历性</h3><p>统计平均：对样本空间取平均</p>\n<div>$$\nE\\lbrace X(t_0) \\rbrace = \\int_{}^{}x\\mathrm dF_X(x;t_0)\n$$</div>\n\n<p>时间平均：</p>\n<div>$$\n\\langle X(t) \\rangle = \\frac{1}{T} \\int_{-T/2}^{T/2}X(t)\\mathrm dt\n$$</div>\n\n<p>统计平均和时间平均的关系？</p>\n<p>时间平均更容易获得。如果我们可以通过时间平均来获得统计平均？</p>\n<p><strong>遍历性</strong></p>\n<p>定义-宽平稳过程均值遍历：</p>\n<div>$$\n\\langle X(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} E \\lbrace X(t) \\rbrace = \\mu\n$$</div>\n\n<p>a.s. &#x3D; with probability 1</p>\n<p>左边是随机变量，右边是一个确定的数。这样的相等，意味着左边的随机变量的均值确定，方差为0.</p>\n<p>定义：宽平稳过程自相关遍历</p>\n<div>$$\n\\langle X(t + \\tau)X^*(t) \\rangle = \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T} \\int_{-T}^{T}X(t + \\tau)X^*(t)\\mathrm dt \\mathop{=}\\limits^{a.s.} R_X(\\tau) = E \\lbrace X(t + \\tau)X^*(t)\\rbrace\n$$</div>\n\n<p>a.s. &#x3D; with probability 1</p>\n<p>定理：</p>\n<p>宽平稳过程 $X(t)$ 满足均值遍历 $\\lrArr$ </p>\n<div>$$\nD(\\langle X(t) \\rangle) = \\lim\\limits_{T \\rightarrow\\infty} \\frac{1}{2T}\\int_{-2T}^{2T}\\left(1 - \\frac{|\\tau|}{2T}\\right)(R_X(\\tau) - |\\mu|^2)\\mathrm d\\tau = 0\n$$</div>\n\n<p>定理：</p>\n<p>宽平稳过程具有均值遍历性的充要条件是：</p>\n<div>$$\n\\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{2T}\\int_{-T}^{T}C_X(\\tau)\\mathrm d\\tau = 0 或者 \\lim\\limits_{T\\rightarrow\\infty} \\frac{1}{T}\\int_{0}^{T}C_X(\\tau)\\mathrm d\\tau = 0\n$$</div>\n\n<p>时间比较长的时候相关性消失了，也就是说过了一段时间同一轨道的样本就独立了，等价于多个轨道的样本，时间平均和统计平均就相等了。</p>\n<p>2个推论：</p>\n<ul>\n<li>若实数宽平稳过程的协方差函数满足 $\\int_{0}^{+\\infty}C_x(\\tau)\\mathrm d\\tau\\lt +\\infty$，则该过程具有均值遍历性</li>\n<li>若实数宽平稳过程的协方差函数满足 $C_x(\\tau) \\rightarrow 0, \\tau \\rightarrow +\\infty$，则该过程具有均值遍历性</li>\n</ul>\n<h3 id=\"随机过程的线性展开\"><a href=\"#随机过程的线性展开\" class=\"headerlink\" title=\"随机过程的线性展开\"></a>随机过程的线性展开</h3><p><strong>卡胡曼-洛伊夫展开</strong></p>\n<p>在平方可积空间上</p>\n<p>定义范数</p>\n<p>定义内积，正交</p>\n<p>在 $L^2[a, b]$ 中一定有一组标准正交基函数 $\\phi_1(t), \\phi_2(t), \\phi_3(t)\\dots$ 满足</p>\n<div>$$\n\\begin{cases}\n    \\langle \\phi_i, \\phi_j \\rangle = 0, i\\ne j\\\\\n    \\langle \\phi_i, \\phi_i \\rangle = 1\n\\end{cases}\n$$</div>\n\n<ul>\n<li>$f$ 可以用有限个基函数线性加和来逼近</li>\n<li>$\\langle f, \\phi_n \\rangle$ 表示 $f$ 在 $\\phi_n$ 基上的坐标。</li>\n</ul>\n<p>周期性宽平稳随机过程可以用傅里叶级数展开</p>\n<div>$$\nE\\left(\\left |X(t) -\\sum\\limits_{n=-\\infty}^{\\infty}c_ne^{j\\omega_0t}  \\right |^2\\right) = 0\n$$</div>\n\n<p>一般的用 KL 展开</p>\n<p>随机向量的双正交展开：</p>\n<p>零均值的 $n$ 元随机向量 $\\mathbf X \\in R^n$ 可以如下展开：</p>\n<div>$$\nX = \\sum\\limits_{k=1}^{n} \\xi_k \\mathbf e_k\n$$</div>\n\n<p>基向量选择的是自相关矩阵 $\\mathbf R$ 的特征向量。</p>\n<p>如果我们用 $\\mathbf K$ 个维度来逼近 $\\mathbf X$，为了使得误差最小，选取最大的$\\mathbf K$个特征值： $\\mathbf X &#x3D;\\sum\\limits_{k&#x3D;1}^{K} \\alpha_k\\mathbf e_k$。这就是主成分分析（PCA）。</p>\n<h2 id=\"谱分析\"><a href=\"#谱分析\" class=\"headerlink\" title=\"谱分析\"></a>谱分析</h2><h3 id=\"周期函数的傅里叶级数\"><a href=\"#周期函数的傅里叶级数\" class=\"headerlink\" title=\"周期函数的傅里叶级数\"></a>周期函数的傅里叶级数</h3><div>$$\nx(t) =\\sum\\limits_{n=-\\infty}^{\\infty}a_n e^{j\\omega_0 t}, \\omega_0 = \\frac{2\\pi}{T}\\\\\na_n = \\frac{1}{T}\\int_{0}^{T}x(t)e^{-jn\\omega_0t}\\mathrm dt\n$$</div>\n\n<p>帕斯瓦尔定理</p>\n<div>$$\n\\frac{1}{T}\\int_{0}^{T}|x(t)|^2\\mathrm dt =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\n$$</div>\n\n<p>自相关函数</p>\n<div>$$\nR(\\tau) = \\frac{1}{T}\\int_{0}^{T}x(t + \\tau)x^*(t)\\mathrm dt\n$$</div>\n\n<p>功率谱密度</p>\n<div>$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}|a_n|^2\\delta(\\omega - n \\omega_0)\n$$</div>\n\n<p>从而有</p>\n<div>$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\n$$</div>\n\n<h3 id=\"非周期函数的傅里叶变换\"><a href=\"#非周期函数的傅里叶变换\" class=\"headerlink\" title=\"非周期函数的傅里叶变换\"></a>非周期函数的傅里叶变换</h3><h4 id=\"知识\"><a href=\"#知识\" class=\"headerlink\" title=\"知识\"></a>知识</h4><div>$$\nF(\\omega) = \\int_{-\\infty}^{\\infty}x(t)\\exp(-j\\omega t)\\mathrm dt\\\\\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}F(\\omega)\\exp(j\\omega t)\\mathrm d\\omega = \\int_{-\\infty}^{\\infty}F(f)\\exp(j2\\pi ft)\\mathrm df\n$$</div>\n\n<p>帕斯瓦尔定理</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}|x(t)|^2\\mathrm dt = \\int_{-\\infty}^{\\infty}|F(f)|^2\\mathrm df\n$$</div>\n\n<div>$$\n时域采样 \\lrarr 频域周期延拓\\\\\n时域周期延拓 \\lrarr 频域采样\\\\\n$$</div>\n\n<p>自相关函数</p>\n<div>$$\nR(\\tau) = \\int_{-\\infty}^{\\infty}x(t + \\tau)x^*(t)\\mathrm dt\n$$</div>\n\n<p>能量谱密度</p>\n<div>$$\nS(\\omega) = |F(\\omega)|^2 = \\left |\\int_{-\\infty}^{\\infty}x(t)e^{j\\omega t}\\mathrm dt  \\right|^2\\\\\n$$</div>\n\n<p>波赫纳尔——辛钦定理</p>\n<div>$$\nS(\\omega) = \\int_{-\\infty}^{\\infty}R(\\tau)e^{-j\\omega\\tau}\\mathrm d\\tau\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S(\\omega)e^{j\\omega\\tau}\\mathrm d\\omega, S(\\omega)\\ge 0\n$$</div>\n\n<p>实过程的 $S(\\omega)$ 为偶函数。</p>\n<p>离散随机过程的功率谱：</p>\n<p>只在整数点 k 采样</p>\n<div>$$\nS(\\omega) =\\sum\\limits_{k=-\\infty}^{\\infty}R(k)e^{-j\\omega k}\\\\\nR(k) = \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}S(\\omega)e^{j\\omega k}\\mathrm d\\omega\n$$</div>\n\n<p>周期过程（自相关函数有周期性）的功率谱</p>\n<div>$$\nS(\\omega) =\\sum\\limits_{n=-\\infty}^{\\infty}b_n\\delta(\\omega - n \\Delta \\omega)\\\\\nR(\\tau) = \\frac{1}{2\\pi}\\sum\\limits_{n=-\\infty}^{\\infty}b_ne^{jn\\Delta\\omega\\tau}\n$$</div>\n\n<h4 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h4><p>白噪声 $E \\lbrace X(t) \\rbrace &#x3D; 0$，</p>\n<div>$$\nS(\\omega) = N_0, -\\infty \\lt \\omega \\le \\infty\\\\\nR(\\tau) = N_0\\delta(\\tau)\n$$</div>\n\n<ul>\n<li>任意两个不同时刻 $X(t_1), X(t_2)$ 都不相关。</li>\n<li>在各个频率上都有分量，且强度一致。</li>\n</ul>\n<p>高斯白噪声：各时刻服从高斯分布的白噪声</p>\n<p>色噪声： $R(\\tau)$ 不是冲击函数。</p>\n<ul>\n<li>当某过程 $R(\\tau)$ 比较胖的时候，功率谱比较瘦<ul>\n<li>相隔较长时间 $X(t)$ 与 $X(t + \\tau)$ 还相关，说明信号变化慢，对应频域低频多<br>分量多</li>\n</ul>\n</li>\n<li>当某过程 $R(\\tau)$ 比较瘦时，功率谱比较胖</li>\n<li>相隔一点时间， $X(t)$ 与 $X(t + \\tau)$ 不太相关，说明信号变化快，对应频域高频分量多。</li>\n</ul>\n<p>互谱密度</p>\n<div>$$\nS_{XY}(\\omega) = \\int_{-\\infty}^{\\infty}R_{XY}(\\tau)e^{-j\\omega \\tau}\\mathrm d\\tau\n$$</div>\n\n<p>称为互谱密度，不具有功率的含义。</p>\n<div>$$\nS_{YX}(\\omega) = S_{XY}^*(\\omega)\\\\\nR_{XY}(\\tau) = 0, \\forall \\tau \\lrArr S_{XY}(\\omega) = 0, \\forall \\omega\n$$</div>\n\n<div>$$\nZ(t) = X(t) + Y(t)\\\\\nR_Z(\\tau) = E \\lbrace (X(t + \\tau) + Y(t + \\tau))\\overline{(X(t) + Y(t))} \\rbrace = R_X(\\tau) + R_{XY}(\\tau) + R_{XY}\n$$</div>\n\n<p>一个宽平稳过程分别通过两个 LTI 系统：</p>\n<div>$$\nY_1(t) = X(t) * h_1(t)\\\\\nY_2(t) = X(t) * h_2(t)\\\\\nR_{Y_1Y_2}(\\tau) = R_X(\\tau) * h_1(\\tau) * h_2^*(-\\tau)\\\\\nS_{Y_1Y_2}(\\omega) = S_X(\\omega)H_1(\\omega)H_2^*(\\omega)\\\\\n$$</div>\n\n<p>两个过程输入两个系统，输出过程的互谱（互相关函数的傅里叶变换）。怎么求？</p>\n<p>（输入为联合宽平稳）</p>\n<div>$$\n\\hat X(t) = X(t) * f(t)\\\\\n\\hat Y(t) = Y(t) * g(t)\\\\\nR_{\\hat X\\hat Y}(\\tau) = R_{XY}(\\tau) * f(\\tau) * g^*(-\\tau)\\\\\nS_{\\hat X\\hat Y}(\\omega) = S_{XY}(\\omega)F(\\omega)G^*(\\omega)\n$$</div>\n\n\n<h3 id=\"宽平稳过程通过线性系统\"><a href=\"#宽平稳过程通过线性系统\" class=\"headerlink\" title=\"宽平稳过程通过线性系统\"></a>宽平稳过程通过线性系统</h3><div>$$\nY(t) = \\int_{-\\infty}^{\\infty}h(t - \\tau)X(\\tau)\\mathrm d\\tau\n$$</div>\n\n<p>总结：</p>\n<ul>\n<li>输出过程的均值：易求，因为宽平稳过程的均值为常数</li>\n<li>输出过程的自相关函数：有点麻烦</li>\n</ul>\n<p>首先看输出与输入的自相关</p>\n<div>$$\nR_{YX}(\\tau) = \\int_{-\\infty}^{\\infty}h(v)R_x(\\tau - v)\\mathrm dv\\\\\nR_Y(\\tau) = \\int_{-\\infty}^{\\infty}h^*(-u)R_{YX}(\\tau - u)\\mathrm du\n$$</div>\n\n<div>$$\nR_Y(\\tau) = R_X(\\tau) * h(\\tau) * h^*(-\\tau)\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$</div>\n\n<p>因此，输出的自相关，也可以用功率谱求解。</p>\n<h3 id=\"离散时间宽平稳序列\"><a href=\"#离散时间宽平稳序列\" class=\"headerlink\" title=\"离散时间宽平稳序列\"></a>离散时间宽平稳序列</h3><div>$$\nR_{YX}(k) = h(k) * R_X(k)\\\\\nR_Y(k) = h^*(-k) * h(k) * R_X(k)\\\\\nS_Y(z) = H(z) H^*(\\frac{1}{z^*})S_X(z)\\\\\n其中 H(z) =\\sum\\limits_{}^{}h(k)z^{-k}\\\\\n令 z = e^{j\\omega}\\\\\nS_Y(\\omega) = |H(\\omega)|^2S_X(\\omega)\n$$</div>\n\n<p>理想白噪声通过低通滤波器：</p>\n<div>$$\nS_Y(f) = \\begin{cases}\n    k_0, -f_c \\le f \\le f_c,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\\\\\nR_Y(0) = 2f_ck_0\\\\\nR(\\tau) = R_Y(0)\\frac{\\sin(2\\pi f_c\\tau)}{2\\pi f_c\\tau}\n$$</div>\n\n<p>从自相关函数可看出，相隔 $\\frac{n}{2f_c}$ 的两个时刻不相关。因此，以 $2f_c$ 为采样频率的噪声采样数据彼此不相关。</p>\n<p>可以证明宽平稳过程功率谱非负：$S_X(f) \\ge 0$：</p>\n<div>$$\nE \\lbrace |Y(t)|^2 \\rbrace =  R_Y(0) = \\int_{-\\infty}^{\\infty}S_Y(f)\\mathrm df = \\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\ge 0\n$$</div>\n\n<p>如果 $S_X(f)$ 在某个地方小于0，可以设计对应的滤波器 $H(f)$将这个小于0的区域滤出来，从而 $\\int_{-\\infty}^{\\infty}S_X(f)|H(f)|^2\\mathrm df \\le 0$，导致矛盾。</p>\n<p>线性系统例子：</p>\n<p>滑动平均</p>\n<div>$$\nY(t) = \\frac{1}{T}\\int_{t-T}^{t}X(s)\\mathrm ds\n$$</div>\n\n<p>转化为滤波器：</p>\n<div>$$\nR_Y(t) = R_X(t) * h(t) * h^*(-t)\\\\\nh(t) = \\begin{cases}\n    \\frac{1}{T}, 0 \\le t \\le T,\\\\\n    0, \\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>令 </p>\n<div>$$\ng(t) = h(t) * h^*(t) = \\begin{cases}\n    \\frac{1}{T}\\left ( 1 - \\frac{|t|}{T} \\right), t \\in [-T, T],\\\\\n    0,\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>理想的矩形窗</p>\n<div>$$\nR_Y(t) = \\int_{-\\infty}^{\\infty}g(t - \\tau)R_X(\\tau)\\mathrm d\\tau = \\int_{-T}^{T}\\frac{1}{T}\\left ( 1 - \\frac{|t - \\tau|}{T} \\right)R_X(\\tau)\\mathrm d\\tau\n$$</div>\n\n<p>从频域看</p>\n<div>$$\nH(\\omega) = \\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)e^{-j\\omega \\frac{T}{2}}\\\\\nS_Y(\\omega) = S_X(\\omega)\\left |\\text{sinc} \\left ( \\frac{\\omega T}{2} \\right)  \\right|^2\n$$</div>\n\n<p>是一个低通滤波器。</p>\n<p>例子2：MTI 滤波</p>\n<p>静止目标反射信号相同，运动目标反射回波不同。因此设计滤波器消去静止目标。称为“对消”。</p>\n<div>$$\nY(t) = X(t) - X(t - T)\n$$</div>\n\n<p>在频域看：</p>\n<div>$$\nH(\\omega) = 1 - e^{j\\omega T}\n$$</div>\n\n<p>静止目标，多普勒频率为0，因此频域响应为0；运动目标，多普勒频率不为0，频域响应不为0。因此这是一个高通滤波器。</p>\n<p>还可以多次对消：</p>\n<div>$$\nY_1(t) = X(t) - X(t - T)\\\\\nY_2(t) = Y_1(t) - Y_1(t - T)\\\\\nY_3(t) = Y_2(t) - Y_2(t - T)\\\\\n\\vdots\\\\\nY_n(t) = Y_{n - 1}(t) - Y_{n - 1}(t - T)\n$$</div>\n\n<p>频率响应：</p>\n<div>$$\nH(\\omega) = (1 - e^{-j\\omega T})^n\n$$</div>\n\n<h3 id=\"采样定理\"><a href=\"#采样定理\" class=\"headerlink\" title=\"采样定理\"></a>采样定理</h3><p>随机过程下的采样定理</p>\n<p>$|f| \\le f_0$, 当 $f_s \\le 2f_0$ 时，均方意义下有</p>\n<div>$$\nX(t) =\\sum\\limits_{k=-\\infty}^{\\infty}X(kT) \\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right)\n$$</div>\n\n<p>证明：</p>\n<div>$$\n\\begin{align*}\n    &要证明 N \\rightarrow \\infty 时,\\\\\n    &\\varepsilon_N = E \\left \\lbrace  \\left | X(t) -\\sum\\limits_{k=-N}^{N}X(kT)\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 \\right \\rbrace \\rightarrow 0\\\\\n    &利用E \\lbrace X(a) X^*(b) \\rbrace = R_X(a - b) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}e^{j\\omega a}e^{-j\\omega b}S_X(\\omega)\\mathrm d\\omega，展开上式\\\\\n    &\\varepsilon_N = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &= \\frac{1}{2\\pi}\\int_{-\\omega_s/2}^{\\omega_s/2}\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2  S_X(\\omega)\\mathrm d\\omega\\\\\n    &对 e^{j\\omega t}做周期延拓，周期为 \\omega_s，可以做频域傅里叶级数展开\\\\\n    &e^{j\\omega t} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega \\frac{2\\pi}{\\omega_s}} = \\sum\\limits_{k=-\\infty}^{\\infty}\\alpha_k e^{j\\omega kT}\\\\\n    &\\alpha_k = \\frac{1}{\\omega_s}\\int_{-\\omega_s/2}^{\\omega_s/2}e^{j\\omega t}e^{-j\\omega kT}\\mathrm d\\omega = \\frac{\\sin(\\frac{\\omega}{2}(t - kT))}{\\frac{\\omega}{2}(t - kT)}\\\\\n    &从而\\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}e^{j\\omega kT}\\text{sinc} \\left ( \\frac{\\pi}{T}(t - kT) \\right) \\right|^2 = \\left | e^{j\\omega t} -\\sum\\limits_{k=-N}^{N}\\alpha_k e^{j\\omega kT}\\right|^2 \\rightarrow 0, N \\rightarrow \\infty\n\\end{align*}\n$$</div>\n\n<ul>\n<li>采样定理两边是均方相等。</li>\n<li>当满足采样定理时，离散点包含全部信息，任意取值点可以恢复。</li>\n<li>频带边界点<ul>\n<li>当功率谱在 $\\pm \\omega_0$ 处有 $\\delta$ 函数时，以 $f_s &#x3D; 2f_0$ 无法恢复信号。</li>\n<li>例如：$X(t) &#x3D; \\cos(\\omega_0 t + \\phi)$，$\\phi$ 为随机相位，在$[0, 2\\pi]$内均匀分布。</li>\n<li>$R(\\tau) &#x3D; \\frac{1}{2}\\cos(\\omega_0\\tau)$</li>\n<li>$S(\\omega) &#x3D; \\delta(\\omega - \\omega_0) + \\delta(\\omega + \\omega_0)$</li>\n<li>采样点 $X(kT) &#x3D; (-1)^kX(0)$，与 $X(0)$ 严重相关。</li>\n</ul>\n</li>\n</ul>\n<p>欠采样</p>\n<div>$$\n\\begin{align*}\n    E \\lbrace |\\varepsilon(t)|^2 \\rbrace =& \\int_{\\omega_s/2}^{-\\omega_s/2}\\sum\\limits_{n=-\\infty}^{\\infty}|1 - e^{jn\\omega t}|S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n    =&\\sum\\limits_{n=-\\infty}^{\\infty}4\\sin^2(\\omega_snt/2) \\cdot \\int_{\\omega_s/2}^{-\\omega_s/2}S(\\omega + n\\omega_s)\\mathrm d\\omega\\\\\n\\end{align*}\\\\\n\n<p>上面的级数为积分的加权求和。 n &#x3D; 0 时权重为0，对应[-\\omega_s&#x2F;2, \\omega_s&#x2F;2] 内的功率谱。\\<br>n\\ne 0 时，权不为0，对应[-\\omega_s&#x2F;2, \\omega_s&#x2F;2]外的频谱，如果在这个区间外功率谱不是0，那 |\\varepsilon|^2 将大于0。</p>\n<p>$$</div></p>\n<h3 id=\"带通采样\"><a href=\"#带通采样\" class=\"headerlink\" title=\"带通采样\"></a>带通采样</h3><div>$$\nX(\\omega) = 0, |\\omega - \\omega_c| > \\omega_0, |\\omega + \\omega_c| > \\omega_0\n$$</div>\n\n<p>一般研究实信号 $g(t)$，频谱具有共轭对称性，只需要考虑正半轴的频带就可以了：</p>\n<div>$$\nG(-\\omega) = G^*(\\omega)\\\\\nA(\\omega) = A(-\\omega), \\varphi(-\\omega) = -\\varphi(\\omega)\n$$</div>\n\n<p>希尔伯特变换：</p>\n<div>$$\nH(\\omega) = \\begin{cases}\n    -j, \\omega \\gt 0,\\\\\n    0, \\omega = 0,\\\\\n    j, \\omega \\lt 0.\n\\end{cases}\n$$</div>\n\n<div>$$\n\\lbrace G(\\omega)H(\\omega) \\rbrace^* = G(-\\omega)H(-\\omega)\n$$</div>\n\n<p>希尔伯特把正频率移相 $-90\\degree$，负频率移相 $+90\\degree$</p>\n<p>时域表示：</p>\n<p>滤波器的时域响应为</p>\n<div>$$\n\\hat h(t) = \\frac{1}{\\pi t}\n$$</div>\n\n<p>g(t) 做两次希尔伯特变换，相位转了 $180\\degree$：</p>\n<div>$$\ng(t)\\xrightarrow{H(\\omega)}\\hat g(t) \\xrightarrow{H(\\omega)} -g(t)\n$$</div>\n\n<p>正交性：</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = 0\n$$</div>\n\n<p>看成$\\hat g(t)$ 与 $g(-t)$ 的卷积：</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}g(t)\\hat g(t)\\mathrm dt = \\int_{-\\infty}^{\\infty}g(- (u - t))\\hat g(t)\\mathrm dt|_{u = 0} = g(-t) * \\hat g(t) |_{t = 0}\\\\\ng(-t) \\rightarrow G^*(\\omega) = G(-\\omega), \\hat g(t) \\rightarrow G(\\omega)H(\\omega)\\\\\ng(-t) * \\hat g(t)|_{t = 0} = \\int_{-\\infty}^{\\infty}G^*(\\omega)G(\\omega)H(\\omega)e^{j\\omega t}\\mathrm d\\omega|_{t = 0} = 0\n$$</div>\n\n<p>希尔伯特变换与原信号相加得到单边的频谱：</p>\n<div>$$\ng(t) \\rightarrow A^* + A\\\\\nj\\hat g(t) \\rightarrow \\\\\ng(t) + j\\hat g(t) \\rightarrow 2A\\\\\n$$</div>\n\n<p>下变频：</p>\n<div>$$\n\\tilde{g}(t) = \\lbrace g(t) + j\\hat g(t) \\rbrace e^{-j\\omega_c t} = g_I(t) + jg_Q(t)\\\\\ng_I(t) = g(t) \\cos \\omega_c t + \\hat g(t) \\sin (\\omega_c t)\\\\\ng_Q(t) = - g(t) \\sin \\omega_c t + \\hat g(t) \\cos (\\omega_c t)\\\\\n$$</div>\n\n<p>实际上是一个旋转矩阵，把单边频信号 $\\tilde g(t)$ 顺时针旋转了 $\\omega_ct$变成了基带复信号。</p>\n<p>与原信号频谱的关系：</p>\n<div>$$\ng_I(t) \\rightarrow G(f - f_c) + G(f + f_c) \\\\\ng_Q(t) \\rightarrow G(f - f_c)(+j) + G(f + f_c)(-j)\\\\\n(f \\le |f_0|)\n$$</div>\n\n<p>调制和解调的流程</p>\n<ul>\n<li>调制：不需要得到 $\\hat g(t)$</li>\n<li>解调：通过低通滤波代替$\\hat g(t)$</li>\n</ul>\n<p>随机过程的希尔伯特变换</p>\n<p>$X(t)$为实的带通随机过程</p>\n<div>$$\nR_X(-\\tau) = E\\left \\lbrace  X(t - \\tau)X^*(t) \\right \\rbrace = E\\left \\lbrace  X(t)X^*(t + \\tau) \\right \\rbrace = E\\left \\lbrace  X(t + \\tau)X(t) \\right \\rbrace = R_X(\\tau)\\\\\nS_X(-\\omega) = \\int_{-\\infty}^{\\infty}R_X(\\tau)e^{-j(-\\omega) \\tau}\\mathrm d\\tau = \\int_{-\\infty}^{\\infty}R_X(-u)e^{-j\\omega\\tau}\\mathrm du = \\int_{-\\infty}^{\\infty}R_X(u)e^{-j\\omega\\tau}\\mathrm du = S_X(\\omega)\n$$</div>\n\n<p>通过希尔伯特滤波器后：</p>\n<div>$$\n\\hat X(t) = X(t) * h(t)\\\\\nR_{\\hat X}(\\tau) = R_X(\\tau) * h(t) * h^*(-t) = R_X(\\tau)\\\\\nS_{\\hat X}(\\omega) = S_X(\\omega)|H(\\omega)|^2 = S_X(\\omega)\n$$</div>\n\n<p>互相关：</p>\n<div>$$\n\\hat R_X(\\tau) = R_{\\hat XX}(\\tau) = E \\left \\lbrace \\int_{-\\infty}^{\\infty}X(t + \\tau - u)\\frac{1}{\\pi u}\\mathrm duX(t)   \\right\\rbrace = \\int_{-\\infty}^{\\infty}R_X(\\tau)\\frac{1}{\\pi u}\\mathrm du\n$$</div>\n\n<div>$$\nR_{X\\hat X}(\\tau) = -\\hat R_X(\\tau)\n$$</div>\n\n<p>因此</p>\n<div>$$\nY = X + j\\hat X\\\\\nR_Y(\\tau) = R_X(\\tau) + R_{\\hat X}(\\tau) + jR_{\\hat XX}(\\tau) - jR_{X\\hat X}(\\tau) = 2R_X(\\tau) + 2j\\hat R_X(\\tau)\\\\\nS_Y(f) = \\begin{cases}\n    4S_X(f), &f \\gt 0\\\\\n    0, &f\\lt 0\n\\end{cases}\n$$</div>\n\n<p>实的带通随机过程配合虚部的希尔伯特变换，同样也是只有正频率</p>\n<p>反之，如果功率谱只有正频率有值，则实部和虚部互为希尔伯特变换，实部和虚部的信息是重复的。</p>\n<p>随机信号的下变频：</p>\n<div>$$\n\\tilde{X}(t) = \\lbrace X(t) + j\\hat X(t) \\rbrace e^{-j\\omega_c t} = X_I(t) + jX_Q(t)\\\\\nX_I(t) = X(t) \\cos \\omega_c t + \\hat X(t) \\sin (\\omega_c t)\\\\\nX_Q(t) = - X(t) \\sin \\omega_c t + \\hat X(t) \\cos (\\omega_c t)\\\\\n$$</div>\n\n<p>同样是顺时针旋转了 $2\\pi f_c t$ 之后得到了基带信号</p>\n<p>研究基带信号的实部、虚部的统计特性</p>\n<p>$\\tilde{X}(t)$ 还是一个平稳过程</p>\n<div>$$\nE \\lbrace \\tilde{X}(t) \\rbrace = E \\lbrace X_I(t) \\rbrace = E \\lbrace X_Q(t) \\rbrace = 0\\\\\nR_{X_I}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_Q}(\\tau) = R_X(\\tau)\\cos(2\\pi f_c\\tau) + \\hat R_X(\\tau)\\sin(2\\pi f_c\\tau)\\\\\nR_{X_I}(\\tau) = R_{X_Q}(\\tau)\\\\\nR_{X_Q}(0) = R_{X_I}(0) = R_{X}(0)(三者方差一样)\\\\\n\\hat R_X(0) = 0(奇函数，不具备自相关函数的性质)\\\\\nS_{X_I}(f) = S_{X_Q}(f) = \\begin{cases}\n    S_X(f - f_c) + S_X(f + f_c), &|f| \\le f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>基带信号虚部和实部的互相关</p>\n<div>$$\nR_{X_IX_Q}(\\tau) = R_X(\\tau)\\sin(2\\pi f_c\\tau) - \\hat R_X(\\tau)\\cos (2\\pi f_c\\tau)，奇函数\n$$</div>\n\n<div>$$\nR_{X_IX_Q}(0) = 0\n$$</div>\n\n<p>因此同一时刻实部和虚部不相关。</p>\n<p>互谱密度</p>\n<div>$$\nS_{X_IX_Q}(f) = \\begin{cases}\n    jS_X(f + f_c) - jS_X(f - f_c), &|f| \\lt f_0,\\\\\n    0, &\\text{otherwise.}\n\\end{cases}\n$$</div>\n\n<p>只有当正频谱和负频谱分别跟 $f &#x3D; \\pm f_c$ 对称时，互谱密度恒为0。此时，任意两个时间的虚部和实部信号都是不相关的。</p>\n<h2 id=\"高斯过程\"><a href=\"#高斯过程\" class=\"headerlink\" title=\"高斯过程\"></a>高斯过程</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>随机向量$X &#x3D; (X(t_1), \\dots, X(t_n))^T$ 服从 $n$ 元高斯分布，称为高斯过程。</p>\n<p>均值 $\\mu_k$ &#x3D; $E \\lbrace X_k \\rbrace$</p>\n<p>协方差阵</p>\n<div>$$\n\\Sigma = E \\lbrace (X - \\mu)(X - \\mu)^T \\rbrace = \\begin{bmatrix}\n    b_{11}& \\dots &b_{1n}\\\\\n    \\vdots& \\ddots & \\vdots\\\\\n    b_{n1} & \\dots & b_{nn}\n\\end{bmatrix}\\\\\nb_{ij} = E \\lbrace (X_i - \\mu_i)(X_j - \\mu_j)^T \\rbrace\\\\\nb_{ij} = b_{ji}^* = b_{ji}\n$$</div>\n\n<p>做特征分解</p>\n<div>$$\n\\Sigma v_i = \\lambda_i v_i\\\\\nQ = (v_1, v_2, \\dots, v_n)正交阵, Q^{-1} = Q^T\\\\\n\\Sigma = Q\\text{diag}(\\lambda_1, \\dots, \\lambda_n)Q^T\\\\\n\\Sigma^{-1} = Q^T\\text{diag}(\\lambda_1^{-1}, \\dots, \\lambda_n^{-1})Q\n$$</div>\n\n<h3 id=\"多元高斯分布\"><a href=\"#多元高斯分布\" class=\"headerlink\" title=\"多元高斯分布\"></a>多元高斯分布</h3><div>$$\nf(x) = K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$</div>\n\n<p>线性变换以消去下标$ij$项：</p>\n<div>$$\n\\Sigma^{-1} = A^TA\\\\\ny = A(x - \\mu)\\\\\n(x - \\mu)\\Sigma^{-1}(x - \\mu)^T = y^Ty\n$$</div>\n\n<div>$$\n1 = K \\int \\dots \\int \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace \\mathrm dx_1 \\dots \\mathrm dx_n\\\\\nK = \\frac{1}{(\\sqrt{2\\pi})^n\\cdot \\sqrt{|\\Sigma|}}\n$$</div>\n\n<p>多元高斯矢量的特征函数</p>\n<div>$$\n\\omega = (\\omega_1, \\omega_2,\\dots, \\omega_n)^T\\\\\n\\Phi_X(\\omega) = E \\lbrace e^{j\\omega^TX} \\rbrace = E \\lbrace e^{j(\\omega_1 X_1 + \\omega_2 X_2 + \\dots + \\omega_n X_n)} \\rbrace = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T\\Sigma\\omega \\right \\rbrace\n$$</div>\n\n<p>特征函数不要求 $\\Sigma$ 可逆。概率密度函数要求 $\\Sigma$ 正定，特征值都大于0.</p>\n<p>当 $X$ 为高斯矢量时</p>\n<div>$$\n\\Phi_X(\\omega) = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)^T\\Sigma^{-1}(x - \\mu) \\right \\rbrace\\mathrm dx_1\\mathrm dx_2\\dots\\mathrm dx_n = \\int_{}^{}\\int_{}^{}\\dots\\int_{}^{} K \\cdot \\exp \\left \\lbrace  -\\frac{y^Ty}{2} \\right \\rbrace \\sqrt{|\\Sigma|}\n$$</div>\n\n<p>高斯白噪声的协方差矩阵只有对角元，对角元为方差。</p>\n<p>可以用逼近处理 $|\\Sigma| &#x3D; 0$：</p>\n<div>$$\n\\Sigma_K = \\Sigma + \\frac{1}{K}I\\\\\n\\Phi_X(\\omega) = \\exp \\left \\lbrace  j\\omega^T\\mu - \\frac{1}{2}\\omega^T \\left (\\Sigma + \\frac{1}{K}I  \\right)\\omega \\right \\rbrace\\\\\nf(x) = \\frac{1}{\\sqrt{2\\pi}^n \\sqrt{|\\Sigma_K|}} \\cdot \\exp \\left \\lbrace  -\\frac{1}{2}(x - \\mu)\\Sigma^{-1}(x - \\mu)^T \\right \\rbrace\n$$</div>\n\n<p>然后再讨论 $K \\rightarrow \\infty$ 的情况。</p>\n<p>多元高斯矢量的边缘分布</p>\n<p>任取子矢量 $\\lbrace K_1, K_2, \\dots, K_m \\rbrace \\subseteq {1, 2, \\dots, n}$</p>\n<p>观察 $\\tilde{ X} &#x3D; (X_{K_1}, X_{K_2}, \\dots, X_{K_m})^T$ 的分布</p>\n<div>$$\n\\tilde{\\Phi}(\\tilde\\omega) = E \\lbrace e^{j(\\omega_{K_1}\\tilde X_{K_1} + \\omega_{K_2}\\tilde X_{K_2} + \\dots + \\omega_{K_m}\\tilde X_{K_m})} \\rbrace = \\exp \\left \\lbrace  j\\tilde\\omega^T\\mu - \\frac{1}{2}\\tilde\\omega^T\\Sigma\\tilde\\omega \\right \\rbrace\n$$</div>\n\n<p>用置换矩阵 $P$ 将 $\\Sigma$ 的第 $K_1, K_2, \\dots, K_m$ 行、列移到 $\\Sigma$ 的左上角，对应的 $\\omega$ 也置换：</p>\n<div>$$\nP\\omega = \\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix}\\\\\nP^T\\Sigma P^T = \\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\n$$</div>\n\n<p>置换到左上角后，容易看出子矢量的特征函数可以通过将原矢量其他的$\\omega$置零得到，均值就是选择对应的均值，协方差矩阵就是把对应的行列元素抽出来：</p>\n<div>$$\n\\omega^T\\Sigma\\omega = (\\tilde{\\omega}, 0)^T\\begin{pmatrix}\n    \\tilde{\\Sigma} & B\\\\\n    C & D\n\\end{pmatrix}\\begin{pmatrix}\n    \\tilde{\\omega}\\\\\n    0\n\\end{pmatrix} = \\tilde{\\omega}^T\\tilde{\\Sigma}\\tilde{\\omega}\n$$</div>\n\n<p>利用特征函数求数字特征：</p>\n<div>$$\n\\frac{\\partial^2\\Phi}{\\partial \\omega_k\\partial \\omega_l}|_{\\omega_k = \\omega_l = 0} = -(\\mu_l\\mu_k + b_{kl})\\\\\nE \\lbrace X_kX_l \\rbrace = \\mu_l\\mu_k + b_{kl}\n$$</div>\n\n<div>$$\nE \\lbrace X_1^{k_1}\\dots X_n^{k_n} \\rbrace = j^{\\sum\\limits_{i=1}^{n}k_i} \\frac{\\partial^{k_1 + k_2 + \\dots k_n}}{\\partial^{k_1}\\omega_1\\partial^{k_2}\\omega_2\\dots \\partial^{k_n}\\omega_n}\\bigg|_{\\omega_1 = \\omega_2 = \\dots = \\omega_n = 0}\n$$</div>\n\n<p>高斯的矢量分布的高阶矩完全由一阶矩 $\\mu$ 和二阶矩 $\\Sigma$ 决定。例如可以用特征函数推出：</p>\n<div>$$\n\\begin{align*}\n    &E \\left \\lbrace  X_1X_2X_3X_4 \\right \\rbrace \\\\\n    =& j^4 \\frac{\\partial^4\\Phi}{\\partial \\omega_1\\partial \\omega_2\\partial \\omega_3\\partial \\omega_4}\\bigg|_{\\omega_1 = \\omega_2 = \\omega_3 = \\omega_4 = 0} \\\\\n    =& E \\left \\lbrace  X_1X_2  \\right \\rbrace E \\left \\lbrace  X_3X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_3  \\right \\rbrace E \\left \\lbrace  X_2X_4  \\right \\rbrace + E \\left \\lbrace  X_1X_4  \\right \\rbrace E \\left \\lbrace  X_2X_3  \\right \\rbrace\n\\end{align*}\n$$</div>\n\n<p>独立性</p>\n<p>独立性说的是统计，不相关说的是线性（二阶矩）</p>\n<p>一般来说</p>\n<div>$$\n独立 \\Rightarrow 不相关\\\\\n不相关 \\not \\Rightarrow 独立\n$$</div>\n\n<p>但是，对于高斯分布而言：</p>\n<div>$$\n独立 \\lrArr 不相关\n$$</div>\n\n<p>这是因为高斯分布完全由一阶和二阶矩决定。</p>\n<p>定理：</p>\n<p>$n$ 元向量 $X &#x3D; \\binom{X_1}{X_2}$ 服从 $N(\\mu, \\Sigma)$，则 $X_1, X_2$ 独立 $\\lrArr$ $\\Sigma_{12} &#x3D; 0$</p>\n<div>$$\n\\Sigma = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\n$$</div>\n\n<p>充分性：</p>\n<div>$$\n\\Sigma_{12} = E \\left \\lbrace (X_1 - \\mu_1)^T(X_2 - \\mu_2)  \\right \\rbrace = E \\left \\lbrace (X_1 - \\mu_1)\\right\\rbrace E\\left \\lbrace(X_2 - \\mu_2)  \\right \\rbrace = 0\n$$</div>\n\n<p>必要性：</p>\n<div>$$\nf(x_1, x_2) = \\frac{1}{(2\\pi)^{n/2}\\sqrt{|\\Sigma|}}\\exp \\left \\lbrace -\\frac{1}{2}\\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix}^T\\begin{pmatrix}\n    \\Sigma_{11}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix} \\begin{pmatrix}\n    x_1 - \\mu_1\\\\\n    x_2 - \\mu_2\n\\end{pmatrix} \\right  \\rbrace = f(x_1)f(x_2)\n$$</div>\n\n<p>可见 $X_1, X_2$ 统计独立。</p>\n<p>对于高斯过程：</p>\n<div>$$\n严平稳 \\lrArr 宽平稳\n$$</div>\n\n<p>即 $X(t_1), X(t_2), \\dots, X(t_n)$ 和 $X(t_1 + \\tau), X(t_2 + \\tau), \\dots, X(t_n + \\tau)$ 有相同的 $\\mu, \\Sigma$ 等价于具有相同的分布函数。</p>\n<p>线性变换</p>\n<p>定理： $X$ 服从高斯分布，矩阵 $C_{m\\times n}$， $Y &#x3D; CX$，则 $Y$ 服从高斯分布 $N \\left(C\\mu, C \\Sigma C^T \\right)$。</p>\n<p>高斯过程经过微分，积分，滤波等线性操作，输出还是高斯过程。</p>\n<p>有一种重要的线性变换：去相关。</p>\n<div>$$\n\\Sigma_X = \\begin{pmatrix}\n    \\Sigma_{11}&\\Sigma_{12}\\\\\n    \\Sigma_{21}&\\Sigma_{22}\n\\end{pmatrix}\\\\\nY = \\begin{pmatrix}\n    Y_1\\\\Y_2\n\\end{pmatrix}= \\begin{pmatrix}\n    I & A\\\\\n    0 & I\n\\end{pmatrix}\\begin{pmatrix}\n    X_1\\\\X_2\n\\end{pmatrix}\\\\\nE \\left \\lbrace  (Y_1 - E(Y_1))(Y_2 - E(Y_2))^T \\right \\rbrace = \\Sigma_{12} + A\\Sigma_{22 } = 0\n$$</div>\n\n<p>需要</p>\n<div>$$\n-\\Sigma_{12}\\Sigma_{22}^{-1} = A\\\\\n$$</div>\n\n<p>计算协方差</p>\n<div>$$\nE \\left \\lbrace  (Y - E(Y))(Y - E(Y))^T \\right \\rbrace = \\begin{pmatrix}\n    \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}&0\\\\\n    0&\\Sigma_{22}\n\\end{pmatrix}\n$$</div>\n\n<p>去相关之后方差减小了。可以认为 $X_1 &#x3D; Y_1 - AX_2$ 中，$- AX_2$是与 $Y$ “独立” 的“噪声项”，这个噪声导致了 $X_1$ 的方差大于去相关之后的 $Y$ 的方差。</p>\n<p>去相关与是否是高斯矢量无关。但是对于高斯矢量，去相关之后，两个矢量就独立了，具有重要的意义。</p>\n<p>对于一般的二阶矩过程，希望找到一个矩阵 $U$ ，使得 $Y &#x3D; UX$ 的各个分量不相关：</p>\n<div>$$\nE \\left \\lbrace  (Y - \\mu_Y)(Y - \\mu_Y)^T \\right \\rbrace = \\text{diag}\\\\\nE \\left \\lbrace  U(X - \\mu_X)(X - \\mu_X)^TU^T \\right \\rbrace  = \\text{diag} = U\\Sigma U^T\n$$</div>\n\n<p>所以，本质上就是分析了协方差矩阵 $\\Sigma$ 的特征值。也就是二阶矩章节讲到的主成分分析：</p>\n<div>$$\n\\text{diag}(\\lambda_1, \\dots, \\lambda_n)\n$$</div>\n\n<p>选取 $\\lambda_i$ 大的特征矢量，张成主成分空间。</p>\n<p>信号处理中有信号空间（特征值大的）和噪声空间（特征值小的，被噪声掩盖了）。</p>\n<p>有时候 $Y$ 的各个分量不相关还不能完全消去元素之间的统计关系。只是线性不相关。不相关的约束实际上很弱。</p>\n<p>如果要设计 $U$，使得 $Y &#x3D; UX$ 的各个分量独立，运算很复杂。</p>\n<p>但是，对于高斯矢量而言，不相关就是独立。所以对于高斯过程，主成分分析 $\\lrArr$ 独立成分分析。</p>\n<h3 id=\"高斯变量的条件分布\"><a href=\"#高斯变量的条件分布\" class=\"headerlink\" title=\"高斯变量的条件分布\"></a>高斯变量的条件分布</h3><p>仍是高斯：</p>\n<div>$$\nf_{X_1|X_2}(x_1|x_2) = \\frac{1}{\\sqrt{\\tilde{\\Sigma}_{11}}(2\\pi)^{\\frac{n_1}{2}}}\\exp \\left \\lbrace -\\frac{1}{2}(x_1 - \\tilde{\\mu}_1)^T\\tilde{\\Sigma}_{11}^{-1}(x_1 - \\tilde{\\mu}_1)   \\right\\rbrace\\\\\nE \\lbrace X_1 | X_2 \\rbrace = \\mu_1 + \\Sigma_{12}\\Sigma_{22}^{-1}(X_2 - \\mu_2)\\\\\nE \\lbrace (X_1 - E(X_1 | X_2))(X_1 - E(X_1|X_2))^T|X_2 \\rbrace = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}\n$$</div>\n\n<h3 id=\"实高斯过程的若干性质\"><a href=\"#实高斯过程的若干性质\" class=\"headerlink\" title=\"实高斯过程的若干性质\"></a>实高斯过程的若干性质</h3><p>实高斯过程完全由均值函数和协方差函数确定。</p>\n<p>严平稳等价于宽平稳。</p>\n<p>若实高斯过程均方可导，则 $\\lbrace X^\\prime(t) \\rbrace$ 也是高斯过程。</p>\n<p>高斯过程通过一般线性系统仍然是高斯过程。</p>\n<div>$$\nY(t) = \\int_{a}^{b}X(\\tau)h(t, \\tau)\\mathrm d\\tau\\\\\n更强的结论：\\left \\lbrace  \\binom{X(t)}{Y(t)} \\right \\rbrace 是高斯过程。\n$$</div>\n\n<h3 id=\"零均值带通高斯过程\"><a href=\"#零均值带通高斯过程\" class=\"headerlink\" title=\"零均值带通高斯过程\"></a>零均值带通高斯过程</h3><div>$$\nZ(t) = X(t) + j \\hat X(t)\\\\\nX_B(t) = X_I(t) + j X_Q(t)\\\\\nV(t) = \\sqrt{X_I^2(t) + X_Q^2(t)}\\\\\n\\Theta(t) = \\arctan \\frac{X_Q(t)}{X_I(t)}\\\\\n$$</div>\n\n<p>此时有</p>\n<div>$$\nX(t) = V(t)\\cos(\\omega_ct + \\Theta(t))\\\\\n\\binom{X_I(t)}{X_Q(t)} = \\binom{\\ \\ \\ \\cos(\\omega_ct)\\quad \\sin(\\omega_c t)}{-\\sin(\\omega_ct)\\quad \\cos(\\omega_ct)}\\binom{X(t)}{\\hat X(t)}\n$$</div>\n\n<p>幅度为瑞利分布，相位为均匀分布，相互统计独立：</p>\n<div>$$\nf_V(v) = \\frac{v}{\\sigma^2}e^{-\\frac{v^2}{2\\sigma^2}}, v \\ge 0\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}, \\theta \\in [0, 2\\pi]\n$$</div>\n\n<h3 id=\"随机相位正弦波信号叠加零均值带通高斯\"><a href=\"#随机相位正弦波信号叠加零均值带通高斯\" class=\"headerlink\" title=\"随机相位正弦波信号叠加零均值带通高斯\"></a>随机相位正弦波信号叠加零均值带通高斯</h3><div>$$\nY(t) = A\\sin(\\omega_ct + \\Phi) + X(t)\n$$</div>\n\n<p>结果是幅度为莱斯分布，相位均匀分布，二者统计独立：</p>\n<div>$$\nf_{V(t)}(v) = \\frac{v}{\\sigma^2}\\exp(-\\frac{v^2 + A^2}{2\\sigma^2})I_0(\\frac{Av}{\\sigma^2})\\\\\nf_\\Theta(\\theta) = \\frac{1}{2\\pi}\n$$</div>\n\n<h3 id=\"高斯过程经过非线性函数\"><a href=\"#高斯过程经过非线性函数\" class=\"headerlink\" title=\"高斯过程经过非线性函数\"></a>高斯过程经过非线性函数</h3><p>限幅器</p>\n<div>$$\nh(x) = \\begin{cases}\n    1, x\\ge 0,\\\\\n    0, x \\lt 0\n\\end{cases}\n$$</div>\n\n<p>服从两点分布</p>\n<div>$$\nP(Y(t) = 1) = P(Y(t) = 0) = \\frac{1}{2}\\\\\nE_Y(t) = 0\\\\\nR_Y(t, s) = P \\lbrace X(t)X(s) \\ge 0 \\rbrace - P \\lbrace X(t)X(s) \\lt 0 \\rbrace\n$$</div>\n\n<div>$$\nP \\lbrace X(t)X(s) \\ge 0 \\rbrace = \\int_{0}^{\\infty}\\int_{0}^{\\infty}\\frac{1}{2\\pi\\sqrt{|\\Sigma|^{-1}}}\\exp((x_1\\ x_2)\\Sigma^{-1}\\binom{x_1}{x_2})\\mathrm dx_2\\mathrm dx_1 = \\frac{\\pi/2 + \\sin^{-1}(-\\rho)}{2\\pi}\n$$</div>\n\n<p>全线性检波（求绝对值）</p>\n<div>$$\nE(Y) = \\frac{2\\sigma}{2\\pi}\\int_{0}^{\\infty}\\frac{y}{\\sigma^2}\\exp(-\\frac{y^2}{2\\sigma^2})\\mathrm dy = \\sqrt{\\frac{2}{\\pi}}\\sigma\\\\\nR_Y(t, s) E \\lbrace |X(t)||X(s)| \\rbrace = \\frac{2\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace, \\rho = \\frac{R_X(t - s)}{\\sigma^2}\\\\\n\\int_{0}^{\\infty}\\int_{0}^{\\infty}x_1x_2\\frac{1}{2\\pi\\sigma^2\\sqrt{1 - \\rho^2}}\\exp(-\\frac{x_1^2 - 2\\rho x_1x_2 + x_2^2}{2\\sigma(1 - \\rho^2)})\\mathrm dx_1\\mathrm dx_2\n$$</div>\n\n<p>半波线性检波</p>\n<div>$$\nh(x) = \\begin{cases}\n    x, x\\ge 0,\\\\\n    0, x\\lt 0\n\\end{cases}\n$$</div>\n\n<div>$$\nR_Y(t, s) = \\frac{\\sigma^2}{\\pi} \\lbrace \\sqrt{1 - \\rho^2} + \\rho\\sin^{-1}\\rho \\rbrace\\\\\n$$</div>\n\n<p>平方率检波</p>\n<div>$$\nh(x) = x^2\n$$</div>\n\n<div>$$\nP(Y(t) \\le y) = P(-\\sqrt{y} \\le Y(t) \\le \\sqrt{y}) = 2\\Phi(\\frac{\\sqrt{y}}{\\sigma}) - 1\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\frac{1}{\\sqrt{y}}\\exp \\lbrace -\\frac{y}{2\\sigma^2} \\rbrace,\\ (y \\gt 0)\\\\\nE \\lbrace Y(t) \\rbrace = \\sigma^2\\\\\nR_Y(t,s) = E \\lbrace X^2(t_1)X^2(t_2) \\rbrace = \\sigma^2 + \\sigma^2 + \\rho\\sigma^2 + \\rho\\sigma^2 = 2(\\rho + 1)\\sigma^2\n$$</div>\n\n<p>基带信号的包络经过平方律检波</p>\n<div>$$\nX_I^2 + X_Q^2 = V^2 服从复指数分布\n$$</div>\n\n<h3 id=\"高斯——马尔可夫性\"><a href=\"#高斯——马尔可夫性\" class=\"headerlink\" title=\"高斯——马尔可夫性\"></a>高斯——马尔可夫性</h3><p>马尔可夫特性：</p>\n<div>$$\nf(x_n|x_1, \\dots, x_{n - 1}) = f(x_n|x_{n - 1})\n$$</div>\n\n<p>如果一个过程既是高斯的，又是马尔可夫的，会有很好的性质。</p>\n<p>对于零均值高斯分布：</p>\n<div>$$\nX(t) 是 \\text{Markov} \\lrArr R(t_1, t_3) = \\frac{R(t_1, t_2)R(t_2, t_3)}{R(t_2, t_2)}\n$$</div>\n\n<p>正向很好证明，反向证明的关键是计算均值和方差。</p>\n<div>$$\nX(t) 是 \\text{Markov} \\lrArr \\forall t_1\\le t_2\\le...\\le t_n, E \\lbrace X_n|X_1, X_2, \\dots, X_{n - 1} \\rbrace = E \\lbrace X_n|X_{n - 1} \\rbrace\n$$</div>\n\n<p>从右到左：条件协方差 $E\\lbrace (Y_1 - E \\lbrace Y_1|Y_2 \\rbrace)^2|Y_2\\rbrace &#x3D; \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}$ 跟 $Y_2$ 无关（这并不是说条件协方差和协方差具有相同的意义，只是数值上正好相等）</p>\n<div>$$\nE(X_n|X_{n - 1}) = \\frac{E(X_nX_{n - 1})}{E(X_{n - 1}^2)}X_{n - 1}\\\\\n$$</div>\n\n<p>残差与已有信息正交：</p>\n<div>$$\nE \\lbrace [X_n - E(X_n | X_{n - 1})] \\cdot X_k \\rbrace = 0, k = 1, 2, \\dots, n - 1\\\\\n$$</div>\n\n<p>类似于最小二乘估计：</p>\n<div>$$\nX_n - \\alpha_n X_{n - 1} 是一个高斯过程，与 X_1, X_2, \\dots, X_n 独立\n$$</div>\n\n<p>自回归方程：</p>\n<div>$$\nX_n = \\alpha_n X_{n - 1} + \\beta_nY_n\\\\\nY_n \\sim N(0, 1)\n$$</div>\n\n<h3 id=\"Brown-运动\"><a href=\"#Brown-运动\" class=\"headerlink\" title=\"Brown 运动\"></a>Brown 运动</h3><p>从一维随机游走开始：</p>\n<div>$$\nP \\lbrace X_i = a \\rbrace = P \\lbrace X_i = -a \\rbrace = \\frac{1}{2}\\\\\nY =\\sum\\limits_{i=1}^{\\infty}X_i\n$$</div>\n\n<p>令 $t &#x3D; nT$，固定 $t$，令 $n \\rightarrow \\infty$，由 CLT 可知成为一个高斯分布：</p>\n<div>$$\nE(Y) = 0\\\\\nD(Y) = \\frac{t}{T}a^2\\\\\n\\frac{a^2}{T} = \\beta\\\\\nf_Y(y) = \\frac{1}{\\sqrt{2\\pi}\\sqrt{\\beta t}}\\exp (-\\frac{y^2}{2\\beta t})\n$$</div>\n\n<p>随着时间增加，不确定性越来越大。</p>\n<p>标准布朗运动：</p>\n<p>（1）$B(t)$ 满足独立增量，平稳增量<br>（2）$B(t)$ 的每个样本轨道都是连续的<br>（3）$\\forall t, B(t)$ 遵循高斯分布，均值0，方差 $t$</p>\n<div>$$\nf_t(x) = \\frac{1}{\\sqrt{2\\pi t}}\\exp (-\\frac{x^2}{2t})\n$$</div>\n\n<p>布朗运动是高斯白噪声的积分：</p>\n<div>$$\nY(t) = \\int_{0}^{t}X(u)\\mathrm du\n$$</div>\n\n<p>可见布朗运动的不规则。</p>\n<h2 id=\"Markov-过程\"><a href=\"#Markov-过程\" class=\"headerlink\" title=\"Markov 过程\"></a>Markov 过程</h2><h3 id=\"Markov-链\"><a href=\"#Markov-链\" class=\"headerlink\" title=\"Markov 链\"></a>Markov 链</h3><p>一种状态离散、时间离散的随机过程。</p>\n<h3 id=\"Markov-特性\"><a href=\"#Markov-特性\" class=\"headerlink\" title=\"Markov 特性\"></a>Markov 特性</h3><p>马尔可夫特性的一种表示：</p>\n<p>在已知现在的条件下，过去与将来独立。</p>\n<div>$$\nP(C,A | B) = P(C | B, A) \\cdot P(A|B) = P(C|B)P(A|B)\n$$</div>\n\n<p>其他表示：过去用集合事件表示</p>\n<div>$$\nP \\lbrace X_{n+1}=j|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}=j|X_n=i \\rbrace\n$$</div>\n\n<p>进一步，过去是一个集合，未来也是一个集合：</p>\n<div>$$\nP \\lbrace X_{n+1}\\in B|(X_{n-1}, \\dots, X_1)\\in A, X_n=i \\rbrace = P \\lbrace X_{n+1}\\in B|X_n=i \\rbrace\n$$</div>\n\n<p>但是，变量“现在”必须取值为一个确定的值，不能是一个集合。对现在的状态一定要精确掌握，不能放宽约束。</p>\n<p>口号：从小事做起（泊松），从现在做起（马尔可夫）</p>\n<p>转移概率</p>\n<div>$$\nP_{ij}(m, n) = P \\lbrace X_n = a_j | X_m = a_i \\rbrace\n$$</div>\n\n<div>$$\nP_{ij}(m, n) \\ge 0\\\\\n\\sum\\limits_{j}^{}P_{ij}(m, n) = 1\n$$</div>\n\n<p>一步转移概率：</p>\n<div>$$\nP_{ij}(m, m + 1) 或 P_{ij}(m)\n$$</div>\n\n<p>状态转移矩阵</p>\n<p>观察变量族的联合分布</p>\n<h3 id=\"齐次马尔科夫链的迭代表示\"><a href=\"#齐次马尔科夫链的迭代表示\" class=\"headerlink\" title=\"齐次马尔科夫链的迭代表示\"></a>齐次马尔科夫链的迭代表示</h3><div>$$\nX_0 \\xrightarrow{Z_1} X_1 \\xrightarrow{Z_2} X_2 \\dots \\xrightarrow{Z_n} X_{n}\n$$</div>\n\n<div>$$\nX_{n+1} = f(X_n,Z_{n+1}) = P \\lbrace X_{n+1} = j | X_n = i \\rbrace\n$$</div>\n\n<p>也称为新息过程</p>\n<h3 id=\"一维随机游走\"><a href=\"#一维随机游走\" class=\"headerlink\" title=\"一维随机游走\"></a>一维随机游走</h3><p>吸收壁</p>\n<p>反射壁 - 完全反射壁</p>\n<p>成功逃跑</p>\n<p>等待服务人数</p>\n<div>$$\nX_{n + 1} = \\begin{cases}\n    X_n - 1 + Y_{n + 1}, X_n \\ne 0\\\\\n    Y_{n + 1}, X_0\n\\end{cases}\\\\\nP = \\begin{bmatrix}\n    a_0 & a_1 & a_2 & \\dots\\\\\n    a_0 & a_1 & a_2 & \\dots\\\\\n        & a_0 & a_1 & \\dots\\\\\n        &     & a_0 & \\dotsb\n\\end{bmatrix}\n$$</div>\n\n<h3 id=\"柯尔莫格洛夫方程\"><a href=\"#柯尔莫格洛夫方程\" class=\"headerlink\" title=\"柯尔莫格洛夫方程\"></a>柯尔莫格洛夫方程</h3><p>多步转移矩阵概率</p>\n<div>$$\nP_{ij}(m, n) = \\sum_k P(X_n = j | X_r = k) \\cdot P(X_r = k | X_m = i)\n$$</div>\n\n<p>或者表示为</p>\n<div>$$\nP_{ij}^{(p + q)} = \\sum_{k \\in \\Omega} P_{ik}^{(p)} P_{kj}^{(q)}\n$$</div>\n\n<p>由于上面转移阵步数 $p, q$ 的任意性，多步跳变矩阵可以转变为矩阵相乘：</p>\n<div>$$\nP^{(L)} = P^{(L - 1)}P^{(1)} = ... = P^L\n$$</div>\n\n<p>求多步转移矩阵：适用于齐次马尔可夫</p>\n<p>齐次马尔可夫链的 $P$ 与时间起点无关</p>\n<p>先求 $P^{(n)} &#x3D; P^n$，再看 $[P^n]_{ij}$ 就是要求的转移概率。</p>\n<p>如何求 $P^n$ ？</p>\n<p>首先做特征分解 $PU &#x3D; U\\Lambda$</p>\n<div>$$\nP^n = U \\Lambda^nU^{-1}\n$$</div>\n\n<p>二元通信信道</p>\n<div>$$\nP  = \\begin{pmatrix}\n    1 - \\alpha & \\alpha\\\\\n    \\beta & 1 - \\beta\n\\end{pmatrix}\\\\\nU = \\begin{pmatrix}\n    1 & -\\alpha\\\\\n    1 & \\beta\n\\end{pmatrix}\n$$</div>\n\n\n<div>$$\nP^n = \\frac{(1 - \\alpha - \\beta)^n}{\\alpha + \\beta}\\begin{pmatrix}\n    \\alpha & -\\alpha\\\\\n    -\\beta & \\beta\n\\end{pmatrix} + \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$</div>\n\n<p>在 $|1 - \\alpha - \\beta| &lt; 1$ 的条件下，无穷步跳变后：</p>\n<div>$$\nP^n = \\frac{1}{\\alpha + \\beta} \\begin{pmatrix}\n    \\beta & \\alpha\\\\\n    \\beta & \\alpha\n\\end{pmatrix}\n$$</div>\n\n<p>各列相等，说明这个马尔可夫链与初始状态无关，历史被淡忘——马尔可夫性。</p>\n<p>$1 - \\alpha - \\beta &#x3D; -1$ 时，极限不存在</p>\n<div>$$\nP = \\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\\\\\n\\end{pmatrix}\n$$</div>\n\n<h3 id=\"状态分类\"><a href=\"#状态分类\" class=\"headerlink\" title=\"状态分类\"></a>状态分类</h3><p>可达性：$\\exists m, s.t. P_{ij}^{(m)} &gt; 0$</p>\n<p>互通性：$\\exist m, n, s.t. P_{ij}^{(m)} &gt; 0, P_{ji}^{(n)} &gt; 0$，是等价关系。</p>\n<p>不可约(irreducible)，不可分</p>\n<p>马尔可夫链中每两个状态都是互通的，也叫互通链。</p>\n<p>闭集：$\\forall i \\in C, j\\not \\in C, i \\not \\rightarrow j$</p>\n<p>不可约的另一定义：除了把整个链作为闭集，不存在取其中一些状态构成其他闭集了。</p>\n<p>激励状态</p>\n<p>稳定状态（闭集）</p>\n<p>一般情况，Markov 链的转移矩阵行列重排后可化为：</p>\n<div>$$\nP = \\begin{pmatrix}\n    u_1\\\\\n    &u_2\\\\\n    &&\\ddots\\\\\n    &&&u_k\\\\\n    v_1&v_2&\\dots&v_k&v_{k+1}\n\\end{pmatrix}\n$$</div>\n\n<p>对闭集而言，可以在闭集内使用柯尔莫格洛夫方程：</p>\n<div>$$\nP_{ij}^{(n + m)} =\\sum\\limits_{r\\in \\Omega_1}^{}P_{ir}^{(n)}P_{rj}^{(m)}\n$$</div>\n\n<p>首次达到时间：$T_{ij}(\\omega) &#x3D; \\min \\lbrace n: X_0(\\omega) &#x3D; i, X_n(\\omega) &#x3D; j, n \\ge 1 \\rbrace$</p>\n<div>$$\nT_{ij} \\in [1, 2, ..., \\infty)\n$$</div>\n\n<p>首次到达概率</p>\n<div>$$\nf_{ij}^{(n)} = P \\lbrace T_{ij} = n| X_0 = i \\rbrace\n$$</div>\n\n<p>此时有</p>\n<div>$$\nf_{ij}^{(1)} = P_{ij}\n$$</div>\n\n<p>定义</p>\n<div>$$\nf_{ij} =\\sum\\limits_{k=1}^{\\infty^-} f_{ij}^{(k)}\n$$</div>\n\n<p>为迟早到达的概率。</p>\n<div>$$\nf_{ij}^{(\\infty)} = 1 - f_{ij}\n$$</div>\n\n<p>表示永远无法到达的概率。</p>\n<p>定理：</p>\n<div>$$\nP_{ij}^{(n)} =\\sum\\limits_{r=1}^{n} f_{ij}^{(r)}P_{jj}^{(n - r)}\n$$</div>\n\n<p>考虑 $P_{ij}^{(0)} &#x3D; \\delta_{ij}$，上述可以写成卷积形式：</p>\n<div>$$\nF_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^r\\\\\nG_{ij}(z) = \\sum\\limits_{r=0}^{\\infty} f_{ij}^{(r)}z^{r}\\\\\nG_{ij}(z) = \\delta_{ij} + F_{ij}(z)G_{jj}(z)\n$$</div>\n\n<div>$$\ni \\rightarrow j \\lrArr  f_{ij} \\gt 0\n$$</div>\n\n<h3 id=\"常返性\"><a href=\"#常返性\" class=\"headerlink\" title=\"常返性\"></a>常返性</h3><h4 id=\"常返与非常返\"><a href=\"#常返与非常返\" class=\"headerlink\" title=\"常返与非常返\"></a>常返与非常返</h4><p>若 $f_{ij} &#x3D; 1$，称状态 i 为常返态</p>\n<p>令 $z &#x3D; 1$：</p>\n<div>$$\nG_{ij}(1) = \\delta_{ij} + F_{ij}(1)G_{jj}(1)\\\\\ni = j \\rArr G_{ii}(1) = \\frac{1}{1 - F_{ii}(1)} \\rArr \\sum_{n = 0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}}\n$$</div>\n\n<p>常返性判别：</p>\n<div>$$\n常返态 \\lrArr f_{ii} = 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = +\\infty\\\\\n非常返态 \\lrArr f_{ii} \\lt 1 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{ii}^{(n)} = \\frac{1}{1 - f_{ii}} < +\\infty\\\\\n$$</div>\n\n<p>后面会证明，这种返回的次数都是无穷大。</p>\n<p>常返的理解：</p>\n<div>$$\n\\forall n, A_n = \\begin{cases}\n    A_n = 1, X_n = i,\\\\\n    A_n = 0, X_n \\ne i.\n\\end{cases}\n$$</div>\n\n<div>$$\nE \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k | X_0 = i \\rbrace = \\sum\\limits_{k=0}^{\\infty}P_{ii}^{(0)}\\\\\n$$</div>\n\n<p>从判别定理可以看出，在期望意义上，常返态被无限次访问。</p>\n<p>推论1：既然常返态被无穷次返回，非常返态被有限次访问，则在有限状态的 Markov 链中一定存在常返态。</p>\n<p>反证法：如果全是有限返回次数，那所有态的访问次数加起来还是有限的，但是马尔可夫可以访问无限次，矛盾。所以一定有常返态。</p>\n<p>推论1.1：如果非常返态的个数有限，则足够长的时间后，状态一定会到达常返态。</p>\n<p>推论1.2：若 j 非常返，则$\\forall i$</p>\n<div>$$\n\\sum\\limits_{n=0}^{\\infty}P_{ij}^{(n)} < \\infty (i 到达 j的次数为有限值)\\\\\n\\lim_{n \\rightarrow \\infty} P_{ij}^{(n)} = 0\n$$</div>\n\n<p>推论2：若 $i$ 常返，$i \\lrarr j$，则 $j$ 也是常返的。</p>\n<p>推论3：若 $i$ 为常返，$i \\rarr j$，则 $j \\rarr i$</p>\n<h4 id=\"正常返与零常返\"><a href=\"#正常返与零常返\" class=\"headerlink\" title=\"正常返与零常返\"></a>正常返与零常返</h4><p>$f_{ii}^n$ 可以视为首次返回时间 $T_{ii}$ 的概率分布。对于非常返态不能这么看，因为 $f_{ii} &lt; 1$。</p>\n<p>对于常返态的 $T_{ii}$，可以计算期望</p>\n<div>$$\n\\mu_i = E \\lbrace T_{ii} \\rbrace = \\sum\\limits_{n = 1}^{\\infty} n f_{ii}^{(n)}\n$$</div>\n\n<p>若均值为无穷大，则称为零常返。</p>\n<p>零常返与非常返是有区别的。零常返是可以常返，只是大概率步数很多。</p>\n<p>定义返回的速率，可推导</p>\n<div>$$\n\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\sum\\limits_ {k=0}^{n - 1} P_{jj}^{(k)} = \\frac{1}{\\mu_j}\n$$</div>\n\n<p>正常返意味着速率为常数，零常返意味着速率为 0。</p>\n<p>判定定理：</p>\n<div>$$\nj 状态零常返 \\lrArr \\sum\\limits_{n=0}^{\\infty}P_{jj}^{(n)} = \\infty, 且 n \\rightarrow \\infty 时，P_{jj}^{(n)} = 0\n$$</div>\n\n<p>条件一就是常返的判定定理。条件二比较特殊：</p>\n<div>$$\n\\lim_{n \\rightarrow \\infty}P_{jj}^{(n)} = \\frac{1}{\\mu_j}\n$$</div>\n\n<p>如果是零常返，这个极限就是0。在条件二上，零常返和非常返是一样的。</p>\n<p>定理：常返态 $i$，$i \\rarr j$，则 $i, j$ 同为正常返或者零常返</p>\n<h4 id=\"补充性质\"><a href=\"#补充性质\" class=\"headerlink\" title=\"补充性质\"></a>补充性质</h4><div>$$\nq_{jj}(M) = P \\lbrace \\sum\\limits_{k=0}^{\\infty}A_k \\ge M | X_0 = j \\rbrace\\\\\n\\lim_{M \\rarr \\infty}q_{jj}(M) = \\begin{cases}\n    1, f_{jj} = 1\\\\\n    0, f_{jj} < 1\\\\\n\\end{cases}\n$$</div>\n\n<p>下面研究常返态 $j$，不可约链</p>\n<p>“从常返态触发，返回次数为无穷大”这件事的概率为 1.</p>\n<div>$$\n\\lim_{M \\rarr \\infty} q_{rj}(M) = 1, \\forall\n$$</div>\n\n<p>“任意状态访问常返态的次数为无穷大”的概率为1.</p>\n<div>$$\nq_{ij}(M) = f_{ij}q_{jj}(M)\n$$</div>\n\n<p>两边取极限可得 $f_{ij} &#x3D; 1$</p>\n<p>结论3： 从不可约链任何状态出发，迟早访问状态 $j$</p>\n<div>$$\n\\lim_{n \\rarr \\infty} P_{ij}^{(n)} = \\frac{1}{\\mu_j}\n$$</div>\n\n<p>结论4：极限概率与初始状态无关。</p>\n<p>分类方式</p>\n<p>对于每个常返态 i，存在一个 i 可达状态构成的状态集 C 。则这些状态彼此相通，构成一个不可约闭集，都常返</p>\n<p>马尔可夫链可以唯一划分为 $C_1, C_2, …, T$，其中 $C_i$ 互为不相交的不可约闭集。T 为非常返态。每个闭集中，常返类型一致，不同闭集不互通。</p>\n<p>定理：马尔科夫链若有一个零常返，有无穷多个零常返。</p>\n<p>推论：有限状态马尔可夫链的常返态必然为正常返。</p>\n<h4 id=\"马尔可夫链的平稳分布和极限概率\"><a href=\"#马尔可夫链的平稳分布和极限概率\" class=\"headerlink\" title=\"马尔可夫链的平稳分布和极限概率\"></a>马尔可夫链的平稳分布和极限概率</h4><p>对于不可约链：</p>\n<div>$$\n\\lim_{n \\rarr \\infty}P_{ij}^{(n)} = 0，j非常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j} = 0，j零常返\\\\\nP_{ij}^{(n)} = \\frac{1}{\\mu_j}，j正常返\n$$</div>\n\n<p>极限概率用 $\\pi_j$表示</p>\n<p>对于非常返和零常返，极限概率都是0。零常返的链一定有无穷个状态。</p>\n<p>对于正常返，$\\pi_j \\gt 0, \\sum\\limits_{j\\in S}^{}\\pi_j &#x3D; 1$</p>\n<p>从柯式方程得出：</p>\n<div>$$\n\\pi_j = \\sum\\limits_{i}^{}\\pi_iP_{ij}\n$$</div>\n\n<p>矩阵形式：</p>\n<div>$$\n\\lim_{n \\rarr \\infty} P^n = \\Pi = \\begin{bmatrix}\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\pi_1 & \\pi_2 & \\cdots & \\pi_n & \\cdots\\\\\n    \\cdots & \\cdots & \\cdots & \\cdots & \\cdots\\\\\n\\end{bmatrix}\n$$</div>\n\n\n<h2 id=\"泊松过程\"><a href=\"#泊松过程\" class=\"headerlink\" title=\"泊松过程\"></a>泊松过程</h2><h3 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h3><h4 id=\"计数过程\"><a href=\"#计数过程\" class=\"headerlink\" title=\"计数过程\"></a>计数过程</h4><p>在 $[0, t]$ 内发生某类事件的次数记为 $\\lbrace N(t), t\\ge 0 \\rbrace$，则称 $\\lbrace N(t) \\rbrace$ 为计数过程。</p>\n<h4 id=\"泊松过程-1\"><a href=\"#泊松过程-1\" class=\"headerlink\" title=\"泊松过程\"></a>泊松过程</h4><p>若满足以下条件：</p>\n<ol>\n<li>$N(0) &#x3D; 0$</li>\n<li>非负性：$N(t)$ 的取值非负整数；</li>\n<li>非降性：$N(t)$ 是随时间单调不减的；</li>\n<li>独立增量性：对于 $0 \\le t_1 &lt; t_2 &lt; \\ldots &lt; t_n$，$N(t_2) - N(t_1), N(t_3) - N(t_2), \\ldots, N(t_n) - N(t_{n-1})$ 是相互独立的随机变量；</li>\n<li>平稳增量性：对于 $0 \\le s &lt; t$，$N(t) - N(s)$ 的分布只与时间间隔 $t-s$ 有关，而与具体的时刻 $s$ 无关。</li>\n<li>$P(N(t + \\Delta t) - N(t) &#x3D; 1) &#x3D; \\lambda\\Delta t + o(\\Delta t), P(N(t + \\Delta t) - N(t) \\ge 2) &#x3D; o(\\Delta t)$<br>则称 $\\lbrace N(t), t\\ge 0 \\rbrace$ 为泊松过程。</li>\n</ol>\n<h3 id=\"性质\"><a href=\"#性质\" class=\"headerlink\" title=\"性质\"></a>性质</h3><p>泊松的表达式</p>\n<div>$$\nP_n(t) = P(N(t) = n) = \\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}\n$$</div>\n\n<p>泊松分布的特征函数</p>\n<div>$$\n\\phi_{N(t)}(\\omega) = \\exp \\left \\lbrace \\lambda t (e^{j\\omega} - 1) \\right \\rbrace\n$$</div>\n\n<p>泊松过程的数字特征</p>\n<div>$$\nE(N(t)) = \\lambda t\\\\\nR(t_1, t_2) = \\lambda t_1 + \\lambda^2 (t_1t_2) (t_1 \\le t_2)\\\\\nC(t_1, t_2) = \\min \\lbrace t_1, t_2 \\rbrace\n$$</div>\n\n<h3 id=\"泊松与二项分布\"><a href=\"#泊松与二项分布\" class=\"headerlink\" title=\"泊松与二项分布\"></a>泊松与二项分布</h3><p>泊松分布是二项分布的极限。</p>\n<p>泊松脉冲串：</p>\n<div>$$\nX(t) = \\frac{\\mathrm dN(t)}{\\mathrm dt} = \\sum\\limits_{i}^{}\\delta(t - t_i)\\\\\nE(X(t)) = \\lambda\n$$</div>\n\n<h3 id=\"泊松相关问题\"><a href=\"#泊松相关问题\" class=\"headerlink\" title=\"泊松相关问题\"></a>泊松相关问题</h3><h4 id=\"事件间隔时间的分布\"><a href=\"#事件间隔时间的分布\" class=\"headerlink\" title=\"事件间隔时间的分布\"></a>事件间隔时间的分布</h4><p>$S_n$ 表示第 n 件事到达的时刻</p>\n<p>$T_n$ 表示相邻两件事发生的间隔</p>\n<div>$$\nP\\lbrace S_n \\gt t \\rbrace = P \\lbrace N(t) \\le n - 1 \\rbrace\n$$</div>\n\n<div>$$\nf_{T_n}(t) = \\lambda e^{-\\lambda t}\\\\\nE(T_n) = 1 / \\lambda\n$$</div>\n\n<p>$T_n$ 和 $T_m$ 是独立的。</p>\n<h4 id=\"等待时间的分布\"><a href=\"#等待时间的分布\" class=\"headerlink\" title=\"等待时间的分布\"></a>等待时间的分布</h4><p>概率密度函数与特征函数互为傅里叶变换</p>\n<div>$$\n\\Phi_{T_i}(\\omega) = \\frac{\\lambda}{\\lambda - j\\omega}\\\\\n\\Phi_{S_n}(\\omega) = \\left (\\frac{\\lambda}{\\lambda - j\\omega}  \\right)^n\\\\\n$$</div>\n\n<p>要求 $S_n$ 的概率密度函数，可以看作 $T_n$ 的卷积：</p>\n<div>$$\nf_{S_n}(t) = \\frac{(\\lambda t)^{n - 1}}{(n - 1)!}\\lambda e^{-\\lambda t}\\\\\n$$</div>\n\n<p>称为 $\\Gamma$ 分布，参数 $\\lambda, n$。</p>\n<h4 id=\"相邻两次事件之间的计数\"><a href=\"#相邻两次事件之间的计数\" class=\"headerlink\" title=\"相邻两次事件之间的计数\"></a>相邻两次事件之间的计数</h4><p>两次公交车到来（速度 $\\mu$）之间，等车人数（速度 $\\lambda$）的计数：</p>\n<div>$$\nP(L = k) = (\\frac{\\mu}{\\mu + \\lambda})(\\frac{\\lambda}{\\mu + \\lambda})^k\n$$</div>\n\n<h4 id=\"n个事件到达时间的的联合分布\"><a href=\"#n个事件到达时间的的联合分布\" class=\"headerlink\" title=\"n个事件到达时间的的联合分布\"></a>n个事件到达时间的的联合分布</h4><div>$$\nf_{S_1...S_n|N(t) = n}(u_1, u_2, ..., u_n) = \\frac{n!}{t^n}\n$$</div>\n\n<p>如果是有编号的（不是按顺序到达）：</p>\n<div>$$\nf_{V_1...V_n|N(t) = n}(t_1, t_2, ..., t_n) = \\frac{1}{t^n}\n$$</div>\n\n<p>以下分布的极限，就是泊松过程：</p>\n<div>$$\nP \\lbrace N(s) = k | N(t) = n \\rbrace = \\binom{n}{k}(\\frac{\\lambda s}{n})^k(1 - \\frac{\\lambda s}{n})^{n - k}\n$$</div>\n\n<h4 id=\"总结泊松过程的几种定义\"><a href=\"#总结泊松过程的几种定义\" class=\"headerlink\" title=\"总结泊松过程的几种定义\"></a>总结泊松过程的几种定义</h4><ol>\n<li>N(0) &#x3D; 0，独立增量，平稳增量，$\\Delta t$ 内发生一个事件的概率 $\\lambda \\Delta t$，发生两件事以上的概率小</li>\n<li>事件时间间隔独立同分布，服从复指数分布，则计数为泊松</li>\n<li>N 个客体随机地分布在 $[0, t]$ 区间上，每个客体的出现时间均匀分布，且相互时间独立，当 $n \\rightarrow \\infty, t \\rightarrow \\infty$，极限分布为泊松分布</li>\n<li>二项分布的极限</li>\n</ol>\n<h3 id=\"顺序统计量\"><a href=\"#顺序统计量\" class=\"headerlink\" title=\"顺序统计量\"></a>顺序统计量</h3><p>统计量是样本的某个函数 $g(X_1, …, X_n)$。例如：最大值、中值、平均值、样本协方差阵</p>\n<p>顺序统计量：根据到达时刻排序。例如 $S_1, S_2, …, S_n$ 就是 $V_1, V_2, …, V_n$ 的顺序统计量</p>\n<div>$$\nf_{Y_k}(x) = \\binom{n}{k - 1}F(x)\\binom{n - k + 1}{1}f(x)(1 - F(x))^{n - k}\n$$</div>\n\n<p>有序的顺序统计量的分布：</p>\n<div>$$\nf_{Y_1...Y_n}(y_1, y_2, ..., y_n) = n!f(y_1)f(y_2)...f(y_n)\n$$</div>\n\n<h3 id=\"非齐次泊松过程\"><a href=\"#非齐次泊松过程\" class=\"headerlink\" title=\"非齐次泊松过程\"></a>非齐次泊松过程</h3><p>四个条件：</p>\n<p>$N(0) &#x3D; 0$</p>\n<p>$N(t)$ 独立增量</p>\n<p>$P(N(t + \\Delta t) - N(t) &#x3D; 1) &#x3D; \\lambda(t)\\Delta t + o(\\Delta t)$</p>\n<p>$P(N(t + \\Delta t) - N(t) \\ge 2) &#x3D; o(\\Delta t)$</p>\n<p>定理：</p>\n<div>$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{[m(t_0 + t) - m(t_0)]^n}{n!}e^{-[m(t_0 + t) - m(t_0)]}\n$$</div>\n\n<p>其中，</p>\n<div>$$\nm(t) = \\int_{0}^{t}\\mathrm \\lambda(u) du\n$$</div>\n\n<p>其意义可以理解为事件的个数。</p>\n<p>令 $m(t + t_0) - m(t_0) &#x3D; \\alpha$</p>\n<div>$$\nP(N(t_0 + t) - N(t_0) = n) = \\frac{\\alpha^n}{n!}e^{-\\alpha}\n$$</div>\n\n<p>则期望和方差</p>\n<div>$$\nE(N(t_0 + t) - N(t_0)) = \\alpha\\\\\nV(N(t_0 + t) - N(t_0)) = \\alpha\n$$</div>\n\n<h3 id=\"复合泊松\"><a href=\"#复合泊松\" class=\"headerlink\" title=\"复合泊松\"></a>复合泊松</h3><p>$Y_n$ 随机变量族，$N(t)$ 泊松过程，称$X(t) &#x3D; \\sum_{n &#x3D; 1}^{N(t)}Y_n$ 为复合泊松。</p>\n<div>$$\nE \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i \\rbrace\\\\\nD \\lbrace X(t) \\rbrace = \\lambda t \\cdot E \\lbrace Y_i^2 \\rbrace\\\\\nG_X(z) = \\exp(\\lambda t G_Y(z) - 1)\\\\\n\\phi_X(\\omega) = \\exp(\\lambda t \\phi_Y(\\omega) - 1)\n$$</div>\n\n<h3 id=\"随机参数泊松\"><a href=\"#随机参数泊松\" class=\"headerlink\" title=\"随机参数泊松\"></a>随机参数泊松</h3><p>参数 $\\lambda$ 是随机变量，PDF为 $f(\\lambda)$</p>\n<ul>\n<li>是平稳增量</li>\n<li>不是独立增量</li>\n</ul>\n<div>$$\nP(Y(t) = n) = \\int^{+\\infty}_{0}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda\n$$</div>\n\n<p>母函数：</p>\n<div>$$\nG_{Y(t)}(z) = \\int_{0}^{\\infty}\\exp (\\lambda t(z - 1))f(\\lambda)\\mathrm d\\lambda\n$$</div>\n\n<div>$$\nE(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\nV(Y(t)) = \\int_{0}^{\\infty}\\lambda t f(\\lambda)\\mathrm d\\lambda\\\\\n$$</div>\n\n<p>数据统计的后验分布</p>\n<div>$$\nP(\\Lambda \\le x | Y(t) = n) = \\frac{\\int_{0}^{x}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\\\\\nf_\\Lambda(x|Y(t) = n) = \\frac{\\frac{(x t)^n}{n!}e^{-x t}f(x)}{\\int_{0}^{\\infty}\\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}f(\\lambda)\\mathrm d\\lambda}\n$$</div>\n\n<h3 id=\"过滤的泊松过程\"><a href=\"#过滤的泊松过程\" class=\"headerlink\" title=\"过滤的泊松过程\"></a>过滤的泊松过程</h3><p>统计一段时间影响的总和</p>\n<div>$$\nY(t) = \\sum\\limits_{i=1}^{N(t)}h(t, S_i, A_i)\n$$</div>\n\n<p>特征函数：</p>\n<div>$$\n\\Phi_{Y(t)}(\\omega) = \\exp \\left ( \\lambda t \\left ( \\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv - 1\\right) \\right)\n$$</div>\n\n<p>均值：</p>\n<div>$$\nE(Y(t)) = \\frac{1}{j}\\frac{\\partial \\Phi_{Y(t)}}{\\partial \\omega} = \\underbrace{\\lambda t}_{平均到达个数} \\underbrace{\\int_{0}^{t}\\frac{1}{t}\\exp(j\\omega h(t, v))\\mathrm dv}_{每个事件在 t 时刻的影响}\n$$</div>\n\n<h2 id=\"生灭过程\"><a href=\"#生灭过程\" class=\"headerlink\" title=\"生灭过程\"></a>生灭过程</h2><p>该过程状态可以用整数序列 $n &#x3D; 0, 1, 2, 3, …$ 来表示</p>\n<p>状态转移只能发生在临近状态之间</p>\n<p>在$[t, t + \\Delta t)$ 区间内，n状态转移到 $n + 1$ 状态的概率为 $\\lambda \\Delta t$， 转移到 $n - 1$ 状态的概率为 $\\mu \\Delta t$。</p>\n<h3 id=\"M-x2F-M-x2F-1\"><a href=\"#M-x2F-M-x2F-1\" class=\"headerlink\" title=\"M&#x2F;M&#x2F;1\"></a>M&#x2F;M&#x2F;1</h3><p>系统平均顾客人数 $L &#x3D; \\frac{\\lambda &#x2F; \\mu}{1 - \\lambda &#x2F; \\mu}$</p>\n<p>排队平均人数</p>\n<div>$$\nL_Q = \\sum\\limits_{n=1}^{\\infty}(n - 1)p_n = \\frac{\\lambda^2}{(\\mu - \\lambda)\\mu}\\\\\nL_Q \\ne L - 1\n$$</div>\n\n<p>前面有一个人，等待时间：负指数分布的无记忆性</p>\n<div>$$\nf_T(t|T > t_0) = \\mu e^{-\\mu (t - t_0)}\n$$</div>\n\n<p>从而不管你什么时候来，平均等待时间为 $1&#x2F;\\mu$，和一个人被服务的时间是一样的。</p>\n<h2 id=\"习题课\"><a href=\"#习题课\" class=\"headerlink\" title=\"习题课\"></a>习题课</h2><p><img src=\"/../images/stochastic/exer_1.jpg\" alt=\"alt\"></p>\n"},{"title":"Hello World","katex":true,"_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n```bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n```bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n```bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n```bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n\n$$\n\\text{Katex is refined.}\n$$\n\n$$\n\\int_{birth}^{death} stu\\text{d}y = \\text{touch fish}\n$$\n\n## Latex 主题\n\n### 这是h3。\n\n#### 这是h4。\n\n##### 这是h5。\n\n这是正文 Content。\n\n**这是粗体 Bold。**\n\n*这是斜体 Italic。*\n\n* 这是列表 List。\n\n1. 这是有序列表 Ordered List。\n\n| 这This   | 是is | 表a | 格table    | 。. |\n| ---- | -- | -- | ----- | -- |\n| 这   | 是 | 表 | 格    | 。 |\n| This | is | a  | table | .  |\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\nkatex: true\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n```bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n```bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n```bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n```bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n\n$$\n\\text{Katex is refined.}\n$$\n\n$$\n\\int_{birth}^{death} stu\\text{d}y = \\text{touch fish}\n$$\n\n## Latex 主题\n\n### 这是h3。\n\n#### 这是h4。\n\n##### 这是h5。\n\n这是正文 Content。\n\n**这是粗体 Bold。**\n\n*这是斜体 Italic。*\n\n* 这是列表 List。\n\n1. 这是有序列表 Ordered List。\n\n| 这This   | 是is | 表a | 格table    | 。. |\n| ---- | -- | -- | ----- | -- |\n| 这   | 是 | 表 | 格    | 。 |\n| This | is | a  | table | .  |\n","slug":"hello-world","published":1,"date":"2024-03-21T17:47:58.298Z","updated":"2024-03-22T01:07:02.466Z","_id":"clu1gtfi0000qrsug2tfpfvca","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n<div>$$\n\\text{Katex is refined.}\n$$</div>\n\n<div>$$\n\\int_{birth}^{death} stu\\text{d}y = \\text{touch fish}\n$$</div>\n\n<h2 id=\"Latex-主题\"><a href=\"#Latex-主题\" class=\"headerlink\" title=\"Latex 主题\"></a>Latex 主题</h2><h3 id=\"这是h3。\"><a href=\"#这是h3。\" class=\"headerlink\" title=\"这是h3。\"></a>这是h3。</h3><h4 id=\"这是h4。\"><a href=\"#这是h4。\" class=\"headerlink\" title=\"这是h4。\"></a>这是h4。</h4><h5 id=\"这是h5。\"><a href=\"#这是h5。\" class=\"headerlink\" title=\"这是h5。\"></a>这是h5。</h5><p>这是正文 Content。</p>\n<p><strong>这是粗体 Bold。</strong></p>\n<p><em>这是斜体 Italic。</em></p>\n<ul>\n<li>这是列表 List。</li>\n</ul>\n<ol>\n<li>这是有序列表 Ordered List。</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>这This</th>\n<th>是is</th>\n<th>表a</th>\n<th>格table</th>\n<th>。.</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>这</td>\n<td>是</td>\n<td>表</td>\n<td>格</td>\n<td>。</td>\n</tr>\n<tr>\n<td>This</td>\n<td>is</td>\n<td>a</td>\n<td>table</td>\n<td>.</td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n<div>$$\n\\text{Katex is refined.}\n$$</div>\n\n<div>$$\n\\int_{birth}^{death} stu\\text{d}y = \\text{touch fish}\n$$</div>\n\n<h2 id=\"Latex-主题\"><a href=\"#Latex-主题\" class=\"headerlink\" title=\"Latex 主题\"></a>Latex 主题</h2><h3 id=\"这是h3。\"><a href=\"#这是h3。\" class=\"headerlink\" title=\"这是h3。\"></a>这是h3。</h3><h4 id=\"这是h4。\"><a href=\"#这是h4。\" class=\"headerlink\" title=\"这是h4。\"></a>这是h4。</h4><h5 id=\"这是h5。\"><a href=\"#这是h5。\" class=\"headerlink\" title=\"这是h5。\"></a>这是h5。</h5><p>这是正文 Content。</p>\n<p><strong>这是粗体 Bold。</strong></p>\n<p><em>这是斜体 Italic。</em></p>\n<ul>\n<li>这是列表 List。</li>\n</ul>\n<ol>\n<li>这是有序列表 Ordered List。</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>这This</th>\n<th>是is</th>\n<th>表a</th>\n<th>格table</th>\n<th>。.</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>这</td>\n<td>是</td>\n<td>表</td>\n<td>格</td>\n<td>。</td>\n</tr>\n<tr>\n<td>This</td>\n<td>is</td>\n<td>a</td>\n<td>table</td>\n<td>.</td>\n</tr>\n</tbody></table>\n"},{"title":"杂项","date":"2022-11-10T13:08:58.000Z","_content":"批处理命令设置环境变量\nset path=xxxx\n\n## 好玩的东西\n\n### Lambda 递归\n\n```python\nf = (lambda h: lambda n:(h(h, n)))(lambda f,n: n + f(f, n-1) if n > 0 else 0)\n# >>> f(10)\n# 55\n```\n\n### Lambda 计数器\n\n```python\nf,n = (lambda f,n=0: ((lambda f, n: lambda x, m=n: f(x, m))(f, n+1), n))(lambda f,n: ((lambda f, n: lambda x, m=n: f(x, m))(f, n+1), n))\n\nprint(n)\nf,n = f(f)\nprint(n)\n\nf,n = f(f)\nprint(n)\n\nf,n = f(f)\nprint(n)\n\nf,n = f(f)\nprint(n)\n\n```\n\n更好玩的版本！\n\n```python\nf,n = (lambda f,n=0: ((lambda h: lambda: h(h))((lambda f, n: lambda x, m=n: f(x, m))(f, n+1)), n))(lambda f,n: ((lambda h: lambda: h(h))((lambda f, n: lambda x, m=n: f(x, m))(f, n+1)), n))\n\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n```\n\n与上一个版本效果相同：\n\n```python\nf = (lambda g: g(lambda f,n=0: (g((lambda f, n: lambda x, m=n: f(x, m))(f, n+1)), n)))(lambda h: lambda: h(h))\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n```\n\n更加简洁：\n\n```python\nf = (lambda g: g(lambda f,t, n=0: n if t == 0 else g((lambda f, t, n: lambda x, u=t, m=n: f(x, u, m))(f, t, n+1))))((lambda h: lambda t=1: h(h, t)))\nprint(f(0))\nf = f()\nprint(f(0))\nf = f()\nprint(f(0))\n```\n\n## js爬虫\n\n**1.js保存字符串到本地**\n\n```js\nfunction saveShareContent (content, fileName) {\n    let downLink = document.createElement('a')\n    downLink.download = fileName\n    //字符内容转换为blod地址\n    let blob = new Blob([content])\n    downLink.href = URL.createObjectURL(blob)\n    // 链接插入到页面\n    document.body.appendChild(downLink)\n    downLink.click()\n    // 移除下载链接\n    document.body.removeChild(downLink)\n}\n```\n\n**2. 包含iframe/#document的文档**\n\n```js\n    var ifram = document.querySelector(\"#iframe\")\n    var idoc = ifram.contentWindow.document;\n    //console.log(idoc);\n    var ifram2 = idoc.querySelector(\"#ext-gen1046 > iframe\")\n    var idoc2 = ifram2.contentWindow.document;\n    //console.log(idoc2);\n    var ifram3 = idoc2.querySelector(\"#frame_content\");\n    var idoc3 = ifram3.contentWindow.document;\n    console.log(idoc3);\n    text = idoc3.documentElement.innerHTML;\n```\n\n层层剥开，否则在iframe内部的元素会定位失败。在F12界面右键选择“复制js路径”可以获取 `querySeletor`语句。\n\n**3.滚动至最低部**\n\n```js\n    var ele = document.documentElement;\n    if(ele.scrollHeight > ele.clientHeight) {\n\t\t//设置滚动条到最底部\n\t\tele.scrollTop = ele.scrollHeight;\n    }\n```\n\n必要时可以增加 `setTimeout`等待网页加载完毕。\n\n**4.逐步滚动**\n\n```javascript\n    var count = 0;\n    pos = document.documentElement.scrollTop;\n    console.log(pos);\n    var id = setInterval(\n        function (){\n            if (count < 500) {\n                document.documentElement.scrollTop++;\n                count++;\n            } else {\n                clearInterval(id);\n            }\n        }\n    , 2);\n```\n\n## electron-vue\n\n**如何引入.node文件**\n\n需要将.node文件放在public文件夹下，引用时可以用相对路径也可以用 `__static`+文件名。\n\n需要安装node-loader@1.0.3。太高的版本会导致问题。\n\n```javascript\nconst addon = require(\"node-loader!../public/addon.node\")\n```\n\n**在vue中使用ipcRenderer**\n\n主进程中引入ipcMain没啥大问题。\n在vue文件中引入ipcRenderer，需要先在vue.config.js中配置\n\n```js\nnodeIntegration: true\n\n  pluginOptions: {\n    electronBuilder: {\n      // 在vue中能引入electron模块\n      nodeIntegration: true,\n```\n\n然后在各个vue文件中引入\n\n```js\nimport { ipcRenderer } from 'electron'\n```\n\n## math\n\n一个只跟a, b中最大的那一个有关的积分：\n\n$$\n\\int_{0}^{\\pi}\\frac{\\sin \\theta}{\\sqrt{a^2+b^2-2ab\\cos\\theta}}\\mathrm d\\theta = \\frac{1}{ab}(|a+b| - |a-b|)\n$$\n\n## js 小技巧\n\n### 可变定时检测\n\n问：每隔10秒检测一次当前页面是否包含某字符串，如果包含，则 console.log，下次检测的时间变为 100 秒\n\n答：为了实现这个功能，你可以使用 `setInterval`函数来设置一个定期执行的任务。然而，因为你想在满足特定条件时改变间隔时间，你可能需要使用 `setTimeout`来代替，因为 `setInterval`的间隔时间一旦设定就无法改变。以下是如何实现这一逻辑的示例代码：\n\n```javascript\nfunction checkContentAndAdjustInterval(searchString, initialDelay, newDelay) {\n  // 定义一个函数，用于检查页面内容并根据条件调整定时器\n  function checkAndSchedule() {\n    // 检查文档中是否包含特定字符串\n    if (document.body.textContent.includes(searchString)) {\n      console.log(`页面包含指定字符串: ${searchString}`);\n      // 如果找到字符串，设置下一次检查的延时为 newDelay\n      setTimeout(checkAndSchedule, newDelay);\n    } else {\n      // 如果没有找到字符串，保持原来的检查频率\n      setTimeout(checkAndSchedule, initialDelay);\n    }\n  }\n\n  // 启动循环检查\n  setTimeout(checkAndSchedule, initialDelay);\n}\n\n// 使用示例：每隔10秒检查一次页面是否包含\"特定字符串\"，\n// 如果找到，则下次检查的时间间隔变为100秒\ncheckContentAndAdjustInterval(\"特定字符串\", 10000, 100000);\n```\n\n这段代码首先定义了一个 `checkContentAndAdjustInterval`函数，它接受三个参数：要搜索的字符串 `searchString`、初始的检查间隔时间 `initialDelay`（以毫秒为单位）、以及在找到字符串后新的检查间隔时间 `newDelay`。\n\n在 `checkContentAndAdjustInterval`函数内部，定义了另一个名为 `checkAndSchedule`的函数。`checkAndSchedule`函数首先检查当前页面的内容是否包含指定的字符串。如果包含，它将使用 `console.log`输出一个消息，并使用新的延迟时间 `newDelay`来安排下一次执行。如果不包含指定的字符串，它将继续使用初始的延迟时间 `initialDelay`来安排下一次执行。\n\n最后，`checkContentAndAdjustInterval`函数通过调用 `setTimeout`并传入 `checkAndSchedule`函数和初始延迟时间 `initialDelay`来启动整个检查流程。\n\n这种方法的好处是你可以灵活地控制检查的间隔时间，而且它在满足特定条件后能够自动调整这个间隔，非常适合需要根据条件动态调整检查频率的场景。\n\n## NFS 常用指令\n\n主要参考：[如何在 Ubuntu 20.04 上安装和配置 NFS 服务器？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/480960387)\n\n### 服务端绑定 NFS\n\n直接绑定：\n\n```text\nsudo mount --bind /opt/backups /srv/nfs4/backups\nsudo mount --bind /var/www /srv/nfs4/www\n```\n\n要在重新启动后使绑定挂载永久化，请打开/etc/fstab文件：\n\n```text\nsudo nano /etc/fstab\n```\n\n并添加以下行：\n\n```text\n/etc/fstab\n/opt/backups /srv/nfs4/backups  none   bind   0   0\n/var/www     /srv/nfs4/www      none   bind   0   0\n```\n\n`/var/www `为本地需要绑定的文件夹，`/srv/nfs4/www `为 NFS 管理的文件夹，必须以 `/srv/nfs4`开头。\n\n绑定后，服务端可以修改 `/var/www `内的文件，会被自动同步到 NFS 绑定的目录下。\n\n### 客户端绑定 NFS\n\n为挂载点创建两个新目录：\n\n```text\nsudo mkdir -p /backups\nsudo mkdir -p /srv/www\n```\n\n您可以在任何您想要的位置创建目录。\n\n使用以下命令挂载导出的文件系统mount ：\n\n```text\nsudo mount -t nfs -o vers=4 192.168.33.10:/backups /backups\nsudo mount -t nfs -o vers=4 192.168.33.10:/www /srv/www\n```\n\n要在重新启动时永久挂载，请打开/etc/fstab文件并添加以下行：\n\n```text\nsudo nano /etc/fstab\n\n/etc/fstab\n192.168.33.10:/backups /backups   nfs   defaults,timeo=900,retrans=5,_netdev 0 0\n192.168.33.10:/www /srv/www       nfs   defaults,timeo=900,retrans=5,_netdev 0 0\n```\n\n有关挂载 NFS 文件系统时可用选项的信息，请输入man nfs您的终端。\n\n### IP 检测\n\n编辑配置文件\n\n```\nsudo nano /etc/exports\n```\n\n配置文件例子：\n\n```\n/srv/nfs4         192.168.33.0/24(rw,sync,no_subtree_check,crossmnt,fsid=0)\n/srv/nfs4/backups 192.168.33.0/24(ro,sync,no_subtree_check) 192.168.33.3(rw,sync,no_subtree_check)\n/srv/nfs4/www     192.168.33.20(rw,sync,no_subtree_check)\n```\n\n其中，192.168.33.0/24 等为需要过滤的 ip 规则。\n\n应用 ip 设置\n\n```\nsudo exportfs -ar\n```\n\n查看 ip 检测\n\n```\nsudo exportfs -v\n```\n\n### 重启 NFS\n\n```\nsudo /etc/init.d/nfs-kernel-server restart\n```\n\n## WSL 相关\n\n### WSL 寄了！\n\n可能是因为配置 nfs 的原因吧，wsl 关掉之后就打不开了。\n\n* wsl 无响应。\n* 当 ubuntu 处于停止状态时，`wsl --list`, `wsl --status` 有响应；但我一旦尝试运行 `wsl` 以启动 ubuntu，就无响应了。\n* `wsl --help` 一直没问题。\n\n怀疑是配置 `/etc/fstab` 的时候出的问题，导致 wsl 无响应。\n\n后来的解决方案：\n\n1. 把 `ext4.vhdx` 备份了一份。\n2. 卸载 ubuntu distro，重新安装了一遍 ubuntu 22.04。\n3. `wsl --mount --vhd` 将 `ext4.vhdx` 挂到新安装的 ubuntu wsl 上。\n\n幸好 `ext4.vhdx` 还在。\n\n另外，挂完 `ext4.vhdx` 后，我将存有 `ext4.vhdx` 的移动硬盘拔出，然后重新打开 wsl，发现出现了同样的问题。这样就验证了我的假说：\n\n* 我设置了开机默认挂载 nfs 硬盘，连接远程的服务器。\n* nfs 服务器因为一些原因没连上。\n* wsl 文件系统因为挂载的硬盘找不到了，发生错误。\n* wsl 在启动界面无响应。\n\n重启了电脑，发现之前 `wsl --mount` 挂载的 `ext4.vhdx` 已经被清空了，证明 wsl --mount 命令的效果在重启之后清空了。\n\n### yarn add hasura-cli 安装失败\n\n报错：\n\n```\nCommand: node dist/index.js\nArguments: \nDirectory: /home/guoyun812/eesast/hasura/node_modules/hasura-cli\nOutput:\nhasura-cli@2.36.1\nDownloading Hasura CLI binary v2.36.1 from https://github.com/hasura/graphql-engine/releases/download/v2.36.1/cli-hasura-linux-amd64\n\n\nhasura-cli@2.36.1\nError! Failed to install Hasura CLI binary.\nTry npm uninstall hasura-cli or yarn remove hasura-cli and then reinstall it.\nIf the issue occurs repeatedly, check if your network can access https://github.com as the the Hasura CLI binary file is hosted on Github.\nYou can report the issue on https://github.com/jjangga0214/hasura-cli/issues with error message.\n```\n\n解决方案：手动下载 hasura-cli 的二进制文件，并粘贴到 `node_modules/hasura/`。\n\n## SSH 相关\n\n### ssh 端口转发的坑点\n\n转发之前一定要在远程服务器的 `/etc/ssh/sshd_config` 中配置：\n\nGatewayPorts **yes（或 clientspecified，不能是 no）**\n\n具体的原理我说不清楚。大概意思是，我们通常用以下方式进行远程端口转发：\n\n```\nssh -CNgv -R <remote_ip>:<port>:<local_ip>:<port> <hostname>\n```\n\n一般会把 remote_ip 设为 0.0.0.0，以绑定到所有接口。但是，若不设置 GatewayPorts，则远程服务器上仍然只有 localhost 能够访问这个端口，如果你在 docker 容器内访问这个端口是不行的。我花了很多时间去排除 docker 容器到主机上的连接是否正确，包括使用 docker 的网关地址/host.docker.internal、修改 iptables、修改防火墙，都没什么用。因为实际上这个 ip 可以 ping 通，根本就不是 ip 地址或者防火墙的问题，是 ssh 转发里面限制了网关访问端口。\n\nclaude-sonnet 给出的解释如下：\n\n| 配置选项            | 客户端命令                      | 实际绑定地址         | 说明           |\n| ------------------- | ------------------------------- | -------------------- | -------------- |\n| `no`              | `ssh -R 8000:...`             | `127.0.0.1:8000`   | 强制 localhost |\n| `no`              | `ssh -R 0.0.0.0:8000:...`     | `127.0.0.1:8000`   | 忽略客户端指定 |\n| `yes`             | `ssh -R 8000:...`             | `0.0.0.0:8000`     | 默认所有接口   |\n| `yes`             | `ssh -R 192.168.1.1:8000:...` | `192.168.1.1:8000` | 允许指定       |\n| `clientspecified` | `ssh -R 8000:...`             | `127.0.0.1:8000`   | 默认 localhost |\n| `clientspecified` | `ssh -R 0.0.0.0:8000:...`     | `0.0.0.0:8000`     | 允许客户端指定 |\n\n可以看到，如果服务端配置为 no，无论客户端怎么强制绑 `0.0.0.0` 都没用的，还是变成了 `localhost:8000` 的服务。如果设置为 yes，那么默认就绑 `0.0.0.0:8000`，要指定也是可以的。\n\n### 服务器共用怎么设置自己的环境变量\n\n在 vscode user settings 中添加：\n\n```\n    \"terminal.integrated.env.linux\": {\n        \"ZZZ_INIT_COMMAND\": \"1\"\n    },\n```\n\n在启动文件（例如 `.bashrc`）中添加：\n\n```bash\n# used for zzz's bash init if the env var below is defined\nif [[ -n $ZZZ_INIT_COMMAND ]]; then\n    echo \"Hello, welcome to tsz's bash shell!\"\n    eval \"source /home/ubuntu/tsz/config.sh\"\nfi\n```\n\n### ssh 服务器\n\n使用 `ssh-keygen` 时最好设置一个口令，否则别人也能用这个密钥。\n\n### 常用命令\n\nssh 反向代理（服务器端口映射到本地端口），挂在后台\n\n```\nssh -CqTfnN -R <remote_port>:localhost:<local_port>  -v  username@hostname -p <ssh_port>\n```\n\nssh 前向代理（本地端口映射到服务器端口）\n\n```\nssh -CqTfnN -L <local_port>:localhost:<remote_port>  -v  username@hostname -p <ssh_port>\n```\n\n将请求转发到 github\n\n```\nssh -CqTfnN -L <local_port>:github.com:22 -v  username@hostname -p <ssh_port>\n```\n\n### ssh agent\n\n启动 ssh agent，并查看 pid\n\n```\neval $(ssh-agent -s)\n```\n\n查看当前 agent 有哪些密钥\n\n```\nssh-add -l # 查看公钥的 sha256\nssh-add -L # 查看完整公钥\n```\n\n添加密钥\n\n```\nssh-add <private_key_path>\n```\n\n## Node.js\n\n### listen EACCES: permission denied 0.0.0.0:3000\n\n1、先判断是否是端口占用的问题导致的 `netstat -ano| findstr 3000`\n\n关闭相关进程（cmd）\n\n```\ntaskkill /PID <process_id> /F\n```\n\n发现并没有程序在使用这个端口\n\n2、改用管理员再运行一遍\n\n发现仍然不行\n\n3、使用管理员权限运行以下命令\n\n`net stop winnat`\n\n`net start winnat`\n\n## AI\n\n### Could not load symbol cudnnGetLibConfig\n\n环境变量的问题，如果你在环境变量中将 LD_LIBRARY_PATH 指向了不正确的版本会导致这里出问题。\n\n运行下面的代码以获得正确的 cudnn 路径：\n\n```\nexport LD_LIBRARY_PATH=`python3  -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + \":\" + os.path.dirname(nvidia.cudnn.lib.__file__))'`\n```\n\n### /usr/bin/ld: cannot find -lcuda\n\n见[这个 issue](https://github.com/NVlabs/tiny-cuda-nn/issues/183#issuecomment-1342828785)\n\nexport LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs:$LIBRARY_PATH\"\n\nexport LD_LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs:/usr/local/cuda/lib64\"\n\n### Llama 架构\n\n![1713000493686](../images/stuffs/1713000493686.png)\n\n### 使用 Tensorboard\n\n```python-repl\nfrom torch.utils.tensorboard import SummaryWriter\nfrom accelerate.tracking import GeneralTracker, on_main_process\nimport os\nfrom typing import Union\n\n# 0. 自定义追踪器\nclass MyCustomTracker(GeneralTracker):\n    \"\"\"\n    my custom `Tracker` class that supports `tensorboard`. Should be initialized at the start of your script.\n\n    Args:\n        run_name (`str`):\n            The name of the experiment run\n        logging_dir (`str`, `os.PathLike`):\n            Location for TensorBoard logs to be stored.\n        kwargs:\n            Additional key word arguments passed along to the `tensorboard.SummaryWriter.__init__` method.\n    \"\"\"\n\n    name = \"tensorboard\"\n    requires_logging_directory = True\n\n    @on_main_process\n    def __init__(self, run_name: str, logging_dir: Union[str, os.PathLike],\n                 **kwargs):\n        super().__init__()\n        self.run_name = run_name\n        self.logging_dir = os.path.join(logging_dir, run_name)\n        self.writer = SummaryWriter(self.logging_dir, **kwargs)\n\n    @property\n    def tracker(self):\n        return self.writer\n\n    @on_main_process\n    def add_scalar(self, tag, scalar_value, **kwargs):\n        self.writer.add_scalar(tag=tag, scalar_value=scalar_value, **kwargs)\n\n    @on_main_process\n    def add_text(self, tag, text_string, **kwargs):\n        self.writer.add_text(tag=tag, text_string=text_string, **kwargs)\n\n    @on_main_process\n    def add_figure(self, tag, figure, **kwargs):\n        self.writer.add_figure(tag=tag, figure=figure, **kwargs)\n\n    @on_main_process\n    def add_vector(self, tag, mat, **kwargs):\n        self.writer.add_embedding(tag=tag, mat=mat, **kwargs)\n\n```\n\n### 记录神经元的激活值\n\n```python\nfrom torch import nn\nimport torch\n\nclass TestForHook(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.linear_1 = nn.Linear(in_features=2, out_features=2)\n        self.linear_2 = nn.Linear(in_features=2, out_features=1)\n        self.relu = nn.ReLU()\n        self.relu6 = nn.ReLU6()\n\n    def forward(self, x):\n        linear_1 = self.linear_1(x)\n        linear_2 = self.linear_2(linear_1)\n        relu = self.relu(linear_2)\n        relu6 = self.relu6(relu)\n        layers_in = (x, linear_1, linear_2)\n        layers_out = (linear_1, linear_2, relu)\n        return relu6\n\nfeatures_in_hook = []\nfeatures_out_hook = []\n\ndef hook(module, fea_in, fea_out):\n    print(f\"hook! module: {module}, in: {fea_in}, out: {fea_out}\")\n    features_in_hook.append(fea_in)\n    features_out_hook.append(fea_out)\n    return None\n\nnet = TestForHook()\n\n\"\"\"\n# 第一种写法，按照类型勾，但如果有重复类型的layer比较复杂\nnet_chilren = net.children()\nfor child in net_chilren:\n    if not isinstance(child, nn.ReLU6):\n        child.register_forward_hook(hook=hook)\n\"\"\"\n\n\"\"\"\n推荐下面我改的这种写法，因为我自己的网络中，在Sequential中有很多层，\n这种方式可以直接先print(net)一下，找出自己所需要那个layer的名称，按名称勾出来\n\"\"\"\n\nprint(net)\n\nlayer_name = 'linear_1'\nfor (name, module) in net.named_modules():\n    if name == layer_name:\n        module.register_forward_hook(hook=hook)\n\nprint(features_in_hook)  # 勾的是指定层的输入\nprint(features_out_hook)  # 勾的是指定层的输出\n\nrand_x = torch.rand(1, 2)\nprint(f\"input x: {rand_x}\")\nresult = net(rand_x)\nprint(f\"result: {result}\")\nprint(f\"features in: {features_in_hook}\")\nprint(f\"features out: {features_out_hook}\")\n```\n","source":"_posts/stuffs.md","raw":"---\ntitle: 杂项\ndate: 2022-11-10 21:08:58\ntags:\n---\n批处理命令设置环境变量\nset path=xxxx\n\n## 好玩的东西\n\n### Lambda 递归\n\n```python\nf = (lambda h: lambda n:(h(h, n)))(lambda f,n: n + f(f, n-1) if n > 0 else 0)\n# >>> f(10)\n# 55\n```\n\n### Lambda 计数器\n\n```python\nf,n = (lambda f,n=0: ((lambda f, n: lambda x, m=n: f(x, m))(f, n+1), n))(lambda f,n: ((lambda f, n: lambda x, m=n: f(x, m))(f, n+1), n))\n\nprint(n)\nf,n = f(f)\nprint(n)\n\nf,n = f(f)\nprint(n)\n\nf,n = f(f)\nprint(n)\n\nf,n = f(f)\nprint(n)\n\n```\n\n更好玩的版本！\n\n```python\nf,n = (lambda f,n=0: ((lambda h: lambda: h(h))((lambda f, n: lambda x, m=n: f(x, m))(f, n+1)), n))(lambda f,n: ((lambda h: lambda: h(h))((lambda f, n: lambda x, m=n: f(x, m))(f, n+1)), n))\n\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n```\n\n与上一个版本效果相同：\n\n```python\nf = (lambda g: g(lambda f,n=0: (g((lambda f, n: lambda x, m=n: f(x, m))(f, n+1)), n)))(lambda h: lambda: h(h))\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n\nf,n = f()\nprint(n)\n```\n\n更加简洁：\n\n```python\nf = (lambda g: g(lambda f,t, n=0: n if t == 0 else g((lambda f, t, n: lambda x, u=t, m=n: f(x, u, m))(f, t, n+1))))((lambda h: lambda t=1: h(h, t)))\nprint(f(0))\nf = f()\nprint(f(0))\nf = f()\nprint(f(0))\n```\n\n## js爬虫\n\n**1.js保存字符串到本地**\n\n```js\nfunction saveShareContent (content, fileName) {\n    let downLink = document.createElement('a')\n    downLink.download = fileName\n    //字符内容转换为blod地址\n    let blob = new Blob([content])\n    downLink.href = URL.createObjectURL(blob)\n    // 链接插入到页面\n    document.body.appendChild(downLink)\n    downLink.click()\n    // 移除下载链接\n    document.body.removeChild(downLink)\n}\n```\n\n**2. 包含iframe/#document的文档**\n\n```js\n    var ifram = document.querySelector(\"#iframe\")\n    var idoc = ifram.contentWindow.document;\n    //console.log(idoc);\n    var ifram2 = idoc.querySelector(\"#ext-gen1046 > iframe\")\n    var idoc2 = ifram2.contentWindow.document;\n    //console.log(idoc2);\n    var ifram3 = idoc2.querySelector(\"#frame_content\");\n    var idoc3 = ifram3.contentWindow.document;\n    console.log(idoc3);\n    text = idoc3.documentElement.innerHTML;\n```\n\n层层剥开，否则在iframe内部的元素会定位失败。在F12界面右键选择“复制js路径”可以获取 `querySeletor`语句。\n\n**3.滚动至最低部**\n\n```js\n    var ele = document.documentElement;\n    if(ele.scrollHeight > ele.clientHeight) {\n\t\t//设置滚动条到最底部\n\t\tele.scrollTop = ele.scrollHeight;\n    }\n```\n\n必要时可以增加 `setTimeout`等待网页加载完毕。\n\n**4.逐步滚动**\n\n```javascript\n    var count = 0;\n    pos = document.documentElement.scrollTop;\n    console.log(pos);\n    var id = setInterval(\n        function (){\n            if (count < 500) {\n                document.documentElement.scrollTop++;\n                count++;\n            } else {\n                clearInterval(id);\n            }\n        }\n    , 2);\n```\n\n## electron-vue\n\n**如何引入.node文件**\n\n需要将.node文件放在public文件夹下，引用时可以用相对路径也可以用 `__static`+文件名。\n\n需要安装node-loader@1.0.3。太高的版本会导致问题。\n\n```javascript\nconst addon = require(\"node-loader!../public/addon.node\")\n```\n\n**在vue中使用ipcRenderer**\n\n主进程中引入ipcMain没啥大问题。\n在vue文件中引入ipcRenderer，需要先在vue.config.js中配置\n\n```js\nnodeIntegration: true\n\n  pluginOptions: {\n    electronBuilder: {\n      // 在vue中能引入electron模块\n      nodeIntegration: true,\n```\n\n然后在各个vue文件中引入\n\n```js\nimport { ipcRenderer } from 'electron'\n```\n\n## math\n\n一个只跟a, b中最大的那一个有关的积分：\n\n$$\n\\int_{0}^{\\pi}\\frac{\\sin \\theta}{\\sqrt{a^2+b^2-2ab\\cos\\theta}}\\mathrm d\\theta = \\frac{1}{ab}(|a+b| - |a-b|)\n$$\n\n## js 小技巧\n\n### 可变定时检测\n\n问：每隔10秒检测一次当前页面是否包含某字符串，如果包含，则 console.log，下次检测的时间变为 100 秒\n\n答：为了实现这个功能，你可以使用 `setInterval`函数来设置一个定期执行的任务。然而，因为你想在满足特定条件时改变间隔时间，你可能需要使用 `setTimeout`来代替，因为 `setInterval`的间隔时间一旦设定就无法改变。以下是如何实现这一逻辑的示例代码：\n\n```javascript\nfunction checkContentAndAdjustInterval(searchString, initialDelay, newDelay) {\n  // 定义一个函数，用于检查页面内容并根据条件调整定时器\n  function checkAndSchedule() {\n    // 检查文档中是否包含特定字符串\n    if (document.body.textContent.includes(searchString)) {\n      console.log(`页面包含指定字符串: ${searchString}`);\n      // 如果找到字符串，设置下一次检查的延时为 newDelay\n      setTimeout(checkAndSchedule, newDelay);\n    } else {\n      // 如果没有找到字符串，保持原来的检查频率\n      setTimeout(checkAndSchedule, initialDelay);\n    }\n  }\n\n  // 启动循环检查\n  setTimeout(checkAndSchedule, initialDelay);\n}\n\n// 使用示例：每隔10秒检查一次页面是否包含\"特定字符串\"，\n// 如果找到，则下次检查的时间间隔变为100秒\ncheckContentAndAdjustInterval(\"特定字符串\", 10000, 100000);\n```\n\n这段代码首先定义了一个 `checkContentAndAdjustInterval`函数，它接受三个参数：要搜索的字符串 `searchString`、初始的检查间隔时间 `initialDelay`（以毫秒为单位）、以及在找到字符串后新的检查间隔时间 `newDelay`。\n\n在 `checkContentAndAdjustInterval`函数内部，定义了另一个名为 `checkAndSchedule`的函数。`checkAndSchedule`函数首先检查当前页面的内容是否包含指定的字符串。如果包含，它将使用 `console.log`输出一个消息，并使用新的延迟时间 `newDelay`来安排下一次执行。如果不包含指定的字符串，它将继续使用初始的延迟时间 `initialDelay`来安排下一次执行。\n\n最后，`checkContentAndAdjustInterval`函数通过调用 `setTimeout`并传入 `checkAndSchedule`函数和初始延迟时间 `initialDelay`来启动整个检查流程。\n\n这种方法的好处是你可以灵活地控制检查的间隔时间，而且它在满足特定条件后能够自动调整这个间隔，非常适合需要根据条件动态调整检查频率的场景。\n\n## NFS 常用指令\n\n主要参考：[如何在 Ubuntu 20.04 上安装和配置 NFS 服务器？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/480960387)\n\n### 服务端绑定 NFS\n\n直接绑定：\n\n```text\nsudo mount --bind /opt/backups /srv/nfs4/backups\nsudo mount --bind /var/www /srv/nfs4/www\n```\n\n要在重新启动后使绑定挂载永久化，请打开/etc/fstab文件：\n\n```text\nsudo nano /etc/fstab\n```\n\n并添加以下行：\n\n```text\n/etc/fstab\n/opt/backups /srv/nfs4/backups  none   bind   0   0\n/var/www     /srv/nfs4/www      none   bind   0   0\n```\n\n`/var/www `为本地需要绑定的文件夹，`/srv/nfs4/www `为 NFS 管理的文件夹，必须以 `/srv/nfs4`开头。\n\n绑定后，服务端可以修改 `/var/www `内的文件，会被自动同步到 NFS 绑定的目录下。\n\n### 客户端绑定 NFS\n\n为挂载点创建两个新目录：\n\n```text\nsudo mkdir -p /backups\nsudo mkdir -p /srv/www\n```\n\n您可以在任何您想要的位置创建目录。\n\n使用以下命令挂载导出的文件系统mount ：\n\n```text\nsudo mount -t nfs -o vers=4 192.168.33.10:/backups /backups\nsudo mount -t nfs -o vers=4 192.168.33.10:/www /srv/www\n```\n\n要在重新启动时永久挂载，请打开/etc/fstab文件并添加以下行：\n\n```text\nsudo nano /etc/fstab\n\n/etc/fstab\n192.168.33.10:/backups /backups   nfs   defaults,timeo=900,retrans=5,_netdev 0 0\n192.168.33.10:/www /srv/www       nfs   defaults,timeo=900,retrans=5,_netdev 0 0\n```\n\n有关挂载 NFS 文件系统时可用选项的信息，请输入man nfs您的终端。\n\n### IP 检测\n\n编辑配置文件\n\n```\nsudo nano /etc/exports\n```\n\n配置文件例子：\n\n```\n/srv/nfs4         192.168.33.0/24(rw,sync,no_subtree_check,crossmnt,fsid=0)\n/srv/nfs4/backups 192.168.33.0/24(ro,sync,no_subtree_check) 192.168.33.3(rw,sync,no_subtree_check)\n/srv/nfs4/www     192.168.33.20(rw,sync,no_subtree_check)\n```\n\n其中，192.168.33.0/24 等为需要过滤的 ip 规则。\n\n应用 ip 设置\n\n```\nsudo exportfs -ar\n```\n\n查看 ip 检测\n\n```\nsudo exportfs -v\n```\n\n### 重启 NFS\n\n```\nsudo /etc/init.d/nfs-kernel-server restart\n```\n\n## WSL 相关\n\n### WSL 寄了！\n\n可能是因为配置 nfs 的原因吧，wsl 关掉之后就打不开了。\n\n* wsl 无响应。\n* 当 ubuntu 处于停止状态时，`wsl --list`, `wsl --status` 有响应；但我一旦尝试运行 `wsl` 以启动 ubuntu，就无响应了。\n* `wsl --help` 一直没问题。\n\n怀疑是配置 `/etc/fstab` 的时候出的问题，导致 wsl 无响应。\n\n后来的解决方案：\n\n1. 把 `ext4.vhdx` 备份了一份。\n2. 卸载 ubuntu distro，重新安装了一遍 ubuntu 22.04。\n3. `wsl --mount --vhd` 将 `ext4.vhdx` 挂到新安装的 ubuntu wsl 上。\n\n幸好 `ext4.vhdx` 还在。\n\n另外，挂完 `ext4.vhdx` 后，我将存有 `ext4.vhdx` 的移动硬盘拔出，然后重新打开 wsl，发现出现了同样的问题。这样就验证了我的假说：\n\n* 我设置了开机默认挂载 nfs 硬盘，连接远程的服务器。\n* nfs 服务器因为一些原因没连上。\n* wsl 文件系统因为挂载的硬盘找不到了，发生错误。\n* wsl 在启动界面无响应。\n\n重启了电脑，发现之前 `wsl --mount` 挂载的 `ext4.vhdx` 已经被清空了，证明 wsl --mount 命令的效果在重启之后清空了。\n\n### yarn add hasura-cli 安装失败\n\n报错：\n\n```\nCommand: node dist/index.js\nArguments: \nDirectory: /home/guoyun812/eesast/hasura/node_modules/hasura-cli\nOutput:\nhasura-cli@2.36.1\nDownloading Hasura CLI binary v2.36.1 from https://github.com/hasura/graphql-engine/releases/download/v2.36.1/cli-hasura-linux-amd64\n\n\nhasura-cli@2.36.1\nError! Failed to install Hasura CLI binary.\nTry npm uninstall hasura-cli or yarn remove hasura-cli and then reinstall it.\nIf the issue occurs repeatedly, check if your network can access https://github.com as the the Hasura CLI binary file is hosted on Github.\nYou can report the issue on https://github.com/jjangga0214/hasura-cli/issues with error message.\n```\n\n解决方案：手动下载 hasura-cli 的二进制文件，并粘贴到 `node_modules/hasura/`。\n\n## SSH 相关\n\n### ssh 端口转发的坑点\n\n转发之前一定要在远程服务器的 `/etc/ssh/sshd_config` 中配置：\n\nGatewayPorts **yes（或 clientspecified，不能是 no）**\n\n具体的原理我说不清楚。大概意思是，我们通常用以下方式进行远程端口转发：\n\n```\nssh -CNgv -R <remote_ip>:<port>:<local_ip>:<port> <hostname>\n```\n\n一般会把 remote_ip 设为 0.0.0.0，以绑定到所有接口。但是，若不设置 GatewayPorts，则远程服务器上仍然只有 localhost 能够访问这个端口，如果你在 docker 容器内访问这个端口是不行的。我花了很多时间去排除 docker 容器到主机上的连接是否正确，包括使用 docker 的网关地址/host.docker.internal、修改 iptables、修改防火墙，都没什么用。因为实际上这个 ip 可以 ping 通，根本就不是 ip 地址或者防火墙的问题，是 ssh 转发里面限制了网关访问端口。\n\nclaude-sonnet 给出的解释如下：\n\n| 配置选项            | 客户端命令                      | 实际绑定地址         | 说明           |\n| ------------------- | ------------------------------- | -------------------- | -------------- |\n| `no`              | `ssh -R 8000:...`             | `127.0.0.1:8000`   | 强制 localhost |\n| `no`              | `ssh -R 0.0.0.0:8000:...`     | `127.0.0.1:8000`   | 忽略客户端指定 |\n| `yes`             | `ssh -R 8000:...`             | `0.0.0.0:8000`     | 默认所有接口   |\n| `yes`             | `ssh -R 192.168.1.1:8000:...` | `192.168.1.1:8000` | 允许指定       |\n| `clientspecified` | `ssh -R 8000:...`             | `127.0.0.1:8000`   | 默认 localhost |\n| `clientspecified` | `ssh -R 0.0.0.0:8000:...`     | `0.0.0.0:8000`     | 允许客户端指定 |\n\n可以看到，如果服务端配置为 no，无论客户端怎么强制绑 `0.0.0.0` 都没用的，还是变成了 `localhost:8000` 的服务。如果设置为 yes，那么默认就绑 `0.0.0.0:8000`，要指定也是可以的。\n\n### 服务器共用怎么设置自己的环境变量\n\n在 vscode user settings 中添加：\n\n```\n    \"terminal.integrated.env.linux\": {\n        \"ZZZ_INIT_COMMAND\": \"1\"\n    },\n```\n\n在启动文件（例如 `.bashrc`）中添加：\n\n```bash\n# used for zzz's bash init if the env var below is defined\nif [[ -n $ZZZ_INIT_COMMAND ]]; then\n    echo \"Hello, welcome to tsz's bash shell!\"\n    eval \"source /home/ubuntu/tsz/config.sh\"\nfi\n```\n\n### ssh 服务器\n\n使用 `ssh-keygen` 时最好设置一个口令，否则别人也能用这个密钥。\n\n### 常用命令\n\nssh 反向代理（服务器端口映射到本地端口），挂在后台\n\n```\nssh -CqTfnN -R <remote_port>:localhost:<local_port>  -v  username@hostname -p <ssh_port>\n```\n\nssh 前向代理（本地端口映射到服务器端口）\n\n```\nssh -CqTfnN -L <local_port>:localhost:<remote_port>  -v  username@hostname -p <ssh_port>\n```\n\n将请求转发到 github\n\n```\nssh -CqTfnN -L <local_port>:github.com:22 -v  username@hostname -p <ssh_port>\n```\n\n### ssh agent\n\n启动 ssh agent，并查看 pid\n\n```\neval $(ssh-agent -s)\n```\n\n查看当前 agent 有哪些密钥\n\n```\nssh-add -l # 查看公钥的 sha256\nssh-add -L # 查看完整公钥\n```\n\n添加密钥\n\n```\nssh-add <private_key_path>\n```\n\n## Node.js\n\n### listen EACCES: permission denied 0.0.0.0:3000\n\n1、先判断是否是端口占用的问题导致的 `netstat -ano| findstr 3000`\n\n关闭相关进程（cmd）\n\n```\ntaskkill /PID <process_id> /F\n```\n\n发现并没有程序在使用这个端口\n\n2、改用管理员再运行一遍\n\n发现仍然不行\n\n3、使用管理员权限运行以下命令\n\n`net stop winnat`\n\n`net start winnat`\n\n## AI\n\n### Could not load symbol cudnnGetLibConfig\n\n环境变量的问题，如果你在环境变量中将 LD_LIBRARY_PATH 指向了不正确的版本会导致这里出问题。\n\n运行下面的代码以获得正确的 cudnn 路径：\n\n```\nexport LD_LIBRARY_PATH=`python3  -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + \":\" + os.path.dirname(nvidia.cudnn.lib.__file__))'`\n```\n\n### /usr/bin/ld: cannot find -lcuda\n\n见[这个 issue](https://github.com/NVlabs/tiny-cuda-nn/issues/183#issuecomment-1342828785)\n\nexport LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs:$LIBRARY_PATH\"\n\nexport LD_LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs:/usr/local/cuda/lib64\"\n\n### Llama 架构\n\n![1713000493686](../images/stuffs/1713000493686.png)\n\n### 使用 Tensorboard\n\n```python-repl\nfrom torch.utils.tensorboard import SummaryWriter\nfrom accelerate.tracking import GeneralTracker, on_main_process\nimport os\nfrom typing import Union\n\n# 0. 自定义追踪器\nclass MyCustomTracker(GeneralTracker):\n    \"\"\"\n    my custom `Tracker` class that supports `tensorboard`. Should be initialized at the start of your script.\n\n    Args:\n        run_name (`str`):\n            The name of the experiment run\n        logging_dir (`str`, `os.PathLike`):\n            Location for TensorBoard logs to be stored.\n        kwargs:\n            Additional key word arguments passed along to the `tensorboard.SummaryWriter.__init__` method.\n    \"\"\"\n\n    name = \"tensorboard\"\n    requires_logging_directory = True\n\n    @on_main_process\n    def __init__(self, run_name: str, logging_dir: Union[str, os.PathLike],\n                 **kwargs):\n        super().__init__()\n        self.run_name = run_name\n        self.logging_dir = os.path.join(logging_dir, run_name)\n        self.writer = SummaryWriter(self.logging_dir, **kwargs)\n\n    @property\n    def tracker(self):\n        return self.writer\n\n    @on_main_process\n    def add_scalar(self, tag, scalar_value, **kwargs):\n        self.writer.add_scalar(tag=tag, scalar_value=scalar_value, **kwargs)\n\n    @on_main_process\n    def add_text(self, tag, text_string, **kwargs):\n        self.writer.add_text(tag=tag, text_string=text_string, **kwargs)\n\n    @on_main_process\n    def add_figure(self, tag, figure, **kwargs):\n        self.writer.add_figure(tag=tag, figure=figure, **kwargs)\n\n    @on_main_process\n    def add_vector(self, tag, mat, **kwargs):\n        self.writer.add_embedding(tag=tag, mat=mat, **kwargs)\n\n```\n\n### 记录神经元的激活值\n\n```python\nfrom torch import nn\nimport torch\n\nclass TestForHook(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.linear_1 = nn.Linear(in_features=2, out_features=2)\n        self.linear_2 = nn.Linear(in_features=2, out_features=1)\n        self.relu = nn.ReLU()\n        self.relu6 = nn.ReLU6()\n\n    def forward(self, x):\n        linear_1 = self.linear_1(x)\n        linear_2 = self.linear_2(linear_1)\n        relu = self.relu(linear_2)\n        relu6 = self.relu6(relu)\n        layers_in = (x, linear_1, linear_2)\n        layers_out = (linear_1, linear_2, relu)\n        return relu6\n\nfeatures_in_hook = []\nfeatures_out_hook = []\n\ndef hook(module, fea_in, fea_out):\n    print(f\"hook! module: {module}, in: {fea_in}, out: {fea_out}\")\n    features_in_hook.append(fea_in)\n    features_out_hook.append(fea_out)\n    return None\n\nnet = TestForHook()\n\n\"\"\"\n# 第一种写法，按照类型勾，但如果有重复类型的layer比较复杂\nnet_chilren = net.children()\nfor child in net_chilren:\n    if not isinstance(child, nn.ReLU6):\n        child.register_forward_hook(hook=hook)\n\"\"\"\n\n\"\"\"\n推荐下面我改的这种写法，因为我自己的网络中，在Sequential中有很多层，\n这种方式可以直接先print(net)一下，找出自己所需要那个layer的名称，按名称勾出来\n\"\"\"\n\nprint(net)\n\nlayer_name = 'linear_1'\nfor (name, module) in net.named_modules():\n    if name == layer_name:\n        module.register_forward_hook(hook=hook)\n\nprint(features_in_hook)  # 勾的是指定层的输入\nprint(features_out_hook)  # 勾的是指定层的输出\n\nrand_x = torch.rand(1, 2)\nprint(f\"input x: {rand_x}\")\nresult = net(rand_x)\nprint(f\"result: {result}\")\nprint(f\"features in: {features_in_hook}\")\nprint(f\"features out: {features_out_hook}\")\n```\n","slug":"stuffs","published":1,"updated":"2025-09-04T13:47:06.003Z","_id":"clu1gtfi0000srsug08cj3g8s","comments":1,"layout":"post","photos":[],"link":"","content":"<p>批处理命令设置环境变量<br>set path&#x3D;xxxx</p>\n<h2 id=\"好玩的东西\"><a href=\"#好玩的东西\" class=\"headerlink\" title=\"好玩的东西\"></a>好玩的东西</h2><h3 id=\"Lambda-递归\"><a href=\"#Lambda-递归\" class=\"headerlink\" title=\"Lambda 递归\"></a>Lambda 递归</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = (<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span> n:(h(h, n)))(<span class=\"keyword\">lambda</span> f,n: n + f(f, n-<span class=\"number\">1</span>) <span class=\"keyword\">if</span> n &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"comment\"># &gt;&gt;&gt; f(10)</span></span><br><span class=\"line\"><span class=\"comment\"># 55</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Lambda-计数器\"><a href=\"#Lambda-计数器\" class=\"headerlink\" title=\"Lambda 计数器\"></a>Lambda 计数器</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f,n = (<span class=\"keyword\">lambda</span> f,n=<span class=\"number\">0</span>: ((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>), n))(<span class=\"keyword\">lambda</span> f,n: ((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>), n))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>更好玩的版本！</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f,n = (<span class=\"keyword\">lambda</span> f,n=<span class=\"number\">0</span>: ((<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span>: h(h))((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>)), n))(<span class=\"keyword\">lambda</span> f,n: ((<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span>: h(h))((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>)), n))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br></pre></td></tr></table></figure>\n\n<p>与上一个版本效果相同：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = (<span class=\"keyword\">lambda</span> g: g(<span class=\"keyword\">lambda</span> f,n=<span class=\"number\">0</span>: (g((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>)), n)))(<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span>: h(h))</span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br></pre></td></tr></table></figure>\n\n<p>更加简洁：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = (<span class=\"keyword\">lambda</span> g: g(<span class=\"keyword\">lambda</span> f,t, n=<span class=\"number\">0</span>: n <span class=\"keyword\">if</span> t == <span class=\"number\">0</span> <span class=\"keyword\">else</span> g((<span class=\"keyword\">lambda</span> f, t, n: <span class=\"keyword\">lambda</span> x, u=t, m=n: f(x, u, m))(f, t, n+<span class=\"number\">1</span>))))((<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span> t=<span class=\"number\">1</span>: h(h, t)))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f(<span class=\"number\">0</span>))</span><br><span class=\"line\">f = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f(<span class=\"number\">0</span>))</span><br><span class=\"line\">f = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f(<span class=\"number\">0</span>))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"js爬虫\"><a href=\"#js爬虫\" class=\"headerlink\" title=\"js爬虫\"></a>js爬虫</h2><p><strong>1.js保存字符串到本地</strong></p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">saveShareContent</span> (content, fileName) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">let</span> downLink = <span class=\"variable language_\">document</span>.<span class=\"title function_\">createElement</span>(<span class=\"string\">&#x27;a&#x27;</span>)</span><br><span class=\"line\">    downLink.<span class=\"property\">download</span> = fileName</span><br><span class=\"line\">    <span class=\"comment\">//字符内容转换为blod地址</span></span><br><span class=\"line\">    <span class=\"keyword\">let</span> blob = <span class=\"keyword\">new</span> <span class=\"title class_\">Blob</span>([content])</span><br><span class=\"line\">    downLink.<span class=\"property\">href</span> = <span class=\"variable constant_\">URL</span>.<span class=\"title function_\">createObjectURL</span>(blob)</span><br><span class=\"line\">    <span class=\"comment\">// 链接插入到页面</span></span><br><span class=\"line\">    <span class=\"variable language_\">document</span>.<span class=\"property\">body</span>.<span class=\"title function_\">appendChild</span>(downLink)</span><br><span class=\"line\">    downLink.<span class=\"title function_\">click</span>()</span><br><span class=\"line\">    <span class=\"comment\">// 移除下载链接</span></span><br><span class=\"line\">    <span class=\"variable language_\">document</span>.<span class=\"property\">body</span>.<span class=\"title function_\">removeChild</span>(downLink)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>2. 包含iframe&#x2F;#document的文档</strong></p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> ifram = <span class=\"variable language_\">document</span>.<span class=\"title function_\">querySelector</span>(<span class=\"string\">&quot;#iframe&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">var</span> idoc = ifram.<span class=\"property\">contentWindow</span>.<span class=\"property\">document</span>;</span><br><span class=\"line\"><span class=\"comment\">//console.log(idoc);</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> ifram2 = idoc.<span class=\"title function_\">querySelector</span>(<span class=\"string\">&quot;#ext-gen1046 &gt; iframe&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">var</span> idoc2 = ifram2.<span class=\"property\">contentWindow</span>.<span class=\"property\">document</span>;</span><br><span class=\"line\"><span class=\"comment\">//console.log(idoc2);</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> ifram3 = idoc2.<span class=\"title function_\">querySelector</span>(<span class=\"string\">&quot;#frame_content&quot;</span>);</span><br><span class=\"line\"><span class=\"keyword\">var</span> idoc3 = ifram3.<span class=\"property\">contentWindow</span>.<span class=\"property\">document</span>;</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(idoc3);</span><br><span class=\"line\">text = idoc3.<span class=\"property\">documentElement</span>.<span class=\"property\">innerHTML</span>;</span><br></pre></td></tr></table></figure>\n\n<p>层层剥开，否则在iframe内部的元素会定位失败。在F12界面右键选择“复制js路径”可以获取 <code>querySeletor</code>语句。</p>\n<p><strong>3.滚动至最低部</strong></p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"keyword\">var</span> ele = <span class=\"variable language_\">document</span>.<span class=\"property\">documentElement</span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(ele.<span class=\"property\">scrollHeight</span> &gt; ele.<span class=\"property\">clientHeight</span>) &#123;</span><br><span class=\"line\"><span class=\"comment\">//设置滚动条到最底部</span></span><br><span class=\"line\">ele.<span class=\"property\">scrollTop</span> = ele.<span class=\"property\">scrollHeight</span>;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>必要时可以增加 <code>setTimeout</code>等待网页加载完毕。</p>\n<p><strong>4.逐步滚动</strong></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">pos = <span class=\"variable language_\">document</span>.<span class=\"property\">documentElement</span>.<span class=\"property\">scrollTop</span>;</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(pos);</span><br><span class=\"line\"><span class=\"keyword\">var</span> id = <span class=\"built_in\">setInterval</span>(</span><br><span class=\"line\">    <span class=\"keyword\">function</span> (<span class=\"params\"></span>)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (count &lt; <span class=\"number\">500</span>) &#123;</span><br><span class=\"line\">            <span class=\"variable language_\">document</span>.<span class=\"property\">documentElement</span>.<span class=\"property\">scrollTop</span>++;</span><br><span class=\"line\">            count++;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"built_in\">clearInterval</span>(id);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">, <span class=\"number\">2</span>);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"electron-vue\"><a href=\"#electron-vue\" class=\"headerlink\" title=\"electron-vue\"></a>electron-vue</h2><p><strong>如何引入.node文件</strong></p>\n<p>需要将.node文件放在public文件夹下，引用时可以用相对路径也可以用 <code>__static</code>+文件名。</p>\n<p>需要安装<a href=\"mailto:&#x6e;&#111;&#x64;&#101;&#45;&#x6c;&#111;&#x61;&#x64;&#x65;&#x72;&#x40;&#x31;&#46;&#x30;&#x2e;&#x33;\">&#x6e;&#111;&#x64;&#101;&#45;&#x6c;&#111;&#x61;&#x64;&#x65;&#x72;&#x40;&#x31;&#46;&#x30;&#x2e;&#x33;</a>。太高的版本会导致问题。</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> addon = <span class=\"built_in\">require</span>(<span class=\"string\">&quot;node-loader!../public/addon.node&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>在vue中使用ipcRenderer</strong></p>\n<p>主进程中引入ipcMain没啥大问题。<br>在vue文件中引入ipcRenderer，需要先在vue.config.js中配置</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">nodeIntegration</span>: <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">pluginOptions</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">electronBuilder</span>: &#123;</span><br><span class=\"line\">      <span class=\"comment\">// 在vue中能引入electron模块</span></span><br><span class=\"line\">      <span class=\"attr\">nodeIntegration</span>: <span class=\"literal\">true</span>,</span><br></pre></td></tr></table></figure>\n\n<p>然后在各个vue文件中引入</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> &#123; ipcRenderer &#125; <span class=\"keyword\">from</span> <span class=\"string\">&#x27;electron&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"math\"><a href=\"#math\" class=\"headerlink\" title=\"math\"></a>math</h2><p>一个只跟a, b中最大的那一个有关的积分：</p>\n<div>$$\n\\int_{0}^{\\pi}\\frac{\\sin \\theta}{\\sqrt{a^2+b^2-2ab\\cos\\theta}}\\mathrm d\\theta = \\frac{1}{ab}(|a+b| - |a-b|)\n$$</div>\n\n<h2 id=\"js-小技巧\"><a href=\"#js-小技巧\" class=\"headerlink\" title=\"js 小技巧\"></a>js 小技巧</h2><h3 id=\"可变定时检测\"><a href=\"#可变定时检测\" class=\"headerlink\" title=\"可变定时检测\"></a>可变定时检测</h3><p>问：每隔10秒检测一次当前页面是否包含某字符串，如果包含，则 console.log，下次检测的时间变为 100 秒</p>\n<p>答：为了实现这个功能，你可以使用 <code>setInterval</code>函数来设置一个定期执行的任务。然而，因为你想在满足特定条件时改变间隔时间，你可能需要使用 <code>setTimeout</code>来代替，因为 <code>setInterval</code>的间隔时间一旦设定就无法改变。以下是如何实现这一逻辑的示例代码：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">checkContentAndAdjustInterval</span>(<span class=\"params\">searchString, initialDelay, newDelay</span>) &#123;</span><br><span class=\"line\">  <span class=\"comment\">// 定义一个函数，用于检查页面内容并根据条件调整定时器</span></span><br><span class=\"line\">  <span class=\"keyword\">function</span> <span class=\"title function_\">checkAndSchedule</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 检查文档中是否包含特定字符串</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable language_\">document</span>.<span class=\"property\">body</span>.<span class=\"property\">textContent</span>.<span class=\"title function_\">includes</span>(searchString)) &#123;</span><br><span class=\"line\">      <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"string\">`页面包含指定字符串: <span class=\"subst\">$&#123;searchString&#125;</span>`</span>);</span><br><span class=\"line\">      <span class=\"comment\">// 如果找到字符串，设置下一次检查的延时为 newDelay</span></span><br><span class=\"line\">      <span class=\"built_in\">setTimeout</span>(checkAndSchedule, newDelay);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">      <span class=\"comment\">// 如果没有找到字符串，保持原来的检查频率</span></span><br><span class=\"line\">      <span class=\"built_in\">setTimeout</span>(checkAndSchedule, initialDelay);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 启动循环检查</span></span><br><span class=\"line\">  <span class=\"built_in\">setTimeout</span>(checkAndSchedule, initialDelay);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 使用示例：每隔10秒检查一次页面是否包含&quot;特定字符串&quot;，</span></span><br><span class=\"line\"><span class=\"comment\">// 如果找到，则下次检查的时间间隔变为100秒</span></span><br><span class=\"line\"><span class=\"title function_\">checkContentAndAdjustInterval</span>(<span class=\"string\">&quot;特定字符串&quot;</span>, <span class=\"number\">10000</span>, <span class=\"number\">100000</span>);</span><br></pre></td></tr></table></figure>\n\n<p>这段代码首先定义了一个 <code>checkContentAndAdjustInterval</code>函数，它接受三个参数：要搜索的字符串 <code>searchString</code>、初始的检查间隔时间 <code>initialDelay</code>（以毫秒为单位）、以及在找到字符串后新的检查间隔时间 <code>newDelay</code>。</p>\n<p>在 <code>checkContentAndAdjustInterval</code>函数内部，定义了另一个名为 <code>checkAndSchedule</code>的函数。<code>checkAndSchedule</code>函数首先检查当前页面的内容是否包含指定的字符串。如果包含，它将使用 <code>console.log</code>输出一个消息，并使用新的延迟时间 <code>newDelay</code>来安排下一次执行。如果不包含指定的字符串，它将继续使用初始的延迟时间 <code>initialDelay</code>来安排下一次执行。</p>\n<p>最后，<code>checkContentAndAdjustInterval</code>函数通过调用 <code>setTimeout</code>并传入 <code>checkAndSchedule</code>函数和初始延迟时间 <code>initialDelay</code>来启动整个检查流程。</p>\n<p>这种方法的好处是你可以灵活地控制检查的间隔时间，而且它在满足特定条件后能够自动调整这个间隔，非常适合需要根据条件动态调整检查频率的场景。</p>\n<h2 id=\"NFS-常用指令\"><a href=\"#NFS-常用指令\" class=\"headerlink\" title=\"NFS 常用指令\"></a>NFS 常用指令</h2><p>主要参考：<a href=\"https://zhuanlan.zhihu.com/p/480960387\">如何在 Ubuntu 20.04 上安装和配置 NFS 服务器？ - 知乎 (zhihu.com)</a></p>\n<h3 id=\"服务端绑定-NFS\"><a href=\"#服务端绑定-NFS\" class=\"headerlink\" title=\"服务端绑定 NFS\"></a>服务端绑定 NFS</h3><p>直接绑定：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mount --bind /opt/backups /srv/nfs4/backups</span><br><span class=\"line\">sudo mount --bind /var/www /srv/nfs4/www</span><br></pre></td></tr></table></figure>\n\n<p>要在重新启动后使绑定挂载永久化，请打开&#x2F;etc&#x2F;fstab文件：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo nano /etc/fstab</span><br></pre></td></tr></table></figure>\n\n<p>并添加以下行：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/fstab</span><br><span class=\"line\">/opt/backups /srv/nfs4/backups  none   bind   0   0</span><br><span class=\"line\">/var/www     /srv/nfs4/www      none   bind   0   0</span><br></pre></td></tr></table></figure>\n\n<p><code>/var/www </code>为本地需要绑定的文件夹，<code>/srv/nfs4/www </code>为 NFS 管理的文件夹，必须以 <code>/srv/nfs4</code>开头。</p>\n<p>绑定后，服务端可以修改 <code>/var/www </code>内的文件，会被自动同步到 NFS 绑定的目录下。</p>\n<h3 id=\"客户端绑定-NFS\"><a href=\"#客户端绑定-NFS\" class=\"headerlink\" title=\"客户端绑定 NFS\"></a>客户端绑定 NFS</h3><p>为挂载点创建两个新目录：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir -p /backups</span><br><span class=\"line\">sudo mkdir -p /srv/www</span><br></pre></td></tr></table></figure>\n\n<p>您可以在任何您想要的位置创建目录。</p>\n<p>使用以下命令挂载导出的文件系统mount ：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mount -t nfs -o vers=4 192.168.33.10:/backups /backups</span><br><span class=\"line\">sudo mount -t nfs -o vers=4 192.168.33.10:/www /srv/www</span><br></pre></td></tr></table></figure>\n\n<p>要在重新启动时永久挂载，请打开&#x2F;etc&#x2F;fstab文件并添加以下行：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo nano /etc/fstab</span><br><span class=\"line\"></span><br><span class=\"line\">/etc/fstab</span><br><span class=\"line\">192.168.33.10:/backups /backups   nfs   defaults,timeo=900,retrans=5,_netdev 0 0</span><br><span class=\"line\">192.168.33.10:/www /srv/www       nfs   defaults,timeo=900,retrans=5,_netdev 0 0</span><br></pre></td></tr></table></figure>\n\n<p>有关挂载 NFS 文件系统时可用选项的信息，请输入man nfs您的终端。</p>\n<h3 id=\"IP-检测\"><a href=\"#IP-检测\" class=\"headerlink\" title=\"IP 检测\"></a>IP 检测</h3><p>编辑配置文件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo nano /etc/exports</span><br></pre></td></tr></table></figure>\n\n<p>配置文件例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/srv/nfs4         192.168.33.0/24(rw,sync,no_subtree_check,crossmnt,fsid=0)</span><br><span class=\"line\">/srv/nfs4/backups 192.168.33.0/24(ro,sync,no_subtree_check) 192.168.33.3(rw,sync,no_subtree_check)</span><br><span class=\"line\">/srv/nfs4/www     192.168.33.20(rw,sync,no_subtree_check)</span><br></pre></td></tr></table></figure>\n\n<p>其中，192.168.33.0&#x2F;24 等为需要过滤的 ip 规则。</p>\n<p>应用 ip 设置</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo exportfs -ar</span><br></pre></td></tr></table></figure>\n\n<p>查看 ip 检测</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo exportfs -v</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"重启-NFS\"><a href=\"#重启-NFS\" class=\"headerlink\" title=\"重启 NFS\"></a>重启 NFS</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo /etc/init.d/nfs-kernel-server restart</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"WSL-相关\"><a href=\"#WSL-相关\" class=\"headerlink\" title=\"WSL 相关\"></a>WSL 相关</h2><h3 id=\"WSL-寄了！\"><a href=\"#WSL-寄了！\" class=\"headerlink\" title=\"WSL 寄了！\"></a>WSL 寄了！</h3><p>可能是因为配置 nfs 的原因吧，wsl 关掉之后就打不开了。</p>\n<ul>\n<li>wsl 无响应。</li>\n<li>当 ubuntu 处于停止状态时，<code>wsl --list</code>, <code>wsl --status</code> 有响应；但我一旦尝试运行 <code>wsl</code> 以启动 ubuntu，就无响应了。</li>\n<li><code>wsl --help</code> 一直没问题。</li>\n</ul>\n<p>怀疑是配置 <code>/etc/fstab</code> 的时候出的问题，导致 wsl 无响应。</p>\n<p>后来的解决方案：</p>\n<ol>\n<li>把 <code>ext4.vhdx</code> 备份了一份。</li>\n<li>卸载 ubuntu distro，重新安装了一遍 ubuntu 22.04。</li>\n<li><code>wsl --mount --vhd</code> 将 <code>ext4.vhdx</code> 挂到新安装的 ubuntu wsl 上。</li>\n</ol>\n<p>幸好 <code>ext4.vhdx</code> 还在。</p>\n<p>另外，挂完 <code>ext4.vhdx</code> 后，我将存有 <code>ext4.vhdx</code> 的移动硬盘拔出，然后重新打开 wsl，发现出现了同样的问题。这样就验证了我的假说：</p>\n<ul>\n<li>我设置了开机默认挂载 nfs 硬盘，连接远程的服务器。</li>\n<li>nfs 服务器因为一些原因没连上。</li>\n<li>wsl 文件系统因为挂载的硬盘找不到了，发生错误。</li>\n<li>wsl 在启动界面无响应。</li>\n</ul>\n<p>重启了电脑，发现之前 <code>wsl --mount</code> 挂载的 <code>ext4.vhdx</code> 已经被清空了，证明 wsl –mount 命令的效果在重启之后清空了。</p>\n<h3 id=\"yarn-add-hasura-cli-安装失败\"><a href=\"#yarn-add-hasura-cli-安装失败\" class=\"headerlink\" title=\"yarn add hasura-cli 安装失败\"></a>yarn add hasura-cli 安装失败</h3><p>报错：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Command: node dist/index.js</span><br><span class=\"line\">Arguments: </span><br><span class=\"line\">Directory: /home/guoyun812/eesast/hasura/node_modules/hasura-cli</span><br><span class=\"line\">Output:</span><br><span class=\"line\">hasura-cli@2.36.1</span><br><span class=\"line\">Downloading Hasura CLI binary v2.36.1 from https://github.com/hasura/graphql-engine/releases/download/v2.36.1/cli-hasura-linux-amd64</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">hasura-cli@2.36.1</span><br><span class=\"line\">Error! Failed to install Hasura CLI binary.</span><br><span class=\"line\">Try npm uninstall hasura-cli or yarn remove hasura-cli and then reinstall it.</span><br><span class=\"line\">If the issue occurs repeatedly, check if your network can access https://github.com as the the Hasura CLI binary file is hosted on Github.</span><br><span class=\"line\">You can report the issue on https://github.com/jjangga0214/hasura-cli/issues with error message.</span><br></pre></td></tr></table></figure>\n\n<p>解决方案：手动下载 hasura-cli 的二进制文件，并粘贴到 <code>node_modules/hasura/</code>。</p>\n<h2 id=\"SSH-相关\"><a href=\"#SSH-相关\" class=\"headerlink\" title=\"SSH 相关\"></a>SSH 相关</h2><h3 id=\"ssh-端口转发的坑点\"><a href=\"#ssh-端口转发的坑点\" class=\"headerlink\" title=\"ssh 端口转发的坑点\"></a>ssh 端口转发的坑点</h3><p>转发之前一定要在远程服务器的 <code>/etc/ssh/sshd_config</code> 中配置：</p>\n<p>GatewayPorts <strong>yes（或 clientspecified，不能是 no）</strong></p>\n<p>具体的原理我说不清楚。大概意思是，我们通常用以下方式进行远程端口转发：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CNgv -R &lt;remote_ip&gt;:&lt;port&gt;:&lt;local_ip&gt;:&lt;port&gt; &lt;hostname&gt;</span><br></pre></td></tr></table></figure>\n\n<p>一般会把 remote_ip 设为 0.0.0.0，以绑定到所有接口。但是，若不设置 GatewayPorts，则远程服务器上仍然只有 localhost 能够访问这个端口，如果你在 docker 容器内访问这个端口是不行的。我花了很多时间去排除 docker 容器到主机上的连接是否正确，包括使用 docker 的网关地址&#x2F;host.docker.internal、修改 iptables、修改防火墙，都没什么用。因为实际上这个 ip 可以 ping 通，根本就不是 ip 地址或者防火墙的问题，是 ssh 转发里面限制了网关访问端口。</p>\n<p>claude-sonnet 给出的解释如下：</p>\n<table>\n<thead>\n<tr>\n<th>配置选项</th>\n<th>客户端命令</th>\n<th>实际绑定地址</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>no</code></td>\n<td><code>ssh -R 8000:...</code></td>\n<td><code>127.0.0.1:8000</code></td>\n<td>强制 localhost</td>\n</tr>\n<tr>\n<td><code>no</code></td>\n<td><code>ssh -R 0.0.0.0:8000:...</code></td>\n<td><code>127.0.0.1:8000</code></td>\n<td>忽略客户端指定</td>\n</tr>\n<tr>\n<td><code>yes</code></td>\n<td><code>ssh -R 8000:...</code></td>\n<td><code>0.0.0.0:8000</code></td>\n<td>默认所有接口</td>\n</tr>\n<tr>\n<td><code>yes</code></td>\n<td><code>ssh -R 192.168.1.1:8000:...</code></td>\n<td><code>192.168.1.1:8000</code></td>\n<td>允许指定</td>\n</tr>\n<tr>\n<td><code>clientspecified</code></td>\n<td><code>ssh -R 8000:...</code></td>\n<td><code>127.0.0.1:8000</code></td>\n<td>默认 localhost</td>\n</tr>\n<tr>\n<td><code>clientspecified</code></td>\n<td><code>ssh -R 0.0.0.0:8000:...</code></td>\n<td><code>0.0.0.0:8000</code></td>\n<td>允许客户端指定</td>\n</tr>\n</tbody></table>\n<p>可以看到，如果服务端配置为 no，无论客户端怎么强制绑 <code>0.0.0.0</code> 都没用的，还是变成了 <code>localhost:8000</code> 的服务。如果设置为 yes，那么默认就绑 <code>0.0.0.0:8000</code>，要指定也是可以的。</p>\n<h3 id=\"服务器共用怎么设置自己的环境变量\"><a href=\"#服务器共用怎么设置自己的环境变量\" class=\"headerlink\" title=\"服务器共用怎么设置自己的环境变量\"></a>服务器共用怎么设置自己的环境变量</h3><p>在 vscode user settings 中添加：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;terminal.integrated.env.linux&quot;: &#123;</span><br><span class=\"line\">    &quot;ZZZ_INIT_COMMAND&quot;: &quot;1&quot;</span><br><span class=\"line\">&#125;,</span><br></pre></td></tr></table></figure>\n\n<p>在启动文件（例如 <code>.bashrc</code>）中添加：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># used for zzz&#x27;s bash init if the env var below is defined</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [[ -n <span class=\"variable\">$ZZZ_INIT_COMMAND</span> ]]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">&quot;Hello, welcome to tsz&#x27;s bash shell!&quot;</span></span><br><span class=\"line\">    <span class=\"built_in\">eval</span> <span class=\"string\">&quot;source /home/ubuntu/tsz/config.sh&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ssh-服务器\"><a href=\"#ssh-服务器\" class=\"headerlink\" title=\"ssh 服务器\"></a>ssh 服务器</h3><p>使用 <code>ssh-keygen</code> 时最好设置一个口令，否则别人也能用这个密钥。</p>\n<h3 id=\"常用命令\"><a href=\"#常用命令\" class=\"headerlink\" title=\"常用命令\"></a>常用命令</h3><p>ssh 反向代理（服务器端口映射到本地端口），挂在后台</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CqTfnN -R &lt;remote_port&gt;:localhost:&lt;local_port&gt;  -v  username@hostname -p &lt;ssh_port&gt;</span><br></pre></td></tr></table></figure>\n\n<p>ssh 前向代理（本地端口映射到服务器端口）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CqTfnN -L &lt;local_port&gt;:localhost:&lt;remote_port&gt;  -v  username@hostname -p &lt;ssh_port&gt;</span><br></pre></td></tr></table></figure>\n\n<p>将请求转发到 github</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CqTfnN -L &lt;local_port&gt;:github.com:22 -v  username@hostname -p &lt;ssh_port&gt;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ssh-agent\"><a href=\"#ssh-agent\" class=\"headerlink\" title=\"ssh agent\"></a>ssh agent</h3><p>启动 ssh agent，并查看 pid</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eval $(ssh-agent -s)</span><br></pre></td></tr></table></figure>\n\n<p>查看当前 agent 有哪些密钥</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-add -l # 查看公钥的 sha256</span><br><span class=\"line\">ssh-add -L # 查看完整公钥</span><br></pre></td></tr></table></figure>\n\n<p>添加密钥</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-add &lt;private_key_path&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Node-js\"><a href=\"#Node-js\" class=\"headerlink\" title=\"Node.js\"></a>Node.js</h2><h3 id=\"listen-EACCES-permission-denied-0-0-0-0-3000\"><a href=\"#listen-EACCES-permission-denied-0-0-0-0-3000\" class=\"headerlink\" title=\"listen EACCES: permission denied 0.0.0.0:3000\"></a>listen EACCES: permission denied 0.0.0.0:3000</h3><p>1、先判断是否是端口占用的问题导致的 <code>netstat -ano| findstr 3000</code></p>\n<p>关闭相关进程（cmd）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">taskkill /PID &lt;process_id&gt; /F</span><br></pre></td></tr></table></figure>\n\n<p>发现并没有程序在使用这个端口</p>\n<p>2、改用管理员再运行一遍</p>\n<p>发现仍然不行</p>\n<p>3、使用管理员权限运行以下命令</p>\n<p><code>net stop winnat</code></p>\n<p><code>net start winnat</code></p>\n<h2 id=\"AI\"><a href=\"#AI\" class=\"headerlink\" title=\"AI\"></a>AI</h2><h3 id=\"Could-not-load-symbol-cudnnGetLibConfig\"><a href=\"#Could-not-load-symbol-cudnnGetLibConfig\" class=\"headerlink\" title=\"Could not load symbol cudnnGetLibConfig\"></a>Could not load symbol cudnnGetLibConfig</h3><p>环境变量的问题，如果你在环境变量中将 LD_LIBRARY_PATH 指向了不正确的版本会导致这里出问题。</p>\n<p>运行下面的代码以获得正确的 cudnn 路径：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LD_LIBRARY_PATH=`python3  -c &#x27;import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + &quot;:&quot; + os.path.dirname(nvidia.cudnn.lib.__file__))&#x27;`</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"x2F-usr-x2F-bin-x2F-ld-cannot-find-lcuda\"><a href=\"#x2F-usr-x2F-bin-x2F-ld-cannot-find-lcuda\" class=\"headerlink\" title=\"&#x2F;usr&#x2F;bin&#x2F;ld: cannot find -lcuda\"></a>&#x2F;usr&#x2F;bin&#x2F;ld: cannot find -lcuda</h3><p>见<a href=\"https://github.com/NVlabs/tiny-cuda-nn/issues/183#issuecomment-1342828785\">这个 issue</a></p>\n<p>export LIBRARY_PATH&#x3D;”&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64&#x2F;stubs:$LIBRARY_PATH”</p>\n<p>export LD_LIBRARY_PATH&#x3D;”&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64&#x2F;stubs:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64”</p>\n<h3 id=\"Llama-架构\"><a href=\"#Llama-架构\" class=\"headerlink\" title=\"Llama 架构\"></a>Llama 架构</h3><p><img src=\"/../images/stuffs/1713000493686.png\" alt=\"1713000493686\" loading=\"lazy\"></p>\n<h3 id=\"使用-Tensorboard\"><a href=\"#使用-Tensorboard\" class=\"headerlink\" title=\"使用 Tensorboard\"></a>使用 Tensorboard</h3><figure class=\"highlight python-repl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from torch.utils.tensorboard import SummaryWriter</span><br><span class=\"line\">from accelerate.tracking import GeneralTracker, on_main_process</span><br><span class=\"line\">import os</span><br><span class=\"line\">from typing import Union</span><br><span class=\"line\"></span><br><span class=\"line\"># 0. 自定义追踪器</span><br><span class=\"line\">class MyCustomTracker(GeneralTracker):</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    my custom `Tracker` class that supports `tensorboard`. Should be initialized at the start of your script.</span><br><span class=\"line\"></span><br><span class=\"line\">    Args:</span><br><span class=\"line\">        run_name (`str`):</span><br><span class=\"line\">            The name of the experiment run</span><br><span class=\"line\">        logging_dir (`str`, `os.PathLike`):</span><br><span class=\"line\">            Location for TensorBoard logs to be stored.</span><br><span class=\"line\">        kwargs:</span><br><span class=\"line\">            Additional key word arguments passed along to the `tensorboard.SummaryWriter.__init__` method.</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    name = &quot;tensorboard&quot;</span><br><span class=\"line\">    requires_logging_directory = True</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def __init__(self, run_name: str, logging_dir: Union[str, os.PathLike],</span><br><span class=\"line\">                 **kwargs):</span><br><span class=\"line\">        super().__init__()</span><br><span class=\"line\">        self.run_name = run_name</span><br><span class=\"line\">        self.logging_dir = os.path.join(logging_dir, run_name)</span><br><span class=\"line\">        self.writer = SummaryWriter(self.logging_dir, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @property</span><br><span class=\"line\">    def tracker(self):</span><br><span class=\"line\">        return self.writer</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_scalar(self, tag, scalar_value, **kwargs):</span><br><span class=\"line\">        self.writer.add_scalar(tag=tag, scalar_value=scalar_value, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_text(self, tag, text_string, **kwargs):</span><br><span class=\"line\">        self.writer.add_text(tag=tag, text_string=text_string, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_figure(self, tag, figure, **kwargs):</span><br><span class=\"line\">        self.writer.add_figure(tag=tag, figure=figure, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_vector(self, tag, mat, **kwargs):</span><br><span class=\"line\">        self.writer.add_embedding(tag=tag, mat=mat, **kwargs)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"记录神经元的激活值\"><a href=\"#记录神经元的激活值\" class=\"headerlink\" title=\"记录神经元的激活值\"></a>记录神经元的激活值</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">TestForHook</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">        self.linear_1 = nn.Linear(in_features=<span class=\"number\">2</span>, out_features=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.linear_2 = nn.Linear(in_features=<span class=\"number\">2</span>, out_features=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.relu = nn.ReLU()</span><br><span class=\"line\">        self.relu6 = nn.ReLU6()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        linear_1 = self.linear_1(x)</span><br><span class=\"line\">        linear_2 = self.linear_2(linear_1)</span><br><span class=\"line\">        relu = self.relu(linear_2)</span><br><span class=\"line\">        relu6 = self.relu6(relu)</span><br><span class=\"line\">        layers_in = (x, linear_1, linear_2)</span><br><span class=\"line\">        layers_out = (linear_1, linear_2, relu)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> relu6</span><br><span class=\"line\"></span><br><span class=\"line\">features_in_hook = []</span><br><span class=\"line\">features_out_hook = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">hook</span>(<span class=\"params\">module, fea_in, fea_out</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;hook! module: <span class=\"subst\">&#123;module&#125;</span>, in: <span class=\"subst\">&#123;fea_in&#125;</span>, out: <span class=\"subst\">&#123;fea_out&#125;</span>&quot;</span>)</span><br><span class=\"line\">    features_in_hook.append(fea_in)</span><br><span class=\"line\">    features_out_hook.append(fea_out)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">net = TestForHook()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\"># 第一种写法，按照类型勾，但如果有重复类型的layer比较复杂</span></span><br><span class=\"line\"><span class=\"string\">net_chilren = net.children()</span></span><br><span class=\"line\"><span class=\"string\">for child in net_chilren:</span></span><br><span class=\"line\"><span class=\"string\">    if not isinstance(child, nn.ReLU6):</span></span><br><span class=\"line\"><span class=\"string\">        child.register_forward_hook(hook=hook)</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">推荐下面我改的这种写法，因为我自己的网络中，在Sequential中有很多层，</span></span><br><span class=\"line\"><span class=\"string\">这种方式可以直接先print(net)一下，找出自己所需要那个layer的名称，按名称勾出来</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net)</span><br><span class=\"line\"></span><br><span class=\"line\">layer_name = <span class=\"string\">&#x27;linear_1&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (name, module) <span class=\"keyword\">in</span> net.named_modules():</span><br><span class=\"line\">    <span class=\"keyword\">if</span> name == layer_name:</span><br><span class=\"line\">        module.register_forward_hook(hook=hook)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(features_in_hook)  <span class=\"comment\"># 勾的是指定层的输入</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(features_out_hook)  <span class=\"comment\"># 勾的是指定层的输出</span></span><br><span class=\"line\"></span><br><span class=\"line\">rand_x = torch.rand(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;input x: <span class=\"subst\">&#123;rand_x&#125;</span>&quot;</span>)</span><br><span class=\"line\">result = net(rand_x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;result: <span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;features in: <span class=\"subst\">&#123;features_in_hook&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;features out: <span class=\"subst\">&#123;features_out_hook&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>批处理命令设置环境变量<br>set path&#x3D;xxxx</p>\n<h2 id=\"好玩的东西\"><a href=\"#好玩的东西\" class=\"headerlink\" title=\"好玩的东西\"></a>好玩的东西</h2><h3 id=\"Lambda-递归\"><a href=\"#Lambda-递归\" class=\"headerlink\" title=\"Lambda 递归\"></a>Lambda 递归</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = (<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span> n:(h(h, n)))(<span class=\"keyword\">lambda</span> f,n: n + f(f, n-<span class=\"number\">1</span>) <span class=\"keyword\">if</span> n &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"comment\"># &gt;&gt;&gt; f(10)</span></span><br><span class=\"line\"><span class=\"comment\"># 55</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Lambda-计数器\"><a href=\"#Lambda-计数器\" class=\"headerlink\" title=\"Lambda 计数器\"></a>Lambda 计数器</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f,n = (<span class=\"keyword\">lambda</span> f,n=<span class=\"number\">0</span>: ((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>), n))(<span class=\"keyword\">lambda</span> f,n: ((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>), n))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f(f)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>更好玩的版本！</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f,n = (<span class=\"keyword\">lambda</span> f,n=<span class=\"number\">0</span>: ((<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span>: h(h))((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>)), n))(<span class=\"keyword\">lambda</span> f,n: ((<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span>: h(h))((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>)), n))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br></pre></td></tr></table></figure>\n\n<p>与上一个版本效果相同：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = (<span class=\"keyword\">lambda</span> g: g(<span class=\"keyword\">lambda</span> f,n=<span class=\"number\">0</span>: (g((<span class=\"keyword\">lambda</span> f, n: <span class=\"keyword\">lambda</span> x, m=n: f(x, m))(f, n+<span class=\"number\">1</span>)), n)))(<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span>: h(h))</span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br><span class=\"line\"></span><br><span class=\"line\">f,n = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(n)</span><br></pre></td></tr></table></figure>\n\n<p>更加简洁：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = (<span class=\"keyword\">lambda</span> g: g(<span class=\"keyword\">lambda</span> f,t, n=<span class=\"number\">0</span>: n <span class=\"keyword\">if</span> t == <span class=\"number\">0</span> <span class=\"keyword\">else</span> g((<span class=\"keyword\">lambda</span> f, t, n: <span class=\"keyword\">lambda</span> x, u=t, m=n: f(x, u, m))(f, t, n+<span class=\"number\">1</span>))))((<span class=\"keyword\">lambda</span> h: <span class=\"keyword\">lambda</span> t=<span class=\"number\">1</span>: h(h, t)))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f(<span class=\"number\">0</span>))</span><br><span class=\"line\">f = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f(<span class=\"number\">0</span>))</span><br><span class=\"line\">f = f()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f(<span class=\"number\">0</span>))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"js爬虫\"><a href=\"#js爬虫\" class=\"headerlink\" title=\"js爬虫\"></a>js爬虫</h2><p><strong>1.js保存字符串到本地</strong></p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">saveShareContent</span> (content, fileName) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">let</span> downLink = <span class=\"variable language_\">document</span>.<span class=\"title function_\">createElement</span>(<span class=\"string\">&#x27;a&#x27;</span>)</span><br><span class=\"line\">    downLink.<span class=\"property\">download</span> = fileName</span><br><span class=\"line\">    <span class=\"comment\">//字符内容转换为blod地址</span></span><br><span class=\"line\">    <span class=\"keyword\">let</span> blob = <span class=\"keyword\">new</span> <span class=\"title class_\">Blob</span>([content])</span><br><span class=\"line\">    downLink.<span class=\"property\">href</span> = <span class=\"variable constant_\">URL</span>.<span class=\"title function_\">createObjectURL</span>(blob)</span><br><span class=\"line\">    <span class=\"comment\">// 链接插入到页面</span></span><br><span class=\"line\">    <span class=\"variable language_\">document</span>.<span class=\"property\">body</span>.<span class=\"title function_\">appendChild</span>(downLink)</span><br><span class=\"line\">    downLink.<span class=\"title function_\">click</span>()</span><br><span class=\"line\">    <span class=\"comment\">// 移除下载链接</span></span><br><span class=\"line\">    <span class=\"variable language_\">document</span>.<span class=\"property\">body</span>.<span class=\"title function_\">removeChild</span>(downLink)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>2. 包含iframe&#x2F;#document的文档</strong></p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> ifram = <span class=\"variable language_\">document</span>.<span class=\"title function_\">querySelector</span>(<span class=\"string\">&quot;#iframe&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">var</span> idoc = ifram.<span class=\"property\">contentWindow</span>.<span class=\"property\">document</span>;</span><br><span class=\"line\"><span class=\"comment\">//console.log(idoc);</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> ifram2 = idoc.<span class=\"title function_\">querySelector</span>(<span class=\"string\">&quot;#ext-gen1046 &gt; iframe&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">var</span> idoc2 = ifram2.<span class=\"property\">contentWindow</span>.<span class=\"property\">document</span>;</span><br><span class=\"line\"><span class=\"comment\">//console.log(idoc2);</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> ifram3 = idoc2.<span class=\"title function_\">querySelector</span>(<span class=\"string\">&quot;#frame_content&quot;</span>);</span><br><span class=\"line\"><span class=\"keyword\">var</span> idoc3 = ifram3.<span class=\"property\">contentWindow</span>.<span class=\"property\">document</span>;</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(idoc3);</span><br><span class=\"line\">text = idoc3.<span class=\"property\">documentElement</span>.<span class=\"property\">innerHTML</span>;</span><br></pre></td></tr></table></figure>\n\n<p>层层剥开，否则在iframe内部的元素会定位失败。在F12界面右键选择“复制js路径”可以获取 <code>querySeletor</code>语句。</p>\n<p><strong>3.滚动至最低部</strong></p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  <span class=\"keyword\">var</span> ele = <span class=\"variable language_\">document</span>.<span class=\"property\">documentElement</span>;</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(ele.<span class=\"property\">scrollHeight</span> &gt; ele.<span class=\"property\">clientHeight</span>) &#123;</span><br><span class=\"line\"><span class=\"comment\">//设置滚动条到最底部</span></span><br><span class=\"line\">ele.<span class=\"property\">scrollTop</span> = ele.<span class=\"property\">scrollHeight</span>;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p>必要时可以增加 <code>setTimeout</code>等待网页加载完毕。</p>\n<p><strong>4.逐步滚动</strong></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\">pos = <span class=\"variable language_\">document</span>.<span class=\"property\">documentElement</span>.<span class=\"property\">scrollTop</span>;</span><br><span class=\"line\"><span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(pos);</span><br><span class=\"line\"><span class=\"keyword\">var</span> id = <span class=\"built_in\">setInterval</span>(</span><br><span class=\"line\">    <span class=\"keyword\">function</span> (<span class=\"params\"></span>)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (count &lt; <span class=\"number\">500</span>) &#123;</span><br><span class=\"line\">            <span class=\"variable language_\">document</span>.<span class=\"property\">documentElement</span>.<span class=\"property\">scrollTop</span>++;</span><br><span class=\"line\">            count++;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"built_in\">clearInterval</span>(id);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">, <span class=\"number\">2</span>);</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"electron-vue\"><a href=\"#electron-vue\" class=\"headerlink\" title=\"electron-vue\"></a>electron-vue</h2><p><strong>如何引入.node文件</strong></p>\n<p>需要将.node文件放在public文件夹下，引用时可以用相对路径也可以用 <code>__static</code>+文件名。</p>\n<p>需要安装<a href=\"mailto:&#x6e;&#111;&#x64;&#101;&#45;&#x6c;&#111;&#x61;&#x64;&#x65;&#x72;&#x40;&#x31;&#46;&#x30;&#x2e;&#x33;\">&#x6e;&#111;&#x64;&#101;&#45;&#x6c;&#111;&#x61;&#x64;&#x65;&#x72;&#x40;&#x31;&#46;&#x30;&#x2e;&#x33;</a>。太高的版本会导致问题。</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">const</span> addon = <span class=\"built_in\">require</span>(<span class=\"string\">&quot;node-loader!../public/addon.node&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>在vue中使用ipcRenderer</strong></p>\n<p>主进程中引入ipcMain没啥大问题。<br>在vue文件中引入ipcRenderer，需要先在vue.config.js中配置</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">nodeIntegration</span>: <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">pluginOptions</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">electronBuilder</span>: &#123;</span><br><span class=\"line\">      <span class=\"comment\">// 在vue中能引入electron模块</span></span><br><span class=\"line\">      <span class=\"attr\">nodeIntegration</span>: <span class=\"literal\">true</span>,</span><br></pre></td></tr></table></figure>\n\n<p>然后在各个vue文件中引入</p>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> &#123; ipcRenderer &#125; <span class=\"keyword\">from</span> <span class=\"string\">&#x27;electron&#x27;</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"math\"><a href=\"#math\" class=\"headerlink\" title=\"math\"></a>math</h2><p>一个只跟a, b中最大的那一个有关的积分：</p>\n<div>$$\n\\int_{0}^{\\pi}\\frac{\\sin \\theta}{\\sqrt{a^2+b^2-2ab\\cos\\theta}}\\mathrm d\\theta = \\frac{1}{ab}(|a+b| - |a-b|)\n$$</div>\n\n<h2 id=\"js-小技巧\"><a href=\"#js-小技巧\" class=\"headerlink\" title=\"js 小技巧\"></a>js 小技巧</h2><h3 id=\"可变定时检测\"><a href=\"#可变定时检测\" class=\"headerlink\" title=\"可变定时检测\"></a>可变定时检测</h3><p>问：每隔10秒检测一次当前页面是否包含某字符串，如果包含，则 console.log，下次检测的时间变为 100 秒</p>\n<p>答：为了实现这个功能，你可以使用 <code>setInterval</code>函数来设置一个定期执行的任务。然而，因为你想在满足特定条件时改变间隔时间，你可能需要使用 <code>setTimeout</code>来代替，因为 <code>setInterval</code>的间隔时间一旦设定就无法改变。以下是如何实现这一逻辑的示例代码：</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">function</span> <span class=\"title function_\">checkContentAndAdjustInterval</span>(<span class=\"params\">searchString, initialDelay, newDelay</span>) &#123;</span><br><span class=\"line\">  <span class=\"comment\">// 定义一个函数，用于检查页面内容并根据条件调整定时器</span></span><br><span class=\"line\">  <span class=\"keyword\">function</span> <span class=\"title function_\">checkAndSchedule</span>(<span class=\"params\"></span>) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 检查文档中是否包含特定字符串</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"variable language_\">document</span>.<span class=\"property\">body</span>.<span class=\"property\">textContent</span>.<span class=\"title function_\">includes</span>(searchString)) &#123;</span><br><span class=\"line\">      <span class=\"variable language_\">console</span>.<span class=\"title function_\">log</span>(<span class=\"string\">`页面包含指定字符串: <span class=\"subst\">$&#123;searchString&#125;</span>`</span>);</span><br><span class=\"line\">      <span class=\"comment\">// 如果找到字符串，设置下一次检查的延时为 newDelay</span></span><br><span class=\"line\">      <span class=\"built_in\">setTimeout</span>(checkAndSchedule, newDelay);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">      <span class=\"comment\">// 如果没有找到字符串，保持原来的检查频率</span></span><br><span class=\"line\">      <span class=\"built_in\">setTimeout</span>(checkAndSchedule, initialDelay);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 启动循环检查</span></span><br><span class=\"line\">  <span class=\"built_in\">setTimeout</span>(checkAndSchedule, initialDelay);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 使用示例：每隔10秒检查一次页面是否包含&quot;特定字符串&quot;，</span></span><br><span class=\"line\"><span class=\"comment\">// 如果找到，则下次检查的时间间隔变为100秒</span></span><br><span class=\"line\"><span class=\"title function_\">checkContentAndAdjustInterval</span>(<span class=\"string\">&quot;特定字符串&quot;</span>, <span class=\"number\">10000</span>, <span class=\"number\">100000</span>);</span><br></pre></td></tr></table></figure>\n\n<p>这段代码首先定义了一个 <code>checkContentAndAdjustInterval</code>函数，它接受三个参数：要搜索的字符串 <code>searchString</code>、初始的检查间隔时间 <code>initialDelay</code>（以毫秒为单位）、以及在找到字符串后新的检查间隔时间 <code>newDelay</code>。</p>\n<p>在 <code>checkContentAndAdjustInterval</code>函数内部，定义了另一个名为 <code>checkAndSchedule</code>的函数。<code>checkAndSchedule</code>函数首先检查当前页面的内容是否包含指定的字符串。如果包含，它将使用 <code>console.log</code>输出一个消息，并使用新的延迟时间 <code>newDelay</code>来安排下一次执行。如果不包含指定的字符串，它将继续使用初始的延迟时间 <code>initialDelay</code>来安排下一次执行。</p>\n<p>最后，<code>checkContentAndAdjustInterval</code>函数通过调用 <code>setTimeout</code>并传入 <code>checkAndSchedule</code>函数和初始延迟时间 <code>initialDelay</code>来启动整个检查流程。</p>\n<p>这种方法的好处是你可以灵活地控制检查的间隔时间，而且它在满足特定条件后能够自动调整这个间隔，非常适合需要根据条件动态调整检查频率的场景。</p>\n<h2 id=\"NFS-常用指令\"><a href=\"#NFS-常用指令\" class=\"headerlink\" title=\"NFS 常用指令\"></a>NFS 常用指令</h2><p>主要参考：<a href=\"https://zhuanlan.zhihu.com/p/480960387\">如何在 Ubuntu 20.04 上安装和配置 NFS 服务器？ - 知乎 (zhihu.com)</a></p>\n<h3 id=\"服务端绑定-NFS\"><a href=\"#服务端绑定-NFS\" class=\"headerlink\" title=\"服务端绑定 NFS\"></a>服务端绑定 NFS</h3><p>直接绑定：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mount --bind /opt/backups /srv/nfs4/backups</span><br><span class=\"line\">sudo mount --bind /var/www /srv/nfs4/www</span><br></pre></td></tr></table></figure>\n\n<p>要在重新启动后使绑定挂载永久化，请打开&#x2F;etc&#x2F;fstab文件：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo nano /etc/fstab</span><br></pre></td></tr></table></figure>\n\n<p>并添加以下行：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/fstab</span><br><span class=\"line\">/opt/backups /srv/nfs4/backups  none   bind   0   0</span><br><span class=\"line\">/var/www     /srv/nfs4/www      none   bind   0   0</span><br></pre></td></tr></table></figure>\n\n<p><code>/var/www </code>为本地需要绑定的文件夹，<code>/srv/nfs4/www </code>为 NFS 管理的文件夹，必须以 <code>/srv/nfs4</code>开头。</p>\n<p>绑定后，服务端可以修改 <code>/var/www </code>内的文件，会被自动同步到 NFS 绑定的目录下。</p>\n<h3 id=\"客户端绑定-NFS\"><a href=\"#客户端绑定-NFS\" class=\"headerlink\" title=\"客户端绑定 NFS\"></a>客户端绑定 NFS</h3><p>为挂载点创建两个新目录：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir -p /backups</span><br><span class=\"line\">sudo mkdir -p /srv/www</span><br></pre></td></tr></table></figure>\n\n<p>您可以在任何您想要的位置创建目录。</p>\n<p>使用以下命令挂载导出的文件系统mount ：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mount -t nfs -o vers=4 192.168.33.10:/backups /backups</span><br><span class=\"line\">sudo mount -t nfs -o vers=4 192.168.33.10:/www /srv/www</span><br></pre></td></tr></table></figure>\n\n<p>要在重新启动时永久挂载，请打开&#x2F;etc&#x2F;fstab文件并添加以下行：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo nano /etc/fstab</span><br><span class=\"line\"></span><br><span class=\"line\">/etc/fstab</span><br><span class=\"line\">192.168.33.10:/backups /backups   nfs   defaults,timeo=900,retrans=5,_netdev 0 0</span><br><span class=\"line\">192.168.33.10:/www /srv/www       nfs   defaults,timeo=900,retrans=5,_netdev 0 0</span><br></pre></td></tr></table></figure>\n\n<p>有关挂载 NFS 文件系统时可用选项的信息，请输入man nfs您的终端。</p>\n<h3 id=\"IP-检测\"><a href=\"#IP-检测\" class=\"headerlink\" title=\"IP 检测\"></a>IP 检测</h3><p>编辑配置文件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo nano /etc/exports</span><br></pre></td></tr></table></figure>\n\n<p>配置文件例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/srv/nfs4         192.168.33.0/24(rw,sync,no_subtree_check,crossmnt,fsid=0)</span><br><span class=\"line\">/srv/nfs4/backups 192.168.33.0/24(ro,sync,no_subtree_check) 192.168.33.3(rw,sync,no_subtree_check)</span><br><span class=\"line\">/srv/nfs4/www     192.168.33.20(rw,sync,no_subtree_check)</span><br></pre></td></tr></table></figure>\n\n<p>其中，192.168.33.0&#x2F;24 等为需要过滤的 ip 规则。</p>\n<p>应用 ip 设置</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo exportfs -ar</span><br></pre></td></tr></table></figure>\n\n<p>查看 ip 检测</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo exportfs -v</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"重启-NFS\"><a href=\"#重启-NFS\" class=\"headerlink\" title=\"重启 NFS\"></a>重启 NFS</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo /etc/init.d/nfs-kernel-server restart</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"WSL-相关\"><a href=\"#WSL-相关\" class=\"headerlink\" title=\"WSL 相关\"></a>WSL 相关</h2><h3 id=\"WSL-寄了！\"><a href=\"#WSL-寄了！\" class=\"headerlink\" title=\"WSL 寄了！\"></a>WSL 寄了！</h3><p>可能是因为配置 nfs 的原因吧，wsl 关掉之后就打不开了。</p>\n<ul>\n<li>wsl 无响应。</li>\n<li>当 ubuntu 处于停止状态时，<code>wsl --list</code>, <code>wsl --status</code> 有响应；但我一旦尝试运行 <code>wsl</code> 以启动 ubuntu，就无响应了。</li>\n<li><code>wsl --help</code> 一直没问题。</li>\n</ul>\n<p>怀疑是配置 <code>/etc/fstab</code> 的时候出的问题，导致 wsl 无响应。</p>\n<p>后来的解决方案：</p>\n<ol>\n<li>把 <code>ext4.vhdx</code> 备份了一份。</li>\n<li>卸载 ubuntu distro，重新安装了一遍 ubuntu 22.04。</li>\n<li><code>wsl --mount --vhd</code> 将 <code>ext4.vhdx</code> 挂到新安装的 ubuntu wsl 上。</li>\n</ol>\n<p>幸好 <code>ext4.vhdx</code> 还在。</p>\n<p>另外，挂完 <code>ext4.vhdx</code> 后，我将存有 <code>ext4.vhdx</code> 的移动硬盘拔出，然后重新打开 wsl，发现出现了同样的问题。这样就验证了我的假说：</p>\n<ul>\n<li>我设置了开机默认挂载 nfs 硬盘，连接远程的服务器。</li>\n<li>nfs 服务器因为一些原因没连上。</li>\n<li>wsl 文件系统因为挂载的硬盘找不到了，发生错误。</li>\n<li>wsl 在启动界面无响应。</li>\n</ul>\n<p>重启了电脑，发现之前 <code>wsl --mount</code> 挂载的 <code>ext4.vhdx</code> 已经被清空了，证明 wsl –mount 命令的效果在重启之后清空了。</p>\n<h3 id=\"yarn-add-hasura-cli-安装失败\"><a href=\"#yarn-add-hasura-cli-安装失败\" class=\"headerlink\" title=\"yarn add hasura-cli 安装失败\"></a>yarn add hasura-cli 安装失败</h3><p>报错：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Command: node dist/index.js</span><br><span class=\"line\">Arguments: </span><br><span class=\"line\">Directory: /home/guoyun812/eesast/hasura/node_modules/hasura-cli</span><br><span class=\"line\">Output:</span><br><span class=\"line\">hasura-cli@2.36.1</span><br><span class=\"line\">Downloading Hasura CLI binary v2.36.1 from https://github.com/hasura/graphql-engine/releases/download/v2.36.1/cli-hasura-linux-amd64</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">hasura-cli@2.36.1</span><br><span class=\"line\">Error! Failed to install Hasura CLI binary.</span><br><span class=\"line\">Try npm uninstall hasura-cli or yarn remove hasura-cli and then reinstall it.</span><br><span class=\"line\">If the issue occurs repeatedly, check if your network can access https://github.com as the the Hasura CLI binary file is hosted on Github.</span><br><span class=\"line\">You can report the issue on https://github.com/jjangga0214/hasura-cli/issues with error message.</span><br></pre></td></tr></table></figure>\n\n<p>解决方案：手动下载 hasura-cli 的二进制文件，并粘贴到 <code>node_modules/hasura/</code>。</p>\n<h2 id=\"SSH-相关\"><a href=\"#SSH-相关\" class=\"headerlink\" title=\"SSH 相关\"></a>SSH 相关</h2><h3 id=\"ssh-端口转发的坑点\"><a href=\"#ssh-端口转发的坑点\" class=\"headerlink\" title=\"ssh 端口转发的坑点\"></a>ssh 端口转发的坑点</h3><p>转发之前一定要在远程服务器的 <code>/etc/ssh/sshd_config</code> 中配置：</p>\n<p>GatewayPorts <strong>yes（或 clientspecified，不能是 no）</strong></p>\n<p>具体的原理我说不清楚。大概意思是，我们通常用以下方式进行远程端口转发：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CNgv -R &lt;remote_ip&gt;:&lt;port&gt;:&lt;local_ip&gt;:&lt;port&gt; &lt;hostname&gt;</span><br></pre></td></tr></table></figure>\n\n<p>一般会把 remote_ip 设为 0.0.0.0，以绑定到所有接口。但是，若不设置 GatewayPorts，则远程服务器上仍然只有 localhost 能够访问这个端口，如果你在 docker 容器内访问这个端口是不行的。我花了很多时间去排除 docker 容器到主机上的连接是否正确，包括使用 docker 的网关地址&#x2F;host.docker.internal、修改 iptables、修改防火墙，都没什么用。因为实际上这个 ip 可以 ping 通，根本就不是 ip 地址或者防火墙的问题，是 ssh 转发里面限制了网关访问端口。</p>\n<p>claude-sonnet 给出的解释如下：</p>\n<table>\n<thead>\n<tr>\n<th>配置选项</th>\n<th>客户端命令</th>\n<th>实际绑定地址</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>no</code></td>\n<td><code>ssh -R 8000:...</code></td>\n<td><code>127.0.0.1:8000</code></td>\n<td>强制 localhost</td>\n</tr>\n<tr>\n<td><code>no</code></td>\n<td><code>ssh -R 0.0.0.0:8000:...</code></td>\n<td><code>127.0.0.1:8000</code></td>\n<td>忽略客户端指定</td>\n</tr>\n<tr>\n<td><code>yes</code></td>\n<td><code>ssh -R 8000:...</code></td>\n<td><code>0.0.0.0:8000</code></td>\n<td>默认所有接口</td>\n</tr>\n<tr>\n<td><code>yes</code></td>\n<td><code>ssh -R 192.168.1.1:8000:...</code></td>\n<td><code>192.168.1.1:8000</code></td>\n<td>允许指定</td>\n</tr>\n<tr>\n<td><code>clientspecified</code></td>\n<td><code>ssh -R 8000:...</code></td>\n<td><code>127.0.0.1:8000</code></td>\n<td>默认 localhost</td>\n</tr>\n<tr>\n<td><code>clientspecified</code></td>\n<td><code>ssh -R 0.0.0.0:8000:...</code></td>\n<td><code>0.0.0.0:8000</code></td>\n<td>允许客户端指定</td>\n</tr>\n</tbody></table>\n<p>可以看到，如果服务端配置为 no，无论客户端怎么强制绑 <code>0.0.0.0</code> 都没用的，还是变成了 <code>localhost:8000</code> 的服务。如果设置为 yes，那么默认就绑 <code>0.0.0.0:8000</code>，要指定也是可以的。</p>\n<h3 id=\"服务器共用怎么设置自己的环境变量\"><a href=\"#服务器共用怎么设置自己的环境变量\" class=\"headerlink\" title=\"服务器共用怎么设置自己的环境变量\"></a>服务器共用怎么设置自己的环境变量</h3><p>在 vscode user settings 中添加：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;terminal.integrated.env.linux&quot;: &#123;</span><br><span class=\"line\">    &quot;ZZZ_INIT_COMMAND&quot;: &quot;1&quot;</span><br><span class=\"line\">&#125;,</span><br></pre></td></tr></table></figure>\n\n<p>在启动文件（例如 <code>.bashrc</code>）中添加：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># used for zzz&#x27;s bash init if the env var below is defined</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [[ -n <span class=\"variable\">$ZZZ_INIT_COMMAND</span> ]]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">&quot;Hello, welcome to tsz&#x27;s bash shell!&quot;</span></span><br><span class=\"line\">    <span class=\"built_in\">eval</span> <span class=\"string\">&quot;source /home/ubuntu/tsz/config.sh&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ssh-服务器\"><a href=\"#ssh-服务器\" class=\"headerlink\" title=\"ssh 服务器\"></a>ssh 服务器</h3><p>使用 <code>ssh-keygen</code> 时最好设置一个口令，否则别人也能用这个密钥。</p>\n<h3 id=\"常用命令\"><a href=\"#常用命令\" class=\"headerlink\" title=\"常用命令\"></a>常用命令</h3><p>ssh 反向代理（服务器端口映射到本地端口），挂在后台</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CqTfnN -R &lt;remote_port&gt;:localhost:&lt;local_port&gt;  -v  username@hostname -p &lt;ssh_port&gt;</span><br></pre></td></tr></table></figure>\n\n<p>ssh 前向代理（本地端口映射到服务器端口）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CqTfnN -L &lt;local_port&gt;:localhost:&lt;remote_port&gt;  -v  username@hostname -p &lt;ssh_port&gt;</span><br></pre></td></tr></table></figure>\n\n<p>将请求转发到 github</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh -CqTfnN -L &lt;local_port&gt;:github.com:22 -v  username@hostname -p &lt;ssh_port&gt;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ssh-agent\"><a href=\"#ssh-agent\" class=\"headerlink\" title=\"ssh agent\"></a>ssh agent</h3><p>启动 ssh agent，并查看 pid</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">eval $(ssh-agent -s)</span><br></pre></td></tr></table></figure>\n\n<p>查看当前 agent 有哪些密钥</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-add -l # 查看公钥的 sha256</span><br><span class=\"line\">ssh-add -L # 查看完整公钥</span><br></pre></td></tr></table></figure>\n\n<p>添加密钥</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-add &lt;private_key_path&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Node-js\"><a href=\"#Node-js\" class=\"headerlink\" title=\"Node.js\"></a>Node.js</h2><h3 id=\"listen-EACCES-permission-denied-0-0-0-0-3000\"><a href=\"#listen-EACCES-permission-denied-0-0-0-0-3000\" class=\"headerlink\" title=\"listen EACCES: permission denied 0.0.0.0:3000\"></a>listen EACCES: permission denied 0.0.0.0:3000</h3><p>1、先判断是否是端口占用的问题导致的 <code>netstat -ano| findstr 3000</code></p>\n<p>关闭相关进程（cmd）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">taskkill /PID &lt;process_id&gt; /F</span><br></pre></td></tr></table></figure>\n\n<p>发现并没有程序在使用这个端口</p>\n<p>2、改用管理员再运行一遍</p>\n<p>发现仍然不行</p>\n<p>3、使用管理员权限运行以下命令</p>\n<p><code>net stop winnat</code></p>\n<p><code>net start winnat</code></p>\n<h2 id=\"AI\"><a href=\"#AI\" class=\"headerlink\" title=\"AI\"></a>AI</h2><h3 id=\"Could-not-load-symbol-cudnnGetLibConfig\"><a href=\"#Could-not-load-symbol-cudnnGetLibConfig\" class=\"headerlink\" title=\"Could not load symbol cudnnGetLibConfig\"></a>Could not load symbol cudnnGetLibConfig</h3><p>环境变量的问题，如果你在环境变量中将 LD_LIBRARY_PATH 指向了不正确的版本会导致这里出问题。</p>\n<p>运行下面的代码以获得正确的 cudnn 路径：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LD_LIBRARY_PATH=`python3  -c &#x27;import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + &quot;:&quot; + os.path.dirname(nvidia.cudnn.lib.__file__))&#x27;`</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"x2F-usr-x2F-bin-x2F-ld-cannot-find-lcuda\"><a href=\"#x2F-usr-x2F-bin-x2F-ld-cannot-find-lcuda\" class=\"headerlink\" title=\"&#x2F;usr&#x2F;bin&#x2F;ld: cannot find -lcuda\"></a>&#x2F;usr&#x2F;bin&#x2F;ld: cannot find -lcuda</h3><p>见<a href=\"https://github.com/NVlabs/tiny-cuda-nn/issues/183#issuecomment-1342828785\">这个 issue</a></p>\n<p>export LIBRARY_PATH&#x3D;”&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64&#x2F;stubs:$LIBRARY_PATH”</p>\n<p>export LD_LIBRARY_PATH&#x3D;”&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64&#x2F;stubs:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64”</p>\n<h3 id=\"Llama-架构\"><a href=\"#Llama-架构\" class=\"headerlink\" title=\"Llama 架构\"></a>Llama 架构</h3><p><img src=\"/../images/stuffs/1713000493686.png\" alt=\"1713000493686\"></p>\n<h3 id=\"使用-Tensorboard\"><a href=\"#使用-Tensorboard\" class=\"headerlink\" title=\"使用 Tensorboard\"></a>使用 Tensorboard</h3><figure class=\"highlight python-repl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from torch.utils.tensorboard import SummaryWriter</span><br><span class=\"line\">from accelerate.tracking import GeneralTracker, on_main_process</span><br><span class=\"line\">import os</span><br><span class=\"line\">from typing import Union</span><br><span class=\"line\"></span><br><span class=\"line\"># 0. 自定义追踪器</span><br><span class=\"line\">class MyCustomTracker(GeneralTracker):</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    my custom `Tracker` class that supports `tensorboard`. Should be initialized at the start of your script.</span><br><span class=\"line\"></span><br><span class=\"line\">    Args:</span><br><span class=\"line\">        run_name (`str`):</span><br><span class=\"line\">            The name of the experiment run</span><br><span class=\"line\">        logging_dir (`str`, `os.PathLike`):</span><br><span class=\"line\">            Location for TensorBoard logs to be stored.</span><br><span class=\"line\">        kwargs:</span><br><span class=\"line\">            Additional key word arguments passed along to the `tensorboard.SummaryWriter.__init__` method.</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    name = &quot;tensorboard&quot;</span><br><span class=\"line\">    requires_logging_directory = True</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def __init__(self, run_name: str, logging_dir: Union[str, os.PathLike],</span><br><span class=\"line\">                 **kwargs):</span><br><span class=\"line\">        super().__init__()</span><br><span class=\"line\">        self.run_name = run_name</span><br><span class=\"line\">        self.logging_dir = os.path.join(logging_dir, run_name)</span><br><span class=\"line\">        self.writer = SummaryWriter(self.logging_dir, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @property</span><br><span class=\"line\">    def tracker(self):</span><br><span class=\"line\">        return self.writer</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_scalar(self, tag, scalar_value, **kwargs):</span><br><span class=\"line\">        self.writer.add_scalar(tag=tag, scalar_value=scalar_value, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_text(self, tag, text_string, **kwargs):</span><br><span class=\"line\">        self.writer.add_text(tag=tag, text_string=text_string, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_figure(self, tag, figure, **kwargs):</span><br><span class=\"line\">        self.writer.add_figure(tag=tag, figure=figure, **kwargs)</span><br><span class=\"line\"></span><br><span class=\"line\">    @on_main_process</span><br><span class=\"line\">    def add_vector(self, tag, mat, **kwargs):</span><br><span class=\"line\">        self.writer.add_embedding(tag=tag, mat=mat, **kwargs)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"记录神经元的激活值\"><a href=\"#记录神经元的激活值\" class=\"headerlink\" title=\"记录神经元的激活值\"></a>记录神经元的激活值</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">TestForHook</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">        self.linear_1 = nn.Linear(in_features=<span class=\"number\">2</span>, out_features=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.linear_2 = nn.Linear(in_features=<span class=\"number\">2</span>, out_features=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.relu = nn.ReLU()</span><br><span class=\"line\">        self.relu6 = nn.ReLU6()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        linear_1 = self.linear_1(x)</span><br><span class=\"line\">        linear_2 = self.linear_2(linear_1)</span><br><span class=\"line\">        relu = self.relu(linear_2)</span><br><span class=\"line\">        relu6 = self.relu6(relu)</span><br><span class=\"line\">        layers_in = (x, linear_1, linear_2)</span><br><span class=\"line\">        layers_out = (linear_1, linear_2, relu)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> relu6</span><br><span class=\"line\"></span><br><span class=\"line\">features_in_hook = []</span><br><span class=\"line\">features_out_hook = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">hook</span>(<span class=\"params\">module, fea_in, fea_out</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;hook! module: <span class=\"subst\">&#123;module&#125;</span>, in: <span class=\"subst\">&#123;fea_in&#125;</span>, out: <span class=\"subst\">&#123;fea_out&#125;</span>&quot;</span>)</span><br><span class=\"line\">    features_in_hook.append(fea_in)</span><br><span class=\"line\">    features_out_hook.append(fea_out)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\">net = TestForHook()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\"># 第一种写法，按照类型勾，但如果有重复类型的layer比较复杂</span></span><br><span class=\"line\"><span class=\"string\">net_chilren = net.children()</span></span><br><span class=\"line\"><span class=\"string\">for child in net_chilren:</span></span><br><span class=\"line\"><span class=\"string\">    if not isinstance(child, nn.ReLU6):</span></span><br><span class=\"line\"><span class=\"string\">        child.register_forward_hook(hook=hook)</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">推荐下面我改的这种写法，因为我自己的网络中，在Sequential中有很多层，</span></span><br><span class=\"line\"><span class=\"string\">这种方式可以直接先print(net)一下，找出自己所需要那个layer的名称，按名称勾出来</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net)</span><br><span class=\"line\"></span><br><span class=\"line\">layer_name = <span class=\"string\">&#x27;linear_1&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (name, module) <span class=\"keyword\">in</span> net.named_modules():</span><br><span class=\"line\">    <span class=\"keyword\">if</span> name == layer_name:</span><br><span class=\"line\">        module.register_forward_hook(hook=hook)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(features_in_hook)  <span class=\"comment\"># 勾的是指定层的输入</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(features_out_hook)  <span class=\"comment\"># 勾的是指定层的输出</span></span><br><span class=\"line\"></span><br><span class=\"line\">rand_x = torch.rand(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;input x: <span class=\"subst\">&#123;rand_x&#125;</span>&quot;</span>)</span><br><span class=\"line\">result = net(rand_x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;result: <span class=\"subst\">&#123;result&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;features in: <span class=\"subst\">&#123;features_in_hook&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;features out: <span class=\"subst\">&#123;features_out_hook&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n"},{"title":"数字系统设计","date":"2023-09-20T05:33:09.000Z","katex":true,"_content":"\n## 绪论\n\n软硬件协同，制作深度学习硬件\n\n理论课，讲座，Lab\n\n专用电路\n\n目标：做一个类似于Google TPU中的某计算模块\n\nbenchmark: ML\n\n每4周一个Lab，无期中期末\n\n作业：\n\nAlexNet Paper\n\nQuantization of CNN\n\n## DNN\n\n### Training & Inference\n\nTraining: forward and backward\n\nInference: backward\n\n### Model\n\n![](../images/DSD/2_1.jpg)\n\n五类算子：\n\n![](../images/DSD/2_2.jpg)\n\n特征提取器：卷积层，池化层；\n\n分类器：全连接层\n\n**线性卷积层**\n\n边界扩充(Padding)：在图像周围扩展一圈0，避免多次卷积导致数据尺寸越来越小\n\n卷积步长(Stride)：卷积核每次跳的步数。可以用来让数据尺寸快速变化\n\n\n非线性函数-激活函数\n\n非线性-正则化函数\n\n非线性-池化函数\n\n**池化层**\n\n池化层减小图片的尺寸，从而减小参数的数量和计算量。\n\n最大池化：在池化窗口内取最大值作为输出。\n* 复杂度低，硬件实现容易\n* 最为常用\n\n平均池化：取池化窗口内的平均值作为输出。\n\n$L^2$ 池化法：对所有的数计算平方后累加求和再开平方。\n* 计算复杂度高\n* 几何平均池化的复杂度更高\n\n**线性全连接层**\n\n将特征图映射为分类结果\n\n**Softmax 层**\n\n有的模型在输出层使用softmax对输出进行归一化：\n\n$$\nf(z_j) = \\dfrac{e^{z_j}}{\\sum_{i = 0}^n e^{z_j}}\n$$\n\n* 输入和输出规模相同\n* 归一化计算，让较大的值凸显，让较小的值被抑制，从而决定分类概率\n\n**卷积神经网络的总体结构**\n\n\n\n### Dataset\n\n数据集的建立：数据采集，数据标签，数据清洗，数据增强，数据分割\n\n### Cost function\n\n### Optimization\n\n* 梯度下降法\n* SGD\n* 动量法：计算过去的平均梯度\n* AdaGrad法：累加梯度方差\n* RMSProp：按时间降低学习率\n* Adam 算法：指数加权移动平均值计算梯度动量和二次矩\n* SGD简单，但是训练过程边长，自适应算法会更高效\n\n### Evaluation\n\n**回归问题指标**\n\nPSNR\n\n$$\nPSNR = 10 \\cdot \\log_{10}(\\frac{MAX_I^2}{MSE})\n$$\n\n**分类问题指标**\n\n* Top1 accuracy\n* Top5 accuracy\n\n**IoU**\n\nIntersection of Union?\n\n$$\n\\text{IoU} = \\frac{|A\\cap B|}{|A \\cup B|}\n$$\n\n**检测任务评价指标 mAP**\n\nmean average precision\n\n真阳性TP: 预测为真，实际为真\n\n假阳性FP：预测为真，实际为假\n\n假阴性FN：预测为假，实际为真\n\n**查全率（召回率，Recall）和查准率（准确率，Precision）**\n\n$$\n\\text{Precision} = \\frac{TP}{TP + FP}\\\\\n\\text{Recall} = \\frac{TP}{TP + FN}\n$$\n\n置信度衡量的是模型认为有效的自信程度。我们先将结果按照置信度从高到低排序。\n\nmAP是不同查全率下，最高查准率的平均值。\n\n### 网络结构的发展和讨论\n\n**分类任务**\n\nAlexNet\n* 使用多个卷积层，有效提取图像特征\n* ReLU 提高训练速度\n* Dropout、数据增强扩大训练集，防止过拟合\n\nVGG\n* 使用 3 * 3 的卷积核取代 AlexNet 的大卷积核\n    * 提升收敛速度\n    * 参数量更少\n    * 可以构建更深的网络，有更多的非线性变换，还有更强的表征能力\n* 参数预初始化策略\n\nResNet\n\n?\n\n**目标检测**\n\nTwo-stage v.s. One-stage\n\n**Two-stage**\n\n先画框，再分类\n\nMS CoCo Dataset\n* 用的最多的还是目标检测任务\n\nR-CNN\n* 输入图像\n* 提取候选框\n* 每一个候选框提取单独的特征\n* 进行分类\n\nFast R-CNN\n* 输入图像\n* 一次特征提取\n* 提取候选框\n* 进行分类\n\nFaster R-CNN\n* 输入图像\n* 一次特征提取\n* 提取候选框\n* 进行分类\n\n**One-stage**\n\nYOLO\n\n五代发展，最广泛的目标检测算法\n\n对于每一个像素，都会输出一个对应的特征向量，包含：\n* 二分类：是物体中心的置信度\n* 回归：偏离物体中心的长度 $\\Delta x$ 和 $\\Delta y$\n* 分类：对应的物体分类以及置信度\n* 回归：该像素所代表的物体的长宽，YOLO有一些基础框(anchor)，输出值是相对基础框的形变 $\\Delta h$ 和 $\\Delta w$\n\n\n**NMS (Non-Maximum Suppression)**\nBounding boxes for one instance may overlap.\nMethod: For each type, use NMS to eliminate redundant bounding boxes (greedy approach).\nWorkflow:\n1. Sort candidate bounding boxes by classification confidence.\n2. Adding the boxes b with most confidence to output list, and delete it from the candidate boxes.\n3. Calculate IoU between b and other boxes bi. If > threshold, delete bi.\n4. Repeat until no candidate bounding boxes.\n\n**序列模型（Serial Model）**\n\nto process Speech, text, video, audio, etc.\n\nFeature: \n1. The data input is in the time sequence.\n2. There is a correlation between the data before and after.\n\nSo the model should have the ability to \"store\" information.\n\nSpeech dataset: TIMIT\n1. It consists of recordings of 630 speakers of 8 dialects of American English each reading 10 phonetically-rich sentences.\n2. It also comes with the word and phone-level transcriptions of the speech.\n\nVideo dataset: DAVIS\n\nThe Densely Annotation Video Segmentation dataset (DAVIS) is a high quality and high resolution densely annotated video segmentation dataset under two resolutions, 480p and 1080p.\n\nThere are 50 video sequences with 3455 densely annotated frames in pixel level. 30 videos with 2079 frames are for training and 20 videos with 1376 frames are for validation.\n\nNLP dataset: GLUE\n\nGeneral Language Understanding Evaluation (GLUE) benchmark: Standard split of data totrain, validation, test, where labels for the test set is only held in the server.\n\n* Sentence pair tasks\n    * MNLI, Multi-Genre Natural Language Inference\n    * QQP, Ouora Ouestion Pairs\n    * QNLI, Ouestion Natural Language Inference\n    * STS-B The Semantic Textual Similarity Benchmark\n    * MRPC Microsoft Research Paraphrase Corpus\n    * RTE Recognizing Textual Entailment\n    * WNLI Winograd NLI is a small natural language inference \n* datasetSingle sentence classification\n    * SST-2 The Stanford Sentiment Treebank\n    * CoLA The Corpus of Linguistic Acceptability\n\n**Models**\n\n**RNN: Recurrent Neural Network**\n\n* one to one \n* one to many\n* many to one\n* many to many\n* many to many\n\n![](../images/DSD/2_3.jpg)\n\n损失函数的计算：\n\n单个时刻：\n\n$$\nL^{(t)} = -\\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$\n\n整个序列：\n\n$$\nL = \\sum\\limits_{t=1}^{\\tau}L^{(t)} = - \\sum\\limits_{t=1}^{\\tau} \\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$\n\n然后可求梯度：\n\n![alt](../images/DSD/2_4.jpg)\n\n循环神经网络存在梯度爆炸或梯度消失，因此无法处理长期的依赖关系。\n\n**LSTM: Solving the Gradient**\n\n**Transformer**\n\nSelf attention:\n\n$$\n\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK}{\\sqrt d_k})V\n$$\n\n## Quantization\n\n### Fixed-point and floating-point representation\n\n#### Fixed Point arithmetic\n\n$$\n\\underbrace{0}_{\\text{Sign bit}}\\ \\ \\underbrace{10\\dots01}_{n\\text{ bit integer part}}\\ \\ .\\underbrace{10\\dots01}_{m\\text{ bit fractional part}}\n$$\n\n**Fixed point with slope and bias**\n\napply a linear transform on fixed point:\n\n$$\ny = s*x + z\n$$\n\n\n\n#### Floating-poing arithmatic\n\n![alt](../images/DSD/3_1.jpg)\n\n**IEEE 754 Floating Point Standard**\n\n* Called Biased Notation, where bias is number subtracted to get real number. \n* IEEE 754 uses bias of 127 for single precision, 1023 for double precision.\n\n![alt](../images/DSD/3_3.jpg)\n\n$$\n(-1)^S \\times (1 + m) \\times 2^{(E - \\text{Bias})}\n$$\n\n**fp15(helf precision)**\n\n![alt](../images/DSD/3_2.jpg)\n\n### Hardware implications\n\n![alt](../images/DSD/3_4.jpg)\n\n加法下定点数比浮点数功耗小得多，但是乘法下定点数和浮点数的性能差不多。\n\nLow bit Fixed-point representations on digital system\n\n### Quantization for deep learning\n\n* Post-training quantization\n* Quantization-aware training\n\n**Post-training quantization**\n\n$$\nr = S(Q - Z)\\\\\nOA[i, k] =\\sum\\limits_{j=1}^{N}(W[i, j] * IA[j, k])\\\\\nq_{OA}^{(i, k)} = Z_{OA} + \\frac{S_W * S_{IA}}{S_{OA}}\\sum\\limits_{j=1}^{N} (q_W^{(i, j)} * q_{IA}^{(j, k)})\n$$\n\nChoose the optimal threshold\n\nNo saturation is bad \n\n### Classic research for quantization methods\n\n**Basic structure**\n\nWeight Quantization & Activation Quantization\n\n![alt](../images/DSD/3_5.jpg)\n\n**Dorefa Net**\n\n* quantization for gradient\n* normalize data to ensure the data distribution not change after quantization\n* uniform noise to offset the quantization noise for gradient\n* replace accumulate with bitcount operation\n* result is that gradient precision is most sensitive in TAQ(G > A > W)\n\n**INQ**\n\n* quantization first half and freeze the other, then unfreeze other to train normally\n* exchange the first half and second half, and repeat above\n\n![alt](../images/DSD/3_6.jpg)\n\n**Pact**\n\n* clipping the activation before quantization is better\n\n$$\nPACT(x) = 0.5(|x| - |x - \\alpha| + \\alpha) = \\begin{cases}\n    0, x<0,\\\\\n    x, 0\\le x \\lt \\alpha,\\\\\n    \\alpha, x \\ge \\alpha \n\\end{cases}\n$$\n\nDifferent layers need different α\n\nalpha should be learnable\n\n**Outlier quantization**\n\n* Use different quantized bits to quantize different weights. Some weight can have higher precision while others not.\n\n![alt](../images/DSD/3_7.jpg)\n\n**Quantization interval learning**\n\n* Most of the weights are very small. Minor weights can have too large value.\n\n![alt](../images/DSD/3_8.jpg)\n\na should be pruned, c should be clipped, only b worths quantizing.\n\n**Binary neural networks (BNN)**\n\n* Networks with weights composed of {-1, 1}\n\n![alt](../images/DSD/3_9.jpg)\n\n* 计算时长跟精度有平方反比的关系，优化是平方的\n* 存储跟精度只有线性的关系，优化是线性的，由于BNN bit数少，总的参数量更多，实际上存储没怎么优化\n* BNN 大幅优化了计算，但是存储没变，此时存储成为了瓶颈\n\n**State-of-the-art hardware support for low \nprecision DNNs**\n\n![alt](../images/DSD/3_10.jpg)\n\n## Pruning\n\n稀疏矩阵是指矩阵中大部分元素都是0的矩阵。获得稀疏矩阵，有助于加速训练和推理速度。\n\n### Sparsity: New Dimension For Efficiency\n\n稀疏性的来源：\n* 剪枝 - 权重\n* ReLU - 激活\n* Domain Specific\n\n#### Weight Sparsity: Pruning\n\n剪枝方法：\n* 很多参数其实是很接近0的数\n* 因此，低于某一阈值时，直接将其赋0.但是这样会影响精度。\n* 还可以用添加正则项的方法（Weight decay）：\n  * $CF = MSE_{train} + \\lambda \\sum_i w_i^2$\n  * $CF = MSE_{train} + \\lambda \\sum_i |w_i|$\n\n#### Activation Sparsity: ReLU\n\n### Weight Sparsity Perspective\n\n不同的稀疏程度：\n\n![alt](../images/DSD/4_1.jpg)\n\n#### Unstructured Sparsity\n\nHan Song@NIPS2015 的剪枝策略：\n\n![alt](../images/DSD/4_2.jpg)\n\n第一轮训练后，将所有接近0的神经元剪除，再重新对剩下的进行训练(retrain)。\n\n* 压缩比很高，而准确率几乎不下降\n* 对于硬件并不友好，虽然有很多0，但是硬件上没法把它们压缩掉。\n* 计算速度并没有提高，甚至降低了\n\n\n#### Structural Sparsity\n\n\n**SSL 剪枝策略(Structured weight pruning)**\n\n* 不是剪一个神经元，而是把一行/一列/一个通道全部剪掉。（不过，不是真的剪枝，而是修改代价函数的正则项）\n* 规则化的剪枝对硬件更加友好\n\n代价函数的表达式：\n\n![alt](../images/DSD/4_4.jpg)\n\n* 成功在一般设备上加速了\n\n**Pattern Pruning**\n\n研究卷积核内非0的权重是如何分布的。\n\n![alt](../images/DSD/4_5.jpg)\n\n如果某个“分布模式”反复的出现，就可以对它进行压缩存储：\n\n![alt](../images/DSD/4_6.jpg)\n\n这一方面的成果：\n* Flexible-Length Pattern Pruning：用概率统计方法得到特定的模式\n* Fixed-Length Pattern Pruning：约束了模式里面非0元素的个数\n\n\n#### Unstructured vs. structured\n\n剪枝技术基本上已经成熟：\n* Non-stuctured pruning\n  * 高压缩率\n  * 只能在特定设备上来降低功耗，但是性能其实没什么提升\n* Structured pruning\n  * 对硬件更友好\n  * 低压缩率\n\n（压缩率指的是训练的速度，即将数据“压缩”为神经网络的内蕴知识的能力。）\n\n#### Frequency-Domain Sparsity\n\n采用循环的卷积核\n* 因为循环出现的元素，存储降低\n* 计算等价为循环卷积，可以转换为 FFT 频域相乘，获得更高效的计算\n\n### Activation Sparsity Perspective\n\n#### Inter-Frame Sparsity\n\n一段序列的相邻帧之间具有相似性。因此只需要存储帧与帧之间的差值就行了。\n\nYuan Z@ISSCC 2020 的结论：\n* 差分帧并不是稀疏的\n* 差分帧的数值集中于低的bit位，分布集中\n* 而高bit位很多都是0，非常稀疏\n\n因此，可以对低 bit 位和高 bit 位拆分处理。\n\n#### ROI Spasity：Input Dependent\n\nROI: Region of Interest\n\n图像里包含的信息，有的丰富，有的贫乏，有的容易识别，有的很难识别。\n* 稠密的输入用大核，稀疏的输入用小核？\n\n基于不同的输入，采用不同的网络：\n* 图像中难度高的区域通过更深的网络层\n* 难度低的区域通过更浅的网络层\n\n### Leveraging Sparsity in Storage\n\n如何压缩稀疏矩阵的存储空间？\n\n#### Bitmask Compression\n\n![alt](../images/DSD/4_7.jpg)\n\n#### Run-Length Encoding\n\n游程编码\n(matlab警告)\n\n![alt](../images/DSD/4_8.jpg)\n\n#### Compressed Sparse Row (CSR)\n\n![alt](../images/DSD/4_10.jpg)\n\n#### Compressed Sparse Column (CSC)\n\n![alt](../images/DSD/4_9.jpg)\n\n#### The Taco Notation\n\n?\n\n\n## 讲座\n\n### 量化\n\nUniform & Non-uniform\n\nNon-uniform quantization is not efficient for hardware deployment\n\nSymmetric vs Asymmetric Quantization\n\nQuantization Granularity: Layer-wise vs Channel-wise\n\nDynamic vs Static Quantization\n\n静态的更常用，因为量化本身就是为了加快速度，动态量化却一边训模型一边更新量化区间的范围，反而减慢了速度。不过也有使用动态量化的时候（Mid Journey 生成图像）。\n\n什么是mixed-precsion quantization？\n\n","source":"_posts/数字系统设计.md","raw":"---\ntitle: 数字系统设计\ndate: 2023-09-20 13:33:09\ntags: note\nkatex: true\n---\n\n## 绪论\n\n软硬件协同，制作深度学习硬件\n\n理论课，讲座，Lab\n\n专用电路\n\n目标：做一个类似于Google TPU中的某计算模块\n\nbenchmark: ML\n\n每4周一个Lab，无期中期末\n\n作业：\n\nAlexNet Paper\n\nQuantization of CNN\n\n## DNN\n\n### Training & Inference\n\nTraining: forward and backward\n\nInference: backward\n\n### Model\n\n![](../images/DSD/2_1.jpg)\n\n五类算子：\n\n![](../images/DSD/2_2.jpg)\n\n特征提取器：卷积层，池化层；\n\n分类器：全连接层\n\n**线性卷积层**\n\n边界扩充(Padding)：在图像周围扩展一圈0，避免多次卷积导致数据尺寸越来越小\n\n卷积步长(Stride)：卷积核每次跳的步数。可以用来让数据尺寸快速变化\n\n\n非线性函数-激活函数\n\n非线性-正则化函数\n\n非线性-池化函数\n\n**池化层**\n\n池化层减小图片的尺寸，从而减小参数的数量和计算量。\n\n最大池化：在池化窗口内取最大值作为输出。\n* 复杂度低，硬件实现容易\n* 最为常用\n\n平均池化：取池化窗口内的平均值作为输出。\n\n$L^2$ 池化法：对所有的数计算平方后累加求和再开平方。\n* 计算复杂度高\n* 几何平均池化的复杂度更高\n\n**线性全连接层**\n\n将特征图映射为分类结果\n\n**Softmax 层**\n\n有的模型在输出层使用softmax对输出进行归一化：\n\n$$\nf(z_j) = \\dfrac{e^{z_j}}{\\sum_{i = 0}^n e^{z_j}}\n$$\n\n* 输入和输出规模相同\n* 归一化计算，让较大的值凸显，让较小的值被抑制，从而决定分类概率\n\n**卷积神经网络的总体结构**\n\n\n\n### Dataset\n\n数据集的建立：数据采集，数据标签，数据清洗，数据增强，数据分割\n\n### Cost function\n\n### Optimization\n\n* 梯度下降法\n* SGD\n* 动量法：计算过去的平均梯度\n* AdaGrad法：累加梯度方差\n* RMSProp：按时间降低学习率\n* Adam 算法：指数加权移动平均值计算梯度动量和二次矩\n* SGD简单，但是训练过程边长，自适应算法会更高效\n\n### Evaluation\n\n**回归问题指标**\n\nPSNR\n\n$$\nPSNR = 10 \\cdot \\log_{10}(\\frac{MAX_I^2}{MSE})\n$$\n\n**分类问题指标**\n\n* Top1 accuracy\n* Top5 accuracy\n\n**IoU**\n\nIntersection of Union?\n\n$$\n\\text{IoU} = \\frac{|A\\cap B|}{|A \\cup B|}\n$$\n\n**检测任务评价指标 mAP**\n\nmean average precision\n\n真阳性TP: 预测为真，实际为真\n\n假阳性FP：预测为真，实际为假\n\n假阴性FN：预测为假，实际为真\n\n**查全率（召回率，Recall）和查准率（准确率，Precision）**\n\n$$\n\\text{Precision} = \\frac{TP}{TP + FP}\\\\\n\\text{Recall} = \\frac{TP}{TP + FN}\n$$\n\n置信度衡量的是模型认为有效的自信程度。我们先将结果按照置信度从高到低排序。\n\nmAP是不同查全率下，最高查准率的平均值。\n\n### 网络结构的发展和讨论\n\n**分类任务**\n\nAlexNet\n* 使用多个卷积层，有效提取图像特征\n* ReLU 提高训练速度\n* Dropout、数据增强扩大训练集，防止过拟合\n\nVGG\n* 使用 3 * 3 的卷积核取代 AlexNet 的大卷积核\n    * 提升收敛速度\n    * 参数量更少\n    * 可以构建更深的网络，有更多的非线性变换，还有更强的表征能力\n* 参数预初始化策略\n\nResNet\n\n?\n\n**目标检测**\n\nTwo-stage v.s. One-stage\n\n**Two-stage**\n\n先画框，再分类\n\nMS CoCo Dataset\n* 用的最多的还是目标检测任务\n\nR-CNN\n* 输入图像\n* 提取候选框\n* 每一个候选框提取单独的特征\n* 进行分类\n\nFast R-CNN\n* 输入图像\n* 一次特征提取\n* 提取候选框\n* 进行分类\n\nFaster R-CNN\n* 输入图像\n* 一次特征提取\n* 提取候选框\n* 进行分类\n\n**One-stage**\n\nYOLO\n\n五代发展，最广泛的目标检测算法\n\n对于每一个像素，都会输出一个对应的特征向量，包含：\n* 二分类：是物体中心的置信度\n* 回归：偏离物体中心的长度 $\\Delta x$ 和 $\\Delta y$\n* 分类：对应的物体分类以及置信度\n* 回归：该像素所代表的物体的长宽，YOLO有一些基础框(anchor)，输出值是相对基础框的形变 $\\Delta h$ 和 $\\Delta w$\n\n\n**NMS (Non-Maximum Suppression)**\nBounding boxes for one instance may overlap.\nMethod: For each type, use NMS to eliminate redundant bounding boxes (greedy approach).\nWorkflow:\n1. Sort candidate bounding boxes by classification confidence.\n2. Adding the boxes b with most confidence to output list, and delete it from the candidate boxes.\n3. Calculate IoU between b and other boxes bi. If > threshold, delete bi.\n4. Repeat until no candidate bounding boxes.\n\n**序列模型（Serial Model）**\n\nto process Speech, text, video, audio, etc.\n\nFeature: \n1. The data input is in the time sequence.\n2. There is a correlation between the data before and after.\n\nSo the model should have the ability to \"store\" information.\n\nSpeech dataset: TIMIT\n1. It consists of recordings of 630 speakers of 8 dialects of American English each reading 10 phonetically-rich sentences.\n2. It also comes with the word and phone-level transcriptions of the speech.\n\nVideo dataset: DAVIS\n\nThe Densely Annotation Video Segmentation dataset (DAVIS) is a high quality and high resolution densely annotated video segmentation dataset under two resolutions, 480p and 1080p.\n\nThere are 50 video sequences with 3455 densely annotated frames in pixel level. 30 videos with 2079 frames are for training and 20 videos with 1376 frames are for validation.\n\nNLP dataset: GLUE\n\nGeneral Language Understanding Evaluation (GLUE) benchmark: Standard split of data totrain, validation, test, where labels for the test set is only held in the server.\n\n* Sentence pair tasks\n    * MNLI, Multi-Genre Natural Language Inference\n    * QQP, Ouora Ouestion Pairs\n    * QNLI, Ouestion Natural Language Inference\n    * STS-B The Semantic Textual Similarity Benchmark\n    * MRPC Microsoft Research Paraphrase Corpus\n    * RTE Recognizing Textual Entailment\n    * WNLI Winograd NLI is a small natural language inference \n* datasetSingle sentence classification\n    * SST-2 The Stanford Sentiment Treebank\n    * CoLA The Corpus of Linguistic Acceptability\n\n**Models**\n\n**RNN: Recurrent Neural Network**\n\n* one to one \n* one to many\n* many to one\n* many to many\n* many to many\n\n![](../images/DSD/2_3.jpg)\n\n损失函数的计算：\n\n单个时刻：\n\n$$\nL^{(t)} = -\\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$\n\n整个序列：\n\n$$\nL = \\sum\\limits_{t=1}^{\\tau}L^{(t)} = - \\sum\\limits_{t=1}^{\\tau} \\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$\n\n然后可求梯度：\n\n![alt](../images/DSD/2_4.jpg)\n\n循环神经网络存在梯度爆炸或梯度消失，因此无法处理长期的依赖关系。\n\n**LSTM: Solving the Gradient**\n\n**Transformer**\n\nSelf attention:\n\n$$\n\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK}{\\sqrt d_k})V\n$$\n\n## Quantization\n\n### Fixed-point and floating-point representation\n\n#### Fixed Point arithmetic\n\n$$\n\\underbrace{0}_{\\text{Sign bit}}\\ \\ \\underbrace{10\\dots01}_{n\\text{ bit integer part}}\\ \\ .\\underbrace{10\\dots01}_{m\\text{ bit fractional part}}\n$$\n\n**Fixed point with slope and bias**\n\napply a linear transform on fixed point:\n\n$$\ny = s*x + z\n$$\n\n\n\n#### Floating-poing arithmatic\n\n![alt](../images/DSD/3_1.jpg)\n\n**IEEE 754 Floating Point Standard**\n\n* Called Biased Notation, where bias is number subtracted to get real number. \n* IEEE 754 uses bias of 127 for single precision, 1023 for double precision.\n\n![alt](../images/DSD/3_3.jpg)\n\n$$\n(-1)^S \\times (1 + m) \\times 2^{(E - \\text{Bias})}\n$$\n\n**fp15(helf precision)**\n\n![alt](../images/DSD/3_2.jpg)\n\n### Hardware implications\n\n![alt](../images/DSD/3_4.jpg)\n\n加法下定点数比浮点数功耗小得多，但是乘法下定点数和浮点数的性能差不多。\n\nLow bit Fixed-point representations on digital system\n\n### Quantization for deep learning\n\n* Post-training quantization\n* Quantization-aware training\n\n**Post-training quantization**\n\n$$\nr = S(Q - Z)\\\\\nOA[i, k] =\\sum\\limits_{j=1}^{N}(W[i, j] * IA[j, k])\\\\\nq_{OA}^{(i, k)} = Z_{OA} + \\frac{S_W * S_{IA}}{S_{OA}}\\sum\\limits_{j=1}^{N} (q_W^{(i, j)} * q_{IA}^{(j, k)})\n$$\n\nChoose the optimal threshold\n\nNo saturation is bad \n\n### Classic research for quantization methods\n\n**Basic structure**\n\nWeight Quantization & Activation Quantization\n\n![alt](../images/DSD/3_5.jpg)\n\n**Dorefa Net**\n\n* quantization for gradient\n* normalize data to ensure the data distribution not change after quantization\n* uniform noise to offset the quantization noise for gradient\n* replace accumulate with bitcount operation\n* result is that gradient precision is most sensitive in TAQ(G > A > W)\n\n**INQ**\n\n* quantization first half and freeze the other, then unfreeze other to train normally\n* exchange the first half and second half, and repeat above\n\n![alt](../images/DSD/3_6.jpg)\n\n**Pact**\n\n* clipping the activation before quantization is better\n\n$$\nPACT(x) = 0.5(|x| - |x - \\alpha| + \\alpha) = \\begin{cases}\n    0, x<0,\\\\\n    x, 0\\le x \\lt \\alpha,\\\\\n    \\alpha, x \\ge \\alpha \n\\end{cases}\n$$\n\nDifferent layers need different α\n\nalpha should be learnable\n\n**Outlier quantization**\n\n* Use different quantized bits to quantize different weights. Some weight can have higher precision while others not.\n\n![alt](../images/DSD/3_7.jpg)\n\n**Quantization interval learning**\n\n* Most of the weights are very small. Minor weights can have too large value.\n\n![alt](../images/DSD/3_8.jpg)\n\na should be pruned, c should be clipped, only b worths quantizing.\n\n**Binary neural networks (BNN)**\n\n* Networks with weights composed of {-1, 1}\n\n![alt](../images/DSD/3_9.jpg)\n\n* 计算时长跟精度有平方反比的关系，优化是平方的\n* 存储跟精度只有线性的关系，优化是线性的，由于BNN bit数少，总的参数量更多，实际上存储没怎么优化\n* BNN 大幅优化了计算，但是存储没变，此时存储成为了瓶颈\n\n**State-of-the-art hardware support for low \nprecision DNNs**\n\n![alt](../images/DSD/3_10.jpg)\n\n## Pruning\n\n稀疏矩阵是指矩阵中大部分元素都是0的矩阵。获得稀疏矩阵，有助于加速训练和推理速度。\n\n### Sparsity: New Dimension For Efficiency\n\n稀疏性的来源：\n* 剪枝 - 权重\n* ReLU - 激活\n* Domain Specific\n\n#### Weight Sparsity: Pruning\n\n剪枝方法：\n* 很多参数其实是很接近0的数\n* 因此，低于某一阈值时，直接将其赋0.但是这样会影响精度。\n* 还可以用添加正则项的方法（Weight decay）：\n  * $CF = MSE_{train} + \\lambda \\sum_i w_i^2$\n  * $CF = MSE_{train} + \\lambda \\sum_i |w_i|$\n\n#### Activation Sparsity: ReLU\n\n### Weight Sparsity Perspective\n\n不同的稀疏程度：\n\n![alt](../images/DSD/4_1.jpg)\n\n#### Unstructured Sparsity\n\nHan Song@NIPS2015 的剪枝策略：\n\n![alt](../images/DSD/4_2.jpg)\n\n第一轮训练后，将所有接近0的神经元剪除，再重新对剩下的进行训练(retrain)。\n\n* 压缩比很高，而准确率几乎不下降\n* 对于硬件并不友好，虽然有很多0，但是硬件上没法把它们压缩掉。\n* 计算速度并没有提高，甚至降低了\n\n\n#### Structural Sparsity\n\n\n**SSL 剪枝策略(Structured weight pruning)**\n\n* 不是剪一个神经元，而是把一行/一列/一个通道全部剪掉。（不过，不是真的剪枝，而是修改代价函数的正则项）\n* 规则化的剪枝对硬件更加友好\n\n代价函数的表达式：\n\n![alt](../images/DSD/4_4.jpg)\n\n* 成功在一般设备上加速了\n\n**Pattern Pruning**\n\n研究卷积核内非0的权重是如何分布的。\n\n![alt](../images/DSD/4_5.jpg)\n\n如果某个“分布模式”反复的出现，就可以对它进行压缩存储：\n\n![alt](../images/DSD/4_6.jpg)\n\n这一方面的成果：\n* Flexible-Length Pattern Pruning：用概率统计方法得到特定的模式\n* Fixed-Length Pattern Pruning：约束了模式里面非0元素的个数\n\n\n#### Unstructured vs. structured\n\n剪枝技术基本上已经成熟：\n* Non-stuctured pruning\n  * 高压缩率\n  * 只能在特定设备上来降低功耗，但是性能其实没什么提升\n* Structured pruning\n  * 对硬件更友好\n  * 低压缩率\n\n（压缩率指的是训练的速度，即将数据“压缩”为神经网络的内蕴知识的能力。）\n\n#### Frequency-Domain Sparsity\n\n采用循环的卷积核\n* 因为循环出现的元素，存储降低\n* 计算等价为循环卷积，可以转换为 FFT 频域相乘，获得更高效的计算\n\n### Activation Sparsity Perspective\n\n#### Inter-Frame Sparsity\n\n一段序列的相邻帧之间具有相似性。因此只需要存储帧与帧之间的差值就行了。\n\nYuan Z@ISSCC 2020 的结论：\n* 差分帧并不是稀疏的\n* 差分帧的数值集中于低的bit位，分布集中\n* 而高bit位很多都是0，非常稀疏\n\n因此，可以对低 bit 位和高 bit 位拆分处理。\n\n#### ROI Spasity：Input Dependent\n\nROI: Region of Interest\n\n图像里包含的信息，有的丰富，有的贫乏，有的容易识别，有的很难识别。\n* 稠密的输入用大核，稀疏的输入用小核？\n\n基于不同的输入，采用不同的网络：\n* 图像中难度高的区域通过更深的网络层\n* 难度低的区域通过更浅的网络层\n\n### Leveraging Sparsity in Storage\n\n如何压缩稀疏矩阵的存储空间？\n\n#### Bitmask Compression\n\n![alt](../images/DSD/4_7.jpg)\n\n#### Run-Length Encoding\n\n游程编码\n(matlab警告)\n\n![alt](../images/DSD/4_8.jpg)\n\n#### Compressed Sparse Row (CSR)\n\n![alt](../images/DSD/4_10.jpg)\n\n#### Compressed Sparse Column (CSC)\n\n![alt](../images/DSD/4_9.jpg)\n\n#### The Taco Notation\n\n?\n\n\n## 讲座\n\n### 量化\n\nUniform & Non-uniform\n\nNon-uniform quantization is not efficient for hardware deployment\n\nSymmetric vs Asymmetric Quantization\n\nQuantization Granularity: Layer-wise vs Channel-wise\n\nDynamic vs Static Quantization\n\n静态的更常用，因为量化本身就是为了加快速度，动态量化却一边训模型一边更新量化区间的范围，反而减慢了速度。不过也有使用动态量化的时候（Mid Journey 生成图像）。\n\n什么是mixed-precsion quantization？\n\n","slug":"数字系统设计","published":1,"updated":"2024-03-19T06:01:16.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfi0000trsug4b5s2zgs","content":"<h2 id=\"绪论\"><a href=\"#绪论\" class=\"headerlink\" title=\"绪论\"></a>绪论</h2><p>软硬件协同，制作深度学习硬件</p>\n<p>理论课，讲座，Lab</p>\n<p>专用电路</p>\n<p>目标：做一个类似于Google TPU中的某计算模块</p>\n<p>benchmark: ML</p>\n<p>每4周一个Lab，无期中期末</p>\n<p>作业：</p>\n<p>AlexNet Paper</p>\n<p>Quantization of CNN</p>\n<h2 id=\"DNN\"><a href=\"#DNN\" class=\"headerlink\" title=\"DNN\"></a>DNN</h2><h3 id=\"Training-amp-Inference\"><a href=\"#Training-amp-Inference\" class=\"headerlink\" title=\"Training &amp; Inference\"></a>Training &amp; Inference</h3><p>Training: forward and backward</p>\n<p>Inference: backward</p>\n<h3 id=\"Model\"><a href=\"#Model\" class=\"headerlink\" title=\"Model\"></a>Model</h3><p><img src=\"/../images/DSD/2_1.jpg\" loading=\"lazy\"></p>\n<p>五类算子：</p>\n<p><img src=\"/../images/DSD/2_2.jpg\" loading=\"lazy\"></p>\n<p>特征提取器：卷积层，池化层；</p>\n<p>分类器：全连接层</p>\n<p><strong>线性卷积层</strong></p>\n<p>边界扩充(Padding)：在图像周围扩展一圈0，避免多次卷积导致数据尺寸越来越小</p>\n<p>卷积步长(Stride)：卷积核每次跳的步数。可以用来让数据尺寸快速变化</p>\n<p>非线性函数-激活函数</p>\n<p>非线性-正则化函数</p>\n<p>非线性-池化函数</p>\n<p><strong>池化层</strong></p>\n<p>池化层减小图片的尺寸，从而减小参数的数量和计算量。</p>\n<p>最大池化：在池化窗口内取最大值作为输出。</p>\n<ul>\n<li>复杂度低，硬件实现容易</li>\n<li>最为常用</li>\n</ul>\n<p>平均池化：取池化窗口内的平均值作为输出。</p>\n<p>$L^2$ 池化法：对所有的数计算平方后累加求和再开平方。</p>\n<ul>\n<li>计算复杂度高</li>\n<li>几何平均池化的复杂度更高</li>\n</ul>\n<p><strong>线性全连接层</strong></p>\n<p>将特征图映射为分类结果</p>\n<p><strong>Softmax 层</strong></p>\n<p>有的模型在输出层使用softmax对输出进行归一化：</p>\n<div>$$\nf(z_j) = \\dfrac{e^{z_j}}{\\sum_{i = 0}^n e^{z_j}}\n$$</div>\n\n<ul>\n<li>输入和输出规模相同</li>\n<li>归一化计算，让较大的值凸显，让较小的值被抑制，从而决定分类概率</li>\n</ul>\n<p><strong>卷积神经网络的总体结构</strong></p>\n<h3 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h3><p>数据集的建立：数据采集，数据标签，数据清洗，数据增强，数据分割</p>\n<h3 id=\"Cost-function\"><a href=\"#Cost-function\" class=\"headerlink\" title=\"Cost function\"></a>Cost function</h3><h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><ul>\n<li>梯度下降法</li>\n<li>SGD</li>\n<li>动量法：计算过去的平均梯度</li>\n<li>AdaGrad法：累加梯度方差</li>\n<li>RMSProp：按时间降低学习率</li>\n<li>Adam 算法：指数加权移动平均值计算梯度动量和二次矩</li>\n<li>SGD简单，但是训练过程边长，自适应算法会更高效</li>\n</ul>\n<h3 id=\"Evaluation\"><a href=\"#Evaluation\" class=\"headerlink\" title=\"Evaluation\"></a>Evaluation</h3><p><strong>回归问题指标</strong></p>\n<p>PSNR</p>\n<div>$$\nPSNR = 10 \\cdot \\log_{10}(\\frac{MAX_I^2}{MSE})\n$$</div>\n\n<p><strong>分类问题指标</strong></p>\n<ul>\n<li>Top1 accuracy</li>\n<li>Top5 accuracy</li>\n</ul>\n<p><strong>IoU</strong></p>\n<p>Intersection of Union?</p>\n<div>$$\n\\text{IoU} = \\frac{|A\\cap B|}{|A \\cup B|}\n$$</div>\n\n<p><strong>检测任务评价指标 mAP</strong></p>\n<p>mean average precision</p>\n<p>真阳性TP: 预测为真，实际为真</p>\n<p>假阳性FP：预测为真，实际为假</p>\n<p>假阴性FN：预测为假，实际为真</p>\n<p><strong>查全率（召回率，Recall）和查准率（准确率，Precision）</strong></p>\n<div>$$\n\\text{Precision} = \\frac{TP}{TP + FP}\\\\\n\\text{Recall} = \\frac{TP}{TP + FN}\n$$</div>\n\n<p>置信度衡量的是模型认为有效的自信程度。我们先将结果按照置信度从高到低排序。</p>\n<p>mAP是不同查全率下，最高查准率的平均值。</p>\n<h3 id=\"网络结构的发展和讨论\"><a href=\"#网络结构的发展和讨论\" class=\"headerlink\" title=\"网络结构的发展和讨论\"></a>网络结构的发展和讨论</h3><p><strong>分类任务</strong></p>\n<p>AlexNet</p>\n<ul>\n<li>使用多个卷积层，有效提取图像特征</li>\n<li>ReLU 提高训练速度</li>\n<li>Dropout、数据增强扩大训练集，防止过拟合</li>\n</ul>\n<p>VGG</p>\n<ul>\n<li>使用 3 * 3 的卷积核取代 AlexNet 的大卷积核<ul>\n<li>提升收敛速度</li>\n<li>参数量更少</li>\n<li>可以构建更深的网络，有更多的非线性变换，还有更强的表征能力</li>\n</ul>\n</li>\n<li>参数预初始化策略</li>\n</ul>\n<p>ResNet</p>\n<p>?</p>\n<p><strong>目标检测</strong></p>\n<p>Two-stage v.s. One-stage</p>\n<p><strong>Two-stage</strong></p>\n<p>先画框，再分类</p>\n<p>MS CoCo Dataset</p>\n<ul>\n<li>用的最多的还是目标检测任务</li>\n</ul>\n<p>R-CNN</p>\n<ul>\n<li>输入图像</li>\n<li>提取候选框</li>\n<li>每一个候选框提取单独的特征</li>\n<li>进行分类</li>\n</ul>\n<p>Fast R-CNN</p>\n<ul>\n<li>输入图像</li>\n<li>一次特征提取</li>\n<li>提取候选框</li>\n<li>进行分类</li>\n</ul>\n<p>Faster R-CNN</p>\n<ul>\n<li>输入图像</li>\n<li>一次特征提取</li>\n<li>提取候选框</li>\n<li>进行分类</li>\n</ul>\n<p><strong>One-stage</strong></p>\n<p>YOLO</p>\n<p>五代发展，最广泛的目标检测算法</p>\n<p>对于每一个像素，都会输出一个对应的特征向量，包含：</p>\n<ul>\n<li>二分类：是物体中心的置信度</li>\n<li>回归：偏离物体中心的长度 $\\Delta x$ 和 $\\Delta y$</li>\n<li>分类：对应的物体分类以及置信度</li>\n<li>回归：该像素所代表的物体的长宽，YOLO有一些基础框(anchor)，输出值是相对基础框的形变 $\\Delta h$ 和 $\\Delta w$</li>\n</ul>\n<p><strong>NMS (Non-Maximum Suppression)</strong><br>Bounding boxes for one instance may overlap.<br>Method: For each type, use NMS to eliminate redundant bounding boxes (greedy approach).<br>Workflow:</p>\n<ol>\n<li>Sort candidate bounding boxes by classification confidence.</li>\n<li>Adding the boxes b with most confidence to output list, and delete it from the candidate boxes.</li>\n<li>Calculate IoU between b and other boxes bi. If &gt; threshold, delete bi.</li>\n<li>Repeat until no candidate bounding boxes.</li>\n</ol>\n<p><strong>序列模型（Serial Model）</strong></p>\n<p>to process Speech, text, video, audio, etc.</p>\n<p>Feature: </p>\n<ol>\n<li>The data input is in the time sequence.</li>\n<li>There is a correlation between the data before and after.</li>\n</ol>\n<p>So the model should have the ability to “store” information.</p>\n<p>Speech dataset: TIMIT</p>\n<ol>\n<li>It consists of recordings of 630 speakers of 8 dialects of American English each reading 10 phonetically-rich sentences.</li>\n<li>It also comes with the word and phone-level transcriptions of the speech.</li>\n</ol>\n<p>Video dataset: DAVIS</p>\n<p>The Densely Annotation Video Segmentation dataset (DAVIS) is a high quality and high resolution densely annotated video segmentation dataset under two resolutions, 480p and 1080p.</p>\n<p>There are 50 video sequences with 3455 densely annotated frames in pixel level. 30 videos with 2079 frames are for training and 20 videos with 1376 frames are for validation.</p>\n<p>NLP dataset: GLUE</p>\n<p>General Language Understanding Evaluation (GLUE) benchmark: Standard split of data totrain, validation, test, where labels for the test set is only held in the server.</p>\n<ul>\n<li>Sentence pair tasks<ul>\n<li>MNLI, Multi-Genre Natural Language Inference</li>\n<li>QQP, Ouora Ouestion Pairs</li>\n<li>QNLI, Ouestion Natural Language Inference</li>\n<li>STS-B The Semantic Textual Similarity Benchmark</li>\n<li>MRPC Microsoft Research Paraphrase Corpus</li>\n<li>RTE Recognizing Textual Entailment</li>\n<li>WNLI Winograd NLI is a small natural language inference</li>\n</ul>\n</li>\n<li>datasetSingle sentence classification<ul>\n<li>SST-2 The Stanford Sentiment Treebank</li>\n<li>CoLA The Corpus of Linguistic Acceptability</li>\n</ul>\n</li>\n</ul>\n<p><strong>Models</strong></p>\n<p><strong>RNN: Recurrent Neural Network</strong></p>\n<ul>\n<li>one to one </li>\n<li>one to many</li>\n<li>many to one</li>\n<li>many to many</li>\n<li>many to many</li>\n</ul>\n<p><img src=\"/../images/DSD/2_3.jpg\" loading=\"lazy\"></p>\n<p>损失函数的计算：</p>\n<p>单个时刻：</p>\n<div>$$\nL^{(t)} = -\\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$</div>\n\n<p>整个序列：</p>\n<div>$$\nL = \\sum\\limits_{t=1}^{\\tau}L^{(t)} = - \\sum\\limits_{t=1}^{\\tau} \\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$</div>\n\n<p>然后可求梯度：</p>\n<p><img src=\"/../images/DSD/2_4.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>循环神经网络存在梯度爆炸或梯度消失，因此无法处理长期的依赖关系。</p>\n<p><strong>LSTM: Solving the Gradient</strong></p>\n<p><strong>Transformer</strong></p>\n<p>Self attention:</p>\n<div>$$\n\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK}{\\sqrt d_k})V\n$$</div>\n\n<h2 id=\"Quantization\"><a href=\"#Quantization\" class=\"headerlink\" title=\"Quantization\"></a>Quantization</h2><h3 id=\"Fixed-point-and-floating-point-representation\"><a href=\"#Fixed-point-and-floating-point-representation\" class=\"headerlink\" title=\"Fixed-point and floating-point representation\"></a>Fixed-point and floating-point representation</h3><h4 id=\"Fixed-Point-arithmetic\"><a href=\"#Fixed-Point-arithmetic\" class=\"headerlink\" title=\"Fixed Point arithmetic\"></a>Fixed Point arithmetic</h4><div>$$\n\\underbrace{0}_{\\text{Sign bit}}\\ \\ \\underbrace{10\\dots01}_{n\\text{ bit integer part}}\\ \\ .\\underbrace{10\\dots01}_{m\\text{ bit fractional part}}\n$$</div>\n\n<p><strong>Fixed point with slope and bias</strong></p>\n<p>apply a linear transform on fixed point:</p>\n<div>$$\ny = s*x + z\n$$</div>\n\n\n\n<h4 id=\"Floating-poing-arithmatic\"><a href=\"#Floating-poing-arithmatic\" class=\"headerlink\" title=\"Floating-poing arithmatic\"></a>Floating-poing arithmatic</h4><p><img src=\"/../images/DSD/3_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><strong>IEEE 754 Floating Point Standard</strong></p>\n<ul>\n<li>Called Biased Notation, where bias is number subtracted to get real number. </li>\n<li>IEEE 754 uses bias of 127 for single precision, 1023 for double precision.</li>\n</ul>\n<p><img src=\"/../images/DSD/3_3.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<div>$$\n(-1)^S \\times (1 + m) \\times 2^{(E - \\text{Bias})}\n$$</div>\n\n<p><strong>fp15(helf precision)</strong></p>\n<p><img src=\"/../images/DSD/3_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h3 id=\"Hardware-implications\"><a href=\"#Hardware-implications\" class=\"headerlink\" title=\"Hardware implications\"></a>Hardware implications</h3><p><img src=\"/../images/DSD/3_4.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>加法下定点数比浮点数功耗小得多，但是乘法下定点数和浮点数的性能差不多。</p>\n<p>Low bit Fixed-point representations on digital system</p>\n<h3 id=\"Quantization-for-deep-learning\"><a href=\"#Quantization-for-deep-learning\" class=\"headerlink\" title=\"Quantization for deep learning\"></a>Quantization for deep learning</h3><ul>\n<li>Post-training quantization</li>\n<li>Quantization-aware training</li>\n</ul>\n<p><strong>Post-training quantization</strong></p>\n<div>$$\nr = S(Q - Z)\\\\\nOA[i, k] =\\sum\\limits_{j=1}^{N}(W[i, j] * IA[j, k])\\\\\nq_{OA}^{(i, k)} = Z_{OA} + \\frac{S_W * S_{IA}}{S_{OA}}\\sum\\limits_{j=1}^{N} (q_W^{(i, j)} * q_{IA}^{(j, k)})\n$$</div>\n\n<p>Choose the optimal threshold</p>\n<p>No saturation is bad </p>\n<h3 id=\"Classic-research-for-quantization-methods\"><a href=\"#Classic-research-for-quantization-methods\" class=\"headerlink\" title=\"Classic research for quantization methods\"></a>Classic research for quantization methods</h3><p><strong>Basic structure</strong></p>\n<p>Weight Quantization &amp; Activation Quantization</p>\n<p><img src=\"/../images/DSD/3_5.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><strong>Dorefa Net</strong></p>\n<ul>\n<li>quantization for gradient</li>\n<li>normalize data to ensure the data distribution not change after quantization</li>\n<li>uniform noise to offset the quantization noise for gradient</li>\n<li>replace accumulate with bitcount operation</li>\n<li>result is that gradient precision is most sensitive in TAQ(G &gt; A &gt; W)</li>\n</ul>\n<p><strong>INQ</strong></p>\n<ul>\n<li>quantization first half and freeze the other, then unfreeze other to train normally</li>\n<li>exchange the first half and second half, and repeat above</li>\n</ul>\n<p><img src=\"/../images/DSD/3_6.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><strong>Pact</strong></p>\n<ul>\n<li>clipping the activation before quantization is better</li>\n</ul>\n<div>$$\nPACT(x) = 0.5(|x| - |x - \\alpha| + \\alpha) = \\begin{cases}\n    0, x<0,\\\\\n    x, 0\\le x \\lt \\alpha,\\\\\n    \\alpha, x \\ge \\alpha \n\\end{cases}\n$$</div>\n\n<p>Different layers need different α</p>\n<p>alpha should be learnable</p>\n<p><strong>Outlier quantization</strong></p>\n<ul>\n<li>Use different quantized bits to quantize different weights. Some weight can have higher precision while others not.</li>\n</ul>\n<p><img src=\"/../images/DSD/3_7.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><strong>Quantization interval learning</strong></p>\n<ul>\n<li>Most of the weights are very small. Minor weights can have too large value.</li>\n</ul>\n<p><img src=\"/../images/DSD/3_8.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>a should be pruned, c should be clipped, only b worths quantizing.</p>\n<p><strong>Binary neural networks (BNN)</strong></p>\n<ul>\n<li>Networks with weights composed of {-1, 1}</li>\n</ul>\n<p><img src=\"/../images/DSD/3_9.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<ul>\n<li>计算时长跟精度有平方反比的关系，优化是平方的</li>\n<li>存储跟精度只有线性的关系，优化是线性的，由于BNN bit数少，总的参数量更多，实际上存储没怎么优化</li>\n<li>BNN 大幅优化了计算，但是存储没变，此时存储成为了瓶颈</li>\n</ul>\n<p><strong>State-of-the-art hardware support for low<br>precision DNNs</strong></p>\n<p><img src=\"/../images/DSD/3_10.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h2 id=\"Pruning\"><a href=\"#Pruning\" class=\"headerlink\" title=\"Pruning\"></a>Pruning</h2><p>稀疏矩阵是指矩阵中大部分元素都是0的矩阵。获得稀疏矩阵，有助于加速训练和推理速度。</p>\n<h3 id=\"Sparsity-New-Dimension-For-Efficiency\"><a href=\"#Sparsity-New-Dimension-For-Efficiency\" class=\"headerlink\" title=\"Sparsity: New Dimension For Efficiency\"></a>Sparsity: New Dimension For Efficiency</h3><p>稀疏性的来源：</p>\n<ul>\n<li>剪枝 - 权重</li>\n<li>ReLU - 激活</li>\n<li>Domain Specific</li>\n</ul>\n<h4 id=\"Weight-Sparsity-Pruning\"><a href=\"#Weight-Sparsity-Pruning\" class=\"headerlink\" title=\"Weight Sparsity: Pruning\"></a>Weight Sparsity: Pruning</h4><p>剪枝方法：</p>\n<ul>\n<li>很多参数其实是很接近0的数</li>\n<li>因此，低于某一阈值时，直接将其赋0.但是这样会影响精度。</li>\n<li>还可以用添加正则项的方法（Weight decay）：<ul>\n<li>$CF &#x3D; MSE_{train} + \\lambda \\sum_i w_i^2$</li>\n<li>$CF &#x3D; MSE_{train} + \\lambda \\sum_i |w_i|$</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Activation-Sparsity-ReLU\"><a href=\"#Activation-Sparsity-ReLU\" class=\"headerlink\" title=\"Activation Sparsity: ReLU\"></a>Activation Sparsity: ReLU</h4><h3 id=\"Weight-Sparsity-Perspective\"><a href=\"#Weight-Sparsity-Perspective\" class=\"headerlink\" title=\"Weight Sparsity Perspective\"></a>Weight Sparsity Perspective</h3><p>不同的稀疏程度：</p>\n<p><img src=\"/../images/DSD/4_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"Unstructured-Sparsity\"><a href=\"#Unstructured-Sparsity\" class=\"headerlink\" title=\"Unstructured Sparsity\"></a>Unstructured Sparsity</h4><p>Han Song@NIPS2015 的剪枝策略：</p>\n<p><img src=\"/../images/DSD/4_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>第一轮训练后，将所有接近0的神经元剪除，再重新对剩下的进行训练(retrain)。</p>\n<ul>\n<li>压缩比很高，而准确率几乎不下降</li>\n<li>对于硬件并不友好，虽然有很多0，但是硬件上没法把它们压缩掉。</li>\n<li>计算速度并没有提高，甚至降低了</li>\n</ul>\n<h4 id=\"Structural-Sparsity\"><a href=\"#Structural-Sparsity\" class=\"headerlink\" title=\"Structural Sparsity\"></a>Structural Sparsity</h4><p><strong>SSL 剪枝策略(Structured weight pruning)</strong></p>\n<ul>\n<li>不是剪一个神经元，而是把一行&#x2F;一列&#x2F;一个通道全部剪掉。（不过，不是真的剪枝，而是修改代价函数的正则项）</li>\n<li>规则化的剪枝对硬件更加友好</li>\n</ul>\n<p>代价函数的表达式：</p>\n<p><img src=\"/../images/DSD/4_4.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<ul>\n<li>成功在一般设备上加速了</li>\n</ul>\n<p><strong>Pattern Pruning</strong></p>\n<p>研究卷积核内非0的权重是如何分布的。</p>\n<p><img src=\"/../images/DSD/4_5.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>如果某个“分布模式”反复的出现，就可以对它进行压缩存储：</p>\n<p><img src=\"/../images/DSD/4_6.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>这一方面的成果：</p>\n<ul>\n<li>Flexible-Length Pattern Pruning：用概率统计方法得到特定的模式</li>\n<li>Fixed-Length Pattern Pruning：约束了模式里面非0元素的个数</li>\n</ul>\n<h4 id=\"Unstructured-vs-structured\"><a href=\"#Unstructured-vs-structured\" class=\"headerlink\" title=\"Unstructured vs. structured\"></a>Unstructured vs. structured</h4><p>剪枝技术基本上已经成熟：</p>\n<ul>\n<li>Non-stuctured pruning<ul>\n<li>高压缩率</li>\n<li>只能在特定设备上来降低功耗，但是性能其实没什么提升</li>\n</ul>\n</li>\n<li>Structured pruning<ul>\n<li>对硬件更友好</li>\n<li>低压缩率</li>\n</ul>\n</li>\n</ul>\n<p>（压缩率指的是训练的速度，即将数据“压缩”为神经网络的内蕴知识的能力。）</p>\n<h4 id=\"Frequency-Domain-Sparsity\"><a href=\"#Frequency-Domain-Sparsity\" class=\"headerlink\" title=\"Frequency-Domain Sparsity\"></a>Frequency-Domain Sparsity</h4><p>采用循环的卷积核</p>\n<ul>\n<li>因为循环出现的元素，存储降低</li>\n<li>计算等价为循环卷积，可以转换为 FFT 频域相乘，获得更高效的计算</li>\n</ul>\n<h3 id=\"Activation-Sparsity-Perspective\"><a href=\"#Activation-Sparsity-Perspective\" class=\"headerlink\" title=\"Activation Sparsity Perspective\"></a>Activation Sparsity Perspective</h3><h4 id=\"Inter-Frame-Sparsity\"><a href=\"#Inter-Frame-Sparsity\" class=\"headerlink\" title=\"Inter-Frame Sparsity\"></a>Inter-Frame Sparsity</h4><p>一段序列的相邻帧之间具有相似性。因此只需要存储帧与帧之间的差值就行了。</p>\n<p>Yuan Z@ISSCC 2020 的结论：</p>\n<ul>\n<li>差分帧并不是稀疏的</li>\n<li>差分帧的数值集中于低的bit位，分布集中</li>\n<li>而高bit位很多都是0，非常稀疏</li>\n</ul>\n<p>因此，可以对低 bit 位和高 bit 位拆分处理。</p>\n<h4 id=\"ROI-Spasity：Input-Dependent\"><a href=\"#ROI-Spasity：Input-Dependent\" class=\"headerlink\" title=\"ROI Spasity：Input Dependent\"></a>ROI Spasity：Input Dependent</h4><p>ROI: Region of Interest</p>\n<p>图像里包含的信息，有的丰富，有的贫乏，有的容易识别，有的很难识别。</p>\n<ul>\n<li>稠密的输入用大核，稀疏的输入用小核？</li>\n</ul>\n<p>基于不同的输入，采用不同的网络：</p>\n<ul>\n<li>图像中难度高的区域通过更深的网络层</li>\n<li>难度低的区域通过更浅的网络层</li>\n</ul>\n<h3 id=\"Leveraging-Sparsity-in-Storage\"><a href=\"#Leveraging-Sparsity-in-Storage\" class=\"headerlink\" title=\"Leveraging Sparsity in Storage\"></a>Leveraging Sparsity in Storage</h3><p>如何压缩稀疏矩阵的存储空间？</p>\n<h4 id=\"Bitmask-Compression\"><a href=\"#Bitmask-Compression\" class=\"headerlink\" title=\"Bitmask Compression\"></a>Bitmask Compression</h4><p><img src=\"/../images/DSD/4_7.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"Run-Length-Encoding\"><a href=\"#Run-Length-Encoding\" class=\"headerlink\" title=\"Run-Length Encoding\"></a>Run-Length Encoding</h4><p>游程编码<br>(matlab警告)</p>\n<p><img src=\"/../images/DSD/4_8.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"Compressed-Sparse-Row-CSR\"><a href=\"#Compressed-Sparse-Row-CSR\" class=\"headerlink\" title=\"Compressed Sparse Row (CSR)\"></a>Compressed Sparse Row (CSR)</h4><p><img src=\"/../images/DSD/4_10.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"Compressed-Sparse-Column-CSC\"><a href=\"#Compressed-Sparse-Column-CSC\" class=\"headerlink\" title=\"Compressed Sparse Column (CSC)\"></a>Compressed Sparse Column (CSC)</h4><p><img src=\"/../images/DSD/4_9.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"The-Taco-Notation\"><a href=\"#The-Taco-Notation\" class=\"headerlink\" title=\"The Taco Notation\"></a>The Taco Notation</h4><p>?</p>\n<h2 id=\"讲座\"><a href=\"#讲座\" class=\"headerlink\" title=\"讲座\"></a>讲座</h2><h3 id=\"量化\"><a href=\"#量化\" class=\"headerlink\" title=\"量化\"></a>量化</h3><p>Uniform &amp; Non-uniform</p>\n<p>Non-uniform quantization is not efficient for hardware deployment</p>\n<p>Symmetric vs Asymmetric Quantization</p>\n<p>Quantization Granularity: Layer-wise vs Channel-wise</p>\n<p>Dynamic vs Static Quantization</p>\n<p>静态的更常用，因为量化本身就是为了加快速度，动态量化却一边训模型一边更新量化区间的范围，反而减慢了速度。不过也有使用动态量化的时候（Mid Journey 生成图像）。</p>\n<p>什么是mixed-precsion quantization？</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"绪论\"><a href=\"#绪论\" class=\"headerlink\" title=\"绪论\"></a>绪论</h2><p>软硬件协同，制作深度学习硬件</p>\n<p>理论课，讲座，Lab</p>\n<p>专用电路</p>\n<p>目标：做一个类似于Google TPU中的某计算模块</p>\n<p>benchmark: ML</p>\n<p>每4周一个Lab，无期中期末</p>\n<p>作业：</p>\n<p>AlexNet Paper</p>\n<p>Quantization of CNN</p>\n<h2 id=\"DNN\"><a href=\"#DNN\" class=\"headerlink\" title=\"DNN\"></a>DNN</h2><h3 id=\"Training-amp-Inference\"><a href=\"#Training-amp-Inference\" class=\"headerlink\" title=\"Training &amp; Inference\"></a>Training &amp; Inference</h3><p>Training: forward and backward</p>\n<p>Inference: backward</p>\n<h3 id=\"Model\"><a href=\"#Model\" class=\"headerlink\" title=\"Model\"></a>Model</h3><p><img src=\"/../images/DSD/2_1.jpg\"></p>\n<p>五类算子：</p>\n<p><img src=\"/../images/DSD/2_2.jpg\"></p>\n<p>特征提取器：卷积层，池化层；</p>\n<p>分类器：全连接层</p>\n<p><strong>线性卷积层</strong></p>\n<p>边界扩充(Padding)：在图像周围扩展一圈0，避免多次卷积导致数据尺寸越来越小</p>\n<p>卷积步长(Stride)：卷积核每次跳的步数。可以用来让数据尺寸快速变化</p>\n<p>非线性函数-激活函数</p>\n<p>非线性-正则化函数</p>\n<p>非线性-池化函数</p>\n<p><strong>池化层</strong></p>\n<p>池化层减小图片的尺寸，从而减小参数的数量和计算量。</p>\n<p>最大池化：在池化窗口内取最大值作为输出。</p>\n<ul>\n<li>复杂度低，硬件实现容易</li>\n<li>最为常用</li>\n</ul>\n<p>平均池化：取池化窗口内的平均值作为输出。</p>\n<p>$L^2$ 池化法：对所有的数计算平方后累加求和再开平方。</p>\n<ul>\n<li>计算复杂度高</li>\n<li>几何平均池化的复杂度更高</li>\n</ul>\n<p><strong>线性全连接层</strong></p>\n<p>将特征图映射为分类结果</p>\n<p><strong>Softmax 层</strong></p>\n<p>有的模型在输出层使用softmax对输出进行归一化：</p>\n<div>$$\nf(z_j) = \\dfrac{e^{z_j}}{\\sum_{i = 0}^n e^{z_j}}\n$$</div>\n\n<ul>\n<li>输入和输出规模相同</li>\n<li>归一化计算，让较大的值凸显，让较小的值被抑制，从而决定分类概率</li>\n</ul>\n<p><strong>卷积神经网络的总体结构</strong></p>\n<h3 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h3><p>数据集的建立：数据采集，数据标签，数据清洗，数据增强，数据分割</p>\n<h3 id=\"Cost-function\"><a href=\"#Cost-function\" class=\"headerlink\" title=\"Cost function\"></a>Cost function</h3><h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><ul>\n<li>梯度下降法</li>\n<li>SGD</li>\n<li>动量法：计算过去的平均梯度</li>\n<li>AdaGrad法：累加梯度方差</li>\n<li>RMSProp：按时间降低学习率</li>\n<li>Adam 算法：指数加权移动平均值计算梯度动量和二次矩</li>\n<li>SGD简单，但是训练过程边长，自适应算法会更高效</li>\n</ul>\n<h3 id=\"Evaluation\"><a href=\"#Evaluation\" class=\"headerlink\" title=\"Evaluation\"></a>Evaluation</h3><p><strong>回归问题指标</strong></p>\n<p>PSNR</p>\n<div>$$\nPSNR = 10 \\cdot \\log_{10}(\\frac{MAX_I^2}{MSE})\n$$</div>\n\n<p><strong>分类问题指标</strong></p>\n<ul>\n<li>Top1 accuracy</li>\n<li>Top5 accuracy</li>\n</ul>\n<p><strong>IoU</strong></p>\n<p>Intersection of Union?</p>\n<div>$$\n\\text{IoU} = \\frac{|A\\cap B|}{|A \\cup B|}\n$$</div>\n\n<p><strong>检测任务评价指标 mAP</strong></p>\n<p>mean average precision</p>\n<p>真阳性TP: 预测为真，实际为真</p>\n<p>假阳性FP：预测为真，实际为假</p>\n<p>假阴性FN：预测为假，实际为真</p>\n<p><strong>查全率（召回率，Recall）和查准率（准确率，Precision）</strong></p>\n<div>$$\n\\text{Precision} = \\frac{TP}{TP + FP}\\\\\n\\text{Recall} = \\frac{TP}{TP + FN}\n$$</div>\n\n<p>置信度衡量的是模型认为有效的自信程度。我们先将结果按照置信度从高到低排序。</p>\n<p>mAP是不同查全率下，最高查准率的平均值。</p>\n<h3 id=\"网络结构的发展和讨论\"><a href=\"#网络结构的发展和讨论\" class=\"headerlink\" title=\"网络结构的发展和讨论\"></a>网络结构的发展和讨论</h3><p><strong>分类任务</strong></p>\n<p>AlexNet</p>\n<ul>\n<li>使用多个卷积层，有效提取图像特征</li>\n<li>ReLU 提高训练速度</li>\n<li>Dropout、数据增强扩大训练集，防止过拟合</li>\n</ul>\n<p>VGG</p>\n<ul>\n<li>使用 3 * 3 的卷积核取代 AlexNet 的大卷积核<ul>\n<li>提升收敛速度</li>\n<li>参数量更少</li>\n<li>可以构建更深的网络，有更多的非线性变换，还有更强的表征能力</li>\n</ul>\n</li>\n<li>参数预初始化策略</li>\n</ul>\n<p>ResNet</p>\n<p>?</p>\n<p><strong>目标检测</strong></p>\n<p>Two-stage v.s. One-stage</p>\n<p><strong>Two-stage</strong></p>\n<p>先画框，再分类</p>\n<p>MS CoCo Dataset</p>\n<ul>\n<li>用的最多的还是目标检测任务</li>\n</ul>\n<p>R-CNN</p>\n<ul>\n<li>输入图像</li>\n<li>提取候选框</li>\n<li>每一个候选框提取单独的特征</li>\n<li>进行分类</li>\n</ul>\n<p>Fast R-CNN</p>\n<ul>\n<li>输入图像</li>\n<li>一次特征提取</li>\n<li>提取候选框</li>\n<li>进行分类</li>\n</ul>\n<p>Faster R-CNN</p>\n<ul>\n<li>输入图像</li>\n<li>一次特征提取</li>\n<li>提取候选框</li>\n<li>进行分类</li>\n</ul>\n<p><strong>One-stage</strong></p>\n<p>YOLO</p>\n<p>五代发展，最广泛的目标检测算法</p>\n<p>对于每一个像素，都会输出一个对应的特征向量，包含：</p>\n<ul>\n<li>二分类：是物体中心的置信度</li>\n<li>回归：偏离物体中心的长度 $\\Delta x$ 和 $\\Delta y$</li>\n<li>分类：对应的物体分类以及置信度</li>\n<li>回归：该像素所代表的物体的长宽，YOLO有一些基础框(anchor)，输出值是相对基础框的形变 $\\Delta h$ 和 $\\Delta w$</li>\n</ul>\n<p><strong>NMS (Non-Maximum Suppression)</strong><br>Bounding boxes for one instance may overlap.<br>Method: For each type, use NMS to eliminate redundant bounding boxes (greedy approach).<br>Workflow:</p>\n<ol>\n<li>Sort candidate bounding boxes by classification confidence.</li>\n<li>Adding the boxes b with most confidence to output list, and delete it from the candidate boxes.</li>\n<li>Calculate IoU between b and other boxes bi. If &gt; threshold, delete bi.</li>\n<li>Repeat until no candidate bounding boxes.</li>\n</ol>\n<p><strong>序列模型（Serial Model）</strong></p>\n<p>to process Speech, text, video, audio, etc.</p>\n<p>Feature: </p>\n<ol>\n<li>The data input is in the time sequence.</li>\n<li>There is a correlation between the data before and after.</li>\n</ol>\n<p>So the model should have the ability to “store” information.</p>\n<p>Speech dataset: TIMIT</p>\n<ol>\n<li>It consists of recordings of 630 speakers of 8 dialects of American English each reading 10 phonetically-rich sentences.</li>\n<li>It also comes with the word and phone-level transcriptions of the speech.</li>\n</ol>\n<p>Video dataset: DAVIS</p>\n<p>The Densely Annotation Video Segmentation dataset (DAVIS) is a high quality and high resolution densely annotated video segmentation dataset under two resolutions, 480p and 1080p.</p>\n<p>There are 50 video sequences with 3455 densely annotated frames in pixel level. 30 videos with 2079 frames are for training and 20 videos with 1376 frames are for validation.</p>\n<p>NLP dataset: GLUE</p>\n<p>General Language Understanding Evaluation (GLUE) benchmark: Standard split of data totrain, validation, test, where labels for the test set is only held in the server.</p>\n<ul>\n<li>Sentence pair tasks<ul>\n<li>MNLI, Multi-Genre Natural Language Inference</li>\n<li>QQP, Ouora Ouestion Pairs</li>\n<li>QNLI, Ouestion Natural Language Inference</li>\n<li>STS-B The Semantic Textual Similarity Benchmark</li>\n<li>MRPC Microsoft Research Paraphrase Corpus</li>\n<li>RTE Recognizing Textual Entailment</li>\n<li>WNLI Winograd NLI is a small natural language inference</li>\n</ul>\n</li>\n<li>datasetSingle sentence classification<ul>\n<li>SST-2 The Stanford Sentiment Treebank</li>\n<li>CoLA The Corpus of Linguistic Acceptability</li>\n</ul>\n</li>\n</ul>\n<p><strong>Models</strong></p>\n<p><strong>RNN: Recurrent Neural Network</strong></p>\n<ul>\n<li>one to one </li>\n<li>one to many</li>\n<li>many to one</li>\n<li>many to many</li>\n<li>many to many</li>\n</ul>\n<p><img src=\"/../images/DSD/2_3.jpg\"></p>\n<p>损失函数的计算：</p>\n<p>单个时刻：</p>\n<div>$$\nL^{(t)} = -\\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$</div>\n\n<p>整个序列：</p>\n<div>$$\nL = \\sum\\limits_{t=1}^{\\tau}L^{(t)} = - \\sum\\limits_{t=1}^{\\tau} \\mathbf y^{(t)} \\ln \\mathbf {\\hat {y}}^{(t)}\n$$</div>\n\n<p>然后可求梯度：</p>\n<p><img src=\"/../images/DSD/2_4.jpg\" alt=\"alt\"></p>\n<p>循环神经网络存在梯度爆炸或梯度消失，因此无法处理长期的依赖关系。</p>\n<p><strong>LSTM: Solving the Gradient</strong></p>\n<p><strong>Transformer</strong></p>\n<p>Self attention:</p>\n<div>$$\n\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK}{\\sqrt d_k})V\n$$</div>\n\n<h2 id=\"Quantization\"><a href=\"#Quantization\" class=\"headerlink\" title=\"Quantization\"></a>Quantization</h2><h3 id=\"Fixed-point-and-floating-point-representation\"><a href=\"#Fixed-point-and-floating-point-representation\" class=\"headerlink\" title=\"Fixed-point and floating-point representation\"></a>Fixed-point and floating-point representation</h3><h4 id=\"Fixed-Point-arithmetic\"><a href=\"#Fixed-Point-arithmetic\" class=\"headerlink\" title=\"Fixed Point arithmetic\"></a>Fixed Point arithmetic</h4><div>$$\n\\underbrace{0}_{\\text{Sign bit}}\\ \\ \\underbrace{10\\dots01}_{n\\text{ bit integer part}}\\ \\ .\\underbrace{10\\dots01}_{m\\text{ bit fractional part}}\n$$</div>\n\n<p><strong>Fixed point with slope and bias</strong></p>\n<p>apply a linear transform on fixed point:</p>\n<div>$$\ny = s*x + z\n$$</div>\n\n\n\n<h4 id=\"Floating-poing-arithmatic\"><a href=\"#Floating-poing-arithmatic\" class=\"headerlink\" title=\"Floating-poing arithmatic\"></a>Floating-poing arithmatic</h4><p><img src=\"/../images/DSD/3_1.jpg\" alt=\"alt\"></p>\n<p><strong>IEEE 754 Floating Point Standard</strong></p>\n<ul>\n<li>Called Biased Notation, where bias is number subtracted to get real number. </li>\n<li>IEEE 754 uses bias of 127 for single precision, 1023 for double precision.</li>\n</ul>\n<p><img src=\"/../images/DSD/3_3.jpg\" alt=\"alt\"></p>\n<div>$$\n(-1)^S \\times (1 + m) \\times 2^{(E - \\text{Bias})}\n$$</div>\n\n<p><strong>fp15(helf precision)</strong></p>\n<p><img src=\"/../images/DSD/3_2.jpg\" alt=\"alt\"></p>\n<h3 id=\"Hardware-implications\"><a href=\"#Hardware-implications\" class=\"headerlink\" title=\"Hardware implications\"></a>Hardware implications</h3><p><img src=\"/../images/DSD/3_4.jpg\" alt=\"alt\"></p>\n<p>加法下定点数比浮点数功耗小得多，但是乘法下定点数和浮点数的性能差不多。</p>\n<p>Low bit Fixed-point representations on digital system</p>\n<h3 id=\"Quantization-for-deep-learning\"><a href=\"#Quantization-for-deep-learning\" class=\"headerlink\" title=\"Quantization for deep learning\"></a>Quantization for deep learning</h3><ul>\n<li>Post-training quantization</li>\n<li>Quantization-aware training</li>\n</ul>\n<p><strong>Post-training quantization</strong></p>\n<div>$$\nr = S(Q - Z)\\\\\nOA[i, k] =\\sum\\limits_{j=1}^{N}(W[i, j] * IA[j, k])\\\\\nq_{OA}^{(i, k)} = Z_{OA} + \\frac{S_W * S_{IA}}{S_{OA}}\\sum\\limits_{j=1}^{N} (q_W^{(i, j)} * q_{IA}^{(j, k)})\n$$</div>\n\n<p>Choose the optimal threshold</p>\n<p>No saturation is bad </p>\n<h3 id=\"Classic-research-for-quantization-methods\"><a href=\"#Classic-research-for-quantization-methods\" class=\"headerlink\" title=\"Classic research for quantization methods\"></a>Classic research for quantization methods</h3><p><strong>Basic structure</strong></p>\n<p>Weight Quantization &amp; Activation Quantization</p>\n<p><img src=\"/../images/DSD/3_5.jpg\" alt=\"alt\"></p>\n<p><strong>Dorefa Net</strong></p>\n<ul>\n<li>quantization for gradient</li>\n<li>normalize data to ensure the data distribution not change after quantization</li>\n<li>uniform noise to offset the quantization noise for gradient</li>\n<li>replace accumulate with bitcount operation</li>\n<li>result is that gradient precision is most sensitive in TAQ(G &gt; A &gt; W)</li>\n</ul>\n<p><strong>INQ</strong></p>\n<ul>\n<li>quantization first half and freeze the other, then unfreeze other to train normally</li>\n<li>exchange the first half and second half, and repeat above</li>\n</ul>\n<p><img src=\"/../images/DSD/3_6.jpg\" alt=\"alt\"></p>\n<p><strong>Pact</strong></p>\n<ul>\n<li>clipping the activation before quantization is better</li>\n</ul>\n<div>$$\nPACT(x) = 0.5(|x| - |x - \\alpha| + \\alpha) = \\begin{cases}\n    0, x<0,\\\\\n    x, 0\\le x \\lt \\alpha,\\\\\n    \\alpha, x \\ge \\alpha \n\\end{cases}\n$$</div>\n\n<p>Different layers need different α</p>\n<p>alpha should be learnable</p>\n<p><strong>Outlier quantization</strong></p>\n<ul>\n<li>Use different quantized bits to quantize different weights. Some weight can have higher precision while others not.</li>\n</ul>\n<p><img src=\"/../images/DSD/3_7.jpg\" alt=\"alt\"></p>\n<p><strong>Quantization interval learning</strong></p>\n<ul>\n<li>Most of the weights are very small. Minor weights can have too large value.</li>\n</ul>\n<p><img src=\"/../images/DSD/3_8.jpg\" alt=\"alt\"></p>\n<p>a should be pruned, c should be clipped, only b worths quantizing.</p>\n<p><strong>Binary neural networks (BNN)</strong></p>\n<ul>\n<li>Networks with weights composed of {-1, 1}</li>\n</ul>\n<p><img src=\"/../images/DSD/3_9.jpg\" alt=\"alt\"></p>\n<ul>\n<li>计算时长跟精度有平方反比的关系，优化是平方的</li>\n<li>存储跟精度只有线性的关系，优化是线性的，由于BNN bit数少，总的参数量更多，实际上存储没怎么优化</li>\n<li>BNN 大幅优化了计算，但是存储没变，此时存储成为了瓶颈</li>\n</ul>\n<p><strong>State-of-the-art hardware support for low<br>precision DNNs</strong></p>\n<p><img src=\"/../images/DSD/3_10.jpg\" alt=\"alt\"></p>\n<h2 id=\"Pruning\"><a href=\"#Pruning\" class=\"headerlink\" title=\"Pruning\"></a>Pruning</h2><p>稀疏矩阵是指矩阵中大部分元素都是0的矩阵。获得稀疏矩阵，有助于加速训练和推理速度。</p>\n<h3 id=\"Sparsity-New-Dimension-For-Efficiency\"><a href=\"#Sparsity-New-Dimension-For-Efficiency\" class=\"headerlink\" title=\"Sparsity: New Dimension For Efficiency\"></a>Sparsity: New Dimension For Efficiency</h3><p>稀疏性的来源：</p>\n<ul>\n<li>剪枝 - 权重</li>\n<li>ReLU - 激活</li>\n<li>Domain Specific</li>\n</ul>\n<h4 id=\"Weight-Sparsity-Pruning\"><a href=\"#Weight-Sparsity-Pruning\" class=\"headerlink\" title=\"Weight Sparsity: Pruning\"></a>Weight Sparsity: Pruning</h4><p>剪枝方法：</p>\n<ul>\n<li>很多参数其实是很接近0的数</li>\n<li>因此，低于某一阈值时，直接将其赋0.但是这样会影响精度。</li>\n<li>还可以用添加正则项的方法（Weight decay）：<ul>\n<li>$CF &#x3D; MSE_{train} + \\lambda \\sum_i w_i^2$</li>\n<li>$CF &#x3D; MSE_{train} + \\lambda \\sum_i |w_i|$</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Activation-Sparsity-ReLU\"><a href=\"#Activation-Sparsity-ReLU\" class=\"headerlink\" title=\"Activation Sparsity: ReLU\"></a>Activation Sparsity: ReLU</h4><h3 id=\"Weight-Sparsity-Perspective\"><a href=\"#Weight-Sparsity-Perspective\" class=\"headerlink\" title=\"Weight Sparsity Perspective\"></a>Weight Sparsity Perspective</h3><p>不同的稀疏程度：</p>\n<p><img src=\"/../images/DSD/4_1.jpg\" alt=\"alt\"></p>\n<h4 id=\"Unstructured-Sparsity\"><a href=\"#Unstructured-Sparsity\" class=\"headerlink\" title=\"Unstructured Sparsity\"></a>Unstructured Sparsity</h4><p>Han Song@NIPS2015 的剪枝策略：</p>\n<p><img src=\"/../images/DSD/4_2.jpg\" alt=\"alt\"></p>\n<p>第一轮训练后，将所有接近0的神经元剪除，再重新对剩下的进行训练(retrain)。</p>\n<ul>\n<li>压缩比很高，而准确率几乎不下降</li>\n<li>对于硬件并不友好，虽然有很多0，但是硬件上没法把它们压缩掉。</li>\n<li>计算速度并没有提高，甚至降低了</li>\n</ul>\n<h4 id=\"Structural-Sparsity\"><a href=\"#Structural-Sparsity\" class=\"headerlink\" title=\"Structural Sparsity\"></a>Structural Sparsity</h4><p><strong>SSL 剪枝策略(Structured weight pruning)</strong></p>\n<ul>\n<li>不是剪一个神经元，而是把一行&#x2F;一列&#x2F;一个通道全部剪掉。（不过，不是真的剪枝，而是修改代价函数的正则项）</li>\n<li>规则化的剪枝对硬件更加友好</li>\n</ul>\n<p>代价函数的表达式：</p>\n<p><img src=\"/../images/DSD/4_4.jpg\" alt=\"alt\"></p>\n<ul>\n<li>成功在一般设备上加速了</li>\n</ul>\n<p><strong>Pattern Pruning</strong></p>\n<p>研究卷积核内非0的权重是如何分布的。</p>\n<p><img src=\"/../images/DSD/4_5.jpg\" alt=\"alt\"></p>\n<p>如果某个“分布模式”反复的出现，就可以对它进行压缩存储：</p>\n<p><img src=\"/../images/DSD/4_6.jpg\" alt=\"alt\"></p>\n<p>这一方面的成果：</p>\n<ul>\n<li>Flexible-Length Pattern Pruning：用概率统计方法得到特定的模式</li>\n<li>Fixed-Length Pattern Pruning：约束了模式里面非0元素的个数</li>\n</ul>\n<h4 id=\"Unstructured-vs-structured\"><a href=\"#Unstructured-vs-structured\" class=\"headerlink\" title=\"Unstructured vs. structured\"></a>Unstructured vs. structured</h4><p>剪枝技术基本上已经成熟：</p>\n<ul>\n<li>Non-stuctured pruning<ul>\n<li>高压缩率</li>\n<li>只能在特定设备上来降低功耗，但是性能其实没什么提升</li>\n</ul>\n</li>\n<li>Structured pruning<ul>\n<li>对硬件更友好</li>\n<li>低压缩率</li>\n</ul>\n</li>\n</ul>\n<p>（压缩率指的是训练的速度，即将数据“压缩”为神经网络的内蕴知识的能力。）</p>\n<h4 id=\"Frequency-Domain-Sparsity\"><a href=\"#Frequency-Domain-Sparsity\" class=\"headerlink\" title=\"Frequency-Domain Sparsity\"></a>Frequency-Domain Sparsity</h4><p>采用循环的卷积核</p>\n<ul>\n<li>因为循环出现的元素，存储降低</li>\n<li>计算等价为循环卷积，可以转换为 FFT 频域相乘，获得更高效的计算</li>\n</ul>\n<h3 id=\"Activation-Sparsity-Perspective\"><a href=\"#Activation-Sparsity-Perspective\" class=\"headerlink\" title=\"Activation Sparsity Perspective\"></a>Activation Sparsity Perspective</h3><h4 id=\"Inter-Frame-Sparsity\"><a href=\"#Inter-Frame-Sparsity\" class=\"headerlink\" title=\"Inter-Frame Sparsity\"></a>Inter-Frame Sparsity</h4><p>一段序列的相邻帧之间具有相似性。因此只需要存储帧与帧之间的差值就行了。</p>\n<p>Yuan Z@ISSCC 2020 的结论：</p>\n<ul>\n<li>差分帧并不是稀疏的</li>\n<li>差分帧的数值集中于低的bit位，分布集中</li>\n<li>而高bit位很多都是0，非常稀疏</li>\n</ul>\n<p>因此，可以对低 bit 位和高 bit 位拆分处理。</p>\n<h4 id=\"ROI-Spasity：Input-Dependent\"><a href=\"#ROI-Spasity：Input-Dependent\" class=\"headerlink\" title=\"ROI Spasity：Input Dependent\"></a>ROI Spasity：Input Dependent</h4><p>ROI: Region of Interest</p>\n<p>图像里包含的信息，有的丰富，有的贫乏，有的容易识别，有的很难识别。</p>\n<ul>\n<li>稠密的输入用大核，稀疏的输入用小核？</li>\n</ul>\n<p>基于不同的输入，采用不同的网络：</p>\n<ul>\n<li>图像中难度高的区域通过更深的网络层</li>\n<li>难度低的区域通过更浅的网络层</li>\n</ul>\n<h3 id=\"Leveraging-Sparsity-in-Storage\"><a href=\"#Leveraging-Sparsity-in-Storage\" class=\"headerlink\" title=\"Leveraging Sparsity in Storage\"></a>Leveraging Sparsity in Storage</h3><p>如何压缩稀疏矩阵的存储空间？</p>\n<h4 id=\"Bitmask-Compression\"><a href=\"#Bitmask-Compression\" class=\"headerlink\" title=\"Bitmask Compression\"></a>Bitmask Compression</h4><p><img src=\"/../images/DSD/4_7.jpg\" alt=\"alt\"></p>\n<h4 id=\"Run-Length-Encoding\"><a href=\"#Run-Length-Encoding\" class=\"headerlink\" title=\"Run-Length Encoding\"></a>Run-Length Encoding</h4><p>游程编码<br>(matlab警告)</p>\n<p><img src=\"/../images/DSD/4_8.jpg\" alt=\"alt\"></p>\n<h4 id=\"Compressed-Sparse-Row-CSR\"><a href=\"#Compressed-Sparse-Row-CSR\" class=\"headerlink\" title=\"Compressed Sparse Row (CSR)\"></a>Compressed Sparse Row (CSR)</h4><p><img src=\"/../images/DSD/4_10.jpg\" alt=\"alt\"></p>\n<h4 id=\"Compressed-Sparse-Column-CSC\"><a href=\"#Compressed-Sparse-Column-CSC\" class=\"headerlink\" title=\"Compressed Sparse Column (CSC)\"></a>Compressed Sparse Column (CSC)</h4><p><img src=\"/../images/DSD/4_9.jpg\" alt=\"alt\"></p>\n<h4 id=\"The-Taco-Notation\"><a href=\"#The-Taco-Notation\" class=\"headerlink\" title=\"The Taco Notation\"></a>The Taco Notation</h4><p>?</p>\n<h2 id=\"讲座\"><a href=\"#讲座\" class=\"headerlink\" title=\"讲座\"></a>讲座</h2><h3 id=\"量化\"><a href=\"#量化\" class=\"headerlink\" title=\"量化\"></a>量化</h3><p>Uniform &amp; Non-uniform</p>\n<p>Non-uniform quantization is not efficient for hardware deployment</p>\n<p>Symmetric vs Asymmetric Quantization</p>\n<p>Quantization Granularity: Layer-wise vs Channel-wise</p>\n<p>Dynamic vs Static Quantization</p>\n<p>静态的更常用，因为量化本身就是为了加快速度，动态量化却一边训模型一边更新量化区间的范围，反而减慢了速度。不过也有使用动态量化的时候（Mid Journey 生成图像）。</p>\n<p>什么是mixed-precsion quantization？</p>\n"},{"title":"数逻","date":"2023-02-27T01:54:53.000Z","katex":true,"_content":"\n\n\n## Introduction\n\n## Boolean Algebra\n\n\n\n### The Number System\n\n\n#### BCD\n\nBCD (Binary-Coded Decimal)\n\nClassic method: 8421BCD.\n\nadd calculation:\n\nthe problem of carry:\n\n$$\n(14)_D+(28)_D=(0001\\ 0100)_{BCD} + (0100\\ 0100)_{BCD}\\\\\n=(0101\\ 1100)_{BCD}=(0110\\ 0010)_{BCD}\n$$\n\n#### Gray Code\n\nused in logic simplification and signal transmission.\n\nevery time a single bit is changed.\n\n#### Floating poing Number\n\n#### Negative numbers\n\n**Complement Numeric System**\n\n1's Complement: $N_{1's} + (-N)_{1's} = (111...)_{1's}$, or just inverting every bit of N. Low space efficiency and difficult to compute.\n\n2's Complement: $N_{2's} + (-N)_{2's} = (000...)_{2's}$, or just inverting every bit of N and plus 1. A shift on 1's Complement.\n\nMSB=Most significant bit, LSB=Least significant bit.\n\n$$\n-N=N_{us}-2^n=\\sum_{i=0}^{n-1}k_i2^i-2^n=-k_{n-1}2^{n-1}+k_{n-2}2^{n-2}+\\dots k_02^0\n$$\n\nSo just set the weight of MSB to $-2^{n-1}$.\n\n\nwe ignore the bit beyond the range to make sure the answer is correct.\n$$\n(101)_{2's}+(001)_{2's}=(110)_{2's}\\\\\n(011)_{2's}-(001)_{2's}=(011)_{2's}+(111)_{2's}=(010)_{2's}\n$$\nTo detect an overflow, we can notice if 2 positive numbers add up to a negative numbers or 2 negative numbers add up to a positive numbers.\n\nWe can fix overflow by adding 0 as MSB if the answer should be positive and adding 1 as MSB if the answer should be negative.\n### Boolean expression\n\n#### Definition\n\n$$\n+(\\text{OR/logic add}),\\cdot (\\text{AND/logic multiply}), \\prime(\\bar{})(\\text{NOT/logit NOT})\n$$\n\n#### Boolean function\n\n**Duality**\n\nAND<->OR, 0<->1, variables unchanged.\n\n$$\nF_1=F_2\\Leftrightarrow F_1^D=F_2^D\n$$\n\n**De Morgan's Law**\n\nAND<->OR, 0<->1, **X<->X'**\n\n**Useful Theorem**\n\nX(Y+Z)=XY+XZ\n\nXY+Z=(X+Z)(Y+Z)\n\nX+XY=X\n\nX(X+Y)=X\n\n\n\n### Boolean function simplification\n\n\n#### 2-level logic\n\n**Standard form**\nSOP and POS\n\nSum of Products or Products of Sum\n\n**Min-term**\nA min-term is a product of all variables taken either in the direct or complemented form, each variable shown once.\n\n$A'B'C'=m_0$ and $ABC=M_7$\n\n**Max-term** A max-term is a sum of all variables taken either in the direct or complemented form, each variable shown once.\n\n$A+B+C=M_0$ and $A'+B'+C'=M_7$\n\n$$\nm_6= \\overline{M_6}\n$$\n\n**Karnaugh Maps**\n\nUse row and columns to represent combinations of the inputs(by min-terms), the cell to represent the value. The inputs is ordered by the sequence of Grey Code.\n\n#### Simplification of 2-level logic\n\n**Karnaugh Maps method**\n\nIf two adjacent min-terms deliver logic 1, merge them.\n\n**Implicant**\n\n$$\nG\\Rightarrow F, \\text{then }G\\text{ is the implicant of }F\\\\\nno\\ Q\\ s.t.P\\Rightarrow Q\\Rightarrow F, \\text{then }P \\text{ is the prime implicant of }F\\\\\n\\text{If one min-term can only be covered by one prime implicant, this prime implicant is an EPI.}\n$$\n\nEPI will finally exist there.\n\n**Q-M method**\n\nalgorithm to simplify multiple-input large-scale function.\n\n## Combinational Logic\n\n### Gate\n\nNAND, NOT, NOR is better than AND, OR in saving area.\n\n**Transmission Gate** Use both NMOS and PMOS to form a CMOS switch. NMOS is good at transmitting low volt while PMOS is better at working on high volt.\n\n**Tri-state Gate** EN is high, TG on, F=A; EN is low, TG off, F is isolated from input A. The states are called logic 0, logic 1 and high-resistance Z.\n\n![](../images/digital/lec_3_1.jpg)\n\nThe bottom part of the circuit is used to avoid the high-Z state.\n\n### Combinational logic circuits\n\nOutputs are the function of logic input circuits.\n\nDetermined only by current not past inputs + delay\n\nTo deal with complex logic with many inputs, we should:\n\n* From 2-level to multi-level(BDD?)\n* Divide-and-conquer\n* Re-using\n\n#### Metrics\n\n**Static metrics** Logic voltage values, DC noise margins, Area, Fan-out\n\n**Dynamic metrics** Speed/delay, Power dissipation, Noise(reference)\n\n**Speed** rise time and fall time. Propagation time.\n\n**Fan out** The maximum number of CMOS inputs that one logic output can drive.\n\n**Power and energy** Leakage power(static power): subthreshold leakage power, gate leakage, D/S subtrate leakage. We can reduce the static power:\n\n* increase $|V_{TH}|$ \n* or decrease $V_{DD}$.\n\n$$\nP_{total} = P_{dynamic} + P_{dynamic\\_short} + P_{leakage}\n$$\n\nDynamic power $P_{dynamic\\_short}$ shows in pull-up and pull-down on.\n\n$$\nP = C_LV_{DD}^2\\underset{\\text{Flip Prob.}}{\\alpha_{0-1}}f\n$$\n\nTo reduce dynamic power:\n\n* Reduce VDD and Capacitors\n* Reduce frequency, flipping probability.\n\nEnergy-delay product is a metric. It's hard to reduce.\n\n* Low power can increase the lifetime of the chip.\n* Low delay can increase the speed of the chip.\n\n#### Hazard\n\n**static-1 hazard** '1' output has a transient '0' glitch\n\n**static-0 hazard** '1' output has a transient '0' glitch\n\n**dynamic hazard** several transitions during a single output change(not required)\n\nIf the initial input and final input cannot be covered by one PI, it may have a glitch as state transition.\n\n### Basic comb. logic circuits\n\nEncoder: inputs are more, outputs are less($n \\le 2^m$)\n\nDecoder: inputs are less, outputs are more($m = 2^n$)\n\nMultiplexer: From several inputs, choose one as output according to the address inputs. It can be used to make a shift register. We can use n-bit-addr MUX for m-bit function.\n\nAdder: Half adder & full adder.\n\nHalf Adder: $S = A \\oplus B$\n\nFull adder: $C_{out} = A\\cdot C_{in} + B\\cdot C_{in} + A\\cdot B, S = A\\oplus B\\oplus C_{in}$\n\nImplements of Full Adder:\n\n**Serial Adder** $C_{i+1} = A_iC_i+B_iC_i + A_iB_i$. The latency is disastrous.\n\n**Carry Lookahead Adder(CLA)**\n\nFirst define $P_i = A_i\\oplus B_i, G_i = A_iB_i$, P means Carry-bit propagation, G means Carry-bit Generation. Thus, $C_{i+1} = G_i + P_iC_i, S_i = A_i\\oplus B_i\\oplus C_i = P_i\\oplus C_i$. Thus the $C_i$ can be replaced: \n\n$$\nC_1 = G_0+P_0C_0\\\\\nC_2 = G_1 + P_1(G_0+P_0C_0) =  G_1 + P_1G_0+P_1P_0C_0\\\\\nC_3 = G_2 + P_2(G_1 + P_1G_0+P_1P_0C_0) = G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0\\\\\nC_4=G_3+P_3(G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0)=G_3+P_3G_2 + P_3P_2G_1 + P_3P_2P_1G_0+P_3P_2P_1P_0C_0\n$$\n\nA 4-bit CLA can be designed using these formulas. For more, it is too complex. However, we can cascade the 4-bit CLA to reach the balance of latency and complexity.\n\nMoreover, here comes the parallel intra- and inter-group CLA which regards the 4-bit adder as a block and defines its $P_i$ and $G_i$, connecting the 4-bit adders in a similar manner as the structure of 4-bit adder inside.\n\n## Sequential logic\n\n![](../images/digital/lec_4_1.jpg)\n\n### Clock\n\n- Ring Oscillator\n- LC oscilator\n- Crystal Oscillator\n\n### State and FSM\n\n**States** contain all needed infomation. could be redundant.\n\n**Finite State Machine(FSM)** The number of input, output and states are finite.\n\nMealy FSM: \n\n![](../images/digital/lec_4_2.jpg)\n\nMoore FSM: \n\n![](../images/digital/lec_4_3.jpg)\n\nWe describe the FSM by State Transition Table or State Diagram.\n\n![](../images/digital/lec_4_4.jpg)\n\n![](../images/digital/lec_4_5.jpg)\n\nRemember: Moore is less.\n\n### Latch\n\nWatch the input at the **duration** clock enables.\n\n#### Examples\n\n**SR latch**\n\n\n![](../images/digital/lec_4_6.jpg)\n\n$SR=0$ is required.\n\n$$\nQ^+=S+R^\\prime Q\n$$\n\nA gated version:\n\n![](../images/digital/lec_4_7.jpg)\n\n$$\nQ^+=C^\\prime Q + C(S+R^\\prime Q)\n$$\n\n**D latch**\n\n\n![](../images/digital/lec_4_8.jpg)\n\n$$\nQ^+=D\n$$\n\nTransimission Gate version\n\n![](../images/digital/lec_4_9.jpg)\n\n#### Timing parameters\n\n![](../images/digital/lec_4_10.jpg)\n\n![](../images/digital/lec_4_11.jpg)\n\n\n\n### Flip-Flop\n\nWatch the input only at the **moment** when clock signal rises or falls.\n\n\n#### Examples\n\nD Flip-flop(DFF)\n\n![](../images/digital/lec_4_12.jpg)\n\n2 D latches in series with opposite clock.\n\n**Use the delay to help us**\n\nThe delay of  NOT gate at the bottom enables the slave to lock first and the master to unlock second when clock falls.\n\nAlso, the delay of NOT gate at the bottom makes $t_h=0$.\n\n\n![](../images/digital/lec_4_13.jpg)\n\n**Two time constraints**\n\nSet-up time constraints: restrict the clock cycle.\n\n![](../images/digital/lec_4_14.jpg)\n\n$t_{logic}(max)$ is also called propagation delay $t_{dab}$.\n\nHold time constraints: restrict the $t_d$\n\n![](../images/digital/lec_4_15.jpg)\n\n$t_{logic}(min)$ is also called contamination delay($t_{cab}$).\n\n#### 4 types of FF\n\n![](../images/digital/lec_4_16.jpg)\n\n![](../images/digital/lec_4_17.jpg)\n\n![](../images/digital/lec_4_1.jpg8.jpg)\n\nCharacteristic equations\n\n$$\nQ^+=D\\\\\nQ^+=T\\overline Q + \\overline{T}Q\\\\\nQ^+=S+\\overline{R}Q\\\\\nQ^+=J\\overline{Q}+\\overline{K}Q\n$$\n\n### Problems\n\nCan $t_h$ be negative?\n\n[setup-and-hold-time](https://www.physicaldesign4u.com/2020/04/sta-iii-global-setup-and-hold-time-can.html)\n\nHow to convert FF?\n\nhttps://blog.csdn.net/qq_43975016/article/details/121193168\n\n### Analyzing Sequential Logic\n\n**Function Analysis**\n\n![](../images/digital/lec_5_1.jpg)\n\n**State Transistion Table**\n\n![](../images/digital/lec_5_2.jpg)\n\n![](../images/digital/lec_5_3.jpg)\n\n![](../images/digital/lec_5_4.jpg)\n\n![](../images/digital/lec_5_5.jpg)\n\n![](../images/digital/lec_5_6.jpg)\n\nOpt.2 is different and needed to be thought carefully. The x and s in $g(x, s)$ may not be caused by same x.\n\n**Time Constraint**\n\n### Designing Sequential Logic\n\n**Step 1 Determine the input, output and state**\n\n![](../images/digital/lec_5_7.jpg)\n\nHere, Moore is more in FSM states.\n\n**Step 2 State simplification**\n\n2 methods: row matching & implication chart\n\nrow matching: $P\\equiv Q$ iff. outputs and next states are same.\n\nWe can use **implication table** to optimize the row matching method.\n\n![](../images/digital/lec_5_9.jpg)\n\n![](../images/digital/lec_5_10.jpg)\n\n**Step 3 State allocation/representation**\n\n![](../images/digital/lec_5_8.jpg)\n\nMany methods:\n\n![](../images/digital/lec_5_11.jpg)\n\n**Next state and input/output based criteria**\n\nHighest Priority:\n\nSame input and same next state should be encoded adjacently.\n\n![](../images/digital/lec_5_14.jpg)\n\nMedium Priority:\n\nNext states of the same state should have adjacent\nencoding.\n\n![](../images/digital/lec_5_12.jpg)\n\nLowest Priority:\n\nStates with the same output should have adjacent \nencoding.\n\n![](../images/digital/lec_5_13.jpg)\n\n**Step 5 Get Excitation and Output Equations**\n\n![](../images/digital/lec_5_15.jpg)\n\n\n**Step 6 Draw Logic Circuit Diagram**\n\n### Typical Sequential Logic Circuits\n\nRegister & Counter\n\n**Register**\n\nShift register. Serial/Parallel Input, Serial/Parallel Output.\n\n![](../images/digital/lec_5_17.jpg)\n\n![](../images/digital/lec_5_16.jpg)\n\n![](../images/digital/lec_5_18.jpg)\n\n**Counter**\n\n**UP/Down Counter**\n\n![](../images/digital/lec_5_19.jpg)\n\n**Specific-base Counter**\n\n000→010→011→101→110→000\n\n![](../images/digital/lec_5_20.jpg)\n\n**Self-Starting problem of counter**\n\nAbnormal state(001, 100, 111)\n\n![](../images/digital/lec_5_21.jpg)\n\n**Ring counter & twisted ring counter**\n\n![](../images/digital/lec_5_22.jpg)\n\n![](../images/digital/lec_5_23.jpg)\n\n**Async & snyc Counter**\n\n![](../images/digital/lec_5_24.jpg)\n\n![](../images/digital/lec_5_25.jpg)\n\n![](../images/digital/lec_5_26.jpg)\n\n## Instruction Set Architecture\n\n### Introduction\n\n#### Implement Algorithm In Hardware\n\n![](../images/digital/lec_6_1.jpg)\n\nThree steps: \n* Instruction fetch\n* Instruction decoding\n* Instruction execution & data write-back\n\n**Program Counter(PC)**\n\nCurrent Instruction Address\n\nUpdated Every Cycle\n\n**Arithmetic/Logic Instructions**\n\nArithmetic Logic Unit(ALU)\n\nREG to REG, NOT Directly access data memory\n\n\n**Branch/Jump Instructions**\n\nBranch After Comparison\n\nJump Directly\n\n**Load/Store Instructions**\n\nLoad Data: data memory to REG\n\nStore Data: REG to data memory\n\n#### General Purpose Processore Structure\n\n**Turing Machine**\n\n2 Turing Machine Models: \n\n* Princeton architecture\n* Harvard architecture\n\n![](../images/digital/lec_6_2.jpg)\n\n#### Program FLow\n\n![](../images/digital/lec_6_3.jpg)\n\n![](../images/digital/lec_6_4.jpg)\n\n### Instruction Set Design\n\nInstruction set is the bridge between software & generall-purpose (GP) CPU.\n\n**Performance Evaluate**\n\n$$\n\\text{Performance} = \\frac{1}{\\text{Execution Time}}\n$$\n\nTask Execution Time By CPU:\n\n$$\n\\text{Total Time} = \\text{Waiting for I/O} + \\text{Execution Time}\\\\\n\\text{Execution Time} = \\text{Cycle }\\# \\times \\text{Clock Cycle }T = \\frac{\\text{Cycle }\\# }{\\text{Clock }f} \n$$\n\n$$\n\\text{Cycle } \\# = \\text{Progream Instruction }\\# \\times \\text{Average Cycle } \\# \\text{ for one inst.}\n$$\n\nAverage Cycle # for one instruction is also known as the cycle per instruction (CPI)\n\nSo, \n\n$$\n\\text{Execution Time} = \\text{Instruction }\\# \\times \\text{CPI} \\times \\text{Clock Cycle }\n$$\n\n**CPI**\n\n$$\n\\text{CPI} = \\sum_{i = 1}^n \\text{CPI}_i \\times \\text{P}_i\n$$\n\nWhere $\\text{P}_i$ is the i-th instruction occurrence frequency, and $\\text{CPI}_i$ is the clock cycle # of the i-th instruction.\n\n**Factors that affect Performance**\n* Instruction # \n* - ISA, regardless of its specific implementation\n* - Compiler\n* CPI\n* - Memory System and Processor Architecture\n* - The Instruction Composition In the Program\n* - Compiler\n* Clock Cycle\n* - Machine implementation details\n* - Memory System and Processor Architecture\n\n![](../images/digital/lec_6_5.jpg)\n\n**Data Access**\n\n![](../images/digital/lec_6_6.jpg)\n\n![](../images/digital/lec_6_7.jpg)\n\n**Set Design**\n\nRISC & CISC\n\n![](../images/digital/lec_6_8.jpg)\n\n![](../images/digital/lec_6_9.jpg)\n\n**Five Questions**\n\n* How to make use of 11 extra bits in arithmetic operations?\n* How to use 16 bits to represent 32-bit address for branch?\n* How to encode branch instruction with immediate?\n* How to use 21 bits to represent 32-bit address for memory address?\n* How to use 26 bits to represent 32-bit address for jump?\n\n\n\n\n### MIPS Instruction Set\n\n#### Instruction Storage and Data Storage\n\n32-bits instruction length, and 32 general-purpose registers.\n\nFirst 6 bits are opcode.\n\n**Register**\n\n![](../images/digital/lec_7_9.jpg)\n\nthe register index is limited to 5 bits.\n\n#### Instruction Type(R, I, J)\n\n**Type: R**\n\n**Field Division and detailed definition**\n\n![](../images/digital/lec_7_1.jpg)\n\nQ1: Can we make use of the extra 11 bits?\n\n![](../images/digital/lec_7_13.jpg)\n\n**Type: I**\n\nIt's immediate.\n\n![](../images/digital/lec_7_5.jpg)\n\n2 cases:\n\n![](../images/digital/lec_7_2.jpg)\n\n![](../images/digital/lec_7_3.jpg)\n\nQ2:The possible address range covers 32 bits. How to represent the address with limited 16 bits for branch?\n\nbase + offset\n\n![](../images/digital/lec_7_10.jpg)\n\nQ3: How to encode the branch with immediate?\n\nNo direct instructions for this.\n\nWe use compare instruction and branch instruction to achieve this.\n\nQ4: The possible address range covers 32 bits. How to represent the address with limited 21 bits for memory access?\n\nbase + offset\n\n![](../images/digital/lec_7_4.jpg)\n\n**Type: J**\n\n![](../images/digital/lec_7_6.jpg)\n\nQ5: The possible address range covers 32 bits. How to represent \nthe address with limited 26 bits for jump?\n\n3 types of jump operation: `j`, `jal` and `jr`.\n\n![](../images/digital/lec_7_7.jpg)\n\n**Summary**\n\n![](../images/digital/lec_7_.jpg)\n\n#### Addressing mode\n\n5 modes:\n\n* Register addressing\n* Immediate addressing\n* Base (base-offset) addressing\n* PC-related addressing\n* Pseudo-direct addressing\n\n**Register addressing**\n\n![](../images/digital/lec_7_11.jpg)\n\n**Immediate addressing**\n\n![](../images/digital/lec_7_12.jpg)\n\nHow to load a 32-bit constant to $s0?\n\n![](../images/digital/lec_7_14.jpg)\n\n**Base-offset addressing**\n\n![](../images/digital/lec_7_15.jpg)\n\n**PC-related addressing**\n\n![](../images/digital/lec_7_16.jpg)\n\n![](../images/digital/lec_7_17.jpg)\n\n**Pseudo-direct addressing**\n\n![](../images/digital/lec_7_18.jpg)\n\nIt is faster because no add operation needed, comparing to `PC_new = {PC_old + address << 2}`.\n\n**Summary**\n\n![](../images/digital/lec_7_19.jpg)\n\n#### Instruciton System\n\n**Arithmetic**\n\nAdd  `add $t0, $t1, $t2      #$t0=$t1+$t2`\n\nAdd immediate `addi $t2, $t3, 5  #$t2=$t3+5`\n\nSubtract `sub $t2,$t3,$t4 #$t2=$t3-$t4`\n\nNO subtract-an-immediate instruction! We use 2's complement immediate in the `addi`.\n\n**Logic**\n\n```assembly\nand $t0, $t1, $t2\nor $t0, $t1, $t2\nxor $t0, $t1, $t2\nnor $t0, $t1, $t2\n```\n\nNo NOT instruction. We set `$t1` or `$t2` to 0 and use NOR.\n\nWith immediate:\n\n```\nandi $t0, $t1, 10\nori $t0, $t1, 10\nxori $t0, $t1, 10\n```\n\n**Shift**\n\nImmediate-amount shift:\n\n```\nsll $t0, $t1, 10\n# $t0 = $t1 << 10, logical\nsrl $t0, $t1, 10\n# $t0 = $t1 << 10, logical\nsra $t0, $t1, 10\n# $t0 = $t1 >> 10, arithmetic, depending on the sign bit\n```\n\nRegister-amonut shift: \n\n```\nsllv $t0, $t1, $t3\n# $t0 = $t1 << ($t3%32), logical\nsrl $t0, $t1, $t3\n# $t0 = $t1 << ($t3%32), logical\nsra $t0, $t1, $t3\n# $t0 = $t1 >> ($t3%32), arithmetic, depending on the sign bit\n```\n\n**Compare instruction**\n\n```\nslt $t1, $t2, $t3\n# if ($t2 < $t3) $t1=1;\n# else $t1=0\nsltu $t1, $t2, $t3\n# unsigned comparison\n```\n\nWith immediate:\n\n```\nslti $t1, $t2, 10\nsltui $t1, $t2, 10\n```\n\n**About i, u, iu**\n\n![](../images/digital/lec_7_20.jpg)\n\n**Load/Store Instruction**\n\n```\nlw $t1, 32($t2)\nsw $t3, 500($t4)\n```\n\nRegister stores base address is called base register, \nConstant in the instruction is called offset.\n\n**Branch instruction**\n\n```\nbeq $t0, $t1, target\n#if $t0=$t1, then execute\n#instruction target\nbne $t0, $t1, target\n# if $t0!=$t1, then execute\n# instruction target\n```\n\nMore than this 2 instructions.\n\n**Jump instruction**\n\nUnconditional branch\n\n```\nj label\n#unconditionally jump to label\n```\n\n#### Procedure Call\n\n![](../images/digital/lec_7_21.jpg)\n\nMIPS uses registers for argument and return data/address.\n\nArgument registers: `$a0-$a3`\n\nReturn value registers: `$v0-$v1`\n\nRetuen address register: `$ra`\n\n``\njal Procedure #Procedure call\njr $ra #Procedure return\n``\n\n`jal` and `j` are both J-type, but `jal` will store the return address.\n\n`jr` is R-type, will jump to the address restored in the register, so it can jump very far.\n\n**Maintain the register data**\n\n2 types:\n\n* Temporaries data registers\n* Saved data registers\n\n![](../images/digital/lec_7_22.jpg)\n\nWho saves the register data?\n\nCaller(temp) or Callee(save)\n\n![](../images/digital/lec_7_23.jpg)\n\nWe use Stack to maintain the register data.\n\n![](../images/digital/lec_7_24.jpg)\n\n**Stack Operation with $sp**\n\ne.g. `push $s1, $s2 , $s3`\n\n```\naddi $sp, $sp, -12\nsw $s1, 8($sp)\nsw $s2, 4($sp)\nsw $s3, 0($sp)\n```\n`pop $s1, $s2, $s3`\n\n```\nlw $s1, 0($sp)\nlw $s2, 4($sp)\nlw $s3, 8($sp)\naddi, $sp, $sp, 12\n```\n\n**Leaf Procedures**\n\nProcedures that do not call others are called *leaf* procedures.\n\n**Nested Procedures**\n\nNested(Recursive) Procedures are procedures that invoke \"clones\" of themselves.\n\ne.g.\n\n```C\nint fact (int n) {\n    if (n < 1) return 1;\n    else return (n * fact(n - 1));\n}\n```\n\n```assembly\nfact:\n    addi    $sp, $sp, -8\n    sw      $ra, 4($sp)\n    sw      $a0, 0($sp)\n    slti    $t0, $a0, 1\n    beq     $t0, $zero, L1\n    addi    $v0, $zero, 1\n    addi    $sp, $sp, 8\n    jr      $ra\nL1:\n    addi    $a0, $a0, -1\n    jal     fact\n    lw      $a0, 0($sp)\n    lw      $ra, 4($sp)\n    addi    $sp, $sp, 8\n    mul     $v0, $a0, $v0\n    jr      $ra\n```\n\n## Single-Cycle Processor\n\n![](../images/digital/lec_8_1.jpg)\n\n![](../images/digital/lec_8_2.jpg)\n\n![](../images/digital/lec_8_3.jpg)\n\n![](../images/digital/lec_8_4.jpg)\n\n![](../images/digital/lec_8_5.jpg)\n\n![](../images/digital/lec_8_6.jpg)\n\n![](../images/digital/lec_8_7.jpg)\n\n**Load Operation Takes MUCH LONGER!!!**\n\n## Multi-Cycle Processor\n\n![](../images/digital/lec_8_8.jpg)\n\nThe Multicycle processor processes different inst. in different cycles. Thus, it can avoid the time limitation by the slow instruction.\n\nModules on th datapath can be used multiple times within an inst. That is **Module reuse**.\n\nPerformance improvement depends on the detailed delay. The multicycle is not necessarily faster than the single cycle.\n\n![](../images/digital/lec_8_9.jpg)\n\n![](../images/digital/lec_8_10.jpg)\n\n![](../images/digital/lec_8_11.jpg)\n\n![](../images/digital/lec_8_12.jpg)\n\n![](../images/digital/lec_8_13.jpg)\n\n![](../images/digital/lec_8_14.jpg)\n\n![](../images/digital/lec_8_15.jpg)\n\n![](../images/digital/lec_8_16.jpg)\n\n![](../images/digital/lec_8_17.jpg)\n\n![](../images/digital/lec_8_18.jpg)\n\n![](../images/digital/lec_8_19.jpg)\n\n![](../images/digital/lec_8_20.jpg)\n\n![](../images/digital/lec_8_21.jpg)\n\n![](../images/digital/lec_8_30.jpg)\n\n![](../images/digital/lec_8_31.jpg)\n\n\n\n## Exception and Interrupt\n\n![](../images/digital/lec_8_22.jpg)\n\nGenerally, exceptions and interrupts are events that can change the normal instruction execution flow (other than branches and jumps).\n\nException\n– Internal unpredictable events such as overflow.\n\nInterrupt\n– External unpredictable events such as I/O.\n\n![](../images/digital/lec_8_23.jpg)\n\n![](../images/digital/lec_8_24.jpg)\n\n![](../images/digital/lec_8_25.jpg)\n\n![](../images/digital/lec_8_26.jpg)\n\n![](../images/digital/lec_8_27.jpg)\n\n![](../images/digital/lec_8_28.jpg)\n\n![](../images/digital/lec_8_29.jpg)\n\n## Pipelined processor\n\n![](../images/digital/lec_9_1.jpg)\n\nPipeline means spatial and temporal reuse.\n\nDivide a complex task into several sub-tasks to \nexecute sequentially, and assign each sub-task to \ndedicated hardware\n\nDifferent sub-tasks of multiple tasks can be \nprocessed simultaneously to improve the \nperformance\n\n• Time-division multiplexing: the same resource is reused through \ndifferent cycles\n\n• Space-division multiplexing: multiple resources are reused \nwithin one cycle\n\nPros: improved efficiency\n\nCons: Some inst. depends on the former inst.. However, the former inst. has not finished yet, if the prediction of branch is wrong, time is wasted.\n\nInstruction-Level Parallelism (ILP)\n\n– Execute multiple instructions in parallel\n\n– One mainstream approach to CPU performance improvement\n\nBasic Techniques\n\n– Pipelining: instruction execution is divided into several stages, and \neach stage can be processed with the other stages (of other \ninstructions) simultaneously\n\n– Superscalar: multiple dedicated functional units are equipped so \nthat CPU can receive & execute more instructions within one cycle.\n\n– Very Long Instruction Word (VLIW): each instruction consists of \nmultiple segments to utilize the processor resources independently.\n\n5 stages in MIPS:\n\n1. Instruction Fetch (IF)\n2. Instruction Decode / Register File\n3. ALU Execution(EX)\n4. Memory Data Access(MEM)\n5. Reg Write-Back(WB)\n\nLatency of the stages in the pipeline should \nbe as equivalent as possible, why?\n–The pipeline performance is bottlenecked by the stage \nof the longest latency\n\n**Metrics of pipelined processors**\n\n* Throughput(TP): Executed instruction # per unit time\n* Max throughput: The throughput of a steady-state pipeline with a continuous instruction input stream\n* Real throughput: The throughput of the pipeline executing task with finite instructions\n\nReal TP:\n\n$$\nTP = \\frac n {T_k} = \\frac{n}{(n+k-1)\\Delta t}\n$$\n\nMax TP:\n\n$$\nTP_{max} = \\lim_{n\\rightarrow\\infty}\\frac{n}{(n+k-1)\\Delta t} = \\frac{1}{\\Delta t}\n$$\n\n**Speed up** Execution time ratio between w/o or w/ pipelining.\n\n$T_0$: execution time without pipelining\n\n$T_k$: execution time with k-stage pipelining(assume each stage has the same latency)\n\n$$\n\\frac{T_0}{T_k}\n$$\n\nReal speedup:\n\n$$\nS = \\frac{nk\\Delta t}{(n + k - 1)\\Delta t} = \\frac{kn}{n + k - 1}\n$$\n\nMax speedup:\n\n$$\nS_{max} = \\lim_{n\\rightarrow \\infty}\\frac{kn}{k + n - 1} = k\n$$\n\n**Pipelined datapath**\n\n![](../images/digital/lec_9_3.jpg)\n\n![](../images/digital/lec_9_4.jpg)\n\n![](../images/digital/lec_9_5.jpg)\n\n![](../images/digital/lec_9_6.jpg)\n\n![](../images/digital/lec_9_7.jpg)\n\n![](../images/digital/lec_9_8.jpg)\n\nMany inst. doesnt need MEM stage, but the stage can't be skipped, since it may \"collide\" with the previous inst.\n\nQ: How to get the control signals in each stage?\n\nControl signals are generated at ID/RF stage.\n\nControl signals flow in the pipeline: use when needed; reserve when subsequent stages needed; discard when not needed any more.\n\n![](../images/digital/lec_9_10.jpg)\n\nWhy RegDst Doesnt needed in the stages after EX?\n\nThe RegDst is used to select the destination register. However, the destination register is determined in the EX stage. Thus, RegDst is not needed in the stages after EX.\n\nSometimes this can cause trouble:\n\n```MIPS\nLW R2, R9(10)\nADD R4, R3, R2\nADD R6, R5, R4\n```\n\nThe R4 is accessed before it updates.\n\n### Hazard in the pipeline\n\n**Structural Hazards**\n\nTwo instructions acquire the same hardware resource simultaneously.\n\n![](../images/digital/lec_9_11.jpg)\n\nSolution:\n\n1. Add resources: separating PC+4 from ALU; Harvard architecture\n2. Adjust stages: add MEM\n\n![](../images/digital/lec_9_15.jpg)\n\n![](../images/digital/lec_9_12.jpg)\n\nMIPS is born to be  pipelined: the problem of structural hazard is solved by the structure of MIPS.\n\n**Data Hazards**\n\n![](../images/digital/lec_9_13.jpg)\n\n2 solutions:\n\n**Stalling**\n\n![](../images/ss/lec21_8.jpg)\n\n**Forwarding(Bypassing)**\n\n![](../images/ss/lec21_1.jpg)\n\n![](../images/ss/lec21_2.jpg)\n\nBut, load uses hazard emerges:\n\n![](../images/ss/lec21_8.jpg)\n\n![](../images/digital/lec_10_1.jpg)\n\nStill, a nop needed to stall the pipeline.\n\n![](../images/digital/lec_10_2.jpg)\n\nIs there any possibility to eliminate the stall?\n\nYes, if the MIPS code can be optimized.\n\n![](../images/digital/lec_10_3.jpg)\n\n\n**Control Hazards**\n\n![](../images/digital/lec_9_14.jpg)\n\n**Stalling**\n\n![](../images/digital/lec_10_4.jpg)\n\n**Forwarding**\n\n![](../images/digital/lec_10_5.jpg)\n\nIf Move the branch decision to ID stage:\n\n![](../images/digital/lec_10_6.jpg)\n\n\n![](../images/digital/lec_10_7.jpg)\n\n\n**Delay slot**\n\n![](../images/digital/lec_10_8.jpg)\n\n**Prediction**\n\nStatic Branch Prediction\n\n![](../images/digital/lec_10_9.jpg)\n\nCancel the effect caused by false prediction.\n\nDynamic Branch Prediction\n\n* History-based dynamic prediction\n* Using runtime behaviour to predict future branches\n\nAt IF stage, there are Branch History Table(BHT) and Branch Target Buffer(BTB).\n\nbeq at IF stage\n\n• Look up if the instruction address is in BHT and BTB.\n\n• If not in, create a new entry. If in, check whether the \nbranch is taken at the last time. If taken, send the target \naddress to PC as the next address for IF.\n\n–beq at ID stage\n\n• IF stage will fetch instruction based on the predicted \ntarget address\n\n### Implementation of the Pipiline\n\n![](../images/digital/lec_10_10.jpg)\n\n**Data hazard**\n\nForwarding\n\n\nEX/MEM hazard\n~~~Verilog\nif (EX/MEM.RegWrite\nand (EX/MEM.RegWrAddr != 0)\nand (EX/MEM.RegWrAddr == ID/EX.RegisterRs))\n    ForwardA = 10\nif (EX/MEM.RegWrite\nand (EX/MEM.RegWrAddr != 0)\nand (EX/MEM.RegWrAddr == ID/EX.RegisterRt))\n    ForwardB = 10\n~~~\n\nMEM/WB hazard\n~~~Verilog\nif (MEM/WB.RegWrite\nand (MEM/WB.RegWrAddr != 0)\nand (MEM/WB.RegWrAddr == ID/EX.RegisterRs)\nand (EX/MEM.RegWrAddr != ID/EX.RegisterRs || ~ EX/MEM.RegWrite))\n    ForwardA = 01\nif (MEM/WB.RegWrite\nand (MEM/WB.RegWrAddr != 0)\nand (MEM/WB.RegWrAddr == ID/EX.RegisterRt)\nand (EX/MEM.RegWrAddr != ID/EX.RegisterRt || ~ EX/MEM.RegWrite))\n    ForwardB = 01\n~~~\n\nload-use hazard\n\nWe have to stall the pipeline for one cycle.\n\nCondition: `if (ID/EX.MemRead and ((ID/EX.RegisterRt == IF/ID.RegisterRs) or \n(ID/EX.RegisterRt == IF/ID.RegisterRt)))`\n\nHow to stall?\n\nStall & flush\n\nPC & ID/IF: stall(Keep the control signals)\n\nEX & MEM & WB: flush(Set the control signals to 0)\n\nControl signals:\n\nEX: RegDst, ALUOp1, ALUOp0, ALUSrc\n\nMEM: Branch, MemRead, MemWrite\n\nWB: MemToReg, RegWrite\n\n~~~Verilog\nif {ID/EX.MemRead\nand ((ID/EX.RegisterRt = IF/ID.RegisterRs)\nor (ID/EX.RegisterRt = IF/ID.RegisterRt))}\n    Keep IF/ID; Keep PC; Flush ID/EX;\n~~~\n\nSpecial Case:\n\nMemory-to-memory copy\n\n~~~\nlw $1, 10($2)\nsw $1, 10($3)\n~~~\n\nThe stall is unnecessary. We can use forwarding to solve the problem.\n\n**Control Hazard**\n\nBEQ & J need 1 stall cycle.\n\nControl hazards are not as frequent as data \nhazards, but they are harder to be resolved \neffectively as forwarding.\n\nAnother type of control hazard: exceptions and interrupts.\n\n– “Exception” includes any unpredictable events that \ncan change the normal control flow, which has no \ndistinction between internal and external. \n\n– “Interrupt” is only used for external events.\n\n![](../images/digital/lec_12_1.jpg)\n\n## Advanced techniques for processor\n\n### Instruction-level parallelism\n\nSuperpipelining: a deeper pipeline\n\nVLIW\n\n\nMultiple-issue: a wider pipeline\n\nSuperscalar\n\n![](../images/digital/lec_12_2.jpg)\n\n### Thread-level parallelism\n\nHyper-threading\n\n![](../images/digital/lec_12_3.jpg)\n\nMulticore\n\n### Heterogeneous computing\n\nGPU\n\nXPU\n\n## Memory\n\n### Basics\n\nSRAM cell\n\nHigh speed, low density & expensive\n\n![](../images/digital/lec_12_4.jpg)\n\nDRAM cell\n\nLow speed, high density & cheap. The charge in capacitor may leak, so the data cannot be stored for a long time.\n\n![](../images/digital/lec_12_5.jpg)\n\n![](../images/digital/lec_12_6.jpg)\n\n### Evaluation\n\n3C model:\n\n**Compulsory miss** first access to a block\n\n**Capacity miss** all lines in cache are used\n\n**Conflict miss(collision miss)** not fully filled, but the blocks # > available ways #.","source":"_posts/数逻.md","raw":"---\ntitle: 数逻\ndate: 2023-02-27 09:54:53\ntags: note\nkatex: true\n---\n\n\n\n## Introduction\n\n## Boolean Algebra\n\n\n\n### The Number System\n\n\n#### BCD\n\nBCD (Binary-Coded Decimal)\n\nClassic method: 8421BCD.\n\nadd calculation:\n\nthe problem of carry:\n\n$$\n(14)_D+(28)_D=(0001\\ 0100)_{BCD} + (0100\\ 0100)_{BCD}\\\\\n=(0101\\ 1100)_{BCD}=(0110\\ 0010)_{BCD}\n$$\n\n#### Gray Code\n\nused in logic simplification and signal transmission.\n\nevery time a single bit is changed.\n\n#### Floating poing Number\n\n#### Negative numbers\n\n**Complement Numeric System**\n\n1's Complement: $N_{1's} + (-N)_{1's} = (111...)_{1's}$, or just inverting every bit of N. Low space efficiency and difficult to compute.\n\n2's Complement: $N_{2's} + (-N)_{2's} = (000...)_{2's}$, or just inverting every bit of N and plus 1. A shift on 1's Complement.\n\nMSB=Most significant bit, LSB=Least significant bit.\n\n$$\n-N=N_{us}-2^n=\\sum_{i=0}^{n-1}k_i2^i-2^n=-k_{n-1}2^{n-1}+k_{n-2}2^{n-2}+\\dots k_02^0\n$$\n\nSo just set the weight of MSB to $-2^{n-1}$.\n\n\nwe ignore the bit beyond the range to make sure the answer is correct.\n$$\n(101)_{2's}+(001)_{2's}=(110)_{2's}\\\\\n(011)_{2's}-(001)_{2's}=(011)_{2's}+(111)_{2's}=(010)_{2's}\n$$\nTo detect an overflow, we can notice if 2 positive numbers add up to a negative numbers or 2 negative numbers add up to a positive numbers.\n\nWe can fix overflow by adding 0 as MSB if the answer should be positive and adding 1 as MSB if the answer should be negative.\n### Boolean expression\n\n#### Definition\n\n$$\n+(\\text{OR/logic add}),\\cdot (\\text{AND/logic multiply}), \\prime(\\bar{})(\\text{NOT/logit NOT})\n$$\n\n#### Boolean function\n\n**Duality**\n\nAND<->OR, 0<->1, variables unchanged.\n\n$$\nF_1=F_2\\Leftrightarrow F_1^D=F_2^D\n$$\n\n**De Morgan's Law**\n\nAND<->OR, 0<->1, **X<->X'**\n\n**Useful Theorem**\n\nX(Y+Z)=XY+XZ\n\nXY+Z=(X+Z)(Y+Z)\n\nX+XY=X\n\nX(X+Y)=X\n\n\n\n### Boolean function simplification\n\n\n#### 2-level logic\n\n**Standard form**\nSOP and POS\n\nSum of Products or Products of Sum\n\n**Min-term**\nA min-term is a product of all variables taken either in the direct or complemented form, each variable shown once.\n\n$A'B'C'=m_0$ and $ABC=M_7$\n\n**Max-term** A max-term is a sum of all variables taken either in the direct or complemented form, each variable shown once.\n\n$A+B+C=M_0$ and $A'+B'+C'=M_7$\n\n$$\nm_6= \\overline{M_6}\n$$\n\n**Karnaugh Maps**\n\nUse row and columns to represent combinations of the inputs(by min-terms), the cell to represent the value. The inputs is ordered by the sequence of Grey Code.\n\n#### Simplification of 2-level logic\n\n**Karnaugh Maps method**\n\nIf two adjacent min-terms deliver logic 1, merge them.\n\n**Implicant**\n\n$$\nG\\Rightarrow F, \\text{then }G\\text{ is the implicant of }F\\\\\nno\\ Q\\ s.t.P\\Rightarrow Q\\Rightarrow F, \\text{then }P \\text{ is the prime implicant of }F\\\\\n\\text{If one min-term can only be covered by one prime implicant, this prime implicant is an EPI.}\n$$\n\nEPI will finally exist there.\n\n**Q-M method**\n\nalgorithm to simplify multiple-input large-scale function.\n\n## Combinational Logic\n\n### Gate\n\nNAND, NOT, NOR is better than AND, OR in saving area.\n\n**Transmission Gate** Use both NMOS and PMOS to form a CMOS switch. NMOS is good at transmitting low volt while PMOS is better at working on high volt.\n\n**Tri-state Gate** EN is high, TG on, F=A; EN is low, TG off, F is isolated from input A. The states are called logic 0, logic 1 and high-resistance Z.\n\n![](../images/digital/lec_3_1.jpg)\n\nThe bottom part of the circuit is used to avoid the high-Z state.\n\n### Combinational logic circuits\n\nOutputs are the function of logic input circuits.\n\nDetermined only by current not past inputs + delay\n\nTo deal with complex logic with many inputs, we should:\n\n* From 2-level to multi-level(BDD?)\n* Divide-and-conquer\n* Re-using\n\n#### Metrics\n\n**Static metrics** Logic voltage values, DC noise margins, Area, Fan-out\n\n**Dynamic metrics** Speed/delay, Power dissipation, Noise(reference)\n\n**Speed** rise time and fall time. Propagation time.\n\n**Fan out** The maximum number of CMOS inputs that one logic output can drive.\n\n**Power and energy** Leakage power(static power): subthreshold leakage power, gate leakage, D/S subtrate leakage. We can reduce the static power:\n\n* increase $|V_{TH}|$ \n* or decrease $V_{DD}$.\n\n$$\nP_{total} = P_{dynamic} + P_{dynamic\\_short} + P_{leakage}\n$$\n\nDynamic power $P_{dynamic\\_short}$ shows in pull-up and pull-down on.\n\n$$\nP = C_LV_{DD}^2\\underset{\\text{Flip Prob.}}{\\alpha_{0-1}}f\n$$\n\nTo reduce dynamic power:\n\n* Reduce VDD and Capacitors\n* Reduce frequency, flipping probability.\n\nEnergy-delay product is a metric. It's hard to reduce.\n\n* Low power can increase the lifetime of the chip.\n* Low delay can increase the speed of the chip.\n\n#### Hazard\n\n**static-1 hazard** '1' output has a transient '0' glitch\n\n**static-0 hazard** '1' output has a transient '0' glitch\n\n**dynamic hazard** several transitions during a single output change(not required)\n\nIf the initial input and final input cannot be covered by one PI, it may have a glitch as state transition.\n\n### Basic comb. logic circuits\n\nEncoder: inputs are more, outputs are less($n \\le 2^m$)\n\nDecoder: inputs are less, outputs are more($m = 2^n$)\n\nMultiplexer: From several inputs, choose one as output according to the address inputs. It can be used to make a shift register. We can use n-bit-addr MUX for m-bit function.\n\nAdder: Half adder & full adder.\n\nHalf Adder: $S = A \\oplus B$\n\nFull adder: $C_{out} = A\\cdot C_{in} + B\\cdot C_{in} + A\\cdot B, S = A\\oplus B\\oplus C_{in}$\n\nImplements of Full Adder:\n\n**Serial Adder** $C_{i+1} = A_iC_i+B_iC_i + A_iB_i$. The latency is disastrous.\n\n**Carry Lookahead Adder(CLA)**\n\nFirst define $P_i = A_i\\oplus B_i, G_i = A_iB_i$, P means Carry-bit propagation, G means Carry-bit Generation. Thus, $C_{i+1} = G_i + P_iC_i, S_i = A_i\\oplus B_i\\oplus C_i = P_i\\oplus C_i$. Thus the $C_i$ can be replaced: \n\n$$\nC_1 = G_0+P_0C_0\\\\\nC_2 = G_1 + P_1(G_0+P_0C_0) =  G_1 + P_1G_0+P_1P_0C_0\\\\\nC_3 = G_2 + P_2(G_1 + P_1G_0+P_1P_0C_0) = G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0\\\\\nC_4=G_3+P_3(G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0)=G_3+P_3G_2 + P_3P_2G_1 + P_3P_2P_1G_0+P_3P_2P_1P_0C_0\n$$\n\nA 4-bit CLA can be designed using these formulas. For more, it is too complex. However, we can cascade the 4-bit CLA to reach the balance of latency and complexity.\n\nMoreover, here comes the parallel intra- and inter-group CLA which regards the 4-bit adder as a block and defines its $P_i$ and $G_i$, connecting the 4-bit adders in a similar manner as the structure of 4-bit adder inside.\n\n## Sequential logic\n\n![](../images/digital/lec_4_1.jpg)\n\n### Clock\n\n- Ring Oscillator\n- LC oscilator\n- Crystal Oscillator\n\n### State and FSM\n\n**States** contain all needed infomation. could be redundant.\n\n**Finite State Machine(FSM)** The number of input, output and states are finite.\n\nMealy FSM: \n\n![](../images/digital/lec_4_2.jpg)\n\nMoore FSM: \n\n![](../images/digital/lec_4_3.jpg)\n\nWe describe the FSM by State Transition Table or State Diagram.\n\n![](../images/digital/lec_4_4.jpg)\n\n![](../images/digital/lec_4_5.jpg)\n\nRemember: Moore is less.\n\n### Latch\n\nWatch the input at the **duration** clock enables.\n\n#### Examples\n\n**SR latch**\n\n\n![](../images/digital/lec_4_6.jpg)\n\n$SR=0$ is required.\n\n$$\nQ^+=S+R^\\prime Q\n$$\n\nA gated version:\n\n![](../images/digital/lec_4_7.jpg)\n\n$$\nQ^+=C^\\prime Q + C(S+R^\\prime Q)\n$$\n\n**D latch**\n\n\n![](../images/digital/lec_4_8.jpg)\n\n$$\nQ^+=D\n$$\n\nTransimission Gate version\n\n![](../images/digital/lec_4_9.jpg)\n\n#### Timing parameters\n\n![](../images/digital/lec_4_10.jpg)\n\n![](../images/digital/lec_4_11.jpg)\n\n\n\n### Flip-Flop\n\nWatch the input only at the **moment** when clock signal rises or falls.\n\n\n#### Examples\n\nD Flip-flop(DFF)\n\n![](../images/digital/lec_4_12.jpg)\n\n2 D latches in series with opposite clock.\n\n**Use the delay to help us**\n\nThe delay of  NOT gate at the bottom enables the slave to lock first and the master to unlock second when clock falls.\n\nAlso, the delay of NOT gate at the bottom makes $t_h=0$.\n\n\n![](../images/digital/lec_4_13.jpg)\n\n**Two time constraints**\n\nSet-up time constraints: restrict the clock cycle.\n\n![](../images/digital/lec_4_14.jpg)\n\n$t_{logic}(max)$ is also called propagation delay $t_{dab}$.\n\nHold time constraints: restrict the $t_d$\n\n![](../images/digital/lec_4_15.jpg)\n\n$t_{logic}(min)$ is also called contamination delay($t_{cab}$).\n\n#### 4 types of FF\n\n![](../images/digital/lec_4_16.jpg)\n\n![](../images/digital/lec_4_17.jpg)\n\n![](../images/digital/lec_4_1.jpg8.jpg)\n\nCharacteristic equations\n\n$$\nQ^+=D\\\\\nQ^+=T\\overline Q + \\overline{T}Q\\\\\nQ^+=S+\\overline{R}Q\\\\\nQ^+=J\\overline{Q}+\\overline{K}Q\n$$\n\n### Problems\n\nCan $t_h$ be negative?\n\n[setup-and-hold-time](https://www.physicaldesign4u.com/2020/04/sta-iii-global-setup-and-hold-time-can.html)\n\nHow to convert FF?\n\nhttps://blog.csdn.net/qq_43975016/article/details/121193168\n\n### Analyzing Sequential Logic\n\n**Function Analysis**\n\n![](../images/digital/lec_5_1.jpg)\n\n**State Transistion Table**\n\n![](../images/digital/lec_5_2.jpg)\n\n![](../images/digital/lec_5_3.jpg)\n\n![](../images/digital/lec_5_4.jpg)\n\n![](../images/digital/lec_5_5.jpg)\n\n![](../images/digital/lec_5_6.jpg)\n\nOpt.2 is different and needed to be thought carefully. The x and s in $g(x, s)$ may not be caused by same x.\n\n**Time Constraint**\n\n### Designing Sequential Logic\n\n**Step 1 Determine the input, output and state**\n\n![](../images/digital/lec_5_7.jpg)\n\nHere, Moore is more in FSM states.\n\n**Step 2 State simplification**\n\n2 methods: row matching & implication chart\n\nrow matching: $P\\equiv Q$ iff. outputs and next states are same.\n\nWe can use **implication table** to optimize the row matching method.\n\n![](../images/digital/lec_5_9.jpg)\n\n![](../images/digital/lec_5_10.jpg)\n\n**Step 3 State allocation/representation**\n\n![](../images/digital/lec_5_8.jpg)\n\nMany methods:\n\n![](../images/digital/lec_5_11.jpg)\n\n**Next state and input/output based criteria**\n\nHighest Priority:\n\nSame input and same next state should be encoded adjacently.\n\n![](../images/digital/lec_5_14.jpg)\n\nMedium Priority:\n\nNext states of the same state should have adjacent\nencoding.\n\n![](../images/digital/lec_5_12.jpg)\n\nLowest Priority:\n\nStates with the same output should have adjacent \nencoding.\n\n![](../images/digital/lec_5_13.jpg)\n\n**Step 5 Get Excitation and Output Equations**\n\n![](../images/digital/lec_5_15.jpg)\n\n\n**Step 6 Draw Logic Circuit Diagram**\n\n### Typical Sequential Logic Circuits\n\nRegister & Counter\n\n**Register**\n\nShift register. Serial/Parallel Input, Serial/Parallel Output.\n\n![](../images/digital/lec_5_17.jpg)\n\n![](../images/digital/lec_5_16.jpg)\n\n![](../images/digital/lec_5_18.jpg)\n\n**Counter**\n\n**UP/Down Counter**\n\n![](../images/digital/lec_5_19.jpg)\n\n**Specific-base Counter**\n\n000→010→011→101→110→000\n\n![](../images/digital/lec_5_20.jpg)\n\n**Self-Starting problem of counter**\n\nAbnormal state(001, 100, 111)\n\n![](../images/digital/lec_5_21.jpg)\n\n**Ring counter & twisted ring counter**\n\n![](../images/digital/lec_5_22.jpg)\n\n![](../images/digital/lec_5_23.jpg)\n\n**Async & snyc Counter**\n\n![](../images/digital/lec_5_24.jpg)\n\n![](../images/digital/lec_5_25.jpg)\n\n![](../images/digital/lec_5_26.jpg)\n\n## Instruction Set Architecture\n\n### Introduction\n\n#### Implement Algorithm In Hardware\n\n![](../images/digital/lec_6_1.jpg)\n\nThree steps: \n* Instruction fetch\n* Instruction decoding\n* Instruction execution & data write-back\n\n**Program Counter(PC)**\n\nCurrent Instruction Address\n\nUpdated Every Cycle\n\n**Arithmetic/Logic Instructions**\n\nArithmetic Logic Unit(ALU)\n\nREG to REG, NOT Directly access data memory\n\n\n**Branch/Jump Instructions**\n\nBranch After Comparison\n\nJump Directly\n\n**Load/Store Instructions**\n\nLoad Data: data memory to REG\n\nStore Data: REG to data memory\n\n#### General Purpose Processore Structure\n\n**Turing Machine**\n\n2 Turing Machine Models: \n\n* Princeton architecture\n* Harvard architecture\n\n![](../images/digital/lec_6_2.jpg)\n\n#### Program FLow\n\n![](../images/digital/lec_6_3.jpg)\n\n![](../images/digital/lec_6_4.jpg)\n\n### Instruction Set Design\n\nInstruction set is the bridge between software & generall-purpose (GP) CPU.\n\n**Performance Evaluate**\n\n$$\n\\text{Performance} = \\frac{1}{\\text{Execution Time}}\n$$\n\nTask Execution Time By CPU:\n\n$$\n\\text{Total Time} = \\text{Waiting for I/O} + \\text{Execution Time}\\\\\n\\text{Execution Time} = \\text{Cycle }\\# \\times \\text{Clock Cycle }T = \\frac{\\text{Cycle }\\# }{\\text{Clock }f} \n$$\n\n$$\n\\text{Cycle } \\# = \\text{Progream Instruction }\\# \\times \\text{Average Cycle } \\# \\text{ for one inst.}\n$$\n\nAverage Cycle # for one instruction is also known as the cycle per instruction (CPI)\n\nSo, \n\n$$\n\\text{Execution Time} = \\text{Instruction }\\# \\times \\text{CPI} \\times \\text{Clock Cycle }\n$$\n\n**CPI**\n\n$$\n\\text{CPI} = \\sum_{i = 1}^n \\text{CPI}_i \\times \\text{P}_i\n$$\n\nWhere $\\text{P}_i$ is the i-th instruction occurrence frequency, and $\\text{CPI}_i$ is the clock cycle # of the i-th instruction.\n\n**Factors that affect Performance**\n* Instruction # \n* - ISA, regardless of its specific implementation\n* - Compiler\n* CPI\n* - Memory System and Processor Architecture\n* - The Instruction Composition In the Program\n* - Compiler\n* Clock Cycle\n* - Machine implementation details\n* - Memory System and Processor Architecture\n\n![](../images/digital/lec_6_5.jpg)\n\n**Data Access**\n\n![](../images/digital/lec_6_6.jpg)\n\n![](../images/digital/lec_6_7.jpg)\n\n**Set Design**\n\nRISC & CISC\n\n![](../images/digital/lec_6_8.jpg)\n\n![](../images/digital/lec_6_9.jpg)\n\n**Five Questions**\n\n* How to make use of 11 extra bits in arithmetic operations?\n* How to use 16 bits to represent 32-bit address for branch?\n* How to encode branch instruction with immediate?\n* How to use 21 bits to represent 32-bit address for memory address?\n* How to use 26 bits to represent 32-bit address for jump?\n\n\n\n\n### MIPS Instruction Set\n\n#### Instruction Storage and Data Storage\n\n32-bits instruction length, and 32 general-purpose registers.\n\nFirst 6 bits are opcode.\n\n**Register**\n\n![](../images/digital/lec_7_9.jpg)\n\nthe register index is limited to 5 bits.\n\n#### Instruction Type(R, I, J)\n\n**Type: R**\n\n**Field Division and detailed definition**\n\n![](../images/digital/lec_7_1.jpg)\n\nQ1: Can we make use of the extra 11 bits?\n\n![](../images/digital/lec_7_13.jpg)\n\n**Type: I**\n\nIt's immediate.\n\n![](../images/digital/lec_7_5.jpg)\n\n2 cases:\n\n![](../images/digital/lec_7_2.jpg)\n\n![](../images/digital/lec_7_3.jpg)\n\nQ2:The possible address range covers 32 bits. How to represent the address with limited 16 bits for branch?\n\nbase + offset\n\n![](../images/digital/lec_7_10.jpg)\n\nQ3: How to encode the branch with immediate?\n\nNo direct instructions for this.\n\nWe use compare instruction and branch instruction to achieve this.\n\nQ4: The possible address range covers 32 bits. How to represent the address with limited 21 bits for memory access?\n\nbase + offset\n\n![](../images/digital/lec_7_4.jpg)\n\n**Type: J**\n\n![](../images/digital/lec_7_6.jpg)\n\nQ5: The possible address range covers 32 bits. How to represent \nthe address with limited 26 bits for jump?\n\n3 types of jump operation: `j`, `jal` and `jr`.\n\n![](../images/digital/lec_7_7.jpg)\n\n**Summary**\n\n![](../images/digital/lec_7_.jpg)\n\n#### Addressing mode\n\n5 modes:\n\n* Register addressing\n* Immediate addressing\n* Base (base-offset) addressing\n* PC-related addressing\n* Pseudo-direct addressing\n\n**Register addressing**\n\n![](../images/digital/lec_7_11.jpg)\n\n**Immediate addressing**\n\n![](../images/digital/lec_7_12.jpg)\n\nHow to load a 32-bit constant to $s0?\n\n![](../images/digital/lec_7_14.jpg)\n\n**Base-offset addressing**\n\n![](../images/digital/lec_7_15.jpg)\n\n**PC-related addressing**\n\n![](../images/digital/lec_7_16.jpg)\n\n![](../images/digital/lec_7_17.jpg)\n\n**Pseudo-direct addressing**\n\n![](../images/digital/lec_7_18.jpg)\n\nIt is faster because no add operation needed, comparing to `PC_new = {PC_old + address << 2}`.\n\n**Summary**\n\n![](../images/digital/lec_7_19.jpg)\n\n#### Instruciton System\n\n**Arithmetic**\n\nAdd  `add $t0, $t1, $t2      #$t0=$t1+$t2`\n\nAdd immediate `addi $t2, $t3, 5  #$t2=$t3+5`\n\nSubtract `sub $t2,$t3,$t4 #$t2=$t3-$t4`\n\nNO subtract-an-immediate instruction! We use 2's complement immediate in the `addi`.\n\n**Logic**\n\n```assembly\nand $t0, $t1, $t2\nor $t0, $t1, $t2\nxor $t0, $t1, $t2\nnor $t0, $t1, $t2\n```\n\nNo NOT instruction. We set `$t1` or `$t2` to 0 and use NOR.\n\nWith immediate:\n\n```\nandi $t0, $t1, 10\nori $t0, $t1, 10\nxori $t0, $t1, 10\n```\n\n**Shift**\n\nImmediate-amount shift:\n\n```\nsll $t0, $t1, 10\n# $t0 = $t1 << 10, logical\nsrl $t0, $t1, 10\n# $t0 = $t1 << 10, logical\nsra $t0, $t1, 10\n# $t0 = $t1 >> 10, arithmetic, depending on the sign bit\n```\n\nRegister-amonut shift: \n\n```\nsllv $t0, $t1, $t3\n# $t0 = $t1 << ($t3%32), logical\nsrl $t0, $t1, $t3\n# $t0 = $t1 << ($t3%32), logical\nsra $t0, $t1, $t3\n# $t0 = $t1 >> ($t3%32), arithmetic, depending on the sign bit\n```\n\n**Compare instruction**\n\n```\nslt $t1, $t2, $t3\n# if ($t2 < $t3) $t1=1;\n# else $t1=0\nsltu $t1, $t2, $t3\n# unsigned comparison\n```\n\nWith immediate:\n\n```\nslti $t1, $t2, 10\nsltui $t1, $t2, 10\n```\n\n**About i, u, iu**\n\n![](../images/digital/lec_7_20.jpg)\n\n**Load/Store Instruction**\n\n```\nlw $t1, 32($t2)\nsw $t3, 500($t4)\n```\n\nRegister stores base address is called base register, \nConstant in the instruction is called offset.\n\n**Branch instruction**\n\n```\nbeq $t0, $t1, target\n#if $t0=$t1, then execute\n#instruction target\nbne $t0, $t1, target\n# if $t0!=$t1, then execute\n# instruction target\n```\n\nMore than this 2 instructions.\n\n**Jump instruction**\n\nUnconditional branch\n\n```\nj label\n#unconditionally jump to label\n```\n\n#### Procedure Call\n\n![](../images/digital/lec_7_21.jpg)\n\nMIPS uses registers for argument and return data/address.\n\nArgument registers: `$a0-$a3`\n\nReturn value registers: `$v0-$v1`\n\nRetuen address register: `$ra`\n\n``\njal Procedure #Procedure call\njr $ra #Procedure return\n``\n\n`jal` and `j` are both J-type, but `jal` will store the return address.\n\n`jr` is R-type, will jump to the address restored in the register, so it can jump very far.\n\n**Maintain the register data**\n\n2 types:\n\n* Temporaries data registers\n* Saved data registers\n\n![](../images/digital/lec_7_22.jpg)\n\nWho saves the register data?\n\nCaller(temp) or Callee(save)\n\n![](../images/digital/lec_7_23.jpg)\n\nWe use Stack to maintain the register data.\n\n![](../images/digital/lec_7_24.jpg)\n\n**Stack Operation with $sp**\n\ne.g. `push $s1, $s2 , $s3`\n\n```\naddi $sp, $sp, -12\nsw $s1, 8($sp)\nsw $s2, 4($sp)\nsw $s3, 0($sp)\n```\n`pop $s1, $s2, $s3`\n\n```\nlw $s1, 0($sp)\nlw $s2, 4($sp)\nlw $s3, 8($sp)\naddi, $sp, $sp, 12\n```\n\n**Leaf Procedures**\n\nProcedures that do not call others are called *leaf* procedures.\n\n**Nested Procedures**\n\nNested(Recursive) Procedures are procedures that invoke \"clones\" of themselves.\n\ne.g.\n\n```C\nint fact (int n) {\n    if (n < 1) return 1;\n    else return (n * fact(n - 1));\n}\n```\n\n```assembly\nfact:\n    addi    $sp, $sp, -8\n    sw      $ra, 4($sp)\n    sw      $a0, 0($sp)\n    slti    $t0, $a0, 1\n    beq     $t0, $zero, L1\n    addi    $v0, $zero, 1\n    addi    $sp, $sp, 8\n    jr      $ra\nL1:\n    addi    $a0, $a0, -1\n    jal     fact\n    lw      $a0, 0($sp)\n    lw      $ra, 4($sp)\n    addi    $sp, $sp, 8\n    mul     $v0, $a0, $v0\n    jr      $ra\n```\n\n## Single-Cycle Processor\n\n![](../images/digital/lec_8_1.jpg)\n\n![](../images/digital/lec_8_2.jpg)\n\n![](../images/digital/lec_8_3.jpg)\n\n![](../images/digital/lec_8_4.jpg)\n\n![](../images/digital/lec_8_5.jpg)\n\n![](../images/digital/lec_8_6.jpg)\n\n![](../images/digital/lec_8_7.jpg)\n\n**Load Operation Takes MUCH LONGER!!!**\n\n## Multi-Cycle Processor\n\n![](../images/digital/lec_8_8.jpg)\n\nThe Multicycle processor processes different inst. in different cycles. Thus, it can avoid the time limitation by the slow instruction.\n\nModules on th datapath can be used multiple times within an inst. That is **Module reuse**.\n\nPerformance improvement depends on the detailed delay. The multicycle is not necessarily faster than the single cycle.\n\n![](../images/digital/lec_8_9.jpg)\n\n![](../images/digital/lec_8_10.jpg)\n\n![](../images/digital/lec_8_11.jpg)\n\n![](../images/digital/lec_8_12.jpg)\n\n![](../images/digital/lec_8_13.jpg)\n\n![](../images/digital/lec_8_14.jpg)\n\n![](../images/digital/lec_8_15.jpg)\n\n![](../images/digital/lec_8_16.jpg)\n\n![](../images/digital/lec_8_17.jpg)\n\n![](../images/digital/lec_8_18.jpg)\n\n![](../images/digital/lec_8_19.jpg)\n\n![](../images/digital/lec_8_20.jpg)\n\n![](../images/digital/lec_8_21.jpg)\n\n![](../images/digital/lec_8_30.jpg)\n\n![](../images/digital/lec_8_31.jpg)\n\n\n\n## Exception and Interrupt\n\n![](../images/digital/lec_8_22.jpg)\n\nGenerally, exceptions and interrupts are events that can change the normal instruction execution flow (other than branches and jumps).\n\nException\n– Internal unpredictable events such as overflow.\n\nInterrupt\n– External unpredictable events such as I/O.\n\n![](../images/digital/lec_8_23.jpg)\n\n![](../images/digital/lec_8_24.jpg)\n\n![](../images/digital/lec_8_25.jpg)\n\n![](../images/digital/lec_8_26.jpg)\n\n![](../images/digital/lec_8_27.jpg)\n\n![](../images/digital/lec_8_28.jpg)\n\n![](../images/digital/lec_8_29.jpg)\n\n## Pipelined processor\n\n![](../images/digital/lec_9_1.jpg)\n\nPipeline means spatial and temporal reuse.\n\nDivide a complex task into several sub-tasks to \nexecute sequentially, and assign each sub-task to \ndedicated hardware\n\nDifferent sub-tasks of multiple tasks can be \nprocessed simultaneously to improve the \nperformance\n\n• Time-division multiplexing: the same resource is reused through \ndifferent cycles\n\n• Space-division multiplexing: multiple resources are reused \nwithin one cycle\n\nPros: improved efficiency\n\nCons: Some inst. depends on the former inst.. However, the former inst. has not finished yet, if the prediction of branch is wrong, time is wasted.\n\nInstruction-Level Parallelism (ILP)\n\n– Execute multiple instructions in parallel\n\n– One mainstream approach to CPU performance improvement\n\nBasic Techniques\n\n– Pipelining: instruction execution is divided into several stages, and \neach stage can be processed with the other stages (of other \ninstructions) simultaneously\n\n– Superscalar: multiple dedicated functional units are equipped so \nthat CPU can receive & execute more instructions within one cycle.\n\n– Very Long Instruction Word (VLIW): each instruction consists of \nmultiple segments to utilize the processor resources independently.\n\n5 stages in MIPS:\n\n1. Instruction Fetch (IF)\n2. Instruction Decode / Register File\n3. ALU Execution(EX)\n4. Memory Data Access(MEM)\n5. Reg Write-Back(WB)\n\nLatency of the stages in the pipeline should \nbe as equivalent as possible, why?\n–The pipeline performance is bottlenecked by the stage \nof the longest latency\n\n**Metrics of pipelined processors**\n\n* Throughput(TP): Executed instruction # per unit time\n* Max throughput: The throughput of a steady-state pipeline with a continuous instruction input stream\n* Real throughput: The throughput of the pipeline executing task with finite instructions\n\nReal TP:\n\n$$\nTP = \\frac n {T_k} = \\frac{n}{(n+k-1)\\Delta t}\n$$\n\nMax TP:\n\n$$\nTP_{max} = \\lim_{n\\rightarrow\\infty}\\frac{n}{(n+k-1)\\Delta t} = \\frac{1}{\\Delta t}\n$$\n\n**Speed up** Execution time ratio between w/o or w/ pipelining.\n\n$T_0$: execution time without pipelining\n\n$T_k$: execution time with k-stage pipelining(assume each stage has the same latency)\n\n$$\n\\frac{T_0}{T_k}\n$$\n\nReal speedup:\n\n$$\nS = \\frac{nk\\Delta t}{(n + k - 1)\\Delta t} = \\frac{kn}{n + k - 1}\n$$\n\nMax speedup:\n\n$$\nS_{max} = \\lim_{n\\rightarrow \\infty}\\frac{kn}{k + n - 1} = k\n$$\n\n**Pipelined datapath**\n\n![](../images/digital/lec_9_3.jpg)\n\n![](../images/digital/lec_9_4.jpg)\n\n![](../images/digital/lec_9_5.jpg)\n\n![](../images/digital/lec_9_6.jpg)\n\n![](../images/digital/lec_9_7.jpg)\n\n![](../images/digital/lec_9_8.jpg)\n\nMany inst. doesnt need MEM stage, but the stage can't be skipped, since it may \"collide\" with the previous inst.\n\nQ: How to get the control signals in each stage?\n\nControl signals are generated at ID/RF stage.\n\nControl signals flow in the pipeline: use when needed; reserve when subsequent stages needed; discard when not needed any more.\n\n![](../images/digital/lec_9_10.jpg)\n\nWhy RegDst Doesnt needed in the stages after EX?\n\nThe RegDst is used to select the destination register. However, the destination register is determined in the EX stage. Thus, RegDst is not needed in the stages after EX.\n\nSometimes this can cause trouble:\n\n```MIPS\nLW R2, R9(10)\nADD R4, R3, R2\nADD R6, R5, R4\n```\n\nThe R4 is accessed before it updates.\n\n### Hazard in the pipeline\n\n**Structural Hazards**\n\nTwo instructions acquire the same hardware resource simultaneously.\n\n![](../images/digital/lec_9_11.jpg)\n\nSolution:\n\n1. Add resources: separating PC+4 from ALU; Harvard architecture\n2. Adjust stages: add MEM\n\n![](../images/digital/lec_9_15.jpg)\n\n![](../images/digital/lec_9_12.jpg)\n\nMIPS is born to be  pipelined: the problem of structural hazard is solved by the structure of MIPS.\n\n**Data Hazards**\n\n![](../images/digital/lec_9_13.jpg)\n\n2 solutions:\n\n**Stalling**\n\n![](../images/ss/lec21_8.jpg)\n\n**Forwarding(Bypassing)**\n\n![](../images/ss/lec21_1.jpg)\n\n![](../images/ss/lec21_2.jpg)\n\nBut, load uses hazard emerges:\n\n![](../images/ss/lec21_8.jpg)\n\n![](../images/digital/lec_10_1.jpg)\n\nStill, a nop needed to stall the pipeline.\n\n![](../images/digital/lec_10_2.jpg)\n\nIs there any possibility to eliminate the stall?\n\nYes, if the MIPS code can be optimized.\n\n![](../images/digital/lec_10_3.jpg)\n\n\n**Control Hazards**\n\n![](../images/digital/lec_9_14.jpg)\n\n**Stalling**\n\n![](../images/digital/lec_10_4.jpg)\n\n**Forwarding**\n\n![](../images/digital/lec_10_5.jpg)\n\nIf Move the branch decision to ID stage:\n\n![](../images/digital/lec_10_6.jpg)\n\n\n![](../images/digital/lec_10_7.jpg)\n\n\n**Delay slot**\n\n![](../images/digital/lec_10_8.jpg)\n\n**Prediction**\n\nStatic Branch Prediction\n\n![](../images/digital/lec_10_9.jpg)\n\nCancel the effect caused by false prediction.\n\nDynamic Branch Prediction\n\n* History-based dynamic prediction\n* Using runtime behaviour to predict future branches\n\nAt IF stage, there are Branch History Table(BHT) and Branch Target Buffer(BTB).\n\nbeq at IF stage\n\n• Look up if the instruction address is in BHT and BTB.\n\n• If not in, create a new entry. If in, check whether the \nbranch is taken at the last time. If taken, send the target \naddress to PC as the next address for IF.\n\n–beq at ID stage\n\n• IF stage will fetch instruction based on the predicted \ntarget address\n\n### Implementation of the Pipiline\n\n![](../images/digital/lec_10_10.jpg)\n\n**Data hazard**\n\nForwarding\n\n\nEX/MEM hazard\n~~~Verilog\nif (EX/MEM.RegWrite\nand (EX/MEM.RegWrAddr != 0)\nand (EX/MEM.RegWrAddr == ID/EX.RegisterRs))\n    ForwardA = 10\nif (EX/MEM.RegWrite\nand (EX/MEM.RegWrAddr != 0)\nand (EX/MEM.RegWrAddr == ID/EX.RegisterRt))\n    ForwardB = 10\n~~~\n\nMEM/WB hazard\n~~~Verilog\nif (MEM/WB.RegWrite\nand (MEM/WB.RegWrAddr != 0)\nand (MEM/WB.RegWrAddr == ID/EX.RegisterRs)\nand (EX/MEM.RegWrAddr != ID/EX.RegisterRs || ~ EX/MEM.RegWrite))\n    ForwardA = 01\nif (MEM/WB.RegWrite\nand (MEM/WB.RegWrAddr != 0)\nand (MEM/WB.RegWrAddr == ID/EX.RegisterRt)\nand (EX/MEM.RegWrAddr != ID/EX.RegisterRt || ~ EX/MEM.RegWrite))\n    ForwardB = 01\n~~~\n\nload-use hazard\n\nWe have to stall the pipeline for one cycle.\n\nCondition: `if (ID/EX.MemRead and ((ID/EX.RegisterRt == IF/ID.RegisterRs) or \n(ID/EX.RegisterRt == IF/ID.RegisterRt)))`\n\nHow to stall?\n\nStall & flush\n\nPC & ID/IF: stall(Keep the control signals)\n\nEX & MEM & WB: flush(Set the control signals to 0)\n\nControl signals:\n\nEX: RegDst, ALUOp1, ALUOp0, ALUSrc\n\nMEM: Branch, MemRead, MemWrite\n\nWB: MemToReg, RegWrite\n\n~~~Verilog\nif {ID/EX.MemRead\nand ((ID/EX.RegisterRt = IF/ID.RegisterRs)\nor (ID/EX.RegisterRt = IF/ID.RegisterRt))}\n    Keep IF/ID; Keep PC; Flush ID/EX;\n~~~\n\nSpecial Case:\n\nMemory-to-memory copy\n\n~~~\nlw $1, 10($2)\nsw $1, 10($3)\n~~~\n\nThe stall is unnecessary. We can use forwarding to solve the problem.\n\n**Control Hazard**\n\nBEQ & J need 1 stall cycle.\n\nControl hazards are not as frequent as data \nhazards, but they are harder to be resolved \neffectively as forwarding.\n\nAnother type of control hazard: exceptions and interrupts.\n\n– “Exception” includes any unpredictable events that \ncan change the normal control flow, which has no \ndistinction between internal and external. \n\n– “Interrupt” is only used for external events.\n\n![](../images/digital/lec_12_1.jpg)\n\n## Advanced techniques for processor\n\n### Instruction-level parallelism\n\nSuperpipelining: a deeper pipeline\n\nVLIW\n\n\nMultiple-issue: a wider pipeline\n\nSuperscalar\n\n![](../images/digital/lec_12_2.jpg)\n\n### Thread-level parallelism\n\nHyper-threading\n\n![](../images/digital/lec_12_3.jpg)\n\nMulticore\n\n### Heterogeneous computing\n\nGPU\n\nXPU\n\n## Memory\n\n### Basics\n\nSRAM cell\n\nHigh speed, low density & expensive\n\n![](../images/digital/lec_12_4.jpg)\n\nDRAM cell\n\nLow speed, high density & cheap. The charge in capacitor may leak, so the data cannot be stored for a long time.\n\n![](../images/digital/lec_12_5.jpg)\n\n![](../images/digital/lec_12_6.jpg)\n\n### Evaluation\n\n3C model:\n\n**Compulsory miss** first access to a block\n\n**Capacity miss** all lines in cache are used\n\n**Conflict miss(collision miss)** not fully filled, but the blocks # > available ways #.","slug":"数逻","published":1,"updated":"2024-03-19T06:01:16.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfi1000ursug79zm1v1u","content":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h2 id=\"Boolean-Algebra\"><a href=\"#Boolean-Algebra\" class=\"headerlink\" title=\"Boolean Algebra\"></a>Boolean Algebra</h2><h3 id=\"The-Number-System\"><a href=\"#The-Number-System\" class=\"headerlink\" title=\"The Number System\"></a>The Number System</h3><h4 id=\"BCD\"><a href=\"#BCD\" class=\"headerlink\" title=\"BCD\"></a>BCD</h4><p>BCD (Binary-Coded Decimal)</p>\n<p>Classic method: 8421BCD.</p>\n<p>add calculation:</p>\n<p>the problem of carry:</p>\n<div>$$\n(14)_D+(28)_D=(0001\\ 0100)_{BCD} + (0100\\ 0100)_{BCD}\\\\\n=(0101\\ 1100)_{BCD}=(0110\\ 0010)_{BCD}\n$$</div>\n\n<h4 id=\"Gray-Code\"><a href=\"#Gray-Code\" class=\"headerlink\" title=\"Gray Code\"></a>Gray Code</h4><p>used in logic simplification and signal transmission.</p>\n<p>every time a single bit is changed.</p>\n<h4 id=\"Floating-poing-Number\"><a href=\"#Floating-poing-Number\" class=\"headerlink\" title=\"Floating poing Number\"></a>Floating poing Number</h4><h4 id=\"Negative-numbers\"><a href=\"#Negative-numbers\" class=\"headerlink\" title=\"Negative numbers\"></a>Negative numbers</h4><p><strong>Complement Numeric System</strong></p>\n<p>1’s Complement: $N_{1’s} + (-N)<em>{1’s} &#x3D; (111…)</em>{1’s}$, or just inverting every bit of N. Low space efficiency and difficult to compute.</p>\n<p>2’s Complement: $N_{2’s} + (-N)<em>{2’s} &#x3D; (000…)</em>{2’s}$, or just inverting every bit of N and plus 1. A shift on 1’s Complement.</p>\n<p>MSB&#x3D;Most significant bit, LSB&#x3D;Least significant bit.</p>\n<div>$$\n-N=N_{us}-2^n=\\sum_{i=0}^{n-1}k_i2^i-2^n=-k_{n-1}2^{n-1}+k_{n-2}2^{n-2}+\\dots k_02^0\n$$</div>\n\n<p>So just set the weight of MSB to $-2^{n-1}$.</p>\n<p>we ignore the bit beyond the range to make sure the answer is correct.</p>\n<div>$$\n(101)_{2's}+(001)_{2's}=(110)_{2's}\\\\\n(011)_{2's}-(001)_{2's}=(011)_{2's}+(111)_{2's}=(010)_{2's}\n$$</div>\nTo detect an overflow, we can notice if 2 positive numbers add up to a negative numbers or 2 negative numbers add up to a positive numbers.\n\n<p>We can fix overflow by adding 0 as MSB if the answer should be positive and adding 1 as MSB if the answer should be negative.</p>\n<h3 id=\"Boolean-expression\"><a href=\"#Boolean-expression\" class=\"headerlink\" title=\"Boolean expression\"></a>Boolean expression</h3><h4 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h4><div>$$\n+(\\text{OR/logic add}),\\cdot (\\text{AND/logic multiply}), \\prime(\\bar{})(\\text{NOT/logit NOT})\n$$</div>\n\n<h4 id=\"Boolean-function\"><a href=\"#Boolean-function\" class=\"headerlink\" title=\"Boolean function\"></a>Boolean function</h4><p><strong>Duality</strong></p>\n<p>AND&lt;-&gt;OR, 0&lt;-&gt;1, variables unchanged.</p>\n<div>$$\nF_1=F_2\\Leftrightarrow F_1^D=F_2^D\n$$</div>\n\n<p><strong>De Morgan’s Law</strong></p>\n<p>AND&lt;-&gt;OR, 0&lt;-&gt;1, <strong>X&lt;-&gt;X’</strong></p>\n<p><strong>Useful Theorem</strong></p>\n<p>X(Y+Z)&#x3D;XY+XZ</p>\n<p>XY+Z&#x3D;(X+Z)(Y+Z)</p>\n<p>X+XY&#x3D;X</p>\n<p>X(X+Y)&#x3D;X</p>\n<h3 id=\"Boolean-function-simplification\"><a href=\"#Boolean-function-simplification\" class=\"headerlink\" title=\"Boolean function simplification\"></a>Boolean function simplification</h3><h4 id=\"2-level-logic\"><a href=\"#2-level-logic\" class=\"headerlink\" title=\"2-level logic\"></a>2-level logic</h4><p><strong>Standard form</strong><br>SOP and POS</p>\n<p>Sum of Products or Products of Sum</p>\n<p><strong>Min-term</strong><br>A min-term is a product of all variables taken either in the direct or complemented form, each variable shown once.</p>\n<p>$A’B’C’&#x3D;m_0$ and $ABC&#x3D;M_7$</p>\n<p><strong>Max-term</strong> A max-term is a sum of all variables taken either in the direct or complemented form, each variable shown once.</p>\n<p>$A+B+C&#x3D;M_0$ and $A’+B’+C’&#x3D;M_7$</p>\n<div>$$\nm_6= \\overline{M_6}\n$$</div>\n\n<p><strong>Karnaugh Maps</strong></p>\n<p>Use row and columns to represent combinations of the inputs(by min-terms), the cell to represent the value. The inputs is ordered by the sequence of Grey Code.</p>\n<h4 id=\"Simplification-of-2-level-logic\"><a href=\"#Simplification-of-2-level-logic\" class=\"headerlink\" title=\"Simplification of 2-level logic\"></a>Simplification of 2-level logic</h4><p><strong>Karnaugh Maps method</strong></p>\n<p>If two adjacent min-terms deliver logic 1, merge them.</p>\n<p><strong>Implicant</strong></p>\n<div>$$\nG\\Rightarrow F, \\text{then }G\\text{ is the implicant of }F\\\\\nno\\ Q\\ s.t.P\\Rightarrow Q\\Rightarrow F, \\text{then }P \\text{ is the prime implicant of }F\\\\\n\\text{If one min-term can only be covered by one prime implicant, this prime implicant is an EPI.}\n$$</div>\n\n<p>EPI will finally exist there.</p>\n<p><strong>Q-M method</strong></p>\n<p>algorithm to simplify multiple-input large-scale function.</p>\n<h2 id=\"Combinational-Logic\"><a href=\"#Combinational-Logic\" class=\"headerlink\" title=\"Combinational Logic\"></a>Combinational Logic</h2><h3 id=\"Gate\"><a href=\"#Gate\" class=\"headerlink\" title=\"Gate\"></a>Gate</h3><p>NAND, NOT, NOR is better than AND, OR in saving area.</p>\n<p><strong>Transmission Gate</strong> Use both NMOS and PMOS to form a CMOS switch. NMOS is good at transmitting low volt while PMOS is better at working on high volt.</p>\n<p><strong>Tri-state Gate</strong> EN is high, TG on, F&#x3D;A; EN is low, TG off, F is isolated from input A. The states are called logic 0, logic 1 and high-resistance Z.</p>\n<p><img src=\"/../images/digital/lec_3_1.jpg\" loading=\"lazy\"></p>\n<p>The bottom part of the circuit is used to avoid the high-Z state.</p>\n<h3 id=\"Combinational-logic-circuits\"><a href=\"#Combinational-logic-circuits\" class=\"headerlink\" title=\"Combinational logic circuits\"></a>Combinational logic circuits</h3><p>Outputs are the function of logic input circuits.</p>\n<p>Determined only by current not past inputs + delay</p>\n<p>To deal with complex logic with many inputs, we should:</p>\n<ul>\n<li>From 2-level to multi-level(BDD?)</li>\n<li>Divide-and-conquer</li>\n<li>Re-using</li>\n</ul>\n<h4 id=\"Metrics\"><a href=\"#Metrics\" class=\"headerlink\" title=\"Metrics\"></a>Metrics</h4><p><strong>Static metrics</strong> Logic voltage values, DC noise margins, Area, Fan-out</p>\n<p><strong>Dynamic metrics</strong> Speed&#x2F;delay, Power dissipation, Noise(reference)</p>\n<p><strong>Speed</strong> rise time and fall time. Propagation time.</p>\n<p><strong>Fan out</strong> The maximum number of CMOS inputs that one logic output can drive.</p>\n<p><strong>Power and energy</strong> Leakage power(static power): subthreshold leakage power, gate leakage, D&#x2F;S subtrate leakage. We can reduce the static power:</p>\n<ul>\n<li>increase $|V_{TH}|$ </li>\n<li>or decrease $V_{DD}$.</li>\n</ul>\n<div>$$\nP_{total} = P_{dynamic} + P_{dynamic\\_short} + P_{leakage}\n$$</div>\n\n<p>Dynamic power $P_{dynamic_short}$ shows in pull-up and pull-down on.</p>\n<div>$$\nP = C_LV_{DD}^2\\underset{\\text{Flip Prob.}}{\\alpha_{0-1}}f\n$$</div>\n\n<p>To reduce dynamic power:</p>\n<ul>\n<li>Reduce VDD and Capacitors</li>\n<li>Reduce frequency, flipping probability.</li>\n</ul>\n<p>Energy-delay product is a metric. It’s hard to reduce.</p>\n<ul>\n<li>Low power can increase the lifetime of the chip.</li>\n<li>Low delay can increase the speed of the chip.</li>\n</ul>\n<h4 id=\"Hazard\"><a href=\"#Hazard\" class=\"headerlink\" title=\"Hazard\"></a>Hazard</h4><p><strong>static-1 hazard</strong> ‘1’ output has a transient ‘0’ glitch</p>\n<p><strong>static-0 hazard</strong> ‘1’ output has a transient ‘0’ glitch</p>\n<p><strong>dynamic hazard</strong> several transitions during a single output change(not required)</p>\n<p>If the initial input and final input cannot be covered by one PI, it may have a glitch as state transition.</p>\n<h3 id=\"Basic-comb-logic-circuits\"><a href=\"#Basic-comb-logic-circuits\" class=\"headerlink\" title=\"Basic comb. logic circuits\"></a>Basic comb. logic circuits</h3><p>Encoder: inputs are more, outputs are less($n \\le 2^m$)</p>\n<p>Decoder: inputs are less, outputs are more($m &#x3D; 2^n$)</p>\n<p>Multiplexer: From several inputs, choose one as output according to the address inputs. It can be used to make a shift register. We can use n-bit-addr MUX for m-bit function.</p>\n<p>Adder: Half adder &amp; full adder.</p>\n<p>Half Adder: $S &#x3D; A \\oplus B$</p>\n<p>Full adder: $C_{out} &#x3D; A\\cdot C_{in} + B\\cdot C_{in} + A\\cdot B, S &#x3D; A\\oplus B\\oplus C_{in}$</p>\n<p>Implements of Full Adder:</p>\n<p><strong>Serial Adder</strong> $C_{i+1} &#x3D; A_iC_i+B_iC_i + A_iB_i$. The latency is disastrous.</p>\n<p><strong>Carry Lookahead Adder(CLA)</strong></p>\n<p>First define $P_i &#x3D; A_i\\oplus B_i, G_i &#x3D; A_iB_i$, P means Carry-bit propagation, G means Carry-bit Generation. Thus, $C_{i+1} &#x3D; G_i + P_iC_i, S_i &#x3D; A_i\\oplus B_i\\oplus C_i &#x3D; P_i\\oplus C_i$. Thus the $C_i$ can be replaced: </p>\n<div>$$\nC_1 = G_0+P_0C_0\\\\\nC_2 = G_1 + P_1(G_0+P_0C_0) =  G_1 + P_1G_0+P_1P_0C_0\\\\\nC_3 = G_2 + P_2(G_1 + P_1G_0+P_1P_0C_0) = G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0\\\\\nC_4=G_3+P_3(G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0)=G_3+P_3G_2 + P_3P_2G_1 + P_3P_2P_1G_0+P_3P_2P_1P_0C_0\n$$</div>\n\n<p>A 4-bit CLA can be designed using these formulas. For more, it is too complex. However, we can cascade the 4-bit CLA to reach the balance of latency and complexity.</p>\n<p>Moreover, here comes the parallel intra- and inter-group CLA which regards the 4-bit adder as a block and defines its $P_i$ and $G_i$, connecting the 4-bit adders in a similar manner as the structure of 4-bit adder inside.</p>\n<h2 id=\"Sequential-logic\"><a href=\"#Sequential-logic\" class=\"headerlink\" title=\"Sequential logic\"></a>Sequential logic</h2><p><img src=\"/../images/digital/lec_4_1.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Clock\"><a href=\"#Clock\" class=\"headerlink\" title=\"Clock\"></a>Clock</h3><ul>\n<li>Ring Oscillator</li>\n<li>LC oscilator</li>\n<li>Crystal Oscillator</li>\n</ul>\n<h3 id=\"State-and-FSM\"><a href=\"#State-and-FSM\" class=\"headerlink\" title=\"State and FSM\"></a>State and FSM</h3><p><strong>States</strong> contain all needed infomation. could be redundant.</p>\n<p><strong>Finite State Machine(FSM)</strong> The number of input, output and states are finite.</p>\n<p>Mealy FSM: </p>\n<p><img src=\"/../images/digital/lec_4_2.jpg\" loading=\"lazy\"></p>\n<p>Moore FSM: </p>\n<p><img src=\"/../images/digital/lec_4_3.jpg\" loading=\"lazy\"></p>\n<p>We describe the FSM by State Transition Table or State Diagram.</p>\n<p><img src=\"/../images/digital/lec_4_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_4_5.jpg\" loading=\"lazy\"></p>\n<p>Remember: Moore is less.</p>\n<h3 id=\"Latch\"><a href=\"#Latch\" class=\"headerlink\" title=\"Latch\"></a>Latch</h3><p>Watch the input at the <strong>duration</strong> clock enables.</p>\n<h4 id=\"Examples\"><a href=\"#Examples\" class=\"headerlink\" title=\"Examples\"></a>Examples</h4><p><strong>SR latch</strong></p>\n<p><img src=\"/../images/digital/lec_4_6.jpg\" loading=\"lazy\"></p>\n<p>$SR&#x3D;0$ is required.</p>\n<div>$$\nQ^+=S+R^\\prime Q\n$$</div>\n\n<p>A gated version:</p>\n<p><img src=\"/../images/digital/lec_4_7.jpg\" loading=\"lazy\"></p>\n<div>$$\nQ^+=C^\\prime Q + C(S+R^\\prime Q)\n$$</div>\n\n<p><strong>D latch</strong></p>\n<p><img src=\"/../images/digital/lec_4_8.jpg\" loading=\"lazy\"></p>\n<div>$$\nQ^+=D\n$$</div>\n\n<p>Transimission Gate version</p>\n<p><img src=\"/../images/digital/lec_4_9.jpg\" loading=\"lazy\"></p>\n<h4 id=\"Timing-parameters\"><a href=\"#Timing-parameters\" class=\"headerlink\" title=\"Timing parameters\"></a>Timing parameters</h4><p><img src=\"/../images/digital/lec_4_10.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_4_11.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Flip-Flop\"><a href=\"#Flip-Flop\" class=\"headerlink\" title=\"Flip-Flop\"></a>Flip-Flop</h3><p>Watch the input only at the <strong>moment</strong> when clock signal rises or falls.</p>\n<h4 id=\"Examples-1\"><a href=\"#Examples-1\" class=\"headerlink\" title=\"Examples\"></a>Examples</h4><p>D Flip-flop(DFF)</p>\n<p><img src=\"/../images/digital/lec_4_12.jpg\" loading=\"lazy\"></p>\n<p>2 D latches in series with opposite clock.</p>\n<p><strong>Use the delay to help us</strong></p>\n<p>The delay of  NOT gate at the bottom enables the slave to lock first and the master to unlock second when clock falls.</p>\n<p>Also, the delay of NOT gate at the bottom makes $t_h&#x3D;0$.</p>\n<p><img src=\"/../images/digital/lec_4_13.jpg\" loading=\"lazy\"></p>\n<p><strong>Two time constraints</strong></p>\n<p>Set-up time constraints: restrict the clock cycle.</p>\n<p><img src=\"/../images/digital/lec_4_14.jpg\" loading=\"lazy\"></p>\n<p>$t_{logic}(max)$ is also called propagation delay $t_{dab}$.</p>\n<p>Hold time constraints: restrict the $t_d$</p>\n<p><img src=\"/../images/digital/lec_4_15.jpg\" loading=\"lazy\"></p>\n<p>$t_{logic}(min)$ is also called contamination delay($t_{cab}$).</p>\n<h4 id=\"4-types-of-FF\"><a href=\"#4-types-of-FF\" class=\"headerlink\" title=\"4 types of FF\"></a>4 types of FF</h4><p><img src=\"/../images/digital/lec_4_16.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_4_17.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_4_1.jpg8.jpg\" loading=\"lazy\"></p>\n<p>Characteristic equations</p>\n<div>$$\nQ^+=D\\\\\nQ^+=T\\overline Q + \\overline{T}Q\\\\\nQ^+=S+\\overline{R}Q\\\\\nQ^+=J\\overline{Q}+\\overline{K}Q\n$$</div>\n\n<h3 id=\"Problems\"><a href=\"#Problems\" class=\"headerlink\" title=\"Problems\"></a>Problems</h3><p>Can $t_h$ be negative?</p>\n<p><a href=\"https://www.physicaldesign4u.com/2020/04/sta-iii-global-setup-and-hold-time-can.html\">setup-and-hold-time</a></p>\n<p>How to convert FF?</p>\n<p><a href=\"https://blog.csdn.net/qq_43975016/article/details/121193168\">https://blog.csdn.net/qq_43975016/article/details/121193168</a></p>\n<h3 id=\"Analyzing-Sequential-Logic\"><a href=\"#Analyzing-Sequential-Logic\" class=\"headerlink\" title=\"Analyzing Sequential Logic\"></a>Analyzing Sequential Logic</h3><p><strong>Function Analysis</strong></p>\n<p><img src=\"/../images/digital/lec_5_1.jpg\" loading=\"lazy\"></p>\n<p><strong>State Transistion Table</strong></p>\n<p><img src=\"/../images/digital/lec_5_2.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_5.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_6.jpg\" loading=\"lazy\"></p>\n<p>Opt.2 is different and needed to be thought carefully. The x and s in $g(x, s)$ may not be caused by same x.</p>\n<p><strong>Time Constraint</strong></p>\n<h3 id=\"Designing-Sequential-Logic\"><a href=\"#Designing-Sequential-Logic\" class=\"headerlink\" title=\"Designing Sequential Logic\"></a>Designing Sequential Logic</h3><p><strong>Step 1 Determine the input, output and state</strong></p>\n<p><img src=\"/../images/digital/lec_5_7.jpg\" loading=\"lazy\"></p>\n<p>Here, Moore is more in FSM states.</p>\n<p><strong>Step 2 State simplification</strong></p>\n<p>2 methods: row matching &amp; implication chart</p>\n<p>row matching: $P\\equiv Q$ iff. outputs and next states are same.</p>\n<p>We can use <strong>implication table</strong> to optimize the row matching method.</p>\n<p><img src=\"/../images/digital/lec_5_9.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_10.jpg\" loading=\"lazy\"></p>\n<p><strong>Step 3 State allocation&#x2F;representation</strong></p>\n<p><img src=\"/../images/digital/lec_5_8.jpg\" loading=\"lazy\"></p>\n<p>Many methods:</p>\n<p><img src=\"/../images/digital/lec_5_11.jpg\" loading=\"lazy\"></p>\n<p><strong>Next state and input&#x2F;output based criteria</strong></p>\n<p>Highest Priority:</p>\n<p>Same input and same next state should be encoded adjacently.</p>\n<p><img src=\"/../images/digital/lec_5_14.jpg\" loading=\"lazy\"></p>\n<p>Medium Priority:</p>\n<p>Next states of the same state should have adjacent<br>encoding.</p>\n<p><img src=\"/../images/digital/lec_5_12.jpg\" loading=\"lazy\"></p>\n<p>Lowest Priority:</p>\n<p>States with the same output should have adjacent<br>encoding.</p>\n<p><img src=\"/../images/digital/lec_5_13.jpg\" loading=\"lazy\"></p>\n<p><strong>Step 5 Get Excitation and Output Equations</strong></p>\n<p><img src=\"/../images/digital/lec_5_15.jpg\" loading=\"lazy\"></p>\n<p><strong>Step 6 Draw Logic Circuit Diagram</strong></p>\n<h3 id=\"Typical-Sequential-Logic-Circuits\"><a href=\"#Typical-Sequential-Logic-Circuits\" class=\"headerlink\" title=\"Typical Sequential Logic Circuits\"></a>Typical Sequential Logic Circuits</h3><p>Register &amp; Counter</p>\n<p><strong>Register</strong></p>\n<p>Shift register. Serial&#x2F;Parallel Input, Serial&#x2F;Parallel Output.</p>\n<p><img src=\"/../images/digital/lec_5_17.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_16.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_18.jpg\" loading=\"lazy\"></p>\n<p><strong>Counter</strong></p>\n<p><strong>UP&#x2F;Down Counter</strong></p>\n<p><img src=\"/../images/digital/lec_5_19.jpg\" loading=\"lazy\"></p>\n<p><strong>Specific-base Counter</strong></p>\n<p>000→010→011→101→110→000</p>\n<p><img src=\"/../images/digital/lec_5_20.jpg\" loading=\"lazy\"></p>\n<p><strong>Self-Starting problem of counter</strong></p>\n<p>Abnormal state(001, 100, 111)</p>\n<p><img src=\"/../images/digital/lec_5_21.jpg\" loading=\"lazy\"></p>\n<p><strong>Ring counter &amp; twisted ring counter</strong></p>\n<p><img src=\"/../images/digital/lec_5_22.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_23.jpg\" loading=\"lazy\"></p>\n<p><strong>Async &amp; snyc Counter</strong></p>\n<p><img src=\"/../images/digital/lec_5_24.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_25.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_5_26.jpg\" loading=\"lazy\"></p>\n<h2 id=\"Instruction-Set-Architecture\"><a href=\"#Instruction-Set-Architecture\" class=\"headerlink\" title=\"Instruction Set Architecture\"></a>Instruction Set Architecture</h2><h3 id=\"Introduction-1\"><a href=\"#Introduction-1\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><h4 id=\"Implement-Algorithm-In-Hardware\"><a href=\"#Implement-Algorithm-In-Hardware\" class=\"headerlink\" title=\"Implement Algorithm In Hardware\"></a>Implement Algorithm In Hardware</h4><p><img src=\"/../images/digital/lec_6_1.jpg\" loading=\"lazy\"></p>\n<p>Three steps: </p>\n<ul>\n<li>Instruction fetch</li>\n<li>Instruction decoding</li>\n<li>Instruction execution &amp; data write-back</li>\n</ul>\n<p><strong>Program Counter(PC)</strong></p>\n<p>Current Instruction Address</p>\n<p>Updated Every Cycle</p>\n<p><strong>Arithmetic&#x2F;Logic Instructions</strong></p>\n<p>Arithmetic Logic Unit(ALU)</p>\n<p>REG to REG, NOT Directly access data memory</p>\n<p><strong>Branch&#x2F;Jump Instructions</strong></p>\n<p>Branch After Comparison</p>\n<p>Jump Directly</p>\n<p><strong>Load&#x2F;Store Instructions</strong></p>\n<p>Load Data: data memory to REG</p>\n<p>Store Data: REG to data memory</p>\n<h4 id=\"General-Purpose-Processore-Structure\"><a href=\"#General-Purpose-Processore-Structure\" class=\"headerlink\" title=\"General Purpose Processore Structure\"></a>General Purpose Processore Structure</h4><p><strong>Turing Machine</strong></p>\n<p>2 Turing Machine Models: </p>\n<ul>\n<li>Princeton architecture</li>\n<li>Harvard architecture</li>\n</ul>\n<p><img src=\"/../images/digital/lec_6_2.jpg\" loading=\"lazy\"></p>\n<h4 id=\"Program-FLow\"><a href=\"#Program-FLow\" class=\"headerlink\" title=\"Program FLow\"></a>Program FLow</h4><p><img src=\"/../images/digital/lec_6_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_6_4.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Instruction-Set-Design\"><a href=\"#Instruction-Set-Design\" class=\"headerlink\" title=\"Instruction Set Design\"></a>Instruction Set Design</h3><p>Instruction set is the bridge between software &amp; generall-purpose (GP) CPU.</p>\n<p><strong>Performance Evaluate</strong></p>\n<div>$$\n\\text{Performance} = \\frac{1}{\\text{Execution Time}}\n$$</div>\n\n<p>Task Execution Time By CPU:</p>\n<div>$$\n\\text{Total Time} = \\text{Waiting for I/O} + \\text{Execution Time}\\\\\n\\text{Execution Time} = \\text{Cycle }\\# \\times \\text{Clock Cycle }T = \\frac{\\text{Cycle }\\# }{\\text{Clock }f} \n$$</div>\n\n<div>$$\n\\text{Cycle } \\# = \\text{Progream Instruction }\\# \\times \\text{Average Cycle } \\# \\text{ for one inst.}\n$$</div>\n\n<p>Average Cycle # for one instruction is also known as the cycle per instruction (CPI)</p>\n<p>So, </p>\n<div>$$\n\\text{Execution Time} = \\text{Instruction }\\# \\times \\text{CPI} \\times \\text{Clock Cycle }\n$$</div>\n\n<p><strong>CPI</strong></p>\n<div>$$\n\\text{CPI} = \\sum_{i = 1}^n \\text{CPI}_i \\times \\text{P}_i\n$$</div>\n\n<p>Where $\\text{P}_i$ is the i-th instruction occurrence frequency, and $\\text{CPI}_i$ is the clock cycle # of the i-th instruction.</p>\n<p><strong>Factors that affect Performance</strong></p>\n<ul>\n<li>Instruction # </li>\n<li><ul>\n<li>ISA, regardless of its specific implementation</li>\n</ul>\n</li>\n<li><ul>\n<li>Compiler</li>\n</ul>\n</li>\n<li>CPI</li>\n<li><ul>\n<li>Memory System and Processor Architecture</li>\n</ul>\n</li>\n<li><ul>\n<li>The Instruction Composition In the Program</li>\n</ul>\n</li>\n<li><ul>\n<li>Compiler</li>\n</ul>\n</li>\n<li>Clock Cycle</li>\n<li><ul>\n<li>Machine implementation details</li>\n</ul>\n</li>\n<li><ul>\n<li>Memory System and Processor Architecture</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/../images/digital/lec_6_5.jpg\" loading=\"lazy\"></p>\n<p><strong>Data Access</strong></p>\n<p><img src=\"/../images/digital/lec_6_6.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_6_7.jpg\" loading=\"lazy\"></p>\n<p><strong>Set Design</strong></p>\n<p>RISC &amp; CISC</p>\n<p><img src=\"/../images/digital/lec_6_8.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_6_9.jpg\" loading=\"lazy\"></p>\n<p><strong>Five Questions</strong></p>\n<ul>\n<li>How to make use of 11 extra bits in arithmetic operations?</li>\n<li>How to use 16 bits to represent 32-bit address for branch?</li>\n<li>How to encode branch instruction with immediate?</li>\n<li>How to use 21 bits to represent 32-bit address for memory address?</li>\n<li>How to use 26 bits to represent 32-bit address for jump?</li>\n</ul>\n<h3 id=\"MIPS-Instruction-Set\"><a href=\"#MIPS-Instruction-Set\" class=\"headerlink\" title=\"MIPS Instruction Set\"></a>MIPS Instruction Set</h3><h4 id=\"Instruction-Storage-and-Data-Storage\"><a href=\"#Instruction-Storage-and-Data-Storage\" class=\"headerlink\" title=\"Instruction Storage and Data Storage\"></a>Instruction Storage and Data Storage</h4><p>32-bits instruction length, and 32 general-purpose registers.</p>\n<p>First 6 bits are opcode.</p>\n<p><strong>Register</strong></p>\n<p><img src=\"/../images/digital/lec_7_9.jpg\" loading=\"lazy\"></p>\n<p>the register index is limited to 5 bits.</p>\n<h4 id=\"Instruction-Type-R-I-J\"><a href=\"#Instruction-Type-R-I-J\" class=\"headerlink\" title=\"Instruction Type(R, I, J)\"></a>Instruction Type(R, I, J)</h4><p><strong>Type: R</strong></p>\n<p><strong>Field Division and detailed definition</strong></p>\n<p><img src=\"/../images/digital/lec_7_1.jpg\" loading=\"lazy\"></p>\n<p>Q1: Can we make use of the extra 11 bits?</p>\n<p><img src=\"/../images/digital/lec_7_13.jpg\" loading=\"lazy\"></p>\n<p><strong>Type: I</strong></p>\n<p>It’s immediate.</p>\n<p><img src=\"/../images/digital/lec_7_5.jpg\" loading=\"lazy\"></p>\n<p>2 cases:</p>\n<p><img src=\"/../images/digital/lec_7_2.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_7_3.jpg\" loading=\"lazy\"></p>\n<p>Q2:The possible address range covers 32 bits. How to represent the address with limited 16 bits for branch?</p>\n<p>base + offset</p>\n<p><img src=\"/../images/digital/lec_7_10.jpg\" loading=\"lazy\"></p>\n<p>Q3: How to encode the branch with immediate?</p>\n<p>No direct instructions for this.</p>\n<p>We use compare instruction and branch instruction to achieve this.</p>\n<p>Q4: The possible address range covers 32 bits. How to represent the address with limited 21 bits for memory access?</p>\n<p>base + offset</p>\n<p><img src=\"/../images/digital/lec_7_4.jpg\" loading=\"lazy\"></p>\n<p><strong>Type: J</strong></p>\n<p><img src=\"/../images/digital/lec_7_6.jpg\" loading=\"lazy\"></p>\n<p>Q5: The possible address range covers 32 bits. How to represent<br>the address with limited 26 bits for jump?</p>\n<p>3 types of jump operation: <code>j</code>, <code>jal</code> and <code>jr</code>.</p>\n<p><img src=\"/../images/digital/lec_7_7.jpg\" loading=\"lazy\"></p>\n<p><strong>Summary</strong></p>\n<p><img src=\"/../images/digital/lec_7_.jpg\" loading=\"lazy\"></p>\n<h4 id=\"Addressing-mode\"><a href=\"#Addressing-mode\" class=\"headerlink\" title=\"Addressing mode\"></a>Addressing mode</h4><p>5 modes:</p>\n<ul>\n<li>Register addressing</li>\n<li>Immediate addressing</li>\n<li>Base (base-offset) addressing</li>\n<li>PC-related addressing</li>\n<li>Pseudo-direct addressing</li>\n</ul>\n<p><strong>Register addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_11.jpg\" loading=\"lazy\"></p>\n<p><strong>Immediate addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_12.jpg\" loading=\"lazy\"></p>\n<p>How to load a 32-bit constant to $s0?</p>\n<p><img src=\"/../images/digital/lec_7_14.jpg\" loading=\"lazy\"></p>\n<p><strong>Base-offset addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_15.jpg\" loading=\"lazy\"></p>\n<p><strong>PC-related addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_16.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_7_17.jpg\" loading=\"lazy\"></p>\n<p><strong>Pseudo-direct addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_18.jpg\" loading=\"lazy\"></p>\n<p>It is faster because no add operation needed, comparing to <code>PC_new = &#123;PC_old + address &lt;&lt; 2&#125;</code>.</p>\n<p><strong>Summary</strong></p>\n<p><img src=\"/../images/digital/lec_7_19.jpg\" loading=\"lazy\"></p>\n<h4 id=\"Instruciton-System\"><a href=\"#Instruciton-System\" class=\"headerlink\" title=\"Instruciton System\"></a>Instruciton System</h4><p><strong>Arithmetic</strong></p>\n<p>Add  <code>add $t0, $t1, $t2      #$t0=$t1+$t2</code></p>\n<p>Add immediate <code>addi $t2, $t3, 5  #$t2=$t3+5</code></p>\n<p>Subtract <code>sub $t2,$t3,$t4 #$t2=$t3-$t4</code></p>\n<p>NO subtract-an-immediate instruction! We use 2’s complement immediate in the <code>addi</code>.</p>\n<p><strong>Logic</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">and $t0, $t1, $t2</span><br><span class=\"line\">or $t0, $t1, $t2</span><br><span class=\"line\">xor $t0, $t1, $t2</span><br><span class=\"line\">nor $t0, $t1, $t2</span><br></pre></td></tr></table></figure>\n\n<p>No NOT instruction. We set <code>$t1</code> or <code>$t2</code> to 0 and use NOR.</p>\n<p>With immediate:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">andi $t0, $t1, 10</span><br><span class=\"line\">ori $t0, $t1, 10</span><br><span class=\"line\">xori $t0, $t1, 10</span><br></pre></td></tr></table></figure>\n\n<p><strong>Shift</strong></p>\n<p>Immediate-amount shift:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sll $t0, $t1, 10</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; 10, logical</span><br><span class=\"line\">srl $t0, $t1, 10</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; 10, logical</span><br><span class=\"line\">sra $t0, $t1, 10</span><br><span class=\"line\"># $t0 = $t1 &gt;&gt; 10, arithmetic, depending on the sign bit</span><br></pre></td></tr></table></figure>\n\n<p>Register-amonut shift: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sllv $t0, $t1, $t3</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; ($t3%32), logical</span><br><span class=\"line\">srl $t0, $t1, $t3</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; ($t3%32), logical</span><br><span class=\"line\">sra $t0, $t1, $t3</span><br><span class=\"line\"># $t0 = $t1 &gt;&gt; ($t3%32), arithmetic, depending on the sign bit</span><br></pre></td></tr></table></figure>\n\n<p><strong>Compare instruction</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slt $t1, $t2, $t3</span><br><span class=\"line\"># if ($t2 &lt; $t3) $t1=1;</span><br><span class=\"line\"># else $t1=0</span><br><span class=\"line\">sltu $t1, $t2, $t3</span><br><span class=\"line\"># unsigned comparison</span><br></pre></td></tr></table></figure>\n\n<p>With immediate:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slti $t1, $t2, 10</span><br><span class=\"line\">sltui $t1, $t2, 10</span><br></pre></td></tr></table></figure>\n\n<p><strong>About i, u, iu</strong></p>\n<p><img src=\"/../images/digital/lec_7_20.jpg\" loading=\"lazy\"></p>\n<p><strong>Load&#x2F;Store Instruction</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lw $t1, 32($t2)</span><br><span class=\"line\">sw $t3, 500($t4)</span><br></pre></td></tr></table></figure>\n\n<p>Register stores base address is called base register,<br>Constant in the instruction is called offset.</p>\n<p><strong>Branch instruction</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">beq $t0, $t1, target</span><br><span class=\"line\">#if $t0=$t1, then execute</span><br><span class=\"line\">#instruction target</span><br><span class=\"line\">bne $t0, $t1, target</span><br><span class=\"line\"># if $t0!=$t1, then execute</span><br><span class=\"line\"># instruction target</span><br></pre></td></tr></table></figure>\n\n<p>More than this 2 instructions.</p>\n<p><strong>Jump instruction</strong></p>\n<p>Unconditional branch</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">j label</span><br><span class=\"line\">#unconditionally jump to label</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Procedure-Call\"><a href=\"#Procedure-Call\" class=\"headerlink\" title=\"Procedure Call\"></a>Procedure Call</h4><p><img src=\"/../images/digital/lec_7_21.jpg\" loading=\"lazy\"></p>\n<p>MIPS uses registers for argument and return data&#x2F;address.</p>\n<p>Argument registers: <code>$a0-$a3</code></p>\n<p>Return value registers: <code>$v0-$v1</code></p>\n<p>Retuen address register: <code>$ra</code></p>\n<p><code>jal Procedure #Procedure call jr $ra #Procedure return</code></p>\n<p><code>jal</code> and <code>j</code> are both J-type, but <code>jal</code> will store the return address.</p>\n<p><code>jr</code> is R-type, will jump to the address restored in the register, so it can jump very far.</p>\n<p><strong>Maintain the register data</strong></p>\n<p>2 types:</p>\n<ul>\n<li>Temporaries data registers</li>\n<li>Saved data registers</li>\n</ul>\n<p><img src=\"/../images/digital/lec_7_22.jpg\" loading=\"lazy\"></p>\n<p>Who saves the register data?</p>\n<p>Caller(temp) or Callee(save)</p>\n<p><img src=\"/../images/digital/lec_7_23.jpg\" loading=\"lazy\"></p>\n<p>We use Stack to maintain the register data.</p>\n<p><img src=\"/../images/digital/lec_7_24.jpg\" loading=\"lazy\"></p>\n<p><strong>Stack Operation with $sp</strong></p>\n<p>e.g. <code>push $s1, $s2 , $s3</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">addi $sp, $sp, -12</span><br><span class=\"line\">sw $s1, 8($sp)</span><br><span class=\"line\">sw $s2, 4($sp)</span><br><span class=\"line\">sw $s3, 0($sp)</span><br></pre></td></tr></table></figure>\n<p><code>pop $s1, $s2, $s3</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lw $s1, 0($sp)</span><br><span class=\"line\">lw $s2, 4($sp)</span><br><span class=\"line\">lw $s3, 8($sp)</span><br><span class=\"line\">addi, $sp, $sp, 12</span><br></pre></td></tr></table></figure>\n\n<p><strong>Leaf Procedures</strong></p>\n<p>Procedures that do not call others are called <em>leaf</em> procedures.</p>\n<p><strong>Nested Procedures</strong></p>\n<p>Nested(Recursive) Procedures are procedures that invoke “clones” of themselves.</p>\n<p>e.g.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">fact</span> <span class=\"params\">(<span class=\"type\">int</span> n)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (n &lt; <span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> (n * fact(n - <span class=\"number\">1</span>));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fact:</span><br><span class=\"line\">    addi    $sp, $sp, -8</span><br><span class=\"line\">    sw      $ra, 4($sp)</span><br><span class=\"line\">    sw      $a0, 0($sp)</span><br><span class=\"line\">    slti    $t0, $a0, 1</span><br><span class=\"line\">    beq     $t0, $zero, L1</span><br><span class=\"line\">    addi    $v0, $zero, 1</span><br><span class=\"line\">    addi    $sp, $sp, 8</span><br><span class=\"line\">    jr      $ra</span><br><span class=\"line\">L1:</span><br><span class=\"line\">    addi    $a0, $a0, -1</span><br><span class=\"line\">    jal     fact</span><br><span class=\"line\">    lw      $a0, 0($sp)</span><br><span class=\"line\">    lw      $ra, 4($sp)</span><br><span class=\"line\">    addi    $sp, $sp, 8</span><br><span class=\"line\">    mul     $v0, $a0, $v0</span><br><span class=\"line\">    jr      $ra</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Single-Cycle-Processor\"><a href=\"#Single-Cycle-Processor\" class=\"headerlink\" title=\"Single-Cycle Processor\"></a>Single-Cycle Processor</h2><p><img src=\"/../images/digital/lec_8_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_2.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_5.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_6.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_7.jpg\" loading=\"lazy\"></p>\n<p><strong>Load Operation Takes MUCH LONGER!!!</strong></p>\n<h2 id=\"Multi-Cycle-Processor\"><a href=\"#Multi-Cycle-Processor\" class=\"headerlink\" title=\"Multi-Cycle Processor\"></a>Multi-Cycle Processor</h2><p><img src=\"/../images/digital/lec_8_8.jpg\" loading=\"lazy\"></p>\n<p>The Multicycle processor processes different inst. in different cycles. Thus, it can avoid the time limitation by the slow instruction.</p>\n<p>Modules on th datapath can be used multiple times within an inst. That is <strong>Module reuse</strong>.</p>\n<p>Performance improvement depends on the detailed delay. The multicycle is not necessarily faster than the single cycle.</p>\n<p><img src=\"/../images/digital/lec_8_9.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_10.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_11.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_12.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_13.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_14.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_15.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_16.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_17.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_18.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_19.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_20.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_21.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_30.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_31.jpg\" loading=\"lazy\"></p>\n<h2 id=\"Exception-and-Interrupt\"><a href=\"#Exception-and-Interrupt\" class=\"headerlink\" title=\"Exception and Interrupt\"></a>Exception and Interrupt</h2><p><img src=\"/../images/digital/lec_8_22.jpg\" loading=\"lazy\"></p>\n<p>Generally, exceptions and interrupts are events that can change the normal instruction execution flow (other than branches and jumps).</p>\n<p>Exception<br>– Internal unpredictable events such as overflow.</p>\n<p>Interrupt<br>– External unpredictable events such as I&#x2F;O.</p>\n<p><img src=\"/../images/digital/lec_8_23.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_24.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_25.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_26.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_27.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_28.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_8_29.jpg\" loading=\"lazy\"></p>\n<h2 id=\"Pipelined-processor\"><a href=\"#Pipelined-processor\" class=\"headerlink\" title=\"Pipelined processor\"></a>Pipelined processor</h2><p><img src=\"/../images/digital/lec_9_1.jpg\" loading=\"lazy\"></p>\n<p>Pipeline means spatial and temporal reuse.</p>\n<p>Divide a complex task into several sub-tasks to<br>execute sequentially, and assign each sub-task to<br>dedicated hardware</p>\n<p>Different sub-tasks of multiple tasks can be<br>processed simultaneously to improve the<br>performance</p>\n<p>• Time-division multiplexing: the same resource is reused through<br>different cycles</p>\n<p>• Space-division multiplexing: multiple resources are reused<br>within one cycle</p>\n<p>Pros: improved efficiency</p>\n<p>Cons: Some inst. depends on the former inst.. However, the former inst. has not finished yet, if the prediction of branch is wrong, time is wasted.</p>\n<p>Instruction-Level Parallelism (ILP)</p>\n<p>– Execute multiple instructions in parallel</p>\n<p>– One mainstream approach to CPU performance improvement</p>\n<p>Basic Techniques</p>\n<p>– Pipelining: instruction execution is divided into several stages, and<br>each stage can be processed with the other stages (of other<br>instructions) simultaneously</p>\n<p>– Superscalar: multiple dedicated functional units are equipped so<br>that CPU can receive &amp; execute more instructions within one cycle.</p>\n<p>– Very Long Instruction Word (VLIW): each instruction consists of<br>multiple segments to utilize the processor resources independently.</p>\n<p>5 stages in MIPS:</p>\n<ol>\n<li>Instruction Fetch (IF)</li>\n<li>Instruction Decode &#x2F; Register File</li>\n<li>ALU Execution(EX)</li>\n<li>Memory Data Access(MEM)</li>\n<li>Reg Write-Back(WB)</li>\n</ol>\n<p>Latency of the stages in the pipeline should<br>be as equivalent as possible, why?<br>–The pipeline performance is bottlenecked by the stage<br>of the longest latency</p>\n<p><strong>Metrics of pipelined processors</strong></p>\n<ul>\n<li>Throughput(TP): Executed instruction # per unit time</li>\n<li>Max throughput: The throughput of a steady-state pipeline with a continuous instruction input stream</li>\n<li>Real throughput: The throughput of the pipeline executing task with finite instructions</li>\n</ul>\n<p>Real TP:</p>\n<div>$$\nTP = \\frac n {T_k} = \\frac{n}{(n+k-1)\\Delta t}\n$$</div>\n\n<p>Max TP:</p>\n<div>$$\nTP_{max} = \\lim_{n\\rightarrow\\infty}\\frac{n}{(n+k-1)\\Delta t} = \\frac{1}{\\Delta t}\n$$</div>\n\n<p><strong>Speed up</strong> Execution time ratio between w&#x2F;o or w&#x2F; pipelining.</p>\n<p>$T_0$: execution time without pipelining</p>\n<p>$T_k$: execution time with k-stage pipelining(assume each stage has the same latency)</p>\n<div>$$\n\\frac{T_0}{T_k}\n$$</div>\n\n<p>Real speedup:</p>\n<div>$$\nS = \\frac{nk\\Delta t}{(n + k - 1)\\Delta t} = \\frac{kn}{n + k - 1}\n$$</div>\n\n<p>Max speedup:</p>\n<div>$$\nS_{max} = \\lim_{n\\rightarrow \\infty}\\frac{kn}{k + n - 1} = k\n$$</div>\n\n<p><strong>Pipelined datapath</strong></p>\n<p><img src=\"/../images/digital/lec_9_3.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_9_4.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_9_5.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_9_6.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_9_7.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_9_8.jpg\" loading=\"lazy\"></p>\n<p>Many inst. doesnt need MEM stage, but the stage can’t be skipped, since it may “collide” with the previous inst.</p>\n<p>Q: How to get the control signals in each stage?</p>\n<p>Control signals are generated at ID&#x2F;RF stage.</p>\n<p>Control signals flow in the pipeline: use when needed; reserve when subsequent stages needed; discard when not needed any more.</p>\n<p><img src=\"/../images/digital/lec_9_10.jpg\" loading=\"lazy\"></p>\n<p>Why RegDst Doesnt needed in the stages after EX?</p>\n<p>The RegDst is used to select the destination register. However, the destination register is determined in the EX stage. Thus, RegDst is not needed in the stages after EX.</p>\n<p>Sometimes this can cause trouble:</p>\n<figure class=\"highlight mips\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">LW </span>R2, R9(<span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"keyword\">ADD </span>R4, R3, R2</span><br><span class=\"line\"><span class=\"keyword\">ADD </span>R6, R5, R4</span><br></pre></td></tr></table></figure>\n\n<p>The R4 is accessed before it updates.</p>\n<h3 id=\"Hazard-in-the-pipeline\"><a href=\"#Hazard-in-the-pipeline\" class=\"headerlink\" title=\"Hazard in the pipeline\"></a>Hazard in the pipeline</h3><p><strong>Structural Hazards</strong></p>\n<p>Two instructions acquire the same hardware resource simultaneously.</p>\n<p><img src=\"/../images/digital/lec_9_11.jpg\" loading=\"lazy\"></p>\n<p>Solution:</p>\n<ol>\n<li>Add resources: separating PC+4 from ALU; Harvard architecture</li>\n<li>Adjust stages: add MEM</li>\n</ol>\n<p><img src=\"/../images/digital/lec_9_15.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_9_12.jpg\" loading=\"lazy\"></p>\n<p>MIPS is born to be  pipelined: the problem of structural hazard is solved by the structure of MIPS.</p>\n<p><strong>Data Hazards</strong></p>\n<p><img src=\"/../images/digital/lec_9_13.jpg\" loading=\"lazy\"></p>\n<p>2 solutions:</p>\n<p><strong>Stalling</strong></p>\n<p><img src=\"/../images/ss/lec21_8.jpg\" loading=\"lazy\"></p>\n<p><strong>Forwarding(Bypassing)</strong></p>\n<p><img src=\"/../images/ss/lec21_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/ss/lec21_2.jpg\" loading=\"lazy\"></p>\n<p>But, load uses hazard emerges:</p>\n<p><img src=\"/../images/ss/lec21_8.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_10_1.jpg\" loading=\"lazy\"></p>\n<p>Still, a nop needed to stall the pipeline.</p>\n<p><img src=\"/../images/digital/lec_10_2.jpg\" loading=\"lazy\"></p>\n<p>Is there any possibility to eliminate the stall?</p>\n<p>Yes, if the MIPS code can be optimized.</p>\n<p><img src=\"/../images/digital/lec_10_3.jpg\" loading=\"lazy\"></p>\n<p><strong>Control Hazards</strong></p>\n<p><img src=\"/../images/digital/lec_9_14.jpg\" loading=\"lazy\"></p>\n<p><strong>Stalling</strong></p>\n<p><img src=\"/../images/digital/lec_10_4.jpg\" loading=\"lazy\"></p>\n<p><strong>Forwarding</strong></p>\n<p><img src=\"/../images/digital/lec_10_5.jpg\" loading=\"lazy\"></p>\n<p>If Move the branch decision to ID stage:</p>\n<p><img src=\"/../images/digital/lec_10_6.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_10_7.jpg\" loading=\"lazy\"></p>\n<p><strong>Delay slot</strong></p>\n<p><img src=\"/../images/digital/lec_10_8.jpg\" loading=\"lazy\"></p>\n<p><strong>Prediction</strong></p>\n<p>Static Branch Prediction</p>\n<p><img src=\"/../images/digital/lec_10_9.jpg\" loading=\"lazy\"></p>\n<p>Cancel the effect caused by false prediction.</p>\n<p>Dynamic Branch Prediction</p>\n<ul>\n<li>History-based dynamic prediction</li>\n<li>Using runtime behaviour to predict future branches</li>\n</ul>\n<p>At IF stage, there are Branch History Table(BHT) and Branch Target Buffer(BTB).</p>\n<p>beq at IF stage</p>\n<p>• Look up if the instruction address is in BHT and BTB.</p>\n<p>• If not in, create a new entry. If in, check whether the<br>branch is taken at the last time. If taken, send the target<br>address to PC as the next address for IF.</p>\n<p>–beq at ID stage</p>\n<p>• IF stage will fetch instruction based on the predicted<br>target address</p>\n<h3 id=\"Implementation-of-the-Pipiline\"><a href=\"#Implementation-of-the-Pipiline\" class=\"headerlink\" title=\"Implementation of the Pipiline\"></a>Implementation of the Pipiline</h3><p><img src=\"/../images/digital/lec_10_10.jpg\" loading=\"lazy\"></p>\n<p><strong>Data hazard</strong></p>\n<p>Forwarding</p>\n<p>EX&#x2F;MEM hazard</p>\n<figure class=\"highlight verilog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (EX/MEM<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRs</span>))</span><br><span class=\"line\">    ForwardA = <span class=\"number\">10</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (EX/MEM<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRt</span>))</span><br><span class=\"line\">    ForwardB = <span class=\"number\">10</span></span><br></pre></td></tr></table></figure>\n\n<p>MEM&#x2F;WB hazard</p>\n<figure class=\"highlight verilog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (MEM/WB<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRs</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != ID/EX<span class=\"variable\">.RegisterRs</span> || ~ EX/MEM<span class=\"variable\">.RegWrite</span>))</span><br><span class=\"line\">    ForwardA = <span class=\"number\">01</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (MEM/WB<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRt</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != ID/EX<span class=\"variable\">.RegisterRt</span> || ~ EX/MEM<span class=\"variable\">.RegWrite</span>))</span><br><span class=\"line\">    ForwardB = <span class=\"number\">01</span></span><br></pre></td></tr></table></figure>\n\n<p>load-use hazard</p>\n<p>We have to stall the pipeline for one cycle.</p>\n<p>Condition: <code>if (ID/EX.MemRead and ((ID/EX.RegisterRt == IF/ID.RegisterRs) or  (ID/EX.RegisterRt == IF/ID.RegisterRt)))</code></p>\n<p>How to stall?</p>\n<p>Stall &amp; flush</p>\n<p>PC &amp; ID&#x2F;IF: stall(Keep the control signals)</p>\n<p>EX &amp; MEM &amp; WB: flush(Set the control signals to 0)</p>\n<p>Control signals:</p>\n<p>EX: RegDst, ALUOp1, ALUOp0, ALUSrc</p>\n<p>MEM: Branch, MemRead, MemWrite</p>\n<p>WB: MemToReg, RegWrite</p>\n<figure class=\"highlight verilog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> &#123;ID/EX<span class=\"variable\">.MemRead</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> ((ID/EX<span class=\"variable\">.RegisterRt</span> = IF/ID<span class=\"variable\">.RegisterRs</span>)</span><br><span class=\"line\"><span class=\"keyword\">or</span> (ID/EX<span class=\"variable\">.RegisterRt</span> = IF/ID<span class=\"variable\">.RegisterRt</span>))&#125;</span><br><span class=\"line\">    Keep IF/ID; Keep PC; Flush ID/EX;</span><br></pre></td></tr></table></figure>\n\n<p>Special Case:</p>\n<p>Memory-to-memory copy</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lw $1, 10($2)</span><br><span class=\"line\">sw $1, 10($3)</span><br></pre></td></tr></table></figure>\n\n<p>The stall is unnecessary. We can use forwarding to solve the problem.</p>\n<p><strong>Control Hazard</strong></p>\n<p>BEQ &amp; J need 1 stall cycle.</p>\n<p>Control hazards are not as frequent as data<br>hazards, but they are harder to be resolved<br>effectively as forwarding.</p>\n<p>Another type of control hazard: exceptions and interrupts.</p>\n<p>– “Exception” includes any unpredictable events that<br>can change the normal control flow, which has no<br>distinction between internal and external. </p>\n<p>– “Interrupt” is only used for external events.</p>\n<p><img src=\"/../images/digital/lec_12_1.jpg\" loading=\"lazy\"></p>\n<h2 id=\"Advanced-techniques-for-processor\"><a href=\"#Advanced-techniques-for-processor\" class=\"headerlink\" title=\"Advanced techniques for processor\"></a>Advanced techniques for processor</h2><h3 id=\"Instruction-level-parallelism\"><a href=\"#Instruction-level-parallelism\" class=\"headerlink\" title=\"Instruction-level parallelism\"></a>Instruction-level parallelism</h3><p>Superpipelining: a deeper pipeline</p>\n<p>VLIW</p>\n<p>Multiple-issue: a wider pipeline</p>\n<p>Superscalar</p>\n<p><img src=\"/../images/digital/lec_12_2.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Thread-level-parallelism\"><a href=\"#Thread-level-parallelism\" class=\"headerlink\" title=\"Thread-level parallelism\"></a>Thread-level parallelism</h3><p>Hyper-threading</p>\n<p><img src=\"/../images/digital/lec_12_3.jpg\" loading=\"lazy\"></p>\n<p>Multicore</p>\n<h3 id=\"Heterogeneous-computing\"><a href=\"#Heterogeneous-computing\" class=\"headerlink\" title=\"Heterogeneous computing\"></a>Heterogeneous computing</h3><p>GPU</p>\n<p>XPU</p>\n<h2 id=\"Memory\"><a href=\"#Memory\" class=\"headerlink\" title=\"Memory\"></a>Memory</h2><h3 id=\"Basics\"><a href=\"#Basics\" class=\"headerlink\" title=\"Basics\"></a>Basics</h3><p>SRAM cell</p>\n<p>High speed, low density &amp; expensive</p>\n<p><img src=\"/../images/digital/lec_12_4.jpg\" loading=\"lazy\"></p>\n<p>DRAM cell</p>\n<p>Low speed, high density &amp; cheap. The charge in capacitor may leak, so the data cannot be stored for a long time.</p>\n<p><img src=\"/../images/digital/lec_12_5.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/digital/lec_12_6.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Evaluation\"><a href=\"#Evaluation\" class=\"headerlink\" title=\"Evaluation\"></a>Evaluation</h3><p>3C model:</p>\n<p><strong>Compulsory miss</strong> first access to a block</p>\n<p><strong>Capacity miss</strong> all lines in cache are used</p>\n<p><strong>Conflict miss(collision miss)</strong> not fully filled, but the blocks # &gt; available ways #.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h2 id=\"Boolean-Algebra\"><a href=\"#Boolean-Algebra\" class=\"headerlink\" title=\"Boolean Algebra\"></a>Boolean Algebra</h2><h3 id=\"The-Number-System\"><a href=\"#The-Number-System\" class=\"headerlink\" title=\"The Number System\"></a>The Number System</h3><h4 id=\"BCD\"><a href=\"#BCD\" class=\"headerlink\" title=\"BCD\"></a>BCD</h4><p>BCD (Binary-Coded Decimal)</p>\n<p>Classic method: 8421BCD.</p>\n<p>add calculation:</p>\n<p>the problem of carry:</p>\n<div>$$\n(14)_D+(28)_D=(0001\\ 0100)_{BCD} + (0100\\ 0100)_{BCD}\\\\\n=(0101\\ 1100)_{BCD}=(0110\\ 0010)_{BCD}\n$$</div>\n\n<h4 id=\"Gray-Code\"><a href=\"#Gray-Code\" class=\"headerlink\" title=\"Gray Code\"></a>Gray Code</h4><p>used in logic simplification and signal transmission.</p>\n<p>every time a single bit is changed.</p>\n<h4 id=\"Floating-poing-Number\"><a href=\"#Floating-poing-Number\" class=\"headerlink\" title=\"Floating poing Number\"></a>Floating poing Number</h4><h4 id=\"Negative-numbers\"><a href=\"#Negative-numbers\" class=\"headerlink\" title=\"Negative numbers\"></a>Negative numbers</h4><p><strong>Complement Numeric System</strong></p>\n<p>1’s Complement: $N_{1’s} + (-N)<em>{1’s} &#x3D; (111…)</em>{1’s}$, or just inverting every bit of N. Low space efficiency and difficult to compute.</p>\n<p>2’s Complement: $N_{2’s} + (-N)<em>{2’s} &#x3D; (000…)</em>{2’s}$, or just inverting every bit of N and plus 1. A shift on 1’s Complement.</p>\n<p>MSB&#x3D;Most significant bit, LSB&#x3D;Least significant bit.</p>\n<div>$$\n-N=N_{us}-2^n=\\sum_{i=0}^{n-1}k_i2^i-2^n=-k_{n-1}2^{n-1}+k_{n-2}2^{n-2}+\\dots k_02^0\n$$</div>\n\n<p>So just set the weight of MSB to $-2^{n-1}$.</p>\n<p>we ignore the bit beyond the range to make sure the answer is correct.</p>\n<div>$$\n(101)_{2's}+(001)_{2's}=(110)_{2's}\\\\\n(011)_{2's}-(001)_{2's}=(011)_{2's}+(111)_{2's}=(010)_{2's}\n$$</div>\nTo detect an overflow, we can notice if 2 positive numbers add up to a negative numbers or 2 negative numbers add up to a positive numbers.\n\n<p>We can fix overflow by adding 0 as MSB if the answer should be positive and adding 1 as MSB if the answer should be negative.</p>\n<h3 id=\"Boolean-expression\"><a href=\"#Boolean-expression\" class=\"headerlink\" title=\"Boolean expression\"></a>Boolean expression</h3><h4 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h4><div>$$\n+(\\text{OR/logic add}),\\cdot (\\text{AND/logic multiply}), \\prime(\\bar{})(\\text{NOT/logit NOT})\n$$</div>\n\n<h4 id=\"Boolean-function\"><a href=\"#Boolean-function\" class=\"headerlink\" title=\"Boolean function\"></a>Boolean function</h4><p><strong>Duality</strong></p>\n<p>AND&lt;-&gt;OR, 0&lt;-&gt;1, variables unchanged.</p>\n<div>$$\nF_1=F_2\\Leftrightarrow F_1^D=F_2^D\n$$</div>\n\n<p><strong>De Morgan’s Law</strong></p>\n<p>AND&lt;-&gt;OR, 0&lt;-&gt;1, <strong>X&lt;-&gt;X’</strong></p>\n<p><strong>Useful Theorem</strong></p>\n<p>X(Y+Z)&#x3D;XY+XZ</p>\n<p>XY+Z&#x3D;(X+Z)(Y+Z)</p>\n<p>X+XY&#x3D;X</p>\n<p>X(X+Y)&#x3D;X</p>\n<h3 id=\"Boolean-function-simplification\"><a href=\"#Boolean-function-simplification\" class=\"headerlink\" title=\"Boolean function simplification\"></a>Boolean function simplification</h3><h4 id=\"2-level-logic\"><a href=\"#2-level-logic\" class=\"headerlink\" title=\"2-level logic\"></a>2-level logic</h4><p><strong>Standard form</strong><br>SOP and POS</p>\n<p>Sum of Products or Products of Sum</p>\n<p><strong>Min-term</strong><br>A min-term is a product of all variables taken either in the direct or complemented form, each variable shown once.</p>\n<p>$A’B’C’&#x3D;m_0$ and $ABC&#x3D;M_7$</p>\n<p><strong>Max-term</strong> A max-term is a sum of all variables taken either in the direct or complemented form, each variable shown once.</p>\n<p>$A+B+C&#x3D;M_0$ and $A’+B’+C’&#x3D;M_7$</p>\n<div>$$\nm_6= \\overline{M_6}\n$$</div>\n\n<p><strong>Karnaugh Maps</strong></p>\n<p>Use row and columns to represent combinations of the inputs(by min-terms), the cell to represent the value. The inputs is ordered by the sequence of Grey Code.</p>\n<h4 id=\"Simplification-of-2-level-logic\"><a href=\"#Simplification-of-2-level-logic\" class=\"headerlink\" title=\"Simplification of 2-level logic\"></a>Simplification of 2-level logic</h4><p><strong>Karnaugh Maps method</strong></p>\n<p>If two adjacent min-terms deliver logic 1, merge them.</p>\n<p><strong>Implicant</strong></p>\n<div>$$\nG\\Rightarrow F, \\text{then }G\\text{ is the implicant of }F\\\\\nno\\ Q\\ s.t.P\\Rightarrow Q\\Rightarrow F, \\text{then }P \\text{ is the prime implicant of }F\\\\\n\\text{If one min-term can only be covered by one prime implicant, this prime implicant is an EPI.}\n$$</div>\n\n<p>EPI will finally exist there.</p>\n<p><strong>Q-M method</strong></p>\n<p>algorithm to simplify multiple-input large-scale function.</p>\n<h2 id=\"Combinational-Logic\"><a href=\"#Combinational-Logic\" class=\"headerlink\" title=\"Combinational Logic\"></a>Combinational Logic</h2><h3 id=\"Gate\"><a href=\"#Gate\" class=\"headerlink\" title=\"Gate\"></a>Gate</h3><p>NAND, NOT, NOR is better than AND, OR in saving area.</p>\n<p><strong>Transmission Gate</strong> Use both NMOS and PMOS to form a CMOS switch. NMOS is good at transmitting low volt while PMOS is better at working on high volt.</p>\n<p><strong>Tri-state Gate</strong> EN is high, TG on, F&#x3D;A; EN is low, TG off, F is isolated from input A. The states are called logic 0, logic 1 and high-resistance Z.</p>\n<p><img src=\"/../images/digital/lec_3_1.jpg\"></p>\n<p>The bottom part of the circuit is used to avoid the high-Z state.</p>\n<h3 id=\"Combinational-logic-circuits\"><a href=\"#Combinational-logic-circuits\" class=\"headerlink\" title=\"Combinational logic circuits\"></a>Combinational logic circuits</h3><p>Outputs are the function of logic input circuits.</p>\n<p>Determined only by current not past inputs + delay</p>\n<p>To deal with complex logic with many inputs, we should:</p>\n<ul>\n<li>From 2-level to multi-level(BDD?)</li>\n<li>Divide-and-conquer</li>\n<li>Re-using</li>\n</ul>\n<h4 id=\"Metrics\"><a href=\"#Metrics\" class=\"headerlink\" title=\"Metrics\"></a>Metrics</h4><p><strong>Static metrics</strong> Logic voltage values, DC noise margins, Area, Fan-out</p>\n<p><strong>Dynamic metrics</strong> Speed&#x2F;delay, Power dissipation, Noise(reference)</p>\n<p><strong>Speed</strong> rise time and fall time. Propagation time.</p>\n<p><strong>Fan out</strong> The maximum number of CMOS inputs that one logic output can drive.</p>\n<p><strong>Power and energy</strong> Leakage power(static power): subthreshold leakage power, gate leakage, D&#x2F;S subtrate leakage. We can reduce the static power:</p>\n<ul>\n<li>increase $|V_{TH}|$ </li>\n<li>or decrease $V_{DD}$.</li>\n</ul>\n<div>$$\nP_{total} = P_{dynamic} + P_{dynamic\\_short} + P_{leakage}\n$$</div>\n\n<p>Dynamic power $P_{dynamic_short}$ shows in pull-up and pull-down on.</p>\n<div>$$\nP = C_LV_{DD}^2\\underset{\\text{Flip Prob.}}{\\alpha_{0-1}}f\n$$</div>\n\n<p>To reduce dynamic power:</p>\n<ul>\n<li>Reduce VDD and Capacitors</li>\n<li>Reduce frequency, flipping probability.</li>\n</ul>\n<p>Energy-delay product is a metric. It’s hard to reduce.</p>\n<ul>\n<li>Low power can increase the lifetime of the chip.</li>\n<li>Low delay can increase the speed of the chip.</li>\n</ul>\n<h4 id=\"Hazard\"><a href=\"#Hazard\" class=\"headerlink\" title=\"Hazard\"></a>Hazard</h4><p><strong>static-1 hazard</strong> ‘1’ output has a transient ‘0’ glitch</p>\n<p><strong>static-0 hazard</strong> ‘1’ output has a transient ‘0’ glitch</p>\n<p><strong>dynamic hazard</strong> several transitions during a single output change(not required)</p>\n<p>If the initial input and final input cannot be covered by one PI, it may have a glitch as state transition.</p>\n<h3 id=\"Basic-comb-logic-circuits\"><a href=\"#Basic-comb-logic-circuits\" class=\"headerlink\" title=\"Basic comb. logic circuits\"></a>Basic comb. logic circuits</h3><p>Encoder: inputs are more, outputs are less($n \\le 2^m$)</p>\n<p>Decoder: inputs are less, outputs are more($m &#x3D; 2^n$)</p>\n<p>Multiplexer: From several inputs, choose one as output according to the address inputs. It can be used to make a shift register. We can use n-bit-addr MUX for m-bit function.</p>\n<p>Adder: Half adder &amp; full adder.</p>\n<p>Half Adder: $S &#x3D; A \\oplus B$</p>\n<p>Full adder: $C_{out} &#x3D; A\\cdot C_{in} + B\\cdot C_{in} + A\\cdot B, S &#x3D; A\\oplus B\\oplus C_{in}$</p>\n<p>Implements of Full Adder:</p>\n<p><strong>Serial Adder</strong> $C_{i+1} &#x3D; A_iC_i+B_iC_i + A_iB_i$. The latency is disastrous.</p>\n<p><strong>Carry Lookahead Adder(CLA)</strong></p>\n<p>First define $P_i &#x3D; A_i\\oplus B_i, G_i &#x3D; A_iB_i$, P means Carry-bit propagation, G means Carry-bit Generation. Thus, $C_{i+1} &#x3D; G_i + P_iC_i, S_i &#x3D; A_i\\oplus B_i\\oplus C_i &#x3D; P_i\\oplus C_i$. Thus the $C_i$ can be replaced: </p>\n<div>$$\nC_1 = G_0+P_0C_0\\\\\nC_2 = G_1 + P_1(G_0+P_0C_0) =  G_1 + P_1G_0+P_1P_0C_0\\\\\nC_3 = G_2 + P_2(G_1 + P_1G_0+P_1P_0C_0) = G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0\\\\\nC_4=G_3+P_3(G_2 + P_2G_1 + P_2P_1G_0+P_2P_1P_0C_0)=G_3+P_3G_2 + P_3P_2G_1 + P_3P_2P_1G_0+P_3P_2P_1P_0C_0\n$$</div>\n\n<p>A 4-bit CLA can be designed using these formulas. For more, it is too complex. However, we can cascade the 4-bit CLA to reach the balance of latency and complexity.</p>\n<p>Moreover, here comes the parallel intra- and inter-group CLA which regards the 4-bit adder as a block and defines its $P_i$ and $G_i$, connecting the 4-bit adders in a similar manner as the structure of 4-bit adder inside.</p>\n<h2 id=\"Sequential-logic\"><a href=\"#Sequential-logic\" class=\"headerlink\" title=\"Sequential logic\"></a>Sequential logic</h2><p><img src=\"/../images/digital/lec_4_1.jpg\"></p>\n<h3 id=\"Clock\"><a href=\"#Clock\" class=\"headerlink\" title=\"Clock\"></a>Clock</h3><ul>\n<li>Ring Oscillator</li>\n<li>LC oscilator</li>\n<li>Crystal Oscillator</li>\n</ul>\n<h3 id=\"State-and-FSM\"><a href=\"#State-and-FSM\" class=\"headerlink\" title=\"State and FSM\"></a>State and FSM</h3><p><strong>States</strong> contain all needed infomation. could be redundant.</p>\n<p><strong>Finite State Machine(FSM)</strong> The number of input, output and states are finite.</p>\n<p>Mealy FSM: </p>\n<p><img src=\"/../images/digital/lec_4_2.jpg\"></p>\n<p>Moore FSM: </p>\n<p><img src=\"/../images/digital/lec_4_3.jpg\"></p>\n<p>We describe the FSM by State Transition Table or State Diagram.</p>\n<p><img src=\"/../images/digital/lec_4_4.jpg\"></p>\n<p><img src=\"/../images/digital/lec_4_5.jpg\"></p>\n<p>Remember: Moore is less.</p>\n<h3 id=\"Latch\"><a href=\"#Latch\" class=\"headerlink\" title=\"Latch\"></a>Latch</h3><p>Watch the input at the <strong>duration</strong> clock enables.</p>\n<h4 id=\"Examples\"><a href=\"#Examples\" class=\"headerlink\" title=\"Examples\"></a>Examples</h4><p><strong>SR latch</strong></p>\n<p><img src=\"/../images/digital/lec_4_6.jpg\"></p>\n<p>$SR&#x3D;0$ is required.</p>\n<div>$$\nQ^+=S+R^\\prime Q\n$$</div>\n\n<p>A gated version:</p>\n<p><img src=\"/../images/digital/lec_4_7.jpg\"></p>\n<div>$$\nQ^+=C^\\prime Q + C(S+R^\\prime Q)\n$$</div>\n\n<p><strong>D latch</strong></p>\n<p><img src=\"/../images/digital/lec_4_8.jpg\"></p>\n<div>$$\nQ^+=D\n$$</div>\n\n<p>Transimission Gate version</p>\n<p><img src=\"/../images/digital/lec_4_9.jpg\"></p>\n<h4 id=\"Timing-parameters\"><a href=\"#Timing-parameters\" class=\"headerlink\" title=\"Timing parameters\"></a>Timing parameters</h4><p><img src=\"/../images/digital/lec_4_10.jpg\"></p>\n<p><img src=\"/../images/digital/lec_4_11.jpg\"></p>\n<h3 id=\"Flip-Flop\"><a href=\"#Flip-Flop\" class=\"headerlink\" title=\"Flip-Flop\"></a>Flip-Flop</h3><p>Watch the input only at the <strong>moment</strong> when clock signal rises or falls.</p>\n<h4 id=\"Examples-1\"><a href=\"#Examples-1\" class=\"headerlink\" title=\"Examples\"></a>Examples</h4><p>D Flip-flop(DFF)</p>\n<p><img src=\"/../images/digital/lec_4_12.jpg\"></p>\n<p>2 D latches in series with opposite clock.</p>\n<p><strong>Use the delay to help us</strong></p>\n<p>The delay of  NOT gate at the bottom enables the slave to lock first and the master to unlock second when clock falls.</p>\n<p>Also, the delay of NOT gate at the bottom makes $t_h&#x3D;0$.</p>\n<p><img src=\"/../images/digital/lec_4_13.jpg\"></p>\n<p><strong>Two time constraints</strong></p>\n<p>Set-up time constraints: restrict the clock cycle.</p>\n<p><img src=\"/../images/digital/lec_4_14.jpg\"></p>\n<p>$t_{logic}(max)$ is also called propagation delay $t_{dab}$.</p>\n<p>Hold time constraints: restrict the $t_d$</p>\n<p><img src=\"/../images/digital/lec_4_15.jpg\"></p>\n<p>$t_{logic}(min)$ is also called contamination delay($t_{cab}$).</p>\n<h4 id=\"4-types-of-FF\"><a href=\"#4-types-of-FF\" class=\"headerlink\" title=\"4 types of FF\"></a>4 types of FF</h4><p><img src=\"/../images/digital/lec_4_16.jpg\"></p>\n<p><img src=\"/../images/digital/lec_4_17.jpg\"></p>\n<p><img src=\"/../images/digital/lec_4_1.jpg8.jpg\"></p>\n<p>Characteristic equations</p>\n<div>$$\nQ^+=D\\\\\nQ^+=T\\overline Q + \\overline{T}Q\\\\\nQ^+=S+\\overline{R}Q\\\\\nQ^+=J\\overline{Q}+\\overline{K}Q\n$$</div>\n\n<h3 id=\"Problems\"><a href=\"#Problems\" class=\"headerlink\" title=\"Problems\"></a>Problems</h3><p>Can $t_h$ be negative?</p>\n<p><a href=\"https://www.physicaldesign4u.com/2020/04/sta-iii-global-setup-and-hold-time-can.html\">setup-and-hold-time</a></p>\n<p>How to convert FF?</p>\n<p><a href=\"https://blog.csdn.net/qq_43975016/article/details/121193168\">https://blog.csdn.net/qq_43975016/article/details/121193168</a></p>\n<h3 id=\"Analyzing-Sequential-Logic\"><a href=\"#Analyzing-Sequential-Logic\" class=\"headerlink\" title=\"Analyzing Sequential Logic\"></a>Analyzing Sequential Logic</h3><p><strong>Function Analysis</strong></p>\n<p><img src=\"/../images/digital/lec_5_1.jpg\"></p>\n<p><strong>State Transistion Table</strong></p>\n<p><img src=\"/../images/digital/lec_5_2.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_3.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_4.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_5.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_6.jpg\"></p>\n<p>Opt.2 is different and needed to be thought carefully. The x and s in $g(x, s)$ may not be caused by same x.</p>\n<p><strong>Time Constraint</strong></p>\n<h3 id=\"Designing-Sequential-Logic\"><a href=\"#Designing-Sequential-Logic\" class=\"headerlink\" title=\"Designing Sequential Logic\"></a>Designing Sequential Logic</h3><p><strong>Step 1 Determine the input, output and state</strong></p>\n<p><img src=\"/../images/digital/lec_5_7.jpg\"></p>\n<p>Here, Moore is more in FSM states.</p>\n<p><strong>Step 2 State simplification</strong></p>\n<p>2 methods: row matching &amp; implication chart</p>\n<p>row matching: $P\\equiv Q$ iff. outputs and next states are same.</p>\n<p>We can use <strong>implication table</strong> to optimize the row matching method.</p>\n<p><img src=\"/../images/digital/lec_5_9.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_10.jpg\"></p>\n<p><strong>Step 3 State allocation&#x2F;representation</strong></p>\n<p><img src=\"/../images/digital/lec_5_8.jpg\"></p>\n<p>Many methods:</p>\n<p><img src=\"/../images/digital/lec_5_11.jpg\"></p>\n<p><strong>Next state and input&#x2F;output based criteria</strong></p>\n<p>Highest Priority:</p>\n<p>Same input and same next state should be encoded adjacently.</p>\n<p><img src=\"/../images/digital/lec_5_14.jpg\"></p>\n<p>Medium Priority:</p>\n<p>Next states of the same state should have adjacent<br>encoding.</p>\n<p><img src=\"/../images/digital/lec_5_12.jpg\"></p>\n<p>Lowest Priority:</p>\n<p>States with the same output should have adjacent<br>encoding.</p>\n<p><img src=\"/../images/digital/lec_5_13.jpg\"></p>\n<p><strong>Step 5 Get Excitation and Output Equations</strong></p>\n<p><img src=\"/../images/digital/lec_5_15.jpg\"></p>\n<p><strong>Step 6 Draw Logic Circuit Diagram</strong></p>\n<h3 id=\"Typical-Sequential-Logic-Circuits\"><a href=\"#Typical-Sequential-Logic-Circuits\" class=\"headerlink\" title=\"Typical Sequential Logic Circuits\"></a>Typical Sequential Logic Circuits</h3><p>Register &amp; Counter</p>\n<p><strong>Register</strong></p>\n<p>Shift register. Serial&#x2F;Parallel Input, Serial&#x2F;Parallel Output.</p>\n<p><img src=\"/../images/digital/lec_5_17.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_16.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_18.jpg\"></p>\n<p><strong>Counter</strong></p>\n<p><strong>UP&#x2F;Down Counter</strong></p>\n<p><img src=\"/../images/digital/lec_5_19.jpg\"></p>\n<p><strong>Specific-base Counter</strong></p>\n<p>000→010→011→101→110→000</p>\n<p><img src=\"/../images/digital/lec_5_20.jpg\"></p>\n<p><strong>Self-Starting problem of counter</strong></p>\n<p>Abnormal state(001, 100, 111)</p>\n<p><img src=\"/../images/digital/lec_5_21.jpg\"></p>\n<p><strong>Ring counter &amp; twisted ring counter</strong></p>\n<p><img src=\"/../images/digital/lec_5_22.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_23.jpg\"></p>\n<p><strong>Async &amp; snyc Counter</strong></p>\n<p><img src=\"/../images/digital/lec_5_24.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_25.jpg\"></p>\n<p><img src=\"/../images/digital/lec_5_26.jpg\"></p>\n<h2 id=\"Instruction-Set-Architecture\"><a href=\"#Instruction-Set-Architecture\" class=\"headerlink\" title=\"Instruction Set Architecture\"></a>Instruction Set Architecture</h2><h3 id=\"Introduction-1\"><a href=\"#Introduction-1\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><h4 id=\"Implement-Algorithm-In-Hardware\"><a href=\"#Implement-Algorithm-In-Hardware\" class=\"headerlink\" title=\"Implement Algorithm In Hardware\"></a>Implement Algorithm In Hardware</h4><p><img src=\"/../images/digital/lec_6_1.jpg\"></p>\n<p>Three steps: </p>\n<ul>\n<li>Instruction fetch</li>\n<li>Instruction decoding</li>\n<li>Instruction execution &amp; data write-back</li>\n</ul>\n<p><strong>Program Counter(PC)</strong></p>\n<p>Current Instruction Address</p>\n<p>Updated Every Cycle</p>\n<p><strong>Arithmetic&#x2F;Logic Instructions</strong></p>\n<p>Arithmetic Logic Unit(ALU)</p>\n<p>REG to REG, NOT Directly access data memory</p>\n<p><strong>Branch&#x2F;Jump Instructions</strong></p>\n<p>Branch After Comparison</p>\n<p>Jump Directly</p>\n<p><strong>Load&#x2F;Store Instructions</strong></p>\n<p>Load Data: data memory to REG</p>\n<p>Store Data: REG to data memory</p>\n<h4 id=\"General-Purpose-Processore-Structure\"><a href=\"#General-Purpose-Processore-Structure\" class=\"headerlink\" title=\"General Purpose Processore Structure\"></a>General Purpose Processore Structure</h4><p><strong>Turing Machine</strong></p>\n<p>2 Turing Machine Models: </p>\n<ul>\n<li>Princeton architecture</li>\n<li>Harvard architecture</li>\n</ul>\n<p><img src=\"/../images/digital/lec_6_2.jpg\"></p>\n<h4 id=\"Program-FLow\"><a href=\"#Program-FLow\" class=\"headerlink\" title=\"Program FLow\"></a>Program FLow</h4><p><img src=\"/../images/digital/lec_6_3.jpg\"></p>\n<p><img src=\"/../images/digital/lec_6_4.jpg\"></p>\n<h3 id=\"Instruction-Set-Design\"><a href=\"#Instruction-Set-Design\" class=\"headerlink\" title=\"Instruction Set Design\"></a>Instruction Set Design</h3><p>Instruction set is the bridge between software &amp; generall-purpose (GP) CPU.</p>\n<p><strong>Performance Evaluate</strong></p>\n<div>$$\n\\text{Performance} = \\frac{1}{\\text{Execution Time}}\n$$</div>\n\n<p>Task Execution Time By CPU:</p>\n<div>$$\n\\text{Total Time} = \\text{Waiting for I/O} + \\text{Execution Time}\\\\\n\\text{Execution Time} = \\text{Cycle }\\# \\times \\text{Clock Cycle }T = \\frac{\\text{Cycle }\\# }{\\text{Clock }f} \n$$</div>\n\n<div>$$\n\\text{Cycle } \\# = \\text{Progream Instruction }\\# \\times \\text{Average Cycle } \\# \\text{ for one inst.}\n$$</div>\n\n<p>Average Cycle # for one instruction is also known as the cycle per instruction (CPI)</p>\n<p>So, </p>\n<div>$$\n\\text{Execution Time} = \\text{Instruction }\\# \\times \\text{CPI} \\times \\text{Clock Cycle }\n$$</div>\n\n<p><strong>CPI</strong></p>\n<div>$$\n\\text{CPI} = \\sum_{i = 1}^n \\text{CPI}_i \\times \\text{P}_i\n$$</div>\n\n<p>Where $\\text{P}_i$ is the i-th instruction occurrence frequency, and $\\text{CPI}_i$ is the clock cycle # of the i-th instruction.</p>\n<p><strong>Factors that affect Performance</strong></p>\n<ul>\n<li>Instruction # </li>\n<li><ul>\n<li>ISA, regardless of its specific implementation</li>\n</ul>\n</li>\n<li><ul>\n<li>Compiler</li>\n</ul>\n</li>\n<li>CPI</li>\n<li><ul>\n<li>Memory System and Processor Architecture</li>\n</ul>\n</li>\n<li><ul>\n<li>The Instruction Composition In the Program</li>\n</ul>\n</li>\n<li><ul>\n<li>Compiler</li>\n</ul>\n</li>\n<li>Clock Cycle</li>\n<li><ul>\n<li>Machine implementation details</li>\n</ul>\n</li>\n<li><ul>\n<li>Memory System and Processor Architecture</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/../images/digital/lec_6_5.jpg\"></p>\n<p><strong>Data Access</strong></p>\n<p><img src=\"/../images/digital/lec_6_6.jpg\"></p>\n<p><img src=\"/../images/digital/lec_6_7.jpg\"></p>\n<p><strong>Set Design</strong></p>\n<p>RISC &amp; CISC</p>\n<p><img src=\"/../images/digital/lec_6_8.jpg\"></p>\n<p><img src=\"/../images/digital/lec_6_9.jpg\"></p>\n<p><strong>Five Questions</strong></p>\n<ul>\n<li>How to make use of 11 extra bits in arithmetic operations?</li>\n<li>How to use 16 bits to represent 32-bit address for branch?</li>\n<li>How to encode branch instruction with immediate?</li>\n<li>How to use 21 bits to represent 32-bit address for memory address?</li>\n<li>How to use 26 bits to represent 32-bit address for jump?</li>\n</ul>\n<h3 id=\"MIPS-Instruction-Set\"><a href=\"#MIPS-Instruction-Set\" class=\"headerlink\" title=\"MIPS Instruction Set\"></a>MIPS Instruction Set</h3><h4 id=\"Instruction-Storage-and-Data-Storage\"><a href=\"#Instruction-Storage-and-Data-Storage\" class=\"headerlink\" title=\"Instruction Storage and Data Storage\"></a>Instruction Storage and Data Storage</h4><p>32-bits instruction length, and 32 general-purpose registers.</p>\n<p>First 6 bits are opcode.</p>\n<p><strong>Register</strong></p>\n<p><img src=\"/../images/digital/lec_7_9.jpg\"></p>\n<p>the register index is limited to 5 bits.</p>\n<h4 id=\"Instruction-Type-R-I-J\"><a href=\"#Instruction-Type-R-I-J\" class=\"headerlink\" title=\"Instruction Type(R, I, J)\"></a>Instruction Type(R, I, J)</h4><p><strong>Type: R</strong></p>\n<p><strong>Field Division and detailed definition</strong></p>\n<p><img src=\"/../images/digital/lec_7_1.jpg\"></p>\n<p>Q1: Can we make use of the extra 11 bits?</p>\n<p><img src=\"/../images/digital/lec_7_13.jpg\"></p>\n<p><strong>Type: I</strong></p>\n<p>It’s immediate.</p>\n<p><img src=\"/../images/digital/lec_7_5.jpg\"></p>\n<p>2 cases:</p>\n<p><img src=\"/../images/digital/lec_7_2.jpg\"></p>\n<p><img src=\"/../images/digital/lec_7_3.jpg\"></p>\n<p>Q2:The possible address range covers 32 bits. How to represent the address with limited 16 bits for branch?</p>\n<p>base + offset</p>\n<p><img src=\"/../images/digital/lec_7_10.jpg\"></p>\n<p>Q3: How to encode the branch with immediate?</p>\n<p>No direct instructions for this.</p>\n<p>We use compare instruction and branch instruction to achieve this.</p>\n<p>Q4: The possible address range covers 32 bits. How to represent the address with limited 21 bits for memory access?</p>\n<p>base + offset</p>\n<p><img src=\"/../images/digital/lec_7_4.jpg\"></p>\n<p><strong>Type: J</strong></p>\n<p><img src=\"/../images/digital/lec_7_6.jpg\"></p>\n<p>Q5: The possible address range covers 32 bits. How to represent<br>the address with limited 26 bits for jump?</p>\n<p>3 types of jump operation: <code>j</code>, <code>jal</code> and <code>jr</code>.</p>\n<p><img src=\"/../images/digital/lec_7_7.jpg\"></p>\n<p><strong>Summary</strong></p>\n<p><img src=\"/../images/digital/lec_7_.jpg\"></p>\n<h4 id=\"Addressing-mode\"><a href=\"#Addressing-mode\" class=\"headerlink\" title=\"Addressing mode\"></a>Addressing mode</h4><p>5 modes:</p>\n<ul>\n<li>Register addressing</li>\n<li>Immediate addressing</li>\n<li>Base (base-offset) addressing</li>\n<li>PC-related addressing</li>\n<li>Pseudo-direct addressing</li>\n</ul>\n<p><strong>Register addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_11.jpg\"></p>\n<p><strong>Immediate addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_12.jpg\"></p>\n<p>How to load a 32-bit constant to $s0?</p>\n<p><img src=\"/../images/digital/lec_7_14.jpg\"></p>\n<p><strong>Base-offset addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_15.jpg\"></p>\n<p><strong>PC-related addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_16.jpg\"></p>\n<p><img src=\"/../images/digital/lec_7_17.jpg\"></p>\n<p><strong>Pseudo-direct addressing</strong></p>\n<p><img src=\"/../images/digital/lec_7_18.jpg\"></p>\n<p>It is faster because no add operation needed, comparing to <code>PC_new = &#123;PC_old + address &lt;&lt; 2&#125;</code>.</p>\n<p><strong>Summary</strong></p>\n<p><img src=\"/../images/digital/lec_7_19.jpg\"></p>\n<h4 id=\"Instruciton-System\"><a href=\"#Instruciton-System\" class=\"headerlink\" title=\"Instruciton System\"></a>Instruciton System</h4><p><strong>Arithmetic</strong></p>\n<p>Add  <code>add $t0, $t1, $t2      #$t0=$t1+$t2</code></p>\n<p>Add immediate <code>addi $t2, $t3, 5  #$t2=$t3+5</code></p>\n<p>Subtract <code>sub $t2,$t3,$t4 #$t2=$t3-$t4</code></p>\n<p>NO subtract-an-immediate instruction! We use 2’s complement immediate in the <code>addi</code>.</p>\n<p><strong>Logic</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">and $t0, $t1, $t2</span><br><span class=\"line\">or $t0, $t1, $t2</span><br><span class=\"line\">xor $t0, $t1, $t2</span><br><span class=\"line\">nor $t0, $t1, $t2</span><br></pre></td></tr></table></figure>\n\n<p>No NOT instruction. We set <code>$t1</code> or <code>$t2</code> to 0 and use NOR.</p>\n<p>With immediate:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">andi $t0, $t1, 10</span><br><span class=\"line\">ori $t0, $t1, 10</span><br><span class=\"line\">xori $t0, $t1, 10</span><br></pre></td></tr></table></figure>\n\n<p><strong>Shift</strong></p>\n<p>Immediate-amount shift:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sll $t0, $t1, 10</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; 10, logical</span><br><span class=\"line\">srl $t0, $t1, 10</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; 10, logical</span><br><span class=\"line\">sra $t0, $t1, 10</span><br><span class=\"line\"># $t0 = $t1 &gt;&gt; 10, arithmetic, depending on the sign bit</span><br></pre></td></tr></table></figure>\n\n<p>Register-amonut shift: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sllv $t0, $t1, $t3</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; ($t3%32), logical</span><br><span class=\"line\">srl $t0, $t1, $t3</span><br><span class=\"line\"># $t0 = $t1 &lt;&lt; ($t3%32), logical</span><br><span class=\"line\">sra $t0, $t1, $t3</span><br><span class=\"line\"># $t0 = $t1 &gt;&gt; ($t3%32), arithmetic, depending on the sign bit</span><br></pre></td></tr></table></figure>\n\n<p><strong>Compare instruction</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slt $t1, $t2, $t3</span><br><span class=\"line\"># if ($t2 &lt; $t3) $t1=1;</span><br><span class=\"line\"># else $t1=0</span><br><span class=\"line\">sltu $t1, $t2, $t3</span><br><span class=\"line\"># unsigned comparison</span><br></pre></td></tr></table></figure>\n\n<p>With immediate:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slti $t1, $t2, 10</span><br><span class=\"line\">sltui $t1, $t2, 10</span><br></pre></td></tr></table></figure>\n\n<p><strong>About i, u, iu</strong></p>\n<p><img src=\"/../images/digital/lec_7_20.jpg\"></p>\n<p><strong>Load&#x2F;Store Instruction</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lw $t1, 32($t2)</span><br><span class=\"line\">sw $t3, 500($t4)</span><br></pre></td></tr></table></figure>\n\n<p>Register stores base address is called base register,<br>Constant in the instruction is called offset.</p>\n<p><strong>Branch instruction</strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">beq $t0, $t1, target</span><br><span class=\"line\">#if $t0=$t1, then execute</span><br><span class=\"line\">#instruction target</span><br><span class=\"line\">bne $t0, $t1, target</span><br><span class=\"line\"># if $t0!=$t1, then execute</span><br><span class=\"line\"># instruction target</span><br></pre></td></tr></table></figure>\n\n<p>More than this 2 instructions.</p>\n<p><strong>Jump instruction</strong></p>\n<p>Unconditional branch</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">j label</span><br><span class=\"line\">#unconditionally jump to label</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Procedure-Call\"><a href=\"#Procedure-Call\" class=\"headerlink\" title=\"Procedure Call\"></a>Procedure Call</h4><p><img src=\"/../images/digital/lec_7_21.jpg\"></p>\n<p>MIPS uses registers for argument and return data&#x2F;address.</p>\n<p>Argument registers: <code>$a0-$a3</code></p>\n<p>Return value registers: <code>$v0-$v1</code></p>\n<p>Retuen address register: <code>$ra</code></p>\n<p><code>jal Procedure #Procedure call jr $ra #Procedure return</code></p>\n<p><code>jal</code> and <code>j</code> are both J-type, but <code>jal</code> will store the return address.</p>\n<p><code>jr</code> is R-type, will jump to the address restored in the register, so it can jump very far.</p>\n<p><strong>Maintain the register data</strong></p>\n<p>2 types:</p>\n<ul>\n<li>Temporaries data registers</li>\n<li>Saved data registers</li>\n</ul>\n<p><img src=\"/../images/digital/lec_7_22.jpg\"></p>\n<p>Who saves the register data?</p>\n<p>Caller(temp) or Callee(save)</p>\n<p><img src=\"/../images/digital/lec_7_23.jpg\"></p>\n<p>We use Stack to maintain the register data.</p>\n<p><img src=\"/../images/digital/lec_7_24.jpg\"></p>\n<p><strong>Stack Operation with $sp</strong></p>\n<p>e.g. <code>push $s1, $s2 , $s3</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">addi $sp, $sp, -12</span><br><span class=\"line\">sw $s1, 8($sp)</span><br><span class=\"line\">sw $s2, 4($sp)</span><br><span class=\"line\">sw $s3, 0($sp)</span><br></pre></td></tr></table></figure>\n<p><code>pop $s1, $s2, $s3</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lw $s1, 0($sp)</span><br><span class=\"line\">lw $s2, 4($sp)</span><br><span class=\"line\">lw $s3, 8($sp)</span><br><span class=\"line\">addi, $sp, $sp, 12</span><br></pre></td></tr></table></figure>\n\n<p><strong>Leaf Procedures</strong></p>\n<p>Procedures that do not call others are called <em>leaf</em> procedures.</p>\n<p><strong>Nested Procedures</strong></p>\n<p>Nested(Recursive) Procedures are procedures that invoke “clones” of themselves.</p>\n<p>e.g.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">fact</span> <span class=\"params\">(<span class=\"type\">int</span> n)</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (n &lt; <span class=\"number\">1</span>) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> <span class=\"keyword\">return</span> (n * fact(n - <span class=\"number\">1</span>));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fact:</span><br><span class=\"line\">    addi    $sp, $sp, -8</span><br><span class=\"line\">    sw      $ra, 4($sp)</span><br><span class=\"line\">    sw      $a0, 0($sp)</span><br><span class=\"line\">    slti    $t0, $a0, 1</span><br><span class=\"line\">    beq     $t0, $zero, L1</span><br><span class=\"line\">    addi    $v0, $zero, 1</span><br><span class=\"line\">    addi    $sp, $sp, 8</span><br><span class=\"line\">    jr      $ra</span><br><span class=\"line\">L1:</span><br><span class=\"line\">    addi    $a0, $a0, -1</span><br><span class=\"line\">    jal     fact</span><br><span class=\"line\">    lw      $a0, 0($sp)</span><br><span class=\"line\">    lw      $ra, 4($sp)</span><br><span class=\"line\">    addi    $sp, $sp, 8</span><br><span class=\"line\">    mul     $v0, $a0, $v0</span><br><span class=\"line\">    jr      $ra</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Single-Cycle-Processor\"><a href=\"#Single-Cycle-Processor\" class=\"headerlink\" title=\"Single-Cycle Processor\"></a>Single-Cycle Processor</h2><p><img src=\"/../images/digital/lec_8_1.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_2.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_3.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_4.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_5.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_6.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_7.jpg\"></p>\n<p><strong>Load Operation Takes MUCH LONGER!!!</strong></p>\n<h2 id=\"Multi-Cycle-Processor\"><a href=\"#Multi-Cycle-Processor\" class=\"headerlink\" title=\"Multi-Cycle Processor\"></a>Multi-Cycle Processor</h2><p><img src=\"/../images/digital/lec_8_8.jpg\"></p>\n<p>The Multicycle processor processes different inst. in different cycles. Thus, it can avoid the time limitation by the slow instruction.</p>\n<p>Modules on th datapath can be used multiple times within an inst. That is <strong>Module reuse</strong>.</p>\n<p>Performance improvement depends on the detailed delay. The multicycle is not necessarily faster than the single cycle.</p>\n<p><img src=\"/../images/digital/lec_8_9.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_10.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_11.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_12.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_13.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_14.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_15.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_16.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_17.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_18.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_19.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_20.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_21.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_30.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_31.jpg\"></p>\n<h2 id=\"Exception-and-Interrupt\"><a href=\"#Exception-and-Interrupt\" class=\"headerlink\" title=\"Exception and Interrupt\"></a>Exception and Interrupt</h2><p><img src=\"/../images/digital/lec_8_22.jpg\"></p>\n<p>Generally, exceptions and interrupts are events that can change the normal instruction execution flow (other than branches and jumps).</p>\n<p>Exception<br>– Internal unpredictable events such as overflow.</p>\n<p>Interrupt<br>– External unpredictable events such as I&#x2F;O.</p>\n<p><img src=\"/../images/digital/lec_8_23.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_24.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_25.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_26.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_27.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_28.jpg\"></p>\n<p><img src=\"/../images/digital/lec_8_29.jpg\"></p>\n<h2 id=\"Pipelined-processor\"><a href=\"#Pipelined-processor\" class=\"headerlink\" title=\"Pipelined processor\"></a>Pipelined processor</h2><p><img src=\"/../images/digital/lec_9_1.jpg\"></p>\n<p>Pipeline means spatial and temporal reuse.</p>\n<p>Divide a complex task into several sub-tasks to<br>execute sequentially, and assign each sub-task to<br>dedicated hardware</p>\n<p>Different sub-tasks of multiple tasks can be<br>processed simultaneously to improve the<br>performance</p>\n<p>• Time-division multiplexing: the same resource is reused through<br>different cycles</p>\n<p>• Space-division multiplexing: multiple resources are reused<br>within one cycle</p>\n<p>Pros: improved efficiency</p>\n<p>Cons: Some inst. depends on the former inst.. However, the former inst. has not finished yet, if the prediction of branch is wrong, time is wasted.</p>\n<p>Instruction-Level Parallelism (ILP)</p>\n<p>– Execute multiple instructions in parallel</p>\n<p>– One mainstream approach to CPU performance improvement</p>\n<p>Basic Techniques</p>\n<p>– Pipelining: instruction execution is divided into several stages, and<br>each stage can be processed with the other stages (of other<br>instructions) simultaneously</p>\n<p>– Superscalar: multiple dedicated functional units are equipped so<br>that CPU can receive &amp; execute more instructions within one cycle.</p>\n<p>– Very Long Instruction Word (VLIW): each instruction consists of<br>multiple segments to utilize the processor resources independently.</p>\n<p>5 stages in MIPS:</p>\n<ol>\n<li>Instruction Fetch (IF)</li>\n<li>Instruction Decode &#x2F; Register File</li>\n<li>ALU Execution(EX)</li>\n<li>Memory Data Access(MEM)</li>\n<li>Reg Write-Back(WB)</li>\n</ol>\n<p>Latency of the stages in the pipeline should<br>be as equivalent as possible, why?<br>–The pipeline performance is bottlenecked by the stage<br>of the longest latency</p>\n<p><strong>Metrics of pipelined processors</strong></p>\n<ul>\n<li>Throughput(TP): Executed instruction # per unit time</li>\n<li>Max throughput: The throughput of a steady-state pipeline with a continuous instruction input stream</li>\n<li>Real throughput: The throughput of the pipeline executing task with finite instructions</li>\n</ul>\n<p>Real TP:</p>\n<div>$$\nTP = \\frac n {T_k} = \\frac{n}{(n+k-1)\\Delta t}\n$$</div>\n\n<p>Max TP:</p>\n<div>$$\nTP_{max} = \\lim_{n\\rightarrow\\infty}\\frac{n}{(n+k-1)\\Delta t} = \\frac{1}{\\Delta t}\n$$</div>\n\n<p><strong>Speed up</strong> Execution time ratio between w&#x2F;o or w&#x2F; pipelining.</p>\n<p>$T_0$: execution time without pipelining</p>\n<p>$T_k$: execution time with k-stage pipelining(assume each stage has the same latency)</p>\n<div>$$\n\\frac{T_0}{T_k}\n$$</div>\n\n<p>Real speedup:</p>\n<div>$$\nS = \\frac{nk\\Delta t}{(n + k - 1)\\Delta t} = \\frac{kn}{n + k - 1}\n$$</div>\n\n<p>Max speedup:</p>\n<div>$$\nS_{max} = \\lim_{n\\rightarrow \\infty}\\frac{kn}{k + n - 1} = k\n$$</div>\n\n<p><strong>Pipelined datapath</strong></p>\n<p><img src=\"/../images/digital/lec_9_3.jpg\"></p>\n<p><img src=\"/../images/digital/lec_9_4.jpg\"></p>\n<p><img src=\"/../images/digital/lec_9_5.jpg\"></p>\n<p><img src=\"/../images/digital/lec_9_6.jpg\"></p>\n<p><img src=\"/../images/digital/lec_9_7.jpg\"></p>\n<p><img src=\"/../images/digital/lec_9_8.jpg\"></p>\n<p>Many inst. doesnt need MEM stage, but the stage can’t be skipped, since it may “collide” with the previous inst.</p>\n<p>Q: How to get the control signals in each stage?</p>\n<p>Control signals are generated at ID&#x2F;RF stage.</p>\n<p>Control signals flow in the pipeline: use when needed; reserve when subsequent stages needed; discard when not needed any more.</p>\n<p><img src=\"/../images/digital/lec_9_10.jpg\"></p>\n<p>Why RegDst Doesnt needed in the stages after EX?</p>\n<p>The RegDst is used to select the destination register. However, the destination register is determined in the EX stage. Thus, RegDst is not needed in the stages after EX.</p>\n<p>Sometimes this can cause trouble:</p>\n<figure class=\"highlight mips\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">LW </span>R2, R9(<span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"keyword\">ADD </span>R4, R3, R2</span><br><span class=\"line\"><span class=\"keyword\">ADD </span>R6, R5, R4</span><br></pre></td></tr></table></figure>\n\n<p>The R4 is accessed before it updates.</p>\n<h3 id=\"Hazard-in-the-pipeline\"><a href=\"#Hazard-in-the-pipeline\" class=\"headerlink\" title=\"Hazard in the pipeline\"></a>Hazard in the pipeline</h3><p><strong>Structural Hazards</strong></p>\n<p>Two instructions acquire the same hardware resource simultaneously.</p>\n<p><img src=\"/../images/digital/lec_9_11.jpg\"></p>\n<p>Solution:</p>\n<ol>\n<li>Add resources: separating PC+4 from ALU; Harvard architecture</li>\n<li>Adjust stages: add MEM</li>\n</ol>\n<p><img src=\"/../images/digital/lec_9_15.jpg\"></p>\n<p><img src=\"/../images/digital/lec_9_12.jpg\"></p>\n<p>MIPS is born to be  pipelined: the problem of structural hazard is solved by the structure of MIPS.</p>\n<p><strong>Data Hazards</strong></p>\n<p><img src=\"/../images/digital/lec_9_13.jpg\"></p>\n<p>2 solutions:</p>\n<p><strong>Stalling</strong></p>\n<p><img src=\"/../images/ss/lec21_8.jpg\"></p>\n<p><strong>Forwarding(Bypassing)</strong></p>\n<p><img src=\"/../images/ss/lec21_1.jpg\"></p>\n<p><img src=\"/../images/ss/lec21_2.jpg\"></p>\n<p>But, load uses hazard emerges:</p>\n<p><img src=\"/../images/ss/lec21_8.jpg\"></p>\n<p><img src=\"/../images/digital/lec_10_1.jpg\"></p>\n<p>Still, a nop needed to stall the pipeline.</p>\n<p><img src=\"/../images/digital/lec_10_2.jpg\"></p>\n<p>Is there any possibility to eliminate the stall?</p>\n<p>Yes, if the MIPS code can be optimized.</p>\n<p><img src=\"/../images/digital/lec_10_3.jpg\"></p>\n<p><strong>Control Hazards</strong></p>\n<p><img src=\"/../images/digital/lec_9_14.jpg\"></p>\n<p><strong>Stalling</strong></p>\n<p><img src=\"/../images/digital/lec_10_4.jpg\"></p>\n<p><strong>Forwarding</strong></p>\n<p><img src=\"/../images/digital/lec_10_5.jpg\"></p>\n<p>If Move the branch decision to ID stage:</p>\n<p><img src=\"/../images/digital/lec_10_6.jpg\"></p>\n<p><img src=\"/../images/digital/lec_10_7.jpg\"></p>\n<p><strong>Delay slot</strong></p>\n<p><img src=\"/../images/digital/lec_10_8.jpg\"></p>\n<p><strong>Prediction</strong></p>\n<p>Static Branch Prediction</p>\n<p><img src=\"/../images/digital/lec_10_9.jpg\"></p>\n<p>Cancel the effect caused by false prediction.</p>\n<p>Dynamic Branch Prediction</p>\n<ul>\n<li>History-based dynamic prediction</li>\n<li>Using runtime behaviour to predict future branches</li>\n</ul>\n<p>At IF stage, there are Branch History Table(BHT) and Branch Target Buffer(BTB).</p>\n<p>beq at IF stage</p>\n<p>• Look up if the instruction address is in BHT and BTB.</p>\n<p>• If not in, create a new entry. If in, check whether the<br>branch is taken at the last time. If taken, send the target<br>address to PC as the next address for IF.</p>\n<p>–beq at ID stage</p>\n<p>• IF stage will fetch instruction based on the predicted<br>target address</p>\n<h3 id=\"Implementation-of-the-Pipiline\"><a href=\"#Implementation-of-the-Pipiline\" class=\"headerlink\" title=\"Implementation of the Pipiline\"></a>Implementation of the Pipiline</h3><p><img src=\"/../images/digital/lec_10_10.jpg\"></p>\n<p><strong>Data hazard</strong></p>\n<p>Forwarding</p>\n<p>EX&#x2F;MEM hazard</p>\n<figure class=\"highlight verilog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (EX/MEM<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRs</span>))</span><br><span class=\"line\">    ForwardA = <span class=\"number\">10</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (EX/MEM<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRt</span>))</span><br><span class=\"line\">    ForwardB = <span class=\"number\">10</span></span><br></pre></td></tr></table></figure>\n\n<p>MEM&#x2F;WB hazard</p>\n<figure class=\"highlight verilog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (MEM/WB<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRs</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != ID/EX<span class=\"variable\">.RegisterRs</span> || ~ EX/MEM<span class=\"variable\">.RegWrite</span>))</span><br><span class=\"line\">    ForwardA = <span class=\"number\">01</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (MEM/WB<span class=\"variable\">.RegWrite</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> != <span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (MEM/WB<span class=\"variable\">.RegWrAddr</span> == ID/EX<span class=\"variable\">.RegisterRt</span>)</span><br><span class=\"line\"><span class=\"keyword\">and</span> (EX/MEM<span class=\"variable\">.RegWrAddr</span> != ID/EX<span class=\"variable\">.RegisterRt</span> || ~ EX/MEM<span class=\"variable\">.RegWrite</span>))</span><br><span class=\"line\">    ForwardB = <span class=\"number\">01</span></span><br></pre></td></tr></table></figure>\n\n<p>load-use hazard</p>\n<p>We have to stall the pipeline for one cycle.</p>\n<p>Condition: <code>if (ID/EX.MemRead and ((ID/EX.RegisterRt == IF/ID.RegisterRs) or  (ID/EX.RegisterRt == IF/ID.RegisterRt)))</code></p>\n<p>How to stall?</p>\n<p>Stall &amp; flush</p>\n<p>PC &amp; ID&#x2F;IF: stall(Keep the control signals)</p>\n<p>EX &amp; MEM &amp; WB: flush(Set the control signals to 0)</p>\n<p>Control signals:</p>\n<p>EX: RegDst, ALUOp1, ALUOp0, ALUSrc</p>\n<p>MEM: Branch, MemRead, MemWrite</p>\n<p>WB: MemToReg, RegWrite</p>\n<figure class=\"highlight verilog\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> &#123;ID/EX<span class=\"variable\">.MemRead</span></span><br><span class=\"line\"><span class=\"keyword\">and</span> ((ID/EX<span class=\"variable\">.RegisterRt</span> = IF/ID<span class=\"variable\">.RegisterRs</span>)</span><br><span class=\"line\"><span class=\"keyword\">or</span> (ID/EX<span class=\"variable\">.RegisterRt</span> = IF/ID<span class=\"variable\">.RegisterRt</span>))&#125;</span><br><span class=\"line\">    Keep IF/ID; Keep PC; Flush ID/EX;</span><br></pre></td></tr></table></figure>\n\n<p>Special Case:</p>\n<p>Memory-to-memory copy</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lw $1, 10($2)</span><br><span class=\"line\">sw $1, 10($3)</span><br></pre></td></tr></table></figure>\n\n<p>The stall is unnecessary. We can use forwarding to solve the problem.</p>\n<p><strong>Control Hazard</strong></p>\n<p>BEQ &amp; J need 1 stall cycle.</p>\n<p>Control hazards are not as frequent as data<br>hazards, but they are harder to be resolved<br>effectively as forwarding.</p>\n<p>Another type of control hazard: exceptions and interrupts.</p>\n<p>– “Exception” includes any unpredictable events that<br>can change the normal control flow, which has no<br>distinction between internal and external. </p>\n<p>– “Interrupt” is only used for external events.</p>\n<p><img src=\"/../images/digital/lec_12_1.jpg\"></p>\n<h2 id=\"Advanced-techniques-for-processor\"><a href=\"#Advanced-techniques-for-processor\" class=\"headerlink\" title=\"Advanced techniques for processor\"></a>Advanced techniques for processor</h2><h3 id=\"Instruction-level-parallelism\"><a href=\"#Instruction-level-parallelism\" class=\"headerlink\" title=\"Instruction-level parallelism\"></a>Instruction-level parallelism</h3><p>Superpipelining: a deeper pipeline</p>\n<p>VLIW</p>\n<p>Multiple-issue: a wider pipeline</p>\n<p>Superscalar</p>\n<p><img src=\"/../images/digital/lec_12_2.jpg\"></p>\n<h3 id=\"Thread-level-parallelism\"><a href=\"#Thread-level-parallelism\" class=\"headerlink\" title=\"Thread-level parallelism\"></a>Thread-level parallelism</h3><p>Hyper-threading</p>\n<p><img src=\"/../images/digital/lec_12_3.jpg\"></p>\n<p>Multicore</p>\n<h3 id=\"Heterogeneous-computing\"><a href=\"#Heterogeneous-computing\" class=\"headerlink\" title=\"Heterogeneous computing\"></a>Heterogeneous computing</h3><p>GPU</p>\n<p>XPU</p>\n<h2 id=\"Memory\"><a href=\"#Memory\" class=\"headerlink\" title=\"Memory\"></a>Memory</h2><h3 id=\"Basics\"><a href=\"#Basics\" class=\"headerlink\" title=\"Basics\"></a>Basics</h3><p>SRAM cell</p>\n<p>High speed, low density &amp; expensive</p>\n<p><img src=\"/../images/digital/lec_12_4.jpg\"></p>\n<p>DRAM cell</p>\n<p>Low speed, high density &amp; cheap. The charge in capacitor may leak, so the data cannot be stored for a long time.</p>\n<p><img src=\"/../images/digital/lec_12_5.jpg\"></p>\n<p><img src=\"/../images/digital/lec_12_6.jpg\"></p>\n<h3 id=\"Evaluation\"><a href=\"#Evaluation\" class=\"headerlink\" title=\"Evaluation\"></a>Evaluation</h3><p>3C model:</p>\n<p><strong>Compulsory miss</strong> first access to a block</p>\n<p><strong>Capacity miss</strong> all lines in cache are used</p>\n<p><strong>Conflict miss(collision miss)</strong> not fully filled, but the blocks # &gt; available ways #.</p>\n"},{"title":"量筒","date":"2023-09-20T00:06:16.000Z","katex":true,"_content":"\n## 量子力学\n\n### 第一章 引言\n\n光的粒子性：\n* 黑体辐射\n* 光电效应\n* 康普顿散射\n\n原子模型：能级和跃迁\n\n电子衍射：例子的波动性\n\n黑体辐射的解释：\n\n#### 普朗克公式\n\n已知\n\n$$\nP(\\varepsilon_\\nu = nh\\nu) \\propto e^{-\\varepsilon_{\\nu}/kT}\n$$\n\n平均光子数\n$$\n\\overline{n} = \\frac{1}{e^{hv/kT} - 1}\\\\\n$$\n\n又知一个光子的能量$h\\nu$，模式密度（单位频率间隔的模式数）$8\\pi\\nu^2/c^3$，故单位体积单位频率间隔之间的能量为\n\n$$\n\\rho(v) = \\frac{8\\pi \\nu^2}{c^3}\\overline{n}h\\nu\n$$\n\n#### de Broglie的物质波假说和薛定谔方程\n\n$\\hbar = h/2\\pi$\n\n$$\n\\vec{k} = \\frac{\\vec p}{\\hbar}, \\omega = \\frac{E}{\\hbar}\n$$\n\n注：非相对论粒子的能量$E = p^2/2m$，光子的能量$E=cp$\n\n**自由粒子波函数**\n\n经典波改写：\n\n$$\n\\Psi(\\vec r, t) = Ae^{-i(\\omega t - \\vec k \\cdot \\vec r)} = A e^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$\n\n满足$E = p^2/2m$.\n\n试探得到，自由粒子波函数是薛定谔方程的解：\n\n$$\n\\begin{align*}\n\\vec p \\Psi &= -i \\hbar \\nabla\\Psi\\\\\n\\Rightarrow p^2\\Psi &= -\\hbar^2\\nabla^2\\Psi\\\\\n\\Rightarrow i\\hbar\\frac{\\partial \\Psi}{\\partial t} &= E\\Psi = \\frac{p^2\\Psi}{2m} = H\\Psi\\\\\n(H &= -\\frac{\\hbar^2}{2m}\\nabla^2)\n\\end{align*}\n$$\n\n由于$E$可以被$\\vec p$表示，故可以写成$\\vec p$的函数：\n\n$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i[E(\\vec p) t - \\vec p \\cdot \\vec r]/\\hbar}\n$$\n\n$\\Psi(\\vec r, t) = \\sum_{\\vec p} C_{\\vec p}\\Psi_{\\vec p}(\\vec r, t)$满足薛定谔方程。\n\n如果有势能项，薛定谔方程改为：\n\n$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = -\\frac{\\hbar^2}{2m}\\nabla^2\\Psi(\\vec r, t) + V(\\vec r)\\Psi(\\vec r, t)\\\\\n$$\n\n这里\n\n$$\nH = -\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r) \\equiv \\frac{\\hat p^2}{2m} + V(\\vec r)\n$$\n\n引入了动量算符（量子化假设）$\\hat p = -i\\hbar \\nabla$\n\n注：从薛定谔方程的形式可以得知，其解的表达式里$t$前面的系数肯定含$-i$。如果含$i$，是不满足薛定谔方程的。\n\n#### 从经典到量子的过渡\n\n**以一维单粒子为例：**\n\n牛顿力学：\n\n$$\np \\equiv m\\dot{q}\\\\\nf = ma = m\\ddot{q}\n$$\n\n保守力：\n\n$$\nf = -\\frac{\\partial V}{\\partial q}\n$$\n\n定义哈密顿量：\n\n$$\nH(q, p) = \\frac{p^2}{2m} + V(q)\n$$\n\n从而牛顿力学可以用正则方程代替：\n\n$$\n\\dot p = -\\frac{\\partial H}{\\partial q}, \\dot{q} = \\frac{\\partial H}{\\partial p}\n$$\n\n推广到体系：\n\n假设一个体系的运动可以用广义坐标$q_i$ $(i=1,2,\\dots,n)$ 描述，拉格朗日函数为 $L(q_i, \\dot{q}_i, t)$。根据哈密顿原理，体系的运动满足哈密顿正则方程。\n\n哈密顿正则方程可表示为：\n\n$\\frac{\\partial H}{\\partial p_i} = \\dot{q}_i, \\quad \\frac{\\partial H}{\\partial q_i} = -\\dot{p}_i$\n\n其中，$H(p_i, q_i, t)$ 是哈密顿函数，定义为：\n\n$H(p_i, q_i, t) = \\sum_{i=1}^{n} p_i\\dot{q}_i - L(q_i, \\dot{q}_i, t)$\n\n其中，$p_i$ 是广义动量，定义为：\n\n$p_i = \\frac{\\partial L}{\\partial \\dot{q}_i}$\n\n哈密顿正则方程描述了体系在广义坐标和广义动量空间中的运动行为，从而完整地描述了体系的运动。\n\n哈密顿函数H是否正确的判据：\n\n如果正则方程与已知的经典力学方程一致，则此哈密顿函数是正确的。\n\n**量子化（单粒子情况）**\n\n\n$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = \\left(-\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r)\\right)\\Psi\\\\\n$$\n\n$|\\Psi^2|$给出了粒子在空间中的位置概率。波函数结果数学变换，还能够给出各个力学量的概率分布（例如动量概率密度分布）。\n\n多粒子体系：\n\n对于全同多粒子体系，还需要引入新假设（对波函数施加新限制，后面讲）。\n\n统计物理怎样描述粒子运动？\n\n统计物理中需要引入新假设描述极大量粒子的热运动，这种运动不能由通常的量子力学给出。\n\n混合态：热运动的无规性会造成状态不能用一个确定的波函数描述，这种状态称为混合态（统计物理中体系的状态一般都是混合态）。\n\n纯态：量子力学部分都默认波函数是确定的，称为纯态（它是极特殊的情况）。单个粒子的叠加态依然是纯态。\n\n### 第二章 薛定谔方程和一维运动问题\n\n\n#### 波函数及其统计解释\n\n**波函数及其统计解释**\n\nBorn 对双缝干涉的解释：$|\\Psi(\\vec r, t)|^2$与概率密度成正比\n\n$\\Psi(\\vec r, t)$称为概率幅，**完全描写了状态（这种描写具有统计的特征）**，它决定了各可观测的物理量的几率分布。\n\n波函数本身不能被直接观测。\n\n**波函数的归一化**\n\n$|\\psi(x, y, z, t)|^2$是相对几率密度。\n\n$|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$是t时刻出现在$x, y, z$处$\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$体积元内的相对几率。\n\n$$\n\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z = 1\n$$\n\n为了归一化，选择新的波函数$\\Psi(x, y, z, t)$\n\n$$\n\\Psi(x, y, z, t) = C\\psi(x, y, z, t)\n$$\n\n可得\n\n$$\n|C| = \\frac{1}{\\sqrt{\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z}}\n$$\n\nRemark:\n* 归一化的波函数仍然有一个位相因子不能确定。**习惯上取C为正实数（相角为0）**。\n* 有的波函数不能（有限地）归一。例如平面波$\\Psi(x, t) = e^{-i(Et - px)/\\hbar}$。$|\\Psi(x, t)|^2 = 1$代表了在各处出现的机率相等。\n\n**态的叠加原理（重要）**\n\n若$\\Psi_1, \\Psi_2$是体系的可能状态，那么\n\n$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2\n$$\n\n也是体系的可能状态。\n\n干涉效应：\n\n<!-- Psi, , mathbf -->\n\n$$\n|\\Psi|^2 = |c_1\\Psi_1|^2 + |c_2\\Psi_2|^2 + \\underbrace{ c_1^*c_2\\Psi_1^*\\Psi_2 + c_1c_2^*\\Psi_1\\Psi_2^*}_{干涉项}\n$$\n\n因此，态相加不等于几率相加。\n\n关于相位：\n* 绝对常数相位没有意义\n* 相对常数相位才有意义\n\n$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2 = e^{i\\phi_1}(|c_1|\\Psi_1 + |c_2|e^{\\phi_2 - \\phi_1}\\Psi_2)\\\\\n$$\n\n$|\\Psi|^2$依赖于$\\phi_2 - \\phi_1$\n\n变化的相位是有意义的。(常数相因子可以扔掉)\n\n$$\n\\Psi(\\vec r, t) = |\\Psi(\\vec r, t)|e^{i\\varphi(\\vec r, t)}\n$$\n\n$\\varphi(\\vec r, t)$在空间几率密度上无法反映，但是在动量几率分布上可以反映出来。\n\n**态叠加原理的一般性描述**\n\n对于一个指定的量子体系，如果我们找到了它的“完备的基本状态集合”,那么任何状态都可以由这些基本状态叠加而得到。\n\n$$\n\\Psi = \\sum_n c_n \\Psi_n\n$$\n\n考虑自由粒子平面波的叠加：\n\n$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$\n\n自由电子的任何状态都可以写成：\n\n$$\n\\Psi = \\sum_{\\vec p} c_{\\vec p} \\Psi_{\\vec p}(\\vec r, t)\n$$\n\n又由于动量是连续分布的，改为积分：\n\n$$\n\\Psi = \\int_{\\infty} c({\\vec p}) \\Psi_{\\vec p}(\\vec r, t)\\mathrm d^3 \\vec p\n$$\n\n改写成另一种形式，把时间移到系数中：\n\n$$\n\\Psi = \\int_{\\infty} c({\\vec p, t}) \\Psi_{\\vec p}(\\vec r)\\mathrm d^3 \\vec p\n$$\n其中\n$$\nc(\\vec p,t) = c(\\vec p)e^{-iEt/\\hbar}\\\\\n\\psi_{\\vec p}(\\vec r) = Ae^{i\\vec p \\cdot \\vec r/\\hbar}\n$$\n\n基底称为动量本征函数，满足本征方程：$-ih\\nabla \\psi_{\\vec p}(r) = \\vec p \\psi_{\\vec p}(\\vec r)$。$|c(\\vec p,t)|^2$就是概率密度。\n\n非自由粒子不能做第一种展开，因为含有$V(\\vec r)$项。\n\n固定时刻 $t = t_1$, 此刻波函数为$\\Psi(\\vec r, t_1) = \\Psi(\\vec r)$\n\n则\n\n$$\n\\Psi(\\vec{r}) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\n$$\n\n利用傅里叶变换计算$c(\\vec{p})$。\n\n首先定义delta函数，其满足\n\n$$\n\\delta(x - a) = \\begin{cases}\n    0, &x\\ne a\\\\\n    +\\infty, &x = a\n\\end{cases}\\\\\n\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx = 1\n$$\n\n或者定义为\n\n$$\n\\int\\limits_{\\infty}^{}f(x)\\delta(x - a)\\mathrm dx = f(a)\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx  = f(a)\n$$\n\n其中$\\int_\\infty = \\int_{-\\infty}^{\\infty}$\n\ndelta 函数性质：\n\n$$\n\\delta(x) = \\frac{1}{2\\pi}\\int\\limits_{\\infty}^{0}\\exp(ikx)\\mathrm dk\\\\\n\\delta(\\lambda x) = \\frac{1}{|\\lambda|}\\delta(x)\\ (\\delta \\ne 0)\n$$\n\n利用delta函数进行傅里叶变换：\n\n$$\n\\begin{align*}\n\\Psi(x) &= \\int\\limits_{\\infty}^{}\\Psi(x)\\delta(x - x^\\prime)\\mathrm dx^\\prime\\\\\n&=\\int\\limits_{\\infty}^{}\\Psi(x^\\prime)\\left(\\frac1{2\\pi}\\int\\limits_{\\infty}^{}e^{ik(x - x^\\prime)}\\mathrm dk\\right)\\mathrm dx^\\prime\\\\\n&= \\int\\limits_{\\infty}^{}\\left(\\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x^\\prime)e^{-ikx^\\prime}\\mathrm dx^\\prime\\right)e^{ikx}\\mathrm dk\n\\end{align*}\n$$\n\n因而\n\n$$\nc(k) = \\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x)\\exp({-ikx})\\mathrm dx\\\\\n\\Psi(x) = \\int\\limits_{\\infty}^{}c(k)\\exp(ikx)\\mathrm dk\n$$\n\n记$\\psi_p = \\frac{1}{ \\sqrt{2\\pi \\hbar} }\\exp\\left(i\\frac{p}{\\hbar}x\\right)$\n\n则\n\n$$\n\\Psi(x) = \\int\\limits_{-\\infty}^{\\infty}c(p)\\psi_p(x)\\mathrm dp\\\\\nc(p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_p^*(x)\\Psi(x)\\mathrm dx\n$$\n\n推广到三维：\n\n$$\n\\Psi(\\vec r) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r)\\mathrm dx\\mathrm dy\\mathrm dz\n$$\n\n加入时间：\n\n\n$$\n\\Psi(\\vec r, t) = \\int\\limits_{\\infty}^{}c(\\vec p, t)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p, t) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r, t)\\mathrm dx\\mathrm dy\\mathrm dz\n$$\n\n已知$c(\\vec p, t)$可以求出动量概率密度和坐标概率密度。\n\n#### 薛定谔方程\n\n**几率流密度**\n\n几率密度：\n\n$$\nw(\\vec{r}, t) = |\\Psi(\\vec{r}, t)|^2\n$$\n\n几率密度的时间变化率与某种“流”有关，类比电荷守恒方程：电荷密度的变化率等于电流密度散度的相反数。我们从薛定谔方程推导几率流密度：\n\n$$\n\\begin{align*}\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} &= -\\frac{\\hbar^2}{2\\mu} \\nabla^2\\Psi + U\\Psi \\Rightarrow\\\\\n    \\frac{\\partial w}{\\partial t} &= \\Psi^*\\frac{\\partial \\Psi}{\\partial t} + \\Psi\\frac{\\partial \\Psi^*}{\\partial t} \\\\\n    &= \\frac{i\\hbar}{2\\mu}(\\Psi^*\\nabla^2\\Psi - \\Psi\\nabla^2\\Psi^*)\\\\\n    &= \\frac{i\\hbar}{2\\mu} \\nabla \\cdot (\\Psi^*\\nabla\\Psi - \\Psi\\nabla\\Psi^*)\\\\\n\\end{align*}\n$$\n\n$$\n\\frac{\\partial w}{\\partial t} + \\nabla \\cdot \\vec J = 0\n$$\n\n从而可以定义\n\n$$\n\\vec J = \\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$\n\n对应的可以推积分形式：\n\n$$\n\\frac{\\mathrm dW_v}{\\mathrm dt} = - \\oint_S \\vec{J} \\cdot \\mathrm{d} \\vec S\n$$\n\n$\\vec J$便于记忆可写成\n\n$$\n\\vec J = \\text{Re}\\left[\\Psi^* \\mathrm {\\hat v} \\Psi\\right]\n$$\n\n其中 $\\mathrm{\\hat v} = \\frac{\\vec{p}}{\\mu}$ 称为速度算符。\n\n可以计算电流密度\n\n$$\n\\vec J_e = e\\vec J = e\\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$\n\n可以计算原子内部电子的电流，计算超导体等量子系统的电流。\n\n例：平面波的几率流密度为$\\vec J = w \\vec v$\n\n全空间总几率守恒：\n<!-- oint j -->\n$$\n\\frac{\\mathrm d}{\\mathrm dt} W = -\\oint_\\infty \\vec J \\cdot \\mathrm{d}\\vec S = -\\frac{i\\hbar}{2\\mu}  \\oint(\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi) \\cdot \\mathrm{d}\\vec S = 0\n$$\n\n这里认为波函数在无穷远处为0.\n\n如果粒子波函数在开始时刻是归一化的，则以后一直有归一化。\n\n**定态**\n\n定态波函数=定态薛定谔方程乘以时间因子\n\n$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{h} Et}\\psi(\\vec r)\n$$\n\n$\\psi(\\vec r)$满足 $H\\psi(\\vec r) = E\\psi(\\vec r)$\n\n**定态薛定谔方程**\n\n$$\nH\\psi(\\vec r) = E\\psi(\\vec r)\n$$\n\n$E$ 称为 $H$ 的本征值，$\\psi(\\vec r)$ 称为 $H$ 的本征函数。\n\n**含薛定谔方程的一般解**\n\n含时方程：$i\\hbar \\frac{\\partial \\Psi}{\\partial t} = H\\Psi$\n\n定态方程： $H\\psi(\\vec r) = E\\psi(\\vec r)$\n\n一般解：$\\Psi(\\vec r, t) = \\sum_n c_n\\psi_n(\\vec r)e^{-\\frac{i}{h}E_n t}$\n\n定态下几率密度，几率流密度，力学几率分布和平均值都不随时间变化。\n\n一维自由粒子定态的基本解：\n\n$$\n\\psi = e^{i\\frac{p}{\\hbar}x} = e^{\\pm ikx}(p = \\pm \\hbar k, k = \\sqrt{\\frac{2\\mu E}{\\hbar})}\n$$\n\n能量给定后，状态并非唯一的（能量的简并），但是动量给定后，状态却是唯一的。\n\n**波函数应当满足以下三个条件**\n\n* 单值性\n* 有限性\n* 连续性\n\n连续性一般意味着 $\\Psi$ 和 $\\nabla\\Psi$ 都连续，但是在势能无穷大的地方，允许 $\\nabla\\Psi$ 不连续。\n\n#### 一维无限深势阱\n\n![alt](../images/量筒/4——1.jpg)\n\n<font color='red'>注意，这里的能量本征态不是动量本征态！这里的动量是连续的。因为波函数在0到a的范围内为三角函数，而在范围外为0，并不是周期函数，做傅里叶变换可知动量的图谱是连续的。</font>\n\n#### 一维谐振子\n\n![alt](../images/量筒/4_2.jpg)\n\n#### 势垒穿透\n\n![alt](../images/量筒/5_1.jpg)\n\n### 第三章\n\n#### 动量算符和角动量算符\n\n**厄米算符**\n\n$$\n\\int_{}^{}\\psi^*(\\hat F \\varphi) \\cdot \\mathrm d\\tau = \\int_{}^{}(\\psi\\hat F)^*\\varphi \\cdot \\mathrm d\\tau\n$$\n\n厄米算符的本征值都是实数。\n\n**一维动量本征函数**\n\n$$\n\\hat p = -i\\hbar \\frac{\\mathrm d}{\\mathrm dx},\\\\\n\\hat p \\psi_p = p \\psi_p,\\\\\n\\psi_p = C \\exp\\big(\\frac{ipx}{\\hbar}\\big)\n$$\n\n**三维动量本征函数**\n\n$$\n\\psi_{\\vec p}(\\vec r) = \\frac{1}{\\sqrt{(2\\pi\\hbar^3)}}\\exp\\bigg(\\frac{i}{\\hbar}\\vec p \\cdot \\vec r\\bigg)\\\\\n\\int_{\\infty}^{}\\psi_{\\vec p}^*(\\vec r)\\psi_{\\vec p}(\\vec r)\\mathrm d\\tau = \\delta^3(\\vec p - \\vec p^\\prime)\n$$\n\n箱归一化本征函数：\n\n$$\n\\psi_{p}(-L / 2) =\\psi_{p}(L/2)\\\\\np = \\frac{2\\pi \\hbar}{n}, n=0, \\pm1, \\pm2, \\dots\\\\\n\\int_{-L/2}^{L/2}\\psi_{p}^*(x)\\psi_{p}(x)\\mathrm dx = \\delta_{pp^\\prime}\\\\\nL \\rightarrow \\infty\n$$\n\n**角动量算符**\n\n角动量算符的定义是：\n\n$$\n\\hat {\\vec L} = \\hat{\\vec r} \\times \\hat{\\vec p} = -i\\hbar \\vec r \\times \\nabla\\\\\n\\hat{L_x} = \n$$\n\n球坐标形式：\n\n球坐标单位向量用直角坐标表示：\n\n\n$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\n$$\n\n本征函数：\n\n$$\n\\psi_{m}(\\varphi) = C \\exp(im\\varphi)\n$$\n\n由于单值性 $\\psi_m(\\varphi + 2\\pi) = \\psi_m(\\varphi)$：\n\n$$\nm = 0, \\pm1, \\pm2, \\dots\n$$\n\n归一化：$C = \\frac{1}{\\sqrt{2\\pi}}$\n\n结论：\n\n$$\n\\hat L_z \\psi_m = m\\hbar \\psi_m\\\\\nm = 0, \\pm1, \\pm2, \\dots\n\\psi_m(\\varphi) = \\frac{1}{\\sqrt{2\\pi}} \\exp(im\\varphi)\n$$\n\n由于空间的任意一个方向都可以为z方向，因此角动量的任一分量都可以量子化。\n\n$$\n\\hat L^2 = -\\hbar^2\\bigg[\\frac{1}{\\sin \\theta}\\frac{\\partial }{\\partial \\theta}\\bigg(\\sin\\theta\\frac{\\partial }{\\partial \\theta}\\bigg) + \\frac{1}{\\sin^2\\theta}\\frac{\\partial^2}{\\partial \\varphi^2}\\bigg]\n$$\n\n$$\n\\hat L^2Y = \\lambda \\hbar^2Y\\\\\nY(\\theta, \\varphi) = P(\\theta)\\exp(im\\varphi)\n$$\n\n省流：球谐函数\n\n$$\nY_{lm}(\\theta, \\varphi) = N_{lm}P_l^m(\\cos \\theta)\\exp(im\\varphi)\n$$\n\n归一化系数\n\n$$\nN_{lm} = (-1)^m\\sqrt{\\frac{(2l + 1)}{4\\pi}\\frac{(l - |m|)!}{(l + |m|)!}}\n$$\n\n勒让德函数：\n\n$$\nP(w) = \\frac{1}{2^l l!}(1 - w^2)^{|m| / 2}\\frac{\\mathrm d^{l+|m|}}{\\mathrm dw^{l+|m|}}(w^2 - 1)^l\n$$\n\n前几个球谐函数：\n\n$$\nY_{00} = \\sqrt{\\frac{1}{4\\pi}}\\\\\nY_{10} = \\sqrt{\\frac{3}{4\\pi}}\\cos \\theta\\\\Y_{1, \\pm1} = \\mp \\sqrt{\\frac{3}{8\\pi}}\\sin \\theta \\exp(\\pm i\\varphi)\\\\\n$$\n\n$l = 1$，是 $L^2$ 和 $L_z$ 的共同本征态，但不是 $L_x$ 和 $L_y$ 的本征态,(不确定性原理决定了这三个分量不能同时有本征态)\n\n**球谐函数的性质**\n\n$$\n\\hat L^2 Y_{lm} = l(l+1)\\hbar^2 Y_{lm}\\\\\n\\hat L_z Y_{lm} = m\\hbar Y_{lm}\\\\\nl = 0, 1, 2, \\dots\\\\\nm = l, l - 1, \\dots, -l.\n$$\n\n正交归一性：\n\n$$\n\\int Y^*_{l^\\prime m^\\prime}(\\theta, \\varphi)Y_{lm}(\\theta, \\varphi) \\mathrm d\\Omega = \\delta_{l^\\prime l}\\delta_{m^\\prime m}\n$$\n\n$$\nY^*_{lm}(\\theta, \\varphi) = (-1)^m Y_{l, -m}(\\theta, \\varphi)\n$$\n\n#### 中心力场的运动，氢原子\n\n经典：\n\n$$\nH = \\frac{1}{2}m_N\\dot{\\vec r_N^2} + \\frac{1}{2}m_e\\dot{\\vec r_e^2} + U(|\\vec r_e - \\vec r_N|)\n$$\n\n采用质心坐标和相对坐标：\n\n$$\n\\vec R = \\frac{m_N\\vec r_N + m_e \\vec r_e}{m_N + m_e}\\\\\n\\vec r = \\vec r_e - \\vec r_N\\\\\nM = m_N + m_e\\\\\n\\mu = \\frac{m_Nm_e}{M}\n$$\n\n$$\nH = \\frac{1}{2}M\\dot{\\vec R^2} + \\frac{1}{2}\\mu \\dot{\\vec r^2} + U(r)\\\\\n\\rArr H = \\frac{\\vec p_R^2}{2M} + \\frac{\\vec p^2}{2\\mu} + U(r)\n$$\n\n量子化：\n\n$$\nH = -\\frac{\\hbar^2}{2M}\\nabla_R^2 - \\frac{\\hbar}{2\\mu}\\nabla^2 + U(r)\n$$\n\n相对运动的动量意义是什么？\n\n求解氢原子波函数时，将哈密顿量分解为质心的哈密顿算符和相对坐标的哈密顿算符，然后分别求解。相对坐标对应的哈密顿算符求解得到的才是氢原子波函数。因此，**得到的氢原子的能量不包括质心运动的能量。**\n\n省流：氢原子波函数\n\n$$\n\\psi_{nlm} = R_{nl}(r) Y_{lm}(\\theta, \\phi)\n$$\n\n其中径向函数\n\n$$\nR_{nl}(r) = \\frac{u_{nl}(r)}{r}, \\rho = \\alpha r\\\\\nu_{nl}(r) = N_{nl} \\rho^{l + 1}(\\rho) v_{nl}(\\rho) \\exp(-\\frac{1}{2}\\rho)\n$$\n\n$$\n主量子数\\quad n = 1, 2, 3,\\dots, \\rightarrow E_n = \\frac{E_1}{n^2}\\\\\n角量子数\\quad l = 0, 1, \\dots, n -1, \\rightarrow L^2 = l(l + 1)\\hbar^2\\\\\n磁量子数\\quad m = l, l - 1, \\dots, -l, \\rightarrow L_z = m\\hbar\\\\\n简并度\\quad g_n =\\sum\\limits_{l=0}^{n - 1}(2l + 1) = n^2\n$$\n\n定态波函数的宇称性质：\n\n$$\nR_nl(r) 偶函数，\n$$\n\n![alt](../images/量筒/7_1.jpg)\n\n![alt](../images/量筒/8_1.jpg)\n\n![alt](../images/量筒/8_2.jpg)\n\n![alt](../images/量筒/8_3.jpg)\n\n\n\n电子云有方向性吗？\n\n以 $n = 2$ 为例，$Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 的模平方之和为常数。若氢原子随机等概率激发到 $Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 之一，则无方向性。但如果是相干叠加，则有方向性。\n\n为什么 $m$ 叫做磁量子数？\n\n![alt](../images/量筒/8_4.jpg)\n\n$$\n\\vec J_e = (-e) \\vec J\n$$\n\n#### 本征函数系的一般性质\n\n**正交与归一**\n\n正交性定理\n\n同一个厄密算符 $\\hat F$ 的属于不同本征值的本征函数是彼此正交的。\n\n$$\n\\int_{}^{}\\psi_1^*\\psi_2\\mathrm d\\tau = 0\n$$\n\n本征函数的正交“归一”性\n\n离散情况：\n\n$$\n\\int_{}^{}\\phi_k^*(\\vec r) \\cdot \\phi_l(\\vec r)\\mathrm d\\tau = \\delta_{kl} = \\begin{cases}\n    0, k\\ne l\\\\\n    1, k = l\n\\end{cases}\n$$\n\n连续情况：\n\n$$\n\\int_{}^{}\\phi_{\\lambda^\\prime}^*(\\vec r) \\cdot \\phi_{\\lambda}(\\vec r)\\mathrm d\\tau = \\delta(\\lambda - \\lambda^\\prime)\n$$\n\n并非真正的归一化，但是依然满足正交性：例如 $\\frac{1}{\\sqrt{2\\pi \\hbar}}e^{\\frac{i}{\\hbar}px}$。\n\n**共同本征函数（重点）**\n\n定义对易括号\n\n$$\n[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G \\hat F\n$$\n\n若\n\n$$\n[\\hat F, \\hat G] = 0 \n$$\n\n则两算符对易。\n\n定理：\n\n$$\n[\\hat F, \\hat G] = 0 \\Rightarrow 两个算符有组成完全系的共同本征函数\n$$\n\n$$\n[\\hat {p_z}, \\hat {p_x}] = [\\hat {p_x}, \\hat {p_y}] = [\\hat {p_y}, \\hat {p_z }] = 0\n$$\n\n它们有共同的本征函数。\n\n$$\n[\\hat {xp}, \\hat {px}] = i\\hbar\n$$\n\n没有共同的本征函数。\n\n如果 $[\\hat {F}, \\hat {G}] \\ne 0$，则不一定没有共同本征态。例如角动量的本征态 $Y_{00}$。\n\n$$\n[\\hat {L^2}, \\hat {L_i}] = 0\\\\\n[\\hat {L_x}, \\hat {L_y}] = i\\hbar \\hat L_z\n$$\n\n性质：\n\n$$\n[A, BC] = [A, B]C + B[A, C]\n$$\n\n简并：力学量 $F$ 的一个本征值对应多个线性无关的本征函数。\n\n**力学量完全集（完备算符集）**\n\n为了消除简并，可以选取一组彼此对易的力学量 $F_1, F_2, F_3, \\dots$，使得它们的本征值组 $\\lambda_1, \\lambda_2, \\dots$ 对应唯一一个线性无关的共同本征函数 $\\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)$\n\n称 $F_1, F_2, F_3, \\dots$ 为力学量完全集。\n\n$$\nF_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r) = \\lambda_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)\n$$\n\n实现了正交化：力学量完全集的共同本征函数必然为正交函数系，因为任意两个本征函数，对应的本征值必然不同，由正交性定理得知，两个本征函数必然正交。\n\n**常见的选取方式**\n\n对于三维空间的单粒子，可以选取为：\n\n* $(x, y, z)$\n* $(p_x, p_y, p_z)$\n* $(H, L^2, L_z)$（对于氢原子适用）\n\n考虑自旋后，还需要增加自旋力学量构成完全集。\n\n#### 力学量的平均值公式\n\n$$\n\\overline{F(t)} = \\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx\n$$\n\n若没有归一化：\n\n$$\n\\overline F = \\frac{\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx}{\\int_{}^{}\\psi^*(x, t) \\psi(x, t)\\mathrm dx}\n$$\n\n实际上， 利用本征函数的正交性\n\n$$\n\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx =\\sum\\limits_{n}^{}\\lambda_n |c_n|^2 = \\overline{F}\n$$\n\n几率幅函数\n\n$$\nc_n(t) = \\int_{}^{}\\phi_n^*(x)\\psi(x, t)\\mathrm dx\n$$\n\n例题：\n\n$$\n\\psi = Ae^{ikx} + Be^{-ikx}\\\\\n$$\n\n动量值 $\\hbar k$ 与 $-\\hbar k$ 的概率比值为 $\\frac{|A|^2}{|B|^2}$\n\n$$\n\\bar p = \\hbar k  \\frac{|A|^2}{|A|^2 + |B|^2} + (-\\hbar k ) \\frac{|B|^2}{|A|^2 + |B|^2} = \\frac{|A|^2 - |B|^2}{|A|^2 + |B|^2}\\hbar k\n$$\n\n#### 不确定关系\n\n一维谐振子为例：\n\n$$\n\\psi_(x) = \\sqrt{\\frac{\\alpha}{\\sqrt \\pi}} e^{-\\frac{1}{2}\\alpha^2 x^2}\\\\\nc_p = \\sqrt{\\frac{\\beta}{\\sqrt \\pi}}e^{-\\frac{\\beta^2p^2}{2}}\\\\\n\\frac{1}{\\alpha} \\cdot \\frac{1}{\\beta} = \\frac{1}{\\hbar}\\\\\n\\alpha = \\sqrt{\\frac{\\mu \\omega}{\\hbar}}\n$$\n\n不确定关系的数学表达以及证明\n\n如果两个力学量F和G的算符彼此不对易，则它们有不相容性，测量精确度（不确定度）上一般是相互制约的。\n\n$$\n\\Delta \\hat F = \\hat F - \\overline{ } F\\\\\n\\overline{(\\Delta \\hat F)^2} = \\overline{(\\hat F - \\overline{F})^2} = \\overline{\\hat F^2} - \\overline{F}^2\n$$\n\n记 $[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G\\hat F = i\\hat C$，则在任意一个状态下\n\n$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$\n\n这里 $\\hat F$ 与 $\\hat G$ 都是厄密算符，所以 $\\overline{\\hat C}$ 为实数\n\n引入\n\n$$\nI(\\xi) = \\int_{}^{}\\left | (\\xi\\Delta \\hat F - i\\Delta \\hat G  )\\psi^2\\right|^2\\mathrm d\\tau \\ge 0\n$$\n\n$$\n\\begin{align*}\n    I(\\xi) =& \\xi^2\\int_{}^{}(\\Delta \\hat F \\psi)^* (\\Delta \\hat F \\psi)\\mathrm d\\tau - i\\xi \\int_{}^{}[(\\Delta \\hat F \\psi)^*(\\Delta \\hat G \\psi) - (\\Delta \\hat G \\psi)^*(\\Delta \\hat F \\psi)]\\mathrm d\\tau + \\int_{}^{}(\\Delta \\hat G\\psi)^*(\\Delta \\hat G\\psi)\\mathrm d\\tau\\\\\n    =& \\xi^2 \\int_{}^{}\\psi^*(\\Delta \\hat F)^2\\psi\\mathrm d\\tau - i\\xi \\int_{}^{}\\psi^*\\Delta\\hat F\\Delta \\hat G\\psi - \\psi^*\\Delta \\hat G\\Delta \\hat F\\psi\\mathrm d\\tau + \\int_{}^{}\\psi^*(\\Delta \\hat G)^2 \\psi\\mathrm d\\tau\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i\\overline{\\Delta \\hat F\\Delta \\hat G - \\Delta \\hat G \\Delta \\hat F}\\cdot \\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat { F}, \\hat { G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - \\overline{\\hat C}\\xi + \\overline{(\\Delta \\hat G)^2}\n\\end{align*}\n$$\n\n由于此式恒正，判别式大于0：\n\n$$\nI(\\xi) \\ge 0 \\Rightarrow \\overline{(\\Delta \\hat C)}^2 - 4\\overline{(\\Delta \\hat F)^2}\\cdot \\overline{(\\Delta \\hat G)^2} \\ge 0\n$$\n\n$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$\n\n如果要满足取等号条件：\n\n$$\n(\\xi \\Delta \\hat F - i \\Delta \\hat G)\\psi = 0\n$$\n\n此时的波包称为最小不确定波包\n\n位置动量不确定关系：\n\n$$\n\\overline{(\\Delta \\hat x)^2} \\overline{(\\Delta \\hat p_x) ^2} \\ge \\frac{\\hbar^2}{4}\n$$\n\n非零的“零点能”是不确定性关系的结果。\n\n$$\n\\overline E = \\frac{1}{2\\mu}\\overline{(\\Delta \\hat p_x)^2} + \\frac{1}{2}\\mu \\omega\\overline{(\\Delta \\hat x)^2} \\ge \\frac{1}{2}\\hbar\\omega\\\\\n\\overline E_{min} = \\frac{1}{2}\\hbar\\omega\\\\\n$$\n\n势垒穿透问题：谈论某一点的动能 T 和总能量 E 没有意义，因为 $\\hat x, \\hat T, \\hat H$ 彼此不对易。\n\n$H, T, U$ 三个物理量之间彼此不对易，不能同时具有确定的值。故 $H = T + U$ 只是一个算符的等式。\n* 若为定态，则 $H$ 确定而 $T, U$ 不确定\n* 若位置确定，则 $U$ 确定但是 $T$ 和 $E$不确定\n\n求平均值：\n\n$$\n\\overline H = \\overline{ T} + \\overline U\n$$\n\n$T$ 的本征值为非负实数，所以\n\n$$\n\\overline{H} \\ge \\overline{ U}\n$$\n\n角动量 $Y_{00}$ 情形下，三个分量都具有确定的取值，三个角动量分量都为 0，还是满足不确定性关系。\n\n#### 守恒量\n\n要求任意态下 $F$ 平均值不变。\n\n平均值的时间演化\n\n$$\n\\hat H = i\\hbar \\frac{\\partial }{\\partial t}\n$$\n\n若算符 $\\hat F$ 不显含时间，则\n\n$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]}\n$$\n\n若 $\\hat F(t)$ 显含时间，则\n\n$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]} + \\overline{\\frac{\\partial }{\\partial t}\\hat F(t)}\n$$\n\n### 第四章\n\n####  狄拉克算符和谐振子升降算符\n计算本征值问题\n\n谐振子：\n\n$$\nH = \\hbar \\omega \\frac{1}{2} \\left ( \\frac{p^2}{m\\hbar\\omega} + \\frac{m\\omega^2x^2}{\\hbar\\omega} \\right)\\\\\n\\alpha \\equiv \\sqrt{\\frac{m\\omega}{\\hbar}}\\\\\np^\\prime = \\frac{1}{\\hbar \\alpha}p\\\\\nx^\\prime = \\alpha x\\\\\n[\\hat {x^\\prime}, \\hat {p^\\prime}] = i\n$$\n\n$$\nH = \\hbar\\omega\\frac{1}{2}[(x^\\prime - ip^\\prime)(x^\\prime + ip^\\prime) + 1]\\\\\np^\\prime = -i \\frac{\\mathrm d}{\\mathrm dx^\\prime}\n$$\n\n基态满足\n\n$$\n(x^\\prime + ip^\\prime)\\psi_0(x) = 0\n$$\n\n通过升算符算出激发态\n\n$$\n\\psi_n = C_n (x^\\prime - ip^\\prime)^n\\psi_0(x)\n$$\n\n换元：\n\n$$\na = \\frac{x^\\prime + ip^\\prime}{\\sqrt{2}}\\\\\na^+ = \\frac{x^\\prime - ip^\\prime}{\\sqrt{2}}\\\\\nH = \\hbar \\omega(a^+a + \\frac{1}{2}) = \\hbar \\omega(\\hat N + \\frac{1}{2})\\\\\n[a, a^+] = 1\n$$\n\n设 $\\hat N$ 的本征矢为 $\\ket{n}$，称$n$为占有数。可以看出这本征矢也是能量的本征态。\n\n接下来计算 $\\hat N$ 的本征矢：\n\n$$\n\\langle \\hat N \\rangle = \\bra{n}a^+a\\ket{n} \\ge 0\\\\\n\\bra{n}a^+a\\ket{n} = n \\langle n|n \\rangle\\\\\n\\Rightarrow n \\ge 0\n$$\n\n如果存在 $n = 0$ 的态：\n\n$$\n\\bra{0}a^+a\\ket{0} = 0\\\\\n\\Rightarrow a\\ket{0} = 0\n$$\n\n这就是基态满足的微分方程。解出基态的坐标表象：\n\n$$\n(\\alpha x + \\frac{1}{\\alpha} \\frac{\\mathrm d}{\\mathrm dx})\\psi_0(x) = 0\n$$\n\n重点：升降性质\n\n$a\\ket{n} = \\ket{\\phi} = \\ket{n - 1}$ 也是本征态。\n\n$$\n\\hat N \\ket{\\phi} = (a^+a)\\ket{\\phi} = (aa^+ - 1)\\ket{\\phi} = (aa^+ - 1)a\\ket{n} = aa^+a\\ket{n} - a\\ket{n} = a\\hat N\\ket{n} - a\\ket{n} = na\\ket{n} - a\\ket{n} = (n - 1)\\ket{\\phi}\n$$\n\n归一化：\n\n$$\n\\ket{\\phi} = c\\ket{n - 1}\\\\\n1 = \\langle n - 1 |n - 1 \\rangle = \\frac{1}{|c|^2}(an, an) = \\frac{1}{|c|^2}\\bra{n}a^+a\\ket{n} = \\frac{n}{|c|^2}\\\\\n取 c = \\sqrt{n}\\\\\na\\ket n = \\sqrt{n}\\ket{n - 1}\n$$\n\n升降算符（重点）：\n\n$$\na\\ket n = \\sqrt{n}\\ket{n - 1}\\\\\na\\ket{0} = 0\\\\\na^+\\ket{n} = \\sqrt{n + 1}\\ket{n + 1}\n$$\n\n$n$ 必为整数。\n\n能级：\n\n$$\nH = \\hbar \\omega(a^+a + \\frac{1}{2})\\\\\nE_n = \\hbar\\omega(n + \\frac{1}{2})\n$$\n\n波函数：\n\n$$\n\\ket n = \\frac{1}{\\sqrt{n}}a^+\\ket{n - 1} = \\frac{1}{\\sqrt{n!}}a^{+n}\\ket{0}\\\\\n\\psi_n(x) = \\frac{1}{\\sqrt{n!}}\\left (\\frac{1}{\\sqrt{2}}\\left (\\alpha x - \\frac{1}{\\alpha}\\frac{\\mathrm d}{\\mathrm dx}  \\right)  \\right)^n \\frac{\\sqrt{\\alpha}}{\\pi^{1/4}}e^{-\\alpha^2x^2/2}\n$$\n\n相干态：满足 $\\hat a \\ket \\beta = \\beta \\ket \\beta$ 的 $\\ket \\beta$。\n\n#### 海森堡方程\n\n力学量算符含时，波函数不含时\n\n$$\n\\bra{\\psi(t)} F\\ket {\\psi(t)} \\rightarrow \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$\n\n不同图景在物理上等价\n\n$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{\\hbar}Ht}\\Psi(\\vec r, 0)\\\\\n\\ket{\\psi(t)} = U\\ket {\\psi(0)}\n$$\n\n力学量平均值\n\n$$\n\\overline{F} = \\bra{\\psi(t)}F\\ket{\\psi(t)} = \\bra{\\psi(0)}U^+FU\\ket{\\psi(0)} = \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$\n\n海森方程\n\n$$\nF_H = U^+(t)FU(t), U = e^{-\\frac{i}{\\hbar}Ht}, U^+ = e^{\\frac{i}{\\hbar}Ht}\\\\\n\\frac{\\mathrm d}{\\mathrm dt}U = \\frac{1}{i\\hbar}HU, \\frac{\\mathrm d}{\\mathrm dt}U^+ = -\\frac{1}{i\\hbar}HU^+, \\\\\n\\frac{\\mathrm d}{\\mathrm dt}F_H = \\frac{1}{i\\hbar}[F_H, H]\\\\\n\\frac{\\mathrm d\\ket{\\psi}_H}{\\mathrm dt} = 0\n$$\n\n$$\nHU = UH\n$$\n\n从经典到量子：\n\n$$\n\\dot q = \\frac{1}{i\\hbar}[q, H]\\\\\n\\dot p = \\frac{1}{i\\hbar}[p, H]\\\\\n[q, p] = i\\hbar\n$$\n\n#### 自旋\n\n用标量波函数 $\\Psi(\\vec r, t)$ 描述是否完整？\n\n经典力学给出了轨道磁矩和磁势能\n\n$$\n\\vec M_L = -\\frac{e}{2m_e}\\vec L\\\\\nU = - \\vec M \\cdot \\vec B\n$$\n\n磁矩的最小单元(Bohr磁子)\n\n$$\nM_B \\equiv \\frac{e\\hbar}{2m_e}\n$$\n\nStern-Gerlach 实验：即使是 $l = 0$ 的 $s$ 态原子也会在磁场中偏转。认为电子除了轨道磁矩，还有自旋磁矩。\n\n自旋磁矩只有两个可能的值：\n\n$$\nM_B \\equiv \\frac{2\\hbar}{2m_e}\\\\\nM_z = \\pm M_B\n$$\n\nUhlenbeck-Goudsmit假设(1925)：电子有内禀（自旋）角动量，其投影只能取两个值：\n\n$$\nS_i = \\pm \\frac{\\hbar }{2}, i = x, y , z\n$$\n\n自旋磁矩：\n\n$$\n\\hat {\\vec M_s} = -\\frac{e}{m_e}\\hat{\\vec S}\n$$\n\n自旋有纯量子力学的起源。没有经典对应，独立于之前学过的所有力学量。\n\n自旋的分量只有两个可能的测量值，因此可以使用 $2\\times 2$ 的矩阵描写。\n\n$S_z$的本征值为 $\\pm \\frac{\\hbar}{2}$，采用 $S_z$ 表象，则 $S_z = \\frac{\\hbar}{2}\\begin{pmatrix}\n    1 &0\\\\\n    0 &-1\n\\end{pmatrix}$\n\n根据角动量的对易关系（假设的）\n\n$$\n[S_x, S_y] = i\\hbar S_z\\\\\n[S_y, S_z] = i\\hbar S_x\\\\\n[S_z, S_x] = i\\hbar S_y\n$$\n\n可以导出 $S_x$ 和 $S_y$\n\n$$\nS_x = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\n\\end{pmatrix}\\\\\nS_y = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & -i\\\\\n    i & 0\n\\end{pmatrix}\\\\\nS_z = \\frac{\\hbar}{2}\\begin{pmatrix}\n    1 & 0\\\\\n    0 & -1\n\\end{pmatrix}\\\\\n$$\n\n三个分量不对易，最多只有一个分量具有确定的取值\n\n$$\nS_x^2 = S_y^2 = S_z^2 = \\frac{\\hbar^2}{4}\\\\\nS^2 = \\frac{3\\hbar^2}{4} = s(s + 1)\\hbar^2\\\\\n(s = \\frac{1}{2})\\\\\n[S^2, S_i] = 0\n$$\n\n自旋是内部基本构造，不同于先前学过的力学量，不能写成 $F(\\vec r, \\vec p)$ 的形式\n\n自旋也不能简单看成绕自身某个轴的旋转（电子被当作“点粒子”，自旋不同于经典物体的旋转，量子自旋没有经典的对应）\n\n带有自旋的电子波函数（自旋 + 空间坐标）\n\n$$\nv_+ = \\begin{pmatrix}\n    1\\\\0\n\\end{pmatrix}\nv_- = \\begin{pmatrix}\n    0\\\\1\n\\end{pmatrix}\n\n\\Psi(\\vec r, t) \\cdot v_+ + \\Psi_2(\\vec r, t) \\cdot v_-\n$$\n\n波函数有两个自旋分量（类比于电磁波有两个偏振分量）\n\n又被称为旋量波函数\n\n$$\n\\Psi = \\begin{pmatrix}\n    \\Psi_1(\\vec r, t)\\\\\n    \\Psi_2(\\vec r, t)\n\\end{pmatrix}\\\\\nw(\\vec r, t) = \\Psi^+\\Psi = |\\Psi_1|^2 + |\\Psi_2|^2\\\\\n\\int_{}^{}\\Psi^+\\Psi\\mathrm d\\tau = \\int_{}^{}(|\\Psi_1|^2 + |\\Psi_2|^2)\\mathrm d\\tau = 1\n$$\n\n自旋角动量的几率分布\n\n$$\nW \\left ( \\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_1|^2\\mathrm d\\tau\\\\\nW \\left ( -\\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_2|^2\\mathrm d\\tau\\\\\n$$\n\n### 第五章 微扰论\n\n$$\n\\hat H \\psi_n = E_n \\psi_n\\\\\n\\hat H = \\hat H^{(0)} + \\hat H^\\prime\n$$\n\n作逐级展开：\n\n$$\n\\psi_n = \\psi_n^{(0)} + \\psi_n^{(1)} + \\psi_n^{(2)} + \\cdots\\\\\nE_n = E_n^{(0)} + E_n^{(1)} + E_n^{(2)} + \\cdots\\\\\n$$\n\n得到零级，一级，二级方程\n\n$$\n\\hat H^{(0)} \\psi_n^{(0)} = E_n^{(0)}\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(1)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(2)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(1)} + E_n^{(2)}\\psi_n^{(0)}\\\\\n$$\n\n#### 能量的非简并情形\n\n结论：能级一级修正\n\n$$\nE_n^{(1)} = H^\\prime_{nn} = \\int_{}^{}\\psi_n^{(0)*}\\hat{H}^\\prime\\psi_n^{(0)}\\mathrm d\\tau\n$$\n\n波函数一级修正\n\n$$\n\\psi_n(x) = \\psi_n^{(0)}(x) + \\psi_n^{(1)}(x)\\\\\n\\psi_n^{(1)}(x) =\\sum\\limits_{m\\ne n}^{}\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}}\\psi_m^{(0)}(x)\n$$\n\n适用条件：\n\n$$\n\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}} << 1\n$$\n\n二级能量修正公式：\n\n$$\nE_n^{(2)} =\\sum\\limits_{m\\ne n}^{}\\frac{|H_{mn}^\\prime|^2}{E_n^{(0)} - E_m^{(0)}}\n$$\n\n#### 零级能量的简并情形\n\n需要确定适当的零级波函数，可以通过对初始的0级波函数进行表象变换得到。\n\n$$\n\\psi_{ni}^{(0)} =\\sum\\limits_{l=1}^{k}c_{li}^{(0)}\\phi_{nl}^{(0)}\n$$\n\n通过哈密顿量的修正值 $H^\\prime$ 来确定 0 级波函数的选取。1级方程左右同乘 $\\phi_l^{(0)*}$ 并积分，可得（下面的方程没有写n，表示都是同一个能级，系数c的下标对应1~k）\n\n$$\nH^\\prime C^{(0)} = E_n^{(1)}C^{(0)}\\\\\nH^\\prime_{ji} = \\int_{}^{}\\phi_j^{(0)*}\\hat H^\\prime\\phi_i^{(0)}\\mathrm d\\tau\\\\\nC^{(0)} = \\begin{pmatrix}\n    c_1^{(0)}\\\\c_2^{(0)}\\\\\\dots\\\\c_k^{(0)}\n\\end{pmatrix}\n$$\n\n对所有的 $l$ 做上述操作，求出所有的新的零级波函数。\n\n$H^\\prime$ 在 $E_n^{(0)}$ 对应的简并态子空间的 $k$ 个本征向量决定新的零级波函数 $\\psi_n^{(0)}$。对应的 $k$ 个本征值表示一级能量修正 $E_n^{(1)}$。这些一级能量互不相同，使得 $E_n^{(0)} + E_n^{(1)}$有 $k$ 个不同的值，也就是说零级加一级能量是“非简并态”。\n\n（这样做有什么意义？）\n\n简并微扰波函数的一级修正：\n\n$$\nc_{ml}^{(1)} = \\frac{\\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime \\psi_{nl}^{(0)}\\mathrm d\\tau}{E_n^{(0)} - E_m^{(0)}}\\\\\n\\psi_{nl}^{(1)} =\\sum\\limits_{m\\ne n}^{}c_{ml}^{(1)}\\phi_m^{(0)}\n$$\n\n注意！其中 $\\phi_m^{(0)}$ 是 $E_n^{(0)}$ 能级以外的态，这些态可以是简并的。\n\n能量的二级修正：\n\n$$\nE_{nl}^{(2)} =\\sum\\limits_{m\\ne n}^{} \\frac{\\left | \\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime\\psi_{nl}^{(0)}\\mathrm d\\tau \\right|^2}{E_n^{(0)} - E_m^{(0)}}\n$$\n\n如果求解的本征值有重根？\n\n此时零级波函数仍然不能求出来，但是可以求出能量一级修正；若考虑能量的二级修正，需要由二级方程确定零级波函数。\n\n#### 外磁场中的原子\n\nZeeman 效应：外磁场中原子的能级会分裂\n\n简单 Zeeman 效应：外磁场作用很强， 可以略去自旋轨道耦合，这就是简单 Zeeman 效应\n\n$$\n\\vec M = \\vec M_L  + \\vec M_s \\approx -\\frac{e}{2\\mu}(\\vec L + 2\\vec S)\\\\\nU_m = -M_zB = \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\\\\\nH = H_0(氢原子) + \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\n$$\n\n结论：$\\psi_{n,l,m_l,m_s}$ 组成了完全函数系，对应能级为\n\n$$\nE_{n,l,m_l,m_s} = E_n + \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$\n\nZeeman 效应可以调节原子能级，操控原子的量子态，灵敏检测磁场。\n\n如何用微扰论求解？\n\n显然，在上面介绍的波函数正好使得 $H^\\prime$ 成为一个对角矩阵：\n\n$$\n\\bra{\\psi_{n,l,m_l^\\prime,m_s\\prime}} H^\\prime \\ket{\\psi_{n,l,m_l,m_s}} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\\delta_{m_l^\\prime, m_l}\\delta_{m_s^\\prime, m_s}\\\\\nE_{n,l,m_l,m_s}^{(1)} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$\n\n**求自旋轨道耦合产生的精细结构？**\n\n（困难的拓展问题，在课程内不能完全解决）\n\n$$\nH = H_0 + H^\\prime\\\\\nH^\\prime = \\ksi(r)\\vec L \\cdot \\vec s\\\\\n\\ksi(r) = \\left ( \\frac{e^2}{8\\pi\\varepsilon_0} \\right)\\frac{1}{m_e^2c^2r^3}\n$$\n\n采用耦合表象基底 $L^2, L_z, S_z$ 共同本征态\n\n$$\n\\hat Y_{ljm} =\\sum\\limits_{m_lm_s}^{}c(l, j, m;l, m_l, m_s)Y_{lm_l}\\chi_{m_s} = \\ket{l, j, m}\n$$\n\n$$\n\\vec J = \\vec L + \\vec s\\\\\n\\vec L \\cdot \\vec s = \\frac{1}{2}(\\vec J^2 - \\vec L^2 - \\vec s^2)\n$$\n\n$H^\\prime$ 又是一个对角阵：\n\n$$\n\\bra{l^\\prime, j^\\prime, m^\\prime}\\vec L \\cdot \\vec s\\ket{l, j, m} = \\frac{1}{2} \\left [ j(j + 1) - l(l + 1) - \\frac{3}{4} \\right]\\hbar^2\\delta_{ll^\\prime}\\delta_{jj^\\prime}\\delta_{mm^\\prime}\n$$\n\n\n相对论得出的真实的精细结构跟 $l$ 并没有关系。\n\n考虑真空电磁场微扰形成的能级微小移动——兰姆位移。\n\n## 统计力学\n\n### 第一章\n\n平衡态下孤立系统各种微观态的几率相等。\n\n最可几方法求玻色分布和费米分布\n\n求 $W \\lbrace n_i \\rbrace$ 的极大值\n\n$$\n\\bar u = \\frac{\\Sigma u \\lbrace n_i \\rbrace W \\lbrace n_i \\rbrace}{W \\lbrace n_i \\rbrace}\n$$\n\n## 习题课\n\n### 20231028\n\n#### 量子力学基本公理\n\n公理1：希尔伯特空间\n\n公理2：可观测量\n\n公理3：位置与动量（正则量子化）\n\n公理4：薛定谔方程\n\n公理5：全同粒子（略：讲统计时会讲）\n\n概率流密度的公式并不本质。根据薛定谔方程、概率密度公式、连续性方程可以推出。\n\n全空间概率密度$w(t)$不是 $x$ 的函数。\n\n要写盒外波函数为0.\n\n对任意的束缚的能量本征态, 动量的平均值是 0.\n\n$$\n[\\hat {x}, \\hat {H}] = [\\hat {x}, \\hat {p}^2/2\\mu] = \\frac{1}{2\\mu}(\\hat p[\\hat {x}, \\hat {p}] + [\\hat {x}, \\hat {p}]\\hat p) = \\frac{i\\hbar}{\\mu}\\hat p\n$$\n\n$$\n\\int_{-\\infty}^{\\infty}e^{-\\alpha x^2 + \\beta x}\\mathrm dx = \\sqrt{\\frac{\\pi}{\\alpha}}e^{\\beta^2/4\\alpha}\n$$\n\n### 20231112\n\n![](../images/量筒/xt_2_1.jpg)\n\n$$\n\\mu = -\\frac{e}{m}S\\\\\nU = - \\mu \\cdot B = -\\dfrac{eB}{m}S \\cdot n =\n$$\n\n![](../images/量筒/xt_2_2.jpg)\n\n透射率，反射率计算（用流密度）\n\n","source":"_posts/量筒.md","raw":"---\ntitle: 量筒\ndate: 2023-09-20 08:06:16\ntags: note\nkatex: true\n---\n\n## 量子力学\n\n### 第一章 引言\n\n光的粒子性：\n* 黑体辐射\n* 光电效应\n* 康普顿散射\n\n原子模型：能级和跃迁\n\n电子衍射：例子的波动性\n\n黑体辐射的解释：\n\n#### 普朗克公式\n\n已知\n\n$$\nP(\\varepsilon_\\nu = nh\\nu) \\propto e^{-\\varepsilon_{\\nu}/kT}\n$$\n\n平均光子数\n$$\n\\overline{n} = \\frac{1}{e^{hv/kT} - 1}\\\\\n$$\n\n又知一个光子的能量$h\\nu$，模式密度（单位频率间隔的模式数）$8\\pi\\nu^2/c^3$，故单位体积单位频率间隔之间的能量为\n\n$$\n\\rho(v) = \\frac{8\\pi \\nu^2}{c^3}\\overline{n}h\\nu\n$$\n\n#### de Broglie的物质波假说和薛定谔方程\n\n$\\hbar = h/2\\pi$\n\n$$\n\\vec{k} = \\frac{\\vec p}{\\hbar}, \\omega = \\frac{E}{\\hbar}\n$$\n\n注：非相对论粒子的能量$E = p^2/2m$，光子的能量$E=cp$\n\n**自由粒子波函数**\n\n经典波改写：\n\n$$\n\\Psi(\\vec r, t) = Ae^{-i(\\omega t - \\vec k \\cdot \\vec r)} = A e^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$\n\n满足$E = p^2/2m$.\n\n试探得到，自由粒子波函数是薛定谔方程的解：\n\n$$\n\\begin{align*}\n\\vec p \\Psi &= -i \\hbar \\nabla\\Psi\\\\\n\\Rightarrow p^2\\Psi &= -\\hbar^2\\nabla^2\\Psi\\\\\n\\Rightarrow i\\hbar\\frac{\\partial \\Psi}{\\partial t} &= E\\Psi = \\frac{p^2\\Psi}{2m} = H\\Psi\\\\\n(H &= -\\frac{\\hbar^2}{2m}\\nabla^2)\n\\end{align*}\n$$\n\n由于$E$可以被$\\vec p$表示，故可以写成$\\vec p$的函数：\n\n$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i[E(\\vec p) t - \\vec p \\cdot \\vec r]/\\hbar}\n$$\n\n$\\Psi(\\vec r, t) = \\sum_{\\vec p} C_{\\vec p}\\Psi_{\\vec p}(\\vec r, t)$满足薛定谔方程。\n\n如果有势能项，薛定谔方程改为：\n\n$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = -\\frac{\\hbar^2}{2m}\\nabla^2\\Psi(\\vec r, t) + V(\\vec r)\\Psi(\\vec r, t)\\\\\n$$\n\n这里\n\n$$\nH = -\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r) \\equiv \\frac{\\hat p^2}{2m} + V(\\vec r)\n$$\n\n引入了动量算符（量子化假设）$\\hat p = -i\\hbar \\nabla$\n\n注：从薛定谔方程的形式可以得知，其解的表达式里$t$前面的系数肯定含$-i$。如果含$i$，是不满足薛定谔方程的。\n\n#### 从经典到量子的过渡\n\n**以一维单粒子为例：**\n\n牛顿力学：\n\n$$\np \\equiv m\\dot{q}\\\\\nf = ma = m\\ddot{q}\n$$\n\n保守力：\n\n$$\nf = -\\frac{\\partial V}{\\partial q}\n$$\n\n定义哈密顿量：\n\n$$\nH(q, p) = \\frac{p^2}{2m} + V(q)\n$$\n\n从而牛顿力学可以用正则方程代替：\n\n$$\n\\dot p = -\\frac{\\partial H}{\\partial q}, \\dot{q} = \\frac{\\partial H}{\\partial p}\n$$\n\n推广到体系：\n\n假设一个体系的运动可以用广义坐标$q_i$ $(i=1,2,\\dots,n)$ 描述，拉格朗日函数为 $L(q_i, \\dot{q}_i, t)$。根据哈密顿原理，体系的运动满足哈密顿正则方程。\n\n哈密顿正则方程可表示为：\n\n$\\frac{\\partial H}{\\partial p_i} = \\dot{q}_i, \\quad \\frac{\\partial H}{\\partial q_i} = -\\dot{p}_i$\n\n其中，$H(p_i, q_i, t)$ 是哈密顿函数，定义为：\n\n$H(p_i, q_i, t) = \\sum_{i=1}^{n} p_i\\dot{q}_i - L(q_i, \\dot{q}_i, t)$\n\n其中，$p_i$ 是广义动量，定义为：\n\n$p_i = \\frac{\\partial L}{\\partial \\dot{q}_i}$\n\n哈密顿正则方程描述了体系在广义坐标和广义动量空间中的运动行为，从而完整地描述了体系的运动。\n\n哈密顿函数H是否正确的判据：\n\n如果正则方程与已知的经典力学方程一致，则此哈密顿函数是正确的。\n\n**量子化（单粒子情况）**\n\n\n$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = \\left(-\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r)\\right)\\Psi\\\\\n$$\n\n$|\\Psi^2|$给出了粒子在空间中的位置概率。波函数结果数学变换，还能够给出各个力学量的概率分布（例如动量概率密度分布）。\n\n多粒子体系：\n\n对于全同多粒子体系，还需要引入新假设（对波函数施加新限制，后面讲）。\n\n统计物理怎样描述粒子运动？\n\n统计物理中需要引入新假设描述极大量粒子的热运动，这种运动不能由通常的量子力学给出。\n\n混合态：热运动的无规性会造成状态不能用一个确定的波函数描述，这种状态称为混合态（统计物理中体系的状态一般都是混合态）。\n\n纯态：量子力学部分都默认波函数是确定的，称为纯态（它是极特殊的情况）。单个粒子的叠加态依然是纯态。\n\n### 第二章 薛定谔方程和一维运动问题\n\n\n#### 波函数及其统计解释\n\n**波函数及其统计解释**\n\nBorn 对双缝干涉的解释：$|\\Psi(\\vec r, t)|^2$与概率密度成正比\n\n$\\Psi(\\vec r, t)$称为概率幅，**完全描写了状态（这种描写具有统计的特征）**，它决定了各可观测的物理量的几率分布。\n\n波函数本身不能被直接观测。\n\n**波函数的归一化**\n\n$|\\psi(x, y, z, t)|^2$是相对几率密度。\n\n$|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$是t时刻出现在$x, y, z$处$\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$体积元内的相对几率。\n\n$$\n\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z = 1\n$$\n\n为了归一化，选择新的波函数$\\Psi(x, y, z, t)$\n\n$$\n\\Psi(x, y, z, t) = C\\psi(x, y, z, t)\n$$\n\n可得\n\n$$\n|C| = \\frac{1}{\\sqrt{\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z}}\n$$\n\nRemark:\n* 归一化的波函数仍然有一个位相因子不能确定。**习惯上取C为正实数（相角为0）**。\n* 有的波函数不能（有限地）归一。例如平面波$\\Psi(x, t) = e^{-i(Et - px)/\\hbar}$。$|\\Psi(x, t)|^2 = 1$代表了在各处出现的机率相等。\n\n**态的叠加原理（重要）**\n\n若$\\Psi_1, \\Psi_2$是体系的可能状态，那么\n\n$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2\n$$\n\n也是体系的可能状态。\n\n干涉效应：\n\n<!-- Psi, , mathbf -->\n\n$$\n|\\Psi|^2 = |c_1\\Psi_1|^2 + |c_2\\Psi_2|^2 + \\underbrace{ c_1^*c_2\\Psi_1^*\\Psi_2 + c_1c_2^*\\Psi_1\\Psi_2^*}_{干涉项}\n$$\n\n因此，态相加不等于几率相加。\n\n关于相位：\n* 绝对常数相位没有意义\n* 相对常数相位才有意义\n\n$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2 = e^{i\\phi_1}(|c_1|\\Psi_1 + |c_2|e^{\\phi_2 - \\phi_1}\\Psi_2)\\\\\n$$\n\n$|\\Psi|^2$依赖于$\\phi_2 - \\phi_1$\n\n变化的相位是有意义的。(常数相因子可以扔掉)\n\n$$\n\\Psi(\\vec r, t) = |\\Psi(\\vec r, t)|e^{i\\varphi(\\vec r, t)}\n$$\n\n$\\varphi(\\vec r, t)$在空间几率密度上无法反映，但是在动量几率分布上可以反映出来。\n\n**态叠加原理的一般性描述**\n\n对于一个指定的量子体系，如果我们找到了它的“完备的基本状态集合”,那么任何状态都可以由这些基本状态叠加而得到。\n\n$$\n\\Psi = \\sum_n c_n \\Psi_n\n$$\n\n考虑自由粒子平面波的叠加：\n\n$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$\n\n自由电子的任何状态都可以写成：\n\n$$\n\\Psi = \\sum_{\\vec p} c_{\\vec p} \\Psi_{\\vec p}(\\vec r, t)\n$$\n\n又由于动量是连续分布的，改为积分：\n\n$$\n\\Psi = \\int_{\\infty} c({\\vec p}) \\Psi_{\\vec p}(\\vec r, t)\\mathrm d^3 \\vec p\n$$\n\n改写成另一种形式，把时间移到系数中：\n\n$$\n\\Psi = \\int_{\\infty} c({\\vec p, t}) \\Psi_{\\vec p}(\\vec r)\\mathrm d^3 \\vec p\n$$\n其中\n$$\nc(\\vec p,t) = c(\\vec p)e^{-iEt/\\hbar}\\\\\n\\psi_{\\vec p}(\\vec r) = Ae^{i\\vec p \\cdot \\vec r/\\hbar}\n$$\n\n基底称为动量本征函数，满足本征方程：$-ih\\nabla \\psi_{\\vec p}(r) = \\vec p \\psi_{\\vec p}(\\vec r)$。$|c(\\vec p,t)|^2$就是概率密度。\n\n非自由粒子不能做第一种展开，因为含有$V(\\vec r)$项。\n\n固定时刻 $t = t_1$, 此刻波函数为$\\Psi(\\vec r, t_1) = \\Psi(\\vec r)$\n\n则\n\n$$\n\\Psi(\\vec{r}) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\n$$\n\n利用傅里叶变换计算$c(\\vec{p})$。\n\n首先定义delta函数，其满足\n\n$$\n\\delta(x - a) = \\begin{cases}\n    0, &x\\ne a\\\\\n    +\\infty, &x = a\n\\end{cases}\\\\\n\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx = 1\n$$\n\n或者定义为\n\n$$\n\\int\\limits_{\\infty}^{}f(x)\\delta(x - a)\\mathrm dx = f(a)\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx  = f(a)\n$$\n\n其中$\\int_\\infty = \\int_{-\\infty}^{\\infty}$\n\ndelta 函数性质：\n\n$$\n\\delta(x) = \\frac{1}{2\\pi}\\int\\limits_{\\infty}^{0}\\exp(ikx)\\mathrm dk\\\\\n\\delta(\\lambda x) = \\frac{1}{|\\lambda|}\\delta(x)\\ (\\delta \\ne 0)\n$$\n\n利用delta函数进行傅里叶变换：\n\n$$\n\\begin{align*}\n\\Psi(x) &= \\int\\limits_{\\infty}^{}\\Psi(x)\\delta(x - x^\\prime)\\mathrm dx^\\prime\\\\\n&=\\int\\limits_{\\infty}^{}\\Psi(x^\\prime)\\left(\\frac1{2\\pi}\\int\\limits_{\\infty}^{}e^{ik(x - x^\\prime)}\\mathrm dk\\right)\\mathrm dx^\\prime\\\\\n&= \\int\\limits_{\\infty}^{}\\left(\\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x^\\prime)e^{-ikx^\\prime}\\mathrm dx^\\prime\\right)e^{ikx}\\mathrm dk\n\\end{align*}\n$$\n\n因而\n\n$$\nc(k) = \\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x)\\exp({-ikx})\\mathrm dx\\\\\n\\Psi(x) = \\int\\limits_{\\infty}^{}c(k)\\exp(ikx)\\mathrm dk\n$$\n\n记$\\psi_p = \\frac{1}{ \\sqrt{2\\pi \\hbar} }\\exp\\left(i\\frac{p}{\\hbar}x\\right)$\n\n则\n\n$$\n\\Psi(x) = \\int\\limits_{-\\infty}^{\\infty}c(p)\\psi_p(x)\\mathrm dp\\\\\nc(p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_p^*(x)\\Psi(x)\\mathrm dx\n$$\n\n推广到三维：\n\n$$\n\\Psi(\\vec r) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r)\\mathrm dx\\mathrm dy\\mathrm dz\n$$\n\n加入时间：\n\n\n$$\n\\Psi(\\vec r, t) = \\int\\limits_{\\infty}^{}c(\\vec p, t)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p, t) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r, t)\\mathrm dx\\mathrm dy\\mathrm dz\n$$\n\n已知$c(\\vec p, t)$可以求出动量概率密度和坐标概率密度。\n\n#### 薛定谔方程\n\n**几率流密度**\n\n几率密度：\n\n$$\nw(\\vec{r}, t) = |\\Psi(\\vec{r}, t)|^2\n$$\n\n几率密度的时间变化率与某种“流”有关，类比电荷守恒方程：电荷密度的变化率等于电流密度散度的相反数。我们从薛定谔方程推导几率流密度：\n\n$$\n\\begin{align*}\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} &= -\\frac{\\hbar^2}{2\\mu} \\nabla^2\\Psi + U\\Psi \\Rightarrow\\\\\n    \\frac{\\partial w}{\\partial t} &= \\Psi^*\\frac{\\partial \\Psi}{\\partial t} + \\Psi\\frac{\\partial \\Psi^*}{\\partial t} \\\\\n    &= \\frac{i\\hbar}{2\\mu}(\\Psi^*\\nabla^2\\Psi - \\Psi\\nabla^2\\Psi^*)\\\\\n    &= \\frac{i\\hbar}{2\\mu} \\nabla \\cdot (\\Psi^*\\nabla\\Psi - \\Psi\\nabla\\Psi^*)\\\\\n\\end{align*}\n$$\n\n$$\n\\frac{\\partial w}{\\partial t} + \\nabla \\cdot \\vec J = 0\n$$\n\n从而可以定义\n\n$$\n\\vec J = \\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$\n\n对应的可以推积分形式：\n\n$$\n\\frac{\\mathrm dW_v}{\\mathrm dt} = - \\oint_S \\vec{J} \\cdot \\mathrm{d} \\vec S\n$$\n\n$\\vec J$便于记忆可写成\n\n$$\n\\vec J = \\text{Re}\\left[\\Psi^* \\mathrm {\\hat v} \\Psi\\right]\n$$\n\n其中 $\\mathrm{\\hat v} = \\frac{\\vec{p}}{\\mu}$ 称为速度算符。\n\n可以计算电流密度\n\n$$\n\\vec J_e = e\\vec J = e\\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$\n\n可以计算原子内部电子的电流，计算超导体等量子系统的电流。\n\n例：平面波的几率流密度为$\\vec J = w \\vec v$\n\n全空间总几率守恒：\n<!-- oint j -->\n$$\n\\frac{\\mathrm d}{\\mathrm dt} W = -\\oint_\\infty \\vec J \\cdot \\mathrm{d}\\vec S = -\\frac{i\\hbar}{2\\mu}  \\oint(\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi) \\cdot \\mathrm{d}\\vec S = 0\n$$\n\n这里认为波函数在无穷远处为0.\n\n如果粒子波函数在开始时刻是归一化的，则以后一直有归一化。\n\n**定态**\n\n定态波函数=定态薛定谔方程乘以时间因子\n\n$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{h} Et}\\psi(\\vec r)\n$$\n\n$\\psi(\\vec r)$满足 $H\\psi(\\vec r) = E\\psi(\\vec r)$\n\n**定态薛定谔方程**\n\n$$\nH\\psi(\\vec r) = E\\psi(\\vec r)\n$$\n\n$E$ 称为 $H$ 的本征值，$\\psi(\\vec r)$ 称为 $H$ 的本征函数。\n\n**含薛定谔方程的一般解**\n\n含时方程：$i\\hbar \\frac{\\partial \\Psi}{\\partial t} = H\\Psi$\n\n定态方程： $H\\psi(\\vec r) = E\\psi(\\vec r)$\n\n一般解：$\\Psi(\\vec r, t) = \\sum_n c_n\\psi_n(\\vec r)e^{-\\frac{i}{h}E_n t}$\n\n定态下几率密度，几率流密度，力学几率分布和平均值都不随时间变化。\n\n一维自由粒子定态的基本解：\n\n$$\n\\psi = e^{i\\frac{p}{\\hbar}x} = e^{\\pm ikx}(p = \\pm \\hbar k, k = \\sqrt{\\frac{2\\mu E}{\\hbar})}\n$$\n\n能量给定后，状态并非唯一的（能量的简并），但是动量给定后，状态却是唯一的。\n\n**波函数应当满足以下三个条件**\n\n* 单值性\n* 有限性\n* 连续性\n\n连续性一般意味着 $\\Psi$ 和 $\\nabla\\Psi$ 都连续，但是在势能无穷大的地方，允许 $\\nabla\\Psi$ 不连续。\n\n#### 一维无限深势阱\n\n![alt](../images/量筒/4——1.jpg)\n\n<font color='red'>注意，这里的能量本征态不是动量本征态！这里的动量是连续的。因为波函数在0到a的范围内为三角函数，而在范围外为0，并不是周期函数，做傅里叶变换可知动量的图谱是连续的。</font>\n\n#### 一维谐振子\n\n![alt](../images/量筒/4_2.jpg)\n\n#### 势垒穿透\n\n![alt](../images/量筒/5_1.jpg)\n\n### 第三章\n\n#### 动量算符和角动量算符\n\n**厄米算符**\n\n$$\n\\int_{}^{}\\psi^*(\\hat F \\varphi) \\cdot \\mathrm d\\tau = \\int_{}^{}(\\psi\\hat F)^*\\varphi \\cdot \\mathrm d\\tau\n$$\n\n厄米算符的本征值都是实数。\n\n**一维动量本征函数**\n\n$$\n\\hat p = -i\\hbar \\frac{\\mathrm d}{\\mathrm dx},\\\\\n\\hat p \\psi_p = p \\psi_p,\\\\\n\\psi_p = C \\exp\\big(\\frac{ipx}{\\hbar}\\big)\n$$\n\n**三维动量本征函数**\n\n$$\n\\psi_{\\vec p}(\\vec r) = \\frac{1}{\\sqrt{(2\\pi\\hbar^3)}}\\exp\\bigg(\\frac{i}{\\hbar}\\vec p \\cdot \\vec r\\bigg)\\\\\n\\int_{\\infty}^{}\\psi_{\\vec p}^*(\\vec r)\\psi_{\\vec p}(\\vec r)\\mathrm d\\tau = \\delta^3(\\vec p - \\vec p^\\prime)\n$$\n\n箱归一化本征函数：\n\n$$\n\\psi_{p}(-L / 2) =\\psi_{p}(L/2)\\\\\np = \\frac{2\\pi \\hbar}{n}, n=0, \\pm1, \\pm2, \\dots\\\\\n\\int_{-L/2}^{L/2}\\psi_{p}^*(x)\\psi_{p}(x)\\mathrm dx = \\delta_{pp^\\prime}\\\\\nL \\rightarrow \\infty\n$$\n\n**角动量算符**\n\n角动量算符的定义是：\n\n$$\n\\hat {\\vec L} = \\hat{\\vec r} \\times \\hat{\\vec p} = -i\\hbar \\vec r \\times \\nabla\\\\\n\\hat{L_x} = \n$$\n\n球坐标形式：\n\n球坐标单位向量用直角坐标表示：\n\n\n$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\n$$\n\n本征函数：\n\n$$\n\\psi_{m}(\\varphi) = C \\exp(im\\varphi)\n$$\n\n由于单值性 $\\psi_m(\\varphi + 2\\pi) = \\psi_m(\\varphi)$：\n\n$$\nm = 0, \\pm1, \\pm2, \\dots\n$$\n\n归一化：$C = \\frac{1}{\\sqrt{2\\pi}}$\n\n结论：\n\n$$\n\\hat L_z \\psi_m = m\\hbar \\psi_m\\\\\nm = 0, \\pm1, \\pm2, \\dots\n\\psi_m(\\varphi) = \\frac{1}{\\sqrt{2\\pi}} \\exp(im\\varphi)\n$$\n\n由于空间的任意一个方向都可以为z方向，因此角动量的任一分量都可以量子化。\n\n$$\n\\hat L^2 = -\\hbar^2\\bigg[\\frac{1}{\\sin \\theta}\\frac{\\partial }{\\partial \\theta}\\bigg(\\sin\\theta\\frac{\\partial }{\\partial \\theta}\\bigg) + \\frac{1}{\\sin^2\\theta}\\frac{\\partial^2}{\\partial \\varphi^2}\\bigg]\n$$\n\n$$\n\\hat L^2Y = \\lambda \\hbar^2Y\\\\\nY(\\theta, \\varphi) = P(\\theta)\\exp(im\\varphi)\n$$\n\n省流：球谐函数\n\n$$\nY_{lm}(\\theta, \\varphi) = N_{lm}P_l^m(\\cos \\theta)\\exp(im\\varphi)\n$$\n\n归一化系数\n\n$$\nN_{lm} = (-1)^m\\sqrt{\\frac{(2l + 1)}{4\\pi}\\frac{(l - |m|)!}{(l + |m|)!}}\n$$\n\n勒让德函数：\n\n$$\nP(w) = \\frac{1}{2^l l!}(1 - w^2)^{|m| / 2}\\frac{\\mathrm d^{l+|m|}}{\\mathrm dw^{l+|m|}}(w^2 - 1)^l\n$$\n\n前几个球谐函数：\n\n$$\nY_{00} = \\sqrt{\\frac{1}{4\\pi}}\\\\\nY_{10} = \\sqrt{\\frac{3}{4\\pi}}\\cos \\theta\\\\Y_{1, \\pm1} = \\mp \\sqrt{\\frac{3}{8\\pi}}\\sin \\theta \\exp(\\pm i\\varphi)\\\\\n$$\n\n$l = 1$，是 $L^2$ 和 $L_z$ 的共同本征态，但不是 $L_x$ 和 $L_y$ 的本征态,(不确定性原理决定了这三个分量不能同时有本征态)\n\n**球谐函数的性质**\n\n$$\n\\hat L^2 Y_{lm} = l(l+1)\\hbar^2 Y_{lm}\\\\\n\\hat L_z Y_{lm} = m\\hbar Y_{lm}\\\\\nl = 0, 1, 2, \\dots\\\\\nm = l, l - 1, \\dots, -l.\n$$\n\n正交归一性：\n\n$$\n\\int Y^*_{l^\\prime m^\\prime}(\\theta, \\varphi)Y_{lm}(\\theta, \\varphi) \\mathrm d\\Omega = \\delta_{l^\\prime l}\\delta_{m^\\prime m}\n$$\n\n$$\nY^*_{lm}(\\theta, \\varphi) = (-1)^m Y_{l, -m}(\\theta, \\varphi)\n$$\n\n#### 中心力场的运动，氢原子\n\n经典：\n\n$$\nH = \\frac{1}{2}m_N\\dot{\\vec r_N^2} + \\frac{1}{2}m_e\\dot{\\vec r_e^2} + U(|\\vec r_e - \\vec r_N|)\n$$\n\n采用质心坐标和相对坐标：\n\n$$\n\\vec R = \\frac{m_N\\vec r_N + m_e \\vec r_e}{m_N + m_e}\\\\\n\\vec r = \\vec r_e - \\vec r_N\\\\\nM = m_N + m_e\\\\\n\\mu = \\frac{m_Nm_e}{M}\n$$\n\n$$\nH = \\frac{1}{2}M\\dot{\\vec R^2} + \\frac{1}{2}\\mu \\dot{\\vec r^2} + U(r)\\\\\n\\rArr H = \\frac{\\vec p_R^2}{2M} + \\frac{\\vec p^2}{2\\mu} + U(r)\n$$\n\n量子化：\n\n$$\nH = -\\frac{\\hbar^2}{2M}\\nabla_R^2 - \\frac{\\hbar}{2\\mu}\\nabla^2 + U(r)\n$$\n\n相对运动的动量意义是什么？\n\n求解氢原子波函数时，将哈密顿量分解为质心的哈密顿算符和相对坐标的哈密顿算符，然后分别求解。相对坐标对应的哈密顿算符求解得到的才是氢原子波函数。因此，**得到的氢原子的能量不包括质心运动的能量。**\n\n省流：氢原子波函数\n\n$$\n\\psi_{nlm} = R_{nl}(r) Y_{lm}(\\theta, \\phi)\n$$\n\n其中径向函数\n\n$$\nR_{nl}(r) = \\frac{u_{nl}(r)}{r}, \\rho = \\alpha r\\\\\nu_{nl}(r) = N_{nl} \\rho^{l + 1}(\\rho) v_{nl}(\\rho) \\exp(-\\frac{1}{2}\\rho)\n$$\n\n$$\n主量子数\\quad n = 1, 2, 3,\\dots, \\rightarrow E_n = \\frac{E_1}{n^2}\\\\\n角量子数\\quad l = 0, 1, \\dots, n -1, \\rightarrow L^2 = l(l + 1)\\hbar^2\\\\\n磁量子数\\quad m = l, l - 1, \\dots, -l, \\rightarrow L_z = m\\hbar\\\\\n简并度\\quad g_n =\\sum\\limits_{l=0}^{n - 1}(2l + 1) = n^2\n$$\n\n定态波函数的宇称性质：\n\n$$\nR_nl(r) 偶函数，\n$$\n\n![alt](../images/量筒/7_1.jpg)\n\n![alt](../images/量筒/8_1.jpg)\n\n![alt](../images/量筒/8_2.jpg)\n\n![alt](../images/量筒/8_3.jpg)\n\n\n\n电子云有方向性吗？\n\n以 $n = 2$ 为例，$Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 的模平方之和为常数。若氢原子随机等概率激发到 $Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 之一，则无方向性。但如果是相干叠加，则有方向性。\n\n为什么 $m$ 叫做磁量子数？\n\n![alt](../images/量筒/8_4.jpg)\n\n$$\n\\vec J_e = (-e) \\vec J\n$$\n\n#### 本征函数系的一般性质\n\n**正交与归一**\n\n正交性定理\n\n同一个厄密算符 $\\hat F$ 的属于不同本征值的本征函数是彼此正交的。\n\n$$\n\\int_{}^{}\\psi_1^*\\psi_2\\mathrm d\\tau = 0\n$$\n\n本征函数的正交“归一”性\n\n离散情况：\n\n$$\n\\int_{}^{}\\phi_k^*(\\vec r) \\cdot \\phi_l(\\vec r)\\mathrm d\\tau = \\delta_{kl} = \\begin{cases}\n    0, k\\ne l\\\\\n    1, k = l\n\\end{cases}\n$$\n\n连续情况：\n\n$$\n\\int_{}^{}\\phi_{\\lambda^\\prime}^*(\\vec r) \\cdot \\phi_{\\lambda}(\\vec r)\\mathrm d\\tau = \\delta(\\lambda - \\lambda^\\prime)\n$$\n\n并非真正的归一化，但是依然满足正交性：例如 $\\frac{1}{\\sqrt{2\\pi \\hbar}}e^{\\frac{i}{\\hbar}px}$。\n\n**共同本征函数（重点）**\n\n定义对易括号\n\n$$\n[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G \\hat F\n$$\n\n若\n\n$$\n[\\hat F, \\hat G] = 0 \n$$\n\n则两算符对易。\n\n定理：\n\n$$\n[\\hat F, \\hat G] = 0 \\Rightarrow 两个算符有组成完全系的共同本征函数\n$$\n\n$$\n[\\hat {p_z}, \\hat {p_x}] = [\\hat {p_x}, \\hat {p_y}] = [\\hat {p_y}, \\hat {p_z }] = 0\n$$\n\n它们有共同的本征函数。\n\n$$\n[\\hat {xp}, \\hat {px}] = i\\hbar\n$$\n\n没有共同的本征函数。\n\n如果 $[\\hat {F}, \\hat {G}] \\ne 0$，则不一定没有共同本征态。例如角动量的本征态 $Y_{00}$。\n\n$$\n[\\hat {L^2}, \\hat {L_i}] = 0\\\\\n[\\hat {L_x}, \\hat {L_y}] = i\\hbar \\hat L_z\n$$\n\n性质：\n\n$$\n[A, BC] = [A, B]C + B[A, C]\n$$\n\n简并：力学量 $F$ 的一个本征值对应多个线性无关的本征函数。\n\n**力学量完全集（完备算符集）**\n\n为了消除简并，可以选取一组彼此对易的力学量 $F_1, F_2, F_3, \\dots$，使得它们的本征值组 $\\lambda_1, \\lambda_2, \\dots$ 对应唯一一个线性无关的共同本征函数 $\\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)$\n\n称 $F_1, F_2, F_3, \\dots$ 为力学量完全集。\n\n$$\nF_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r) = \\lambda_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)\n$$\n\n实现了正交化：力学量完全集的共同本征函数必然为正交函数系，因为任意两个本征函数，对应的本征值必然不同，由正交性定理得知，两个本征函数必然正交。\n\n**常见的选取方式**\n\n对于三维空间的单粒子，可以选取为：\n\n* $(x, y, z)$\n* $(p_x, p_y, p_z)$\n* $(H, L^2, L_z)$（对于氢原子适用）\n\n考虑自旋后，还需要增加自旋力学量构成完全集。\n\n#### 力学量的平均值公式\n\n$$\n\\overline{F(t)} = \\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx\n$$\n\n若没有归一化：\n\n$$\n\\overline F = \\frac{\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx}{\\int_{}^{}\\psi^*(x, t) \\psi(x, t)\\mathrm dx}\n$$\n\n实际上， 利用本征函数的正交性\n\n$$\n\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx =\\sum\\limits_{n}^{}\\lambda_n |c_n|^2 = \\overline{F}\n$$\n\n几率幅函数\n\n$$\nc_n(t) = \\int_{}^{}\\phi_n^*(x)\\psi(x, t)\\mathrm dx\n$$\n\n例题：\n\n$$\n\\psi = Ae^{ikx} + Be^{-ikx}\\\\\n$$\n\n动量值 $\\hbar k$ 与 $-\\hbar k$ 的概率比值为 $\\frac{|A|^2}{|B|^2}$\n\n$$\n\\bar p = \\hbar k  \\frac{|A|^2}{|A|^2 + |B|^2} + (-\\hbar k ) \\frac{|B|^2}{|A|^2 + |B|^2} = \\frac{|A|^2 - |B|^2}{|A|^2 + |B|^2}\\hbar k\n$$\n\n#### 不确定关系\n\n一维谐振子为例：\n\n$$\n\\psi_(x) = \\sqrt{\\frac{\\alpha}{\\sqrt \\pi}} e^{-\\frac{1}{2}\\alpha^2 x^2}\\\\\nc_p = \\sqrt{\\frac{\\beta}{\\sqrt \\pi}}e^{-\\frac{\\beta^2p^2}{2}}\\\\\n\\frac{1}{\\alpha} \\cdot \\frac{1}{\\beta} = \\frac{1}{\\hbar}\\\\\n\\alpha = \\sqrt{\\frac{\\mu \\omega}{\\hbar}}\n$$\n\n不确定关系的数学表达以及证明\n\n如果两个力学量F和G的算符彼此不对易，则它们有不相容性，测量精确度（不确定度）上一般是相互制约的。\n\n$$\n\\Delta \\hat F = \\hat F - \\overline{ } F\\\\\n\\overline{(\\Delta \\hat F)^2} = \\overline{(\\hat F - \\overline{F})^2} = \\overline{\\hat F^2} - \\overline{F}^2\n$$\n\n记 $[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G\\hat F = i\\hat C$，则在任意一个状态下\n\n$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$\n\n这里 $\\hat F$ 与 $\\hat G$ 都是厄密算符，所以 $\\overline{\\hat C}$ 为实数\n\n引入\n\n$$\nI(\\xi) = \\int_{}^{}\\left | (\\xi\\Delta \\hat F - i\\Delta \\hat G  )\\psi^2\\right|^2\\mathrm d\\tau \\ge 0\n$$\n\n$$\n\\begin{align*}\n    I(\\xi) =& \\xi^2\\int_{}^{}(\\Delta \\hat F \\psi)^* (\\Delta \\hat F \\psi)\\mathrm d\\tau - i\\xi \\int_{}^{}[(\\Delta \\hat F \\psi)^*(\\Delta \\hat G \\psi) - (\\Delta \\hat G \\psi)^*(\\Delta \\hat F \\psi)]\\mathrm d\\tau + \\int_{}^{}(\\Delta \\hat G\\psi)^*(\\Delta \\hat G\\psi)\\mathrm d\\tau\\\\\n    =& \\xi^2 \\int_{}^{}\\psi^*(\\Delta \\hat F)^2\\psi\\mathrm d\\tau - i\\xi \\int_{}^{}\\psi^*\\Delta\\hat F\\Delta \\hat G\\psi - \\psi^*\\Delta \\hat G\\Delta \\hat F\\psi\\mathrm d\\tau + \\int_{}^{}\\psi^*(\\Delta \\hat G)^2 \\psi\\mathrm d\\tau\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i\\overline{\\Delta \\hat F\\Delta \\hat G - \\Delta \\hat G \\Delta \\hat F}\\cdot \\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat { F}, \\hat { G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - \\overline{\\hat C}\\xi + \\overline{(\\Delta \\hat G)^2}\n\\end{align*}\n$$\n\n由于此式恒正，判别式大于0：\n\n$$\nI(\\xi) \\ge 0 \\Rightarrow \\overline{(\\Delta \\hat C)}^2 - 4\\overline{(\\Delta \\hat F)^2}\\cdot \\overline{(\\Delta \\hat G)^2} \\ge 0\n$$\n\n$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$\n\n如果要满足取等号条件：\n\n$$\n(\\xi \\Delta \\hat F - i \\Delta \\hat G)\\psi = 0\n$$\n\n此时的波包称为最小不确定波包\n\n位置动量不确定关系：\n\n$$\n\\overline{(\\Delta \\hat x)^2} \\overline{(\\Delta \\hat p_x) ^2} \\ge \\frac{\\hbar^2}{4}\n$$\n\n非零的“零点能”是不确定性关系的结果。\n\n$$\n\\overline E = \\frac{1}{2\\mu}\\overline{(\\Delta \\hat p_x)^2} + \\frac{1}{2}\\mu \\omega\\overline{(\\Delta \\hat x)^2} \\ge \\frac{1}{2}\\hbar\\omega\\\\\n\\overline E_{min} = \\frac{1}{2}\\hbar\\omega\\\\\n$$\n\n势垒穿透问题：谈论某一点的动能 T 和总能量 E 没有意义，因为 $\\hat x, \\hat T, \\hat H$ 彼此不对易。\n\n$H, T, U$ 三个物理量之间彼此不对易，不能同时具有确定的值。故 $H = T + U$ 只是一个算符的等式。\n* 若为定态，则 $H$ 确定而 $T, U$ 不确定\n* 若位置确定，则 $U$ 确定但是 $T$ 和 $E$不确定\n\n求平均值：\n\n$$\n\\overline H = \\overline{ T} + \\overline U\n$$\n\n$T$ 的本征值为非负实数，所以\n\n$$\n\\overline{H} \\ge \\overline{ U}\n$$\n\n角动量 $Y_{00}$ 情形下，三个分量都具有确定的取值，三个角动量分量都为 0，还是满足不确定性关系。\n\n#### 守恒量\n\n要求任意态下 $F$ 平均值不变。\n\n平均值的时间演化\n\n$$\n\\hat H = i\\hbar \\frac{\\partial }{\\partial t}\n$$\n\n若算符 $\\hat F$ 不显含时间，则\n\n$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]}\n$$\n\n若 $\\hat F(t)$ 显含时间，则\n\n$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]} + \\overline{\\frac{\\partial }{\\partial t}\\hat F(t)}\n$$\n\n### 第四章\n\n####  狄拉克算符和谐振子升降算符\n计算本征值问题\n\n谐振子：\n\n$$\nH = \\hbar \\omega \\frac{1}{2} \\left ( \\frac{p^2}{m\\hbar\\omega} + \\frac{m\\omega^2x^2}{\\hbar\\omega} \\right)\\\\\n\\alpha \\equiv \\sqrt{\\frac{m\\omega}{\\hbar}}\\\\\np^\\prime = \\frac{1}{\\hbar \\alpha}p\\\\\nx^\\prime = \\alpha x\\\\\n[\\hat {x^\\prime}, \\hat {p^\\prime}] = i\n$$\n\n$$\nH = \\hbar\\omega\\frac{1}{2}[(x^\\prime - ip^\\prime)(x^\\prime + ip^\\prime) + 1]\\\\\np^\\prime = -i \\frac{\\mathrm d}{\\mathrm dx^\\prime}\n$$\n\n基态满足\n\n$$\n(x^\\prime + ip^\\prime)\\psi_0(x) = 0\n$$\n\n通过升算符算出激发态\n\n$$\n\\psi_n = C_n (x^\\prime - ip^\\prime)^n\\psi_0(x)\n$$\n\n换元：\n\n$$\na = \\frac{x^\\prime + ip^\\prime}{\\sqrt{2}}\\\\\na^+ = \\frac{x^\\prime - ip^\\prime}{\\sqrt{2}}\\\\\nH = \\hbar \\omega(a^+a + \\frac{1}{2}) = \\hbar \\omega(\\hat N + \\frac{1}{2})\\\\\n[a, a^+] = 1\n$$\n\n设 $\\hat N$ 的本征矢为 $\\ket{n}$，称$n$为占有数。可以看出这本征矢也是能量的本征态。\n\n接下来计算 $\\hat N$ 的本征矢：\n\n$$\n\\langle \\hat N \\rangle = \\bra{n}a^+a\\ket{n} \\ge 0\\\\\n\\bra{n}a^+a\\ket{n} = n \\langle n|n \\rangle\\\\\n\\Rightarrow n \\ge 0\n$$\n\n如果存在 $n = 0$ 的态：\n\n$$\n\\bra{0}a^+a\\ket{0} = 0\\\\\n\\Rightarrow a\\ket{0} = 0\n$$\n\n这就是基态满足的微分方程。解出基态的坐标表象：\n\n$$\n(\\alpha x + \\frac{1}{\\alpha} \\frac{\\mathrm d}{\\mathrm dx})\\psi_0(x) = 0\n$$\n\n重点：升降性质\n\n$a\\ket{n} = \\ket{\\phi} = \\ket{n - 1}$ 也是本征态。\n\n$$\n\\hat N \\ket{\\phi} = (a^+a)\\ket{\\phi} = (aa^+ - 1)\\ket{\\phi} = (aa^+ - 1)a\\ket{n} = aa^+a\\ket{n} - a\\ket{n} = a\\hat N\\ket{n} - a\\ket{n} = na\\ket{n} - a\\ket{n} = (n - 1)\\ket{\\phi}\n$$\n\n归一化：\n\n$$\n\\ket{\\phi} = c\\ket{n - 1}\\\\\n1 = \\langle n - 1 |n - 1 \\rangle = \\frac{1}{|c|^2}(an, an) = \\frac{1}{|c|^2}\\bra{n}a^+a\\ket{n} = \\frac{n}{|c|^2}\\\\\n取 c = \\sqrt{n}\\\\\na\\ket n = \\sqrt{n}\\ket{n - 1}\n$$\n\n升降算符（重点）：\n\n$$\na\\ket n = \\sqrt{n}\\ket{n - 1}\\\\\na\\ket{0} = 0\\\\\na^+\\ket{n} = \\sqrt{n + 1}\\ket{n + 1}\n$$\n\n$n$ 必为整数。\n\n能级：\n\n$$\nH = \\hbar \\omega(a^+a + \\frac{1}{2})\\\\\nE_n = \\hbar\\omega(n + \\frac{1}{2})\n$$\n\n波函数：\n\n$$\n\\ket n = \\frac{1}{\\sqrt{n}}a^+\\ket{n - 1} = \\frac{1}{\\sqrt{n!}}a^{+n}\\ket{0}\\\\\n\\psi_n(x) = \\frac{1}{\\sqrt{n!}}\\left (\\frac{1}{\\sqrt{2}}\\left (\\alpha x - \\frac{1}{\\alpha}\\frac{\\mathrm d}{\\mathrm dx}  \\right)  \\right)^n \\frac{\\sqrt{\\alpha}}{\\pi^{1/4}}e^{-\\alpha^2x^2/2}\n$$\n\n相干态：满足 $\\hat a \\ket \\beta = \\beta \\ket \\beta$ 的 $\\ket \\beta$。\n\n#### 海森堡方程\n\n力学量算符含时，波函数不含时\n\n$$\n\\bra{\\psi(t)} F\\ket {\\psi(t)} \\rightarrow \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$\n\n不同图景在物理上等价\n\n$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{\\hbar}Ht}\\Psi(\\vec r, 0)\\\\\n\\ket{\\psi(t)} = U\\ket {\\psi(0)}\n$$\n\n力学量平均值\n\n$$\n\\overline{F} = \\bra{\\psi(t)}F\\ket{\\psi(t)} = \\bra{\\psi(0)}U^+FU\\ket{\\psi(0)} = \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$\n\n海森方程\n\n$$\nF_H = U^+(t)FU(t), U = e^{-\\frac{i}{\\hbar}Ht}, U^+ = e^{\\frac{i}{\\hbar}Ht}\\\\\n\\frac{\\mathrm d}{\\mathrm dt}U = \\frac{1}{i\\hbar}HU, \\frac{\\mathrm d}{\\mathrm dt}U^+ = -\\frac{1}{i\\hbar}HU^+, \\\\\n\\frac{\\mathrm d}{\\mathrm dt}F_H = \\frac{1}{i\\hbar}[F_H, H]\\\\\n\\frac{\\mathrm d\\ket{\\psi}_H}{\\mathrm dt} = 0\n$$\n\n$$\nHU = UH\n$$\n\n从经典到量子：\n\n$$\n\\dot q = \\frac{1}{i\\hbar}[q, H]\\\\\n\\dot p = \\frac{1}{i\\hbar}[p, H]\\\\\n[q, p] = i\\hbar\n$$\n\n#### 自旋\n\n用标量波函数 $\\Psi(\\vec r, t)$ 描述是否完整？\n\n经典力学给出了轨道磁矩和磁势能\n\n$$\n\\vec M_L = -\\frac{e}{2m_e}\\vec L\\\\\nU = - \\vec M \\cdot \\vec B\n$$\n\n磁矩的最小单元(Bohr磁子)\n\n$$\nM_B \\equiv \\frac{e\\hbar}{2m_e}\n$$\n\nStern-Gerlach 实验：即使是 $l = 0$ 的 $s$ 态原子也会在磁场中偏转。认为电子除了轨道磁矩，还有自旋磁矩。\n\n自旋磁矩只有两个可能的值：\n\n$$\nM_B \\equiv \\frac{2\\hbar}{2m_e}\\\\\nM_z = \\pm M_B\n$$\n\nUhlenbeck-Goudsmit假设(1925)：电子有内禀（自旋）角动量，其投影只能取两个值：\n\n$$\nS_i = \\pm \\frac{\\hbar }{2}, i = x, y , z\n$$\n\n自旋磁矩：\n\n$$\n\\hat {\\vec M_s} = -\\frac{e}{m_e}\\hat{\\vec S}\n$$\n\n自旋有纯量子力学的起源。没有经典对应，独立于之前学过的所有力学量。\n\n自旋的分量只有两个可能的测量值，因此可以使用 $2\\times 2$ 的矩阵描写。\n\n$S_z$的本征值为 $\\pm \\frac{\\hbar}{2}$，采用 $S_z$ 表象，则 $S_z = \\frac{\\hbar}{2}\\begin{pmatrix}\n    1 &0\\\\\n    0 &-1\n\\end{pmatrix}$\n\n根据角动量的对易关系（假设的）\n\n$$\n[S_x, S_y] = i\\hbar S_z\\\\\n[S_y, S_z] = i\\hbar S_x\\\\\n[S_z, S_x] = i\\hbar S_y\n$$\n\n可以导出 $S_x$ 和 $S_y$\n\n$$\nS_x = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\n\\end{pmatrix}\\\\\nS_y = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & -i\\\\\n    i & 0\n\\end{pmatrix}\\\\\nS_z = \\frac{\\hbar}{2}\\begin{pmatrix}\n    1 & 0\\\\\n    0 & -1\n\\end{pmatrix}\\\\\n$$\n\n三个分量不对易，最多只有一个分量具有确定的取值\n\n$$\nS_x^2 = S_y^2 = S_z^2 = \\frac{\\hbar^2}{4}\\\\\nS^2 = \\frac{3\\hbar^2}{4} = s(s + 1)\\hbar^2\\\\\n(s = \\frac{1}{2})\\\\\n[S^2, S_i] = 0\n$$\n\n自旋是内部基本构造，不同于先前学过的力学量，不能写成 $F(\\vec r, \\vec p)$ 的形式\n\n自旋也不能简单看成绕自身某个轴的旋转（电子被当作“点粒子”，自旋不同于经典物体的旋转，量子自旋没有经典的对应）\n\n带有自旋的电子波函数（自旋 + 空间坐标）\n\n$$\nv_+ = \\begin{pmatrix}\n    1\\\\0\n\\end{pmatrix}\nv_- = \\begin{pmatrix}\n    0\\\\1\n\\end{pmatrix}\n\n\\Psi(\\vec r, t) \\cdot v_+ + \\Psi_2(\\vec r, t) \\cdot v_-\n$$\n\n波函数有两个自旋分量（类比于电磁波有两个偏振分量）\n\n又被称为旋量波函数\n\n$$\n\\Psi = \\begin{pmatrix}\n    \\Psi_1(\\vec r, t)\\\\\n    \\Psi_2(\\vec r, t)\n\\end{pmatrix}\\\\\nw(\\vec r, t) = \\Psi^+\\Psi = |\\Psi_1|^2 + |\\Psi_2|^2\\\\\n\\int_{}^{}\\Psi^+\\Psi\\mathrm d\\tau = \\int_{}^{}(|\\Psi_1|^2 + |\\Psi_2|^2)\\mathrm d\\tau = 1\n$$\n\n自旋角动量的几率分布\n\n$$\nW \\left ( \\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_1|^2\\mathrm d\\tau\\\\\nW \\left ( -\\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_2|^2\\mathrm d\\tau\\\\\n$$\n\n### 第五章 微扰论\n\n$$\n\\hat H \\psi_n = E_n \\psi_n\\\\\n\\hat H = \\hat H^{(0)} + \\hat H^\\prime\n$$\n\n作逐级展开：\n\n$$\n\\psi_n = \\psi_n^{(0)} + \\psi_n^{(1)} + \\psi_n^{(2)} + \\cdots\\\\\nE_n = E_n^{(0)} + E_n^{(1)} + E_n^{(2)} + \\cdots\\\\\n$$\n\n得到零级，一级，二级方程\n\n$$\n\\hat H^{(0)} \\psi_n^{(0)} = E_n^{(0)}\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(1)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(2)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(1)} + E_n^{(2)}\\psi_n^{(0)}\\\\\n$$\n\n#### 能量的非简并情形\n\n结论：能级一级修正\n\n$$\nE_n^{(1)} = H^\\prime_{nn} = \\int_{}^{}\\psi_n^{(0)*}\\hat{H}^\\prime\\psi_n^{(0)}\\mathrm d\\tau\n$$\n\n波函数一级修正\n\n$$\n\\psi_n(x) = \\psi_n^{(0)}(x) + \\psi_n^{(1)}(x)\\\\\n\\psi_n^{(1)}(x) =\\sum\\limits_{m\\ne n}^{}\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}}\\psi_m^{(0)}(x)\n$$\n\n适用条件：\n\n$$\n\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}} << 1\n$$\n\n二级能量修正公式：\n\n$$\nE_n^{(2)} =\\sum\\limits_{m\\ne n}^{}\\frac{|H_{mn}^\\prime|^2}{E_n^{(0)} - E_m^{(0)}}\n$$\n\n#### 零级能量的简并情形\n\n需要确定适当的零级波函数，可以通过对初始的0级波函数进行表象变换得到。\n\n$$\n\\psi_{ni}^{(0)} =\\sum\\limits_{l=1}^{k}c_{li}^{(0)}\\phi_{nl}^{(0)}\n$$\n\n通过哈密顿量的修正值 $H^\\prime$ 来确定 0 级波函数的选取。1级方程左右同乘 $\\phi_l^{(0)*}$ 并积分，可得（下面的方程没有写n，表示都是同一个能级，系数c的下标对应1~k）\n\n$$\nH^\\prime C^{(0)} = E_n^{(1)}C^{(0)}\\\\\nH^\\prime_{ji} = \\int_{}^{}\\phi_j^{(0)*}\\hat H^\\prime\\phi_i^{(0)}\\mathrm d\\tau\\\\\nC^{(0)} = \\begin{pmatrix}\n    c_1^{(0)}\\\\c_2^{(0)}\\\\\\dots\\\\c_k^{(0)}\n\\end{pmatrix}\n$$\n\n对所有的 $l$ 做上述操作，求出所有的新的零级波函数。\n\n$H^\\prime$ 在 $E_n^{(0)}$ 对应的简并态子空间的 $k$ 个本征向量决定新的零级波函数 $\\psi_n^{(0)}$。对应的 $k$ 个本征值表示一级能量修正 $E_n^{(1)}$。这些一级能量互不相同，使得 $E_n^{(0)} + E_n^{(1)}$有 $k$ 个不同的值，也就是说零级加一级能量是“非简并态”。\n\n（这样做有什么意义？）\n\n简并微扰波函数的一级修正：\n\n$$\nc_{ml}^{(1)} = \\frac{\\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime \\psi_{nl}^{(0)}\\mathrm d\\tau}{E_n^{(0)} - E_m^{(0)}}\\\\\n\\psi_{nl}^{(1)} =\\sum\\limits_{m\\ne n}^{}c_{ml}^{(1)}\\phi_m^{(0)}\n$$\n\n注意！其中 $\\phi_m^{(0)}$ 是 $E_n^{(0)}$ 能级以外的态，这些态可以是简并的。\n\n能量的二级修正：\n\n$$\nE_{nl}^{(2)} =\\sum\\limits_{m\\ne n}^{} \\frac{\\left | \\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime\\psi_{nl}^{(0)}\\mathrm d\\tau \\right|^2}{E_n^{(0)} - E_m^{(0)}}\n$$\n\n如果求解的本征值有重根？\n\n此时零级波函数仍然不能求出来，但是可以求出能量一级修正；若考虑能量的二级修正，需要由二级方程确定零级波函数。\n\n#### 外磁场中的原子\n\nZeeman 效应：外磁场中原子的能级会分裂\n\n简单 Zeeman 效应：外磁场作用很强， 可以略去自旋轨道耦合，这就是简单 Zeeman 效应\n\n$$\n\\vec M = \\vec M_L  + \\vec M_s \\approx -\\frac{e}{2\\mu}(\\vec L + 2\\vec S)\\\\\nU_m = -M_zB = \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\\\\\nH = H_0(氢原子) + \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\n$$\n\n结论：$\\psi_{n,l,m_l,m_s}$ 组成了完全函数系，对应能级为\n\n$$\nE_{n,l,m_l,m_s} = E_n + \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$\n\nZeeman 效应可以调节原子能级，操控原子的量子态，灵敏检测磁场。\n\n如何用微扰论求解？\n\n显然，在上面介绍的波函数正好使得 $H^\\prime$ 成为一个对角矩阵：\n\n$$\n\\bra{\\psi_{n,l,m_l^\\prime,m_s\\prime}} H^\\prime \\ket{\\psi_{n,l,m_l,m_s}} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\\delta_{m_l^\\prime, m_l}\\delta_{m_s^\\prime, m_s}\\\\\nE_{n,l,m_l,m_s}^{(1)} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$\n\n**求自旋轨道耦合产生的精细结构？**\n\n（困难的拓展问题，在课程内不能完全解决）\n\n$$\nH = H_0 + H^\\prime\\\\\nH^\\prime = \\ksi(r)\\vec L \\cdot \\vec s\\\\\n\\ksi(r) = \\left ( \\frac{e^2}{8\\pi\\varepsilon_0} \\right)\\frac{1}{m_e^2c^2r^3}\n$$\n\n采用耦合表象基底 $L^2, L_z, S_z$ 共同本征态\n\n$$\n\\hat Y_{ljm} =\\sum\\limits_{m_lm_s}^{}c(l, j, m;l, m_l, m_s)Y_{lm_l}\\chi_{m_s} = \\ket{l, j, m}\n$$\n\n$$\n\\vec J = \\vec L + \\vec s\\\\\n\\vec L \\cdot \\vec s = \\frac{1}{2}(\\vec J^2 - \\vec L^2 - \\vec s^2)\n$$\n\n$H^\\prime$ 又是一个对角阵：\n\n$$\n\\bra{l^\\prime, j^\\prime, m^\\prime}\\vec L \\cdot \\vec s\\ket{l, j, m} = \\frac{1}{2} \\left [ j(j + 1) - l(l + 1) - \\frac{3}{4} \\right]\\hbar^2\\delta_{ll^\\prime}\\delta_{jj^\\prime}\\delta_{mm^\\prime}\n$$\n\n\n相对论得出的真实的精细结构跟 $l$ 并没有关系。\n\n考虑真空电磁场微扰形成的能级微小移动——兰姆位移。\n\n## 统计力学\n\n### 第一章\n\n平衡态下孤立系统各种微观态的几率相等。\n\n最可几方法求玻色分布和费米分布\n\n求 $W \\lbrace n_i \\rbrace$ 的极大值\n\n$$\n\\bar u = \\frac{\\Sigma u \\lbrace n_i \\rbrace W \\lbrace n_i \\rbrace}{W \\lbrace n_i \\rbrace}\n$$\n\n## 习题课\n\n### 20231028\n\n#### 量子力学基本公理\n\n公理1：希尔伯特空间\n\n公理2：可观测量\n\n公理3：位置与动量（正则量子化）\n\n公理4：薛定谔方程\n\n公理5：全同粒子（略：讲统计时会讲）\n\n概率流密度的公式并不本质。根据薛定谔方程、概率密度公式、连续性方程可以推出。\n\n全空间概率密度$w(t)$不是 $x$ 的函数。\n\n要写盒外波函数为0.\n\n对任意的束缚的能量本征态, 动量的平均值是 0.\n\n$$\n[\\hat {x}, \\hat {H}] = [\\hat {x}, \\hat {p}^2/2\\mu] = \\frac{1}{2\\mu}(\\hat p[\\hat {x}, \\hat {p}] + [\\hat {x}, \\hat {p}]\\hat p) = \\frac{i\\hbar}{\\mu}\\hat p\n$$\n\n$$\n\\int_{-\\infty}^{\\infty}e^{-\\alpha x^2 + \\beta x}\\mathrm dx = \\sqrt{\\frac{\\pi}{\\alpha}}e^{\\beta^2/4\\alpha}\n$$\n\n### 20231112\n\n![](../images/量筒/xt_2_1.jpg)\n\n$$\n\\mu = -\\frac{e}{m}S\\\\\nU = - \\mu \\cdot B = -\\dfrac{eB}{m}S \\cdot n =\n$$\n\n![](../images/量筒/xt_2_2.jpg)\n\n透射率，反射率计算（用流密度）\n\n","slug":"量筒","published":1,"updated":"2024-03-19T06:01:16.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfi1000wrsugbb00a844","content":"<h2 id=\"量子力学\"><a href=\"#量子力学\" class=\"headerlink\" title=\"量子力学\"></a>量子力学</h2><h3 id=\"第一章-引言\"><a href=\"#第一章-引言\" class=\"headerlink\" title=\"第一章 引言\"></a>第一章 引言</h3><p>光的粒子性：</p>\n<ul>\n<li>黑体辐射</li>\n<li>光电效应</li>\n<li>康普顿散射</li>\n</ul>\n<p>原子模型：能级和跃迁</p>\n<p>电子衍射：例子的波动性</p>\n<p>黑体辐射的解释：</p>\n<h4 id=\"普朗克公式\"><a href=\"#普朗克公式\" class=\"headerlink\" title=\"普朗克公式\"></a>普朗克公式</h4><p>已知</p>\n<div>$$\nP(\\varepsilon_\\nu = nh\\nu) \\propto e^{-\\varepsilon_{\\nu}/kT}\n$$</div>\n\n<p>平均光子数</p>\n<div>$$\n\\overline{n} = \\frac{1}{e^{hv/kT} - 1}\\\\\n$$</div>\n\n<p>又知一个光子的能量$h\\nu$，模式密度（单位频率间隔的模式数）$8\\pi\\nu^2&#x2F;c^3$，故单位体积单位频率间隔之间的能量为</p>\n<div>$$\n\\rho(v) = \\frac{8\\pi \\nu^2}{c^3}\\overline{n}h\\nu\n$$</div>\n\n<h4 id=\"de-Broglie的物质波假说和薛定谔方程\"><a href=\"#de-Broglie的物质波假说和薛定谔方程\" class=\"headerlink\" title=\"de Broglie的物质波假说和薛定谔方程\"></a>de Broglie的物质波假说和薛定谔方程</h4><p>$\\hbar &#x3D; h&#x2F;2\\pi$</p>\n<div>$$\n\\vec{k} = \\frac{\\vec p}{\\hbar}, \\omega = \\frac{E}{\\hbar}\n$$</div>\n\n<p>注：非相对论粒子的能量$E &#x3D; p^2&#x2F;2m$，光子的能量$E&#x3D;cp$</p>\n<p><strong>自由粒子波函数</strong></p>\n<p>经典波改写：</p>\n<div>$$\n\\Psi(\\vec r, t) = Ae^{-i(\\omega t - \\vec k \\cdot \\vec r)} = A e^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$</div>\n\n<p>满足$E &#x3D; p^2&#x2F;2m$.</p>\n<p>试探得到，自由粒子波函数是薛定谔方程的解：</p>\n<div>$$\n\\begin{align*}\n\\vec p \\Psi &= -i \\hbar \\nabla\\Psi\\\\\n\\Rightarrow p^2\\Psi &= -\\hbar^2\\nabla^2\\Psi\\\\\n\\Rightarrow i\\hbar\\frac{\\partial \\Psi}{\\partial t} &= E\\Psi = \\frac{p^2\\Psi}{2m} = H\\Psi\\\\\n(H &= -\\frac{\\hbar^2}{2m}\\nabla^2)\n\\end{align*}\n$$</div>\n\n<p>由于$E$可以被$\\vec p$表示，故可以写成$\\vec p$的函数：</p>\n<div>$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i[E(\\vec p) t - \\vec p \\cdot \\vec r]/\\hbar}\n$$</div>\n\n<p>$\\Psi(\\vec r, t) &#x3D; \\sum_{\\vec p} C_{\\vec p}\\Psi_{\\vec p}(\\vec r, t)$满足薛定谔方程。</p>\n<p>如果有势能项，薛定谔方程改为：</p>\n<div>$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = -\\frac{\\hbar^2}{2m}\\nabla^2\\Psi(\\vec r, t) + V(\\vec r)\\Psi(\\vec r, t)\\\\\n$$</div>\n\n<p>这里</p>\n<div>$$\nH = -\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r) \\equiv \\frac{\\hat p^2}{2m} + V(\\vec r)\n$$</div>\n\n<p>引入了动量算符（量子化假设）$\\hat p &#x3D; -i\\hbar \\nabla$</p>\n<p>注：从薛定谔方程的形式可以得知，其解的表达式里$t$前面的系数肯定含$-i$。如果含$i$，是不满足薛定谔方程的。</p>\n<h4 id=\"从经典到量子的过渡\"><a href=\"#从经典到量子的过渡\" class=\"headerlink\" title=\"从经典到量子的过渡\"></a>从经典到量子的过渡</h4><p><strong>以一维单粒子为例：</strong></p>\n<p>牛顿力学：</p>\n<div>$$\np \\equiv m\\dot{q}\\\\\nf = ma = m\\ddot{q}\n$$</div>\n\n<p>保守力：</p>\n<div>$$\nf = -\\frac{\\partial V}{\\partial q}\n$$</div>\n\n<p>定义哈密顿量：</p>\n<div>$$\nH(q, p) = \\frac{p^2}{2m} + V(q)\n$$</div>\n\n<p>从而牛顿力学可以用正则方程代替：</p>\n<div>$$\n\\dot p = -\\frac{\\partial H}{\\partial q}, \\dot{q} = \\frac{\\partial H}{\\partial p}\n$$</div>\n\n<p>推广到体系：</p>\n<p>假设一个体系的运动可以用广义坐标$q_i$ $(i&#x3D;1,2,\\dots,n)$ 描述，拉格朗日函数为 $L(q_i, \\dot{q}_i, t)$。根据哈密顿原理，体系的运动满足哈密顿正则方程。</p>\n<p>哈密顿正则方程可表示为：</p>\n<p>$\\frac{\\partial H}{\\partial p_i} &#x3D; \\dot{q}_i, \\quad \\frac{\\partial H}{\\partial q_i} &#x3D; -\\dot{p}_i$</p>\n<p>其中，$H(p_i, q_i, t)$ 是哈密顿函数，定义为：</p>\n<p>$H(p_i, q_i, t) &#x3D; \\sum_{i&#x3D;1}^{n} p_i\\dot{q}_i - L(q_i, \\dot{q}_i, t)$</p>\n<p>其中，$p_i$ 是广义动量，定义为：</p>\n<p>$p_i &#x3D; \\frac{\\partial L}{\\partial \\dot{q}_i}$</p>\n<p>哈密顿正则方程描述了体系在广义坐标和广义动量空间中的运动行为，从而完整地描述了体系的运动。</p>\n<p>哈密顿函数H是否正确的判据：</p>\n<p>如果正则方程与已知的经典力学方程一致，则此哈密顿函数是正确的。</p>\n<p><strong>量子化（单粒子情况）</strong></p>\n<div>$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = \\left(-\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r)\\right)\\Psi\\\\\n$$</div>\n\n<p>$|\\Psi^2|$给出了粒子在空间中的位置概率。波函数结果数学变换，还能够给出各个力学量的概率分布（例如动量概率密度分布）。</p>\n<p>多粒子体系：</p>\n<p>对于全同多粒子体系，还需要引入新假设（对波函数施加新限制，后面讲）。</p>\n<p>统计物理怎样描述粒子运动？</p>\n<p>统计物理中需要引入新假设描述极大量粒子的热运动，这种运动不能由通常的量子力学给出。</p>\n<p>混合态：热运动的无规性会造成状态不能用一个确定的波函数描述，这种状态称为混合态（统计物理中体系的状态一般都是混合态）。</p>\n<p>纯态：量子力学部分都默认波函数是确定的，称为纯态（它是极特殊的情况）。单个粒子的叠加态依然是纯态。</p>\n<h3 id=\"第二章-薛定谔方程和一维运动问题\"><a href=\"#第二章-薛定谔方程和一维运动问题\" class=\"headerlink\" title=\"第二章 薛定谔方程和一维运动问题\"></a>第二章 薛定谔方程和一维运动问题</h3><h4 id=\"波函数及其统计解释\"><a href=\"#波函数及其统计解释\" class=\"headerlink\" title=\"波函数及其统计解释\"></a>波函数及其统计解释</h4><p><strong>波函数及其统计解释</strong></p>\n<p>Born 对双缝干涉的解释：$|\\Psi(\\vec r, t)|^2$与概率密度成正比</p>\n<p>$\\Psi(\\vec r, t)$称为概率幅，<strong>完全描写了状态（这种描写具有统计的特征）</strong>，它决定了各可观测的物理量的几率分布。</p>\n<p>波函数本身不能被直接观测。</p>\n<p><strong>波函数的归一化</strong></p>\n<p>$|\\psi(x, y, z, t)|^2$是相对几率密度。</p>\n<p>$|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$是t时刻出现在$x, y, z$处$\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$体积元内的相对几率。</p>\n<div>$$\n\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z = 1\n$$</div>\n\n<p>为了归一化，选择新的波函数$\\Psi(x, y, z, t)$</p>\n<div>$$\n\\Psi(x, y, z, t) = C\\psi(x, y, z, t)\n$$</div>\n\n<p>可得</p>\n<div>$$\n|C| = \\frac{1}{\\sqrt{\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z}}\n$$</div>\n\n<p>Remark:</p>\n<ul>\n<li>归一化的波函数仍然有一个位相因子不能确定。<strong>习惯上取C为正实数（相角为0）</strong>。</li>\n<li>有的波函数不能（有限地）归一。例如平面波$\\Psi(x, t) &#x3D; e^{-i(Et - px)&#x2F;\\hbar}$。$|\\Psi(x, t)|^2 &#x3D; 1$代表了在各处出现的机率相等。</li>\n</ul>\n<p><strong>态的叠加原理（重要）</strong></p>\n<p>若$\\Psi_1, \\Psi_2$是体系的可能状态，那么</p>\n<div>$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2\n$$</div>\n\n<p>也是体系的可能状态。</p>\n<p>干涉效应：</p>\n<!-- Psi, , mathbf -->\n\n<div>$$\n|\\Psi|^2 = |c_1\\Psi_1|^2 + |c_2\\Psi_2|^2 + \\underbrace{ c_1^*c_2\\Psi_1^*\\Psi_2 + c_1c_2^*\\Psi_1\\Psi_2^*}_{干涉项}\n$$</div>\n\n<p>因此，态相加不等于几率相加。</p>\n<p>关于相位：</p>\n<ul>\n<li>绝对常数相位没有意义</li>\n<li>相对常数相位才有意义</li>\n</ul>\n<div>$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2 = e^{i\\phi_1}(|c_1|\\Psi_1 + |c_2|e^{\\phi_2 - \\phi_1}\\Psi_2)\\\\\n$$</div>\n\n<p>$|\\Psi|^2$依赖于$\\phi_2 - \\phi_1$</p>\n<p>变化的相位是有意义的。(常数相因子可以扔掉)</p>\n<div>$$\n\\Psi(\\vec r, t) = |\\Psi(\\vec r, t)|e^{i\\varphi(\\vec r, t)}\n$$</div>\n\n<p>$\\varphi(\\vec r, t)$在空间几率密度上无法反映，但是在动量几率分布上可以反映出来。</p>\n<p><strong>态叠加原理的一般性描述</strong></p>\n<p>对于一个指定的量子体系，如果我们找到了它的“完备的基本状态集合”,那么任何状态都可以由这些基本状态叠加而得到。</p>\n<div>$$\n\\Psi = \\sum_n c_n \\Psi_n\n$$</div>\n\n<p>考虑自由粒子平面波的叠加：</p>\n<div>$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$</div>\n\n<p>自由电子的任何状态都可以写成：</p>\n<div>$$\n\\Psi = \\sum_{\\vec p} c_{\\vec p} \\Psi_{\\vec p}(\\vec r, t)\n$$</div>\n\n<p>又由于动量是连续分布的，改为积分：</p>\n<div>$$\n\\Psi = \\int_{\\infty} c({\\vec p}) \\Psi_{\\vec p}(\\vec r, t)\\mathrm d^3 \\vec p\n$$</div>\n\n<p>改写成另一种形式，把时间移到系数中：</p>\n<div>$$\n\\Psi = \\int_{\\infty} c({\\vec p, t}) \\Psi_{\\vec p}(\\vec r)\\mathrm d^3 \\vec p\n$$</div>\n其中\n<div>$$\nc(\\vec p,t) = c(\\vec p)e^{-iEt/\\hbar}\\\\\n\\psi_{\\vec p}(\\vec r) = Ae^{i\\vec p \\cdot \\vec r/\\hbar}\n$$</div>\n\n<p>基底称为动量本征函数，满足本征方程：$-ih\\nabla \\psi_{\\vec p}(r) &#x3D; \\vec p \\psi_{\\vec p}(\\vec r)$。$|c(\\vec p,t)|^2$就是概率密度。</p>\n<p>非自由粒子不能做第一种展开，因为含有$V(\\vec r)$项。</p>\n<p>固定时刻 $t &#x3D; t_1$, 此刻波函数为$\\Psi(\\vec r, t_1) &#x3D; \\Psi(\\vec r)$</p>\n<p>则</p>\n<div>$$\n\\Psi(\\vec{r}) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\n$$</div>\n\n<p>利用傅里叶变换计算$c(\\vec{p})$。</p>\n<p>首先定义delta函数，其满足</p>\n<div>$$\n\\delta(x - a) = \\begin{cases}\n    0, &x\\ne a\\\\\n    +\\infty, &x = a\n\\end{cases}\\\\\n\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx = 1\n$$</div>\n\n<p>或者定义为</p>\n<div>$$\n\\int\\limits_{\\infty}^{}f(x)\\delta(x - a)\\mathrm dx = f(a)\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx  = f(a)\n$$</div>\n\n<p>其中$\\int_\\infty &#x3D; \\int_{-\\infty}^{\\infty}$</p>\n<p>delta 函数性质：</p>\n<div>$$\n\\delta(x) = \\frac{1}{2\\pi}\\int\\limits_{\\infty}^{0}\\exp(ikx)\\mathrm dk\\\\\n\\delta(\\lambda x) = \\frac{1}{|\\lambda|}\\delta(x)\\ (\\delta \\ne 0)\n$$</div>\n\n<p>利用delta函数进行傅里叶变换：</p>\n<div>$$\n\\begin{align*}\n\\Psi(x) &= \\int\\limits_{\\infty}^{}\\Psi(x)\\delta(x - x^\\prime)\\mathrm dx^\\prime\\\\\n&=\\int\\limits_{\\infty}^{}\\Psi(x^\\prime)\\left(\\frac1{2\\pi}\\int\\limits_{\\infty}^{}e^{ik(x - x^\\prime)}\\mathrm dk\\right)\\mathrm dx^\\prime\\\\\n&= \\int\\limits_{\\infty}^{}\\left(\\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x^\\prime)e^{-ikx^\\prime}\\mathrm dx^\\prime\\right)e^{ikx}\\mathrm dk\n\\end{align*}\n$$</div>\n\n<p>因而</p>\n<div>$$\nc(k) = \\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x)\\exp({-ikx})\\mathrm dx\\\\\n\\Psi(x) = \\int\\limits_{\\infty}^{}c(k)\\exp(ikx)\\mathrm dk\n$$</div>\n\n<p>记$\\psi_p &#x3D; \\frac{1}{ \\sqrt{2\\pi \\hbar} }\\exp\\left(i\\frac{p}{\\hbar}x\\right)$</p>\n<p>则</p>\n<div>$$\n\\Psi(x) = \\int\\limits_{-\\infty}^{\\infty}c(p)\\psi_p(x)\\mathrm dp\\\\\nc(p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_p^*(x)\\Psi(x)\\mathrm dx\n$$</div>\n\n<p>推广到三维：</p>\n<div>$$\n\\Psi(\\vec r) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r)\\mathrm dx\\mathrm dy\\mathrm dz\n$$</div>\n\n<p>加入时间：</p>\n<div>$$\n\\Psi(\\vec r, t) = \\int\\limits_{\\infty}^{}c(\\vec p, t)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p, t) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r, t)\\mathrm dx\\mathrm dy\\mathrm dz\n$$</div>\n\n<p>已知$c(\\vec p, t)$可以求出动量概率密度和坐标概率密度。</p>\n<h4 id=\"薛定谔方程\"><a href=\"#薛定谔方程\" class=\"headerlink\" title=\"薛定谔方程\"></a>薛定谔方程</h4><p><strong>几率流密度</strong></p>\n<p>几率密度：</p>\n<div>$$\nw(\\vec{r}, t) = |\\Psi(\\vec{r}, t)|^2\n$$</div>\n\n<p>几率密度的时间变化率与某种“流”有关，类比电荷守恒方程：电荷密度的变化率等于电流密度散度的相反数。我们从薛定谔方程推导几率流密度：</p>\n<div>$$\n\\begin{align*}\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} &= -\\frac{\\hbar^2}{2\\mu} \\nabla^2\\Psi + U\\Psi \\Rightarrow\\\\\n    \\frac{\\partial w}{\\partial t} &= \\Psi^*\\frac{\\partial \\Psi}{\\partial t} + \\Psi\\frac{\\partial \\Psi^*}{\\partial t} \\\\\n    &= \\frac{i\\hbar}{2\\mu}(\\Psi^*\\nabla^2\\Psi - \\Psi\\nabla^2\\Psi^*)\\\\\n    &= \\frac{i\\hbar}{2\\mu} \\nabla \\cdot (\\Psi^*\\nabla\\Psi - \\Psi\\nabla\\Psi^*)\\\\\n\\end{align*}\n$$</div>\n\n<div>$$\n\\frac{\\partial w}{\\partial t} + \\nabla \\cdot \\vec J = 0\n$$</div>\n\n<p>从而可以定义</p>\n<div>$$\n\\vec J = \\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$</div>\n\n<p>对应的可以推积分形式：</p>\n<div>$$\n\\frac{\\mathrm dW_v}{\\mathrm dt} = - \\oint_S \\vec{J} \\cdot \\mathrm{d} \\vec S\n$$</div>\n\n<p>$\\vec J$便于记忆可写成</p>\n<div>$$\n\\vec J = \\text{Re}\\left[\\Psi^* \\mathrm {\\hat v} \\Psi\\right]\n$$</div>\n\n<p>其中 $\\mathrm{\\hat v} &#x3D; \\frac{\\vec{p}}{\\mu}$ 称为速度算符。</p>\n<p>可以计算电流密度</p>\n<div>$$\n\\vec J_e = e\\vec J = e\\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$</div>\n\n<p>可以计算原子内部电子的电流，计算超导体等量子系统的电流。</p>\n<p>例：平面波的几率流密度为$\\vec J &#x3D; w \\vec v$</p>\n<p>全空间总几率守恒：</p>\n<!-- oint j -->\n<div>$$\n\\frac{\\mathrm d}{\\mathrm dt} W = -\\oint_\\infty \\vec J \\cdot \\mathrm{d}\\vec S = -\\frac{i\\hbar}{2\\mu}  \\oint(\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi) \\cdot \\mathrm{d}\\vec S = 0\n$$</div>\n\n<p>这里认为波函数在无穷远处为0.</p>\n<p>如果粒子波函数在开始时刻是归一化的，则以后一直有归一化。</p>\n<p><strong>定态</strong></p>\n<p>定态波函数&#x3D;定态薛定谔方程乘以时间因子</p>\n<div>$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{h} Et}\\psi(\\vec r)\n$$</div>\n\n<p>$\\psi(\\vec r)$满足 $H\\psi(\\vec r) &#x3D; E\\psi(\\vec r)$</p>\n<p><strong>定态薛定谔方程</strong></p>\n<div>$$\nH\\psi(\\vec r) = E\\psi(\\vec r)\n$$</div>\n\n<p>$E$ 称为 $H$ 的本征值，$\\psi(\\vec r)$ 称为 $H$ 的本征函数。</p>\n<p><strong>含薛定谔方程的一般解</strong></p>\n<p>含时方程：$i\\hbar \\frac{\\partial \\Psi}{\\partial t} &#x3D; H\\Psi$</p>\n<p>定态方程： $H\\psi(\\vec r) &#x3D; E\\psi(\\vec r)$</p>\n<p>一般解：$\\Psi(\\vec r, t) &#x3D; \\sum_n c_n\\psi_n(\\vec r)e^{-\\frac{i}{h}E_n t}$</p>\n<p>定态下几率密度，几率流密度，力学几率分布和平均值都不随时间变化。</p>\n<p>一维自由粒子定态的基本解：</p>\n<div>$$\n\\psi = e^{i\\frac{p}{\\hbar}x} = e^{\\pm ikx}(p = \\pm \\hbar k, k = \\sqrt{\\frac{2\\mu E}{\\hbar})}\n$$</div>\n\n<p>能量给定后，状态并非唯一的（能量的简并），但是动量给定后，状态却是唯一的。</p>\n<p><strong>波函数应当满足以下三个条件</strong></p>\n<ul>\n<li>单值性</li>\n<li>有限性</li>\n<li>连续性</li>\n</ul>\n<p>连续性一般意味着 $\\Psi$ 和 $\\nabla\\Psi$ 都连续，但是在势能无穷大的地方，允许 $\\nabla\\Psi$ 不连续。</p>\n<h4 id=\"一维无限深势阱\"><a href=\"#一维无限深势阱\" class=\"headerlink\" title=\"一维无限深势阱\"></a>一维无限深势阱</h4><p><img src=\"/../images/%E9%87%8F%E7%AD%92/4%E2%80%94%E2%80%941.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><font color='red'>注意，这里的能量本征态不是动量本征态！这里的动量是连续的。因为波函数在0到a的范围内为三角函数，而在范围外为0，并不是周期函数，做傅里叶变换可知动量的图谱是连续的。</font></p>\n<h4 id=\"一维谐振子\"><a href=\"#一维谐振子\" class=\"headerlink\" title=\"一维谐振子\"></a>一维谐振子</h4><p><img src=\"/../images/%E9%87%8F%E7%AD%92/4_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"势垒穿透\"><a href=\"#势垒穿透\" class=\"headerlink\" title=\"势垒穿透\"></a>势垒穿透</h4><p><img src=\"/../images/%E9%87%8F%E7%AD%92/5_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h3 id=\"第三章\"><a href=\"#第三章\" class=\"headerlink\" title=\"第三章\"></a>第三章</h3><h4 id=\"动量算符和角动量算符\"><a href=\"#动量算符和角动量算符\" class=\"headerlink\" title=\"动量算符和角动量算符\"></a>动量算符和角动量算符</h4><p><strong>厄米算符</strong></p>\n<div>$$\n\\int_{}^{}\\psi^*(\\hat F \\varphi) \\cdot \\mathrm d\\tau = \\int_{}^{}(\\psi\\hat F)^*\\varphi \\cdot \\mathrm d\\tau\n$$</div>\n\n<p>厄米算符的本征值都是实数。</p>\n<p><strong>一维动量本征函数</strong></p>\n<div>$$\n\\hat p = -i\\hbar \\frac{\\mathrm d}{\\mathrm dx},\\\\\n\\hat p \\psi_p = p \\psi_p,\\\\\n\\psi_p = C \\exp\\big(\\frac{ipx}{\\hbar}\\big)\n$$</div>\n\n<p><strong>三维动量本征函数</strong></p>\n<div>$$\n\\psi_{\\vec p}(\\vec r) = \\frac{1}{\\sqrt{(2\\pi\\hbar^3)}}\\exp\\bigg(\\frac{i}{\\hbar}\\vec p \\cdot \\vec r\\bigg)\\\\\n\\int_{\\infty}^{}\\psi_{\\vec p}^*(\\vec r)\\psi_{\\vec p}(\\vec r)\\mathrm d\\tau = \\delta^3(\\vec p - \\vec p^\\prime)\n$$</div>\n\n<p>箱归一化本征函数：</p>\n<div>$$\n\\psi_{p}(-L / 2) =\\psi_{p}(L/2)\\\\\np = \\frac{2\\pi \\hbar}{n}, n=0, \\pm1, \\pm2, \\dots\\\\\n\\int_{-L/2}^{L/2}\\psi_{p}^*(x)\\psi_{p}(x)\\mathrm dx = \\delta_{pp^\\prime}\\\\\nL \\rightarrow \\infty\n$$</div>\n\n<p><strong>角动量算符</strong></p>\n<p>角动量算符的定义是：</p>\n<div>$$\n\\hat {\\vec L} = \\hat{\\vec r} \\times \\hat{\\vec p} = -i\\hbar \\vec r \\times \\nabla\\\\\n\\hat{L_x} = \n$$</div>\n\n<p>球坐标形式：</p>\n<p>球坐标单位向量用直角坐标表示：</p>\n<div>$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\n$$</div>\n\n<p>本征函数：</p>\n<div>$$\n\\psi_{m}(\\varphi) = C \\exp(im\\varphi)\n$$</div>\n\n<p>由于单值性 $\\psi_m(\\varphi + 2\\pi) &#x3D; \\psi_m(\\varphi)$：</p>\n<div>$$\nm = 0, \\pm1, \\pm2, \\dots\n$$</div>\n\n<p>归一化：$C &#x3D; \\frac{1}{\\sqrt{2\\pi}}$</p>\n<p>结论：</p>\n<div>$$\n\\hat L_z \\psi_m = m\\hbar \\psi_m\\\\\nm = 0, \\pm1, \\pm2, \\dots\n\\psi_m(\\varphi) = \\frac{1}{\\sqrt{2\\pi}} \\exp(im\\varphi)\n$$</div>\n\n<p>由于空间的任意一个方向都可以为z方向，因此角动量的任一分量都可以量子化。</p>\n<div>$$\n\\hat L^2 = -\\hbar^2\\bigg[\\frac{1}{\\sin \\theta}\\frac{\\partial }{\\partial \\theta}\\bigg(\\sin\\theta\\frac{\\partial }{\\partial \\theta}\\bigg) + \\frac{1}{\\sin^2\\theta}\\frac{\\partial^2}{\\partial \\varphi^2}\\bigg]\n$$</div>\n\n<div>$$\n\\hat L^2Y = \\lambda \\hbar^2Y\\\\\nY(\\theta, \\varphi) = P(\\theta)\\exp(im\\varphi)\n$$</div>\n\n<p>省流：球谐函数</p>\n<div>$$\nY_{lm}(\\theta, \\varphi) = N_{lm}P_l^m(\\cos \\theta)\\exp(im\\varphi)\n$$</div>\n\n<p>归一化系数</p>\n<div>$$\nN_{lm} = (-1)^m\\sqrt{\\frac{(2l + 1)}{4\\pi}\\frac{(l - |m|)!}{(l + |m|)!}}\n$$</div>\n\n<p>勒让德函数：</p>\n<div>$$\nP(w) = \\frac{1}{2^l l!}(1 - w^2)^{|m| / 2}\\frac{\\mathrm d^{l+|m|}}{\\mathrm dw^{l+|m|}}(w^2 - 1)^l\n$$</div>\n\n<p>前几个球谐函数：</p>\n<div>$$\nY_{00} = \\sqrt{\\frac{1}{4\\pi}}\\\\\nY_{10} = \\sqrt{\\frac{3}{4\\pi}}\\cos \\theta\\\\Y_{1, \\pm1} = \\mp \\sqrt{\\frac{3}{8\\pi}}\\sin \\theta \\exp(\\pm i\\varphi)\\\\\n$$</div>\n\n<p>$l &#x3D; 1$，是 $L^2$ 和 $L_z$ 的共同本征态，但不是 $L_x$ 和 $L_y$ 的本征态,(不确定性原理决定了这三个分量不能同时有本征态)</p>\n<p><strong>球谐函数的性质</strong></p>\n<div>$$\n\\hat L^2 Y_{lm} = l(l+1)\\hbar^2 Y_{lm}\\\\\n\\hat L_z Y_{lm} = m\\hbar Y_{lm}\\\\\nl = 0, 1, 2, \\dots\\\\\nm = l, l - 1, \\dots, -l.\n$$</div>\n\n<p>正交归一性：</p>\n<div>$$\n\\int Y^*_{l^\\prime m^\\prime}(\\theta, \\varphi)Y_{lm}(\\theta, \\varphi) \\mathrm d\\Omega = \\delta_{l^\\prime l}\\delta_{m^\\prime m}\n$$</div>\n\n<div>$$\nY^*_{lm}(\\theta, \\varphi) = (-1)^m Y_{l, -m}(\\theta, \\varphi)\n$$</div>\n\n<h4 id=\"中心力场的运动，氢原子\"><a href=\"#中心力场的运动，氢原子\" class=\"headerlink\" title=\"中心力场的运动，氢原子\"></a>中心力场的运动，氢原子</h4><p>经典：</p>\n<div>$$\nH = \\frac{1}{2}m_N\\dot{\\vec r_N^2} + \\frac{1}{2}m_e\\dot{\\vec r_e^2} + U(|\\vec r_e - \\vec r_N|)\n$$</div>\n\n<p>采用质心坐标和相对坐标：</p>\n<div>$$\n\\vec R = \\frac{m_N\\vec r_N + m_e \\vec r_e}{m_N + m_e}\\\\\n\\vec r = \\vec r_e - \\vec r_N\\\\\nM = m_N + m_e\\\\\n\\mu = \\frac{m_Nm_e}{M}\n$$</div>\n\n<div>$$\nH = \\frac{1}{2}M\\dot{\\vec R^2} + \\frac{1}{2}\\mu \\dot{\\vec r^2} + U(r)\\\\\n\\rArr H = \\frac{\\vec p_R^2}{2M} + \\frac{\\vec p^2}{2\\mu} + U(r)\n$$</div>\n\n<p>量子化：</p>\n<div>$$\nH = -\\frac{\\hbar^2}{2M}\\nabla_R^2 - \\frac{\\hbar}{2\\mu}\\nabla^2 + U(r)\n$$</div>\n\n<p>相对运动的动量意义是什么？</p>\n<p>求解氢原子波函数时，将哈密顿量分解为质心的哈密顿算符和相对坐标的哈密顿算符，然后分别求解。相对坐标对应的哈密顿算符求解得到的才是氢原子波函数。因此，<strong>得到的氢原子的能量不包括质心运动的能量。</strong></p>\n<p>省流：氢原子波函数</p>\n<div>$$\n\\psi_{nlm} = R_{nl}(r) Y_{lm}(\\theta, \\phi)\n$$</div>\n\n<p>其中径向函数</p>\n<div>$$\nR_{nl}(r) = \\frac{u_{nl}(r)}{r}, \\rho = \\alpha r\\\\\nu_{nl}(r) = N_{nl} \\rho^{l + 1}(\\rho) v_{nl}(\\rho) \\exp(-\\frac{1}{2}\\rho)\n$$</div>\n\n<div>$$\n主量子数\\quad n = 1, 2, 3,\\dots, \\rightarrow E_n = \\frac{E_1}{n^2}\\\\\n角量子数\\quad l = 0, 1, \\dots, n -1, \\rightarrow L^2 = l(l + 1)\\hbar^2\\\\\n磁量子数\\quad m = l, l - 1, \\dots, -l, \\rightarrow L_z = m\\hbar\\\\\n简并度\\quad g_n =\\sum\\limits_{l=0}^{n - 1}(2l + 1) = n^2\n$$</div>\n\n<p>定态波函数的宇称性质：</p>\n<div>$$\nR_nl(r) 偶函数，\n$$</div>\n\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/7_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_3.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>电子云有方向性吗？</p>\n<p>以 $n &#x3D; 2$ 为例，$Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 的模平方之和为常数。若氢原子随机等概率激发到 $Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 之一，则无方向性。但如果是相干叠加，则有方向性。</p>\n<p>为什么 $m$ 叫做磁量子数？</p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_4.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<div>$$\n\\vec J_e = (-e) \\vec J\n$$</div>\n\n<h4 id=\"本征函数系的一般性质\"><a href=\"#本征函数系的一般性质\" class=\"headerlink\" title=\"本征函数系的一般性质\"></a>本征函数系的一般性质</h4><p><strong>正交与归一</strong></p>\n<p>正交性定理</p>\n<p>同一个厄密算符 $\\hat F$ 的属于不同本征值的本征函数是彼此正交的。</p>\n<div>$$\n\\int_{}^{}\\psi_1^*\\psi_2\\mathrm d\\tau = 0\n$$</div>\n\n<p>本征函数的正交“归一”性</p>\n<p>离散情况：</p>\n<div>$$\n\\int_{}^{}\\phi_k^*(\\vec r) \\cdot \\phi_l(\\vec r)\\mathrm d\\tau = \\delta_{kl} = \\begin{cases}\n    0, k\\ne l\\\\\n    1, k = l\n\\end{cases}\n$$</div>\n\n<p>连续情况：</p>\n<div>$$\n\\int_{}^{}\\phi_{\\lambda^\\prime}^*(\\vec r) \\cdot \\phi_{\\lambda}(\\vec r)\\mathrm d\\tau = \\delta(\\lambda - \\lambda^\\prime)\n$$</div>\n\n<p>并非真正的归一化，但是依然满足正交性：例如 $\\frac{1}{\\sqrt{2\\pi \\hbar}}e^{\\frac{i}{\\hbar}px}$。</p>\n<p><strong>共同本征函数（重点）</strong></p>\n<p>定义对易括号</p>\n<div>$$\n[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G \\hat F\n$$</div>\n\n<p>若</p>\n<div>$$\n[\\hat F, \\hat G] = 0 \n$$</div>\n\n<p>则两算符对易。</p>\n<p>定理：</p>\n<div>$$\n[\\hat F, \\hat G] = 0 \\Rightarrow 两个算符有组成完全系的共同本征函数\n$$</div>\n\n<div>$$\n[\\hat {p_z}, \\hat {p_x}] = [\\hat {p_x}, \\hat {p_y}] = [\\hat {p_y}, \\hat {p_z }] = 0\n$$</div>\n\n<p>它们有共同的本征函数。</p>\n<div>$$\n[\\hat {xp}, \\hat {px}] = i\\hbar\n$$</div>\n\n<p>没有共同的本征函数。</p>\n<p>如果 $[\\hat {F}, \\hat {G}] \\ne 0$，则不一定没有共同本征态。例如角动量的本征态 $Y_{00}$。</p>\n<div>$$\n[\\hat {L^2}, \\hat {L_i}] = 0\\\\\n[\\hat {L_x}, \\hat {L_y}] = i\\hbar \\hat L_z\n$$</div>\n\n<p>性质：</p>\n<div>$$\n[A, BC] = [A, B]C + B[A, C]\n$$</div>\n\n<p>简并：力学量 $F$ 的一个本征值对应多个线性无关的本征函数。</p>\n<p><strong>力学量完全集（完备算符集）</strong></p>\n<p>为了消除简并，可以选取一组彼此对易的力学量 $F_1, F_2, F_3, \\dots$，使得它们的本征值组 $\\lambda_1, \\lambda_2, \\dots$ 对应唯一一个线性无关的共同本征函数 $\\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)$</p>\n<p>称 $F_1, F_2, F_3, \\dots$ 为力学量完全集。</p>\n<div>$$\nF_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r) = \\lambda_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)\n$$</div>\n\n<p>实现了正交化：力学量完全集的共同本征函数必然为正交函数系，因为任意两个本征函数，对应的本征值必然不同，由正交性定理得知，两个本征函数必然正交。</p>\n<p><strong>常见的选取方式</strong></p>\n<p>对于三维空间的单粒子，可以选取为：</p>\n<ul>\n<li>$(x, y, z)$</li>\n<li>$(p_x, p_y, p_z)$</li>\n<li>$(H, L^2, L_z)$（对于氢原子适用）</li>\n</ul>\n<p>考虑自旋后，还需要增加自旋力学量构成完全集。</p>\n<h4 id=\"力学量的平均值公式\"><a href=\"#力学量的平均值公式\" class=\"headerlink\" title=\"力学量的平均值公式\"></a>力学量的平均值公式</h4><div>$$\n\\overline{F(t)} = \\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx\n$$</div>\n\n<p>若没有归一化：</p>\n<div>$$\n\\overline F = \\frac{\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx}{\\int_{}^{}\\psi^*(x, t) \\psi(x, t)\\mathrm dx}\n$$</div>\n\n<p>实际上， 利用本征函数的正交性</p>\n<div>$$\n\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx =\\sum\\limits_{n}^{}\\lambda_n |c_n|^2 = \\overline{F}\n$$</div>\n\n<p>几率幅函数</p>\n<div>$$\nc_n(t) = \\int_{}^{}\\phi_n^*(x)\\psi(x, t)\\mathrm dx\n$$</div>\n\n<p>例题：</p>\n<div>$$\n\\psi = Ae^{ikx} + Be^{-ikx}\\\\\n$$</div>\n\n<p>动量值 $\\hbar k$ 与 $-\\hbar k$ 的概率比值为 $\\frac{|A|^2}{|B|^2}$</p>\n<div>$$\n\\bar p = \\hbar k  \\frac{|A|^2}{|A|^2 + |B|^2} + (-\\hbar k ) \\frac{|B|^2}{|A|^2 + |B|^2} = \\frac{|A|^2 - |B|^2}{|A|^2 + |B|^2}\\hbar k\n$$</div>\n\n<h4 id=\"不确定关系\"><a href=\"#不确定关系\" class=\"headerlink\" title=\"不确定关系\"></a>不确定关系</h4><p>一维谐振子为例：</p>\n<div>$$\n\\psi_(x) = \\sqrt{\\frac{\\alpha}{\\sqrt \\pi}} e^{-\\frac{1}{2}\\alpha^2 x^2}\\\\\nc_p = \\sqrt{\\frac{\\beta}{\\sqrt \\pi}}e^{-\\frac{\\beta^2p^2}{2}}\\\\\n\\frac{1}{\\alpha} \\cdot \\frac{1}{\\beta} = \\frac{1}{\\hbar}\\\\\n\\alpha = \\sqrt{\\frac{\\mu \\omega}{\\hbar}}\n$$</div>\n\n<p>不确定关系的数学表达以及证明</p>\n<p>如果两个力学量F和G的算符彼此不对易，则它们有不相容性，测量精确度（不确定度）上一般是相互制约的。</p>\n<div>$$\n\\Delta \\hat F = \\hat F - \\overline{ } F\\\\\n\\overline{(\\Delta \\hat F)^2} = \\overline{(\\hat F - \\overline{F})^2} = \\overline{\\hat F^2} - \\overline{F}^2\n$$</div>\n\n<p>记 $[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G\\hat F &#x3D; i\\hat C$，则在任意一个状态下</p>\n<div>$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$</div>\n\n<p>这里 $\\hat F$ 与 $\\hat G$ 都是厄密算符，所以 $\\overline{\\hat C}$ 为实数</p>\n<p>引入</p>\n<div>$$\nI(\\xi) = \\int_{}^{}\\left | (\\xi\\Delta \\hat F - i\\Delta \\hat G  )\\psi^2\\right|^2\\mathrm d\\tau \\ge 0\n$$</div>\n\n<div>$$\n\\begin{align*}\n    I(\\xi) =& \\xi^2\\int_{}^{}(\\Delta \\hat F \\psi)^* (\\Delta \\hat F \\psi)\\mathrm d\\tau - i\\xi \\int_{}^{}[(\\Delta \\hat F \\psi)^*(\\Delta \\hat G \\psi) - (\\Delta \\hat G \\psi)^*(\\Delta \\hat F \\psi)]\\mathrm d\\tau + \\int_{}^{}(\\Delta \\hat G\\psi)^*(\\Delta \\hat G\\psi)\\mathrm d\\tau\\\\\n    =& \\xi^2 \\int_{}^{}\\psi^*(\\Delta \\hat F)^2\\psi\\mathrm d\\tau - i\\xi \\int_{}^{}\\psi^*\\Delta\\hat F\\Delta \\hat G\\psi - \\psi^*\\Delta \\hat G\\Delta \\hat F\\psi\\mathrm d\\tau + \\int_{}^{}\\psi^*(\\Delta \\hat G)^2 \\psi\\mathrm d\\tau\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i\\overline{\\Delta \\hat F\\Delta \\hat G - \\Delta \\hat G \\Delta \\hat F}\\cdot \\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat { F}, \\hat { G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - \\overline{\\hat C}\\xi + \\overline{(\\Delta \\hat G)^2}\n\\end{align*}\n$$</div>\n\n<p>由于此式恒正，判别式大于0：</p>\n<div>$$\nI(\\xi) \\ge 0 \\Rightarrow \\overline{(\\Delta \\hat C)}^2 - 4\\overline{(\\Delta \\hat F)^2}\\cdot \\overline{(\\Delta \\hat G)^2} \\ge 0\n$$</div>\n\n<div>$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$</div>\n\n<p>如果要满足取等号条件：</p>\n<div>$$\n(\\xi \\Delta \\hat F - i \\Delta \\hat G)\\psi = 0\n$$</div>\n\n<p>此时的波包称为最小不确定波包</p>\n<p>位置动量不确定关系：</p>\n<div>$$\n\\overline{(\\Delta \\hat x)^2} \\overline{(\\Delta \\hat p_x) ^2} \\ge \\frac{\\hbar^2}{4}\n$$</div>\n\n<p>非零的“零点能”是不确定性关系的结果。</p>\n<div>$$\n\\overline E = \\frac{1}{2\\mu}\\overline{(\\Delta \\hat p_x)^2} + \\frac{1}{2}\\mu \\omega\\overline{(\\Delta \\hat x)^2} \\ge \\frac{1}{2}\\hbar\\omega\\\\\n\\overline E_{min} = \\frac{1}{2}\\hbar\\omega\\\\\n$$</div>\n\n<p>势垒穿透问题：谈论某一点的动能 T 和总能量 E 没有意义，因为 $\\hat x, \\hat T, \\hat H$ 彼此不对易。</p>\n<p>$H, T, U$ 三个物理量之间彼此不对易，不能同时具有确定的值。故 $H &#x3D; T + U$ 只是一个算符的等式。</p>\n<ul>\n<li>若为定态，则 $H$ 确定而 $T, U$ 不确定</li>\n<li>若位置确定，则 $U$ 确定但是 $T$ 和 $E$不确定</li>\n</ul>\n<p>求平均值：</p>\n<div>$$\n\\overline H = \\overline{ T} + \\overline U\n$$</div>\n\n<p>$T$ 的本征值为非负实数，所以</p>\n<div>$$\n\\overline{H} \\ge \\overline{ U}\n$$</div>\n\n<p>角动量 $Y_{00}$ 情形下，三个分量都具有确定的取值，三个角动量分量都为 0，还是满足不确定性关系。</p>\n<h4 id=\"守恒量\"><a href=\"#守恒量\" class=\"headerlink\" title=\"守恒量\"></a>守恒量</h4><p>要求任意态下 $F$ 平均值不变。</p>\n<p>平均值的时间演化</p>\n<div>$$\n\\hat H = i\\hbar \\frac{\\partial }{\\partial t}\n$$</div>\n\n<p>若算符 $\\hat F$ 不显含时间，则</p>\n<div>$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]}\n$$</div>\n\n<p>若 $\\hat F(t)$ 显含时间，则</p>\n<div>$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]} + \\overline{\\frac{\\partial }{\\partial t}\\hat F(t)}\n$$</div>\n\n<h3 id=\"第四章\"><a href=\"#第四章\" class=\"headerlink\" title=\"第四章\"></a>第四章</h3><h4 id=\"狄拉克算符和谐振子升降算符\"><a href=\"#狄拉克算符和谐振子升降算符\" class=\"headerlink\" title=\"狄拉克算符和谐振子升降算符\"></a>狄拉克算符和谐振子升降算符</h4><p>计算本征值问题</p>\n<p>谐振子：</p>\n<div>$$\nH = \\hbar \\omega \\frac{1}{2} \\left ( \\frac{p^2}{m\\hbar\\omega} + \\frac{m\\omega^2x^2}{\\hbar\\omega} \\right)\\\\\n\\alpha \\equiv \\sqrt{\\frac{m\\omega}{\\hbar}}\\\\\np^\\prime = \\frac{1}{\\hbar \\alpha}p\\\\\nx^\\prime = \\alpha x\\\\\n[\\hat {x^\\prime}, \\hat {p^\\prime}] = i\n$$</div>\n\n<div>$$\nH = \\hbar\\omega\\frac{1}{2}[(x^\\prime - ip^\\prime)(x^\\prime + ip^\\prime) + 1]\\\\\np^\\prime = -i \\frac{\\mathrm d}{\\mathrm dx^\\prime}\n$$</div>\n\n<p>基态满足</p>\n<div>$$\n(x^\\prime + ip^\\prime)\\psi_0(x) = 0\n$$</div>\n\n<p>通过升算符算出激发态</p>\n<div>$$\n\\psi_n = C_n (x^\\prime - ip^\\prime)^n\\psi_0(x)\n$$</div>\n\n<p>换元：</p>\n<div>$$\na = \\frac{x^\\prime + ip^\\prime}{\\sqrt{2}}\\\\\na^+ = \\frac{x^\\prime - ip^\\prime}{\\sqrt{2}}\\\\\nH = \\hbar \\omega(a^+a + \\frac{1}{2}) = \\hbar \\omega(\\hat N + \\frac{1}{2})\\\\\n[a, a^+] = 1\n$$</div>\n\n<p>设 $\\hat N$ 的本征矢为 $\\ket{n}$，称$n$为占有数。可以看出这本征矢也是能量的本征态。</p>\n<p>接下来计算 $\\hat N$ 的本征矢：</p>\n<div>$$\n\\langle \\hat N \\rangle = \\bra{n}a^+a\\ket{n} \\ge 0\\\\\n\\bra{n}a^+a\\ket{n} = n \\langle n|n \\rangle\\\\\n\\Rightarrow n \\ge 0\n$$</div>\n\n<p>如果存在 $n &#x3D; 0$ 的态：</p>\n<div>$$\n\\bra{0}a^+a\\ket{0} = 0\\\\\n\\Rightarrow a\\ket{0} = 0\n$$</div>\n\n<p>这就是基态满足的微分方程。解出基态的坐标表象：</p>\n<div>$$\n(\\alpha x + \\frac{1}{\\alpha} \\frac{\\mathrm d}{\\mathrm dx})\\psi_0(x) = 0\n$$</div>\n\n<p>重点：升降性质</p>\n<p>$a\\ket{n} &#x3D; \\ket{\\phi} &#x3D; \\ket{n - 1}$ 也是本征态。</p>\n<div>$$\n\\hat N \\ket{\\phi} = (a^+a)\\ket{\\phi} = (aa^+ - 1)\\ket{\\phi} = (aa^+ - 1)a\\ket{n} = aa^+a\\ket{n} - a\\ket{n} = a\\hat N\\ket{n} - a\\ket{n} = na\\ket{n} - a\\ket{n} = (n - 1)\\ket{\\phi}\n$$</div>\n\n<p>归一化：</p>\n<div>$$\n\\ket{\\phi} = c\\ket{n - 1}\\\\\n1 = \\langle n - 1 |n - 1 \\rangle = \\frac{1}{|c|^2}(an, an) = \\frac{1}{|c|^2}\\bra{n}a^+a\\ket{n} = \\frac{n}{|c|^2}\\\\\n取 c = \\sqrt{n}\\\\\na\\ket n = \\sqrt{n}\\ket{n - 1}\n$$</div>\n\n<p>升降算符（重点）：</p>\n<div>$$\na\\ket n = \\sqrt{n}\\ket{n - 1}\\\\\na\\ket{0} = 0\\\\\na^+\\ket{n} = \\sqrt{n + 1}\\ket{n + 1}\n$$</div>\n\n<p>$n$ 必为整数。</p>\n<p>能级：</p>\n<div>$$\nH = \\hbar \\omega(a^+a + \\frac{1}{2})\\\\\nE_n = \\hbar\\omega(n + \\frac{1}{2})\n$$</div>\n\n<p>波函数：</p>\n<div>$$\n\\ket n = \\frac{1}{\\sqrt{n}}a^+\\ket{n - 1} = \\frac{1}{\\sqrt{n!}}a^{+n}\\ket{0}\\\\\n\\psi_n(x) = \\frac{1}{\\sqrt{n!}}\\left (\\frac{1}{\\sqrt{2}}\\left (\\alpha x - \\frac{1}{\\alpha}\\frac{\\mathrm d}{\\mathrm dx}  \\right)  \\right)^n \\frac{\\sqrt{\\alpha}}{\\pi^{1/4}}e^{-\\alpha^2x^2/2}\n$$</div>\n\n<p>相干态：满足 $\\hat a \\ket \\beta &#x3D; \\beta \\ket \\beta$ 的 $\\ket \\beta$。</p>\n<h4 id=\"海森堡方程\"><a href=\"#海森堡方程\" class=\"headerlink\" title=\"海森堡方程\"></a>海森堡方程</h4><p>力学量算符含时，波函数不含时</p>\n<div>$$\n\\bra{\\psi(t)} F\\ket {\\psi(t)} \\rightarrow \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$</div>\n\n<p>不同图景在物理上等价</p>\n<div>$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{\\hbar}Ht}\\Psi(\\vec r, 0)\\\\\n\\ket{\\psi(t)} = U\\ket {\\psi(0)}\n$$</div>\n\n<p>力学量平均值</p>\n<div>$$\n\\overline{F} = \\bra{\\psi(t)}F\\ket{\\psi(t)} = \\bra{\\psi(0)}U^+FU\\ket{\\psi(0)} = \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$</div>\n\n<p>海森方程</p>\n<div>$$\nF_H = U^+(t)FU(t), U = e^{-\\frac{i}{\\hbar}Ht}, U^+ = e^{\\frac{i}{\\hbar}Ht}\\\\\n\\frac{\\mathrm d}{\\mathrm dt}U = \\frac{1}{i\\hbar}HU, \\frac{\\mathrm d}{\\mathrm dt}U^+ = -\\frac{1}{i\\hbar}HU^+, \\\\\n\\frac{\\mathrm d}{\\mathrm dt}F_H = \\frac{1}{i\\hbar}[F_H, H]\\\\\n\\frac{\\mathrm d\\ket{\\psi}_H}{\\mathrm dt} = 0\n$$</div>\n\n<div>$$\nHU = UH\n$$</div>\n\n<p>从经典到量子：</p>\n<div>$$\n\\dot q = \\frac{1}{i\\hbar}[q, H]\\\\\n\\dot p = \\frac{1}{i\\hbar}[p, H]\\\\\n[q, p] = i\\hbar\n$$</div>\n\n<h4 id=\"自旋\"><a href=\"#自旋\" class=\"headerlink\" title=\"自旋\"></a>自旋</h4><p>用标量波函数 $\\Psi(\\vec r, t)$ 描述是否完整？</p>\n<p>经典力学给出了轨道磁矩和磁势能</p>\n<div>$$\n\\vec M_L = -\\frac{e}{2m_e}\\vec L\\\\\nU = - \\vec M \\cdot \\vec B\n$$</div>\n\n<p>磁矩的最小单元(Bohr磁子)</p>\n<div>$$\nM_B \\equiv \\frac{e\\hbar}{2m_e}\n$$</div>\n\n<p>Stern-Gerlach 实验：即使是 $l &#x3D; 0$ 的 $s$ 态原子也会在磁场中偏转。认为电子除了轨道磁矩，还有自旋磁矩。</p>\n<p>自旋磁矩只有两个可能的值：</p>\n<div>$$\nM_B \\equiv \\frac{2\\hbar}{2m_e}\\\\\nM_z = \\pm M_B\n$$</div>\n\n<p>Uhlenbeck-Goudsmit假设(1925)：电子有内禀（自旋）角动量，其投影只能取两个值：</p>\n<div>$$\nS_i = \\pm \\frac{\\hbar }{2}, i = x, y , z\n$$</div>\n\n<p>自旋磁矩：</p>\n<div>$$\n\\hat {\\vec M_s} = -\\frac{e}{m_e}\\hat{\\vec S}\n$$</div>\n\n<p>自旋有纯量子力学的起源。没有经典对应，独立于之前学过的所有力学量。</p>\n<p>自旋的分量只有两个可能的测量值，因此可以使用 $2\\times 2$ 的矩阵描写。</p>\n<p>$S_z$的本征值为 $\\pm \\frac{\\hbar}{2}$，采用 $S_z$ 表象，则 $S_z &#x3D; \\frac{\\hbar}{2}\\begin{pmatrix}<br>    1 &amp;0\\<br>    0 &amp;-1<br>\\end{pmatrix}$</p>\n<p>根据角动量的对易关系（假设的）</p>\n<div>$$\n[S_x, S_y] = i\\hbar S_z\\\\\n[S_y, S_z] = i\\hbar S_x\\\\\n[S_z, S_x] = i\\hbar S_y\n$$</div>\n\n<p>可以导出 $S_x$ 和 $S_y$</p>\n<div>$$\nS_x = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\n\\end{pmatrix}\\\\\nS_y = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & -i\\\\\n    i & 0\n\\end{pmatrix}\\\\\nS_z = \\frac{\\hbar}{2}\\begin{pmatrix}\n    1 & 0\\\\\n    0 & -1\n\\end{pmatrix}\\\\\n$$</div>\n\n<p>三个分量不对易，最多只有一个分量具有确定的取值</p>\n<div>$$\nS_x^2 = S_y^2 = S_z^2 = \\frac{\\hbar^2}{4}\\\\\nS^2 = \\frac{3\\hbar^2}{4} = s(s + 1)\\hbar^2\\\\\n(s = \\frac{1}{2})\\\\\n[S^2, S_i] = 0\n$$</div>\n\n<p>自旋是内部基本构造，不同于先前学过的力学量，不能写成 $F(\\vec r, \\vec p)$ 的形式</p>\n<p>自旋也不能简单看成绕自身某个轴的旋转（电子被当作“点粒子”，自旋不同于经典物体的旋转，量子自旋没有经典的对应）</p>\n<p>带有自旋的电子波函数（自旋 + 空间坐标）</p>\n<div>$$\nv_+ = \\begin{pmatrix}\n    1\\\\0\n\\end{pmatrix}\nv_- = \\begin{pmatrix}\n    0\\\\1\n\\end{pmatrix}\n\n<p>\\Psi(\\vec r, t) \\cdot v_+ + \\Psi_2(\\vec r, t) \\cdot v_-<br>$$</div></p>\n<p>波函数有两个自旋分量（类比于电磁波有两个偏振分量）</p>\n<p>又被称为旋量波函数</p>\n<div>$$\n\\Psi = \\begin{pmatrix}\n    \\Psi_1(\\vec r, t)\\\\\n    \\Psi_2(\\vec r, t)\n\\end{pmatrix}\\\\\nw(\\vec r, t) = \\Psi^+\\Psi = |\\Psi_1|^2 + |\\Psi_2|^2\\\\\n\\int_{}^{}\\Psi^+\\Psi\\mathrm d\\tau = \\int_{}^{}(|\\Psi_1|^2 + |\\Psi_2|^2)\\mathrm d\\tau = 1\n$$</div>\n\n<p>自旋角动量的几率分布</p>\n<div>$$\nW \\left ( \\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_1|^2\\mathrm d\\tau\\\\\nW \\left ( -\\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_2|^2\\mathrm d\\tau\\\\\n$$</div>\n\n<h3 id=\"第五章-微扰论\"><a href=\"#第五章-微扰论\" class=\"headerlink\" title=\"第五章 微扰论\"></a>第五章 微扰论</h3><div>$$\n\\hat H \\psi_n = E_n \\psi_n\\\\\n\\hat H = \\hat H^{(0)} + \\hat H^\\prime\n$$</div>\n\n<p>作逐级展开：</p>\n<div>$$\n\\psi_n = \\psi_n^{(0)} + \\psi_n^{(1)} + \\psi_n^{(2)} + \\cdots\\\\\nE_n = E_n^{(0)} + E_n^{(1)} + E_n^{(2)} + \\cdots\\\\\n$$</div>\n\n<p>得到零级，一级，二级方程</p>\n<div>$$\n\\hat H^{(0)} \\psi_n^{(0)} = E_n^{(0)}\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(1)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(2)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(1)} + E_n^{(2)}\\psi_n^{(0)}\\\\\n$$</div>\n\n<h4 id=\"能量的非简并情形\"><a href=\"#能量的非简并情形\" class=\"headerlink\" title=\"能量的非简并情形\"></a>能量的非简并情形</h4><p>结论：能级一级修正</p>\n<div>$$\nE_n^{(1)} = H^\\prime_{nn} = \\int_{}^{}\\psi_n^{(0)*}\\hat{H}^\\prime\\psi_n^{(0)}\\mathrm d\\tau\n$$</div>\n\n<p>波函数一级修正</p>\n<div>$$\n\\psi_n(x) = \\psi_n^{(0)}(x) + \\psi_n^{(1)}(x)\\\\\n\\psi_n^{(1)}(x) =\\sum\\limits_{m\\ne n}^{}\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}}\\psi_m^{(0)}(x)\n$$</div>\n\n<p>适用条件：</p>\n<div>$$\n\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}} << 1\n$$</div>\n\n<p>二级能量修正公式：</p>\n<div>$$\nE_n^{(2)} =\\sum\\limits_{m\\ne n}^{}\\frac{|H_{mn}^\\prime|^2}{E_n^{(0)} - E_m^{(0)}}\n$$</div>\n\n<h4 id=\"零级能量的简并情形\"><a href=\"#零级能量的简并情形\" class=\"headerlink\" title=\"零级能量的简并情形\"></a>零级能量的简并情形</h4><p>需要确定适当的零级波函数，可以通过对初始的0级波函数进行表象变换得到。</p>\n<div>$$\n\\psi_{ni}^{(0)} =\\sum\\limits_{l=1}^{k}c_{li}^{(0)}\\phi_{nl}^{(0)}\n$$</div>\n\n<p>通过哈密顿量的修正值 $H^\\prime$ 来确定 0 级波函数的选取。1级方程左右同乘 $\\phi_l^{(0)*}$ 并积分，可得（下面的方程没有写n，表示都是同一个能级，系数c的下标对应1~k）</p>\n<div>$$\nH^\\prime C^{(0)} = E_n^{(1)}C^{(0)}\\\\\nH^\\prime_{ji} = \\int_{}^{}\\phi_j^{(0)*}\\hat H^\\prime\\phi_i^{(0)}\\mathrm d\\tau\\\\\nC^{(0)} = \\begin{pmatrix}\n    c_1^{(0)}\\\\c_2^{(0)}\\\\\\dots\\\\c_k^{(0)}\n\\end{pmatrix}\n$$</div>\n\n<p>对所有的 $l$ 做上述操作，求出所有的新的零级波函数。</p>\n<p>$H^\\prime$ 在 $E_n^{(0)}$ 对应的简并态子空间的 $k$ 个本征向量决定新的零级波函数 $\\psi_n^{(0)}$。对应的 $k$ 个本征值表示一级能量修正 $E_n^{(1)}$。这些一级能量互不相同，使得 $E_n^{(0)} + E_n^{(1)}$有 $k$ 个不同的值，也就是说零级加一级能量是“非简并态”。</p>\n<p>（这样做有什么意义？）</p>\n<p>简并微扰波函数的一级修正：</p>\n<div>$$\nc_{ml}^{(1)} = \\frac{\\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime \\psi_{nl}^{(0)}\\mathrm d\\tau}{E_n^{(0)} - E_m^{(0)}}\\\\\n\\psi_{nl}^{(1)} =\\sum\\limits_{m\\ne n}^{}c_{ml}^{(1)}\\phi_m^{(0)}\n$$</div>\n\n<p>注意！其中 $\\phi_m^{(0)}$ 是 $E_n^{(0)}$ 能级以外的态，这些态可以是简并的。</p>\n<p>能量的二级修正：</p>\n<div>$$\nE_{nl}^{(2)} =\\sum\\limits_{m\\ne n}^{} \\frac{\\left | \\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime\\psi_{nl}^{(0)}\\mathrm d\\tau \\right|^2}{E_n^{(0)} - E_m^{(0)}}\n$$</div>\n\n<p>如果求解的本征值有重根？</p>\n<p>此时零级波函数仍然不能求出来，但是可以求出能量一级修正；若考虑能量的二级修正，需要由二级方程确定零级波函数。</p>\n<h4 id=\"外磁场中的原子\"><a href=\"#外磁场中的原子\" class=\"headerlink\" title=\"外磁场中的原子\"></a>外磁场中的原子</h4><p>Zeeman 效应：外磁场中原子的能级会分裂</p>\n<p>简单 Zeeman 效应：外磁场作用很强， 可以略去自旋轨道耦合，这就是简单 Zeeman 效应</p>\n<div>$$\n\\vec M = \\vec M_L  + \\vec M_s \\approx -\\frac{e}{2\\mu}(\\vec L + 2\\vec S)\\\\\nU_m = -M_zB = \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\\\\\nH = H_0(氢原子) + \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\n$$</div>\n\n<p>结论：$\\psi_{n,l,m_l,m_s}$ 组成了完全函数系，对应能级为</p>\n<div>$$\nE_{n,l,m_l,m_s} = E_n + \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$</div>\n\n<p>Zeeman 效应可以调节原子能级，操控原子的量子态，灵敏检测磁场。</p>\n<p>如何用微扰论求解？</p>\n<p>显然，在上面介绍的波函数正好使得 $H^\\prime$ 成为一个对角矩阵：</p>\n<div>$$\n\\bra{\\psi_{n,l,m_l^\\prime,m_s\\prime}} H^\\prime \\ket{\\psi_{n,l,m_l,m_s}} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\\delta_{m_l^\\prime, m_l}\\delta_{m_s^\\prime, m_s}\\\\\nE_{n,l,m_l,m_s}^{(1)} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$</div>\n\n<p><strong>求自旋轨道耦合产生的精细结构？</strong></p>\n<p>（困难的拓展问题，在课程内不能完全解决）</p>\n<div>$$\nH = H_0 + H^\\prime\\\\\nH^\\prime = \\ksi(r)\\vec L \\cdot \\vec s\\\\\n\\ksi(r) = \\left ( \\frac{e^2}{8\\pi\\varepsilon_0} \\right)\\frac{1}{m_e^2c^2r^3}\n$$</div>\n\n<p>采用耦合表象基底 $L^2, L_z, S_z$ 共同本征态</p>\n<div>$$\n\\hat Y_{ljm} =\\sum\\limits_{m_lm_s}^{}c(l, j, m;l, m_l, m_s)Y_{lm_l}\\chi_{m_s} = \\ket{l, j, m}\n$$</div>\n\n<div>$$\n\\vec J = \\vec L + \\vec s\\\\\n\\vec L \\cdot \\vec s = \\frac{1}{2}(\\vec J^2 - \\vec L^2 - \\vec s^2)\n$$</div>\n\n<p>$H^\\prime$ 又是一个对角阵：</p>\n<div>$$\n\\bra{l^\\prime, j^\\prime, m^\\prime}\\vec L \\cdot \\vec s\\ket{l, j, m} = \\frac{1}{2} \\left [ j(j + 1) - l(l + 1) - \\frac{3}{4} \\right]\\hbar^2\\delta_{ll^\\prime}\\delta_{jj^\\prime}\\delta_{mm^\\prime}\n$$</div>\n\n\n<p>相对论得出的真实的精细结构跟 $l$ 并没有关系。</p>\n<p>考虑真空电磁场微扰形成的能级微小移动——兰姆位移。</p>\n<h2 id=\"统计力学\"><a href=\"#统计力学\" class=\"headerlink\" title=\"统计力学\"></a>统计力学</h2><h3 id=\"第一章\"><a href=\"#第一章\" class=\"headerlink\" title=\"第一章\"></a>第一章</h3><p>平衡态下孤立系统各种微观态的几率相等。</p>\n<p>最可几方法求玻色分布和费米分布</p>\n<p>求 $W \\lbrace n_i \\rbrace$ 的极大值</p>\n<div>$$\n\\bar u = \\frac{\\Sigma u \\lbrace n_i \\rbrace W \\lbrace n_i \\rbrace}{W \\lbrace n_i \\rbrace}\n$$</div>\n\n<h2 id=\"习题课\"><a href=\"#习题课\" class=\"headerlink\" title=\"习题课\"></a>习题课</h2><h3 id=\"20231028\"><a href=\"#20231028\" class=\"headerlink\" title=\"20231028\"></a>20231028</h3><h4 id=\"量子力学基本公理\"><a href=\"#量子力学基本公理\" class=\"headerlink\" title=\"量子力学基本公理\"></a>量子力学基本公理</h4><p>公理1：希尔伯特空间</p>\n<p>公理2：可观测量</p>\n<p>公理3：位置与动量（正则量子化）</p>\n<p>公理4：薛定谔方程</p>\n<p>公理5：全同粒子（略：讲统计时会讲）</p>\n<p>概率流密度的公式并不本质。根据薛定谔方程、概率密度公式、连续性方程可以推出。</p>\n<p>全空间概率密度$w(t)$不是 $x$ 的函数。</p>\n<p>要写盒外波函数为0.</p>\n<p>对任意的束缚的能量本征态, 动量的平均值是 0.</p>\n<div>$$\n[\\hat {x}, \\hat {H}] = [\\hat {x}, \\hat {p}^2/2\\mu] = \\frac{1}{2\\mu}(\\hat p[\\hat {x}, \\hat {p}] + [\\hat {x}, \\hat {p}]\\hat p) = \\frac{i\\hbar}{\\mu}\\hat p\n$$</div>\n\n<div>$$\n\\int_{-\\infty}^{\\infty}e^{-\\alpha x^2 + \\beta x}\\mathrm dx = \\sqrt{\\frac{\\pi}{\\alpha}}e^{\\beta^2/4\\alpha}\n$$</div>\n\n<h3 id=\"20231112\"><a href=\"#20231112\" class=\"headerlink\" title=\"20231112\"></a>20231112</h3><p><img src=\"/../images/%E9%87%8F%E7%AD%92/xt_2_1.jpg\" loading=\"lazy\"></p>\n<div>$$\n\\mu = -\\frac{e}{m}S\\\\\nU = - \\mu \\cdot B = -\\dfrac{eB}{m}S \\cdot n =\n$$</div>\n\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/xt_2_2.jpg\" loading=\"lazy\"></p>\n<p>透射率，反射率计算（用流密度）</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"量子力学\"><a href=\"#量子力学\" class=\"headerlink\" title=\"量子力学\"></a>量子力学</h2><h3 id=\"第一章-引言\"><a href=\"#第一章-引言\" class=\"headerlink\" title=\"第一章 引言\"></a>第一章 引言</h3><p>光的粒子性：</p>\n<ul>\n<li>黑体辐射</li>\n<li>光电效应</li>\n<li>康普顿散射</li>\n</ul>\n<p>原子模型：能级和跃迁</p>\n<p>电子衍射：例子的波动性</p>\n<p>黑体辐射的解释：</p>\n<h4 id=\"普朗克公式\"><a href=\"#普朗克公式\" class=\"headerlink\" title=\"普朗克公式\"></a>普朗克公式</h4><p>已知</p>\n<div>$$\nP(\\varepsilon_\\nu = nh\\nu) \\propto e^{-\\varepsilon_{\\nu}/kT}\n$$</div>\n\n<p>平均光子数</p>\n<div>$$\n\\overline{n} = \\frac{1}{e^{hv/kT} - 1}\\\\\n$$</div>\n\n<p>又知一个光子的能量$h\\nu$，模式密度（单位频率间隔的模式数）$8\\pi\\nu^2&#x2F;c^3$，故单位体积单位频率间隔之间的能量为</p>\n<div>$$\n\\rho(v) = \\frac{8\\pi \\nu^2}{c^3}\\overline{n}h\\nu\n$$</div>\n\n<h4 id=\"de-Broglie的物质波假说和薛定谔方程\"><a href=\"#de-Broglie的物质波假说和薛定谔方程\" class=\"headerlink\" title=\"de Broglie的物质波假说和薛定谔方程\"></a>de Broglie的物质波假说和薛定谔方程</h4><p>$\\hbar &#x3D; h&#x2F;2\\pi$</p>\n<div>$$\n\\vec{k} = \\frac{\\vec p}{\\hbar}, \\omega = \\frac{E}{\\hbar}\n$$</div>\n\n<p>注：非相对论粒子的能量$E &#x3D; p^2&#x2F;2m$，光子的能量$E&#x3D;cp$</p>\n<p><strong>自由粒子波函数</strong></p>\n<p>经典波改写：</p>\n<div>$$\n\\Psi(\\vec r, t) = Ae^{-i(\\omega t - \\vec k \\cdot \\vec r)} = A e^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$</div>\n\n<p>满足$E &#x3D; p^2&#x2F;2m$.</p>\n<p>试探得到，自由粒子波函数是薛定谔方程的解：</p>\n<div>$$\n\\begin{align*}\n\\vec p \\Psi &= -i \\hbar \\nabla\\Psi\\\\\n\\Rightarrow p^2\\Psi &= -\\hbar^2\\nabla^2\\Psi\\\\\n\\Rightarrow i\\hbar\\frac{\\partial \\Psi}{\\partial t} &= E\\Psi = \\frac{p^2\\Psi}{2m} = H\\Psi\\\\\n(H &= -\\frac{\\hbar^2}{2m}\\nabla^2)\n\\end{align*}\n$$</div>\n\n<p>由于$E$可以被$\\vec p$表示，故可以写成$\\vec p$的函数：</p>\n<div>$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i[E(\\vec p) t - \\vec p \\cdot \\vec r]/\\hbar}\n$$</div>\n\n<p>$\\Psi(\\vec r, t) &#x3D; \\sum_{\\vec p} C_{\\vec p}\\Psi_{\\vec p}(\\vec r, t)$满足薛定谔方程。</p>\n<p>如果有势能项，薛定谔方程改为：</p>\n<div>$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = -\\frac{\\hbar^2}{2m}\\nabla^2\\Psi(\\vec r, t) + V(\\vec r)\\Psi(\\vec r, t)\\\\\n$$</div>\n\n<p>这里</p>\n<div>$$\nH = -\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r) \\equiv \\frac{\\hat p^2}{2m} + V(\\vec r)\n$$</div>\n\n<p>引入了动量算符（量子化假设）$\\hat p &#x3D; -i\\hbar \\nabla$</p>\n<p>注：从薛定谔方程的形式可以得知，其解的表达式里$t$前面的系数肯定含$-i$。如果含$i$，是不满足薛定谔方程的。</p>\n<h4 id=\"从经典到量子的过渡\"><a href=\"#从经典到量子的过渡\" class=\"headerlink\" title=\"从经典到量子的过渡\"></a>从经典到量子的过渡</h4><p><strong>以一维单粒子为例：</strong></p>\n<p>牛顿力学：</p>\n<div>$$\np \\equiv m\\dot{q}\\\\\nf = ma = m\\ddot{q}\n$$</div>\n\n<p>保守力：</p>\n<div>$$\nf = -\\frac{\\partial V}{\\partial q}\n$$</div>\n\n<p>定义哈密顿量：</p>\n<div>$$\nH(q, p) = \\frac{p^2}{2m} + V(q)\n$$</div>\n\n<p>从而牛顿力学可以用正则方程代替：</p>\n<div>$$\n\\dot p = -\\frac{\\partial H}{\\partial q}, \\dot{q} = \\frac{\\partial H}{\\partial p}\n$$</div>\n\n<p>推广到体系：</p>\n<p>假设一个体系的运动可以用广义坐标$q_i$ $(i&#x3D;1,2,\\dots,n)$ 描述，拉格朗日函数为 $L(q_i, \\dot{q}_i, t)$。根据哈密顿原理，体系的运动满足哈密顿正则方程。</p>\n<p>哈密顿正则方程可表示为：</p>\n<p>$\\frac{\\partial H}{\\partial p_i} &#x3D; \\dot{q}_i, \\quad \\frac{\\partial H}{\\partial q_i} &#x3D; -\\dot{p}_i$</p>\n<p>其中，$H(p_i, q_i, t)$ 是哈密顿函数，定义为：</p>\n<p>$H(p_i, q_i, t) &#x3D; \\sum_{i&#x3D;1}^{n} p_i\\dot{q}_i - L(q_i, \\dot{q}_i, t)$</p>\n<p>其中，$p_i$ 是广义动量，定义为：</p>\n<p>$p_i &#x3D; \\frac{\\partial L}{\\partial \\dot{q}_i}$</p>\n<p>哈密顿正则方程描述了体系在广义坐标和广义动量空间中的运动行为，从而完整地描述了体系的运动。</p>\n<p>哈密顿函数H是否正确的判据：</p>\n<p>如果正则方程与已知的经典力学方程一致，则此哈密顿函数是正确的。</p>\n<p><strong>量子化（单粒子情况）</strong></p>\n<div>$$\ni\\hbar\\frac{\\partial \\Psi}{\\partial t}= H\\Psi = \\left(-\\frac{\\hbar^2}{2m}\\nabla^2 + V(\\vec r)\\right)\\Psi\\\\\n$$</div>\n\n<p>$|\\Psi^2|$给出了粒子在空间中的位置概率。波函数结果数学变换，还能够给出各个力学量的概率分布（例如动量概率密度分布）。</p>\n<p>多粒子体系：</p>\n<p>对于全同多粒子体系，还需要引入新假设（对波函数施加新限制，后面讲）。</p>\n<p>统计物理怎样描述粒子运动？</p>\n<p>统计物理中需要引入新假设描述极大量粒子的热运动，这种运动不能由通常的量子力学给出。</p>\n<p>混合态：热运动的无规性会造成状态不能用一个确定的波函数描述，这种状态称为混合态（统计物理中体系的状态一般都是混合态）。</p>\n<p>纯态：量子力学部分都默认波函数是确定的，称为纯态（它是极特殊的情况）。单个粒子的叠加态依然是纯态。</p>\n<h3 id=\"第二章-薛定谔方程和一维运动问题\"><a href=\"#第二章-薛定谔方程和一维运动问题\" class=\"headerlink\" title=\"第二章 薛定谔方程和一维运动问题\"></a>第二章 薛定谔方程和一维运动问题</h3><h4 id=\"波函数及其统计解释\"><a href=\"#波函数及其统计解释\" class=\"headerlink\" title=\"波函数及其统计解释\"></a>波函数及其统计解释</h4><p><strong>波函数及其统计解释</strong></p>\n<p>Born 对双缝干涉的解释：$|\\Psi(\\vec r, t)|^2$与概率密度成正比</p>\n<p>$\\Psi(\\vec r, t)$称为概率幅，<strong>完全描写了状态（这种描写具有统计的特征）</strong>，它决定了各可观测的物理量的几率分布。</p>\n<p>波函数本身不能被直接观测。</p>\n<p><strong>波函数的归一化</strong></p>\n<p>$|\\psi(x, y, z, t)|^2$是相对几率密度。</p>\n<p>$|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$是t时刻出现在$x, y, z$处$\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z$体积元内的相对几率。</p>\n<div>$$\n\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z = 1\n$$</div>\n\n<p>为了归一化，选择新的波函数$\\Psi(x, y, z, t)$</p>\n<div>$$\n\\Psi(x, y, z, t) = C\\psi(x, y, z, t)\n$$</div>\n\n<p>可得</p>\n<div>$$\n|C| = \\frac{1}{\\sqrt{\\int_{全空间}|\\psi(x, y, z, t)|^2\\mathrm{d}x\\mathrm{d}y\\mathrm{d}z}}\n$$</div>\n\n<p>Remark:</p>\n<ul>\n<li>归一化的波函数仍然有一个位相因子不能确定。<strong>习惯上取C为正实数（相角为0）</strong>。</li>\n<li>有的波函数不能（有限地）归一。例如平面波$\\Psi(x, t) &#x3D; e^{-i(Et - px)&#x2F;\\hbar}$。$|\\Psi(x, t)|^2 &#x3D; 1$代表了在各处出现的机率相等。</li>\n</ul>\n<p><strong>态的叠加原理（重要）</strong></p>\n<p>若$\\Psi_1, \\Psi_2$是体系的可能状态，那么</p>\n<div>$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2\n$$</div>\n\n<p>也是体系的可能状态。</p>\n<p>干涉效应：</p>\n<!-- Psi, , mathbf -->\n\n<div>$$\n|\\Psi|^2 = |c_1\\Psi_1|^2 + |c_2\\Psi_2|^2 + \\underbrace{ c_1^*c_2\\Psi_1^*\\Psi_2 + c_1c_2^*\\Psi_1\\Psi_2^*}_{干涉项}\n$$</div>\n\n<p>因此，态相加不等于几率相加。</p>\n<p>关于相位：</p>\n<ul>\n<li>绝对常数相位没有意义</li>\n<li>相对常数相位才有意义</li>\n</ul>\n<div>$$\n\\Psi = c_1\\Psi_1 + c_2\\Psi_2 = e^{i\\phi_1}(|c_1|\\Psi_1 + |c_2|e^{\\phi_2 - \\phi_1}\\Psi_2)\\\\\n$$</div>\n\n<p>$|\\Psi|^2$依赖于$\\phi_2 - \\phi_1$</p>\n<p>变化的相位是有意义的。(常数相因子可以扔掉)</p>\n<div>$$\n\\Psi(\\vec r, t) = |\\Psi(\\vec r, t)|e^{i\\varphi(\\vec r, t)}\n$$</div>\n\n<p>$\\varphi(\\vec r, t)$在空间几率密度上无法反映，但是在动量几率分布上可以反映出来。</p>\n<p><strong>态叠加原理的一般性描述</strong></p>\n<p>对于一个指定的量子体系，如果我们找到了它的“完备的基本状态集合”,那么任何状态都可以由这些基本状态叠加而得到。</p>\n<div>$$\n\\Psi = \\sum_n c_n \\Psi_n\n$$</div>\n\n<p>考虑自由粒子平面波的叠加：</p>\n<div>$$\n\\Psi_{\\vec p}(\\vec r, t) = Ae^{-i(Et - \\vec p \\cdot \\vec r)/\\hbar}\n$$</div>\n\n<p>自由电子的任何状态都可以写成：</p>\n<div>$$\n\\Psi = \\sum_{\\vec p} c_{\\vec p} \\Psi_{\\vec p}(\\vec r, t)\n$$</div>\n\n<p>又由于动量是连续分布的，改为积分：</p>\n<div>$$\n\\Psi = \\int_{\\infty} c({\\vec p}) \\Psi_{\\vec p}(\\vec r, t)\\mathrm d^3 \\vec p\n$$</div>\n\n<p>改写成另一种形式，把时间移到系数中：</p>\n<div>$$\n\\Psi = \\int_{\\infty} c({\\vec p, t}) \\Psi_{\\vec p}(\\vec r)\\mathrm d^3 \\vec p\n$$</div>\n其中\n<div>$$\nc(\\vec p,t) = c(\\vec p)e^{-iEt/\\hbar}\\\\\n\\psi_{\\vec p}(\\vec r) = Ae^{i\\vec p \\cdot \\vec r/\\hbar}\n$$</div>\n\n<p>基底称为动量本征函数，满足本征方程：$-ih\\nabla \\psi_{\\vec p}(r) &#x3D; \\vec p \\psi_{\\vec p}(\\vec r)$。$|c(\\vec p,t)|^2$就是概率密度。</p>\n<p>非自由粒子不能做第一种展开，因为含有$V(\\vec r)$项。</p>\n<p>固定时刻 $t &#x3D; t_1$, 此刻波函数为$\\Psi(\\vec r, t_1) &#x3D; \\Psi(\\vec r)$</p>\n<p>则</p>\n<div>$$\n\\Psi(\\vec{r}) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\n$$</div>\n\n<p>利用傅里叶变换计算$c(\\vec{p})$。</p>\n<p>首先定义delta函数，其满足</p>\n<div>$$\n\\delta(x - a) = \\begin{cases}\n    0, &x\\ne a\\\\\n    +\\infty, &x = a\n\\end{cases}\\\\\n\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx = 1\n$$</div>\n\n<p>或者定义为</p>\n<div>$$\n\\int\\limits_{\\infty}^{}f(x)\\delta(x - a)\\mathrm dx = f(a)\\int\\limits_{\\infty}^{}\\delta(x - a)\\mathrm dx  = f(a)\n$$</div>\n\n<p>其中$\\int_\\infty &#x3D; \\int_{-\\infty}^{\\infty}$</p>\n<p>delta 函数性质：</p>\n<div>$$\n\\delta(x) = \\frac{1}{2\\pi}\\int\\limits_{\\infty}^{0}\\exp(ikx)\\mathrm dk\\\\\n\\delta(\\lambda x) = \\frac{1}{|\\lambda|}\\delta(x)\\ (\\delta \\ne 0)\n$$</div>\n\n<p>利用delta函数进行傅里叶变换：</p>\n<div>$$\n\\begin{align*}\n\\Psi(x) &= \\int\\limits_{\\infty}^{}\\Psi(x)\\delta(x - x^\\prime)\\mathrm dx^\\prime\\\\\n&=\\int\\limits_{\\infty}^{}\\Psi(x^\\prime)\\left(\\frac1{2\\pi}\\int\\limits_{\\infty}^{}e^{ik(x - x^\\prime)}\\mathrm dk\\right)\\mathrm dx^\\prime\\\\\n&= \\int\\limits_{\\infty}^{}\\left(\\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x^\\prime)e^{-ikx^\\prime}\\mathrm dx^\\prime\\right)e^{ikx}\\mathrm dk\n\\end{align*}\n$$</div>\n\n<p>因而</p>\n<div>$$\nc(k) = \\int\\limits_{\\infty}^{}\\frac1{2\\pi}\\Psi(x)\\exp({-ikx})\\mathrm dx\\\\\n\\Psi(x) = \\int\\limits_{\\infty}^{}c(k)\\exp(ikx)\\mathrm dk\n$$</div>\n\n<p>记$\\psi_p &#x3D; \\frac{1}{ \\sqrt{2\\pi \\hbar} }\\exp\\left(i\\frac{p}{\\hbar}x\\right)$</p>\n<p>则</p>\n<div>$$\n\\Psi(x) = \\int\\limits_{-\\infty}^{\\infty}c(p)\\psi_p(x)\\mathrm dp\\\\\nc(p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_p^*(x)\\Psi(x)\\mathrm dx\n$$</div>\n\n<p>推广到三维：</p>\n<div>$$\n\\Psi(\\vec r) = \\int\\limits_{\\infty}^{}c(\\vec p)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r)\\mathrm dx\\mathrm dy\\mathrm dz\n$$</div>\n\n<p>加入时间：</p>\n<div>$$\n\\Psi(\\vec r, t) = \\int\\limits_{\\infty}^{}c(\\vec p, t)\\Psi_{\\vec p}(\\vec r)\\mathrm d^3\\vec p\\\\\n\\psi_{\\vec p} = \\frac{1}{\\sqrt{2\\pi \\hbar}^3}\\exp\\left(i\\frac{\\vec p}{\\hbar} \\cdot \\vec r\\right)\\\\\nc(\\vec p, t) = \\int\\limits_{-\\infty}^{\\infty}\\psi_{\\vec p}^*(\\vec r) \\Psi(\\vec r, t)\\mathrm dx\\mathrm dy\\mathrm dz\n$$</div>\n\n<p>已知$c(\\vec p, t)$可以求出动量概率密度和坐标概率密度。</p>\n<h4 id=\"薛定谔方程\"><a href=\"#薛定谔方程\" class=\"headerlink\" title=\"薛定谔方程\"></a>薛定谔方程</h4><p><strong>几率流密度</strong></p>\n<p>几率密度：</p>\n<div>$$\nw(\\vec{r}, t) = |\\Psi(\\vec{r}, t)|^2\n$$</div>\n\n<p>几率密度的时间变化率与某种“流”有关，类比电荷守恒方程：电荷密度的变化率等于电流密度散度的相反数。我们从薛定谔方程推导几率流密度：</p>\n<div>$$\n\\begin{align*}\ni\\hbar \\frac{\\partial \\Psi}{\\partial t} &= -\\frac{\\hbar^2}{2\\mu} \\nabla^2\\Psi + U\\Psi \\Rightarrow\\\\\n    \\frac{\\partial w}{\\partial t} &= \\Psi^*\\frac{\\partial \\Psi}{\\partial t} + \\Psi\\frac{\\partial \\Psi^*}{\\partial t} \\\\\n    &= \\frac{i\\hbar}{2\\mu}(\\Psi^*\\nabla^2\\Psi - \\Psi\\nabla^2\\Psi^*)\\\\\n    &= \\frac{i\\hbar}{2\\mu} \\nabla \\cdot (\\Psi^*\\nabla\\Psi - \\Psi\\nabla\\Psi^*)\\\\\n\\end{align*}\n$$</div>\n\n<div>$$\n\\frac{\\partial w}{\\partial t} + \\nabla \\cdot \\vec J = 0\n$$</div>\n\n<p>从而可以定义</p>\n<div>$$\n\\vec J = \\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$</div>\n\n<p>对应的可以推积分形式：</p>\n<div>$$\n\\frac{\\mathrm dW_v}{\\mathrm dt} = - \\oint_S \\vec{J} \\cdot \\mathrm{d} \\vec S\n$$</div>\n\n<p>$\\vec J$便于记忆可写成</p>\n<div>$$\n\\vec J = \\text{Re}\\left[\\Psi^* \\mathrm {\\hat v} \\Psi\\right]\n$$</div>\n\n<p>其中 $\\mathrm{\\hat v} &#x3D; \\frac{\\vec{p}}{\\mu}$ 称为速度算符。</p>\n<p>可以计算电流密度</p>\n<div>$$\n\\vec J_e = e\\vec J = e\\frac{i\\hbar}{2\\mu} (\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi)\n$$</div>\n\n<p>可以计算原子内部电子的电流，计算超导体等量子系统的电流。</p>\n<p>例：平面波的几率流密度为$\\vec J &#x3D; w \\vec v$</p>\n<p>全空间总几率守恒：</p>\n<!-- oint j -->\n<div>$$\n\\frac{\\mathrm d}{\\mathrm dt} W = -\\oint_\\infty \\vec J \\cdot \\mathrm{d}\\vec S = -\\frac{i\\hbar}{2\\mu}  \\oint(\\Psi\\nabla\\Psi^* - \\Psi^*\\nabla\\Psi) \\cdot \\mathrm{d}\\vec S = 0\n$$</div>\n\n<p>这里认为波函数在无穷远处为0.</p>\n<p>如果粒子波函数在开始时刻是归一化的，则以后一直有归一化。</p>\n<p><strong>定态</strong></p>\n<p>定态波函数&#x3D;定态薛定谔方程乘以时间因子</p>\n<div>$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{h} Et}\\psi(\\vec r)\n$$</div>\n\n<p>$\\psi(\\vec r)$满足 $H\\psi(\\vec r) &#x3D; E\\psi(\\vec r)$</p>\n<p><strong>定态薛定谔方程</strong></p>\n<div>$$\nH\\psi(\\vec r) = E\\psi(\\vec r)\n$$</div>\n\n<p>$E$ 称为 $H$ 的本征值，$\\psi(\\vec r)$ 称为 $H$ 的本征函数。</p>\n<p><strong>含薛定谔方程的一般解</strong></p>\n<p>含时方程：$i\\hbar \\frac{\\partial \\Psi}{\\partial t} &#x3D; H\\Psi$</p>\n<p>定态方程： $H\\psi(\\vec r) &#x3D; E\\psi(\\vec r)$</p>\n<p>一般解：$\\Psi(\\vec r, t) &#x3D; \\sum_n c_n\\psi_n(\\vec r)e^{-\\frac{i}{h}E_n t}$</p>\n<p>定态下几率密度，几率流密度，力学几率分布和平均值都不随时间变化。</p>\n<p>一维自由粒子定态的基本解：</p>\n<div>$$\n\\psi = e^{i\\frac{p}{\\hbar}x} = e^{\\pm ikx}(p = \\pm \\hbar k, k = \\sqrt{\\frac{2\\mu E}{\\hbar})}\n$$</div>\n\n<p>能量给定后，状态并非唯一的（能量的简并），但是动量给定后，状态却是唯一的。</p>\n<p><strong>波函数应当满足以下三个条件</strong></p>\n<ul>\n<li>单值性</li>\n<li>有限性</li>\n<li>连续性</li>\n</ul>\n<p>连续性一般意味着 $\\Psi$ 和 $\\nabla\\Psi$ 都连续，但是在势能无穷大的地方，允许 $\\nabla\\Psi$ 不连续。</p>\n<h4 id=\"一维无限深势阱\"><a href=\"#一维无限深势阱\" class=\"headerlink\" title=\"一维无限深势阱\"></a>一维无限深势阱</h4><p><img src=\"/../images/%E9%87%8F%E7%AD%92/4%E2%80%94%E2%80%941.jpg\" alt=\"alt\"></p>\n<p><font color='red'>注意，这里的能量本征态不是动量本征态！这里的动量是连续的。因为波函数在0到a的范围内为三角函数，而在范围外为0，并不是周期函数，做傅里叶变换可知动量的图谱是连续的。</font></p>\n<h4 id=\"一维谐振子\"><a href=\"#一维谐振子\" class=\"headerlink\" title=\"一维谐振子\"></a>一维谐振子</h4><p><img src=\"/../images/%E9%87%8F%E7%AD%92/4_2.jpg\" alt=\"alt\"></p>\n<h4 id=\"势垒穿透\"><a href=\"#势垒穿透\" class=\"headerlink\" title=\"势垒穿透\"></a>势垒穿透</h4><p><img src=\"/../images/%E9%87%8F%E7%AD%92/5_1.jpg\" alt=\"alt\"></p>\n<h3 id=\"第三章\"><a href=\"#第三章\" class=\"headerlink\" title=\"第三章\"></a>第三章</h3><h4 id=\"动量算符和角动量算符\"><a href=\"#动量算符和角动量算符\" class=\"headerlink\" title=\"动量算符和角动量算符\"></a>动量算符和角动量算符</h4><p><strong>厄米算符</strong></p>\n<div>$$\n\\int_{}^{}\\psi^*(\\hat F \\varphi) \\cdot \\mathrm d\\tau = \\int_{}^{}(\\psi\\hat F)^*\\varphi \\cdot \\mathrm d\\tau\n$$</div>\n\n<p>厄米算符的本征值都是实数。</p>\n<p><strong>一维动量本征函数</strong></p>\n<div>$$\n\\hat p = -i\\hbar \\frac{\\mathrm d}{\\mathrm dx},\\\\\n\\hat p \\psi_p = p \\psi_p,\\\\\n\\psi_p = C \\exp\\big(\\frac{ipx}{\\hbar}\\big)\n$$</div>\n\n<p><strong>三维动量本征函数</strong></p>\n<div>$$\n\\psi_{\\vec p}(\\vec r) = \\frac{1}{\\sqrt{(2\\pi\\hbar^3)}}\\exp\\bigg(\\frac{i}{\\hbar}\\vec p \\cdot \\vec r\\bigg)\\\\\n\\int_{\\infty}^{}\\psi_{\\vec p}^*(\\vec r)\\psi_{\\vec p}(\\vec r)\\mathrm d\\tau = \\delta^3(\\vec p - \\vec p^\\prime)\n$$</div>\n\n<p>箱归一化本征函数：</p>\n<div>$$\n\\psi_{p}(-L / 2) =\\psi_{p}(L/2)\\\\\np = \\frac{2\\pi \\hbar}{n}, n=0, \\pm1, \\pm2, \\dots\\\\\n\\int_{-L/2}^{L/2}\\psi_{p}^*(x)\\psi_{p}(x)\\mathrm dx = \\delta_{pp^\\prime}\\\\\nL \\rightarrow \\infty\n$$</div>\n\n<p><strong>角动量算符</strong></p>\n<p>角动量算符的定义是：</p>\n<div>$$\n\\hat {\\vec L} = \\hat{\\vec r} \\times \\hat{\\vec p} = -i\\hbar \\vec r \\times \\nabla\\\\\n\\hat{L_x} = \n$$</div>\n\n<p>球坐标形式：</p>\n<p>球坐标单位向量用直角坐标表示：</p>\n<div>$$\n\\hat L_z = -i\\hbar \\frac{\\partial }{\\partial \\varphi}\n$$</div>\n\n<p>本征函数：</p>\n<div>$$\n\\psi_{m}(\\varphi) = C \\exp(im\\varphi)\n$$</div>\n\n<p>由于单值性 $\\psi_m(\\varphi + 2\\pi) &#x3D; \\psi_m(\\varphi)$：</p>\n<div>$$\nm = 0, \\pm1, \\pm2, \\dots\n$$</div>\n\n<p>归一化：$C &#x3D; \\frac{1}{\\sqrt{2\\pi}}$</p>\n<p>结论：</p>\n<div>$$\n\\hat L_z \\psi_m = m\\hbar \\psi_m\\\\\nm = 0, \\pm1, \\pm2, \\dots\n\\psi_m(\\varphi) = \\frac{1}{\\sqrt{2\\pi}} \\exp(im\\varphi)\n$$</div>\n\n<p>由于空间的任意一个方向都可以为z方向，因此角动量的任一分量都可以量子化。</p>\n<div>$$\n\\hat L^2 = -\\hbar^2\\bigg[\\frac{1}{\\sin \\theta}\\frac{\\partial }{\\partial \\theta}\\bigg(\\sin\\theta\\frac{\\partial }{\\partial \\theta}\\bigg) + \\frac{1}{\\sin^2\\theta}\\frac{\\partial^2}{\\partial \\varphi^2}\\bigg]\n$$</div>\n\n<div>$$\n\\hat L^2Y = \\lambda \\hbar^2Y\\\\\nY(\\theta, \\varphi) = P(\\theta)\\exp(im\\varphi)\n$$</div>\n\n<p>省流：球谐函数</p>\n<div>$$\nY_{lm}(\\theta, \\varphi) = N_{lm}P_l^m(\\cos \\theta)\\exp(im\\varphi)\n$$</div>\n\n<p>归一化系数</p>\n<div>$$\nN_{lm} = (-1)^m\\sqrt{\\frac{(2l + 1)}{4\\pi}\\frac{(l - |m|)!}{(l + |m|)!}}\n$$</div>\n\n<p>勒让德函数：</p>\n<div>$$\nP(w) = \\frac{1}{2^l l!}(1 - w^2)^{|m| / 2}\\frac{\\mathrm d^{l+|m|}}{\\mathrm dw^{l+|m|}}(w^2 - 1)^l\n$$</div>\n\n<p>前几个球谐函数：</p>\n<div>$$\nY_{00} = \\sqrt{\\frac{1}{4\\pi}}\\\\\nY_{10} = \\sqrt{\\frac{3}{4\\pi}}\\cos \\theta\\\\Y_{1, \\pm1} = \\mp \\sqrt{\\frac{3}{8\\pi}}\\sin \\theta \\exp(\\pm i\\varphi)\\\\\n$$</div>\n\n<p>$l &#x3D; 1$，是 $L^2$ 和 $L_z$ 的共同本征态，但不是 $L_x$ 和 $L_y$ 的本征态,(不确定性原理决定了这三个分量不能同时有本征态)</p>\n<p><strong>球谐函数的性质</strong></p>\n<div>$$\n\\hat L^2 Y_{lm} = l(l+1)\\hbar^2 Y_{lm}\\\\\n\\hat L_z Y_{lm} = m\\hbar Y_{lm}\\\\\nl = 0, 1, 2, \\dots\\\\\nm = l, l - 1, \\dots, -l.\n$$</div>\n\n<p>正交归一性：</p>\n<div>$$\n\\int Y^*_{l^\\prime m^\\prime}(\\theta, \\varphi)Y_{lm}(\\theta, \\varphi) \\mathrm d\\Omega = \\delta_{l^\\prime l}\\delta_{m^\\prime m}\n$$</div>\n\n<div>$$\nY^*_{lm}(\\theta, \\varphi) = (-1)^m Y_{l, -m}(\\theta, \\varphi)\n$$</div>\n\n<h4 id=\"中心力场的运动，氢原子\"><a href=\"#中心力场的运动，氢原子\" class=\"headerlink\" title=\"中心力场的运动，氢原子\"></a>中心力场的运动，氢原子</h4><p>经典：</p>\n<div>$$\nH = \\frac{1}{2}m_N\\dot{\\vec r_N^2} + \\frac{1}{2}m_e\\dot{\\vec r_e^2} + U(|\\vec r_e - \\vec r_N|)\n$$</div>\n\n<p>采用质心坐标和相对坐标：</p>\n<div>$$\n\\vec R = \\frac{m_N\\vec r_N + m_e \\vec r_e}{m_N + m_e}\\\\\n\\vec r = \\vec r_e - \\vec r_N\\\\\nM = m_N + m_e\\\\\n\\mu = \\frac{m_Nm_e}{M}\n$$</div>\n\n<div>$$\nH = \\frac{1}{2}M\\dot{\\vec R^2} + \\frac{1}{2}\\mu \\dot{\\vec r^2} + U(r)\\\\\n\\rArr H = \\frac{\\vec p_R^2}{2M} + \\frac{\\vec p^2}{2\\mu} + U(r)\n$$</div>\n\n<p>量子化：</p>\n<div>$$\nH = -\\frac{\\hbar^2}{2M}\\nabla_R^2 - \\frac{\\hbar}{2\\mu}\\nabla^2 + U(r)\n$$</div>\n\n<p>相对运动的动量意义是什么？</p>\n<p>求解氢原子波函数时，将哈密顿量分解为质心的哈密顿算符和相对坐标的哈密顿算符，然后分别求解。相对坐标对应的哈密顿算符求解得到的才是氢原子波函数。因此，<strong>得到的氢原子的能量不包括质心运动的能量。</strong></p>\n<p>省流：氢原子波函数</p>\n<div>$$\n\\psi_{nlm} = R_{nl}(r) Y_{lm}(\\theta, \\phi)\n$$</div>\n\n<p>其中径向函数</p>\n<div>$$\nR_{nl}(r) = \\frac{u_{nl}(r)}{r}, \\rho = \\alpha r\\\\\nu_{nl}(r) = N_{nl} \\rho^{l + 1}(\\rho) v_{nl}(\\rho) \\exp(-\\frac{1}{2}\\rho)\n$$</div>\n\n<div>$$\n主量子数\\quad n = 1, 2, 3,\\dots, \\rightarrow E_n = \\frac{E_1}{n^2}\\\\\n角量子数\\quad l = 0, 1, \\dots, n -1, \\rightarrow L^2 = l(l + 1)\\hbar^2\\\\\n磁量子数\\quad m = l, l - 1, \\dots, -l, \\rightarrow L_z = m\\hbar\\\\\n简并度\\quad g_n =\\sum\\limits_{l=0}^{n - 1}(2l + 1) = n^2\n$$</div>\n\n<p>定态波函数的宇称性质：</p>\n<div>$$\nR_nl(r) 偶函数，\n$$</div>\n\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/7_1.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_1.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_2.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_3.jpg\" alt=\"alt\"></p>\n<p>电子云有方向性吗？</p>\n<p>以 $n &#x3D; 2$ 为例，$Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 的模平方之和为常数。若氢原子随机等概率激发到 $Y_{00}, Y_{10}, Y_{11}, Y_{1, -1}$ 之一，则无方向性。但如果是相干叠加，则有方向性。</p>\n<p>为什么 $m$ 叫做磁量子数？</p>\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/8_4.jpg\" alt=\"alt\"></p>\n<div>$$\n\\vec J_e = (-e) \\vec J\n$$</div>\n\n<h4 id=\"本征函数系的一般性质\"><a href=\"#本征函数系的一般性质\" class=\"headerlink\" title=\"本征函数系的一般性质\"></a>本征函数系的一般性质</h4><p><strong>正交与归一</strong></p>\n<p>正交性定理</p>\n<p>同一个厄密算符 $\\hat F$ 的属于不同本征值的本征函数是彼此正交的。</p>\n<div>$$\n\\int_{}^{}\\psi_1^*\\psi_2\\mathrm d\\tau = 0\n$$</div>\n\n<p>本征函数的正交“归一”性</p>\n<p>离散情况：</p>\n<div>$$\n\\int_{}^{}\\phi_k^*(\\vec r) \\cdot \\phi_l(\\vec r)\\mathrm d\\tau = \\delta_{kl} = \\begin{cases}\n    0, k\\ne l\\\\\n    1, k = l\n\\end{cases}\n$$</div>\n\n<p>连续情况：</p>\n<div>$$\n\\int_{}^{}\\phi_{\\lambda^\\prime}^*(\\vec r) \\cdot \\phi_{\\lambda}(\\vec r)\\mathrm d\\tau = \\delta(\\lambda - \\lambda^\\prime)\n$$</div>\n\n<p>并非真正的归一化，但是依然满足正交性：例如 $\\frac{1}{\\sqrt{2\\pi \\hbar}}e^{\\frac{i}{\\hbar}px}$。</p>\n<p><strong>共同本征函数（重点）</strong></p>\n<p>定义对易括号</p>\n<div>$$\n[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G \\hat F\n$$</div>\n\n<p>若</p>\n<div>$$\n[\\hat F, \\hat G] = 0 \n$$</div>\n\n<p>则两算符对易。</p>\n<p>定理：</p>\n<div>$$\n[\\hat F, \\hat G] = 0 \\Rightarrow 两个算符有组成完全系的共同本征函数\n$$</div>\n\n<div>$$\n[\\hat {p_z}, \\hat {p_x}] = [\\hat {p_x}, \\hat {p_y}] = [\\hat {p_y}, \\hat {p_z }] = 0\n$$</div>\n\n<p>它们有共同的本征函数。</p>\n<div>$$\n[\\hat {xp}, \\hat {px}] = i\\hbar\n$$</div>\n\n<p>没有共同的本征函数。</p>\n<p>如果 $[\\hat {F}, \\hat {G}] \\ne 0$，则不一定没有共同本征态。例如角动量的本征态 $Y_{00}$。</p>\n<div>$$\n[\\hat {L^2}, \\hat {L_i}] = 0\\\\\n[\\hat {L_x}, \\hat {L_y}] = i\\hbar \\hat L_z\n$$</div>\n\n<p>性质：</p>\n<div>$$\n[A, BC] = [A, B]C + B[A, C]\n$$</div>\n\n<p>简并：力学量 $F$ 的一个本征值对应多个线性无关的本征函数。</p>\n<p><strong>力学量完全集（完备算符集）</strong></p>\n<p>为了消除简并，可以选取一组彼此对易的力学量 $F_1, F_2, F_3, \\dots$，使得它们的本征值组 $\\lambda_1, \\lambda_2, \\dots$ 对应唯一一个线性无关的共同本征函数 $\\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)$</p>\n<p>称 $F_1, F_2, F_3, \\dots$ 为力学量完全集。</p>\n<div>$$\nF_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r) = \\lambda_k \\psi_{\\lambda_1, \\lambda_2, \\dots}(\\vec r)\n$$</div>\n\n<p>实现了正交化：力学量完全集的共同本征函数必然为正交函数系，因为任意两个本征函数，对应的本征值必然不同，由正交性定理得知，两个本征函数必然正交。</p>\n<p><strong>常见的选取方式</strong></p>\n<p>对于三维空间的单粒子，可以选取为：</p>\n<ul>\n<li>$(x, y, z)$</li>\n<li>$(p_x, p_y, p_z)$</li>\n<li>$(H, L^2, L_z)$（对于氢原子适用）</li>\n</ul>\n<p>考虑自旋后，还需要增加自旋力学量构成完全集。</p>\n<h4 id=\"力学量的平均值公式\"><a href=\"#力学量的平均值公式\" class=\"headerlink\" title=\"力学量的平均值公式\"></a>力学量的平均值公式</h4><div>$$\n\\overline{F(t)} = \\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx\n$$</div>\n\n<p>若没有归一化：</p>\n<div>$$\n\\overline F = \\frac{\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx}{\\int_{}^{}\\psi^*(x, t) \\psi(x, t)\\mathrm dx}\n$$</div>\n\n<p>实际上， 利用本征函数的正交性</p>\n<div>$$\n\\int_{}^{}\\psi^*(x, t) \\hat F \\psi(x, t)\\mathrm dx =\\sum\\limits_{n}^{}\\lambda_n |c_n|^2 = \\overline{F}\n$$</div>\n\n<p>几率幅函数</p>\n<div>$$\nc_n(t) = \\int_{}^{}\\phi_n^*(x)\\psi(x, t)\\mathrm dx\n$$</div>\n\n<p>例题：</p>\n<div>$$\n\\psi = Ae^{ikx} + Be^{-ikx}\\\\\n$$</div>\n\n<p>动量值 $\\hbar k$ 与 $-\\hbar k$ 的概率比值为 $\\frac{|A|^2}{|B|^2}$</p>\n<div>$$\n\\bar p = \\hbar k  \\frac{|A|^2}{|A|^2 + |B|^2} + (-\\hbar k ) \\frac{|B|^2}{|A|^2 + |B|^2} = \\frac{|A|^2 - |B|^2}{|A|^2 + |B|^2}\\hbar k\n$$</div>\n\n<h4 id=\"不确定关系\"><a href=\"#不确定关系\" class=\"headerlink\" title=\"不确定关系\"></a>不确定关系</h4><p>一维谐振子为例：</p>\n<div>$$\n\\psi_(x) = \\sqrt{\\frac{\\alpha}{\\sqrt \\pi}} e^{-\\frac{1}{2}\\alpha^2 x^2}\\\\\nc_p = \\sqrt{\\frac{\\beta}{\\sqrt \\pi}}e^{-\\frac{\\beta^2p^2}{2}}\\\\\n\\frac{1}{\\alpha} \\cdot \\frac{1}{\\beta} = \\frac{1}{\\hbar}\\\\\n\\alpha = \\sqrt{\\frac{\\mu \\omega}{\\hbar}}\n$$</div>\n\n<p>不确定关系的数学表达以及证明</p>\n<p>如果两个力学量F和G的算符彼此不对易，则它们有不相容性，测量精确度（不确定度）上一般是相互制约的。</p>\n<div>$$\n\\Delta \\hat F = \\hat F - \\overline{ } F\\\\\n\\overline{(\\Delta \\hat F)^2} = \\overline{(\\hat F - \\overline{F})^2} = \\overline{\\hat F^2} - \\overline{F}^2\n$$</div>\n\n<p>记 $[\\hat F, \\hat G] \\equiv \\hat F\\hat G - \\hat G\\hat F &#x3D; i\\hat C$，则在任意一个状态下</p>\n<div>$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$</div>\n\n<p>这里 $\\hat F$ 与 $\\hat G$ 都是厄密算符，所以 $\\overline{\\hat C}$ 为实数</p>\n<p>引入</p>\n<div>$$\nI(\\xi) = \\int_{}^{}\\left | (\\xi\\Delta \\hat F - i\\Delta \\hat G  )\\psi^2\\right|^2\\mathrm d\\tau \\ge 0\n$$</div>\n\n<div>$$\n\\begin{align*}\n    I(\\xi) =& \\xi^2\\int_{}^{}(\\Delta \\hat F \\psi)^* (\\Delta \\hat F \\psi)\\mathrm d\\tau - i\\xi \\int_{}^{}[(\\Delta \\hat F \\psi)^*(\\Delta \\hat G \\psi) - (\\Delta \\hat G \\psi)^*(\\Delta \\hat F \\psi)]\\mathrm d\\tau + \\int_{}^{}(\\Delta \\hat G\\psi)^*(\\Delta \\hat G\\psi)\\mathrm d\\tau\\\\\n    =& \\xi^2 \\int_{}^{}\\psi^*(\\Delta \\hat F)^2\\psi\\mathrm d\\tau - i\\xi \\int_{}^{}\\psi^*\\Delta\\hat F\\Delta \\hat G\\psi - \\psi^*\\Delta \\hat G\\Delta \\hat F\\psi\\mathrm d\\tau + \\int_{}^{}\\psi^*(\\Delta \\hat G)^2 \\psi\\mathrm d\\tau\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i\\overline{\\Delta \\hat F\\Delta \\hat G - \\Delta \\hat G \\Delta \\hat F}\\cdot \\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat { F}, \\hat { G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - i [\\hat {\\Delta F}, \\hat {\\Delta G}]\\xi + \\overline{(\\Delta \\hat G)^2}\\\\\n    =& \\overline{(\\Delta \\hat F)^2} \\cdot \\xi^2 - \\overline{\\hat C}\\xi + \\overline{(\\Delta \\hat G)^2}\n\\end{align*}\n$$</div>\n\n<p>由于此式恒正，判别式大于0：</p>\n<div>$$\nI(\\xi) \\ge 0 \\Rightarrow \\overline{(\\Delta \\hat C)}^2 - 4\\overline{(\\Delta \\hat F)^2}\\cdot \\overline{(\\Delta \\hat G)^2} \\ge 0\n$$</div>\n\n<div>$$\n\\overline{(\\Delta \\hat F)^2} \\cdot \\overline{(\\Delta \\hat G)^2} \\ge \\frac{1}{4}\\overline{(\\Delta \\hat C)^2}\n$$</div>\n\n<p>如果要满足取等号条件：</p>\n<div>$$\n(\\xi \\Delta \\hat F - i \\Delta \\hat G)\\psi = 0\n$$</div>\n\n<p>此时的波包称为最小不确定波包</p>\n<p>位置动量不确定关系：</p>\n<div>$$\n\\overline{(\\Delta \\hat x)^2} \\overline{(\\Delta \\hat p_x) ^2} \\ge \\frac{\\hbar^2}{4}\n$$</div>\n\n<p>非零的“零点能”是不确定性关系的结果。</p>\n<div>$$\n\\overline E = \\frac{1}{2\\mu}\\overline{(\\Delta \\hat p_x)^2} + \\frac{1}{2}\\mu \\omega\\overline{(\\Delta \\hat x)^2} \\ge \\frac{1}{2}\\hbar\\omega\\\\\n\\overline E_{min} = \\frac{1}{2}\\hbar\\omega\\\\\n$$</div>\n\n<p>势垒穿透问题：谈论某一点的动能 T 和总能量 E 没有意义，因为 $\\hat x, \\hat T, \\hat H$ 彼此不对易。</p>\n<p>$H, T, U$ 三个物理量之间彼此不对易，不能同时具有确定的值。故 $H &#x3D; T + U$ 只是一个算符的等式。</p>\n<ul>\n<li>若为定态，则 $H$ 确定而 $T, U$ 不确定</li>\n<li>若位置确定，则 $U$ 确定但是 $T$ 和 $E$不确定</li>\n</ul>\n<p>求平均值：</p>\n<div>$$\n\\overline H = \\overline{ T} + \\overline U\n$$</div>\n\n<p>$T$ 的本征值为非负实数，所以</p>\n<div>$$\n\\overline{H} \\ge \\overline{ U}\n$$</div>\n\n<p>角动量 $Y_{00}$ 情形下，三个分量都具有确定的取值，三个角动量分量都为 0，还是满足不确定性关系。</p>\n<h4 id=\"守恒量\"><a href=\"#守恒量\" class=\"headerlink\" title=\"守恒量\"></a>守恒量</h4><p>要求任意态下 $F$ 平均值不变。</p>\n<p>平均值的时间演化</p>\n<div>$$\n\\hat H = i\\hbar \\frac{\\partial }{\\partial t}\n$$</div>\n\n<p>若算符 $\\hat F$ 不显含时间，则</p>\n<div>$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]}\n$$</div>\n\n<p>若 $\\hat F(t)$ 显含时间，则</p>\n<div>$$\n\\frac{\\mathrm d}{\\mathrm dt} \\overline{F} = \\frac{1}{i\\hbar} \\overline{[\\hat {F}, \\hat {H}]} + \\overline{\\frac{\\partial }{\\partial t}\\hat F(t)}\n$$</div>\n\n<h3 id=\"第四章\"><a href=\"#第四章\" class=\"headerlink\" title=\"第四章\"></a>第四章</h3><h4 id=\"狄拉克算符和谐振子升降算符\"><a href=\"#狄拉克算符和谐振子升降算符\" class=\"headerlink\" title=\"狄拉克算符和谐振子升降算符\"></a>狄拉克算符和谐振子升降算符</h4><p>计算本征值问题</p>\n<p>谐振子：</p>\n<div>$$\nH = \\hbar \\omega \\frac{1}{2} \\left ( \\frac{p^2}{m\\hbar\\omega} + \\frac{m\\omega^2x^2}{\\hbar\\omega} \\right)\\\\\n\\alpha \\equiv \\sqrt{\\frac{m\\omega}{\\hbar}}\\\\\np^\\prime = \\frac{1}{\\hbar \\alpha}p\\\\\nx^\\prime = \\alpha x\\\\\n[\\hat {x^\\prime}, \\hat {p^\\prime}] = i\n$$</div>\n\n<div>$$\nH = \\hbar\\omega\\frac{1}{2}[(x^\\prime - ip^\\prime)(x^\\prime + ip^\\prime) + 1]\\\\\np^\\prime = -i \\frac{\\mathrm d}{\\mathrm dx^\\prime}\n$$</div>\n\n<p>基态满足</p>\n<div>$$\n(x^\\prime + ip^\\prime)\\psi_0(x) = 0\n$$</div>\n\n<p>通过升算符算出激发态</p>\n<div>$$\n\\psi_n = C_n (x^\\prime - ip^\\prime)^n\\psi_0(x)\n$$</div>\n\n<p>换元：</p>\n<div>$$\na = \\frac{x^\\prime + ip^\\prime}{\\sqrt{2}}\\\\\na^+ = \\frac{x^\\prime - ip^\\prime}{\\sqrt{2}}\\\\\nH = \\hbar \\omega(a^+a + \\frac{1}{2}) = \\hbar \\omega(\\hat N + \\frac{1}{2})\\\\\n[a, a^+] = 1\n$$</div>\n\n<p>设 $\\hat N$ 的本征矢为 $\\ket{n}$，称$n$为占有数。可以看出这本征矢也是能量的本征态。</p>\n<p>接下来计算 $\\hat N$ 的本征矢：</p>\n<div>$$\n\\langle \\hat N \\rangle = \\bra{n}a^+a\\ket{n} \\ge 0\\\\\n\\bra{n}a^+a\\ket{n} = n \\langle n|n \\rangle\\\\\n\\Rightarrow n \\ge 0\n$$</div>\n\n<p>如果存在 $n &#x3D; 0$ 的态：</p>\n<div>$$\n\\bra{0}a^+a\\ket{0} = 0\\\\\n\\Rightarrow a\\ket{0} = 0\n$$</div>\n\n<p>这就是基态满足的微分方程。解出基态的坐标表象：</p>\n<div>$$\n(\\alpha x + \\frac{1}{\\alpha} \\frac{\\mathrm d}{\\mathrm dx})\\psi_0(x) = 0\n$$</div>\n\n<p>重点：升降性质</p>\n<p>$a\\ket{n} &#x3D; \\ket{\\phi} &#x3D; \\ket{n - 1}$ 也是本征态。</p>\n<div>$$\n\\hat N \\ket{\\phi} = (a^+a)\\ket{\\phi} = (aa^+ - 1)\\ket{\\phi} = (aa^+ - 1)a\\ket{n} = aa^+a\\ket{n} - a\\ket{n} = a\\hat N\\ket{n} - a\\ket{n} = na\\ket{n} - a\\ket{n} = (n - 1)\\ket{\\phi}\n$$</div>\n\n<p>归一化：</p>\n<div>$$\n\\ket{\\phi} = c\\ket{n - 1}\\\\\n1 = \\langle n - 1 |n - 1 \\rangle = \\frac{1}{|c|^2}(an, an) = \\frac{1}{|c|^2}\\bra{n}a^+a\\ket{n} = \\frac{n}{|c|^2}\\\\\n取 c = \\sqrt{n}\\\\\na\\ket n = \\sqrt{n}\\ket{n - 1}\n$$</div>\n\n<p>升降算符（重点）：</p>\n<div>$$\na\\ket n = \\sqrt{n}\\ket{n - 1}\\\\\na\\ket{0} = 0\\\\\na^+\\ket{n} = \\sqrt{n + 1}\\ket{n + 1}\n$$</div>\n\n<p>$n$ 必为整数。</p>\n<p>能级：</p>\n<div>$$\nH = \\hbar \\omega(a^+a + \\frac{1}{2})\\\\\nE_n = \\hbar\\omega(n + \\frac{1}{2})\n$$</div>\n\n<p>波函数：</p>\n<div>$$\n\\ket n = \\frac{1}{\\sqrt{n}}a^+\\ket{n - 1} = \\frac{1}{\\sqrt{n!}}a^{+n}\\ket{0}\\\\\n\\psi_n(x) = \\frac{1}{\\sqrt{n!}}\\left (\\frac{1}{\\sqrt{2}}\\left (\\alpha x - \\frac{1}{\\alpha}\\frac{\\mathrm d}{\\mathrm dx}  \\right)  \\right)^n \\frac{\\sqrt{\\alpha}}{\\pi^{1/4}}e^{-\\alpha^2x^2/2}\n$$</div>\n\n<p>相干态：满足 $\\hat a \\ket \\beta &#x3D; \\beta \\ket \\beta$ 的 $\\ket \\beta$。</p>\n<h4 id=\"海森堡方程\"><a href=\"#海森堡方程\" class=\"headerlink\" title=\"海森堡方程\"></a>海森堡方程</h4><p>力学量算符含时，波函数不含时</p>\n<div>$$\n\\bra{\\psi(t)} F\\ket {\\psi(t)} \\rightarrow \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$</div>\n\n<p>不同图景在物理上等价</p>\n<div>$$\n\\Psi(\\vec r, t) = e^{-\\frac{i}{\\hbar}Ht}\\Psi(\\vec r, 0)\\\\\n\\ket{\\psi(t)} = U\\ket {\\psi(0)}\n$$</div>\n\n<p>力学量平均值</p>\n<div>$$\n\\overline{F} = \\bra{\\psi(t)}F\\ket{\\psi(t)} = \\bra{\\psi(0)}U^+FU\\ket{\\psi(0)} = \\bra{\\psi_H}F_H(t)\\ket{\\psi_H}\n$$</div>\n\n<p>海森方程</p>\n<div>$$\nF_H = U^+(t)FU(t), U = e^{-\\frac{i}{\\hbar}Ht}, U^+ = e^{\\frac{i}{\\hbar}Ht}\\\\\n\\frac{\\mathrm d}{\\mathrm dt}U = \\frac{1}{i\\hbar}HU, \\frac{\\mathrm d}{\\mathrm dt}U^+ = -\\frac{1}{i\\hbar}HU^+, \\\\\n\\frac{\\mathrm d}{\\mathrm dt}F_H = \\frac{1}{i\\hbar}[F_H, H]\\\\\n\\frac{\\mathrm d\\ket{\\psi}_H}{\\mathrm dt} = 0\n$$</div>\n\n<div>$$\nHU = UH\n$$</div>\n\n<p>从经典到量子：</p>\n<div>$$\n\\dot q = \\frac{1}{i\\hbar}[q, H]\\\\\n\\dot p = \\frac{1}{i\\hbar}[p, H]\\\\\n[q, p] = i\\hbar\n$$</div>\n\n<h4 id=\"自旋\"><a href=\"#自旋\" class=\"headerlink\" title=\"自旋\"></a>自旋</h4><p>用标量波函数 $\\Psi(\\vec r, t)$ 描述是否完整？</p>\n<p>经典力学给出了轨道磁矩和磁势能</p>\n<div>$$\n\\vec M_L = -\\frac{e}{2m_e}\\vec L\\\\\nU = - \\vec M \\cdot \\vec B\n$$</div>\n\n<p>磁矩的最小单元(Bohr磁子)</p>\n<div>$$\nM_B \\equiv \\frac{e\\hbar}{2m_e}\n$$</div>\n\n<p>Stern-Gerlach 实验：即使是 $l &#x3D; 0$ 的 $s$ 态原子也会在磁场中偏转。认为电子除了轨道磁矩，还有自旋磁矩。</p>\n<p>自旋磁矩只有两个可能的值：</p>\n<div>$$\nM_B \\equiv \\frac{2\\hbar}{2m_e}\\\\\nM_z = \\pm M_B\n$$</div>\n\n<p>Uhlenbeck-Goudsmit假设(1925)：电子有内禀（自旋）角动量，其投影只能取两个值：</p>\n<div>$$\nS_i = \\pm \\frac{\\hbar }{2}, i = x, y , z\n$$</div>\n\n<p>自旋磁矩：</p>\n<div>$$\n\\hat {\\vec M_s} = -\\frac{e}{m_e}\\hat{\\vec S}\n$$</div>\n\n<p>自旋有纯量子力学的起源。没有经典对应，独立于之前学过的所有力学量。</p>\n<p>自旋的分量只有两个可能的测量值，因此可以使用 $2\\times 2$ 的矩阵描写。</p>\n<p>$S_z$的本征值为 $\\pm \\frac{\\hbar}{2}$，采用 $S_z$ 表象，则 $S_z &#x3D; \\frac{\\hbar}{2}\\begin{pmatrix}<br>    1 &amp;0\\<br>    0 &amp;-1<br>\\end{pmatrix}$</p>\n<p>根据角动量的对易关系（假设的）</p>\n<div>$$\n[S_x, S_y] = i\\hbar S_z\\\\\n[S_y, S_z] = i\\hbar S_x\\\\\n[S_z, S_x] = i\\hbar S_y\n$$</div>\n\n<p>可以导出 $S_x$ 和 $S_y$</p>\n<div>$$\nS_x = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & 1\\\\\n    1 & 0\n\\end{pmatrix}\\\\\nS_y = \\frac{\\hbar}{2}\\begin{pmatrix}\n    0 & -i\\\\\n    i & 0\n\\end{pmatrix}\\\\\nS_z = \\frac{\\hbar}{2}\\begin{pmatrix}\n    1 & 0\\\\\n    0 & -1\n\\end{pmatrix}\\\\\n$$</div>\n\n<p>三个分量不对易，最多只有一个分量具有确定的取值</p>\n<div>$$\nS_x^2 = S_y^2 = S_z^2 = \\frac{\\hbar^2}{4}\\\\\nS^2 = \\frac{3\\hbar^2}{4} = s(s + 1)\\hbar^2\\\\\n(s = \\frac{1}{2})\\\\\n[S^2, S_i] = 0\n$$</div>\n\n<p>自旋是内部基本构造，不同于先前学过的力学量，不能写成 $F(\\vec r, \\vec p)$ 的形式</p>\n<p>自旋也不能简单看成绕自身某个轴的旋转（电子被当作“点粒子”，自旋不同于经典物体的旋转，量子自旋没有经典的对应）</p>\n<p>带有自旋的电子波函数（自旋 + 空间坐标）</p>\n<div>$$\nv_+ = \\begin{pmatrix}\n    1\\\\0\n\\end{pmatrix}\nv_- = \\begin{pmatrix}\n    0\\\\1\n\\end{pmatrix}\n\n<p>\\Psi(\\vec r, t) \\cdot v_+ + \\Psi_2(\\vec r, t) \\cdot v_-<br>$$</div></p>\n<p>波函数有两个自旋分量（类比于电磁波有两个偏振分量）</p>\n<p>又被称为旋量波函数</p>\n<div>$$\n\\Psi = \\begin{pmatrix}\n    \\Psi_1(\\vec r, t)\\\\\n    \\Psi_2(\\vec r, t)\n\\end{pmatrix}\\\\\nw(\\vec r, t) = \\Psi^+\\Psi = |\\Psi_1|^2 + |\\Psi_2|^2\\\\\n\\int_{}^{}\\Psi^+\\Psi\\mathrm d\\tau = \\int_{}^{}(|\\Psi_1|^2 + |\\Psi_2|^2)\\mathrm d\\tau = 1\n$$</div>\n\n<p>自旋角动量的几率分布</p>\n<div>$$\nW \\left ( \\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_1|^2\\mathrm d\\tau\\\\\nW \\left ( -\\frac{\\hbar}{2} \\right) = \\int_{}^{}|\\Psi_2|^2\\mathrm d\\tau\\\\\n$$</div>\n\n<h3 id=\"第五章-微扰论\"><a href=\"#第五章-微扰论\" class=\"headerlink\" title=\"第五章 微扰论\"></a>第五章 微扰论</h3><div>$$\n\\hat H \\psi_n = E_n \\psi_n\\\\\n\\hat H = \\hat H^{(0)} + \\hat H^\\prime\n$$</div>\n\n<p>作逐级展开：</p>\n<div>$$\n\\psi_n = \\psi_n^{(0)} + \\psi_n^{(1)} + \\psi_n^{(2)} + \\cdots\\\\\nE_n = E_n^{(0)} + E_n^{(1)} + E_n^{(2)} + \\cdots\\\\\n$$</div>\n\n<p>得到零级，一级，二级方程</p>\n<div>$$\n\\hat H^{(0)} \\psi_n^{(0)} = E_n^{(0)}\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(1)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(0)}\\\\\n(\\hat H^{(0)} - E_n^{(0)}) \\psi_n^{(2)} = -(\\hat H^\\prime - E_n^{(1)})\\psi_n^{(1)} + E_n^{(2)}\\psi_n^{(0)}\\\\\n$$</div>\n\n<h4 id=\"能量的非简并情形\"><a href=\"#能量的非简并情形\" class=\"headerlink\" title=\"能量的非简并情形\"></a>能量的非简并情形</h4><p>结论：能级一级修正</p>\n<div>$$\nE_n^{(1)} = H^\\prime_{nn} = \\int_{}^{}\\psi_n^{(0)*}\\hat{H}^\\prime\\psi_n^{(0)}\\mathrm d\\tau\n$$</div>\n\n<p>波函数一级修正</p>\n<div>$$\n\\psi_n(x) = \\psi_n^{(0)}(x) + \\psi_n^{(1)}(x)\\\\\n\\psi_n^{(1)}(x) =\\sum\\limits_{m\\ne n}^{}\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}}\\psi_m^{(0)}(x)\n$$</div>\n\n<p>适用条件：</p>\n<div>$$\n\\frac{H_{mn}^\\prime}{E_n^{(0)} - E_m^{(0)}} << 1\n$$</div>\n\n<p>二级能量修正公式：</p>\n<div>$$\nE_n^{(2)} =\\sum\\limits_{m\\ne n}^{}\\frac{|H_{mn}^\\prime|^2}{E_n^{(0)} - E_m^{(0)}}\n$$</div>\n\n<h4 id=\"零级能量的简并情形\"><a href=\"#零级能量的简并情形\" class=\"headerlink\" title=\"零级能量的简并情形\"></a>零级能量的简并情形</h4><p>需要确定适当的零级波函数，可以通过对初始的0级波函数进行表象变换得到。</p>\n<div>$$\n\\psi_{ni}^{(0)} =\\sum\\limits_{l=1}^{k}c_{li}^{(0)}\\phi_{nl}^{(0)}\n$$</div>\n\n<p>通过哈密顿量的修正值 $H^\\prime$ 来确定 0 级波函数的选取。1级方程左右同乘 $\\phi_l^{(0)*}$ 并积分，可得（下面的方程没有写n，表示都是同一个能级，系数c的下标对应1~k）</p>\n<div>$$\nH^\\prime C^{(0)} = E_n^{(1)}C^{(0)}\\\\\nH^\\prime_{ji} = \\int_{}^{}\\phi_j^{(0)*}\\hat H^\\prime\\phi_i^{(0)}\\mathrm d\\tau\\\\\nC^{(0)} = \\begin{pmatrix}\n    c_1^{(0)}\\\\c_2^{(0)}\\\\\\dots\\\\c_k^{(0)}\n\\end{pmatrix}\n$$</div>\n\n<p>对所有的 $l$ 做上述操作，求出所有的新的零级波函数。</p>\n<p>$H^\\prime$ 在 $E_n^{(0)}$ 对应的简并态子空间的 $k$ 个本征向量决定新的零级波函数 $\\psi_n^{(0)}$。对应的 $k$ 个本征值表示一级能量修正 $E_n^{(1)}$。这些一级能量互不相同，使得 $E_n^{(0)} + E_n^{(1)}$有 $k$ 个不同的值，也就是说零级加一级能量是“非简并态”。</p>\n<p>（这样做有什么意义？）</p>\n<p>简并微扰波函数的一级修正：</p>\n<div>$$\nc_{ml}^{(1)} = \\frac{\\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime \\psi_{nl}^{(0)}\\mathrm d\\tau}{E_n^{(0)} - E_m^{(0)}}\\\\\n\\psi_{nl}^{(1)} =\\sum\\limits_{m\\ne n}^{}c_{ml}^{(1)}\\phi_m^{(0)}\n$$</div>\n\n<p>注意！其中 $\\phi_m^{(0)}$ 是 $E_n^{(0)}$ 能级以外的态，这些态可以是简并的。</p>\n<p>能量的二级修正：</p>\n<div>$$\nE_{nl}^{(2)} =\\sum\\limits_{m\\ne n}^{} \\frac{\\left | \\int_{}^{}\\phi_m^{(0)*}\\hat H^\\prime\\psi_{nl}^{(0)}\\mathrm d\\tau \\right|^2}{E_n^{(0)} - E_m^{(0)}}\n$$</div>\n\n<p>如果求解的本征值有重根？</p>\n<p>此时零级波函数仍然不能求出来，但是可以求出能量一级修正；若考虑能量的二级修正，需要由二级方程确定零级波函数。</p>\n<h4 id=\"外磁场中的原子\"><a href=\"#外磁场中的原子\" class=\"headerlink\" title=\"外磁场中的原子\"></a>外磁场中的原子</h4><p>Zeeman 效应：外磁场中原子的能级会分裂</p>\n<p>简单 Zeeman 效应：外磁场作用很强， 可以略去自旋轨道耦合，这就是简单 Zeeman 效应</p>\n<div>$$\n\\vec M = \\vec M_L  + \\vec M_s \\approx -\\frac{e}{2\\mu}(\\vec L + 2\\vec S)\\\\\nU_m = -M_zB = \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\\\\\nH = H_0(氢原子) + \\frac{eB}{2\\mu} (\\hat L_z + 2\\hat S_z)\n$$</div>\n\n<p>结论：$\\psi_{n,l,m_l,m_s}$ 组成了完全函数系，对应能级为</p>\n<div>$$\nE_{n,l,m_l,m_s} = E_n + \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$</div>\n\n<p>Zeeman 效应可以调节原子能级，操控原子的量子态，灵敏检测磁场。</p>\n<p>如何用微扰论求解？</p>\n<p>显然，在上面介绍的波函数正好使得 $H^\\prime$ 成为一个对角矩阵：</p>\n<div>$$\n\\bra{\\psi_{n,l,m_l^\\prime,m_s\\prime}} H^\\prime \\ket{\\psi_{n,l,m_l,m_s}} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\\delta_{m_l^\\prime, m_l}\\delta_{m_s^\\prime, m_s}\\\\\nE_{n,l,m_l,m_s}^{(1)} = \\frac{eB\\hbar}{2\\mu}(m_l + 2m_s)\n$$</div>\n\n<p><strong>求自旋轨道耦合产生的精细结构？</strong></p>\n<p>（困难的拓展问题，在课程内不能完全解决）</p>\n<div>$$\nH = H_0 + H^\\prime\\\\\nH^\\prime = \\ksi(r)\\vec L \\cdot \\vec s\\\\\n\\ksi(r) = \\left ( \\frac{e^2}{8\\pi\\varepsilon_0} \\right)\\frac{1}{m_e^2c^2r^3}\n$$</div>\n\n<p>采用耦合表象基底 $L^2, L_z, S_z$ 共同本征态</p>\n<div>$$\n\\hat Y_{ljm} =\\sum\\limits_{m_lm_s}^{}c(l, j, m;l, m_l, m_s)Y_{lm_l}\\chi_{m_s} = \\ket{l, j, m}\n$$</div>\n\n<div>$$\n\\vec J = \\vec L + \\vec s\\\\\n\\vec L \\cdot \\vec s = \\frac{1}{2}(\\vec J^2 - \\vec L^2 - \\vec s^2)\n$$</div>\n\n<p>$H^\\prime$ 又是一个对角阵：</p>\n<div>$$\n\\bra{l^\\prime, j^\\prime, m^\\prime}\\vec L \\cdot \\vec s\\ket{l, j, m} = \\frac{1}{2} \\left [ j(j + 1) - l(l + 1) - \\frac{3}{4} \\right]\\hbar^2\\delta_{ll^\\prime}\\delta_{jj^\\prime}\\delta_{mm^\\prime}\n$$</div>\n\n\n<p>相对论得出的真实的精细结构跟 $l$ 并没有关系。</p>\n<p>考虑真空电磁场微扰形成的能级微小移动——兰姆位移。</p>\n<h2 id=\"统计力学\"><a href=\"#统计力学\" class=\"headerlink\" title=\"统计力学\"></a>统计力学</h2><h3 id=\"第一章\"><a href=\"#第一章\" class=\"headerlink\" title=\"第一章\"></a>第一章</h3><p>平衡态下孤立系统各种微观态的几率相等。</p>\n<p>最可几方法求玻色分布和费米分布</p>\n<p>求 $W \\lbrace n_i \\rbrace$ 的极大值</p>\n<div>$$\n\\bar u = \\frac{\\Sigma u \\lbrace n_i \\rbrace W \\lbrace n_i \\rbrace}{W \\lbrace n_i \\rbrace}\n$$</div>\n\n<h2 id=\"习题课\"><a href=\"#习题课\" class=\"headerlink\" title=\"习题课\"></a>习题课</h2><h3 id=\"20231028\"><a href=\"#20231028\" class=\"headerlink\" title=\"20231028\"></a>20231028</h3><h4 id=\"量子力学基本公理\"><a href=\"#量子力学基本公理\" class=\"headerlink\" title=\"量子力学基本公理\"></a>量子力学基本公理</h4><p>公理1：希尔伯特空间</p>\n<p>公理2：可观测量</p>\n<p>公理3：位置与动量（正则量子化）</p>\n<p>公理4：薛定谔方程</p>\n<p>公理5：全同粒子（略：讲统计时会讲）</p>\n<p>概率流密度的公式并不本质。根据薛定谔方程、概率密度公式、连续性方程可以推出。</p>\n<p>全空间概率密度$w(t)$不是 $x$ 的函数。</p>\n<p>要写盒外波函数为0.</p>\n<p>对任意的束缚的能量本征态, 动量的平均值是 0.</p>\n<div>$$\n[\\hat {x}, \\hat {H}] = [\\hat {x}, \\hat {p}^2/2\\mu] = \\frac{1}{2\\mu}(\\hat p[\\hat {x}, \\hat {p}] + [\\hat {x}, \\hat {p}]\\hat p) = \\frac{i\\hbar}{\\mu}\\hat p\n$$</div>\n\n<div>$$\n\\int_{-\\infty}^{\\infty}e^{-\\alpha x^2 + \\beta x}\\mathrm dx = \\sqrt{\\frac{\\pi}{\\alpha}}e^{\\beta^2/4\\alpha}\n$$</div>\n\n<h3 id=\"20231112\"><a href=\"#20231112\" class=\"headerlink\" title=\"20231112\"></a>20231112</h3><p><img src=\"/../images/%E9%87%8F%E7%AD%92/xt_2_1.jpg\"></p>\n<div>$$\n\\mu = -\\frac{e}{m}S\\\\\nU = - \\mu \\cdot B = -\\dfrac{eB}{m}S \\cdot n =\n$$</div>\n\n<p><img src=\"/../images/%E9%87%8F%E7%AD%92/xt_2_2.jpg\"></p>\n<p>透射率，反射率计算（用流密度）</p>\n"},{"title":"通网","date":"2023-09-18T03:14:16.000Z","katex":true,"_content":"\n## 信息论基础\n\n### 离散随机变量的信息度量\n\n$$\nH(X) = \\mathbf E\\{H(X=x_i)\\} = -\\sum_i p_i \\log p_i\n$$\n\n称为熵\n\n单位：\n* 2 (Bit)\n* e (Nat)\n* 10 (Hartely)\n\n表示了信息描述的有效性极限\n\n信源编码（Source Coding），通过信息的有效表示，提高通信的有效性。例如: Huffman 编码\n\n离散随机变量的最大熵：$\\max_{p_i} H(X) = \\log|S|$\n\n前缀码：任何码字都不是其他码字的前缀。前缀码保证了唯一可译码。是二叉树叶子节点。\n\n**Kraft不等式**\n\n对于信源字符集$\\lbrace a_1, \\dots, a_m\\rbrace$，必满足：\n\n$$\n\\sum\\limits_{k=1}^{M}2^{-l(a_k)} \\le 1\n$$\n\n同时，若上式成立，必存在码长分别为$𝑙(𝑎_𝑘)$的前缀码。\n\n\n最小前缀码的平均码长：\n\n$$\n\\min \\bar L =\\sum\\limits_{i=1}^{M}p_il_i\\\\\ns.t.\\sum\\limits_{i=1}^{M} 2^{-l_i} = 1\n$$\n\n由拉格朗日乘子法\n\n$$\np_i = 2^{-l_i}, \\bar L_{min} = -\\sum\\limits_{i=1}^{M}p_i \\log p_i\n$$\n\n记 $H(X) = -\\sum p_i\\log p_i$ .一般的，上下界为$H(X) \\le \\bar L  \\lt H(X) + 1$.\n\n如果我们将$k$个独立同分布的信源符号 $x_1, \\dots, x_k$堪称一个，对整体应用前缀码编码：\n\n$$\n\\begin{align*}\n    H(X_1, \\dots, X_k) &= -\\sum P(x_1, \\dots, x_k) \\log P(x_1, \\dots, x_k)\\\\\n    &= -\\sum P(x_1, \\dots, x_k) [\\log P(x_1) +  \\dots +  \\log(x_k)]\\\\\n    &= -\\sum P(x_1)\\log (x_1) - \\dots - \\sum P(x_k)\\log (x_k)\\\\\n    &= -kH(X)\n\\end{align*}\n$$\n\n直观：对长度为$𝑛$的$M$种信源符号序列，$𝑥_𝑖$出现的次数$≈𝑛𝑝_𝑖$\n\n典型序列应满足上述分布，否则就“小众”“非典型”\n\n典型的个数 # $≈ \\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}$\n\n平均每个信源符号可以用 $L = \\frac{1}{n}\\log\\left(\\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}\\right)$ 个 bit 来表达。\n\n通过 Stirling 公式可以得出 L的上下界。\n\n故\n\n$$\n\\lim\\limits_{n\\rightarrow \\infty}^{} L = H(X)\n$$\n\n**最大熵**\n\n离散型随机变量的最大熵为\n<!-- max -->\n$$\n\\max_{p_i} H(X) = \\log |S|\n$$\n\n可以用梯度法直观感受，当所有分量的概率相等时，熵最大。\n\n**联合熵**\n\n联合概率\n<!-- text -->\n$$\np_{i, j} = \\text{Pr}\\lbrace X = x_i, Y = y_j\\rbrace\n$$\n\n联合熵的定义：\n\n$$\nH(XY) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i, j}\n$$\n\n**条件熵**\n\n条件概率\n<!-- text -->\n$$\np_{i\\mid j} = \\text{Pr}\\lbrace X = x_i \\mid Y = y_j\\rbrace\n$$\n\n条件熵的定义：\n\n$$\nH(X|Y) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i\\mid j}\n$$\n\n通过相关观测进行无损压缩，若观测到 $Y = \\alpha_j$：\n\n$$\n\\bar L(\\alpha_j) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i\\mid j} \\log p_{i\\mid j}\n$$\n\n于是\n\n$$\n\\bar L =-\\sum\\limits_{j=1}^{N} \\bar L(\\alpha_j)p_j = -\\sum\\limits_{j=1}^{N}p_j\\sum\\limits_{i=1}^{M}p_{i|j} \\log(p_{i|j}) = -\\sum\\limits_{i=1}^{M}\\sum\\limits_{j=1}^{N}p_{ij}\\log(p_{i|j}) = H(X|Y)\n$$\n\n**链式法则**\n\n$$\nH(XY) = H(Y) + H(X|Y)\n$$\n\n两个随机变量的联合不确定性＝一个随机变量的不确定性＋知道这个随机变量后另一个随机变量残余的不确定性\n\n**互信息(Mutual Infomation)**\n\n$$\n\\begin{align*}\n    I(X;Y) &= H(X) + H(Y) - H(XY)\\\\\n    &= H(X) - H(X|Y) \\\\\n    &= H(Y) - H(Y|X)\n\\end{align*}\n$$\n\n互信息的物理意义\n\n第一种理解：\n- X的不确定度减去观测Y后X残存的不确定度\n- 即：通过观测Y带来的帮助了解X的信息\n\n第二种理解：\n- Y的不确定度减去观测X后Y残存的不确定度\n- 即：通过观测X带来的帮助了解Y的信息\n\n若$X, Y$相互独立，记为$X\\perp Y$，则$I(X;Y) = 0$，$H(X) = H(X|Y)$，$H(Y) = H(Y|X)$。观测一个随机变量完全无助于了解另一个随机变量。\n\n* $H(XY) = H(X) + H(Y)$，总平均码长等于各自平均码长之和。\n\n若$X = Y$，则$I(X;Y) = H(X) = H(Y)$，$H(X|Y) = H(Y|X) = 0$。观测一个随机变量完全了解另一个随机变量。\n\n$H(XY) = H(Y) + H(X|Y) = H(Y)$，只需要编码其中一个即可。\n\n$$\nX \\perp Y \\leftrightarrow H(X + Y | X) = H(Y | X) = H(Y), H(X + Y, X) = H(Y , X)\n$$\n\n\n$$\nH(X + X | X) = H(X | X) = 0, H(X + X, X) = H(X , X) = H(X)\n$$\n\n**信息传输的基本模型**\n* 信息通道，简称信道（Channel）对于输入符号有随机扰动，本质上可用一组条件概率表示\n* 限于物理条件，信宿只能观测信道输出 $Y$，由此了解其输入 $X$\n* 通过观测Y可以获得的关于X的信息量是 $I(X;Y)$\n\n**信息传输的优化**\n\n目标：最大化发送端 $X$ 和接收方 $Y$ 的互信息\n\n方法：\n* 信道是由物理实现所决定的，无法控制\n* 但是可以选择X的概率分布\n\n因此有如下优化问题：\n\n$$\np*_i = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} I(X;Y)\n$$\n\n定义信道容量 $C = \\max_{\\sum_i p_i = 1, p_i \\ge 0} I(X;Y)$\n\n信道容量的物理意义\n- 平均每个信道符号所能传的最大的信息量\n- 或：单位时间内信道所传最大的信息量\n\n优化问题的表达式\n\n$$\np_i^* = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} - \\sum_i\\sum_j p_i p_{j|i} \\log \\frac{\\sum\\limits_i p_i p_{j|i}}{p_{j|i}}\n$$\n\n信道容量不易计算\n\n**对称二进制信道(BSC)**\n\n- 一种典型信道模型\n- 分析信道编码时有很多应用\n\n利用互信息表达式\n\n$$\n\\begin{align*}\n    I(X;Y) &= H(Y) - H(Y | X)\\\\\n    &= H(Y) - \\sum_i p_i \\left[-\\sum_j p_{j|i} \\log p_{j|i}\\right]\\\\\n    &= H(Y) - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)]\\\\\n    &\\le 1 - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)] = C\\\\\n\\end{align*}\\\\\nY \\sim \\begin{bmatrix}\n    0 & 1\\\\\n    1/2 & 1/2\n\\end{bmatrix}\n$$\n\n如果误码率 $\\varepsilon = 0.5$，则信道容量为0, 传递不了信息。\n\n如果误码率 $\\varepsilon > 0.5$，继续增大差错率，反而可以提高信道容量。\n\n**高斯信道**\n<!-- **gauss** -->\n$$\nY = X + N\\\\\nf_N(n) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(-\\frac{(y - x)^2}{2\\sigma^2}\\right)\n$$\n\n![alt](../images/通网/1_1.jpg)\n\n![alt](../images/通网/1_.jpg)\n\nShannon 公式\n\n$$\nC = W\\log(1 + \\frac{P}{Wn_0})\n$$\n\n### 连续性随机变量的熵\n\n$$\nH(X) = - \\int\\limits_{-\\infty}^{\\infty}p(x)\\log p(x) \\mathrm dx + \\lim_{\\Delta \\rightarrow 0} \\log \\frac{1}{\\Delta}\n$$\n\n我们只关心相对不确定性，定义微分熵\n\n$$\nh(X) = -\\int\\limits_{-\\infty}^{\\infty}p(x) \\log p(x)\\mathrm dx\n$$\n\n微分熵是对连续型变量相对不确定性的一种描述\n- 其定义剔除了连续性或“精准要求”带来的困难，保\n留了分布函数形状自身的特征\n- 它说明用有限字符集合的字符串描述连续分布的随机\n变量，则平均字符长度为无穷大\n- 为了用有限长字符串描述信源，需要进行有损压缩，\n从而带来失真，即原始信源和压缩结果之间的差异\n- 失真测度包括：均方误差，绝对值误差，主观误差等\n- 对于图像，视频和语音等连续信源的编码等均属于有\n损压缩\n\n### 多元随机变量的熵\n\n联合熵：\n\n$$\nh(XY) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(x, y)\\mathrm dx \\mathrm{d}y\n$$\n\n条件熵：\n$$\nh(Y|X) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(y|x)\\mathrm dx \\mathrm{d}y\n$$\n\n互信息：\n\n$$\n\\begin{align*}\n    I(X;Y) &= h(X) + h(Y) - h(XY)\\\\\n    &= h(X) - h(X|Y) \\\\\n    &= h(Y) - h(Y|X)\n\\end{align*}\n$$\n\n## 压缩编码\n\n### 压缩编码的分类\n\n* 无损压缩\n    * 输入：数字序列\n    * 输出：数字序列\n    * 目的：使得平均长度更小\n* 有损压缩\n    * 输入：模拟信号\n    * 输出：数字序列\n    * 目的：实现数字传输\n\n信号压缩编码的步骤：\n\n* 抽样\n* 量化\n* 压缩编码\n\n### 抽样\n\n**连续时间信源的离散化**\n\n![](../images/通网/2_1.jpg)\n\n离散化的方式：在标准正交基上投影展开\n\n$$\ns(t) = \\sum_k a_k\\phi_k(t)\\\\\na_k = <s(t), \\phi_k(t)>\n$$\n\n若 $s(t)$ 是时限信号（宽度 $T$），可以用傅里叶展开的系数作为离散化结果：$s(t) = \\sum\\limits_k a_k e^{2\\pi jkt/T}$\n\n若 $s(t)$ 是带限信号（带宽 $W$），可以在频域对 $\\hat S(f)$ 做傅里叶展开：\n\n$$\n\\hat S(f) = \\sum\\limits_k \\alpha_k e^{2\\pi jkf/(2W)}\n$$\n\n变换回时域时，得到 Nyquist 抽样定理：\n\n$$\ns(t) =\\sum\\limits_{k}^{}s(kT) \\text{sinc}\\left(\\left(\\frac{t}{T} - k\\right)\\right), T = \\frac{1}{2W}\n$$\n\n频域无混叠等价于时域无畸变\n\n对于带通采样，有无混叠条件：\n\n![](../images/通网/2_2.jpg)\n\n可以推导得出：\n\n$$\nf_s = 2B\\left(1 + \\frac{M}{N}\\right)\\\\\nN = \\left\\lfloor\\frac{f_H}{B}\\right\\rfloor\\\\\nM = \\left\\lbrace\\frac{f_H}{B}\\right\\rbrace\\\\\nB = f_H - f_L\n$$\n\n![](../images/通网/2_3.jpg)\n\n横轴为 $f_H/B$，纵轴为 $f_s$\n\n**量化**\n\n分层电平： $\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$ \n\n重建/输出电平：$y_k$代表一个量化区间，用以重构信号时使用的电平值\n\n量化函数： $y = Q(x)$, $y_k = Q\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$\n\n量化间隔： $\\Delta_k = x_{k + 1} - x_{k}$\n\n均匀量化 & 非均匀量化\n\n均匀量化只对有界随机变量存在\n\n### 量化\n\n* 在此只讨论标量的量化\n* 量化噪声： $q = x - y = x - Q(x)$ \n* 量化噪声是一个随机变量\n* 方差 $\\sigma_q^2 = \\int_{-\\infty}^{\\infty}[x - Q(x)]^2p_x(x)\\mathrm dx$\n* 方差与输入信号分布有关，不存在普适的最佳量化方案\n\n#### 量化噪声的计算\n\n$$\n\\sigma_q^2 =\\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx\n$$\n\n从较容易的情况着手\n- 只考虑电平区间 $[-V,V]$ 之间的信号，并假设量化间隔很小，亦即分层电平很密\n- 在实际情况中，信号的分布函数处处可导，此时每个量化区间内信号的条件分布为均匀分布\n\n量化区间内，近似概率密度 $p_x(x) = \\frac{P_k}{\\Delta_k}$\n\n密集分层的量化噪声近似\n\n$$\n\\sigma_{qn}^2 = \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx = \\sum\\limits_{k=1}^{L}\\frac{P_k}{\\Delta_k}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2\\mathrm dx = \\frac{1}{12}\\sum_{k = 1}^L P_k\\Delta_k^2 = \\frac{1}{12} \\int_{-V}^{V}(\\Delta_k)^2p_x(x)\\mathrm dx\n$$\n\n若 $\\Delta_k = \\Delta$，\n\n$$\n\\sigma_{qn}^2 = \\frac{1}{12}\\sum_k P_k\\Delta_k^2 = \\frac{\\Delta_k^2}{12}\n$$\n\n计算量化结果做无损压缩后的比特数：\n\n$$\nH(Q(x)) = -\\sum_k P_k \\log P_k = \\underbrace{- \\int_{-\\infty}^{\\infty}p_x(x)\\log p_x(x) \\mathrm dx }_{h(X)} + \\log \\frac{1}{\\Delta}\n$$\n\n由 $\\Delta = \\sqrt{12\\sigma_{qn}^2} = 2\\sigma_{qn}\\sqrt{3}$，\n\n$$\nH(x) = h(x) + \\log \\frac{1}{2\\sigma_{qn}\\sqrt{3}}\n$$\n\n无损压缩的 bit 数为： $\\tilde{R} = h(X) - \\frac{1}{2}\\log \\sigma_{qn}^2 - 1.8$\n\n对于均匀量化：\n\n$$\n\\Delta_k = \\frac{x_{max} - x_{min}}{L} = \\frac{2x_{max}}{L}, \\forall k\n$$\n\n于是\n\n$$\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12} = \\frac{x_{max}^2}{3L^2}\n$$\n\n这里的 $\\sigma_{qn}^2$ 是正常量化噪声，仅仅是计算了信号落在 $[-x_{max}, x_{max}]$ 内的情况\n\n如果信号落在 $[-x_{max}, x_{max}]$ 以外，就就近判断至两端的量化区间，产生过载噪声\n\n$$\n\\sigma_{qo}^2 = \\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx + \\int^{-x_{max}}_{-\\infty}(x + x_{max})^2p_x(x)\\mathrm dx = 2\\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx\n$$\n\n总噪声等于正常量化噪声加上过载噪声：\n\n$$\n\\sigma_{qs}^2 = \\sigma_{qn}^2 + \\sigma_{qo}^2\n$$\n\n如果用 $R$ bit 编码：\n\n$$\n\\Delta_k = \\frac{2x_{max}}{L} = \\frac{x_{max}}{2^{R - 1}}\\\\\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx = \\frac{x_{max}^2}{3 \\times 2^{2R}}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx\n$$\n\n定义非过载信号功率：\n\n$$\n\\sigma_s^2 = \\int_{-x_{max}}^{x_{max}}x^2p_x(x)\\mathrm dx\n$$\n\n当 $\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx \\rightarrow 1$， $SNR_q \\approx \\frac{\\sigma_s^2}{x_{max}^2/(3 \\times 2^{2R})} = 3 \\times 2^{2R} \\times \\zeta^2$，这里定义 $\\zeta = \\frac{\\sigma_s}{x_{max}}$ 为量化范围内信号的饱满程度。\n\n对数单位下：\n\n$$\nSNR_q(dB) = 6.02R + 20\\log_{10}(\\zeta) + 4.77\n$$\n\n* 多一个 bit，$SNR_q$ 提升 $6.02dB$\n* $\\zeta$ 要在合理范围，$\\zeta$ 过大时过载会严重劣化性能\n\n#### 最优量化\n\n目标：给定量化区间总数，最小化量化噪声\n\n优化问题：\n\n$$\n\\min \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2 p_x(x)\\mathrm dx\\\\\ns.t. x_1\\le y_1 \\le x_2 \\le y_2 \\le \\dots \\le y_L \\le x_{L + 1}\n$$\n\n分层电平在重建电平的中点：\n\n$$\n\\frac{\\partial \\sigma_q^2}{\\partial x_k} = 0\\\\\n\\Rightarrow x_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$\n\n重建电平在量化区间的质心：\n\n$$\n\\frac{\\partial \\sigma_q^2}{\\partial y_k} = 0\\\\\n\\Rightarrow y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx}\n$$\n\n对于均匀分布，质心即中点（对于可导的概率分布，当分层很密的时候同样成立）\n\n$$\n y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx} = \\frac{1}{2}(x_{k, opt} + x_{k + 1, opt})\n$$\n\n结合\n\n$$\nx_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$\n\n可得均匀分布的最佳量化是区间等分，中点重建\n\n#### 工程用量化\n\n![](../images/通网/2_4.jpg)\n\n#### 语音信号的量化\n\n$[-V, V]$ 内均匀量化的缺陷：\n* 最适合 $[-V, V]$ 之间的有限分布\n* 语音信号呈拉普拉斯分布，特点是：\n    * 信号功率小\n    * 动态范围大（长拖尾）\n* 如果采用均匀量化\n    * 较大的V：增大[-V，V]内的量化噪声\n    * 较小的V：增大过载噪声\n\n解决思路1：非均匀量化\n\n**语音信号的非均匀量化**\n\n均匀量化的问题\n- 对具有不同“概率权重”的区间“一视同仁”\n- 没有考虑概率密度对于量化噪声的影响\n\n解决方案\n- 对于信号经常出现的区域，使用较细的颗粒度进行量化\n    - 信号经常落入这个区域，减小该区域的量化噪声损失\n- 对于信号不经常出现的区域，使用较粗的颗粒度进行量化\n    - 信号不经常落入这个区域，量化噪声稍大不会影响大局\n\n采用取对数后均匀量化的方法：\n\n![](../images/通网/2_5.jpg)\n\n语音信号的瞬时压扩：\n\n![](../images/通网/2_6.jpg)\n\n**对数量化**\n\n* 正常量化信噪比与信号的分布无关\n* 过载导致的噪声与信号的分布有关！\n\n记 $\\Delta_k$为对数化之前的量化区间, $\\Delta_k^\\prime = \\Delta$ 为对数化之后的量化区间\n\n![](../images/通网/2_9.jpg)\n\n\n**实用的对数量化**\n\n实际工程中，采用另外两个函数（线性放缩，更容易实现）：\n\n* A律（欧洲提出，我国采用）\n\n$$\nf(x) = \\begin{cases}\n    \\frac{Ax}{1 + \\ln A}, 0 \\le x \\le \\frac{1}{A}\\\\\n    \\frac{1 + \\ln Ax}{1 + \\ln A}, \\frac{1}{A} \\le x \\le 1\\\\\n\\end{cases}\n$$\n\n* ITU G.712建议中取A＝87.6\n* 小信号时，信噪比增加了24dB\n\n* μ律（美国提出）\n\n$$\nf(x) = \\frac{\\ln (1 + \\mu x)}{\\ln (1 + \\mu)}, 0 \\le x \\le 1\n$$\n\n\n* ITU G.712建议中取μ＝255\n* 小信号时，信噪比增加了33.5dB\n\n**脉冲编码调制(PCM)**\n\n- 语音信号的实际压缩编码方式\n- 包括两个主要步骤\n- 抽样：$f_s = 8000Hz$\n- 量化与编码：使用近似对数压扩，每个抽样量化为8位\n- PCM的输出码率为64kbps\n\n**该码率与其推导过程十分重要**\n\n\n**PCM编码协议**\n\n基本思想\n- 用13折线近似A律\n- 用15折线近似μ律\n\n![](../images/通网/2_7.jpg)\n\n码字结构：\n\n$$\n\\mathop{M_1}\\limits_{极性码} \\quad \\underbrace{M_2 \\quad M_3 \\quad M_4}_{段落码}\\quad \\underbrace{M_5 \\quad M_6\\quad M_7 \\quad M_8}_{电平码} \\quad \n$$\n\n![](../images/通网/2_8.jpg)\n\n例：\n\n1250的输出：1 110 0011\n\n接收端解码： 1024 + 128 + 64 + 32 = 1248\n\n## 数字基带传输\n\n### 符号映射\n\n**符号集合**\n\n$M = |\\mathcal{A}|$ 为符号集合 $\\mathcal{A}$ 的符号数量。\n\n**bit 承载量**\n每个符号最多可对应 $r = \\log_2|\\mathcal{A}|$ 个 bit，称为集合的 bit 承载量\n\n\n数字通信的典型符号：\n\n* ASK\n* PAM\n* PSK\n* QAM\n\n![](../images/通网/3_1.jpg)\n\n**邻位最小差错映射：Grey 码**\n\n相邻符号对应的 bit 串仅有一位差异\n\n**符号周期（Symbol Period）**\n\n* 传输一个符号所需的平均时间\n* $T_s$\n\n通信速率：\n* 符号速率：$R_s = \\frac{1}{T_s}$\n* Bit 速率： $R_b = R_s \\log_2 M = \\frac{1}{T_s}\\log_2 M$\n\n### 数字调制\n\n基带调制：将时间上离散的符号，加载到时间上形成连续的波形\n\n通信信号具有带宽受限特性，因为：\n\n- 自然原因：各类通信线路，如双绞线，同轴电缆，射频功放等均对通过的频率有一定限制\n- 人为原因：多用户频谱共享通信，如蜂窝无线系统，需约束每路信号的带宽，以免相互干扰\n\n如何产生带限信号？\n\n产生一个信号 $s(t) =\\sum\\limits_{k=-\\infty}^{\\infty}a_kg(t- k T_s)$，$g(t) = \\frac{\\sin 2\\pi Wt}{2\\pi Wt}$是个带限信号。\n\n$$\nG(f) = \\begin{cases}\n    1, |f| \\le W,\\\\\n    0, |f| \\gt W\n\\end{cases}\n$$\n\n让间隔 $T_s$ 的冲击 $a_k\\delta(t - kT_s)$ 依次通过冲击响应为 $g(t)$ 的低通滤波器\n\n![](../images/通网/3_2.jpg)\n\n### Nyquist 准则：无ISI条件\n\n**符号间串扰（Inter Symbol Interference, ISI）**\n\n对 $s(t)$ 采样：\n\n$$\ns(nT_s) = a_ng(0) + \\underbrace{\\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big)}_{\\text{ISI}}\n$$\n\n怎么让 ISI 为0？\n\n**眼图：观察符号间串扰**\n\n眼图（Eye Pattern）是直观察看数字基带传输性能的有效方法，用一个示波器\n\n$$\n垂直输入 \\xrightarrow{接} 匹配滤波器的输出\\\\\n水平扫描速度 \\xrightarrow{设为} 𝑅_𝑠的整数倍\n$$\n\n![alt](../images/通网/3_3.jpg)\n\n眼皮的厚度表示 ISI 的失真，眼睛的张开程度表示噪声容限。\n\n![alt](../images/通网/3_4.jpg)\n\n消除 ISI 对带限脉冲的要求\n\n时域特征：\n\n$$\n\\left.\\begin{align*}\n    g(0) &= 1\\\\\n    \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big) &= 0\n\\end{align*}\\right\\rbrace \\Leftrightarrow \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_{n - k}g\\big(kT_s\\big) = 0\\\\\n\\Leftrightarrow g(kT_s) = \\begin{cases}\n    1, k = 0,\\\\\n    0, k \\ne 0\n\\end{cases} \\\\\n\\lrArr g(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t)\n$$\n\n从频域提取特征：\n\n$$\ng(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t) \\lrArr G(f) *\\sum\\limits_{n=-\\infty}^{\\infty}\\frac{1}{T_s}\\delta(f + \\frac{n}{T_s}) = 1\\\\\n\\lrArr \\sum\\limits_{n=-\\infty}^{\\infty}G\\left(f + \\frac{n}{T_s}\\right) = T_s\n$$\n\n**Nyquist 准则**\n\n将带限脉冲的频谱分别平移 $n/T_s$（ $n$ 为任意整数）若其叠加的结果对任意频率恒为定值，则 ISI 为0\n\n### 通信速率与带宽效率\n\n**理解 Nyquist 准则**\n\n![alt](../images/通网/3_5.jpg)\n\n![alt](../images/通网/3_6.jpg)\n\n* 最大符号速率受制于带宽 $R_s = \\frac{1}{T_s} \\le 2W$\n* 低通发送滤波器应该满足残留对称条件\n\n**通信速率与带宽效率**\n\n$$\nR_s \\le 2W\\\\\nR_b = R_s \\log_2 M\\\\\n\\Rightarrow R_b \\le 2W \\log_2 M\n$$\n\n* 针对给定形式的低通滤波器，可写出$R_s$与$W$之间的线性函数关系\n\n**信号功率与带宽效率**\n\n设单个符号的能量为 $E_s$\n\n则信号功率为单位时间内的能量\n$$\nP = \\frac{E_s}{T_s} = E_sR_s\n$$\n\n无冗余编码时，一个比特的能量为$𝐸_𝑏$，则\n\n$$\nP = \\frac{E_b\\log_2 M}{T_s} = E_bR_b\n$$\n\n带宽效率的定义：单位带宽承载的速率\n\n$$\n\\eta = \\frac{R_b}{W} \\le 2\\log_2 M\n$$\n\n\n* 为什么不能无限制扩大符号集合？\n\n过大的符号集合对信噪比有更高的要求，噪声容易干扰符号的分辨\n\n### 升余弦滤波器\n\n**升余弦滤波器**\n\n由于理想滤波器难以实现，所以常用满足残留对称条件的非理想低通生成基带脉冲，最常用的就是升余弦滤波器\n\nRaised Cosine(要记住)\n\n$$\nH(f) = \\begin{cases}\n    T_s, &0 \\le |f| \\lt \\frac{1 - \\alpha}{2 T_s}\\\\\n    \\frac{T_s}{2}\\left\\lbrace1 + \\cos \\left[\\frac{\\pi T_s}{\\alpha}\\left(|f| - \\frac{1 - \\alpha}{2T_s}\\right)\\right]\\right\\rbrace, &\\frac{1 - \\alpha}{2 T_s} \\le |f| \\le \\frac{1 + \\alpha}{2 T_s}\\\\\n    0, & |f| \\gt \\frac{1 + \\alpha}{2 T_s}\n\\end{cases}\n$$\n\n$\\alpha = 2WT_s - 1 \\in [0, 1]$ 称为滚降系数，越小坡越陡，越大坡越缓。\n\n时域冲激响应：\n\n$$\nh(t) = \\text{Sa}(\\pi t/ T_s)\\frac{\\cos (\\alpha\\pi t/ T_s)}{1 - 4(\\alpha t/T_s)^2}\n$$\n\n升余弦滤波器的性质：\n\n\n<font color=\"red\">常考性质：</font>\n\n$$\nW = \\frac{\\alpha + 1}{2T_s} = \\frac{\\alpha + 1}{2}R_s \\Rightarrow R_s/2 \\le W \\le R_s\\\\\nR_s = \\frac{1}{T_s} = \\frac{2}{\\alpha + 1} W \\Rightarrow W \\le R_s \\le 2W\n$$\n\n带宽效率\n\n$$\n\\eta_b = \\frac{R_s\\log_2|\\mathcal{S}|}{W} \\le 2\\log_2|\\mathcal S|\n$$\n\n升余弦滤波器的带宽效率\n\n$$\n\\eta_b = \\frac{2\\log_2|\\mathcal{S}|}{\\alpha + 1}\n$$\n\nPCM 语言信号速率 64kbps：8 bit 采样，8 bit 量化，8*8 = 64.\n\n例题一：传送一路PCM语音信号\n- 若带宽限制为40kHz，采用二元码，则可用滚降系数范围\n是多少？\n- 若采用四元码，最多需要多少带宽？\n\n解：PCM语音信号是64kbps\n- 采用二元码，则所需符号速率为 $R_s = R_b = 64kbps$\n* 则 $\\frac{\\alpha + 1}{2}64 \\le 40$, $0\\le \\alpha \\le 0.25$\n\n* 采用四元码：$R_s = \\frac{R_b}{\\log_24} = 32kbps$\n* $W \\le R_s = 32kHz$\n\n例题二：若传送一路信号$𝑅_𝑏$ = 112kbps，信道带宽𝑊 = 30𝑘bps,\n求𝑀和𝛼\n\n$$\n\\frac{\\log_2M}{\\alpha} = \\frac{R_b}{2W} = \\frac{28}{15} \\in [1.5, 2]\\\\\n$$\n\n认定 $\\log_2M = k$ 为整数，则$k = 2 或 3$。对应可解：\n\n$$\n\\alpha_1 = \\frac{1}{14}, M_1 = 4\\\\\n\\alpha_2 = \\frac{17}{28}, M_2 = 8\n$$\n\n### 通信信号的功率谱计算\n\n功率谱刻画了随机过程的功率在频域上的分布。\n* 对于宽平稳过程（自相关只与时差有关），功率谱易于从 $R(\\tau)$ 的傅里叶变换得到，即$S(f) = \\mathcal{F}[R(\\tau)]$\n* 但是，通信信号一般不是宽平稳过程，而是周期平稳过程：$R(t_1, t_2) = R(t_1 + kT_s, t_2 + kT_s)$ \n\n定义 \n\n$$\n\\overline{R}(\\tau) = \\frac{1}{T_s} \\int_{0}^{T_s}R(t+\\tau, t)\\mathrm dt\n$$\n\n则其功率谱\n\n$$\nS(f) = \\mathcal{F}[\\overline{R}(\\tau)]\n$$\n\n若输入信号的功率谱 $S_{AI}(f)$，输出为$S_A(f)$，则对于宽平稳和周期平稳信号均有卷积关系：\n\n$$\nS_A(f) = S_{AI}(f)|H(f)|^2\n$$\n\n证明可以采用样本统计法：假设符号序列的长度为 $2N - 1$.\n\n$$\ns_{AI}(t) =\\sum\\limits_{k=-N}^{N}a_k\\delta(t - k T_s)\\\\\ns_{A}(t) =\\sum\\limits_{k=-N}^{N}a_kh(t - k T_s)\\\\\n\\hat s_{AI}(f) =\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\\\\\n\\hat s_{A}(f) = H(f)\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\n$$\n\n功率谱的定义：\n\n$$\nS(f) = \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat s(f)|^2)}{(2N + 1)T_s}\n$$\n\n可以验证 $S_A(f) = S_{AI}(f)|H(f)|^2$\n\n针对样本统计法，可以算出 $E(|\\cdot|^2)$的表达式：\n\n$$\nS_A(f) = \\frac{|H(f)|^2}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f)\n$$\n\n这里$R_a[m]$ 是输入符号的自相关。\n\n先考虑无记忆调制，符号之间相互独立：\n\n$$\nR_a[n] = E[a_ia_{i+n}] = \\begin{cases}\n    \\sigma_a^2+m_a^2 &n=0\\\\\n    m_a^2 &n\\ne 0\n\\end{cases}\n$$\n\n其中，$m_a = E[a_n]$，$\\sigma_a^2 = E[a_n^2] - m_a^2$\n\n于是，重写累加部分：\n\n$$\n\\begin{align*}\n    &\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f) \\\\\n    =& \\sigma_a^2 + m_a^2\\sum\\limits_{n=-\\infty}^{\\infty}\\exp\\big[-jn(2\\pi T_s)f\\big]\\\\\n    =& \\sigma_a^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\delta\\bigg(f - \\frac{n}{T_s}\\bigg)\n\\end{align*}\n$$\n\n从而\n\n$$\nS_A(f) = \\underbrace{\\frac{\\sigma_a^2}{T_s}|H(f)|^2}_{连续谱} + \\underbrace{\\frac{m_a^2}{T_s^2}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|H\\bigg(\\frac{n}{T_s}\\bigg)\\bigg|^2 \\delta\\bigg(f - \\frac{n}{T_s}\\bigg)}_{线谱}\n$$\n\n此式应用的两个条件：\n* 无记忆\n* 不同符号波形一致\n\n线谱：可用于定时恢复。方便恢复时钟分量。\n\n\n**任意波形调制**\n\n之前将 $a_i$ 映射为 $a_ih(t)$，可以推广：\n\n$$\n\\forall a_i \\ne a_j, s_i(t) \\ne s_j(t)\n$$\n\n有时候由于信号功率需要保持稳定（恒包络调制），对不同符号采用不同波形，而不是采用变化幅度的信号。\n\n若任意波形二元调制信号 $s(t) =\\sum\\limits_{k=-\\infty}^{\\infty}g_k(t)$\n\n$$\ng_k(t) = \\begin{cases}\n    s_1(t - kT_s), w.p.\\ p\\\\\n    s_2(t - kT_s), w.p.\\ \\bar p = 1 - p\n\\end{cases}\n$$\n\n(w. p. = with probability)\n\n分解为直流分量和交流分量：\n\n$$\ns(t) = \\underbrace{E(s(t))}_{DC,记为v(t)} + \\underbrace{s(t) - E(s(t))}_{AC, 记q(t)}\n$$\n\n则\n\n$$\nv(t) = \\sum\\limits_{k=-\\infty}^{\\infty}[ps_1(t - kT_s) + \\bar p s_2(t - kT_s)]\n$$\n\n这是一个周期为$𝑇_𝑠$的确定性周期信号，功率谱由傅里叶展开计算\n\n$$\nS_v(f) =\\sum\\limits_{n=-\\infty}^{\\infty}|D_n|^2\\delta(f - \\frac{n}{T_s})\\\\\nD_n = \\frac{1}{T_s}\\int_{-T_s/2}^{T_s/2}v(t)e^{-j2\\pi t/T_s}\\mathrm dt = \\frac{1}{T_s}\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\n$$\n\n$$\nS_v(f) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$\n\n用样本统计法计算 $S_q(f)$：\n\n$$\n\\begin{align*}\n    S_q(f) =& \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat q_N(f)|^2)}{(2N + 1)T_s}\\\\\n    =& \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2\n\\end{align*}\n$$\n\n$$\nS(f) = \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$\n\n### 基带解调\n\n最佳接收用于在给定发送功率下提高信噪比\n\n最佳判决用于在给定信噪比下降低误码率\n\n#### 基带传输的噪声模型\n\n![alt](../images/通网/4_1.jpg)\n\n如何选择解调方案？\n\n**方案一：直接抽样**\n\n在信号的峰值位置 $t = kT_s$ 抽样最好。\n\n但噪声方差满足：\n\n$$\n\\sigma^2 = E \\lbrace n^2(t_1) \\rbrace = R(0) = \\frac{n_0}{2}\\delta(0) \\rightarrow \\infty\n$$\n\n（理想的白噪声信号具有无穷大功率）\n\n真实的噪声环境下，接收信号质量随着噪声信号功率的增加而变差。如果信号的峰值处恰好噪声很大，则产生严重失真。\n\n**方案二：能量累积**\n\n![alt](../images/通网/4_2.jpg)\n\n噪声信号仍为高斯随机变量：\n\n$$\nn = \\int_{0}^{T_s}n(t)\\mathrm dt\n$$\n\n噪声方差：\n\n$$\n\\sigma^2 = E\\lbrace n^2 \\rbrace = \\int_{0}^{T_s}\\int_{0}^{T_s}\\frac{n_0}{2}\\delta(t_1 - t_2)\\mathrm dt_1\\mathrm dt_2 = \\frac{n_0T_s}{2}\n$$\n\n信噪比：\n\n$$\n\\frac{S}{N} = \\frac{\\left (\\int_{0}^{T_s}a_i h(t)\\mathrm dt \\right)^2}{T_sn_0/2}\n$$\n\n直接积分不是最好的方案。\n\n**方案三：匹配滤波**\n\n匹配滤波的基本思想就是对接收值进行加权线性累加，从而最大化抽样时刻信号功率与噪声功率的比值。\n\n![alt](../images/通网/4_3.jpg)\n\n相关器为 $g(t)$。假设信号为实信号。复信号有类似结论。\n\n$$\nP_S = \\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2\\\\\nP_N = \\mathbf E \\left [ \\left | \\int_{0}^{T_s}n(t)g(t)\\mathrm dt \\right|^2 \\right] = \\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt\n$$\n\n利用 Cauchy-Schwartz 不等式：\n\n$$\n\\frac{\\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2}{\\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt} \\le \\frac{2}{n_0}\\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt\n$$\n\n等号成立当且仅当 $g(t) = kh(t)$。\n\n若为复信号，则需要\n\n$$\ng(t) = h^*(t)\n$$\n\n如何把相关器写成滤波器形式？\n\n（滤波=卷积，相关和卷积就是差一个反褶的关系）\n\n$$\ny(t) = [a_ih(t) + n(t)] * h_m(t) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(t - \\tau)\\mathrm d\\tau\n$$\n\n考虑因果系统，一般将符号波形的最高点设置为 $t = T_s$：\n\n$$\ny(T_s) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(T_s - \\tau)\\mathrm d\\tau\n$$\n\n与相关器比较得到匹配滤波器的表达式：\n\n$$\nh_m(t) = h(T_s - t)\n$$\n\n![alt](../images/通网/4_4.jpg)\n\n图中的“开关”是抽样。\n\n匹配滤波的频域解释：\n\n$$\nP_S = \\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2\\\\\nP_N = \\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df\\\\\n\\frac{S}{N} = \\frac{\\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2}{\\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df} = \\frac{2}{n_0}\\int_{-\\infty}^{\\infty}|H(f)|^2\\mathrm df\n$$\n\nCauchy-Schwartz\n\n$$\nH_m(f) = H^*(f)e^{-j2\\pi fT_s}\n$$\n\n**匹配滤波的增益**\n\n数字传输的优势：数字传输中，基带脉冲h(t)是给定的，在整个码元周期内可以相干累加，而同时让噪声在整个周期内自我抵消\n\n$$\n\\left (\\frac{S}{N}  \\right)_{\\text{match}} \\bigg/ \\left (\\frac{S}{N}  \\right)_{\\text{w.o.match}} = \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\left ( \\int_{0}^{T_s}h(t)\\mathrm dt \\right)^2} \\ge \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\int_{0}^{T_s}1\\mathrm dt\\int_{0}^{T_s}h^2(t)\\mathrm dt} = 1\n$$\n\n匹配滤波的信噪比\n\n$$\n\\frac{S}{N} = E \\left [ \\frac{2}{n_0} \\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt \\right] = \\frac{\\int_{0}^{T_s}E[a_i^2]h^2(t)\\mathrm dt}{n_0/2} = \\frac{E_s}{n_0 / 2}\n$$\n\n分子——传送一个符号的能量\n\n分母——噪声谱密度，单位是能量的单位\n\n以上采用的是等效基带模型。采用实际物理波形模型：\n\n$$\nS = \\frac{E_s}{T_s} = E_sR_s\\\\\nN = Wn_0\\\\\n\\frac{S}{N} = \\frac{E_s}{n_0}\\frac{R_s}{W}\\\\\n$$\n\n两个模型推得的信噪比表达式不同，差异在于等效基带模型使用了匹配滤波器，获得了最优的信噪比：\n\n$$\n\\frac{R_s}{W} \\le 2 \\Rightarrow\\left (\\frac{S}{N}  \\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\n$$\n\n从实际物理波形模型来看，上式取等的条件应该是基带脉冲采用的是理想低通（Sa 函数），如果用升余弦滤波\n\n$$\n\\frac{R_s}{W} = \\frac{2}{\\alpha + 1} \\Rightarrow \\left(\\frac{S}{N}\\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\\frac{2}{\\alpha + 1}\n$$\n\n但是，在等效基带模型中，我们考虑的是任意脉冲 $h(t)$，并没有要求它的形状，这两个模型在最优信噪比的产生条件上出现了矛盾？\n\n![alt](../images/通网/4_5.jpg)\n\n![alt](../images/通网/4_6.jpg)\n\n#### 传送一串符号\n\n![alt](../images/通网/4_7.jpg)\n\n无 ISI 条件：\n\n$$\nh(t)*h_m(t) = h(t) * h(T_s - t)\\\\\nH(f)H_m(f) = H(f)H^*(f)e^{-j2\\pi fT_s} = \\left | H(f) \\right|^2 e^{-j2\\pi fT_s} \n$$\n\n从而有根号奈奎斯特条件：\n\n$$\nH(f) = \\sqrt{H_{N-I}(f)}e^{-j2\\pi fT_s} \nH_m(f) = \\sqrt{H_{N-I}^*(f)}e^{-j2\\pi fT_s} \n$$\n\n这就要求发送和接受滤波器要满足如下要求：\n\n$$\nh_T(t) = h_{\\sqrt{N}}\\left ( t - \\frac{T_s}{2} \\right)\\\\\nh_R(t) = h_{\\sqrt{N}}\\left (\\frac{T_s}{2}  - t\\right) = h_T(T_s - t)\n$$\n\n#### 符号差错模型：\n\n![alt](../images/通网/4_8.jpg)\n\n$$\ny_i = \\bar h a_i + n_i\n$$\n\n![alt](../images/通网/4_9.jpg)\n\n### 判决与差错\n\n### 最佳判决\n\n![ima](../images/通网/5_2.jpg)\n\n![ima](../images/通网/5_1.jpg)\n\n![alt](../images/通网/5_3.jpg)\n\n多元符号的最佳判决\n\n$$\na^* = \\argmax_{a\\in U} f(y|a)f(a)\\\\\nf(a) = \\frac{1}{M}\\\\\na^* = \\argmax_{a\\in U} f(y|a)\\\\\n$$\n\n$y = a + n$ 的条件分布是\n\n$$\nf(y|a) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y - a)^2}{2\\sigma^2}\\right)\n$$\n\n从而得到\n\n$$\na^* = \\argmin_{a\\in U} |y - a|\n$$\n\n选择一个符号，让它到接收符号y距离最小，以此作为判决结果！\n\n双极性码的判决门限：\n\n![alt](../images/通网/5_4.jpg)\n\n单极性码的判决门限:\n\n![alt](../images/通网/5_6.jpg)\n\n#### SER & BER\n\n考虑二元符号\n\n发送 A 的出错概率：\n\n$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = \\int_{A/\\sigma}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}\\exp \\left ( -\\frac{t^2}{2} \\right)\\mathrm dt = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n发送 -A 的出错概率：\n\n$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n从而平均符号差错概率：\n\n$$\nP_s = \\frac{1}{2}\\left (Q \\left ( \\frac{A}{\\sigma} \\right) + Q \\left ( \\frac{A}{\\sigma} \\right)  \\right) = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n称为符号差错概率(Symbor Error Probability, SEP)，其统计结果称为误符号率（Symbol Error Ratio, SER）\n\n由于Q是减函数，所以误符号率随A增大而减小，随噪声标准差增大而增大\n\n误符号率不关心具体的A或标准差，而是由其比值所决定\n\n对于多元而言：\n\n对于任意符号集合，只要某判决门限与符号距离为A，则由于超出该判决门限而差错的条件概率就是：\n\n$$\nQ \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n计算信噪比：\n\n信号平均功率： $S = \\frac{1}{M}\\sum\\limits_{i=1}^{M}|a_i|^2$\n\n信号峰值功率： $S_p = \\max_{a_i \\in U} |a_i|^2$\n\n噪声功率： $N = \\sigma^2$\n\n对于双极性二元符号，平均功率为 $S = A^2$\n\n从而信噪比为 \n\n$$\n\\frac{S}{N} = \\frac{A^2}{\\sigma^2}\n$$\n\n利用等效关系得到误符号率和信噪比的关系\n\n$$\nP_s = Q \\left ( \\frac{A}{\\sigma} \\right) = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$\n\n更一般的二元码 SER\n\n$$\nU = \\lbrace D-A, D+A \\rbrace\\\\\n\\zeta = \\frac{D}{A}\\\\\nP_s = Q(\\sqrt{\\frac{S}{(1 + \\zeta^2)N}})\n$$\n\n更一般的 M 元码 SER\n\n符号集合为 $\\lbrace D - (M - 1)A, \\dots, D + (M  - 1)A \\rbrace$\n\n$$\n\\zeta = \\frac{D}{A\\sqrt{\\frac{M^2 - 1}{3}}}\\\\\nP_s = \\frac{2(M - 1)}{M}Q \\left ( \\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{(1 + \\zeta^2)N}} \\right)\n$$\n\n双极性 M 元码的 SER (掌握计算方法)\n\n$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{M^2 - 1} \\frac{S}{N}}\\right)\n$$\n\n无论M为奇数还是偶数，结果都是一样的！\n\n单极性 M 元码的 SER (掌握计算方法)\n\n$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$\n\n\n要使得双极性和单极性码的 SER 相同，二者的信噪比的比值为\n\n$$\n\\left ( \\frac{S}{N} \\right)_d \\bigg / \\left ( \\frac{S}{N} \\right)_s = \\frac{M^2 - 1}{2(M - 1)(2M  - 1)} \\approx \\frac{1}{4}\n$$\n\n显然，双极性的性能更好，它对信噪比的要求是单极性的四分之一，更能忍受噪声。\n\n误比特率(Bit Error Rate, BER)：\n\n$$\nP_b \\approx \\frac{P_s}{\\log_2M}\n$$\n\n注意这是近似结果，且有成立条件，只对二元码是严格成立的！\n* 假设一个符号的错判导致 1bit 的错误，假设成立的条件：\n    * Grey 码映射\n    * 信噪比不过于小\n\n\n各类符号集合的 BER\n\n双极性二元码\n\n$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$\n\n单极性二元码\n\n$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{2N}} \\right)\n$$\n\n单极性二元码损失了 3 dB.\n\n双极性 M 元码\n\n$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{N}})\n$$\n\n单极性 M 元码\n\n$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$\n\n由于\n\n$$\n\\frac{S}{N} = 2\\log_2 M\\frac{E_b}{n_0}\n$$\n\n故可以把 SER 和 BER 用 $E_b/n_0$ 表示：\n\n双极性二元码：\n\n$$\nP_s = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\n$$\n\n单极性二元码：\n\n$$\nP_s = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\n$$\n\n双极性 M 元码：\n\n$$\nP_s = \\frac{2(M - 1)}{M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\n$$\n\n单极性 M 元码：\n\n$$\nP_s = \\frac{2(M - 1)}{M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\n$$\n\n例子：相移键控 MPSK\n\n$$\n\\begin{align*}\n    S_{MPSK}(t) =& \\sum\\limits_{n}^{}g(t - nT_s)A\\cos(\\omega_c t + \\phi_n)\\\\\n    =& \\left [\\sum\\limits_{n}^{}A\\cos \\phi_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}A\\sin \\phi_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$\n\n* 所有符号的模相同\n* 幅角在 $[0, 2\\pi]$ 均匀分布\n\n可以用星座图表示：\n\n![alt](../images/通网/5_5.jpg)\n\n根据信号的 $I, Q$ 表示\n\n计算 MPSK 的 SER:\n\n考虑星座点 $(A, 0)$\n\n接收信号的分布函数为\n\n$$\nf(a, b) - \\frac{1}{2\\pi \\sigma_n^2}\\exp \\left ( -\\frac{(a - A)^2 + b^2}{2\\sigma_n^2} \\right)\n$$\n\n变换到极坐标系\n\n$$\nf(\\rho, \\theta) = \\frac{\\rho}{2\\pi\\sigma_n^2}\\exp \\left ( -\\frac{\\rho^2 + A^2 - 2A\\rho\\cos\\theta}{2\\sigma_n^2} \\right)\\\\\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{A^2}{2\\sigma_n^2}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - A/\\sigma_n\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$\n\n误符号率可以表示为\n\n$$\nP_{s, MPSK} = 1 - \\int_{-\\pi/M}^{\\pi/M}f(\\theta)\\mathrm d\\theta\n$$\n\n用信噪比表示：\n\n$$\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$\n\n如果 $S/N$ 很大：\n\n$$\n\\begin{align*}\n    \\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho \\approx& \\int_{-\\infty}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\\\\\n    =& \\sqrt{\\frac{S}{N}}\\cos\\theta\n\\end{align*}\n$$\n\n利用高信噪比近似：\n\n$$\nf(\\theta) = \\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\n$$\n\n当 M 比较大时：\n\n$$\n\\begin{align*}\n    P_{s, MPSK} =& 1 - \\int_{-\\pi/M}^{\\pi/M}\\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    \\approx& \\frac{2}{\\sqrt{\\pi}}\\int_{\\pi/M}^{\\infty}\\sqrt{\\frac{S}{2N}}\\cos\\theta\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}}\\int_{\\pi/M}^{\\infty}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\sqrt{\\frac{S}{N}}\\sin\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}} \\int_{\\sqrt{S/N}\\sin\\pi/M}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\mathrm du\\\\\n    =& 2Q \\left ( \\sqrt{\\frac{S}{N}}\\sin\\frac{\\pi}{M} \\right)\n\\end{align*}\n$$\n\n换算成 BER， $E_b/n_0$\n\n$$\nP_{b, MPSK} = \\frac{2}{\\log_2M}Q \\left ( \\sqrt{2\\log_2M\\frac{E_b}{n_0}}\\sin\\frac{\\pi}{M} \\right)\n$$\n\n一个简单的方法：\n\n看起来像是先射箭后画靶。\n\n![alt](../images/通网/5_7.jpg)\n\n例子2：正交幅度调制 QAM\n\n信号表示\n\n$$\n\\begin{align*}\n    S_{MQAM}(t) =& \\left [\\sum\\limits_{n}^{}a_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}b_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$\n\nI,Q 两路的电平集合：\n\n$$\na_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\nb_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\n$$\n\nQAM是一种典型的星座图，它分布于复平面的格点上，其符号的实虚部均为奇数（便于分析）\n\n解调过程：\n\nI 路信息提取：乘以同相载波 $\\cos\\omega_c t$，再低通滤波\n\nQ 路信息提取：乘以同相载波 $-\\sin\\omega_c t$，再低通滤波\n\n差错分析：\n\n![alt](../images/通网/5_8.jpg)\n\n（通过后面的分析可以发现，降低误码率的关键是将符号间的最小距离最大化）\n\n计算各符号的差错概率：\n\n四个角：\n\n$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$\n\n$4(L - 2)$ 个边点：\n\n$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\n$$\n\n$(L - 2)^2$ 个内点：\n\n$$\nP_s = 1 - \\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$\n\n计算平均 SEP：\n\n$$\n\\begin{align*}\n    P_s =& \\frac{1}{L^2}\\lbrace 4(2Q - Q^2) + 4(L - 2)(3Q - 2Q^2) + (L - 2)^2(4Q - 4Q^2) \\rbrace\\\\\n    \\approx& \\frac{4L^2 - 4L}{L^2}Q \\left ( \\frac{A}{\\sigma_n} \\right)\n\\end{align*}\n$$\n\n省略了 $Q$ 的高阶量。\n\n计算平均功率：\n\n$$\nS = 2 \\times \\frac{2A^2}{L}[1^2 + 3^2 + \\dots + (L - 1)^2] = \\frac{2(L^2 - 1)}{3}A^2\n$$\n\n是同A的LPAM功率的两倍。因为MQAM有两路LPAM\n\n得到 SEP：\n\n$$\nP_s = \\frac{4M - 4L}{M} Q \\left (\\sqrt{\\frac{3}{2(M - 1)}\\frac{S}{N}}  \\right)\\\\\nM = L^2\n$$\n\n得到 BEP：\n\n$$\nP_b = 4 \\left (1 - \\frac{1}{\\sqrt M}  \\right) Q \\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right) \\approx 4Q\\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right)\\\\\n$$\n\n注意到MQAM可以看成两路正交的MPAM\n\n$$\n\\begin{align*}\n    P_{s, MQAM} =& 1 - (1 - P_{LPAM})^2\\\\\n    \\approx& 2P_{LPAM}\\\\\n    =& 4 \\left ( 1 - \\frac{1}{\\sqrt M} \\right)Q \\left ( \\sqrt{\\frac{3}{(M - 1)}\\frac{S/2}{N}} \\right)\n\\end{align*}\n$$\n\n这个推导方式更简单。\n\nQAM 是在独立解映射条件下最好的方案。但是距离高斯信道容量还有一定距离。要达到更好的信道容量，可以采用联合解映射，将译码过程联合起来。\n\n例子3：频移键控 FSK\n\n一般来说，信号表达式和调制框图的相互反演是比较容易做的\n\n相对于PAM，PSK和QAM，FSK占用更大的频带，\n\n相干解调\n\nCoherent Demodulation\n\n- 反思FSK非相干解调方式，如果对每个频率的载波进行匹配，则可以提高信噪比\n- 这种方法需要本地子载波\n- 解调器的结构和非相干解调很像\n\n- 无法用星座图方法表示，但是可以用类似的信号空间表示\n- 若MFSK载频等间隔，则调制阶数约高，占用带宽越大\n- 如果每次可以选择多个载频，甚至控制载频幅度，则可承载的符号量可以获得极大提升。由此便引申出OFDM技术\n* 通过调制FSK的每个载波的幅度相位，可以承载更多的信息\n\n星座图没法表述 FSK. 可以使用信号空间方法来表示。\n\n差错分析：\n\nFSK 的判决门限为棱锥形状：\n\n![alt](../images/通网/5_9.jpg)\n\n根据对称性，可以只考虑一个符号的差错概率。\n\n考虑 FSK 信号\n\n$$\n[A, 0, \\dots, 0]\n$$\n\n匹配滤波的输出为\n\n$$\n[A + n_1, n_2, \\dots, n_M]\n$$\n\n正确判决：信号落在本棱锥中\n\n$$\nA + n_1 \\gt n_i, i = 2, \\dots, M\n$$\n\n被判决符号的条件分布为\n\n$$\nf_{[A + n_1, n_2, \\dots, n_M]}(\\vec r) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\n$$\n\n不满足正确判决条件的概率为\n\n$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M \\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i\\mathrm dr_1\\\\\n    =&1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\left (\\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i  \\right)^{M - 1}\\mathrm dr_1\n\\end{align*}\n$$\n\n记 $x = \\frac{r_1}{\\sigma}$\n\n$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi }}\\exp \\left ( -\\frac{(x - A/\\sigma)^2}{2} \\right)\\left (1 - Q(x)\\right)^{M - 1}\\mathrm dx\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\frac{A}{\\sigma}  \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$\n\n$$\n\\frac{A}{\\sigma} = \\sqrt{\\frac{S}{N}} = \\sqrt{\\log_2M\\frac{2E_b}{n_0}}\n$$\n\n可得 SEP 的表达式\n\n$$\n\\begin{align*}\n    P_s =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\frac{S}{N}} \\right)\\right)^{M - 1}\\mathrm du\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\log_2M\\frac{2E_b}{n_0}} \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$\n\n另一种简单估界：\n\n![alt](../images/通网/5_10.jpg)\n\n正交 2FSK 信号在最佳接收条件时的错误概率为\n\n$$\nP_{b,NCFSK} = Q(\\sqrt{E_b/n_0})\n$$\n\n随着 M 的增加，MFSK 的差错性能渐优，这是以带宽的占用为代价的。\n\nPAM, QAM, ASK 等技术随着符号个数的增加，差错性能是越来越差。\n\nFDM——Frequency Division Multiplexing\n\n- 先将各路信号调制到不同频段，然后复用整个\n通信带宽\n- 信道的非线性会在FDM系统中产生交调失真与\n高次谐波，引起路际串话，因此，对信道的非\n线性失真要求很高。此外，FDM用到的模拟滤\n波器设计较为复杂。\n\n\n#### OFDM 基本原理\n\nOrthogonal Frequency division multiplexing\n\n- 把一串高速数据流分解为若干速率低得多的子数据流。\n- 将每个子数据流放置在对应的子载波上。\n- 将多个子载波合成，一起并行传输。\n- 优点：频谱利用率高。\n\n正交性的定义：\n\n$$\n\\int_{0}^{T}S_1(t)S_2(t)\\mathrm dt = 0\n$$\n\n设相邻子载波的频率间隔为 $1 / T$，$T$ 为 OFDM 符号的持续时间，则\n任意一对子载波的内积满足\n\n$$\n\\frac{1}{T}\\int_{0}^{T}e^{j2\\pi \\frac{k_1}{T}t}e^{-j2\\pi \\frac{k_2}{T}t}\\mathrm dt = \\begin{cases}\n    1, k_1 = k_2\\\\\n    0, k_1 \\ne k_2\n\\end{cases}\n$$\n\n带宽 $W$ 和 $B$ 的区别：\n\n物理带宽 $W$\n\n信号带宽 $B$：半功率带宽(3dB)，等效噪声带宽，谱零点带宽，功率比例带宽，最低功率谱带宽\n\n#### 带通信号的表示方法\n\n$$\nx(t) = A(t) \\cos [\\omega_c t + \\varphi (t)]\\\\\n$$\n\n同相分量：$x_I(t) = A(t) \\cos(\\varphi(t))$\n\n正交分量：$x_Q(t) = A(t) \\sin(\\varphi(t))$\n\n与幅度相位的关系：\n\n$$\nA(t) = \\sqrt{x_I^2(t) + x_Q^2(t)}\\\\\n\\varphi(t) = \\tan^{-1} \\left [ \\frac{x_Q(t)}{x_I(t)} \\right]\n$$\n\n带通信号的基带表示的方法\n\n$$\nx_{bb}(t) = x_I(t) + jx_Q(t)\\\\\n$$\n\n解析信号表示\n\n$$\nx_A(t) = x_{bb}(t)e^{j\\omega_ct}\\\\\nx(t) = \\real \\lbrace {x_A(t)} \\rbrace = \\real \\lbrace x_{bb}(t)e^{j\\omega_ct} \\rbrace\n$$\n\n原始带通信号是解析信号的实部\n\n从带通信号恢复基带信号？\n\n$$\n\\breve{x}(t) = x(t) \\circledast h(t)\\\\\nh(t) = \\frac{1}{\\pi t}\\\\\n\\breve{x}(t) = \\frac{1}{\\pi} \\int_{-\\infty}^{\\infty}\\frac{s(\\tau)}{t - \\tau}\\mathrm d\\tau\\\\\nH(f) = -j \\cdot \\text{sgn}(f) = \\begin{cases}\n    -j, &f\\gt 0\\\\\n    0, &f=0\\\\\n    j, &f < 0\n\\end{cases}\n$$\n\n构造解析信号\n\n$$\nx_A(t) = x(t) + j\\breve{x}(t)\\\\\n$$\n\n频谱分析\n\n$$\nX_A(\\omega) = [1 + \\text{sgn}(\\omega)]X(\\omega) = \\begin{cases}\n    2X(\\omega), &\\omega \\gt 0\\\\\n    X(0) = 0, &\\omega = 0\\\\\n    0, &\\omega \\lt 0\n\\end{cases}\\\\\nX_{bb} = X_A(\\omega + \\omega_c)\n$$\n\n带通信道\n\n具有实数值的信道冲激响应（CIR） $h(t)$\n\n等效的解析冲激响应 $h_A(t) = h(t) + j\\breve{h}(t)$\n\n任意载波频率 $\\omega_c$ 的等效基带冲激响应CIR\n\n$$\nh_{bb}(t) = h_A(t) \\cdot e^{-j\\omega_c t}\n$$\n\n带通收发信号关系 $y(t) = x(t) * h(t)$，则\n\n$$\nY(\\omega) = H(\\omega) X(\\omega)\\\\\nY_A(\\omega) = H_A(\\omega)X_A(\\omega)\\\\\nY_A(\\omega) = [H(\\omega) \\cdot \\frac{1}{2}\\left (1 + \\text{sgn}(\\omega)  \\right)]X_A(\\omega) = \\left [ \\frac{1}{2}H_A(\\omega) \\right]X_A(\\omega)\n$$\n\n$H_A(\\omega)$ 只有正半轴部分\n\n$$\nY_{bb}(\\omega) = Y_A(\\omega + \\omega_c) = \\left [ \\frac{1}{2}H_A(\\omega + \\omega_c) \\right]X_A(\\omega + \\omega_c) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$\n\n基带等效系统\n\n$$\ny_{bb}(t) = \\frac{1}{2}h_{bb}(t) * x_{bb}(t)\\\\\nY_{bb}(\\omega) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$\n\n基带时域转移函数 $\\frac{1}{2}h_{bb}(t)$\n\n基带频域转移函数 $H(\\omega + \\omega_c)$\n\n用正交基观点构造了信号波形\n\n$$\nx(t) = \\sqrt{2}\\cos 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^I_kg(t - kT_s) + \\sqrt{2}\\sin 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^Q_kg(t - kT_s)\n$$\n\n投影后的噪声：\n\n$$\nE \\lbrace n_k^In_l^Q \\rbrace = 0\\\\\nE \\lbrace n_k^In_l^I \\rbrace = \\delta_{kl}\\\\\nE \\lbrace n_k^Qn_l^Q \\rbrace = \\delta_{kl}\n$$\n\n等效符号差错模型\n\n$$\ny_k = x_k + n_k\\\\\nn_k \\sim \\mathcal{CN}(0, n_0)\n$$\n\n## 差错控制\n\n差错控制的分类：\n* 检错重发 （ARQ）\n* 前向纠错 （FEC）\n\n前向纠错的分类：\n* 线性码，非线性码\n* 分组码（重点），卷积码\n* 系统码，非系统码\n\n编码增益\n\n给定误比特率的情况下，采用纠错编码后，$E_b/n_0$的减小量称为编码增益。\n\n简单例子：\n\n重复编码\n\nBSC 重传三次：\n\n$$\n3p_e^2(1 - p_e) + p_e^3 \\approx 3p_e^2\n$$\n\n信道编码：通过合理得增加冗余信息，纠正信道传输中可能出现的错误\n* 又称为纠错码（Error Correction Coding）\n\n理想信道编码的局限性：\n* 码长无穷大\n* 没发现代数结构，复杂度太大\n\n如何实用化：\n* 有限长。代价：误码率非零，效率低\n* 有代数结构。优点：便于译码\n\n评价标准\n* 误比特率：评价可靠性\n* 码率：评价有效性\n\n### 分组码\n\n奇偶监督码\n* 检错，而非纠错\n* 电路实现简单\n\n漏检概率：\n\n$$\nP_m =\\sum\\limits_{i=1}^{\\lfloor\\frac{n}{2}\\rfloor}\\binom{n}{2i}\\varepsilon^{2i}(1 - \\varepsilon)^{n - 2i}\n$$\n\n群计数码\n* 累计信息码元中1的个数，以二进制形式放在信息码元后面\n* 检错能力\n  * 强于奇偶校验码\n  * 当{1变0数量=0变1数}时，无法检出\n\n纠错码的直观表示\n\n* 码字\n  * 对应 $n$ 维空间的点\n\nHamming 距离：两个码字之间不同码元的个数\n\n**Hamming 距离**\n\n* $x_m$ 和 $x_m^\\prime$ 中不同取值的位置数 $d_H(\\mathbf x_m, \\mathbf x_m^\\prime)$\n* 即模2和中1的个数\n\n汉明码重\n* 二进制向量 $\\mathbf x_m$ 1的个数 $w(\\mathbf x_m)$\n\n最小距离\n\n一个分组码中任意两个码字的最小汉明距离 $d_{\\text{min}}$\n\n#### (n,k)纠错码\n\n$$\nB = E + A, \\forall A \\in \\chi\\\\\nS = BH^T = EH^T\\\\\n$$\n\n$S$ 与 $A$ 无关，$A$ 只是无用的陪同（coset）。\n\n陪集首：上述陪集的特征由 $S = EH^T$ 标识，我们称 $E$ 为陪集首。\n\n陪集首一般选择集合中 \"1\" 最少的元素，这是为了优先标识错误数量较小的差错，这一类差错发生的概率较大。\n\n码重：\n\n$$\nw(A) =\\sum\\limits_{i=1}^{n}\\mathbf 1 \\lbrace a_i = 1 \\rbrace = d_H(A, 0)\n$$\n\n001 -> 0,0,0,0,0,1 -> 101\n\n010 -> 0,0,0,0,1,0 -> 011\n\n011 -> 0,0,0,1,0,0 -> 110\n\n100 -> 0,0,1,0,0,0 -> 001\n\n101 -> 0,1,0,0,0,0 -> 010\n\n110 -> 1,0,0,0,0,0 -> 100\n\n111 -> 0,1,0,0,0,1 -> 111\n\n#### 交织器\n\n线性码的改进：\n\n- 上述线性码，均适合于纠正零散错误\n- Hamming码对于2个以上的差错就无能为力\n- 若差错总是成对出现，则Hamming码基本没用\n- 在通信系统中，往往存在不可抗拒的突发错误\n\n例如：无线信道的衰落引起的误码\n\n抗突发误码的方法：交织器\n\n基本原理\n- 为了对付突发的信道差错，交织器改变发送码元的时\n间顺序\n- 将原本相邻的码元在时间上的距离最大化\n- 例子：考虑一个（n, k）分组码，其交织后的输出为\n\n\n将突发误码转换成零星误码\n\n交织器的性能：\n\n宽度\n- 就是分组码的码长n\n- 决定于所采用的分组码\n\n深度\n- 深度m决定了相邻码元交织后的间隔\n- m又称交织深度\n- 若分组码能纠b个突发错误，则交织后能纠mb个突发错误\n\n解交织：\n- 从另一个角度来看，解交织打散了突发误码\n- 化整为零后的零散误码，就可以交给解码器对付了\n\n### 卷积码\n\n输入无限长的激励，则输出信号无限长，\n\n若冲激响应有限，则输出只与某一段输入有关\n\n卷积码的参数 $n, k, N$\n\n约束长度，信息码位，每次输出\n\n使用树状图进行分类讨论\n\n树状图的冗余：\n- 树状图具有很多冗余表示\n\n\n树状图的应用：计算最小码距\n- 分组码的最小码距定义为非零码字的最小码重\n- 和分组码不同，卷积码没有分组的概念\n- 约束长度隐含了某种独立性，可以只考虑 $kN$ 的信息比特编码后的非零码字，也就是考虑 $nN$ 个非零的编码输出位\n\n状态图的应用\n- 自由距：无限长信息序列编码后的最小汉明距离\n- 自由距不等于最小距\n\n自由距等于寄存器从零状态开始，经过非零状态，然后回到零状态的输出1的个数的最小值\n\n卷积码的译码\n\n#### 维特比译码\n\n网格图\n\n最大似然下的最优译码\n\n- 低复杂度\n- 采用最小汉明距离作为代价函数\n\n采用动态规划的卷积码译码成为 viterbi 译码\n* viterbi 译码的起始状态是 0 状态\n* viterbi 译码没有确定的代价函数，\n\n分组码译码可以知道是否译码错误了。通过校验矩阵来校验就行了。\n\n但是 viterbi 译码并不能肯定译码结果是否正确。\n\n### 硬判决和软判决\n\n硬判决：任务是检测和矫正误码\n\n软判决：应用于卷积/ Viterbi 译码器，迭代译码  \n\n### 检错重发 ARQ\n\n$P_c = (1 - \\varepsilon)^n$ 为正确概率\n\n$P_d$ 检出错误概率\n\n$P_m$ 漏检概率\n\n$$\nP_c + P_d + P_m = 1\n$$\n\n总分组差错概率\n\n$$\nP_b = P_m + P_dP_m + P_d^2P_m + \\dots = \\frac{P_m}{1 - P_d} = \\frac{P_m}{P_c + P_m}\n$$\n\n#### 停等ARQ\n\n收到上一个 ACK/NAK 再发送下一个包或者重传上一个包\n\n假设发送方一直传输（一次就能传输成功），吞吐量的上限为\n\n$$\n\\eta_{sw, 0} = \\frac{k}{T_DR}\\\\\nT_D = T_m + 2 T_d + T_c + T_a = T_m + T_{dca} = \\frac{k}{n + T_{dca}R}\n$$\n\n若有完美的差错检出能力 $P_d = 1 - (1 - \\varepsilon)^n$\n\n则\n\n$$\n\\eta_{sw} = \\frac{k/n}{1 + T_{dca}R/n}(1 - \\varepsilon)^n\n$$\n\n#### 返回 N-ARQ\n\n不等 ACK/NAK 返回就传下一个包，若检错则重传从错误开始的所有包\n\n$$\n\\eta_{GBN, 0} = \\frac{k}{n}\n$$\n\n","source":"_posts/通网.md","raw":"---\ntitle: 通网\ndate: 2023-09-18 11:14:16\ntags: note\nkatex: true\n---\n\n## 信息论基础\n\n### 离散随机变量的信息度量\n\n$$\nH(X) = \\mathbf E\\{H(X=x_i)\\} = -\\sum_i p_i \\log p_i\n$$\n\n称为熵\n\n单位：\n* 2 (Bit)\n* e (Nat)\n* 10 (Hartely)\n\n表示了信息描述的有效性极限\n\n信源编码（Source Coding），通过信息的有效表示，提高通信的有效性。例如: Huffman 编码\n\n离散随机变量的最大熵：$\\max_{p_i} H(X) = \\log|S|$\n\n前缀码：任何码字都不是其他码字的前缀。前缀码保证了唯一可译码。是二叉树叶子节点。\n\n**Kraft不等式**\n\n对于信源字符集$\\lbrace a_1, \\dots, a_m\\rbrace$，必满足：\n\n$$\n\\sum\\limits_{k=1}^{M}2^{-l(a_k)} \\le 1\n$$\n\n同时，若上式成立，必存在码长分别为$𝑙(𝑎_𝑘)$的前缀码。\n\n\n最小前缀码的平均码长：\n\n$$\n\\min \\bar L =\\sum\\limits_{i=1}^{M}p_il_i\\\\\ns.t.\\sum\\limits_{i=1}^{M} 2^{-l_i} = 1\n$$\n\n由拉格朗日乘子法\n\n$$\np_i = 2^{-l_i}, \\bar L_{min} = -\\sum\\limits_{i=1}^{M}p_i \\log p_i\n$$\n\n记 $H(X) = -\\sum p_i\\log p_i$ .一般的，上下界为$H(X) \\le \\bar L  \\lt H(X) + 1$.\n\n如果我们将$k$个独立同分布的信源符号 $x_1, \\dots, x_k$堪称一个，对整体应用前缀码编码：\n\n$$\n\\begin{align*}\n    H(X_1, \\dots, X_k) &= -\\sum P(x_1, \\dots, x_k) \\log P(x_1, \\dots, x_k)\\\\\n    &= -\\sum P(x_1, \\dots, x_k) [\\log P(x_1) +  \\dots +  \\log(x_k)]\\\\\n    &= -\\sum P(x_1)\\log (x_1) - \\dots - \\sum P(x_k)\\log (x_k)\\\\\n    &= -kH(X)\n\\end{align*}\n$$\n\n直观：对长度为$𝑛$的$M$种信源符号序列，$𝑥_𝑖$出现的次数$≈𝑛𝑝_𝑖$\n\n典型序列应满足上述分布，否则就“小众”“非典型”\n\n典型的个数 # $≈ \\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}$\n\n平均每个信源符号可以用 $L = \\frac{1}{n}\\log\\left(\\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}\\right)$ 个 bit 来表达。\n\n通过 Stirling 公式可以得出 L的上下界。\n\n故\n\n$$\n\\lim\\limits_{n\\rightarrow \\infty}^{} L = H(X)\n$$\n\n**最大熵**\n\n离散型随机变量的最大熵为\n<!-- max -->\n$$\n\\max_{p_i} H(X) = \\log |S|\n$$\n\n可以用梯度法直观感受，当所有分量的概率相等时，熵最大。\n\n**联合熵**\n\n联合概率\n<!-- text -->\n$$\np_{i, j} = \\text{Pr}\\lbrace X = x_i, Y = y_j\\rbrace\n$$\n\n联合熵的定义：\n\n$$\nH(XY) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i, j}\n$$\n\n**条件熵**\n\n条件概率\n<!-- text -->\n$$\np_{i\\mid j} = \\text{Pr}\\lbrace X = x_i \\mid Y = y_j\\rbrace\n$$\n\n条件熵的定义：\n\n$$\nH(X|Y) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i\\mid j}\n$$\n\n通过相关观测进行无损压缩，若观测到 $Y = \\alpha_j$：\n\n$$\n\\bar L(\\alpha_j) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i\\mid j} \\log p_{i\\mid j}\n$$\n\n于是\n\n$$\n\\bar L =-\\sum\\limits_{j=1}^{N} \\bar L(\\alpha_j)p_j = -\\sum\\limits_{j=1}^{N}p_j\\sum\\limits_{i=1}^{M}p_{i|j} \\log(p_{i|j}) = -\\sum\\limits_{i=1}^{M}\\sum\\limits_{j=1}^{N}p_{ij}\\log(p_{i|j}) = H(X|Y)\n$$\n\n**链式法则**\n\n$$\nH(XY) = H(Y) + H(X|Y)\n$$\n\n两个随机变量的联合不确定性＝一个随机变量的不确定性＋知道这个随机变量后另一个随机变量残余的不确定性\n\n**互信息(Mutual Infomation)**\n\n$$\n\\begin{align*}\n    I(X;Y) &= H(X) + H(Y) - H(XY)\\\\\n    &= H(X) - H(X|Y) \\\\\n    &= H(Y) - H(Y|X)\n\\end{align*}\n$$\n\n互信息的物理意义\n\n第一种理解：\n- X的不确定度减去观测Y后X残存的不确定度\n- 即：通过观测Y带来的帮助了解X的信息\n\n第二种理解：\n- Y的不确定度减去观测X后Y残存的不确定度\n- 即：通过观测X带来的帮助了解Y的信息\n\n若$X, Y$相互独立，记为$X\\perp Y$，则$I(X;Y) = 0$，$H(X) = H(X|Y)$，$H(Y) = H(Y|X)$。观测一个随机变量完全无助于了解另一个随机变量。\n\n* $H(XY) = H(X) + H(Y)$，总平均码长等于各自平均码长之和。\n\n若$X = Y$，则$I(X;Y) = H(X) = H(Y)$，$H(X|Y) = H(Y|X) = 0$。观测一个随机变量完全了解另一个随机变量。\n\n$H(XY) = H(Y) + H(X|Y) = H(Y)$，只需要编码其中一个即可。\n\n$$\nX \\perp Y \\leftrightarrow H(X + Y | X) = H(Y | X) = H(Y), H(X + Y, X) = H(Y , X)\n$$\n\n\n$$\nH(X + X | X) = H(X | X) = 0, H(X + X, X) = H(X , X) = H(X)\n$$\n\n**信息传输的基本模型**\n* 信息通道，简称信道（Channel）对于输入符号有随机扰动，本质上可用一组条件概率表示\n* 限于物理条件，信宿只能观测信道输出 $Y$，由此了解其输入 $X$\n* 通过观测Y可以获得的关于X的信息量是 $I(X;Y)$\n\n**信息传输的优化**\n\n目标：最大化发送端 $X$ 和接收方 $Y$ 的互信息\n\n方法：\n* 信道是由物理实现所决定的，无法控制\n* 但是可以选择X的概率分布\n\n因此有如下优化问题：\n\n$$\np*_i = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} I(X;Y)\n$$\n\n定义信道容量 $C = \\max_{\\sum_i p_i = 1, p_i \\ge 0} I(X;Y)$\n\n信道容量的物理意义\n- 平均每个信道符号所能传的最大的信息量\n- 或：单位时间内信道所传最大的信息量\n\n优化问题的表达式\n\n$$\np_i^* = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} - \\sum_i\\sum_j p_i p_{j|i} \\log \\frac{\\sum\\limits_i p_i p_{j|i}}{p_{j|i}}\n$$\n\n信道容量不易计算\n\n**对称二进制信道(BSC)**\n\n- 一种典型信道模型\n- 分析信道编码时有很多应用\n\n利用互信息表达式\n\n$$\n\\begin{align*}\n    I(X;Y) &= H(Y) - H(Y | X)\\\\\n    &= H(Y) - \\sum_i p_i \\left[-\\sum_j p_{j|i} \\log p_{j|i}\\right]\\\\\n    &= H(Y) - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)]\\\\\n    &\\le 1 - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)] = C\\\\\n\\end{align*}\\\\\nY \\sim \\begin{bmatrix}\n    0 & 1\\\\\n    1/2 & 1/2\n\\end{bmatrix}\n$$\n\n如果误码率 $\\varepsilon = 0.5$，则信道容量为0, 传递不了信息。\n\n如果误码率 $\\varepsilon > 0.5$，继续增大差错率，反而可以提高信道容量。\n\n**高斯信道**\n<!-- **gauss** -->\n$$\nY = X + N\\\\\nf_N(n) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(-\\frac{(y - x)^2}{2\\sigma^2}\\right)\n$$\n\n![alt](../images/通网/1_1.jpg)\n\n![alt](../images/通网/1_.jpg)\n\nShannon 公式\n\n$$\nC = W\\log(1 + \\frac{P}{Wn_0})\n$$\n\n### 连续性随机变量的熵\n\n$$\nH(X) = - \\int\\limits_{-\\infty}^{\\infty}p(x)\\log p(x) \\mathrm dx + \\lim_{\\Delta \\rightarrow 0} \\log \\frac{1}{\\Delta}\n$$\n\n我们只关心相对不确定性，定义微分熵\n\n$$\nh(X) = -\\int\\limits_{-\\infty}^{\\infty}p(x) \\log p(x)\\mathrm dx\n$$\n\n微分熵是对连续型变量相对不确定性的一种描述\n- 其定义剔除了连续性或“精准要求”带来的困难，保\n留了分布函数形状自身的特征\n- 它说明用有限字符集合的字符串描述连续分布的随机\n变量，则平均字符长度为无穷大\n- 为了用有限长字符串描述信源，需要进行有损压缩，\n从而带来失真，即原始信源和压缩结果之间的差异\n- 失真测度包括：均方误差，绝对值误差，主观误差等\n- 对于图像，视频和语音等连续信源的编码等均属于有\n损压缩\n\n### 多元随机变量的熵\n\n联合熵：\n\n$$\nh(XY) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(x, y)\\mathrm dx \\mathrm{d}y\n$$\n\n条件熵：\n$$\nh(Y|X) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(y|x)\\mathrm dx \\mathrm{d}y\n$$\n\n互信息：\n\n$$\n\\begin{align*}\n    I(X;Y) &= h(X) + h(Y) - h(XY)\\\\\n    &= h(X) - h(X|Y) \\\\\n    &= h(Y) - h(Y|X)\n\\end{align*}\n$$\n\n## 压缩编码\n\n### 压缩编码的分类\n\n* 无损压缩\n    * 输入：数字序列\n    * 输出：数字序列\n    * 目的：使得平均长度更小\n* 有损压缩\n    * 输入：模拟信号\n    * 输出：数字序列\n    * 目的：实现数字传输\n\n信号压缩编码的步骤：\n\n* 抽样\n* 量化\n* 压缩编码\n\n### 抽样\n\n**连续时间信源的离散化**\n\n![](../images/通网/2_1.jpg)\n\n离散化的方式：在标准正交基上投影展开\n\n$$\ns(t) = \\sum_k a_k\\phi_k(t)\\\\\na_k = <s(t), \\phi_k(t)>\n$$\n\n若 $s(t)$ 是时限信号（宽度 $T$），可以用傅里叶展开的系数作为离散化结果：$s(t) = \\sum\\limits_k a_k e^{2\\pi jkt/T}$\n\n若 $s(t)$ 是带限信号（带宽 $W$），可以在频域对 $\\hat S(f)$ 做傅里叶展开：\n\n$$\n\\hat S(f) = \\sum\\limits_k \\alpha_k e^{2\\pi jkf/(2W)}\n$$\n\n变换回时域时，得到 Nyquist 抽样定理：\n\n$$\ns(t) =\\sum\\limits_{k}^{}s(kT) \\text{sinc}\\left(\\left(\\frac{t}{T} - k\\right)\\right), T = \\frac{1}{2W}\n$$\n\n频域无混叠等价于时域无畸变\n\n对于带通采样，有无混叠条件：\n\n![](../images/通网/2_2.jpg)\n\n可以推导得出：\n\n$$\nf_s = 2B\\left(1 + \\frac{M}{N}\\right)\\\\\nN = \\left\\lfloor\\frac{f_H}{B}\\right\\rfloor\\\\\nM = \\left\\lbrace\\frac{f_H}{B}\\right\\rbrace\\\\\nB = f_H - f_L\n$$\n\n![](../images/通网/2_3.jpg)\n\n横轴为 $f_H/B$，纵轴为 $f_s$\n\n**量化**\n\n分层电平： $\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$ \n\n重建/输出电平：$y_k$代表一个量化区间，用以重构信号时使用的电平值\n\n量化函数： $y = Q(x)$, $y_k = Q\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$\n\n量化间隔： $\\Delta_k = x_{k + 1} - x_{k}$\n\n均匀量化 & 非均匀量化\n\n均匀量化只对有界随机变量存在\n\n### 量化\n\n* 在此只讨论标量的量化\n* 量化噪声： $q = x - y = x - Q(x)$ \n* 量化噪声是一个随机变量\n* 方差 $\\sigma_q^2 = \\int_{-\\infty}^{\\infty}[x - Q(x)]^2p_x(x)\\mathrm dx$\n* 方差与输入信号分布有关，不存在普适的最佳量化方案\n\n#### 量化噪声的计算\n\n$$\n\\sigma_q^2 =\\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx\n$$\n\n从较容易的情况着手\n- 只考虑电平区间 $[-V,V]$ 之间的信号，并假设量化间隔很小，亦即分层电平很密\n- 在实际情况中，信号的分布函数处处可导，此时每个量化区间内信号的条件分布为均匀分布\n\n量化区间内，近似概率密度 $p_x(x) = \\frac{P_k}{\\Delta_k}$\n\n密集分层的量化噪声近似\n\n$$\n\\sigma_{qn}^2 = \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx = \\sum\\limits_{k=1}^{L}\\frac{P_k}{\\Delta_k}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2\\mathrm dx = \\frac{1}{12}\\sum_{k = 1}^L P_k\\Delta_k^2 = \\frac{1}{12} \\int_{-V}^{V}(\\Delta_k)^2p_x(x)\\mathrm dx\n$$\n\n若 $\\Delta_k = \\Delta$，\n\n$$\n\\sigma_{qn}^2 = \\frac{1}{12}\\sum_k P_k\\Delta_k^2 = \\frac{\\Delta_k^2}{12}\n$$\n\n计算量化结果做无损压缩后的比特数：\n\n$$\nH(Q(x)) = -\\sum_k P_k \\log P_k = \\underbrace{- \\int_{-\\infty}^{\\infty}p_x(x)\\log p_x(x) \\mathrm dx }_{h(X)} + \\log \\frac{1}{\\Delta}\n$$\n\n由 $\\Delta = \\sqrt{12\\sigma_{qn}^2} = 2\\sigma_{qn}\\sqrt{3}$，\n\n$$\nH(x) = h(x) + \\log \\frac{1}{2\\sigma_{qn}\\sqrt{3}}\n$$\n\n无损压缩的 bit 数为： $\\tilde{R} = h(X) - \\frac{1}{2}\\log \\sigma_{qn}^2 - 1.8$\n\n对于均匀量化：\n\n$$\n\\Delta_k = \\frac{x_{max} - x_{min}}{L} = \\frac{2x_{max}}{L}, \\forall k\n$$\n\n于是\n\n$$\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12} = \\frac{x_{max}^2}{3L^2}\n$$\n\n这里的 $\\sigma_{qn}^2$ 是正常量化噪声，仅仅是计算了信号落在 $[-x_{max}, x_{max}]$ 内的情况\n\n如果信号落在 $[-x_{max}, x_{max}]$ 以外，就就近判断至两端的量化区间，产生过载噪声\n\n$$\n\\sigma_{qo}^2 = \\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx + \\int^{-x_{max}}_{-\\infty}(x + x_{max})^2p_x(x)\\mathrm dx = 2\\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx\n$$\n\n总噪声等于正常量化噪声加上过载噪声：\n\n$$\n\\sigma_{qs}^2 = \\sigma_{qn}^2 + \\sigma_{qo}^2\n$$\n\n如果用 $R$ bit 编码：\n\n$$\n\\Delta_k = \\frac{2x_{max}}{L} = \\frac{x_{max}}{2^{R - 1}}\\\\\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx = \\frac{x_{max}^2}{3 \\times 2^{2R}}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx\n$$\n\n定义非过载信号功率：\n\n$$\n\\sigma_s^2 = \\int_{-x_{max}}^{x_{max}}x^2p_x(x)\\mathrm dx\n$$\n\n当 $\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx \\rightarrow 1$， $SNR_q \\approx \\frac{\\sigma_s^2}{x_{max}^2/(3 \\times 2^{2R})} = 3 \\times 2^{2R} \\times \\zeta^2$，这里定义 $\\zeta = \\frac{\\sigma_s}{x_{max}}$ 为量化范围内信号的饱满程度。\n\n对数单位下：\n\n$$\nSNR_q(dB) = 6.02R + 20\\log_{10}(\\zeta) + 4.77\n$$\n\n* 多一个 bit，$SNR_q$ 提升 $6.02dB$\n* $\\zeta$ 要在合理范围，$\\zeta$ 过大时过载会严重劣化性能\n\n#### 最优量化\n\n目标：给定量化区间总数，最小化量化噪声\n\n优化问题：\n\n$$\n\\min \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2 p_x(x)\\mathrm dx\\\\\ns.t. x_1\\le y_1 \\le x_2 \\le y_2 \\le \\dots \\le y_L \\le x_{L + 1}\n$$\n\n分层电平在重建电平的中点：\n\n$$\n\\frac{\\partial \\sigma_q^2}{\\partial x_k} = 0\\\\\n\\Rightarrow x_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$\n\n重建电平在量化区间的质心：\n\n$$\n\\frac{\\partial \\sigma_q^2}{\\partial y_k} = 0\\\\\n\\Rightarrow y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx}\n$$\n\n对于均匀分布，质心即中点（对于可导的概率分布，当分层很密的时候同样成立）\n\n$$\n y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx} = \\frac{1}{2}(x_{k, opt} + x_{k + 1, opt})\n$$\n\n结合\n\n$$\nx_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$\n\n可得均匀分布的最佳量化是区间等分，中点重建\n\n#### 工程用量化\n\n![](../images/通网/2_4.jpg)\n\n#### 语音信号的量化\n\n$[-V, V]$ 内均匀量化的缺陷：\n* 最适合 $[-V, V]$ 之间的有限分布\n* 语音信号呈拉普拉斯分布，特点是：\n    * 信号功率小\n    * 动态范围大（长拖尾）\n* 如果采用均匀量化\n    * 较大的V：增大[-V，V]内的量化噪声\n    * 较小的V：增大过载噪声\n\n解决思路1：非均匀量化\n\n**语音信号的非均匀量化**\n\n均匀量化的问题\n- 对具有不同“概率权重”的区间“一视同仁”\n- 没有考虑概率密度对于量化噪声的影响\n\n解决方案\n- 对于信号经常出现的区域，使用较细的颗粒度进行量化\n    - 信号经常落入这个区域，减小该区域的量化噪声损失\n- 对于信号不经常出现的区域，使用较粗的颗粒度进行量化\n    - 信号不经常落入这个区域，量化噪声稍大不会影响大局\n\n采用取对数后均匀量化的方法：\n\n![](../images/通网/2_5.jpg)\n\n语音信号的瞬时压扩：\n\n![](../images/通网/2_6.jpg)\n\n**对数量化**\n\n* 正常量化信噪比与信号的分布无关\n* 过载导致的噪声与信号的分布有关！\n\n记 $\\Delta_k$为对数化之前的量化区间, $\\Delta_k^\\prime = \\Delta$ 为对数化之后的量化区间\n\n![](../images/通网/2_9.jpg)\n\n\n**实用的对数量化**\n\n实际工程中，采用另外两个函数（线性放缩，更容易实现）：\n\n* A律（欧洲提出，我国采用）\n\n$$\nf(x) = \\begin{cases}\n    \\frac{Ax}{1 + \\ln A}, 0 \\le x \\le \\frac{1}{A}\\\\\n    \\frac{1 + \\ln Ax}{1 + \\ln A}, \\frac{1}{A} \\le x \\le 1\\\\\n\\end{cases}\n$$\n\n* ITU G.712建议中取A＝87.6\n* 小信号时，信噪比增加了24dB\n\n* μ律（美国提出）\n\n$$\nf(x) = \\frac{\\ln (1 + \\mu x)}{\\ln (1 + \\mu)}, 0 \\le x \\le 1\n$$\n\n\n* ITU G.712建议中取μ＝255\n* 小信号时，信噪比增加了33.5dB\n\n**脉冲编码调制(PCM)**\n\n- 语音信号的实际压缩编码方式\n- 包括两个主要步骤\n- 抽样：$f_s = 8000Hz$\n- 量化与编码：使用近似对数压扩，每个抽样量化为8位\n- PCM的输出码率为64kbps\n\n**该码率与其推导过程十分重要**\n\n\n**PCM编码协议**\n\n基本思想\n- 用13折线近似A律\n- 用15折线近似μ律\n\n![](../images/通网/2_7.jpg)\n\n码字结构：\n\n$$\n\\mathop{M_1}\\limits_{极性码} \\quad \\underbrace{M_2 \\quad M_3 \\quad M_4}_{段落码}\\quad \\underbrace{M_5 \\quad M_6\\quad M_7 \\quad M_8}_{电平码} \\quad \n$$\n\n![](../images/通网/2_8.jpg)\n\n例：\n\n1250的输出：1 110 0011\n\n接收端解码： 1024 + 128 + 64 + 32 = 1248\n\n## 数字基带传输\n\n### 符号映射\n\n**符号集合**\n\n$M = |\\mathcal{A}|$ 为符号集合 $\\mathcal{A}$ 的符号数量。\n\n**bit 承载量**\n每个符号最多可对应 $r = \\log_2|\\mathcal{A}|$ 个 bit，称为集合的 bit 承载量\n\n\n数字通信的典型符号：\n\n* ASK\n* PAM\n* PSK\n* QAM\n\n![](../images/通网/3_1.jpg)\n\n**邻位最小差错映射：Grey 码**\n\n相邻符号对应的 bit 串仅有一位差异\n\n**符号周期（Symbol Period）**\n\n* 传输一个符号所需的平均时间\n* $T_s$\n\n通信速率：\n* 符号速率：$R_s = \\frac{1}{T_s}$\n* Bit 速率： $R_b = R_s \\log_2 M = \\frac{1}{T_s}\\log_2 M$\n\n### 数字调制\n\n基带调制：将时间上离散的符号，加载到时间上形成连续的波形\n\n通信信号具有带宽受限特性，因为：\n\n- 自然原因：各类通信线路，如双绞线，同轴电缆，射频功放等均对通过的频率有一定限制\n- 人为原因：多用户频谱共享通信，如蜂窝无线系统，需约束每路信号的带宽，以免相互干扰\n\n如何产生带限信号？\n\n产生一个信号 $s(t) =\\sum\\limits_{k=-\\infty}^{\\infty}a_kg(t- k T_s)$，$g(t) = \\frac{\\sin 2\\pi Wt}{2\\pi Wt}$是个带限信号。\n\n$$\nG(f) = \\begin{cases}\n    1, |f| \\le W,\\\\\n    0, |f| \\gt W\n\\end{cases}\n$$\n\n让间隔 $T_s$ 的冲击 $a_k\\delta(t - kT_s)$ 依次通过冲击响应为 $g(t)$ 的低通滤波器\n\n![](../images/通网/3_2.jpg)\n\n### Nyquist 准则：无ISI条件\n\n**符号间串扰（Inter Symbol Interference, ISI）**\n\n对 $s(t)$ 采样：\n\n$$\ns(nT_s) = a_ng(0) + \\underbrace{\\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big)}_{\\text{ISI}}\n$$\n\n怎么让 ISI 为0？\n\n**眼图：观察符号间串扰**\n\n眼图（Eye Pattern）是直观察看数字基带传输性能的有效方法，用一个示波器\n\n$$\n垂直输入 \\xrightarrow{接} 匹配滤波器的输出\\\\\n水平扫描速度 \\xrightarrow{设为} 𝑅_𝑠的整数倍\n$$\n\n![alt](../images/通网/3_3.jpg)\n\n眼皮的厚度表示 ISI 的失真，眼睛的张开程度表示噪声容限。\n\n![alt](../images/通网/3_4.jpg)\n\n消除 ISI 对带限脉冲的要求\n\n时域特征：\n\n$$\n\\left.\\begin{align*}\n    g(0) &= 1\\\\\n    \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big) &= 0\n\\end{align*}\\right\\rbrace \\Leftrightarrow \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_{n - k}g\\big(kT_s\\big) = 0\\\\\n\\Leftrightarrow g(kT_s) = \\begin{cases}\n    1, k = 0,\\\\\n    0, k \\ne 0\n\\end{cases} \\\\\n\\lrArr g(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t)\n$$\n\n从频域提取特征：\n\n$$\ng(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t) \\lrArr G(f) *\\sum\\limits_{n=-\\infty}^{\\infty}\\frac{1}{T_s}\\delta(f + \\frac{n}{T_s}) = 1\\\\\n\\lrArr \\sum\\limits_{n=-\\infty}^{\\infty}G\\left(f + \\frac{n}{T_s}\\right) = T_s\n$$\n\n**Nyquist 准则**\n\n将带限脉冲的频谱分别平移 $n/T_s$（ $n$ 为任意整数）若其叠加的结果对任意频率恒为定值，则 ISI 为0\n\n### 通信速率与带宽效率\n\n**理解 Nyquist 准则**\n\n![alt](../images/通网/3_5.jpg)\n\n![alt](../images/通网/3_6.jpg)\n\n* 最大符号速率受制于带宽 $R_s = \\frac{1}{T_s} \\le 2W$\n* 低通发送滤波器应该满足残留对称条件\n\n**通信速率与带宽效率**\n\n$$\nR_s \\le 2W\\\\\nR_b = R_s \\log_2 M\\\\\n\\Rightarrow R_b \\le 2W \\log_2 M\n$$\n\n* 针对给定形式的低通滤波器，可写出$R_s$与$W$之间的线性函数关系\n\n**信号功率与带宽效率**\n\n设单个符号的能量为 $E_s$\n\n则信号功率为单位时间内的能量\n$$\nP = \\frac{E_s}{T_s} = E_sR_s\n$$\n\n无冗余编码时，一个比特的能量为$𝐸_𝑏$，则\n\n$$\nP = \\frac{E_b\\log_2 M}{T_s} = E_bR_b\n$$\n\n带宽效率的定义：单位带宽承载的速率\n\n$$\n\\eta = \\frac{R_b}{W} \\le 2\\log_2 M\n$$\n\n\n* 为什么不能无限制扩大符号集合？\n\n过大的符号集合对信噪比有更高的要求，噪声容易干扰符号的分辨\n\n### 升余弦滤波器\n\n**升余弦滤波器**\n\n由于理想滤波器难以实现，所以常用满足残留对称条件的非理想低通生成基带脉冲，最常用的就是升余弦滤波器\n\nRaised Cosine(要记住)\n\n$$\nH(f) = \\begin{cases}\n    T_s, &0 \\le |f| \\lt \\frac{1 - \\alpha}{2 T_s}\\\\\n    \\frac{T_s}{2}\\left\\lbrace1 + \\cos \\left[\\frac{\\pi T_s}{\\alpha}\\left(|f| - \\frac{1 - \\alpha}{2T_s}\\right)\\right]\\right\\rbrace, &\\frac{1 - \\alpha}{2 T_s} \\le |f| \\le \\frac{1 + \\alpha}{2 T_s}\\\\\n    0, & |f| \\gt \\frac{1 + \\alpha}{2 T_s}\n\\end{cases}\n$$\n\n$\\alpha = 2WT_s - 1 \\in [0, 1]$ 称为滚降系数，越小坡越陡，越大坡越缓。\n\n时域冲激响应：\n\n$$\nh(t) = \\text{Sa}(\\pi t/ T_s)\\frac{\\cos (\\alpha\\pi t/ T_s)}{1 - 4(\\alpha t/T_s)^2}\n$$\n\n升余弦滤波器的性质：\n\n\n<font color=\"red\">常考性质：</font>\n\n$$\nW = \\frac{\\alpha + 1}{2T_s} = \\frac{\\alpha + 1}{2}R_s \\Rightarrow R_s/2 \\le W \\le R_s\\\\\nR_s = \\frac{1}{T_s} = \\frac{2}{\\alpha + 1} W \\Rightarrow W \\le R_s \\le 2W\n$$\n\n带宽效率\n\n$$\n\\eta_b = \\frac{R_s\\log_2|\\mathcal{S}|}{W} \\le 2\\log_2|\\mathcal S|\n$$\n\n升余弦滤波器的带宽效率\n\n$$\n\\eta_b = \\frac{2\\log_2|\\mathcal{S}|}{\\alpha + 1}\n$$\n\nPCM 语言信号速率 64kbps：8 bit 采样，8 bit 量化，8*8 = 64.\n\n例题一：传送一路PCM语音信号\n- 若带宽限制为40kHz，采用二元码，则可用滚降系数范围\n是多少？\n- 若采用四元码，最多需要多少带宽？\n\n解：PCM语音信号是64kbps\n- 采用二元码，则所需符号速率为 $R_s = R_b = 64kbps$\n* 则 $\\frac{\\alpha + 1}{2}64 \\le 40$, $0\\le \\alpha \\le 0.25$\n\n* 采用四元码：$R_s = \\frac{R_b}{\\log_24} = 32kbps$\n* $W \\le R_s = 32kHz$\n\n例题二：若传送一路信号$𝑅_𝑏$ = 112kbps，信道带宽𝑊 = 30𝑘bps,\n求𝑀和𝛼\n\n$$\n\\frac{\\log_2M}{\\alpha} = \\frac{R_b}{2W} = \\frac{28}{15} \\in [1.5, 2]\\\\\n$$\n\n认定 $\\log_2M = k$ 为整数，则$k = 2 或 3$。对应可解：\n\n$$\n\\alpha_1 = \\frac{1}{14}, M_1 = 4\\\\\n\\alpha_2 = \\frac{17}{28}, M_2 = 8\n$$\n\n### 通信信号的功率谱计算\n\n功率谱刻画了随机过程的功率在频域上的分布。\n* 对于宽平稳过程（自相关只与时差有关），功率谱易于从 $R(\\tau)$ 的傅里叶变换得到，即$S(f) = \\mathcal{F}[R(\\tau)]$\n* 但是，通信信号一般不是宽平稳过程，而是周期平稳过程：$R(t_1, t_2) = R(t_1 + kT_s, t_2 + kT_s)$ \n\n定义 \n\n$$\n\\overline{R}(\\tau) = \\frac{1}{T_s} \\int_{0}^{T_s}R(t+\\tau, t)\\mathrm dt\n$$\n\n则其功率谱\n\n$$\nS(f) = \\mathcal{F}[\\overline{R}(\\tau)]\n$$\n\n若输入信号的功率谱 $S_{AI}(f)$，输出为$S_A(f)$，则对于宽平稳和周期平稳信号均有卷积关系：\n\n$$\nS_A(f) = S_{AI}(f)|H(f)|^2\n$$\n\n证明可以采用样本统计法：假设符号序列的长度为 $2N - 1$.\n\n$$\ns_{AI}(t) =\\sum\\limits_{k=-N}^{N}a_k\\delta(t - k T_s)\\\\\ns_{A}(t) =\\sum\\limits_{k=-N}^{N}a_kh(t - k T_s)\\\\\n\\hat s_{AI}(f) =\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\\\\\n\\hat s_{A}(f) = H(f)\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\n$$\n\n功率谱的定义：\n\n$$\nS(f) = \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat s(f)|^2)}{(2N + 1)T_s}\n$$\n\n可以验证 $S_A(f) = S_{AI}(f)|H(f)|^2$\n\n针对样本统计法，可以算出 $E(|\\cdot|^2)$的表达式：\n\n$$\nS_A(f) = \\frac{|H(f)|^2}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f)\n$$\n\n这里$R_a[m]$ 是输入符号的自相关。\n\n先考虑无记忆调制，符号之间相互独立：\n\n$$\nR_a[n] = E[a_ia_{i+n}] = \\begin{cases}\n    \\sigma_a^2+m_a^2 &n=0\\\\\n    m_a^2 &n\\ne 0\n\\end{cases}\n$$\n\n其中，$m_a = E[a_n]$，$\\sigma_a^2 = E[a_n^2] - m_a^2$\n\n于是，重写累加部分：\n\n$$\n\\begin{align*}\n    &\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f) \\\\\n    =& \\sigma_a^2 + m_a^2\\sum\\limits_{n=-\\infty}^{\\infty}\\exp\\big[-jn(2\\pi T_s)f\\big]\\\\\n    =& \\sigma_a^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\delta\\bigg(f - \\frac{n}{T_s}\\bigg)\n\\end{align*}\n$$\n\n从而\n\n$$\nS_A(f) = \\underbrace{\\frac{\\sigma_a^2}{T_s}|H(f)|^2}_{连续谱} + \\underbrace{\\frac{m_a^2}{T_s^2}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|H\\bigg(\\frac{n}{T_s}\\bigg)\\bigg|^2 \\delta\\bigg(f - \\frac{n}{T_s}\\bigg)}_{线谱}\n$$\n\n此式应用的两个条件：\n* 无记忆\n* 不同符号波形一致\n\n线谱：可用于定时恢复。方便恢复时钟分量。\n\n\n**任意波形调制**\n\n之前将 $a_i$ 映射为 $a_ih(t)$，可以推广：\n\n$$\n\\forall a_i \\ne a_j, s_i(t) \\ne s_j(t)\n$$\n\n有时候由于信号功率需要保持稳定（恒包络调制），对不同符号采用不同波形，而不是采用变化幅度的信号。\n\n若任意波形二元调制信号 $s(t) =\\sum\\limits_{k=-\\infty}^{\\infty}g_k(t)$\n\n$$\ng_k(t) = \\begin{cases}\n    s_1(t - kT_s), w.p.\\ p\\\\\n    s_2(t - kT_s), w.p.\\ \\bar p = 1 - p\n\\end{cases}\n$$\n\n(w. p. = with probability)\n\n分解为直流分量和交流分量：\n\n$$\ns(t) = \\underbrace{E(s(t))}_{DC,记为v(t)} + \\underbrace{s(t) - E(s(t))}_{AC, 记q(t)}\n$$\n\n则\n\n$$\nv(t) = \\sum\\limits_{k=-\\infty}^{\\infty}[ps_1(t - kT_s) + \\bar p s_2(t - kT_s)]\n$$\n\n这是一个周期为$𝑇_𝑠$的确定性周期信号，功率谱由傅里叶展开计算\n\n$$\nS_v(f) =\\sum\\limits_{n=-\\infty}^{\\infty}|D_n|^2\\delta(f - \\frac{n}{T_s})\\\\\nD_n = \\frac{1}{T_s}\\int_{-T_s/2}^{T_s/2}v(t)e^{-j2\\pi t/T_s}\\mathrm dt = \\frac{1}{T_s}\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\n$$\n\n$$\nS_v(f) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$\n\n用样本统计法计算 $S_q(f)$：\n\n$$\n\\begin{align*}\n    S_q(f) =& \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat q_N(f)|^2)}{(2N + 1)T_s}\\\\\n    =& \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2\n\\end{align*}\n$$\n\n$$\nS(f) = \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$\n\n### 基带解调\n\n最佳接收用于在给定发送功率下提高信噪比\n\n最佳判决用于在给定信噪比下降低误码率\n\n#### 基带传输的噪声模型\n\n![alt](../images/通网/4_1.jpg)\n\n如何选择解调方案？\n\n**方案一：直接抽样**\n\n在信号的峰值位置 $t = kT_s$ 抽样最好。\n\n但噪声方差满足：\n\n$$\n\\sigma^2 = E \\lbrace n^2(t_1) \\rbrace = R(0) = \\frac{n_0}{2}\\delta(0) \\rightarrow \\infty\n$$\n\n（理想的白噪声信号具有无穷大功率）\n\n真实的噪声环境下，接收信号质量随着噪声信号功率的增加而变差。如果信号的峰值处恰好噪声很大，则产生严重失真。\n\n**方案二：能量累积**\n\n![alt](../images/通网/4_2.jpg)\n\n噪声信号仍为高斯随机变量：\n\n$$\nn = \\int_{0}^{T_s}n(t)\\mathrm dt\n$$\n\n噪声方差：\n\n$$\n\\sigma^2 = E\\lbrace n^2 \\rbrace = \\int_{0}^{T_s}\\int_{0}^{T_s}\\frac{n_0}{2}\\delta(t_1 - t_2)\\mathrm dt_1\\mathrm dt_2 = \\frac{n_0T_s}{2}\n$$\n\n信噪比：\n\n$$\n\\frac{S}{N} = \\frac{\\left (\\int_{0}^{T_s}a_i h(t)\\mathrm dt \\right)^2}{T_sn_0/2}\n$$\n\n直接积分不是最好的方案。\n\n**方案三：匹配滤波**\n\n匹配滤波的基本思想就是对接收值进行加权线性累加，从而最大化抽样时刻信号功率与噪声功率的比值。\n\n![alt](../images/通网/4_3.jpg)\n\n相关器为 $g(t)$。假设信号为实信号。复信号有类似结论。\n\n$$\nP_S = \\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2\\\\\nP_N = \\mathbf E \\left [ \\left | \\int_{0}^{T_s}n(t)g(t)\\mathrm dt \\right|^2 \\right] = \\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt\n$$\n\n利用 Cauchy-Schwartz 不等式：\n\n$$\n\\frac{\\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2}{\\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt} \\le \\frac{2}{n_0}\\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt\n$$\n\n等号成立当且仅当 $g(t) = kh(t)$。\n\n若为复信号，则需要\n\n$$\ng(t) = h^*(t)\n$$\n\n如何把相关器写成滤波器形式？\n\n（滤波=卷积，相关和卷积就是差一个反褶的关系）\n\n$$\ny(t) = [a_ih(t) + n(t)] * h_m(t) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(t - \\tau)\\mathrm d\\tau\n$$\n\n考虑因果系统，一般将符号波形的最高点设置为 $t = T_s$：\n\n$$\ny(T_s) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(T_s - \\tau)\\mathrm d\\tau\n$$\n\n与相关器比较得到匹配滤波器的表达式：\n\n$$\nh_m(t) = h(T_s - t)\n$$\n\n![alt](../images/通网/4_4.jpg)\n\n图中的“开关”是抽样。\n\n匹配滤波的频域解释：\n\n$$\nP_S = \\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2\\\\\nP_N = \\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df\\\\\n\\frac{S}{N} = \\frac{\\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2}{\\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df} = \\frac{2}{n_0}\\int_{-\\infty}^{\\infty}|H(f)|^2\\mathrm df\n$$\n\nCauchy-Schwartz\n\n$$\nH_m(f) = H^*(f)e^{-j2\\pi fT_s}\n$$\n\n**匹配滤波的增益**\n\n数字传输的优势：数字传输中，基带脉冲h(t)是给定的，在整个码元周期内可以相干累加，而同时让噪声在整个周期内自我抵消\n\n$$\n\\left (\\frac{S}{N}  \\right)_{\\text{match}} \\bigg/ \\left (\\frac{S}{N}  \\right)_{\\text{w.o.match}} = \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\left ( \\int_{0}^{T_s}h(t)\\mathrm dt \\right)^2} \\ge \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\int_{0}^{T_s}1\\mathrm dt\\int_{0}^{T_s}h^2(t)\\mathrm dt} = 1\n$$\n\n匹配滤波的信噪比\n\n$$\n\\frac{S}{N} = E \\left [ \\frac{2}{n_0} \\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt \\right] = \\frac{\\int_{0}^{T_s}E[a_i^2]h^2(t)\\mathrm dt}{n_0/2} = \\frac{E_s}{n_0 / 2}\n$$\n\n分子——传送一个符号的能量\n\n分母——噪声谱密度，单位是能量的单位\n\n以上采用的是等效基带模型。采用实际物理波形模型：\n\n$$\nS = \\frac{E_s}{T_s} = E_sR_s\\\\\nN = Wn_0\\\\\n\\frac{S}{N} = \\frac{E_s}{n_0}\\frac{R_s}{W}\\\\\n$$\n\n两个模型推得的信噪比表达式不同，差异在于等效基带模型使用了匹配滤波器，获得了最优的信噪比：\n\n$$\n\\frac{R_s}{W} \\le 2 \\Rightarrow\\left (\\frac{S}{N}  \\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\n$$\n\n从实际物理波形模型来看，上式取等的条件应该是基带脉冲采用的是理想低通（Sa 函数），如果用升余弦滤波\n\n$$\n\\frac{R_s}{W} = \\frac{2}{\\alpha + 1} \\Rightarrow \\left(\\frac{S}{N}\\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\\frac{2}{\\alpha + 1}\n$$\n\n但是，在等效基带模型中，我们考虑的是任意脉冲 $h(t)$，并没有要求它的形状，这两个模型在最优信噪比的产生条件上出现了矛盾？\n\n![alt](../images/通网/4_5.jpg)\n\n![alt](../images/通网/4_6.jpg)\n\n#### 传送一串符号\n\n![alt](../images/通网/4_7.jpg)\n\n无 ISI 条件：\n\n$$\nh(t)*h_m(t) = h(t) * h(T_s - t)\\\\\nH(f)H_m(f) = H(f)H^*(f)e^{-j2\\pi fT_s} = \\left | H(f) \\right|^2 e^{-j2\\pi fT_s} \n$$\n\n从而有根号奈奎斯特条件：\n\n$$\nH(f) = \\sqrt{H_{N-I}(f)}e^{-j2\\pi fT_s} \nH_m(f) = \\sqrt{H_{N-I}^*(f)}e^{-j2\\pi fT_s} \n$$\n\n这就要求发送和接受滤波器要满足如下要求：\n\n$$\nh_T(t) = h_{\\sqrt{N}}\\left ( t - \\frac{T_s}{2} \\right)\\\\\nh_R(t) = h_{\\sqrt{N}}\\left (\\frac{T_s}{2}  - t\\right) = h_T(T_s - t)\n$$\n\n#### 符号差错模型：\n\n![alt](../images/通网/4_8.jpg)\n\n$$\ny_i = \\bar h a_i + n_i\n$$\n\n![alt](../images/通网/4_9.jpg)\n\n### 判决与差错\n\n### 最佳判决\n\n![ima](../images/通网/5_2.jpg)\n\n![ima](../images/通网/5_1.jpg)\n\n![alt](../images/通网/5_3.jpg)\n\n多元符号的最佳判决\n\n$$\na^* = \\argmax_{a\\in U} f(y|a)f(a)\\\\\nf(a) = \\frac{1}{M}\\\\\na^* = \\argmax_{a\\in U} f(y|a)\\\\\n$$\n\n$y = a + n$ 的条件分布是\n\n$$\nf(y|a) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y - a)^2}{2\\sigma^2}\\right)\n$$\n\n从而得到\n\n$$\na^* = \\argmin_{a\\in U} |y - a|\n$$\n\n选择一个符号，让它到接收符号y距离最小，以此作为判决结果！\n\n双极性码的判决门限：\n\n![alt](../images/通网/5_4.jpg)\n\n单极性码的判决门限:\n\n![alt](../images/通网/5_6.jpg)\n\n#### SER & BER\n\n考虑二元符号\n\n发送 A 的出错概率：\n\n$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = \\int_{A/\\sigma}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}\\exp \\left ( -\\frac{t^2}{2} \\right)\\mathrm dt = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n发送 -A 的出错概率：\n\n$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n从而平均符号差错概率：\n\n$$\nP_s = \\frac{1}{2}\\left (Q \\left ( \\frac{A}{\\sigma} \\right) + Q \\left ( \\frac{A}{\\sigma} \\right)  \\right) = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n称为符号差错概率(Symbor Error Probability, SEP)，其统计结果称为误符号率（Symbol Error Ratio, SER）\n\n由于Q是减函数，所以误符号率随A增大而减小，随噪声标准差增大而增大\n\n误符号率不关心具体的A或标准差，而是由其比值所决定\n\n对于多元而言：\n\n对于任意符号集合，只要某判决门限与符号距离为A，则由于超出该判决门限而差错的条件概率就是：\n\n$$\nQ \\left ( \\frac{A}{\\sigma} \\right)\n$$\n\n计算信噪比：\n\n信号平均功率： $S = \\frac{1}{M}\\sum\\limits_{i=1}^{M}|a_i|^2$\n\n信号峰值功率： $S_p = \\max_{a_i \\in U} |a_i|^2$\n\n噪声功率： $N = \\sigma^2$\n\n对于双极性二元符号，平均功率为 $S = A^2$\n\n从而信噪比为 \n\n$$\n\\frac{S}{N} = \\frac{A^2}{\\sigma^2}\n$$\n\n利用等效关系得到误符号率和信噪比的关系\n\n$$\nP_s = Q \\left ( \\frac{A}{\\sigma} \\right) = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$\n\n更一般的二元码 SER\n\n$$\nU = \\lbrace D-A, D+A \\rbrace\\\\\n\\zeta = \\frac{D}{A}\\\\\nP_s = Q(\\sqrt{\\frac{S}{(1 + \\zeta^2)N}})\n$$\n\n更一般的 M 元码 SER\n\n符号集合为 $\\lbrace D - (M - 1)A, \\dots, D + (M  - 1)A \\rbrace$\n\n$$\n\\zeta = \\frac{D}{A\\sqrt{\\frac{M^2 - 1}{3}}}\\\\\nP_s = \\frac{2(M - 1)}{M}Q \\left ( \\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{(1 + \\zeta^2)N}} \\right)\n$$\n\n双极性 M 元码的 SER (掌握计算方法)\n\n$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{M^2 - 1} \\frac{S}{N}}\\right)\n$$\n\n无论M为奇数还是偶数，结果都是一样的！\n\n单极性 M 元码的 SER (掌握计算方法)\n\n$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$\n\n\n要使得双极性和单极性码的 SER 相同，二者的信噪比的比值为\n\n$$\n\\left ( \\frac{S}{N} \\right)_d \\bigg / \\left ( \\frac{S}{N} \\right)_s = \\frac{M^2 - 1}{2(M - 1)(2M  - 1)} \\approx \\frac{1}{4}\n$$\n\n显然，双极性的性能更好，它对信噪比的要求是单极性的四分之一，更能忍受噪声。\n\n误比特率(Bit Error Rate, BER)：\n\n$$\nP_b \\approx \\frac{P_s}{\\log_2M}\n$$\n\n注意这是近似结果，且有成立条件，只对二元码是严格成立的！\n* 假设一个符号的错判导致 1bit 的错误，假设成立的条件：\n    * Grey 码映射\n    * 信噪比不过于小\n\n\n各类符号集合的 BER\n\n双极性二元码\n\n$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$\n\n单极性二元码\n\n$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{2N}} \\right)\n$$\n\n单极性二元码损失了 3 dB.\n\n双极性 M 元码\n\n$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{N}})\n$$\n\n单极性 M 元码\n\n$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$\n\n由于\n\n$$\n\\frac{S}{N} = 2\\log_2 M\\frac{E_b}{n_0}\n$$\n\n故可以把 SER 和 BER 用 $E_b/n_0$ 表示：\n\n双极性二元码：\n\n$$\nP_s = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\n$$\n\n单极性二元码：\n\n$$\nP_s = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\n$$\n\n双极性 M 元码：\n\n$$\nP_s = \\frac{2(M - 1)}{M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\n$$\n\n单极性 M 元码：\n\n$$\nP_s = \\frac{2(M - 1)}{M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\n$$\n\n例子：相移键控 MPSK\n\n$$\n\\begin{align*}\n    S_{MPSK}(t) =& \\sum\\limits_{n}^{}g(t - nT_s)A\\cos(\\omega_c t + \\phi_n)\\\\\n    =& \\left [\\sum\\limits_{n}^{}A\\cos \\phi_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}A\\sin \\phi_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$\n\n* 所有符号的模相同\n* 幅角在 $[0, 2\\pi]$ 均匀分布\n\n可以用星座图表示：\n\n![alt](../images/通网/5_5.jpg)\n\n根据信号的 $I, Q$ 表示\n\n计算 MPSK 的 SER:\n\n考虑星座点 $(A, 0)$\n\n接收信号的分布函数为\n\n$$\nf(a, b) - \\frac{1}{2\\pi \\sigma_n^2}\\exp \\left ( -\\frac{(a - A)^2 + b^2}{2\\sigma_n^2} \\right)\n$$\n\n变换到极坐标系\n\n$$\nf(\\rho, \\theta) = \\frac{\\rho}{2\\pi\\sigma_n^2}\\exp \\left ( -\\frac{\\rho^2 + A^2 - 2A\\rho\\cos\\theta}{2\\sigma_n^2} \\right)\\\\\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{A^2}{2\\sigma_n^2}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - A/\\sigma_n\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$\n\n误符号率可以表示为\n\n$$\nP_{s, MPSK} = 1 - \\int_{-\\pi/M}^{\\pi/M}f(\\theta)\\mathrm d\\theta\n$$\n\n用信噪比表示：\n\n$$\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$\n\n如果 $S/N$ 很大：\n\n$$\n\\begin{align*}\n    \\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho \\approx& \\int_{-\\infty}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\\\\\n    =& \\sqrt{\\frac{S}{N}}\\cos\\theta\n\\end{align*}\n$$\n\n利用高信噪比近似：\n\n$$\nf(\\theta) = \\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\n$$\n\n当 M 比较大时：\n\n$$\n\\begin{align*}\n    P_{s, MPSK} =& 1 - \\int_{-\\pi/M}^{\\pi/M}\\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    \\approx& \\frac{2}{\\sqrt{\\pi}}\\int_{\\pi/M}^{\\infty}\\sqrt{\\frac{S}{2N}}\\cos\\theta\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}}\\int_{\\pi/M}^{\\infty}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\sqrt{\\frac{S}{N}}\\sin\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}} \\int_{\\sqrt{S/N}\\sin\\pi/M}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\mathrm du\\\\\n    =& 2Q \\left ( \\sqrt{\\frac{S}{N}}\\sin\\frac{\\pi}{M} \\right)\n\\end{align*}\n$$\n\n换算成 BER， $E_b/n_0$\n\n$$\nP_{b, MPSK} = \\frac{2}{\\log_2M}Q \\left ( \\sqrt{2\\log_2M\\frac{E_b}{n_0}}\\sin\\frac{\\pi}{M} \\right)\n$$\n\n一个简单的方法：\n\n看起来像是先射箭后画靶。\n\n![alt](../images/通网/5_7.jpg)\n\n例子2：正交幅度调制 QAM\n\n信号表示\n\n$$\n\\begin{align*}\n    S_{MQAM}(t) =& \\left [\\sum\\limits_{n}^{}a_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}b_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$\n\nI,Q 两路的电平集合：\n\n$$\na_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\nb_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\n$$\n\nQAM是一种典型的星座图，它分布于复平面的格点上，其符号的实虚部均为奇数（便于分析）\n\n解调过程：\n\nI 路信息提取：乘以同相载波 $\\cos\\omega_c t$，再低通滤波\n\nQ 路信息提取：乘以同相载波 $-\\sin\\omega_c t$，再低通滤波\n\n差错分析：\n\n![alt](../images/通网/5_8.jpg)\n\n（通过后面的分析可以发现，降低误码率的关键是将符号间的最小距离最大化）\n\n计算各符号的差错概率：\n\n四个角：\n\n$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$\n\n$4(L - 2)$ 个边点：\n\n$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\n$$\n\n$(L - 2)^2$ 个内点：\n\n$$\nP_s = 1 - \\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$\n\n计算平均 SEP：\n\n$$\n\\begin{align*}\n    P_s =& \\frac{1}{L^2}\\lbrace 4(2Q - Q^2) + 4(L - 2)(3Q - 2Q^2) + (L - 2)^2(4Q - 4Q^2) \\rbrace\\\\\n    \\approx& \\frac{4L^2 - 4L}{L^2}Q \\left ( \\frac{A}{\\sigma_n} \\right)\n\\end{align*}\n$$\n\n省略了 $Q$ 的高阶量。\n\n计算平均功率：\n\n$$\nS = 2 \\times \\frac{2A^2}{L}[1^2 + 3^2 + \\dots + (L - 1)^2] = \\frac{2(L^2 - 1)}{3}A^2\n$$\n\n是同A的LPAM功率的两倍。因为MQAM有两路LPAM\n\n得到 SEP：\n\n$$\nP_s = \\frac{4M - 4L}{M} Q \\left (\\sqrt{\\frac{3}{2(M - 1)}\\frac{S}{N}}  \\right)\\\\\nM = L^2\n$$\n\n得到 BEP：\n\n$$\nP_b = 4 \\left (1 - \\frac{1}{\\sqrt M}  \\right) Q \\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right) \\approx 4Q\\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right)\\\\\n$$\n\n注意到MQAM可以看成两路正交的MPAM\n\n$$\n\\begin{align*}\n    P_{s, MQAM} =& 1 - (1 - P_{LPAM})^2\\\\\n    \\approx& 2P_{LPAM}\\\\\n    =& 4 \\left ( 1 - \\frac{1}{\\sqrt M} \\right)Q \\left ( \\sqrt{\\frac{3}{(M - 1)}\\frac{S/2}{N}} \\right)\n\\end{align*}\n$$\n\n这个推导方式更简单。\n\nQAM 是在独立解映射条件下最好的方案。但是距离高斯信道容量还有一定距离。要达到更好的信道容量，可以采用联合解映射，将译码过程联合起来。\n\n例子3：频移键控 FSK\n\n一般来说，信号表达式和调制框图的相互反演是比较容易做的\n\n相对于PAM，PSK和QAM，FSK占用更大的频带，\n\n相干解调\n\nCoherent Demodulation\n\n- 反思FSK非相干解调方式，如果对每个频率的载波进行匹配，则可以提高信噪比\n- 这种方法需要本地子载波\n- 解调器的结构和非相干解调很像\n\n- 无法用星座图方法表示，但是可以用类似的信号空间表示\n- 若MFSK载频等间隔，则调制阶数约高，占用带宽越大\n- 如果每次可以选择多个载频，甚至控制载频幅度，则可承载的符号量可以获得极大提升。由此便引申出OFDM技术\n* 通过调制FSK的每个载波的幅度相位，可以承载更多的信息\n\n星座图没法表述 FSK. 可以使用信号空间方法来表示。\n\n差错分析：\n\nFSK 的判决门限为棱锥形状：\n\n![alt](../images/通网/5_9.jpg)\n\n根据对称性，可以只考虑一个符号的差错概率。\n\n考虑 FSK 信号\n\n$$\n[A, 0, \\dots, 0]\n$$\n\n匹配滤波的输出为\n\n$$\n[A + n_1, n_2, \\dots, n_M]\n$$\n\n正确判决：信号落在本棱锥中\n\n$$\nA + n_1 \\gt n_i, i = 2, \\dots, M\n$$\n\n被判决符号的条件分布为\n\n$$\nf_{[A + n_1, n_2, \\dots, n_M]}(\\vec r) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\n$$\n\n不满足正确判决条件的概率为\n\n$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M \\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i\\mathrm dr_1\\\\\n    =&1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\left (\\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i  \\right)^{M - 1}\\mathrm dr_1\n\\end{align*}\n$$\n\n记 $x = \\frac{r_1}{\\sigma}$\n\n$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi }}\\exp \\left ( -\\frac{(x - A/\\sigma)^2}{2} \\right)\\left (1 - Q(x)\\right)^{M - 1}\\mathrm dx\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\frac{A}{\\sigma}  \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$\n\n$$\n\\frac{A}{\\sigma} = \\sqrt{\\frac{S}{N}} = \\sqrt{\\log_2M\\frac{2E_b}{n_0}}\n$$\n\n可得 SEP 的表达式\n\n$$\n\\begin{align*}\n    P_s =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\frac{S}{N}} \\right)\\right)^{M - 1}\\mathrm du\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\log_2M\\frac{2E_b}{n_0}} \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$\n\n另一种简单估界：\n\n![alt](../images/通网/5_10.jpg)\n\n正交 2FSK 信号在最佳接收条件时的错误概率为\n\n$$\nP_{b,NCFSK} = Q(\\sqrt{E_b/n_0})\n$$\n\n随着 M 的增加，MFSK 的差错性能渐优，这是以带宽的占用为代价的。\n\nPAM, QAM, ASK 等技术随着符号个数的增加，差错性能是越来越差。\n\nFDM——Frequency Division Multiplexing\n\n- 先将各路信号调制到不同频段，然后复用整个\n通信带宽\n- 信道的非线性会在FDM系统中产生交调失真与\n高次谐波，引起路际串话，因此，对信道的非\n线性失真要求很高。此外，FDM用到的模拟滤\n波器设计较为复杂。\n\n\n#### OFDM 基本原理\n\nOrthogonal Frequency division multiplexing\n\n- 把一串高速数据流分解为若干速率低得多的子数据流。\n- 将每个子数据流放置在对应的子载波上。\n- 将多个子载波合成，一起并行传输。\n- 优点：频谱利用率高。\n\n正交性的定义：\n\n$$\n\\int_{0}^{T}S_1(t)S_2(t)\\mathrm dt = 0\n$$\n\n设相邻子载波的频率间隔为 $1 / T$，$T$ 为 OFDM 符号的持续时间，则\n任意一对子载波的内积满足\n\n$$\n\\frac{1}{T}\\int_{0}^{T}e^{j2\\pi \\frac{k_1}{T}t}e^{-j2\\pi \\frac{k_2}{T}t}\\mathrm dt = \\begin{cases}\n    1, k_1 = k_2\\\\\n    0, k_1 \\ne k_2\n\\end{cases}\n$$\n\n带宽 $W$ 和 $B$ 的区别：\n\n物理带宽 $W$\n\n信号带宽 $B$：半功率带宽(3dB)，等效噪声带宽，谱零点带宽，功率比例带宽，最低功率谱带宽\n\n#### 带通信号的表示方法\n\n$$\nx(t) = A(t) \\cos [\\omega_c t + \\varphi (t)]\\\\\n$$\n\n同相分量：$x_I(t) = A(t) \\cos(\\varphi(t))$\n\n正交分量：$x_Q(t) = A(t) \\sin(\\varphi(t))$\n\n与幅度相位的关系：\n\n$$\nA(t) = \\sqrt{x_I^2(t) + x_Q^2(t)}\\\\\n\\varphi(t) = \\tan^{-1} \\left [ \\frac{x_Q(t)}{x_I(t)} \\right]\n$$\n\n带通信号的基带表示的方法\n\n$$\nx_{bb}(t) = x_I(t) + jx_Q(t)\\\\\n$$\n\n解析信号表示\n\n$$\nx_A(t) = x_{bb}(t)e^{j\\omega_ct}\\\\\nx(t) = \\real \\lbrace {x_A(t)} \\rbrace = \\real \\lbrace x_{bb}(t)e^{j\\omega_ct} \\rbrace\n$$\n\n原始带通信号是解析信号的实部\n\n从带通信号恢复基带信号？\n\n$$\n\\breve{x}(t) = x(t) \\circledast h(t)\\\\\nh(t) = \\frac{1}{\\pi t}\\\\\n\\breve{x}(t) = \\frac{1}{\\pi} \\int_{-\\infty}^{\\infty}\\frac{s(\\tau)}{t - \\tau}\\mathrm d\\tau\\\\\nH(f) = -j \\cdot \\text{sgn}(f) = \\begin{cases}\n    -j, &f\\gt 0\\\\\n    0, &f=0\\\\\n    j, &f < 0\n\\end{cases}\n$$\n\n构造解析信号\n\n$$\nx_A(t) = x(t) + j\\breve{x}(t)\\\\\n$$\n\n频谱分析\n\n$$\nX_A(\\omega) = [1 + \\text{sgn}(\\omega)]X(\\omega) = \\begin{cases}\n    2X(\\omega), &\\omega \\gt 0\\\\\n    X(0) = 0, &\\omega = 0\\\\\n    0, &\\omega \\lt 0\n\\end{cases}\\\\\nX_{bb} = X_A(\\omega + \\omega_c)\n$$\n\n带通信道\n\n具有实数值的信道冲激响应（CIR） $h(t)$\n\n等效的解析冲激响应 $h_A(t) = h(t) + j\\breve{h}(t)$\n\n任意载波频率 $\\omega_c$ 的等效基带冲激响应CIR\n\n$$\nh_{bb}(t) = h_A(t) \\cdot e^{-j\\omega_c t}\n$$\n\n带通收发信号关系 $y(t) = x(t) * h(t)$，则\n\n$$\nY(\\omega) = H(\\omega) X(\\omega)\\\\\nY_A(\\omega) = H_A(\\omega)X_A(\\omega)\\\\\nY_A(\\omega) = [H(\\omega) \\cdot \\frac{1}{2}\\left (1 + \\text{sgn}(\\omega)  \\right)]X_A(\\omega) = \\left [ \\frac{1}{2}H_A(\\omega) \\right]X_A(\\omega)\n$$\n\n$H_A(\\omega)$ 只有正半轴部分\n\n$$\nY_{bb}(\\omega) = Y_A(\\omega + \\omega_c) = \\left [ \\frac{1}{2}H_A(\\omega + \\omega_c) \\right]X_A(\\omega + \\omega_c) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$\n\n基带等效系统\n\n$$\ny_{bb}(t) = \\frac{1}{2}h_{bb}(t) * x_{bb}(t)\\\\\nY_{bb}(\\omega) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$\n\n基带时域转移函数 $\\frac{1}{2}h_{bb}(t)$\n\n基带频域转移函数 $H(\\omega + \\omega_c)$\n\n用正交基观点构造了信号波形\n\n$$\nx(t) = \\sqrt{2}\\cos 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^I_kg(t - kT_s) + \\sqrt{2}\\sin 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^Q_kg(t - kT_s)\n$$\n\n投影后的噪声：\n\n$$\nE \\lbrace n_k^In_l^Q \\rbrace = 0\\\\\nE \\lbrace n_k^In_l^I \\rbrace = \\delta_{kl}\\\\\nE \\lbrace n_k^Qn_l^Q \\rbrace = \\delta_{kl}\n$$\n\n等效符号差错模型\n\n$$\ny_k = x_k + n_k\\\\\nn_k \\sim \\mathcal{CN}(0, n_0)\n$$\n\n## 差错控制\n\n差错控制的分类：\n* 检错重发 （ARQ）\n* 前向纠错 （FEC）\n\n前向纠错的分类：\n* 线性码，非线性码\n* 分组码（重点），卷积码\n* 系统码，非系统码\n\n编码增益\n\n给定误比特率的情况下，采用纠错编码后，$E_b/n_0$的减小量称为编码增益。\n\n简单例子：\n\n重复编码\n\nBSC 重传三次：\n\n$$\n3p_e^2(1 - p_e) + p_e^3 \\approx 3p_e^2\n$$\n\n信道编码：通过合理得增加冗余信息，纠正信道传输中可能出现的错误\n* 又称为纠错码（Error Correction Coding）\n\n理想信道编码的局限性：\n* 码长无穷大\n* 没发现代数结构，复杂度太大\n\n如何实用化：\n* 有限长。代价：误码率非零，效率低\n* 有代数结构。优点：便于译码\n\n评价标准\n* 误比特率：评价可靠性\n* 码率：评价有效性\n\n### 分组码\n\n奇偶监督码\n* 检错，而非纠错\n* 电路实现简单\n\n漏检概率：\n\n$$\nP_m =\\sum\\limits_{i=1}^{\\lfloor\\frac{n}{2}\\rfloor}\\binom{n}{2i}\\varepsilon^{2i}(1 - \\varepsilon)^{n - 2i}\n$$\n\n群计数码\n* 累计信息码元中1的个数，以二进制形式放在信息码元后面\n* 检错能力\n  * 强于奇偶校验码\n  * 当{1变0数量=0变1数}时，无法检出\n\n纠错码的直观表示\n\n* 码字\n  * 对应 $n$ 维空间的点\n\nHamming 距离：两个码字之间不同码元的个数\n\n**Hamming 距离**\n\n* $x_m$ 和 $x_m^\\prime$ 中不同取值的位置数 $d_H(\\mathbf x_m, \\mathbf x_m^\\prime)$\n* 即模2和中1的个数\n\n汉明码重\n* 二进制向量 $\\mathbf x_m$ 1的个数 $w(\\mathbf x_m)$\n\n最小距离\n\n一个分组码中任意两个码字的最小汉明距离 $d_{\\text{min}}$\n\n#### (n,k)纠错码\n\n$$\nB = E + A, \\forall A \\in \\chi\\\\\nS = BH^T = EH^T\\\\\n$$\n\n$S$ 与 $A$ 无关，$A$ 只是无用的陪同（coset）。\n\n陪集首：上述陪集的特征由 $S = EH^T$ 标识，我们称 $E$ 为陪集首。\n\n陪集首一般选择集合中 \"1\" 最少的元素，这是为了优先标识错误数量较小的差错，这一类差错发生的概率较大。\n\n码重：\n\n$$\nw(A) =\\sum\\limits_{i=1}^{n}\\mathbf 1 \\lbrace a_i = 1 \\rbrace = d_H(A, 0)\n$$\n\n001 -> 0,0,0,0,0,1 -> 101\n\n010 -> 0,0,0,0,1,0 -> 011\n\n011 -> 0,0,0,1,0,0 -> 110\n\n100 -> 0,0,1,0,0,0 -> 001\n\n101 -> 0,1,0,0,0,0 -> 010\n\n110 -> 1,0,0,0,0,0 -> 100\n\n111 -> 0,1,0,0,0,1 -> 111\n\n#### 交织器\n\n线性码的改进：\n\n- 上述线性码，均适合于纠正零散错误\n- Hamming码对于2个以上的差错就无能为力\n- 若差错总是成对出现，则Hamming码基本没用\n- 在通信系统中，往往存在不可抗拒的突发错误\n\n例如：无线信道的衰落引起的误码\n\n抗突发误码的方法：交织器\n\n基本原理\n- 为了对付突发的信道差错，交织器改变发送码元的时\n间顺序\n- 将原本相邻的码元在时间上的距离最大化\n- 例子：考虑一个（n, k）分组码，其交织后的输出为\n\n\n将突发误码转换成零星误码\n\n交织器的性能：\n\n宽度\n- 就是分组码的码长n\n- 决定于所采用的分组码\n\n深度\n- 深度m决定了相邻码元交织后的间隔\n- m又称交织深度\n- 若分组码能纠b个突发错误，则交织后能纠mb个突发错误\n\n解交织：\n- 从另一个角度来看，解交织打散了突发误码\n- 化整为零后的零散误码，就可以交给解码器对付了\n\n### 卷积码\n\n输入无限长的激励，则输出信号无限长，\n\n若冲激响应有限，则输出只与某一段输入有关\n\n卷积码的参数 $n, k, N$\n\n约束长度，信息码位，每次输出\n\n使用树状图进行分类讨论\n\n树状图的冗余：\n- 树状图具有很多冗余表示\n\n\n树状图的应用：计算最小码距\n- 分组码的最小码距定义为非零码字的最小码重\n- 和分组码不同，卷积码没有分组的概念\n- 约束长度隐含了某种独立性，可以只考虑 $kN$ 的信息比特编码后的非零码字，也就是考虑 $nN$ 个非零的编码输出位\n\n状态图的应用\n- 自由距：无限长信息序列编码后的最小汉明距离\n- 自由距不等于最小距\n\n自由距等于寄存器从零状态开始，经过非零状态，然后回到零状态的输出1的个数的最小值\n\n卷积码的译码\n\n#### 维特比译码\n\n网格图\n\n最大似然下的最优译码\n\n- 低复杂度\n- 采用最小汉明距离作为代价函数\n\n采用动态规划的卷积码译码成为 viterbi 译码\n* viterbi 译码的起始状态是 0 状态\n* viterbi 译码没有确定的代价函数，\n\n分组码译码可以知道是否译码错误了。通过校验矩阵来校验就行了。\n\n但是 viterbi 译码并不能肯定译码结果是否正确。\n\n### 硬判决和软判决\n\n硬判决：任务是检测和矫正误码\n\n软判决：应用于卷积/ Viterbi 译码器，迭代译码  \n\n### 检错重发 ARQ\n\n$P_c = (1 - \\varepsilon)^n$ 为正确概率\n\n$P_d$ 检出错误概率\n\n$P_m$ 漏检概率\n\n$$\nP_c + P_d + P_m = 1\n$$\n\n总分组差错概率\n\n$$\nP_b = P_m + P_dP_m + P_d^2P_m + \\dots = \\frac{P_m}{1 - P_d} = \\frac{P_m}{P_c + P_m}\n$$\n\n#### 停等ARQ\n\n收到上一个 ACK/NAK 再发送下一个包或者重传上一个包\n\n假设发送方一直传输（一次就能传输成功），吞吐量的上限为\n\n$$\n\\eta_{sw, 0} = \\frac{k}{T_DR}\\\\\nT_D = T_m + 2 T_d + T_c + T_a = T_m + T_{dca} = \\frac{k}{n + T_{dca}R}\n$$\n\n若有完美的差错检出能力 $P_d = 1 - (1 - \\varepsilon)^n$\n\n则\n\n$$\n\\eta_{sw} = \\frac{k/n}{1 + T_{dca}R/n}(1 - \\varepsilon)^n\n$$\n\n#### 返回 N-ARQ\n\n不等 ACK/NAK 返回就传下一个包，若检错则重传从错误开始的所有包\n\n$$\n\\eta_{GBN, 0} = \\frac{k}{n}\n$$\n\n","slug":"通网","published":1,"updated":"2024-03-19T06:01:16.164Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clu1gtfi1000yrsugca7h6bkt","content":"<h2 id=\"信息论基础\"><a href=\"#信息论基础\" class=\"headerlink\" title=\"信息论基础\"></a>信息论基础</h2><h3 id=\"离散随机变量的信息度量\"><a href=\"#离散随机变量的信息度量\" class=\"headerlink\" title=\"离散随机变量的信息度量\"></a>离散随机变量的信息度量</h3><div>$$\nH(X) = \\mathbf E\\{H(X=x_i)\\} = -\\sum_i p_i \\log p_i\n$$</div>\n\n<p>称为熵</p>\n<p>单位：</p>\n<ul>\n<li>2 (Bit)</li>\n<li>e (Nat)</li>\n<li>10 (Hartely)</li>\n</ul>\n<p>表示了信息描述的有效性极限</p>\n<p>信源编码（Source Coding），通过信息的有效表示，提高通信的有效性。例如: Huffman 编码</p>\n<p>离散随机变量的最大熵：$\\max_{p_i} H(X) &#x3D; \\log|S|$</p>\n<p>前缀码：任何码字都不是其他码字的前缀。前缀码保证了唯一可译码。是二叉树叶子节点。</p>\n<p><strong>Kraft不等式</strong></p>\n<p>对于信源字符集$\\lbrace a_1, \\dots, a_m\\rbrace$，必满足：</p>\n<div>$$\n\\sum\\limits_{k=1}^{M}2^{-l(a_k)} \\le 1\n$$</div>\n\n<p>同时，若上式成立，必存在码长分别为$𝑙(𝑎_𝑘)$的前缀码。</p>\n<p>最小前缀码的平均码长：</p>\n<div>$$\n\\min \\bar L =\\sum\\limits_{i=1}^{M}p_il_i\\\\\ns.t.\\sum\\limits_{i=1}^{M} 2^{-l_i} = 1\n$$</div>\n\n<p>由拉格朗日乘子法</p>\n<div>$$\np_i = 2^{-l_i}, \\bar L_{min} = -\\sum\\limits_{i=1}^{M}p_i \\log p_i\n$$</div>\n\n<p>记 $H(X) &#x3D; -\\sum p_i\\log p_i$ .一般的，上下界为$H(X) \\le \\bar L  \\lt H(X) + 1$.</p>\n<p>如果我们将$k$个独立同分布的信源符号 $x_1, \\dots, x_k$堪称一个，对整体应用前缀码编码：</p>\n<div>$$\n\\begin{align*}\n    H(X_1, \\dots, X_k) &= -\\sum P(x_1, \\dots, x_k) \\log P(x_1, \\dots, x_k)\\\\\n    &= -\\sum P(x_1, \\dots, x_k) [\\log P(x_1) +  \\dots +  \\log(x_k)]\\\\\n    &= -\\sum P(x_1)\\log (x_1) - \\dots - \\sum P(x_k)\\log (x_k)\\\\\n    &= -kH(X)\n\\end{align*}\n$$</div>\n\n<p>直观：对长度为$𝑛$的$M$种信源符号序列，$𝑥_𝑖$出现的次数$≈𝑛𝑝_𝑖$</p>\n<p>典型序列应满足上述分布，否则就“小众”“非典型”</p>\n<p>典型的个数 # $≈ \\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}$</p>\n<p>平均每个信源符号可以用 $L &#x3D; \\frac{1}{n}\\log\\left(\\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}\\right)$ 个 bit 来表达。</p>\n<p>通过 Stirling 公式可以得出 L的上下界。</p>\n<p>故</p>\n<div>$$\n\\lim\\limits_{n\\rightarrow \\infty}^{} L = H(X)\n$$</div>\n\n<p><strong>最大熵</strong></p>\n<p>离散型随机变量的最大熵为</p>\n<!-- max -->\n<div>$$\n\\max_{p_i} H(X) = \\log |S|\n$$</div>\n\n<p>可以用梯度法直观感受，当所有分量的概率相等时，熵最大。</p>\n<p><strong>联合熵</strong></p>\n<p>联合概率</p>\n<!-- text -->\n<div>$$\np_{i, j} = \\text{Pr}\\lbrace X = x_i, Y = y_j\\rbrace\n$$</div>\n\n<p>联合熵的定义：</p>\n<div>$$\nH(XY) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i, j}\n$$</div>\n\n<p><strong>条件熵</strong></p>\n<p>条件概率</p>\n<!-- text -->\n<div>$$\np_{i\\mid j} = \\text{Pr}\\lbrace X = x_i \\mid Y = y_j\\rbrace\n$$</div>\n\n<p>条件熵的定义：</p>\n<div>$$\nH(X|Y) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i\\mid j}\n$$</div>\n\n<p>通过相关观测进行无损压缩，若观测到 $Y &#x3D; \\alpha_j$：</p>\n<div>$$\n\\bar L(\\alpha_j) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i\\mid j} \\log p_{i\\mid j}\n$$</div>\n\n<p>于是</p>\n<div>$$\n\\bar L =-\\sum\\limits_{j=1}^{N} \\bar L(\\alpha_j)p_j = -\\sum\\limits_{j=1}^{N}p_j\\sum\\limits_{i=1}^{M}p_{i|j} \\log(p_{i|j}) = -\\sum\\limits_{i=1}^{M}\\sum\\limits_{j=1}^{N}p_{ij}\\log(p_{i|j}) = H(X|Y)\n$$</div>\n\n<p><strong>链式法则</strong></p>\n<div>$$\nH(XY) = H(Y) + H(X|Y)\n$$</div>\n\n<p>两个随机变量的联合不确定性＝一个随机变量的不确定性＋知道这个随机变量后另一个随机变量残余的不确定性</p>\n<p><strong>互信息(Mutual Infomation)</strong></p>\n<div>$$\n\\begin{align*}\n    I(X;Y) &= H(X) + H(Y) - H(XY)\\\\\n    &= H(X) - H(X|Y) \\\\\n    &= H(Y) - H(Y|X)\n\\end{align*}\n$$</div>\n\n<p>互信息的物理意义</p>\n<p>第一种理解：</p>\n<ul>\n<li>X的不确定度减去观测Y后X残存的不确定度</li>\n<li>即：通过观测Y带来的帮助了解X的信息</li>\n</ul>\n<p>第二种理解：</p>\n<ul>\n<li>Y的不确定度减去观测X后Y残存的不确定度</li>\n<li>即：通过观测X带来的帮助了解Y的信息</li>\n</ul>\n<p>若$X, Y$相互独立，记为$X\\perp Y$，则$I(X;Y) &#x3D; 0$，$H(X) &#x3D; H(X|Y)$，$H(Y) &#x3D; H(Y|X)$。观测一个随机变量完全无助于了解另一个随机变量。</p>\n<ul>\n<li>$H(XY) &#x3D; H(X) + H(Y)$，总平均码长等于各自平均码长之和。</li>\n</ul>\n<p>若$X &#x3D; Y$，则$I(X;Y) &#x3D; H(X) &#x3D; H(Y)$，$H(X|Y) &#x3D; H(Y|X) &#x3D; 0$。观测一个随机变量完全了解另一个随机变量。</p>\n<p>$H(XY) &#x3D; H(Y) + H(X|Y) &#x3D; H(Y)$，只需要编码其中一个即可。</p>\n<div>$$\nX \\perp Y \\leftrightarrow H(X + Y | X) = H(Y | X) = H(Y), H(X + Y, X) = H(Y , X)\n$$</div>\n\n\n<div>$$\nH(X + X | X) = H(X | X) = 0, H(X + X, X) = H(X , X) = H(X)\n$$</div>\n\n<p><strong>信息传输的基本模型</strong></p>\n<ul>\n<li>信息通道，简称信道（Channel）对于输入符号有随机扰动，本质上可用一组条件概率表示</li>\n<li>限于物理条件，信宿只能观测信道输出 $Y$，由此了解其输入 $X$</li>\n<li>通过观测Y可以获得的关于X的信息量是 $I(X;Y)$</li>\n</ul>\n<p><strong>信息传输的优化</strong></p>\n<p>目标：最大化发送端 $X$ 和接收方 $Y$ 的互信息</p>\n<p>方法：</p>\n<ul>\n<li>信道是由物理实现所决定的，无法控制</li>\n<li>但是可以选择X的概率分布</li>\n</ul>\n<p>因此有如下优化问题：</p>\n<div>$$\np*_i = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} I(X;Y)\n$$</div>\n\n<p>定义信道容量 $C &#x3D; \\max_{\\sum_i p_i &#x3D; 1, p_i \\ge 0} I(X;Y)$</p>\n<p>信道容量的物理意义</p>\n<ul>\n<li>平均每个信道符号所能传的最大的信息量</li>\n<li>或：单位时间内信道所传最大的信息量</li>\n</ul>\n<p>优化问题的表达式</p>\n<div>$$\np_i^* = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} - \\sum_i\\sum_j p_i p_{j|i} \\log \\frac{\\sum\\limits_i p_i p_{j|i}}{p_{j|i}}\n$$</div>\n\n<p>信道容量不易计算</p>\n<p><strong>对称二进制信道(BSC)</strong></p>\n<ul>\n<li>一种典型信道模型</li>\n<li>分析信道编码时有很多应用</li>\n</ul>\n<p>利用互信息表达式</p>\n<div>$$\n\\begin{align*}\n    I(X;Y) &= H(Y) - H(Y | X)\\\\\n    &= H(Y) - \\sum_i p_i \\left[-\\sum_j p_{j|i} \\log p_{j|i}\\right]\\\\\n    &= H(Y) - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)]\\\\\n    &\\le 1 - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)] = C\\\\\n\\end{align*}\\\\\nY \\sim \\begin{bmatrix}\n    0 & 1\\\\\n    1/2 & 1/2\n\\end{bmatrix}\n$$</div>\n\n<p>如果误码率 $\\varepsilon &#x3D; 0.5$，则信道容量为0, 传递不了信息。</p>\n<p>如果误码率 $\\varepsilon &gt; 0.5$，继续增大差错率，反而可以提高信道容量。</p>\n<p><strong>高斯信道</strong></p>\n<!-- **gauss** -->\n<div>$$\nY = X + N\\\\\nf_N(n) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(-\\frac{(y - x)^2}{2\\sigma^2}\\right)\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/1_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/1_.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>Shannon 公式</p>\n<div>$$\nC = W\\log(1 + \\frac{P}{Wn_0})\n$$</div>\n\n<h3 id=\"连续性随机变量的熵\"><a href=\"#连续性随机变量的熵\" class=\"headerlink\" title=\"连续性随机变量的熵\"></a>连续性随机变量的熵</h3><div>$$\nH(X) = - \\int\\limits_{-\\infty}^{\\infty}p(x)\\log p(x) \\mathrm dx + \\lim_{\\Delta \\rightarrow 0} \\log \\frac{1}{\\Delta}\n$$</div>\n\n<p>我们只关心相对不确定性，定义微分熵</p>\n<div>$$\nh(X) = -\\int\\limits_{-\\infty}^{\\infty}p(x) \\log p(x)\\mathrm dx\n$$</div>\n\n<p>微分熵是对连续型变量相对不确定性的一种描述</p>\n<ul>\n<li>其定义剔除了连续性或“精准要求”带来的困难，保<br>留了分布函数形状自身的特征</li>\n<li>它说明用有限字符集合的字符串描述连续分布的随机<br>变量，则平均字符长度为无穷大</li>\n<li>为了用有限长字符串描述信源，需要进行有损压缩，<br>从而带来失真，即原始信源和压缩结果之间的差异</li>\n<li>失真测度包括：均方误差，绝对值误差，主观误差等</li>\n<li>对于图像，视频和语音等连续信源的编码等均属于有<br>损压缩</li>\n</ul>\n<h3 id=\"多元随机变量的熵\"><a href=\"#多元随机变量的熵\" class=\"headerlink\" title=\"多元随机变量的熵\"></a>多元随机变量的熵</h3><p>联合熵：</p>\n<div>$$\nh(XY) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(x, y)\\mathrm dx \\mathrm{d}y\n$$</div>\n\n<p>条件熵：</p>\n<div>$$\nh(Y|X) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(y|x)\\mathrm dx \\mathrm{d}y\n$$</div>\n\n<p>互信息：</p>\n<div>$$\n\\begin{align*}\n    I(X;Y) &= h(X) + h(Y) - h(XY)\\\\\n    &= h(X) - h(X|Y) \\\\\n    &= h(Y) - h(Y|X)\n\\end{align*}\n$$</div>\n\n<h2 id=\"压缩编码\"><a href=\"#压缩编码\" class=\"headerlink\" title=\"压缩编码\"></a>压缩编码</h2><h3 id=\"压缩编码的分类\"><a href=\"#压缩编码的分类\" class=\"headerlink\" title=\"压缩编码的分类\"></a>压缩编码的分类</h3><ul>\n<li>无损压缩<ul>\n<li>输入：数字序列</li>\n<li>输出：数字序列</li>\n<li>目的：使得平均长度更小</li>\n</ul>\n</li>\n<li>有损压缩<ul>\n<li>输入：模拟信号</li>\n<li>输出：数字序列</li>\n<li>目的：实现数字传输</li>\n</ul>\n</li>\n</ul>\n<p>信号压缩编码的步骤：</p>\n<ul>\n<li>抽样</li>\n<li>量化</li>\n<li>压缩编码</li>\n</ul>\n<h3 id=\"抽样\"><a href=\"#抽样\" class=\"headerlink\" title=\"抽样\"></a>抽样</h3><p><strong>连续时间信源的离散化</strong></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_1.jpg\" loading=\"lazy\"></p>\n<p>离散化的方式：在标准正交基上投影展开</p>\n<div>$$\ns(t) = \\sum_k a_k\\phi_k(t)\\\\\na_k = <s(t), \\phi_k(t)>\n$$</div>\n\n<p>若 $s(t)$ 是时限信号（宽度 $T$），可以用傅里叶展开的系数作为离散化结果：$s(t) &#x3D; \\sum\\limits_k a_k e^{2\\pi jkt&#x2F;T}$</p>\n<p>若 $s(t)$ 是带限信号（带宽 $W$），可以在频域对 $\\hat S(f)$ 做傅里叶展开：</p>\n<div>$$\n\\hat S(f) = \\sum\\limits_k \\alpha_k e^{2\\pi jkf/(2W)}\n$$</div>\n\n<p>变换回时域时，得到 Nyquist 抽样定理：</p>\n<div>$$\ns(t) =\\sum\\limits_{k}^{}s(kT) \\text{sinc}\\left(\\left(\\frac{t}{T} - k\\right)\\right), T = \\frac{1}{2W}\n$$</div>\n\n<p>频域无混叠等价于时域无畸变</p>\n<p>对于带通采样，有无混叠条件：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_2.jpg\" loading=\"lazy\"></p>\n<p>可以推导得出：</p>\n<div>$$\nf_s = 2B\\left(1 + \\frac{M}{N}\\right)\\\\\nN = \\left\\lfloor\\frac{f_H}{B}\\right\\rfloor\\\\\nM = \\left\\lbrace\\frac{f_H}{B}\\right\\rbrace\\\\\nB = f_H - f_L\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_3.jpg\" loading=\"lazy\"></p>\n<p>横轴为 $f_H&#x2F;B$，纵轴为 $f_s$</p>\n<p><strong>量化</strong></p>\n<p>分层电平： $\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$ </p>\n<p>重建&#x2F;输出电平：$y_k$代表一个量化区间，用以重构信号时使用的电平值</p>\n<p>量化函数： $y &#x3D; Q(x)$, $y_k &#x3D; Q\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$</p>\n<p>量化间隔： $\\Delta_k &#x3D; x_{k + 1} - x_{k}$</p>\n<p>均匀量化 &amp; 非均匀量化</p>\n<p>均匀量化只对有界随机变量存在</p>\n<h3 id=\"量化\"><a href=\"#量化\" class=\"headerlink\" title=\"量化\"></a>量化</h3><ul>\n<li>在此只讨论标量的量化</li>\n<li>量化噪声： $q &#x3D; x - y &#x3D; x - Q(x)$ </li>\n<li>量化噪声是一个随机变量</li>\n<li>方差 $\\sigma_q^2 &#x3D; \\int_{-\\infty}^{\\infty}[x - Q(x)]^2p_x(x)\\mathrm dx$</li>\n<li>方差与输入信号分布有关，不存在普适的最佳量化方案</li>\n</ul>\n<h4 id=\"量化噪声的计算\"><a href=\"#量化噪声的计算\" class=\"headerlink\" title=\"量化噪声的计算\"></a>量化噪声的计算</h4><div>$$\n\\sigma_q^2 =\\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>从较容易的情况着手</p>\n<ul>\n<li>只考虑电平区间 $[-V,V]$ 之间的信号，并假设量化间隔很小，亦即分层电平很密</li>\n<li>在实际情况中，信号的分布函数处处可导，此时每个量化区间内信号的条件分布为均匀分布</li>\n</ul>\n<p>量化区间内，近似概率密度 $p_x(x) &#x3D; \\frac{P_k}{\\Delta_k}$</p>\n<p>密集分层的量化噪声近似</p>\n<div>$$\n\\sigma_{qn}^2 = \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx = \\sum\\limits_{k=1}^{L}\\frac{P_k}{\\Delta_k}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2\\mathrm dx = \\frac{1}{12}\\sum_{k = 1}^L P_k\\Delta_k^2 = \\frac{1}{12} \\int_{-V}^{V}(\\Delta_k)^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>若 $\\Delta_k &#x3D; \\Delta$，</p>\n<div>$$\n\\sigma_{qn}^2 = \\frac{1}{12}\\sum_k P_k\\Delta_k^2 = \\frac{\\Delta_k^2}{12}\n$$</div>\n\n<p>计算量化结果做无损压缩后的比特数：</p>\n<div>$$\nH(Q(x)) = -\\sum_k P_k \\log P_k = \\underbrace{- \\int_{-\\infty}^{\\infty}p_x(x)\\log p_x(x) \\mathrm dx }_{h(X)} + \\log \\frac{1}{\\Delta}\n$$</div>\n\n<p>由 $\\Delta &#x3D; \\sqrt{12\\sigma_{qn}^2} &#x3D; 2\\sigma_{qn}\\sqrt{3}$，</p>\n<div>$$\nH(x) = h(x) + \\log \\frac{1}{2\\sigma_{qn}\\sqrt{3}}\n$$</div>\n\n<p>无损压缩的 bit 数为： $\\tilde{R} &#x3D; h(X) - \\frac{1}{2}\\log \\sigma_{qn}^2 - 1.8$</p>\n<p>对于均匀量化：</p>\n<div>$$\n\\Delta_k = \\frac{x_{max} - x_{min}}{L} = \\frac{2x_{max}}{L}, \\forall k\n$$</div>\n\n<p>于是</p>\n<div>$$\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12} = \\frac{x_{max}^2}{3L^2}\n$$</div>\n\n<p>这里的 $\\sigma_{qn}^2$ 是正常量化噪声，仅仅是计算了信号落在 $[-x_{max}, x_{max}]$ 内的情况</p>\n<p>如果信号落在 $[-x_{max}, x_{max}]$ 以外，就就近判断至两端的量化区间，产生过载噪声</p>\n<div>$$\n\\sigma_{qo}^2 = \\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx + \\int^{-x_{max}}_{-\\infty}(x + x_{max})^2p_x(x)\\mathrm dx = 2\\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>总噪声等于正常量化噪声加上过载噪声：</p>\n<div>$$\n\\sigma_{qs}^2 = \\sigma_{qn}^2 + \\sigma_{qo}^2\n$$</div>\n\n<p>如果用 $R$ bit 编码：</p>\n<div>$$\n\\Delta_k = \\frac{2x_{max}}{L} = \\frac{x_{max}}{2^{R - 1}}\\\\\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx = \\frac{x_{max}^2}{3 \\times 2^{2R}}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx\n$$</div>\n\n<p>定义非过载信号功率：</p>\n<div>$$\n\\sigma_s^2 = \\int_{-x_{max}}^{x_{max}}x^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>当 $\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx \\rightarrow 1$， $SNR_q \\approx \\frac{\\sigma_s^2}{x_{max}^2&#x2F;(3 \\times 2^{2R})} &#x3D; 3 \\times 2^{2R} \\times \\zeta^2$，这里定义 $\\zeta &#x3D; \\frac{\\sigma_s}{x_{max}}$ 为量化范围内信号的饱满程度。</p>\n<p>对数单位下：</p>\n<div>$$\nSNR_q(dB) = 6.02R + 20\\log_{10}(\\zeta) + 4.77\n$$</div>\n\n<ul>\n<li>多一个 bit，$SNR_q$ 提升 $6.02dB$</li>\n<li>$\\zeta$ 要在合理范围，$\\zeta$ 过大时过载会严重劣化性能</li>\n</ul>\n<h4 id=\"最优量化\"><a href=\"#最优量化\" class=\"headerlink\" title=\"最优量化\"></a>最优量化</h4><p>目标：给定量化区间总数，最小化量化噪声</p>\n<p>优化问题：</p>\n<div>$$\n\\min \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2 p_x(x)\\mathrm dx\\\\\ns.t. x_1\\le y_1 \\le x_2 \\le y_2 \\le \\dots \\le y_L \\le x_{L + 1}\n$$</div>\n\n<p>分层电平在重建电平的中点：</p>\n<div>$$\n\\frac{\\partial \\sigma_q^2}{\\partial x_k} = 0\\\\\n\\Rightarrow x_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$</div>\n\n<p>重建电平在量化区间的质心：</p>\n<div>$$\n\\frac{\\partial \\sigma_q^2}{\\partial y_k} = 0\\\\\n\\Rightarrow y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx}\n$$</div>\n\n<p>对于均匀分布，质心即中点（对于可导的概率分布，当分层很密的时候同样成立）</p>\n<div>$$\n y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx} = \\frac{1}{2}(x_{k, opt} + x_{k + 1, opt})\n$$</div>\n\n<p>结合</p>\n<div>$$\nx_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$</div>\n\n<p>可得均匀分布的最佳量化是区间等分，中点重建</p>\n<h4 id=\"工程用量化\"><a href=\"#工程用量化\" class=\"headerlink\" title=\"工程用量化\"></a>工程用量化</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_4.jpg\" loading=\"lazy\"></p>\n<h4 id=\"语音信号的量化\"><a href=\"#语音信号的量化\" class=\"headerlink\" title=\"语音信号的量化\"></a>语音信号的量化</h4><p>$[-V, V]$ 内均匀量化的缺陷：</p>\n<ul>\n<li>最适合 $[-V, V]$ 之间的有限分布</li>\n<li>语音信号呈拉普拉斯分布，特点是：<ul>\n<li>信号功率小</li>\n<li>动态范围大（长拖尾）</li>\n</ul>\n</li>\n<li>如果采用均匀量化<ul>\n<li>较大的V：增大[-V，V]内的量化噪声</li>\n<li>较小的V：增大过载噪声</li>\n</ul>\n</li>\n</ul>\n<p>解决思路1：非均匀量化</p>\n<p><strong>语音信号的非均匀量化</strong></p>\n<p>均匀量化的问题</p>\n<ul>\n<li>对具有不同“概率权重”的区间“一视同仁”</li>\n<li>没有考虑概率密度对于量化噪声的影响</li>\n</ul>\n<p>解决方案</p>\n<ul>\n<li>对于信号经常出现的区域，使用较细的颗粒度进行量化<ul>\n<li>信号经常落入这个区域，减小该区域的量化噪声损失</li>\n</ul>\n</li>\n<li>对于信号不经常出现的区域，使用较粗的颗粒度进行量化<ul>\n<li>信号不经常落入这个区域，量化噪声稍大不会影响大局</li>\n</ul>\n</li>\n</ul>\n<p>采用取对数后均匀量化的方法：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_5.jpg\" loading=\"lazy\"></p>\n<p>语音信号的瞬时压扩：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_6.jpg\" loading=\"lazy\"></p>\n<p><strong>对数量化</strong></p>\n<ul>\n<li>正常量化信噪比与信号的分布无关</li>\n<li>过载导致的噪声与信号的分布有关！</li>\n</ul>\n<p>记 $\\Delta_k$为对数化之前的量化区间, $\\Delta_k^\\prime &#x3D; \\Delta$ 为对数化之后的量化区间</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_9.jpg\" loading=\"lazy\"></p>\n<p><strong>实用的对数量化</strong></p>\n<p>实际工程中，采用另外两个函数（线性放缩，更容易实现）：</p>\n<ul>\n<li>A律（欧洲提出，我国采用）</li>\n</ul>\n<div>$$\nf(x) = \\begin{cases}\n    \\frac{Ax}{1 + \\ln A}, 0 \\le x \\le \\frac{1}{A}\\\\\n    \\frac{1 + \\ln Ax}{1 + \\ln A}, \\frac{1}{A} \\le x \\le 1\\\\\n\\end{cases}\n$$</div>\n\n<ul>\n<li><p>ITU G.712建议中取A＝87.6</p>\n</li>\n<li><p>小信号时，信噪比增加了24dB</p>\n</li>\n<li><p>μ律（美国提出）</p>\n</li>\n</ul>\n<div>$$\nf(x) = \\frac{\\ln (1 + \\mu x)}{\\ln (1 + \\mu)}, 0 \\le x \\le 1\n$$</div>\n\n\n<ul>\n<li>ITU G.712建议中取μ＝255</li>\n<li>小信号时，信噪比增加了33.5dB</li>\n</ul>\n<p><strong>脉冲编码调制(PCM)</strong></p>\n<ul>\n<li>语音信号的实际压缩编码方式</li>\n<li>包括两个主要步骤</li>\n<li>抽样：$f_s &#x3D; 8000Hz$</li>\n<li>量化与编码：使用近似对数压扩，每个抽样量化为8位</li>\n<li>PCM的输出码率为64kbps</li>\n</ul>\n<p><strong>该码率与其推导过程十分重要</strong></p>\n<p><strong>PCM编码协议</strong></p>\n<p>基本思想</p>\n<ul>\n<li>用13折线近似A律</li>\n<li>用15折线近似μ律</li>\n</ul>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_7.jpg\" loading=\"lazy\"></p>\n<p>码字结构：</p>\n<div>$$\n\\mathop{M_1}\\limits_{极性码} \\quad \\underbrace{M_2 \\quad M_3 \\quad M_4}_{段落码}\\quad \\underbrace{M_5 \\quad M_6\\quad M_7 \\quad M_8}_{电平码} \\quad \n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_8.jpg\" loading=\"lazy\"></p>\n<p>例：</p>\n<p>1250的输出：1 110 0011</p>\n<p>接收端解码： 1024 + 128 + 64 + 32 &#x3D; 1248</p>\n<h2 id=\"数字基带传输\"><a href=\"#数字基带传输\" class=\"headerlink\" title=\"数字基带传输\"></a>数字基带传输</h2><h3 id=\"符号映射\"><a href=\"#符号映射\" class=\"headerlink\" title=\"符号映射\"></a>符号映射</h3><p><strong>符号集合</strong></p>\n<p>$M &#x3D; |\\mathcal{A}|$ 为符号集合 $\\mathcal{A}$ 的符号数量。</p>\n<p><strong>bit 承载量</strong><br>每个符号最多可对应 $r &#x3D; \\log_2|\\mathcal{A}|$ 个 bit，称为集合的 bit 承载量</p>\n<p>数字通信的典型符号：</p>\n<ul>\n<li>ASK</li>\n<li>PAM</li>\n<li>PSK</li>\n<li>QAM</li>\n</ul>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_1.jpg\" loading=\"lazy\"></p>\n<p><strong>邻位最小差错映射：Grey 码</strong></p>\n<p>相邻符号对应的 bit 串仅有一位差异</p>\n<p><strong>符号周期（Symbol Period）</strong></p>\n<ul>\n<li>传输一个符号所需的平均时间</li>\n<li>$T_s$</li>\n</ul>\n<p>通信速率：</p>\n<ul>\n<li>符号速率：$R_s &#x3D; \\frac{1}{T_s}$</li>\n<li>Bit 速率： $R_b &#x3D; R_s \\log_2 M &#x3D; \\frac{1}{T_s}\\log_2 M$</li>\n</ul>\n<h3 id=\"数字调制\"><a href=\"#数字调制\" class=\"headerlink\" title=\"数字调制\"></a>数字调制</h3><p>基带调制：将时间上离散的符号，加载到时间上形成连续的波形</p>\n<p>通信信号具有带宽受限特性，因为：</p>\n<ul>\n<li>自然原因：各类通信线路，如双绞线，同轴电缆，射频功放等均对通过的频率有一定限制</li>\n<li>人为原因：多用户频谱共享通信，如蜂窝无线系统，需约束每路信号的带宽，以免相互干扰</li>\n</ul>\n<p>如何产生带限信号？</p>\n<p>产生一个信号 $s(t) &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}a_kg(t- k T_s)$，$g(t) &#x3D; \\frac{\\sin 2\\pi Wt}{2\\pi Wt}$是个带限信号。</p>\n<div>$$\nG(f) = \\begin{cases}\n    1, |f| \\le W,\\\\\n    0, |f| \\gt W\n\\end{cases}\n$$</div>\n\n<p>让间隔 $T_s$ 的冲击 $a_k\\delta(t - kT_s)$ 依次通过冲击响应为 $g(t)$ 的低通滤波器</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_2.jpg\" loading=\"lazy\"></p>\n<h3 id=\"Nyquist-准则：无ISI条件\"><a href=\"#Nyquist-准则：无ISI条件\" class=\"headerlink\" title=\"Nyquist 准则：无ISI条件\"></a>Nyquist 准则：无ISI条件</h3><p><strong>符号间串扰（Inter Symbol Interference, ISI）</strong></p>\n<p>对 $s(t)$ 采样：</p>\n<div>$$\ns(nT_s) = a_ng(0) + \\underbrace{\\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big)}_{\\text{ISI}}\n$$</div>\n\n<p>怎么让 ISI 为0？</p>\n<p><strong>眼图：观察符号间串扰</strong></p>\n<p>眼图（Eye Pattern）是直观察看数字基带传输性能的有效方法，用一个示波器</p>\n<div>$$\n垂直输入 \\xrightarrow{接} 匹配滤波器的输出\\\\\n水平扫描速度 \\xrightarrow{设为} 𝑅_𝑠的整数倍\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_3.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>眼皮的厚度表示 ISI 的失真，眼睛的张开程度表示噪声容限。</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_4.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>消除 ISI 对带限脉冲的要求</p>\n<p>时域特征：</p>\n<div>$$\n\\left.\\begin{align*}\n    g(0) &= 1\\\\\n    \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big) &= 0\n\\end{align*}\\right\\rbrace \\Leftrightarrow \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_{n - k}g\\big(kT_s\\big) = 0\\\\\n\\Leftrightarrow g(kT_s) = \\begin{cases}\n    1, k = 0,\\\\\n    0, k \\ne 0\n\\end{cases} \\\\\n\\lrArr g(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t)\n$$</div>\n\n<p>从频域提取特征：</p>\n<div>$$\ng(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t) \\lrArr G(f) *\\sum\\limits_{n=-\\infty}^{\\infty}\\frac{1}{T_s}\\delta(f + \\frac{n}{T_s}) = 1\\\\\n\\lrArr \\sum\\limits_{n=-\\infty}^{\\infty}G\\left(f + \\frac{n}{T_s}\\right) = T_s\n$$</div>\n\n<p><strong>Nyquist 准则</strong></p>\n<p>将带限脉冲的频谱分别平移 $n&#x2F;T_s$（ $n$ 为任意整数）若其叠加的结果对任意频率恒为定值，则 ISI 为0</p>\n<h3 id=\"通信速率与带宽效率\"><a href=\"#通信速率与带宽效率\" class=\"headerlink\" title=\"通信速率与带宽效率\"></a>通信速率与带宽效率</h3><p><strong>理解 Nyquist 准则</strong></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_5.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_6.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<ul>\n<li>最大符号速率受制于带宽 $R_s &#x3D; \\frac{1}{T_s} \\le 2W$</li>\n<li>低通发送滤波器应该满足残留对称条件</li>\n</ul>\n<p><strong>通信速率与带宽效率</strong></p>\n<div>$$\nR_s \\le 2W\\\\\nR_b = R_s \\log_2 M\\\\\n\\Rightarrow R_b \\le 2W \\log_2 M\n$$</div>\n\n<ul>\n<li>针对给定形式的低通滤波器，可写出$R_s$与$W$之间的线性函数关系</li>\n</ul>\n<p><strong>信号功率与带宽效率</strong></p>\n<p>设单个符号的能量为 $E_s$</p>\n<p>则信号功率为单位时间内的能量</p>\n<div>$$\nP = \\frac{E_s}{T_s} = E_sR_s\n$$</div>\n\n<p>无冗余编码时，一个比特的能量为$𝐸_𝑏$，则</p>\n<div>$$\nP = \\frac{E_b\\log_2 M}{T_s} = E_bR_b\n$$</div>\n\n<p>带宽效率的定义：单位带宽承载的速率</p>\n<div>$$\n\\eta = \\frac{R_b}{W} \\le 2\\log_2 M\n$$</div>\n\n\n<ul>\n<li>为什么不能无限制扩大符号集合？</li>\n</ul>\n<p>过大的符号集合对信噪比有更高的要求，噪声容易干扰符号的分辨</p>\n<h3 id=\"升余弦滤波器\"><a href=\"#升余弦滤波器\" class=\"headerlink\" title=\"升余弦滤波器\"></a>升余弦滤波器</h3><p><strong>升余弦滤波器</strong></p>\n<p>由于理想滤波器难以实现，所以常用满足残留对称条件的非理想低通生成基带脉冲，最常用的就是升余弦滤波器</p>\n<p>Raised Cosine(要记住)</p>\n<div>$$\nH(f) = \\begin{cases}\n    T_s, &0 \\le |f| \\lt \\frac{1 - \\alpha}{2 T_s}\\\\\n    \\frac{T_s}{2}\\left\\lbrace1 + \\cos \\left[\\frac{\\pi T_s}{\\alpha}\\left(|f| - \\frac{1 - \\alpha}{2T_s}\\right)\\right]\\right\\rbrace, &\\frac{1 - \\alpha}{2 T_s} \\le |f| \\le \\frac{1 + \\alpha}{2 T_s}\\\\\n    0, & |f| \\gt \\frac{1 + \\alpha}{2 T_s}\n\\end{cases}\n$$</div>\n\n<p>$\\alpha &#x3D; 2WT_s - 1 \\in [0, 1]$ 称为滚降系数，越小坡越陡，越大坡越缓。</p>\n<p>时域冲激响应：</p>\n<div>$$\nh(t) = \\text{Sa}(\\pi t/ T_s)\\frac{\\cos (\\alpha\\pi t/ T_s)}{1 - 4(\\alpha t/T_s)^2}\n$$</div>\n\n<p>升余弦滤波器的性质：</p>\n<p><font color=\"red\">常考性质：</font></p>\n<div>$$\nW = \\frac{\\alpha + 1}{2T_s} = \\frac{\\alpha + 1}{2}R_s \\Rightarrow R_s/2 \\le W \\le R_s\\\\\nR_s = \\frac{1}{T_s} = \\frac{2}{\\alpha + 1} W \\Rightarrow W \\le R_s \\le 2W\n$$</div>\n\n<p>带宽效率</p>\n<div>$$\n\\eta_b = \\frac{R_s\\log_2|\\mathcal{S}|}{W} \\le 2\\log_2|\\mathcal S|\n$$</div>\n\n<p>升余弦滤波器的带宽效率</p>\n<div>$$\n\\eta_b = \\frac{2\\log_2|\\mathcal{S}|}{\\alpha + 1}\n$$</div>\n\n<p>PCM 语言信号速率 64kbps：8 bit 采样，8 bit 量化，8*8 &#x3D; 64.</p>\n<p>例题一：传送一路PCM语音信号</p>\n<ul>\n<li>若带宽限制为40kHz，采用二元码，则可用滚降系数范围<br>是多少？</li>\n<li>若采用四元码，最多需要多少带宽？</li>\n</ul>\n<p>解：PCM语音信号是64kbps</p>\n<ul>\n<li>采用二元码，则所需符号速率为 $R_s &#x3D; R_b &#x3D; 64kbps$</li>\n</ul>\n<ul>\n<li><p>则 $\\frac{\\alpha + 1}{2}64 \\le 40$, $0\\le \\alpha \\le 0.25$</p>\n</li>\n<li><p>采用四元码：$R_s &#x3D; \\frac{R_b}{\\log_24} &#x3D; 32kbps$</p>\n</li>\n<li><p>$W \\le R_s &#x3D; 32kHz$</p>\n</li>\n</ul>\n<p>例题二：若传送一路信号$𝑅_𝑏$ &#x3D; 112kbps，信道带宽𝑊 &#x3D; 30𝑘bps,<br>求𝑀和𝛼</p>\n<div>$$\n\\frac{\\log_2M}{\\alpha} = \\frac{R_b}{2W} = \\frac{28}{15} \\in [1.5, 2]\\\\\n$$</div>\n\n<p>认定 $\\log_2M &#x3D; k$ 为整数，则$k &#x3D; 2 或 3$。对应可解：</p>\n<div>$$\n\\alpha_1 = \\frac{1}{14}, M_1 = 4\\\\\n\\alpha_2 = \\frac{17}{28}, M_2 = 8\n$$</div>\n\n<h3 id=\"通信信号的功率谱计算\"><a href=\"#通信信号的功率谱计算\" class=\"headerlink\" title=\"通信信号的功率谱计算\"></a>通信信号的功率谱计算</h3><p>功率谱刻画了随机过程的功率在频域上的分布。</p>\n<ul>\n<li>对于宽平稳过程（自相关只与时差有关），功率谱易于从 $R(\\tau)$ 的傅里叶变换得到，即$S(f) &#x3D; \\mathcal{F}[R(\\tau)]$</li>\n<li>但是，通信信号一般不是宽平稳过程，而是周期平稳过程：$R(t_1, t_2) &#x3D; R(t_1 + kT_s, t_2 + kT_s)$</li>\n</ul>\n<p>定义 </p>\n<div>$$\n\\overline{R}(\\tau) = \\frac{1}{T_s} \\int_{0}^{T_s}R(t+\\tau, t)\\mathrm dt\n$$</div>\n\n<p>则其功率谱</p>\n<div>$$\nS(f) = \\mathcal{F}[\\overline{R}(\\tau)]\n$$</div>\n\n<p>若输入信号的功率谱 $S_{AI}(f)$，输出为$S_A(f)$，则对于宽平稳和周期平稳信号均有卷积关系：</p>\n<div>$$\nS_A(f) = S_{AI}(f)|H(f)|^2\n$$</div>\n\n<p>证明可以采用样本统计法：假设符号序列的长度为 $2N - 1$.</p>\n<div>$$\ns_{AI}(t) =\\sum\\limits_{k=-N}^{N}a_k\\delta(t - k T_s)\\\\\ns_{A}(t) =\\sum\\limits_{k=-N}^{N}a_kh(t - k T_s)\\\\\n\\hat s_{AI}(f) =\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\\\\\n\\hat s_{A}(f) = H(f)\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\n$$</div>\n\n<p>功率谱的定义：</p>\n<div>$$\nS(f) = \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat s(f)|^2)}{(2N + 1)T_s}\n$$</div>\n\n<p>可以验证 $S_A(f) &#x3D; S_{AI}(f)|H(f)|^2$</p>\n<p>针对样本统计法，可以算出 $E(|\\cdot|^2)$的表达式：</p>\n<div>$$\nS_A(f) = \\frac{|H(f)|^2}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f)\n$$</div>\n\n<p>这里$R_a[m]$ 是输入符号的自相关。</p>\n<p>先考虑无记忆调制，符号之间相互独立：</p>\n<div>$$\nR_a[n] = E[a_ia_{i+n}] = \\begin{cases}\n    \\sigma_a^2+m_a^2 &n=0\\\\\n    m_a^2 &n\\ne 0\n\\end{cases}\n$$</div>\n\n<p>其中，$m_a &#x3D; E[a_n]$，$\\sigma_a^2 &#x3D; E[a_n^2] - m_a^2$</p>\n<p>于是，重写累加部分：</p>\n<div>$$\n\\begin{align*}\n    &\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f) \\\\\n    =& \\sigma_a^2 + m_a^2\\sum\\limits_{n=-\\infty}^{\\infty}\\exp\\big[-jn(2\\pi T_s)f\\big]\\\\\n    =& \\sigma_a^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\delta\\bigg(f - \\frac{n}{T_s}\\bigg)\n\\end{align*}\n$$</div>\n\n<p>从而</p>\n<div>$$\nS_A(f) = \\underbrace{\\frac{\\sigma_a^2}{T_s}|H(f)|^2}_{连续谱} + \\underbrace{\\frac{m_a^2}{T_s^2}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|H\\bigg(\\frac{n}{T_s}\\bigg)\\bigg|^2 \\delta\\bigg(f - \\frac{n}{T_s}\\bigg)}_{线谱}\n$$</div>\n\n<p>此式应用的两个条件：</p>\n<ul>\n<li>无记忆</li>\n<li>不同符号波形一致</li>\n</ul>\n<p>线谱：可用于定时恢复。方便恢复时钟分量。</p>\n<p><strong>任意波形调制</strong></p>\n<p>之前将 $a_i$ 映射为 $a_ih(t)$，可以推广：</p>\n<div>$$\n\\forall a_i \\ne a_j, s_i(t) \\ne s_j(t)\n$$</div>\n\n<p>有时候由于信号功率需要保持稳定（恒包络调制），对不同符号采用不同波形，而不是采用变化幅度的信号。</p>\n<p>若任意波形二元调制信号 $s(t) &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}g_k(t)$</p>\n<div>$$\ng_k(t) = \\begin{cases}\n    s_1(t - kT_s), w.p.\\ p\\\\\n    s_2(t - kT_s), w.p.\\ \\bar p = 1 - p\n\\end{cases}\n$$</div>\n\n<p>(w. p. &#x3D; with probability)</p>\n<p>分解为直流分量和交流分量：</p>\n<div>$$\ns(t) = \\underbrace{E(s(t))}_{DC,记为v(t)} + \\underbrace{s(t) - E(s(t))}_{AC, 记q(t)}\n$$</div>\n\n<p>则</p>\n<div>$$\nv(t) = \\sum\\limits_{k=-\\infty}^{\\infty}[ps_1(t - kT_s) + \\bar p s_2(t - kT_s)]\n$$</div>\n\n<p>这是一个周期为$𝑇_𝑠$的确定性周期信号，功率谱由傅里叶展开计算</p>\n<div>$$\nS_v(f) =\\sum\\limits_{n=-\\infty}^{\\infty}|D_n|^2\\delta(f - \\frac{n}{T_s})\\\\\nD_n = \\frac{1}{T_s}\\int_{-T_s/2}^{T_s/2}v(t)e^{-j2\\pi t/T_s}\\mathrm dt = \\frac{1}{T_s}\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\n$$</div>\n\n<div>$$\nS_v(f) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$</div>\n\n<p>用样本统计法计算 $S_q(f)$：</p>\n<div>$$\n\\begin{align*}\n    S_q(f) =& \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat q_N(f)|^2)}{(2N + 1)T_s}\\\\\n    =& \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2\n\\end{align*}\n$$</div>\n\n<div>$$\nS(f) = \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$</div>\n\n<h3 id=\"基带解调\"><a href=\"#基带解调\" class=\"headerlink\" title=\"基带解调\"></a>基带解调</h3><p>最佳接收用于在给定发送功率下提高信噪比</p>\n<p>最佳判决用于在给定信噪比下降低误码率</p>\n<h4 id=\"基带传输的噪声模型\"><a href=\"#基带传输的噪声模型\" class=\"headerlink\" title=\"基带传输的噪声模型\"></a>基带传输的噪声模型</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_1.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>如何选择解调方案？</p>\n<p><strong>方案一：直接抽样</strong></p>\n<p>在信号的峰值位置 $t &#x3D; kT_s$ 抽样最好。</p>\n<p>但噪声方差满足：</p>\n<div>$$\n\\sigma^2 = E \\lbrace n^2(t_1) \\rbrace = R(0) = \\frac{n_0}{2}\\delta(0) \\rightarrow \\infty\n$$</div>\n\n<p>（理想的白噪声信号具有无穷大功率）</p>\n<p>真实的噪声环境下，接收信号质量随着噪声信号功率的增加而变差。如果信号的峰值处恰好噪声很大，则产生严重失真。</p>\n<p><strong>方案二：能量累积</strong></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_2.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>噪声信号仍为高斯随机变量：</p>\n<div>$$\nn = \\int_{0}^{T_s}n(t)\\mathrm dt\n$$</div>\n\n<p>噪声方差：</p>\n<div>$$\n\\sigma^2 = E\\lbrace n^2 \\rbrace = \\int_{0}^{T_s}\\int_{0}^{T_s}\\frac{n_0}{2}\\delta(t_1 - t_2)\\mathrm dt_1\\mathrm dt_2 = \\frac{n_0T_s}{2}\n$$</div>\n\n<p>信噪比：</p>\n<div>$$\n\\frac{S}{N} = \\frac{\\left (\\int_{0}^{T_s}a_i h(t)\\mathrm dt \\right)^2}{T_sn_0/2}\n$$</div>\n\n<p>直接积分不是最好的方案。</p>\n<p><strong>方案三：匹配滤波</strong></p>\n<p>匹配滤波的基本思想就是对接收值进行加权线性累加，从而最大化抽样时刻信号功率与噪声功率的比值。</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_3.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>相关器为 $g(t)$。假设信号为实信号。复信号有类似结论。</p>\n<div>$$\nP_S = \\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2\\\\\nP_N = \\mathbf E \\left [ \\left | \\int_{0}^{T_s}n(t)g(t)\\mathrm dt \\right|^2 \\right] = \\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt\n$$</div>\n\n<p>利用 Cauchy-Schwartz 不等式：</p>\n<div>$$\n\\frac{\\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2}{\\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt} \\le \\frac{2}{n_0}\\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt\n$$</div>\n\n<p>等号成立当且仅当 $g(t) &#x3D; kh(t)$。</p>\n<p>若为复信号，则需要</p>\n<div>$$\ng(t) = h^*(t)\n$$</div>\n\n<p>如何把相关器写成滤波器形式？</p>\n<p>（滤波&#x3D;卷积，相关和卷积就是差一个反褶的关系）</p>\n<div>$$\ny(t) = [a_ih(t) + n(t)] * h_m(t) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(t - \\tau)\\mathrm d\\tau\n$$</div>\n\n<p>考虑因果系统，一般将符号波形的最高点设置为 $t &#x3D; T_s$：</p>\n<div>$$\ny(T_s) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(T_s - \\tau)\\mathrm d\\tau\n$$</div>\n\n<p>与相关器比较得到匹配滤波器的表达式：</p>\n<div>$$\nh_m(t) = h(T_s - t)\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_4.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>图中的“开关”是抽样。</p>\n<p>匹配滤波的频域解释：</p>\n<div>$$\nP_S = \\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2\\\\\nP_N = \\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df\\\\\n\\frac{S}{N} = \\frac{\\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2}{\\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df} = \\frac{2}{n_0}\\int_{-\\infty}^{\\infty}|H(f)|^2\\mathrm df\n$$</div>\n\n<p>Cauchy-Schwartz</p>\n<div>$$\nH_m(f) = H^*(f)e^{-j2\\pi fT_s}\n$$</div>\n\n<p><strong>匹配滤波的增益</strong></p>\n<p>数字传输的优势：数字传输中，基带脉冲h(t)是给定的，在整个码元周期内可以相干累加，而同时让噪声在整个周期内自我抵消</p>\n<div>$$\n\\left (\\frac{S}{N}  \\right)_{\\text{match}} \\bigg/ \\left (\\frac{S}{N}  \\right)_{\\text{w.o.match}} = \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\left ( \\int_{0}^{T_s}h(t)\\mathrm dt \\right)^2} \\ge \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\int_{0}^{T_s}1\\mathrm dt\\int_{0}^{T_s}h^2(t)\\mathrm dt} = 1\n$$</div>\n\n<p>匹配滤波的信噪比</p>\n<div>$$\n\\frac{S}{N} = E \\left [ \\frac{2}{n_0} \\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt \\right] = \\frac{\\int_{0}^{T_s}E[a_i^2]h^2(t)\\mathrm dt}{n_0/2} = \\frac{E_s}{n_0 / 2}\n$$</div>\n\n<p>分子——传送一个符号的能量</p>\n<p>分母——噪声谱密度，单位是能量的单位</p>\n<p>以上采用的是等效基带模型。采用实际物理波形模型：</p>\n<div>$$\nS = \\frac{E_s}{T_s} = E_sR_s\\\\\nN = Wn_0\\\\\n\\frac{S}{N} = \\frac{E_s}{n_0}\\frac{R_s}{W}\\\\\n$$</div>\n\n<p>两个模型推得的信噪比表达式不同，差异在于等效基带模型使用了匹配滤波器，获得了最优的信噪比：</p>\n<div>$$\n\\frac{R_s}{W} \\le 2 \\Rightarrow\\left (\\frac{S}{N}  \\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\n$$</div>\n\n<p>从实际物理波形模型来看，上式取等的条件应该是基带脉冲采用的是理想低通（Sa 函数），如果用升余弦滤波</p>\n<div>$$\n\\frac{R_s}{W} = \\frac{2}{\\alpha + 1} \\Rightarrow \\left(\\frac{S}{N}\\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\\frac{2}{\\alpha + 1}\n$$</div>\n\n<p>但是，在等效基带模型中，我们考虑的是任意脉冲 $h(t)$，并没有要求它的形状，这两个模型在最优信噪比的产生条件上出现了矛盾？</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_5.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_6.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"传送一串符号\"><a href=\"#传送一串符号\" class=\"headerlink\" title=\"传送一串符号\"></a>传送一串符号</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_7.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>无 ISI 条件：</p>\n<div>$$\nh(t)*h_m(t) = h(t) * h(T_s - t)\\\\\nH(f)H_m(f) = H(f)H^*(f)e^{-j2\\pi fT_s} = \\left | H(f) \\right|^2 e^{-j2\\pi fT_s} \n$$</div>\n\n<p>从而有根号奈奎斯特条件：</p>\n<div>$$\nH(f) = \\sqrt{H_{N-I}(f)}e^{-j2\\pi fT_s} \nH_m(f) = \\sqrt{H_{N-I}^*(f)}e^{-j2\\pi fT_s} \n$$</div>\n\n<p>这就要求发送和接受滤波器要满足如下要求：</p>\n<div>$$\nh_T(t) = h_{\\sqrt{N}}\\left ( t - \\frac{T_s}{2} \\right)\\\\\nh_R(t) = h_{\\sqrt{N}}\\left (\\frac{T_s}{2}  - t\\right) = h_T(T_s - t)\n$$</div>\n\n<h4 id=\"符号差错模型：\"><a href=\"#符号差错模型：\" class=\"headerlink\" title=\"符号差错模型：\"></a>符号差错模型：</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_8.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<div>$$\ny_i = \\bar h a_i + n_i\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_9.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h3 id=\"判决与差错\"><a href=\"#判决与差错\" class=\"headerlink\" title=\"判决与差错\"></a>判决与差错</h3><h3 id=\"最佳判决\"><a href=\"#最佳判决\" class=\"headerlink\" title=\"最佳判决\"></a>最佳判决</h3><p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_2.jpg\" alt=\"ima\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_1.jpg\" alt=\"ima\" loading=\"lazy\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_3.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>多元符号的最佳判决</p>\n<div>$$\na^* = \\argmax_{a\\in U} f(y|a)f(a)\\\\\nf(a) = \\frac{1}{M}\\\\\na^* = \\argmax_{a\\in U} f(y|a)\\\\\n$$</div>\n\n<p>$y &#x3D; a + n$ 的条件分布是</p>\n<div>$$\nf(y|a) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y - a)^2}{2\\sigma^2}\\right)\n$$</div>\n\n<p>从而得到</p>\n<div>$$\na^* = \\argmin_{a\\in U} |y - a|\n$$</div>\n\n<p>选择一个符号，让它到接收符号y距离最小，以此作为判决结果！</p>\n<p>双极性码的判决门限：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_4.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>单极性码的判决门限:</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_6.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<h4 id=\"SER-amp-BER\"><a href=\"#SER-amp-BER\" class=\"headerlink\" title=\"SER &amp; BER\"></a>SER &amp; BER</h4><p>考虑二元符号</p>\n<p>发送 A 的出错概率：</p>\n<div>$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = \\int_{A/\\sigma}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}\\exp \\left ( -\\frac{t^2}{2} \\right)\\mathrm dt = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>发送 -A 的出错概率：</p>\n<div>$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>从而平均符号差错概率：</p>\n<div>$$\nP_s = \\frac{1}{2}\\left (Q \\left ( \\frac{A}{\\sigma} \\right) + Q \\left ( \\frac{A}{\\sigma} \\right)  \\right) = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>称为符号差错概率(Symbor Error Probability, SEP)，其统计结果称为误符号率（Symbol Error Ratio, SER）</p>\n<p>由于Q是减函数，所以误符号率随A增大而减小，随噪声标准差增大而增大</p>\n<p>误符号率不关心具体的A或标准差，而是由其比值所决定</p>\n<p>对于多元而言：</p>\n<p>对于任意符号集合，只要某判决门限与符号距离为A，则由于超出该判决门限而差错的条件概率就是：</p>\n<div>$$\nQ \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>计算信噪比：</p>\n<p>信号平均功率： $S &#x3D; \\frac{1}{M}\\sum\\limits_{i&#x3D;1}^{M}|a_i|^2$</p>\n<p>信号峰值功率： $S_p &#x3D; \\max_{a_i \\in U} |a_i|^2$</p>\n<p>噪声功率： $N &#x3D; \\sigma^2$</p>\n<p>对于双极性二元符号，平均功率为 $S &#x3D; A^2$</p>\n<p>从而信噪比为 </p>\n<div>$$\n\\frac{S}{N} = \\frac{A^2}{\\sigma^2}\n$$</div>\n\n<p>利用等效关系得到误符号率和信噪比的关系</p>\n<div>$$\nP_s = Q \\left ( \\frac{A}{\\sigma} \\right) = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$</div>\n\n<p>更一般的二元码 SER</p>\n<div>$$\nU = \\lbrace D-A, D+A \\rbrace\\\\\n\\zeta = \\frac{D}{A}\\\\\nP_s = Q(\\sqrt{\\frac{S}{(1 + \\zeta^2)N}})\n$$</div>\n\n<p>更一般的 M 元码 SER</p>\n<p>符号集合为 $\\lbrace D - (M - 1)A, \\dots, D + (M  - 1)A \\rbrace$</p>\n<div>$$\n\\zeta = \\frac{D}{A\\sqrt{\\frac{M^2 - 1}{3}}}\\\\\nP_s = \\frac{2(M - 1)}{M}Q \\left ( \\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{(1 + \\zeta^2)N}} \\right)\n$$</div>\n\n<p>双极性 M 元码的 SER (掌握计算方法)</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{M^2 - 1} \\frac{S}{N}}\\right)\n$$</div>\n\n<p>无论M为奇数还是偶数，结果都是一样的！</p>\n<p>单极性 M 元码的 SER (掌握计算方法)</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$</div>\n\n\n<p>要使得双极性和单极性码的 SER 相同，二者的信噪比的比值为</p>\n<div>$$\n\\left ( \\frac{S}{N} \\right)_d \\bigg / \\left ( \\frac{S}{N} \\right)_s = \\frac{M^2 - 1}{2(M - 1)(2M  - 1)} \\approx \\frac{1}{4}\n$$</div>\n\n<p>显然，双极性的性能更好，它对信噪比的要求是单极性的四分之一，更能忍受噪声。</p>\n<p>误比特率(Bit Error Rate, BER)：</p>\n<div>$$\nP_b \\approx \\frac{P_s}{\\log_2M}\n$$</div>\n\n<p>注意这是近似结果，且有成立条件，只对二元码是严格成立的！</p>\n<ul>\n<li>假设一个符号的错判导致 1bit 的错误，假设成立的条件：<ul>\n<li>Grey 码映射</li>\n<li>信噪比不过于小</li>\n</ul>\n</li>\n</ul>\n<p>各类符号集合的 BER</p>\n<p>双极性二元码</p>\n<div>$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$</div>\n\n<p>单极性二元码</p>\n<div>$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{2N}} \\right)\n$$</div>\n\n<p>单极性二元码损失了 3 dB.</p>\n<p>双极性 M 元码</p>\n<div>$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{N}})\n$$</div>\n\n<p>单极性 M 元码</p>\n<div>$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$</div>\n\n<p>由于</p>\n<div>$$\n\\frac{S}{N} = 2\\log_2 M\\frac{E_b}{n_0}\n$$</div>\n\n<p>故可以把 SER 和 BER 用 $E_b&#x2F;n_0$ 表示：</p>\n<p>双极性二元码：</p>\n<div>$$\nP_s = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\n$$</div>\n\n<p>单极性二元码：</p>\n<div>$$\nP_s = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\n$$</div>\n\n<p>双极性 M 元码：</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\n$$</div>\n\n<p>单极性 M 元码：</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\n$$</div>\n\n<p>例子：相移键控 MPSK</p>\n<div>$$\n\\begin{align*}\n    S_{MPSK}(t) =& \\sum\\limits_{n}^{}g(t - nT_s)A\\cos(\\omega_c t + \\phi_n)\\\\\n    =& \\left [\\sum\\limits_{n}^{}A\\cos \\phi_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}A\\sin \\phi_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$</div>\n\n<ul>\n<li>所有符号的模相同</li>\n<li>幅角在 $[0, 2\\pi]$ 均匀分布</li>\n</ul>\n<p>可以用星座图表示：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_5.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>根据信号的 $I, Q$ 表示</p>\n<p>计算 MPSK 的 SER:</p>\n<p>考虑星座点 $(A, 0)$</p>\n<p>接收信号的分布函数为</p>\n<div>$$\nf(a, b) - \\frac{1}{2\\pi \\sigma_n^2}\\exp \\left ( -\\frac{(a - A)^2 + b^2}{2\\sigma_n^2} \\right)\n$$</div>\n\n<p>变换到极坐标系</p>\n<div>$$\nf(\\rho, \\theta) = \\frac{\\rho}{2\\pi\\sigma_n^2}\\exp \\left ( -\\frac{\\rho^2 + A^2 - 2A\\rho\\cos\\theta}{2\\sigma_n^2} \\right)\\\\\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{A^2}{2\\sigma_n^2}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - A/\\sigma_n\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$</div>\n\n<p>误符号率可以表示为</p>\n<div>$$\nP_{s, MPSK} = 1 - \\int_{-\\pi/M}^{\\pi/M}f(\\theta)\\mathrm d\\theta\n$$</div>\n\n<p>用信噪比表示：</p>\n<div>$$\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$</div>\n\n<p>如果 $S&#x2F;N$ 很大：</p>\n<div>$$\n\\begin{align*}\n    \\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho \\approx& \\int_{-\\infty}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\\\\\n    =& \\sqrt{\\frac{S}{N}}\\cos\\theta\n\\end{align*}\n$$</div>\n\n<p>利用高信噪比近似：</p>\n<div>$$\nf(\\theta) = \\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\n$$</div>\n\n<p>当 M 比较大时：</p>\n<div>$$\n\\begin{align*}\n    P_{s, MPSK} =& 1 - \\int_{-\\pi/M}^{\\pi/M}\\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    \\approx& \\frac{2}{\\sqrt{\\pi}}\\int_{\\pi/M}^{\\infty}\\sqrt{\\frac{S}{2N}}\\cos\\theta\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}}\\int_{\\pi/M}^{\\infty}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\sqrt{\\frac{S}{N}}\\sin\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}} \\int_{\\sqrt{S/N}\\sin\\pi/M}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\mathrm du\\\\\n    =& 2Q \\left ( \\sqrt{\\frac{S}{N}}\\sin\\frac{\\pi}{M} \\right)\n\\end{align*}\n$$</div>\n\n<p>换算成 BER， $E_b&#x2F;n_0$</p>\n<div>$$\nP_{b, MPSK} = \\frac{2}{\\log_2M}Q \\left ( \\sqrt{2\\log_2M\\frac{E_b}{n_0}}\\sin\\frac{\\pi}{M} \\right)\n$$</div>\n\n<p>一个简单的方法：</p>\n<p>看起来像是先射箭后画靶。</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_7.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>例子2：正交幅度调制 QAM</p>\n<p>信号表示</p>\n<div>$$\n\\begin{align*}\n    S_{MQAM}(t) =& \\left [\\sum\\limits_{n}^{}a_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}b_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$</div>\n\n<p>I,Q 两路的电平集合：</p>\n<div>$$\na_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\nb_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\n$$</div>\n\n<p>QAM是一种典型的星座图，它分布于复平面的格点上，其符号的实虚部均为奇数（便于分析）</p>\n<p>解调过程：</p>\n<p>I 路信息提取：乘以同相载波 $\\cos\\omega_c t$，再低通滤波</p>\n<p>Q 路信息提取：乘以同相载波 $-\\sin\\omega_c t$，再低通滤波</p>\n<p>差错分析：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_8.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>（通过后面的分析可以发现，降低误码率的关键是将符号间的最小距离最大化）</p>\n<p>计算各符号的差错概率：</p>\n<p>四个角：</p>\n<div>$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$</div>\n\n<p>$4(L - 2)$ 个边点：</p>\n<div>$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\n$$</div>\n\n<p>$(L - 2)^2$ 个内点：</p>\n<div>$$\nP_s = 1 - \\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$</div>\n\n<p>计算平均 SEP：</p>\n<div>$$\n\\begin{align*}\n    P_s =& \\frac{1}{L^2}\\lbrace 4(2Q - Q^2) + 4(L - 2)(3Q - 2Q^2) + (L - 2)^2(4Q - 4Q^2) \\rbrace\\\\\n    \\approx& \\frac{4L^2 - 4L}{L^2}Q \\left ( \\frac{A}{\\sigma_n} \\right)\n\\end{align*}\n$$</div>\n\n<p>省略了 $Q$ 的高阶量。</p>\n<p>计算平均功率：</p>\n<div>$$\nS = 2 \\times \\frac{2A^2}{L}[1^2 + 3^2 + \\dots + (L - 1)^2] = \\frac{2(L^2 - 1)}{3}A^2\n$$</div>\n\n<p>是同A的LPAM功率的两倍。因为MQAM有两路LPAM</p>\n<p>得到 SEP：</p>\n<div>$$\nP_s = \\frac{4M - 4L}{M} Q \\left (\\sqrt{\\frac{3}{2(M - 1)}\\frac{S}{N}}  \\right)\\\\\nM = L^2\n$$</div>\n\n<p>得到 BEP：</p>\n<div>$$\nP_b = 4 \\left (1 - \\frac{1}{\\sqrt M}  \\right) Q \\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right) \\approx 4Q\\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right)\\\\\n$$</div>\n\n<p>注意到MQAM可以看成两路正交的MPAM</p>\n<div>$$\n\\begin{align*}\n    P_{s, MQAM} =& 1 - (1 - P_{LPAM})^2\\\\\n    \\approx& 2P_{LPAM}\\\\\n    =& 4 \\left ( 1 - \\frac{1}{\\sqrt M} \\right)Q \\left ( \\sqrt{\\frac{3}{(M - 1)}\\frac{S/2}{N}} \\right)\n\\end{align*}\n$$</div>\n\n<p>这个推导方式更简单。</p>\n<p>QAM 是在独立解映射条件下最好的方案。但是距离高斯信道容量还有一定距离。要达到更好的信道容量，可以采用联合解映射，将译码过程联合起来。</p>\n<p>例子3：频移键控 FSK</p>\n<p>一般来说，信号表达式和调制框图的相互反演是比较容易做的</p>\n<p>相对于PAM，PSK和QAM，FSK占用更大的频带，</p>\n<p>相干解调</p>\n<p>Coherent Demodulation</p>\n<ul>\n<li><p>反思FSK非相干解调方式，如果对每个频率的载波进行匹配，则可以提高信噪比</p>\n</li>\n<li><p>这种方法需要本地子载波</p>\n</li>\n<li><p>解调器的结构和非相干解调很像</p>\n</li>\n<li><p>无法用星座图方法表示，但是可以用类似的信号空间表示</p>\n</li>\n<li><p>若MFSK载频等间隔，则调制阶数约高，占用带宽越大</p>\n</li>\n<li><p>如果每次可以选择多个载频，甚至控制载频幅度，则可承载的符号量可以获得极大提升。由此便引申出OFDM技术</p>\n</li>\n</ul>\n<ul>\n<li>通过调制FSK的每个载波的幅度相位，可以承载更多的信息</li>\n</ul>\n<p>星座图没法表述 FSK. 可以使用信号空间方法来表示。</p>\n<p>差错分析：</p>\n<p>FSK 的判决门限为棱锥形状：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_9.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>根据对称性，可以只考虑一个符号的差错概率。</p>\n<p>考虑 FSK 信号</p>\n<div>$$\n[A, 0, \\dots, 0]\n$$</div>\n\n<p>匹配滤波的输出为</p>\n<div>$$\n[A + n_1, n_2, \\dots, n_M]\n$$</div>\n\n<p>正确判决：信号落在本棱锥中</p>\n<div>$$\nA + n_1 \\gt n_i, i = 2, \\dots, M\n$$</div>\n\n<p>被判决符号的条件分布为</p>\n<div>$$\nf_{[A + n_1, n_2, \\dots, n_M]}(\\vec r) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\n$$</div>\n\n<p>不满足正确判决条件的概率为</p>\n<div>$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M \\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i\\mathrm dr_1\\\\\n    =&1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\left (\\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i  \\right)^{M - 1}\\mathrm dr_1\n\\end{align*}\n$$</div>\n\n<p>记 $x &#x3D; \\frac{r_1}{\\sigma}$</p>\n<div>$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi }}\\exp \\left ( -\\frac{(x - A/\\sigma)^2}{2} \\right)\\left (1 - Q(x)\\right)^{M - 1}\\mathrm dx\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\frac{A}{\\sigma}  \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$</div>\n\n<div>$$\n\\frac{A}{\\sigma} = \\sqrt{\\frac{S}{N}} = \\sqrt{\\log_2M\\frac{2E_b}{n_0}}\n$$</div>\n\n<p>可得 SEP 的表达式</p>\n<div>$$\n\\begin{align*}\n    P_s =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\frac{S}{N}} \\right)\\right)^{M - 1}\\mathrm du\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\log_2M\\frac{2E_b}{n_0}} \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$</div>\n\n<p>另一种简单估界：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_10.jpg\" alt=\"alt\" loading=\"lazy\"></p>\n<p>正交 2FSK 信号在最佳接收条件时的错误概率为</p>\n<div>$$\nP_{b,NCFSK} = Q(\\sqrt{E_b/n_0})\n$$</div>\n\n<p>随着 M 的增加，MFSK 的差错性能渐优，这是以带宽的占用为代价的。</p>\n<p>PAM, QAM, ASK 等技术随着符号个数的增加，差错性能是越来越差。</p>\n<p>FDM——Frequency Division Multiplexing</p>\n<ul>\n<li>先将各路信号调制到不同频段，然后复用整个<br>通信带宽</li>\n<li>信道的非线性会在FDM系统中产生交调失真与<br>高次谐波，引起路际串话，因此，对信道的非<br>线性失真要求很高。此外，FDM用到的模拟滤<br>波器设计较为复杂。</li>\n</ul>\n<h4 id=\"OFDM-基本原理\"><a href=\"#OFDM-基本原理\" class=\"headerlink\" title=\"OFDM 基本原理\"></a>OFDM 基本原理</h4><p>Orthogonal Frequency division multiplexing</p>\n<ul>\n<li>把一串高速数据流分解为若干速率低得多的子数据流。</li>\n<li>将每个子数据流放置在对应的子载波上。</li>\n<li>将多个子载波合成，一起并行传输。</li>\n<li>优点：频谱利用率高。</li>\n</ul>\n<p>正交性的定义：</p>\n<div>$$\n\\int_{0}^{T}S_1(t)S_2(t)\\mathrm dt = 0\n$$</div>\n\n<p>设相邻子载波的频率间隔为 $1 &#x2F; T$，$T$ 为 OFDM 符号的持续时间，则<br>任意一对子载波的内积满足</p>\n<div>$$\n\\frac{1}{T}\\int_{0}^{T}e^{j2\\pi \\frac{k_1}{T}t}e^{-j2\\pi \\frac{k_2}{T}t}\\mathrm dt = \\begin{cases}\n    1, k_1 = k_2\\\\\n    0, k_1 \\ne k_2\n\\end{cases}\n$$</div>\n\n<p>带宽 $W$ 和 $B$ 的区别：</p>\n<p>物理带宽 $W$</p>\n<p>信号带宽 $B$：半功率带宽(3dB)，等效噪声带宽，谱零点带宽，功率比例带宽，最低功率谱带宽</p>\n<h4 id=\"带通信号的表示方法\"><a href=\"#带通信号的表示方法\" class=\"headerlink\" title=\"带通信号的表示方法\"></a>带通信号的表示方法</h4><div>$$\nx(t) = A(t) \\cos [\\omega_c t + \\varphi (t)]\\\\\n$$</div>\n\n<p>同相分量：$x_I(t) &#x3D; A(t) \\cos(\\varphi(t))$</p>\n<p>正交分量：$x_Q(t) &#x3D; A(t) \\sin(\\varphi(t))$</p>\n<p>与幅度相位的关系：</p>\n<div>$$\nA(t) = \\sqrt{x_I^2(t) + x_Q^2(t)}\\\\\n\\varphi(t) = \\tan^{-1} \\left [ \\frac{x_Q(t)}{x_I(t)} \\right]\n$$</div>\n\n<p>带通信号的基带表示的方法</p>\n<div>$$\nx_{bb}(t) = x_I(t) + jx_Q(t)\\\\\n$$</div>\n\n<p>解析信号表示</p>\n<div>$$\nx_A(t) = x_{bb}(t)e^{j\\omega_ct}\\\\\nx(t) = \\real \\lbrace {x_A(t)} \\rbrace = \\real \\lbrace x_{bb}(t)e^{j\\omega_ct} \\rbrace\n$$</div>\n\n<p>原始带通信号是解析信号的实部</p>\n<p>从带通信号恢复基带信号？</p>\n<div>$$\n\\breve{x}(t) = x(t) \\circledast h(t)\\\\\nh(t) = \\frac{1}{\\pi t}\\\\\n\\breve{x}(t) = \\frac{1}{\\pi} \\int_{-\\infty}^{\\infty}\\frac{s(\\tau)}{t - \\tau}\\mathrm d\\tau\\\\\nH(f) = -j \\cdot \\text{sgn}(f) = \\begin{cases}\n    -j, &f\\gt 0\\\\\n    0, &f=0\\\\\n    j, &f < 0\n\\end{cases}\n$$</div>\n\n<p>构造解析信号</p>\n<div>$$\nx_A(t) = x(t) + j\\breve{x}(t)\\\\\n$$</div>\n\n<p>频谱分析</p>\n<div>$$\nX_A(\\omega) = [1 + \\text{sgn}(\\omega)]X(\\omega) = \\begin{cases}\n    2X(\\omega), &\\omega \\gt 0\\\\\n    X(0) = 0, &\\omega = 0\\\\\n    0, &\\omega \\lt 0\n\\end{cases}\\\\\nX_{bb} = X_A(\\omega + \\omega_c)\n$$</div>\n\n<p>带通信道</p>\n<p>具有实数值的信道冲激响应（CIR） $h(t)$</p>\n<p>等效的解析冲激响应 $h_A(t) &#x3D; h(t) + j\\breve{h}(t)$</p>\n<p>任意载波频率 $\\omega_c$ 的等效基带冲激响应CIR</p>\n<div>$$\nh_{bb}(t) = h_A(t) \\cdot e^{-j\\omega_c t}\n$$</div>\n\n<p>带通收发信号关系 $y(t) &#x3D; x(t) * h(t)$，则</p>\n<div>$$\nY(\\omega) = H(\\omega) X(\\omega)\\\\\nY_A(\\omega) = H_A(\\omega)X_A(\\omega)\\\\\nY_A(\\omega) = [H(\\omega) \\cdot \\frac{1}{2}\\left (1 + \\text{sgn}(\\omega)  \\right)]X_A(\\omega) = \\left [ \\frac{1}{2}H_A(\\omega) \\right]X_A(\\omega)\n$$</div>\n\n<p>$H_A(\\omega)$ 只有正半轴部分</p>\n<div>$$\nY_{bb}(\\omega) = Y_A(\\omega + \\omega_c) = \\left [ \\frac{1}{2}H_A(\\omega + \\omega_c) \\right]X_A(\\omega + \\omega_c) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$</div>\n\n<p>基带等效系统</p>\n<div>$$\ny_{bb}(t) = \\frac{1}{2}h_{bb}(t) * x_{bb}(t)\\\\\nY_{bb}(\\omega) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$</div>\n\n<p>基带时域转移函数 $\\frac{1}{2}h_{bb}(t)$</p>\n<p>基带频域转移函数 $H(\\omega + \\omega_c)$</p>\n<p>用正交基观点构造了信号波形</p>\n<div>$$\nx(t) = \\sqrt{2}\\cos 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^I_kg(t - kT_s) + \\sqrt{2}\\sin 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^Q_kg(t - kT_s)\n$$</div>\n\n<p>投影后的噪声：</p>\n<div>$$\nE \\lbrace n_k^In_l^Q \\rbrace = 0\\\\\nE \\lbrace n_k^In_l^I \\rbrace = \\delta_{kl}\\\\\nE \\lbrace n_k^Qn_l^Q \\rbrace = \\delta_{kl}\n$$</div>\n\n<p>等效符号差错模型</p>\n<div>$$\ny_k = x_k + n_k\\\\\nn_k \\sim \\mathcal{CN}(0, n_0)\n$$</div>\n\n<h2 id=\"差错控制\"><a href=\"#差错控制\" class=\"headerlink\" title=\"差错控制\"></a>差错控制</h2><p>差错控制的分类：</p>\n<ul>\n<li>检错重发 （ARQ）</li>\n<li>前向纠错 （FEC）</li>\n</ul>\n<p>前向纠错的分类：</p>\n<ul>\n<li>线性码，非线性码</li>\n<li>分组码（重点），卷积码</li>\n<li>系统码，非系统码</li>\n</ul>\n<p>编码增益</p>\n<p>给定误比特率的情况下，采用纠错编码后，$E_b&#x2F;n_0$的减小量称为编码增益。</p>\n<p>简单例子：</p>\n<p>重复编码</p>\n<p>BSC 重传三次：</p>\n<div>$$\n3p_e^2(1 - p_e) + p_e^3 \\approx 3p_e^2\n$$</div>\n\n<p>信道编码：通过合理得增加冗余信息，纠正信道传输中可能出现的错误</p>\n<ul>\n<li>又称为纠错码（Error Correction Coding）</li>\n</ul>\n<p>理想信道编码的局限性：</p>\n<ul>\n<li>码长无穷大</li>\n<li>没发现代数结构，复杂度太大</li>\n</ul>\n<p>如何实用化：</p>\n<ul>\n<li>有限长。代价：误码率非零，效率低</li>\n<li>有代数结构。优点：便于译码</li>\n</ul>\n<p>评价标准</p>\n<ul>\n<li>误比特率：评价可靠性</li>\n<li>码率：评价有效性</li>\n</ul>\n<h3 id=\"分组码\"><a href=\"#分组码\" class=\"headerlink\" title=\"分组码\"></a>分组码</h3><p>奇偶监督码</p>\n<ul>\n<li>检错，而非纠错</li>\n<li>电路实现简单</li>\n</ul>\n<p>漏检概率：</p>\n<div>$$\nP_m =\\sum\\limits_{i=1}^{\\lfloor\\frac{n}{2}\\rfloor}\\binom{n}{2i}\\varepsilon^{2i}(1 - \\varepsilon)^{n - 2i}\n$$</div>\n\n<p>群计数码</p>\n<ul>\n<li>累计信息码元中1的个数，以二进制形式放在信息码元后面</li>\n<li>检错能力<ul>\n<li>强于奇偶校验码</li>\n<li>当{1变0数量&#x3D;0变1数}时，无法检出</li>\n</ul>\n</li>\n</ul>\n<p>纠错码的直观表示</p>\n<ul>\n<li>码字<ul>\n<li>对应 $n$ 维空间的点</li>\n</ul>\n</li>\n</ul>\n<p>Hamming 距离：两个码字之间不同码元的个数</p>\n<p><strong>Hamming 距离</strong></p>\n<ul>\n<li>$x_m$ 和 $x_m^\\prime$ 中不同取值的位置数 $d_H(\\mathbf x_m, \\mathbf x_m^\\prime)$</li>\n<li>即模2和中1的个数</li>\n</ul>\n<p>汉明码重</p>\n<ul>\n<li>二进制向量 $\\mathbf x_m$ 1的个数 $w(\\mathbf x_m)$</li>\n</ul>\n<p>最小距离</p>\n<p>一个分组码中任意两个码字的最小汉明距离 $d_{\\text{min}}$</p>\n<h4 id=\"n-k-纠错码\"><a href=\"#n-k-纠错码\" class=\"headerlink\" title=\"(n,k)纠错码\"></a>(n,k)纠错码</h4><div>$$\nB = E + A, \\forall A \\in \\chi\\\\\nS = BH^T = EH^T\\\\\n$$</div>\n\n<p>$S$ 与 $A$ 无关，$A$ 只是无用的陪同（coset）。</p>\n<p>陪集首：上述陪集的特征由 $S &#x3D; EH^T$ 标识，我们称 $E$ 为陪集首。</p>\n<p>陪集首一般选择集合中 “1” 最少的元素，这是为了优先标识错误数量较小的差错，这一类差错发生的概率较大。</p>\n<p>码重：</p>\n<div>$$\nw(A) =\\sum\\limits_{i=1}^{n}\\mathbf 1 \\lbrace a_i = 1 \\rbrace = d_H(A, 0)\n$$</div>\n\n<p>001 -&gt; 0,0,0,0,0,1 -&gt; 101</p>\n<p>010 -&gt; 0,0,0,0,1,0 -&gt; 011</p>\n<p>011 -&gt; 0,0,0,1,0,0 -&gt; 110</p>\n<p>100 -&gt; 0,0,1,0,0,0 -&gt; 001</p>\n<p>101 -&gt; 0,1,0,0,0,0 -&gt; 010</p>\n<p>110 -&gt; 1,0,0,0,0,0 -&gt; 100</p>\n<p>111 -&gt; 0,1,0,0,0,1 -&gt; 111</p>\n<h4 id=\"交织器\"><a href=\"#交织器\" class=\"headerlink\" title=\"交织器\"></a>交织器</h4><p>线性码的改进：</p>\n<ul>\n<li>上述线性码，均适合于纠正零散错误</li>\n<li>Hamming码对于2个以上的差错就无能为力</li>\n<li>若差错总是成对出现，则Hamming码基本没用</li>\n<li>在通信系统中，往往存在不可抗拒的突发错误</li>\n</ul>\n<p>例如：无线信道的衰落引起的误码</p>\n<p>抗突发误码的方法：交织器</p>\n<p>基本原理</p>\n<ul>\n<li>为了对付突发的信道差错，交织器改变发送码元的时<br>间顺序</li>\n<li>将原本相邻的码元在时间上的距离最大化</li>\n<li>例子：考虑一个（n, k）分组码，其交织后的输出为</li>\n</ul>\n<p>将突发误码转换成零星误码</p>\n<p>交织器的性能：</p>\n<p>宽度</p>\n<ul>\n<li>就是分组码的码长n</li>\n<li>决定于所采用的分组码</li>\n</ul>\n<p>深度</p>\n<ul>\n<li>深度m决定了相邻码元交织后的间隔</li>\n<li>m又称交织深度</li>\n<li>若分组码能纠b个突发错误，则交织后能纠mb个突发错误</li>\n</ul>\n<p>解交织：</p>\n<ul>\n<li>从另一个角度来看，解交织打散了突发误码</li>\n<li>化整为零后的零散误码，就可以交给解码器对付了</li>\n</ul>\n<h3 id=\"卷积码\"><a href=\"#卷积码\" class=\"headerlink\" title=\"卷积码\"></a>卷积码</h3><p>输入无限长的激励，则输出信号无限长，</p>\n<p>若冲激响应有限，则输出只与某一段输入有关</p>\n<p>卷积码的参数 $n, k, N$</p>\n<p>约束长度，信息码位，每次输出</p>\n<p>使用树状图进行分类讨论</p>\n<p>树状图的冗余：</p>\n<ul>\n<li>树状图具有很多冗余表示</li>\n</ul>\n<p>树状图的应用：计算最小码距</p>\n<ul>\n<li>分组码的最小码距定义为非零码字的最小码重</li>\n<li>和分组码不同，卷积码没有分组的概念</li>\n<li>约束长度隐含了某种独立性，可以只考虑 $kN$ 的信息比特编码后的非零码字，也就是考虑 $nN$ 个非零的编码输出位</li>\n</ul>\n<p>状态图的应用</p>\n<ul>\n<li>自由距：无限长信息序列编码后的最小汉明距离</li>\n<li>自由距不等于最小距</li>\n</ul>\n<p>自由距等于寄存器从零状态开始，经过非零状态，然后回到零状态的输出1的个数的最小值</p>\n<p>卷积码的译码</p>\n<h4 id=\"维特比译码\"><a href=\"#维特比译码\" class=\"headerlink\" title=\"维特比译码\"></a>维特比译码</h4><p>网格图</p>\n<p>最大似然下的最优译码</p>\n<ul>\n<li>低复杂度</li>\n<li>采用最小汉明距离作为代价函数</li>\n</ul>\n<p>采用动态规划的卷积码译码成为 viterbi 译码</p>\n<ul>\n<li>viterbi 译码的起始状态是 0 状态</li>\n<li>viterbi 译码没有确定的代价函数，</li>\n</ul>\n<p>分组码译码可以知道是否译码错误了。通过校验矩阵来校验就行了。</p>\n<p>但是 viterbi 译码并不能肯定译码结果是否正确。</p>\n<h3 id=\"硬判决和软判决\"><a href=\"#硬判决和软判决\" class=\"headerlink\" title=\"硬判决和软判决\"></a>硬判决和软判决</h3><p>硬判决：任务是检测和矫正误码</p>\n<p>软判决：应用于卷积&#x2F; Viterbi 译码器，迭代译码  </p>\n<h3 id=\"检错重发-ARQ\"><a href=\"#检错重发-ARQ\" class=\"headerlink\" title=\"检错重发 ARQ\"></a>检错重发 ARQ</h3><p>$P_c &#x3D; (1 - \\varepsilon)^n$ 为正确概率</p>\n<p>$P_d$ 检出错误概率</p>\n<p>$P_m$ 漏检概率</p>\n<div>$$\nP_c + P_d + P_m = 1\n$$</div>\n\n<p>总分组差错概率</p>\n<div>$$\nP_b = P_m + P_dP_m + P_d^2P_m + \\dots = \\frac{P_m}{1 - P_d} = \\frac{P_m}{P_c + P_m}\n$$</div>\n\n<h4 id=\"停等ARQ\"><a href=\"#停等ARQ\" class=\"headerlink\" title=\"停等ARQ\"></a>停等ARQ</h4><p>收到上一个 ACK&#x2F;NAK 再发送下一个包或者重传上一个包</p>\n<p>假设发送方一直传输（一次就能传输成功），吞吐量的上限为</p>\n<div>$$\n\\eta_{sw, 0} = \\frac{k}{T_DR}\\\\\nT_D = T_m + 2 T_d + T_c + T_a = T_m + T_{dca} = \\frac{k}{n + T_{dca}R}\n$$</div>\n\n<p>若有完美的差错检出能力 $P_d &#x3D; 1 - (1 - \\varepsilon)^n$</p>\n<p>则</p>\n<div>$$\n\\eta_{sw} = \\frac{k/n}{1 + T_{dca}R/n}(1 - \\varepsilon)^n\n$$</div>\n\n<h4 id=\"返回-N-ARQ\"><a href=\"#返回-N-ARQ\" class=\"headerlink\" title=\"返回 N-ARQ\"></a>返回 N-ARQ</h4><p>不等 ACK&#x2F;NAK 返回就传下一个包，若检错则重传从错误开始的所有包</p>\n<div>$$\n\\eta_{GBN, 0} = \\frac{k}{n}\n$$</div>\n\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"信息论基础\"><a href=\"#信息论基础\" class=\"headerlink\" title=\"信息论基础\"></a>信息论基础</h2><h3 id=\"离散随机变量的信息度量\"><a href=\"#离散随机变量的信息度量\" class=\"headerlink\" title=\"离散随机变量的信息度量\"></a>离散随机变量的信息度量</h3><div>$$\nH(X) = \\mathbf E\\{H(X=x_i)\\} = -\\sum_i p_i \\log p_i\n$$</div>\n\n<p>称为熵</p>\n<p>单位：</p>\n<ul>\n<li>2 (Bit)</li>\n<li>e (Nat)</li>\n<li>10 (Hartely)</li>\n</ul>\n<p>表示了信息描述的有效性极限</p>\n<p>信源编码（Source Coding），通过信息的有效表示，提高通信的有效性。例如: Huffman 编码</p>\n<p>离散随机变量的最大熵：$\\max_{p_i} H(X) &#x3D; \\log|S|$</p>\n<p>前缀码：任何码字都不是其他码字的前缀。前缀码保证了唯一可译码。是二叉树叶子节点。</p>\n<p><strong>Kraft不等式</strong></p>\n<p>对于信源字符集$\\lbrace a_1, \\dots, a_m\\rbrace$，必满足：</p>\n<div>$$\n\\sum\\limits_{k=1}^{M}2^{-l(a_k)} \\le 1\n$$</div>\n\n<p>同时，若上式成立，必存在码长分别为$𝑙(𝑎_𝑘)$的前缀码。</p>\n<p>最小前缀码的平均码长：</p>\n<div>$$\n\\min \\bar L =\\sum\\limits_{i=1}^{M}p_il_i\\\\\ns.t.\\sum\\limits_{i=1}^{M} 2^{-l_i} = 1\n$$</div>\n\n<p>由拉格朗日乘子法</p>\n<div>$$\np_i = 2^{-l_i}, \\bar L_{min} = -\\sum\\limits_{i=1}^{M}p_i \\log p_i\n$$</div>\n\n<p>记 $H(X) &#x3D; -\\sum p_i\\log p_i$ .一般的，上下界为$H(X) \\le \\bar L  \\lt H(X) + 1$.</p>\n<p>如果我们将$k$个独立同分布的信源符号 $x_1, \\dots, x_k$堪称一个，对整体应用前缀码编码：</p>\n<div>$$\n\\begin{align*}\n    H(X_1, \\dots, X_k) &= -\\sum P(x_1, \\dots, x_k) \\log P(x_1, \\dots, x_k)\\\\\n    &= -\\sum P(x_1, \\dots, x_k) [\\log P(x_1) +  \\dots +  \\log(x_k)]\\\\\n    &= -\\sum P(x_1)\\log (x_1) - \\dots - \\sum P(x_k)\\log (x_k)\\\\\n    &= -kH(X)\n\\end{align*}\n$$</div>\n\n<p>直观：对长度为$𝑛$的$M$种信源符号序列，$𝑥_𝑖$出现的次数$≈𝑛𝑝_𝑖$</p>\n<p>典型序列应满足上述分布，否则就“小众”“非典型”</p>\n<p>典型的个数 # $≈ \\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}$</p>\n<p>平均每个信源符号可以用 $L &#x3D; \\frac{1}{n}\\log\\left(\\frac{𝒏!}{(𝑛𝑝_1) !… (𝑛𝑝_M) !}\\right)$ 个 bit 来表达。</p>\n<p>通过 Stirling 公式可以得出 L的上下界。</p>\n<p>故</p>\n<div>$$\n\\lim\\limits_{n\\rightarrow \\infty}^{} L = H(X)\n$$</div>\n\n<p><strong>最大熵</strong></p>\n<p>离散型随机变量的最大熵为</p>\n<!-- max -->\n<div>$$\n\\max_{p_i} H(X) = \\log |S|\n$$</div>\n\n<p>可以用梯度法直观感受，当所有分量的概率相等时，熵最大。</p>\n<p><strong>联合熵</strong></p>\n<p>联合概率</p>\n<!-- text -->\n<div>$$\np_{i, j} = \\text{Pr}\\lbrace X = x_i, Y = y_j\\rbrace\n$$</div>\n\n<p>联合熵的定义：</p>\n<div>$$\nH(XY) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i, j}\n$$</div>\n\n<p><strong>条件熵</strong></p>\n<p>条件概率</p>\n<!-- text -->\n<div>$$\np_{i\\mid j} = \\text{Pr}\\lbrace X = x_i \\mid Y = y_j\\rbrace\n$$</div>\n\n<p>条件熵的定义：</p>\n<div>$$\nH(X|Y) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i, j} \\log p_{i\\mid j}\n$$</div>\n\n<p>通过相关观测进行无损压缩，若观测到 $Y &#x3D; \\alpha_j$：</p>\n<div>$$\n\\bar L(\\alpha_j) = -\\sum\\limits_{i}^{}\\sum\\limits_{j}^{} p_{i\\mid j} \\log p_{i\\mid j}\n$$</div>\n\n<p>于是</p>\n<div>$$\n\\bar L =-\\sum\\limits_{j=1}^{N} \\bar L(\\alpha_j)p_j = -\\sum\\limits_{j=1}^{N}p_j\\sum\\limits_{i=1}^{M}p_{i|j} \\log(p_{i|j}) = -\\sum\\limits_{i=1}^{M}\\sum\\limits_{j=1}^{N}p_{ij}\\log(p_{i|j}) = H(X|Y)\n$$</div>\n\n<p><strong>链式法则</strong></p>\n<div>$$\nH(XY) = H(Y) + H(X|Y)\n$$</div>\n\n<p>两个随机变量的联合不确定性＝一个随机变量的不确定性＋知道这个随机变量后另一个随机变量残余的不确定性</p>\n<p><strong>互信息(Mutual Infomation)</strong></p>\n<div>$$\n\\begin{align*}\n    I(X;Y) &= H(X) + H(Y) - H(XY)\\\\\n    &= H(X) - H(X|Y) \\\\\n    &= H(Y) - H(Y|X)\n\\end{align*}\n$$</div>\n\n<p>互信息的物理意义</p>\n<p>第一种理解：</p>\n<ul>\n<li>X的不确定度减去观测Y后X残存的不确定度</li>\n<li>即：通过观测Y带来的帮助了解X的信息</li>\n</ul>\n<p>第二种理解：</p>\n<ul>\n<li>Y的不确定度减去观测X后Y残存的不确定度</li>\n<li>即：通过观测X带来的帮助了解Y的信息</li>\n</ul>\n<p>若$X, Y$相互独立，记为$X\\perp Y$，则$I(X;Y) &#x3D; 0$，$H(X) &#x3D; H(X|Y)$，$H(Y) &#x3D; H(Y|X)$。观测一个随机变量完全无助于了解另一个随机变量。</p>\n<ul>\n<li>$H(XY) &#x3D; H(X) + H(Y)$，总平均码长等于各自平均码长之和。</li>\n</ul>\n<p>若$X &#x3D; Y$，则$I(X;Y) &#x3D; H(X) &#x3D; H(Y)$，$H(X|Y) &#x3D; H(Y|X) &#x3D; 0$。观测一个随机变量完全了解另一个随机变量。</p>\n<p>$H(XY) &#x3D; H(Y) + H(X|Y) &#x3D; H(Y)$，只需要编码其中一个即可。</p>\n<div>$$\nX \\perp Y \\leftrightarrow H(X + Y | X) = H(Y | X) = H(Y), H(X + Y, X) = H(Y , X)\n$$</div>\n\n\n<div>$$\nH(X + X | X) = H(X | X) = 0, H(X + X, X) = H(X , X) = H(X)\n$$</div>\n\n<p><strong>信息传输的基本模型</strong></p>\n<ul>\n<li>信息通道，简称信道（Channel）对于输入符号有随机扰动，本质上可用一组条件概率表示</li>\n<li>限于物理条件，信宿只能观测信道输出 $Y$，由此了解其输入 $X$</li>\n<li>通过观测Y可以获得的关于X的信息量是 $I(X;Y)$</li>\n</ul>\n<p><strong>信息传输的优化</strong></p>\n<p>目标：最大化发送端 $X$ 和接收方 $Y$ 的互信息</p>\n<p>方法：</p>\n<ul>\n<li>信道是由物理实现所决定的，无法控制</li>\n<li>但是可以选择X的概率分布</li>\n</ul>\n<p>因此有如下优化问题：</p>\n<div>$$\np*_i = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} I(X;Y)\n$$</div>\n\n<p>定义信道容量 $C &#x3D; \\max_{\\sum_i p_i &#x3D; 1, p_i \\ge 0} I(X;Y)$</p>\n<p>信道容量的物理意义</p>\n<ul>\n<li>平均每个信道符号所能传的最大的信息量</li>\n<li>或：单位时间内信道所传最大的信息量</li>\n</ul>\n<p>优化问题的表达式</p>\n<div>$$\np_i^* = \\argmax_{\\sum_i p_i = 1, p_i \\ge 0} - \\sum_i\\sum_j p_i p_{j|i} \\log \\frac{\\sum\\limits_i p_i p_{j|i}}{p_{j|i}}\n$$</div>\n\n<p>信道容量不易计算</p>\n<p><strong>对称二进制信道(BSC)</strong></p>\n<ul>\n<li>一种典型信道模型</li>\n<li>分析信道编码时有很多应用</li>\n</ul>\n<p>利用互信息表达式</p>\n<div>$$\n\\begin{align*}\n    I(X;Y) &= H(Y) - H(Y | X)\\\\\n    &= H(Y) - \\sum_i p_i \\left[-\\sum_j p_{j|i} \\log p_{j|i}\\right]\\\\\n    &= H(Y) - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)]\\\\\n    &\\le 1 - [-\\varepsilon\\log \\varepsilon - (1 - \\varepsilon)\\log(1 - \\varepsilon)] = C\\\\\n\\end{align*}\\\\\nY \\sim \\begin{bmatrix}\n    0 & 1\\\\\n    1/2 & 1/2\n\\end{bmatrix}\n$$</div>\n\n<p>如果误码率 $\\varepsilon &#x3D; 0.5$，则信道容量为0, 传递不了信息。</p>\n<p>如果误码率 $\\varepsilon &gt; 0.5$，继续增大差错率，反而可以提高信道容量。</p>\n<p><strong>高斯信道</strong></p>\n<!-- **gauss** -->\n<div>$$\nY = X + N\\\\\nf_N(n) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(-\\frac{(y - x)^2}{2\\sigma^2}\\right)\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/1_1.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/1_.jpg\" alt=\"alt\"></p>\n<p>Shannon 公式</p>\n<div>$$\nC = W\\log(1 + \\frac{P}{Wn_0})\n$$</div>\n\n<h3 id=\"连续性随机变量的熵\"><a href=\"#连续性随机变量的熵\" class=\"headerlink\" title=\"连续性随机变量的熵\"></a>连续性随机变量的熵</h3><div>$$\nH(X) = - \\int\\limits_{-\\infty}^{\\infty}p(x)\\log p(x) \\mathrm dx + \\lim_{\\Delta \\rightarrow 0} \\log \\frac{1}{\\Delta}\n$$</div>\n\n<p>我们只关心相对不确定性，定义微分熵</p>\n<div>$$\nh(X) = -\\int\\limits_{-\\infty}^{\\infty}p(x) \\log p(x)\\mathrm dx\n$$</div>\n\n<p>微分熵是对连续型变量相对不确定性的一种描述</p>\n<ul>\n<li>其定义剔除了连续性或“精准要求”带来的困难，保<br>留了分布函数形状自身的特征</li>\n<li>它说明用有限字符集合的字符串描述连续分布的随机<br>变量，则平均字符长度为无穷大</li>\n<li>为了用有限长字符串描述信源，需要进行有损压缩，<br>从而带来失真，即原始信源和压缩结果之间的差异</li>\n<li>失真测度包括：均方误差，绝对值误差，主观误差等</li>\n<li>对于图像，视频和语音等连续信源的编码等均属于有<br>损压缩</li>\n</ul>\n<h3 id=\"多元随机变量的熵\"><a href=\"#多元随机变量的熵\" class=\"headerlink\" title=\"多元随机变量的熵\"></a>多元随机变量的熵</h3><p>联合熵：</p>\n<div>$$\nh(XY) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(x, y)\\mathrm dx \\mathrm{d}y\n$$</div>\n\n<p>条件熵：</p>\n<div>$$\nh(Y|X) = -\\int\\limits_{-\\infty}^{\\infty}p(x, y) \\log p(y|x)\\mathrm dx \\mathrm{d}y\n$$</div>\n\n<p>互信息：</p>\n<div>$$\n\\begin{align*}\n    I(X;Y) &= h(X) + h(Y) - h(XY)\\\\\n    &= h(X) - h(X|Y) \\\\\n    &= h(Y) - h(Y|X)\n\\end{align*}\n$$</div>\n\n<h2 id=\"压缩编码\"><a href=\"#压缩编码\" class=\"headerlink\" title=\"压缩编码\"></a>压缩编码</h2><h3 id=\"压缩编码的分类\"><a href=\"#压缩编码的分类\" class=\"headerlink\" title=\"压缩编码的分类\"></a>压缩编码的分类</h3><ul>\n<li>无损压缩<ul>\n<li>输入：数字序列</li>\n<li>输出：数字序列</li>\n<li>目的：使得平均长度更小</li>\n</ul>\n</li>\n<li>有损压缩<ul>\n<li>输入：模拟信号</li>\n<li>输出：数字序列</li>\n<li>目的：实现数字传输</li>\n</ul>\n</li>\n</ul>\n<p>信号压缩编码的步骤：</p>\n<ul>\n<li>抽样</li>\n<li>量化</li>\n<li>压缩编码</li>\n</ul>\n<h3 id=\"抽样\"><a href=\"#抽样\" class=\"headerlink\" title=\"抽样\"></a>抽样</h3><p><strong>连续时间信源的离散化</strong></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_1.jpg\"></p>\n<p>离散化的方式：在标准正交基上投影展开</p>\n<div>$$\ns(t) = \\sum_k a_k\\phi_k(t)\\\\\na_k = <s(t), \\phi_k(t)>\n$$</div>\n\n<p>若 $s(t)$ 是时限信号（宽度 $T$），可以用傅里叶展开的系数作为离散化结果：$s(t) &#x3D; \\sum\\limits_k a_k e^{2\\pi jkt&#x2F;T}$</p>\n<p>若 $s(t)$ 是带限信号（带宽 $W$），可以在频域对 $\\hat S(f)$ 做傅里叶展开：</p>\n<div>$$\n\\hat S(f) = \\sum\\limits_k \\alpha_k e^{2\\pi jkf/(2W)}\n$$</div>\n\n<p>变换回时域时，得到 Nyquist 抽样定理：</p>\n<div>$$\ns(t) =\\sum\\limits_{k}^{}s(kT) \\text{sinc}\\left(\\left(\\frac{t}{T} - k\\right)\\right), T = \\frac{1}{2W}\n$$</div>\n\n<p>频域无混叠等价于时域无畸变</p>\n<p>对于带通采样，有无混叠条件：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_2.jpg\"></p>\n<p>可以推导得出：</p>\n<div>$$\nf_s = 2B\\left(1 + \\frac{M}{N}\\right)\\\\\nN = \\left\\lfloor\\frac{f_H}{B}\\right\\rfloor\\\\\nM = \\left\\lbrace\\frac{f_H}{B}\\right\\rbrace\\\\\nB = f_H - f_L\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_3.jpg\"></p>\n<p>横轴为 $f_H&#x2F;B$，纵轴为 $f_s$</p>\n<p><strong>量化</strong></p>\n<p>分层电平： $\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$ </p>\n<p>重建&#x2F;输出电平：$y_k$代表一个量化区间，用以重构信号时使用的电平值</p>\n<p>量化函数： $y &#x3D; Q(x)$, $y_k &#x3D; Q\\lbrace x_k \\lt x \\le x_{k + 1} \\rbrace$</p>\n<p>量化间隔： $\\Delta_k &#x3D; x_{k + 1} - x_{k}$</p>\n<p>均匀量化 &amp; 非均匀量化</p>\n<p>均匀量化只对有界随机变量存在</p>\n<h3 id=\"量化\"><a href=\"#量化\" class=\"headerlink\" title=\"量化\"></a>量化</h3><ul>\n<li>在此只讨论标量的量化</li>\n<li>量化噪声： $q &#x3D; x - y &#x3D; x - Q(x)$ </li>\n<li>量化噪声是一个随机变量</li>\n<li>方差 $\\sigma_q^2 &#x3D; \\int_{-\\infty}^{\\infty}[x - Q(x)]^2p_x(x)\\mathrm dx$</li>\n<li>方差与输入信号分布有关，不存在普适的最佳量化方案</li>\n</ul>\n<h4 id=\"量化噪声的计算\"><a href=\"#量化噪声的计算\" class=\"headerlink\" title=\"量化噪声的计算\"></a>量化噪声的计算</h4><div>$$\n\\sigma_q^2 =\\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>从较容易的情况着手</p>\n<ul>\n<li>只考虑电平区间 $[-V,V]$ 之间的信号，并假设量化间隔很小，亦即分层电平很密</li>\n<li>在实际情况中，信号的分布函数处处可导，此时每个量化区间内信号的条件分布为均匀分布</li>\n</ul>\n<p>量化区间内，近似概率密度 $p_x(x) &#x3D; \\frac{P_k}{\\Delta_k}$</p>\n<p>密集分层的量化噪声近似</p>\n<div>$$\n\\sigma_{qn}^2 = \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2p_x(x)\\mathrm dx = \\sum\\limits_{k=1}^{L}\\frac{P_k}{\\Delta_k}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2\\mathrm dx = \\frac{1}{12}\\sum_{k = 1}^L P_k\\Delta_k^2 = \\frac{1}{12} \\int_{-V}^{V}(\\Delta_k)^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>若 $\\Delta_k &#x3D; \\Delta$，</p>\n<div>$$\n\\sigma_{qn}^2 = \\frac{1}{12}\\sum_k P_k\\Delta_k^2 = \\frac{\\Delta_k^2}{12}\n$$</div>\n\n<p>计算量化结果做无损压缩后的比特数：</p>\n<div>$$\nH(Q(x)) = -\\sum_k P_k \\log P_k = \\underbrace{- \\int_{-\\infty}^{\\infty}p_x(x)\\log p_x(x) \\mathrm dx }_{h(X)} + \\log \\frac{1}{\\Delta}\n$$</div>\n\n<p>由 $\\Delta &#x3D; \\sqrt{12\\sigma_{qn}^2} &#x3D; 2\\sigma_{qn}\\sqrt{3}$，</p>\n<div>$$\nH(x) = h(x) + \\log \\frac{1}{2\\sigma_{qn}\\sqrt{3}}\n$$</div>\n\n<p>无损压缩的 bit 数为： $\\tilde{R} &#x3D; h(X) - \\frac{1}{2}\\log \\sigma_{qn}^2 - 1.8$</p>\n<p>对于均匀量化：</p>\n<div>$$\n\\Delta_k = \\frac{x_{max} - x_{min}}{L} = \\frac{2x_{max}}{L}, \\forall k\n$$</div>\n\n<p>于是</p>\n<div>$$\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12} = \\frac{x_{max}^2}{3L^2}\n$$</div>\n\n<p>这里的 $\\sigma_{qn}^2$ 是正常量化噪声，仅仅是计算了信号落在 $[-x_{max}, x_{max}]$ 内的情况</p>\n<p>如果信号落在 $[-x_{max}, x_{max}]$ 以外，就就近判断至两端的量化区间，产生过载噪声</p>\n<div>$$\n\\sigma_{qo}^2 = \\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx + \\int^{-x_{max}}_{-\\infty}(x + x_{max})^2p_x(x)\\mathrm dx = 2\\int_{x_{max}}^{\\infty}(x - x_{max})^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>总噪声等于正常量化噪声加上过载噪声：</p>\n<div>$$\n\\sigma_{qs}^2 = \\sigma_{qn}^2 + \\sigma_{qo}^2\n$$</div>\n\n<p>如果用 $R$ bit 编码：</p>\n<div>$$\n\\Delta_k = \\frac{2x_{max}}{L} = \\frac{x_{max}}{2^{R - 1}}\\\\\n\\sigma_{qn}^2 = \\frac{\\Delta^2}{12}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx = \\frac{x_{max}^2}{3 \\times 2^{2R}}\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx\n$$</div>\n\n<p>定义非过载信号功率：</p>\n<div>$$\n\\sigma_s^2 = \\int_{-x_{max}}^{x_{max}}x^2p_x(x)\\mathrm dx\n$$</div>\n\n<p>当 $\\int_{-x_{max}}^{x_{max}}p_x(x)\\mathrm dx \\rightarrow 1$， $SNR_q \\approx \\frac{\\sigma_s^2}{x_{max}^2&#x2F;(3 \\times 2^{2R})} &#x3D; 3 \\times 2^{2R} \\times \\zeta^2$，这里定义 $\\zeta &#x3D; \\frac{\\sigma_s}{x_{max}}$ 为量化范围内信号的饱满程度。</p>\n<p>对数单位下：</p>\n<div>$$\nSNR_q(dB) = 6.02R + 20\\log_{10}(\\zeta) + 4.77\n$$</div>\n\n<ul>\n<li>多一个 bit，$SNR_q$ 提升 $6.02dB$</li>\n<li>$\\zeta$ 要在合理范围，$\\zeta$ 过大时过载会严重劣化性能</li>\n</ul>\n<h4 id=\"最优量化\"><a href=\"#最优量化\" class=\"headerlink\" title=\"最优量化\"></a>最优量化</h4><p>目标：给定量化区间总数，最小化量化噪声</p>\n<p>优化问题：</p>\n<div>$$\n\\min \\sum\\limits_{k=1}^{L}\\int_{x_k}^{x_{k + 1}}(x - y_k)^2 p_x(x)\\mathrm dx\\\\\ns.t. x_1\\le y_1 \\le x_2 \\le y_2 \\le \\dots \\le y_L \\le x_{L + 1}\n$$</div>\n\n<p>分层电平在重建电平的中点：</p>\n<div>$$\n\\frac{\\partial \\sigma_q^2}{\\partial x_k} = 0\\\\\n\\Rightarrow x_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$</div>\n\n<p>重建电平在量化区间的质心：</p>\n<div>$$\n\\frac{\\partial \\sigma_q^2}{\\partial y_k} = 0\\\\\n\\Rightarrow y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx}\n$$</div>\n\n<p>对于均匀分布，质心即中点（对于可导的概率分布，当分层很密的时候同样成立）</p>\n<div>$$\n y_{k, opt} = \\frac{\\int_{x_{k, opt}}^{x_{k+1, opt}}xp(x)\\mathrm dx}{\\int_{x_{k, opt}}^{x_{k+1, opt}}p(x)\\mathrm dx} = \\frac{1}{2}(x_{k, opt} + x_{k + 1, opt})\n$$</div>\n\n<p>结合</p>\n<div>$$\nx_{k, opt} = \\frac{1}{2}(y_{k, opt} + y_{k - 1, opt})\n$$</div>\n\n<p>可得均匀分布的最佳量化是区间等分，中点重建</p>\n<h4 id=\"工程用量化\"><a href=\"#工程用量化\" class=\"headerlink\" title=\"工程用量化\"></a>工程用量化</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_4.jpg\"></p>\n<h4 id=\"语音信号的量化\"><a href=\"#语音信号的量化\" class=\"headerlink\" title=\"语音信号的量化\"></a>语音信号的量化</h4><p>$[-V, V]$ 内均匀量化的缺陷：</p>\n<ul>\n<li>最适合 $[-V, V]$ 之间的有限分布</li>\n<li>语音信号呈拉普拉斯分布，特点是：<ul>\n<li>信号功率小</li>\n<li>动态范围大（长拖尾）</li>\n</ul>\n</li>\n<li>如果采用均匀量化<ul>\n<li>较大的V：增大[-V，V]内的量化噪声</li>\n<li>较小的V：增大过载噪声</li>\n</ul>\n</li>\n</ul>\n<p>解决思路1：非均匀量化</p>\n<p><strong>语音信号的非均匀量化</strong></p>\n<p>均匀量化的问题</p>\n<ul>\n<li>对具有不同“概率权重”的区间“一视同仁”</li>\n<li>没有考虑概率密度对于量化噪声的影响</li>\n</ul>\n<p>解决方案</p>\n<ul>\n<li>对于信号经常出现的区域，使用较细的颗粒度进行量化<ul>\n<li>信号经常落入这个区域，减小该区域的量化噪声损失</li>\n</ul>\n</li>\n<li>对于信号不经常出现的区域，使用较粗的颗粒度进行量化<ul>\n<li>信号不经常落入这个区域，量化噪声稍大不会影响大局</li>\n</ul>\n</li>\n</ul>\n<p>采用取对数后均匀量化的方法：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_5.jpg\"></p>\n<p>语音信号的瞬时压扩：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_6.jpg\"></p>\n<p><strong>对数量化</strong></p>\n<ul>\n<li>正常量化信噪比与信号的分布无关</li>\n<li>过载导致的噪声与信号的分布有关！</li>\n</ul>\n<p>记 $\\Delta_k$为对数化之前的量化区间, $\\Delta_k^\\prime &#x3D; \\Delta$ 为对数化之后的量化区间</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_9.jpg\"></p>\n<p><strong>实用的对数量化</strong></p>\n<p>实际工程中，采用另外两个函数（线性放缩，更容易实现）：</p>\n<ul>\n<li>A律（欧洲提出，我国采用）</li>\n</ul>\n<div>$$\nf(x) = \\begin{cases}\n    \\frac{Ax}{1 + \\ln A}, 0 \\le x \\le \\frac{1}{A}\\\\\n    \\frac{1 + \\ln Ax}{1 + \\ln A}, \\frac{1}{A} \\le x \\le 1\\\\\n\\end{cases}\n$$</div>\n\n<ul>\n<li><p>ITU G.712建议中取A＝87.6</p>\n</li>\n<li><p>小信号时，信噪比增加了24dB</p>\n</li>\n<li><p>μ律（美国提出）</p>\n</li>\n</ul>\n<div>$$\nf(x) = \\frac{\\ln (1 + \\mu x)}{\\ln (1 + \\mu)}, 0 \\le x \\le 1\n$$</div>\n\n\n<ul>\n<li>ITU G.712建议中取μ＝255</li>\n<li>小信号时，信噪比增加了33.5dB</li>\n</ul>\n<p><strong>脉冲编码调制(PCM)</strong></p>\n<ul>\n<li>语音信号的实际压缩编码方式</li>\n<li>包括两个主要步骤</li>\n<li>抽样：$f_s &#x3D; 8000Hz$</li>\n<li>量化与编码：使用近似对数压扩，每个抽样量化为8位</li>\n<li>PCM的输出码率为64kbps</li>\n</ul>\n<p><strong>该码率与其推导过程十分重要</strong></p>\n<p><strong>PCM编码协议</strong></p>\n<p>基本思想</p>\n<ul>\n<li>用13折线近似A律</li>\n<li>用15折线近似μ律</li>\n</ul>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_7.jpg\"></p>\n<p>码字结构：</p>\n<div>$$\n\\mathop{M_1}\\limits_{极性码} \\quad \\underbrace{M_2 \\quad M_3 \\quad M_4}_{段落码}\\quad \\underbrace{M_5 \\quad M_6\\quad M_7 \\quad M_8}_{电平码} \\quad \n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/2_8.jpg\"></p>\n<p>例：</p>\n<p>1250的输出：1 110 0011</p>\n<p>接收端解码： 1024 + 128 + 64 + 32 &#x3D; 1248</p>\n<h2 id=\"数字基带传输\"><a href=\"#数字基带传输\" class=\"headerlink\" title=\"数字基带传输\"></a>数字基带传输</h2><h3 id=\"符号映射\"><a href=\"#符号映射\" class=\"headerlink\" title=\"符号映射\"></a>符号映射</h3><p><strong>符号集合</strong></p>\n<p>$M &#x3D; |\\mathcal{A}|$ 为符号集合 $\\mathcal{A}$ 的符号数量。</p>\n<p><strong>bit 承载量</strong><br>每个符号最多可对应 $r &#x3D; \\log_2|\\mathcal{A}|$ 个 bit，称为集合的 bit 承载量</p>\n<p>数字通信的典型符号：</p>\n<ul>\n<li>ASK</li>\n<li>PAM</li>\n<li>PSK</li>\n<li>QAM</li>\n</ul>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_1.jpg\"></p>\n<p><strong>邻位最小差错映射：Grey 码</strong></p>\n<p>相邻符号对应的 bit 串仅有一位差异</p>\n<p><strong>符号周期（Symbol Period）</strong></p>\n<ul>\n<li>传输一个符号所需的平均时间</li>\n<li>$T_s$</li>\n</ul>\n<p>通信速率：</p>\n<ul>\n<li>符号速率：$R_s &#x3D; \\frac{1}{T_s}$</li>\n<li>Bit 速率： $R_b &#x3D; R_s \\log_2 M &#x3D; \\frac{1}{T_s}\\log_2 M$</li>\n</ul>\n<h3 id=\"数字调制\"><a href=\"#数字调制\" class=\"headerlink\" title=\"数字调制\"></a>数字调制</h3><p>基带调制：将时间上离散的符号，加载到时间上形成连续的波形</p>\n<p>通信信号具有带宽受限特性，因为：</p>\n<ul>\n<li>自然原因：各类通信线路，如双绞线，同轴电缆，射频功放等均对通过的频率有一定限制</li>\n<li>人为原因：多用户频谱共享通信，如蜂窝无线系统，需约束每路信号的带宽，以免相互干扰</li>\n</ul>\n<p>如何产生带限信号？</p>\n<p>产生一个信号 $s(t) &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}a_kg(t- k T_s)$，$g(t) &#x3D; \\frac{\\sin 2\\pi Wt}{2\\pi Wt}$是个带限信号。</p>\n<div>$$\nG(f) = \\begin{cases}\n    1, |f| \\le W,\\\\\n    0, |f| \\gt W\n\\end{cases}\n$$</div>\n\n<p>让间隔 $T_s$ 的冲击 $a_k\\delta(t - kT_s)$ 依次通过冲击响应为 $g(t)$ 的低通滤波器</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_2.jpg\"></p>\n<h3 id=\"Nyquist-准则：无ISI条件\"><a href=\"#Nyquist-准则：无ISI条件\" class=\"headerlink\" title=\"Nyquist 准则：无ISI条件\"></a>Nyquist 准则：无ISI条件</h3><p><strong>符号间串扰（Inter Symbol Interference, ISI）</strong></p>\n<p>对 $s(t)$ 采样：</p>\n<div>$$\ns(nT_s) = a_ng(0) + \\underbrace{\\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big)}_{\\text{ISI}}\n$$</div>\n\n<p>怎么让 ISI 为0？</p>\n<p><strong>眼图：观察符号间串扰</strong></p>\n<p>眼图（Eye Pattern）是直观察看数字基带传输性能的有效方法，用一个示波器</p>\n<div>$$\n垂直输入 \\xrightarrow{接} 匹配滤波器的输出\\\\\n水平扫描速度 \\xrightarrow{设为} 𝑅_𝑠的整数倍\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_3.jpg\" alt=\"alt\"></p>\n<p>眼皮的厚度表示 ISI 的失真，眼睛的张开程度表示噪声容限。</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_4.jpg\" alt=\"alt\"></p>\n<p>消除 ISI 对带限脉冲的要求</p>\n<p>时域特征：</p>\n<div>$$\n\\left.\\begin{align*}\n    g(0) &= 1\\\\\n    \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_kg\\big((n - k)T_s\\big) &= 0\n\\end{align*}\\right\\rbrace \\Leftrightarrow \\sum\\limits_{k=-\\infty, k\\ne n}^{\\infty}a_{n - k}g\\big(kT_s\\big) = 0\\\\\n\\Leftrightarrow g(kT_s) = \\begin{cases}\n    1, k = 0,\\\\\n    0, k \\ne 0\n\\end{cases} \\\\\n\\lrArr g(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t)\n$$</div>\n\n<p>从频域提取特征：</p>\n<div>$$\ng(t)\\sum\\limits_{n=-\\infty}^{\\infty}\\delta(t + nT_s) = \\delta(t) \\lrArr G(f) *\\sum\\limits_{n=-\\infty}^{\\infty}\\frac{1}{T_s}\\delta(f + \\frac{n}{T_s}) = 1\\\\\n\\lrArr \\sum\\limits_{n=-\\infty}^{\\infty}G\\left(f + \\frac{n}{T_s}\\right) = T_s\n$$</div>\n\n<p><strong>Nyquist 准则</strong></p>\n<p>将带限脉冲的频谱分别平移 $n&#x2F;T_s$（ $n$ 为任意整数）若其叠加的结果对任意频率恒为定值，则 ISI 为0</p>\n<h3 id=\"通信速率与带宽效率\"><a href=\"#通信速率与带宽效率\" class=\"headerlink\" title=\"通信速率与带宽效率\"></a>通信速率与带宽效率</h3><p><strong>理解 Nyquist 准则</strong></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_5.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/3_6.jpg\" alt=\"alt\"></p>\n<ul>\n<li>最大符号速率受制于带宽 $R_s &#x3D; \\frac{1}{T_s} \\le 2W$</li>\n<li>低通发送滤波器应该满足残留对称条件</li>\n</ul>\n<p><strong>通信速率与带宽效率</strong></p>\n<div>$$\nR_s \\le 2W\\\\\nR_b = R_s \\log_2 M\\\\\n\\Rightarrow R_b \\le 2W \\log_2 M\n$$</div>\n\n<ul>\n<li>针对给定形式的低通滤波器，可写出$R_s$与$W$之间的线性函数关系</li>\n</ul>\n<p><strong>信号功率与带宽效率</strong></p>\n<p>设单个符号的能量为 $E_s$</p>\n<p>则信号功率为单位时间内的能量</p>\n<div>$$\nP = \\frac{E_s}{T_s} = E_sR_s\n$$</div>\n\n<p>无冗余编码时，一个比特的能量为$𝐸_𝑏$，则</p>\n<div>$$\nP = \\frac{E_b\\log_2 M}{T_s} = E_bR_b\n$$</div>\n\n<p>带宽效率的定义：单位带宽承载的速率</p>\n<div>$$\n\\eta = \\frac{R_b}{W} \\le 2\\log_2 M\n$$</div>\n\n\n<ul>\n<li>为什么不能无限制扩大符号集合？</li>\n</ul>\n<p>过大的符号集合对信噪比有更高的要求，噪声容易干扰符号的分辨</p>\n<h3 id=\"升余弦滤波器\"><a href=\"#升余弦滤波器\" class=\"headerlink\" title=\"升余弦滤波器\"></a>升余弦滤波器</h3><p><strong>升余弦滤波器</strong></p>\n<p>由于理想滤波器难以实现，所以常用满足残留对称条件的非理想低通生成基带脉冲，最常用的就是升余弦滤波器</p>\n<p>Raised Cosine(要记住)</p>\n<div>$$\nH(f) = \\begin{cases}\n    T_s, &0 \\le |f| \\lt \\frac{1 - \\alpha}{2 T_s}\\\\\n    \\frac{T_s}{2}\\left\\lbrace1 + \\cos \\left[\\frac{\\pi T_s}{\\alpha}\\left(|f| - \\frac{1 - \\alpha}{2T_s}\\right)\\right]\\right\\rbrace, &\\frac{1 - \\alpha}{2 T_s} \\le |f| \\le \\frac{1 + \\alpha}{2 T_s}\\\\\n    0, & |f| \\gt \\frac{1 + \\alpha}{2 T_s}\n\\end{cases}\n$$</div>\n\n<p>$\\alpha &#x3D; 2WT_s - 1 \\in [0, 1]$ 称为滚降系数，越小坡越陡，越大坡越缓。</p>\n<p>时域冲激响应：</p>\n<div>$$\nh(t) = \\text{Sa}(\\pi t/ T_s)\\frac{\\cos (\\alpha\\pi t/ T_s)}{1 - 4(\\alpha t/T_s)^2}\n$$</div>\n\n<p>升余弦滤波器的性质：</p>\n<p><font color=\"red\">常考性质：</font></p>\n<div>$$\nW = \\frac{\\alpha + 1}{2T_s} = \\frac{\\alpha + 1}{2}R_s \\Rightarrow R_s/2 \\le W \\le R_s\\\\\nR_s = \\frac{1}{T_s} = \\frac{2}{\\alpha + 1} W \\Rightarrow W \\le R_s \\le 2W\n$$</div>\n\n<p>带宽效率</p>\n<div>$$\n\\eta_b = \\frac{R_s\\log_2|\\mathcal{S}|}{W} \\le 2\\log_2|\\mathcal S|\n$$</div>\n\n<p>升余弦滤波器的带宽效率</p>\n<div>$$\n\\eta_b = \\frac{2\\log_2|\\mathcal{S}|}{\\alpha + 1}\n$$</div>\n\n<p>PCM 语言信号速率 64kbps：8 bit 采样，8 bit 量化，8*8 &#x3D; 64.</p>\n<p>例题一：传送一路PCM语音信号</p>\n<ul>\n<li>若带宽限制为40kHz，采用二元码，则可用滚降系数范围<br>是多少？</li>\n<li>若采用四元码，最多需要多少带宽？</li>\n</ul>\n<p>解：PCM语音信号是64kbps</p>\n<ul>\n<li>采用二元码，则所需符号速率为 $R_s &#x3D; R_b &#x3D; 64kbps$</li>\n</ul>\n<ul>\n<li><p>则 $\\frac{\\alpha + 1}{2}64 \\le 40$, $0\\le \\alpha \\le 0.25$</p>\n</li>\n<li><p>采用四元码：$R_s &#x3D; \\frac{R_b}{\\log_24} &#x3D; 32kbps$</p>\n</li>\n<li><p>$W \\le R_s &#x3D; 32kHz$</p>\n</li>\n</ul>\n<p>例题二：若传送一路信号$𝑅_𝑏$ &#x3D; 112kbps，信道带宽𝑊 &#x3D; 30𝑘bps,<br>求𝑀和𝛼</p>\n<div>$$\n\\frac{\\log_2M}{\\alpha} = \\frac{R_b}{2W} = \\frac{28}{15} \\in [1.5, 2]\\\\\n$$</div>\n\n<p>认定 $\\log_2M &#x3D; k$ 为整数，则$k &#x3D; 2 或 3$。对应可解：</p>\n<div>$$\n\\alpha_1 = \\frac{1}{14}, M_1 = 4\\\\\n\\alpha_2 = \\frac{17}{28}, M_2 = 8\n$$</div>\n\n<h3 id=\"通信信号的功率谱计算\"><a href=\"#通信信号的功率谱计算\" class=\"headerlink\" title=\"通信信号的功率谱计算\"></a>通信信号的功率谱计算</h3><p>功率谱刻画了随机过程的功率在频域上的分布。</p>\n<ul>\n<li>对于宽平稳过程（自相关只与时差有关），功率谱易于从 $R(\\tau)$ 的傅里叶变换得到，即$S(f) &#x3D; \\mathcal{F}[R(\\tau)]$</li>\n<li>但是，通信信号一般不是宽平稳过程，而是周期平稳过程：$R(t_1, t_2) &#x3D; R(t_1 + kT_s, t_2 + kT_s)$</li>\n</ul>\n<p>定义 </p>\n<div>$$\n\\overline{R}(\\tau) = \\frac{1}{T_s} \\int_{0}^{T_s}R(t+\\tau, t)\\mathrm dt\n$$</div>\n\n<p>则其功率谱</p>\n<div>$$\nS(f) = \\mathcal{F}[\\overline{R}(\\tau)]\n$$</div>\n\n<p>若输入信号的功率谱 $S_{AI}(f)$，输出为$S_A(f)$，则对于宽平稳和周期平稳信号均有卷积关系：</p>\n<div>$$\nS_A(f) = S_{AI}(f)|H(f)|^2\n$$</div>\n\n<p>证明可以采用样本统计法：假设符号序列的长度为 $2N - 1$.</p>\n<div>$$\ns_{AI}(t) =\\sum\\limits_{k=-N}^{N}a_k\\delta(t - k T_s)\\\\\ns_{A}(t) =\\sum\\limits_{k=-N}^{N}a_kh(t - k T_s)\\\\\n\\hat s_{AI}(f) =\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\\\\\n\\hat s_{A}(f) = H(f)\\sum\\limits_{k=-N}^{N}\\exp(-j2k\\pi T_sf)\n$$</div>\n\n<p>功率谱的定义：</p>\n<div>$$\nS(f) = \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat s(f)|^2)}{(2N + 1)T_s}\n$$</div>\n\n<p>可以验证 $S_A(f) &#x3D; S_{AI}(f)|H(f)|^2$</p>\n<p>针对样本统计法，可以算出 $E(|\\cdot|^2)$的表达式：</p>\n<div>$$\nS_A(f) = \\frac{|H(f)|^2}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f)\n$$</div>\n\n<p>这里$R_a[m]$ 是输入符号的自相关。</p>\n<p>先考虑无记忆调制，符号之间相互独立：</p>\n<div>$$\nR_a[n] = E[a_ia_{i+n}] = \\begin{cases}\n    \\sigma_a^2+m_a^2 &n=0\\\\\n    m_a^2 &n\\ne 0\n\\end{cases}\n$$</div>\n\n<p>其中，$m_a &#x3D; E[a_n]$，$\\sigma_a^2 &#x3D; E[a_n^2] - m_a^2$</p>\n<p>于是，重写累加部分：</p>\n<div>$$\n\\begin{align*}\n    &\\sum\\limits_{n=-\\infty}^{\\infty}R_a[n] \\exp (-j2n\\pi T_s f) \\\\\n    =& \\sigma_a^2 + m_a^2\\sum\\limits_{n=-\\infty}^{\\infty}\\exp\\big[-jn(2\\pi T_s)f\\big]\\\\\n    =& \\sigma_a^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\delta\\bigg(f - \\frac{n}{T_s}\\bigg)\n\\end{align*}\n$$</div>\n\n<p>从而</p>\n<div>$$\nS_A(f) = \\underbrace{\\frac{\\sigma_a^2}{T_s}|H(f)|^2}_{连续谱} + \\underbrace{\\frac{m_a^2}{T_s^2}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|H\\bigg(\\frac{n}{T_s}\\bigg)\\bigg|^2 \\delta\\bigg(f - \\frac{n}{T_s}\\bigg)}_{线谱}\n$$</div>\n\n<p>此式应用的两个条件：</p>\n<ul>\n<li>无记忆</li>\n<li>不同符号波形一致</li>\n</ul>\n<p>线谱：可用于定时恢复。方便恢复时钟分量。</p>\n<p><strong>任意波形调制</strong></p>\n<p>之前将 $a_i$ 映射为 $a_ih(t)$，可以推广：</p>\n<div>$$\n\\forall a_i \\ne a_j, s_i(t) \\ne s_j(t)\n$$</div>\n\n<p>有时候由于信号功率需要保持稳定（恒包络调制），对不同符号采用不同波形，而不是采用变化幅度的信号。</p>\n<p>若任意波形二元调制信号 $s(t) &#x3D;\\sum\\limits_{k&#x3D;-\\infty}^{\\infty}g_k(t)$</p>\n<div>$$\ng_k(t) = \\begin{cases}\n    s_1(t - kT_s), w.p.\\ p\\\\\n    s_2(t - kT_s), w.p.\\ \\bar p = 1 - p\n\\end{cases}\n$$</div>\n\n<p>(w. p. &#x3D; with probability)</p>\n<p>分解为直流分量和交流分量：</p>\n<div>$$\ns(t) = \\underbrace{E(s(t))}_{DC,记为v(t)} + \\underbrace{s(t) - E(s(t))}_{AC, 记q(t)}\n$$</div>\n\n<p>则</p>\n<div>$$\nv(t) = \\sum\\limits_{k=-\\infty}^{\\infty}[ps_1(t - kT_s) + \\bar p s_2(t - kT_s)]\n$$</div>\n\n<p>这是一个周期为$𝑇_𝑠$的确定性周期信号，功率谱由傅里叶展开计算</p>\n<div>$$\nS_v(f) =\\sum\\limits_{n=-\\infty}^{\\infty}|D_n|^2\\delta(f - \\frac{n}{T_s})\\\\\nD_n = \\frac{1}{T_s}\\int_{-T_s/2}^{T_s/2}v(t)e^{-j2\\pi t/T_s}\\mathrm dt = \\frac{1}{T_s}\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\n$$</div>\n\n<div>$$\nS_v(f) = \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$</div>\n\n<p>用样本统计法计算 $S_q(f)$：</p>\n<div>$$\n\\begin{align*}\n    S_q(f) =& \\lim\\limits_{N\\rightarrow\\infty} \\frac{E(|\\hat q_N(f)|^2)}{(2N + 1)T_s}\\\\\n    =& \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2\n\\end{align*}\n$$</div>\n\n<div>$$\nS(f) = \\frac{p\\bar p}{T_s}|\\hat s_1 (f) - \\hat s_2(f)|^2 + \\frac{1}{T_s}\\sum\\limits_{n=-\\infty}^{\\infty}\\bigg|\\Big(p\\hat s_1\\big(\\frac{n}{T_s}\\big) + \\bar p \\hat s_2(\\frac{n}{T_s}\\big)\\Big)\\bigg|^2 \\delta(f - \\frac{n}{T_s})\n$$</div>\n\n<h3 id=\"基带解调\"><a href=\"#基带解调\" class=\"headerlink\" title=\"基带解调\"></a>基带解调</h3><p>最佳接收用于在给定发送功率下提高信噪比</p>\n<p>最佳判决用于在给定信噪比下降低误码率</p>\n<h4 id=\"基带传输的噪声模型\"><a href=\"#基带传输的噪声模型\" class=\"headerlink\" title=\"基带传输的噪声模型\"></a>基带传输的噪声模型</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_1.jpg\" alt=\"alt\"></p>\n<p>如何选择解调方案？</p>\n<p><strong>方案一：直接抽样</strong></p>\n<p>在信号的峰值位置 $t &#x3D; kT_s$ 抽样最好。</p>\n<p>但噪声方差满足：</p>\n<div>$$\n\\sigma^2 = E \\lbrace n^2(t_1) \\rbrace = R(0) = \\frac{n_0}{2}\\delta(0) \\rightarrow \\infty\n$$</div>\n\n<p>（理想的白噪声信号具有无穷大功率）</p>\n<p>真实的噪声环境下，接收信号质量随着噪声信号功率的增加而变差。如果信号的峰值处恰好噪声很大，则产生严重失真。</p>\n<p><strong>方案二：能量累积</strong></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_2.jpg\" alt=\"alt\"></p>\n<p>噪声信号仍为高斯随机变量：</p>\n<div>$$\nn = \\int_{0}^{T_s}n(t)\\mathrm dt\n$$</div>\n\n<p>噪声方差：</p>\n<div>$$\n\\sigma^2 = E\\lbrace n^2 \\rbrace = \\int_{0}^{T_s}\\int_{0}^{T_s}\\frac{n_0}{2}\\delta(t_1 - t_2)\\mathrm dt_1\\mathrm dt_2 = \\frac{n_0T_s}{2}\n$$</div>\n\n<p>信噪比：</p>\n<div>$$\n\\frac{S}{N} = \\frac{\\left (\\int_{0}^{T_s}a_i h(t)\\mathrm dt \\right)^2}{T_sn_0/2}\n$$</div>\n\n<p>直接积分不是最好的方案。</p>\n<p><strong>方案三：匹配滤波</strong></p>\n<p>匹配滤波的基本思想就是对接收值进行加权线性累加，从而最大化抽样时刻信号功率与噪声功率的比值。</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_3.jpg\" alt=\"alt\"></p>\n<p>相关器为 $g(t)$。假设信号为实信号。复信号有类似结论。</p>\n<div>$$\nP_S = \\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2\\\\\nP_N = \\mathbf E \\left [ \\left | \\int_{0}^{T_s}n(t)g(t)\\mathrm dt \\right|^2 \\right] = \\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt\n$$</div>\n\n<p>利用 Cauchy-Schwartz 不等式：</p>\n<div>$$\n\\frac{\\left |\\int_{0}^{T_s}a_ih(t)g(t)\\mathrm dt  \\right|^2}{\\frac{1}{2}n_0 \\int_{0}^{T_s}g^2(t)\\mathrm dt} \\le \\frac{2}{n_0}\\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt\n$$</div>\n\n<p>等号成立当且仅当 $g(t) &#x3D; kh(t)$。</p>\n<p>若为复信号，则需要</p>\n<div>$$\ng(t) = h^*(t)\n$$</div>\n\n<p>如何把相关器写成滤波器形式？</p>\n<p>（滤波&#x3D;卷积，相关和卷积就是差一个反褶的关系）</p>\n<div>$$\ny(t) = [a_ih(t) + n(t)] * h_m(t) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(t - \\tau)\\mathrm d\\tau\n$$</div>\n\n<p>考虑因果系统，一般将符号波形的最高点设置为 $t &#x3D; T_s$：</p>\n<div>$$\ny(T_s) = \\int_{-\\infty}^{\\infty}[a_ih(\\tau) + n(\\tau)]h_m(T_s - \\tau)\\mathrm d\\tau\n$$</div>\n\n<p>与相关器比较得到匹配滤波器的表达式：</p>\n<div>$$\nh_m(t) = h(T_s - t)\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_4.jpg\" alt=\"alt\"></p>\n<p>图中的“开关”是抽样。</p>\n<p>匹配滤波的频域解释：</p>\n<div>$$\nP_S = \\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2\\\\\nP_N = \\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df\\\\\n\\frac{S}{N} = \\frac{\\left | \\int_{-\\infty}^{\\infty}H(f)H_m(f)e^{j2\\pi fT_s}\\mathrm df \\right|^2}{\\frac{n_0}{2}\\int_{-\\infty}^{\\infty}|H_m(f)|^2\\mathrm df} = \\frac{2}{n_0}\\int_{-\\infty}^{\\infty}|H(f)|^2\\mathrm df\n$$</div>\n\n<p>Cauchy-Schwartz</p>\n<div>$$\nH_m(f) = H^*(f)e^{-j2\\pi fT_s}\n$$</div>\n\n<p><strong>匹配滤波的增益</strong></p>\n<p>数字传输的优势：数字传输中，基带脉冲h(t)是给定的，在整个码元周期内可以相干累加，而同时让噪声在整个周期内自我抵消</p>\n<div>$$\n\\left (\\frac{S}{N}  \\right)_{\\text{match}} \\bigg/ \\left (\\frac{S}{N}  \\right)_{\\text{w.o.match}} = \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\left ( \\int_{0}^{T_s}h(t)\\mathrm dt \\right)^2} \\ge \\frac{T_s \\int_{0}^{T_s}h^2(t)\\mathrm dt}{\\int_{0}^{T_s}1\\mathrm dt\\int_{0}^{T_s}h^2(t)\\mathrm dt} = 1\n$$</div>\n\n<p>匹配滤波的信噪比</p>\n<div>$$\n\\frac{S}{N} = E \\left [ \\frac{2}{n_0} \\int_{0}^{T_s}a_i^2h^2(t)\\mathrm dt \\right] = \\frac{\\int_{0}^{T_s}E[a_i^2]h^2(t)\\mathrm dt}{n_0/2} = \\frac{E_s}{n_0 / 2}\n$$</div>\n\n<p>分子——传送一个符号的能量</p>\n<p>分母——噪声谱密度，单位是能量的单位</p>\n<p>以上采用的是等效基带模型。采用实际物理波形模型：</p>\n<div>$$\nS = \\frac{E_s}{T_s} = E_sR_s\\\\\nN = Wn_0\\\\\n\\frac{S}{N} = \\frac{E_s}{n_0}\\frac{R_s}{W}\\\\\n$$</div>\n\n<p>两个模型推得的信噪比表达式不同，差异在于等效基带模型使用了匹配滤波器，获得了最优的信噪比：</p>\n<div>$$\n\\frac{R_s}{W} \\le 2 \\Rightarrow\\left (\\frac{S}{N}  \\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\n$$</div>\n\n<p>从实际物理波形模型来看，上式取等的条件应该是基带脉冲采用的是理想低通（Sa 函数），如果用升余弦滤波</p>\n<div>$$\n\\frac{R_s}{W} = \\frac{2}{\\alpha + 1} \\Rightarrow \\left(\\frac{S}{N}\\right)_{\\text{max}} = \\frac{E_s}{n_0/2}\\frac{2}{\\alpha + 1}\n$$</div>\n\n<p>但是，在等效基带模型中，我们考虑的是任意脉冲 $h(t)$，并没有要求它的形状，这两个模型在最优信噪比的产生条件上出现了矛盾？</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_5.jpg\" alt=\"alt\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_6.jpg\" alt=\"alt\"></p>\n<h4 id=\"传送一串符号\"><a href=\"#传送一串符号\" class=\"headerlink\" title=\"传送一串符号\"></a>传送一串符号</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_7.jpg\" alt=\"alt\"></p>\n<p>无 ISI 条件：</p>\n<div>$$\nh(t)*h_m(t) = h(t) * h(T_s - t)\\\\\nH(f)H_m(f) = H(f)H^*(f)e^{-j2\\pi fT_s} = \\left | H(f) \\right|^2 e^{-j2\\pi fT_s} \n$$</div>\n\n<p>从而有根号奈奎斯特条件：</p>\n<div>$$\nH(f) = \\sqrt{H_{N-I}(f)}e^{-j2\\pi fT_s} \nH_m(f) = \\sqrt{H_{N-I}^*(f)}e^{-j2\\pi fT_s} \n$$</div>\n\n<p>这就要求发送和接受滤波器要满足如下要求：</p>\n<div>$$\nh_T(t) = h_{\\sqrt{N}}\\left ( t - \\frac{T_s}{2} \\right)\\\\\nh_R(t) = h_{\\sqrt{N}}\\left (\\frac{T_s}{2}  - t\\right) = h_T(T_s - t)\n$$</div>\n\n<h4 id=\"符号差错模型：\"><a href=\"#符号差错模型：\" class=\"headerlink\" title=\"符号差错模型：\"></a>符号差错模型：</h4><p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_8.jpg\" alt=\"alt\"></p>\n<div>$$\ny_i = \\bar h a_i + n_i\n$$</div>\n\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/4_9.jpg\" alt=\"alt\"></p>\n<h3 id=\"判决与差错\"><a href=\"#判决与差错\" class=\"headerlink\" title=\"判决与差错\"></a>判决与差错</h3><h3 id=\"最佳判决\"><a href=\"#最佳判决\" class=\"headerlink\" title=\"最佳判决\"></a>最佳判决</h3><p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_2.jpg\" alt=\"ima\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_1.jpg\" alt=\"ima\"></p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_3.jpg\" alt=\"alt\"></p>\n<p>多元符号的最佳判决</p>\n<div>$$\na^* = \\argmax_{a\\in U} f(y|a)f(a)\\\\\nf(a) = \\frac{1}{M}\\\\\na^* = \\argmax_{a\\in U} f(y|a)\\\\\n$$</div>\n\n<p>$y &#x3D; a + n$ 的条件分布是</p>\n<div>$$\nf(y|a) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(y - a)^2}{2\\sigma^2}\\right)\n$$</div>\n\n<p>从而得到</p>\n<div>$$\na^* = \\argmin_{a\\in U} |y - a|\n$$</div>\n\n<p>选择一个符号，让它到接收符号y距离最小，以此作为判决结果！</p>\n<p>双极性码的判决门限：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_4.jpg\" alt=\"alt\"></p>\n<p>单极性码的判决门限:</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_6.jpg\" alt=\"alt\"></p>\n<h4 id=\"SER-amp-BER\"><a href=\"#SER-amp-BER\" class=\"headerlink\" title=\"SER &amp; BER\"></a>SER &amp; BER</h4><p>考虑二元符号</p>\n<p>发送 A 的出错概率：</p>\n<div>$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = \\int_{A/\\sigma}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}\\exp \\left ( -\\frac{t^2}{2} \\right)\\mathrm dt = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>发送 -A 的出错概率：</p>\n<div>$$\n\\int_{-\\infty}^{0}f(y|a = A)\\mathrm dy = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>从而平均符号差错概率：</p>\n<div>$$\nP_s = \\frac{1}{2}\\left (Q \\left ( \\frac{A}{\\sigma} \\right) + Q \\left ( \\frac{A}{\\sigma} \\right)  \\right) = Q \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>称为符号差错概率(Symbor Error Probability, SEP)，其统计结果称为误符号率（Symbol Error Ratio, SER）</p>\n<p>由于Q是减函数，所以误符号率随A增大而减小，随噪声标准差增大而增大</p>\n<p>误符号率不关心具体的A或标准差，而是由其比值所决定</p>\n<p>对于多元而言：</p>\n<p>对于任意符号集合，只要某判决门限与符号距离为A，则由于超出该判决门限而差错的条件概率就是：</p>\n<div>$$\nQ \\left ( \\frac{A}{\\sigma} \\right)\n$$</div>\n\n<p>计算信噪比：</p>\n<p>信号平均功率： $S &#x3D; \\frac{1}{M}\\sum\\limits_{i&#x3D;1}^{M}|a_i|^2$</p>\n<p>信号峰值功率： $S_p &#x3D; \\max_{a_i \\in U} |a_i|^2$</p>\n<p>噪声功率： $N &#x3D; \\sigma^2$</p>\n<p>对于双极性二元符号，平均功率为 $S &#x3D; A^2$</p>\n<p>从而信噪比为 </p>\n<div>$$\n\\frac{S}{N} = \\frac{A^2}{\\sigma^2}\n$$</div>\n\n<p>利用等效关系得到误符号率和信噪比的关系</p>\n<div>$$\nP_s = Q \\left ( \\frac{A}{\\sigma} \\right) = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$</div>\n\n<p>更一般的二元码 SER</p>\n<div>$$\nU = \\lbrace D-A, D+A \\rbrace\\\\\n\\zeta = \\frac{D}{A}\\\\\nP_s = Q(\\sqrt{\\frac{S}{(1 + \\zeta^2)N}})\n$$</div>\n\n<p>更一般的 M 元码 SER</p>\n<p>符号集合为 $\\lbrace D - (M - 1)A, \\dots, D + (M  - 1)A \\rbrace$</p>\n<div>$$\n\\zeta = \\frac{D}{A\\sqrt{\\frac{M^2 - 1}{3}}}\\\\\nP_s = \\frac{2(M - 1)}{M}Q \\left ( \\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{(1 + \\zeta^2)N}} \\right)\n$$</div>\n\n<p>双极性 M 元码的 SER (掌握计算方法)</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{M^2 - 1} \\frac{S}{N}}\\right)\n$$</div>\n\n<p>无论M为奇数还是偶数，结果都是一样的！</p>\n<p>单极性 M 元码的 SER (掌握计算方法)</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M } Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$</div>\n\n\n<p>要使得双极性和单极性码的 SER 相同，二者的信噪比的比值为</p>\n<div>$$\n\\left ( \\frac{S}{N} \\right)_d \\bigg / \\left ( \\frac{S}{N} \\right)_s = \\frac{M^2 - 1}{2(M - 1)(2M  - 1)} \\approx \\frac{1}{4}\n$$</div>\n\n<p>显然，双极性的性能更好，它对信噪比的要求是单极性的四分之一，更能忍受噪声。</p>\n<p>误比特率(Bit Error Rate, BER)：</p>\n<div>$$\nP_b \\approx \\frac{P_s}{\\log_2M}\n$$</div>\n\n<p>注意这是近似结果，且有成立条件，只对二元码是严格成立的！</p>\n<ul>\n<li>假设一个符号的错判导致 1bit 的错误，假设成立的条件：<ul>\n<li>Grey 码映射</li>\n<li>信噪比不过于小</li>\n</ul>\n</li>\n</ul>\n<p>各类符号集合的 BER</p>\n<p>双极性二元码</p>\n<div>$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{N}} \\right)\n$$</div>\n\n<p>单极性二元码</p>\n<div>$$\nP_b = Q \\left ( \\sqrt{\\frac{S}{2N}} \\right)\n$$</div>\n\n<p>单极性二元码损失了 3 dB.</p>\n<p>双极性 M 元码</p>\n<div>$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{3}{M^2 - 1}\\frac{S}{N}})\n$$</div>\n\n<p>单极性 M 元码</p>\n<div>$$\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3}{2(M - 1)(2M - 1)} \\frac{S}{N}}\\right)\n$$</div>\n\n<p>由于</p>\n<div>$$\n\\frac{S}{N} = 2\\log_2 M\\frac{E_b}{n_0}\n$$</div>\n\n<p>故可以把 SER 和 BER 用 $E_b&#x2F;n_0$ 表示：</p>\n<p>双极性二元码：</p>\n<div>$$\nP_s = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{2E_b}{n_0}} \\right)\n$$</div>\n\n<p>单极性二元码：</p>\n<div>$$\nP_s = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\\\\\nP_b = Q \\left ( \\sqrt{\\frac{E_b}{n_0}} \\right)\n$$</div>\n\n<p>双极性 M 元码：</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M}Q(\\sqrt{\\frac{6\\log_2 M}{M^2 - 1}\\frac{E_b}{n_0}})\n$$</div>\n\n<p>单极性 M 元码：</p>\n<div>$$\nP_s = \\frac{2(M - 1)}{M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\\\\\nP_b = \\frac{2(M - 1)}{M\\log_2 M} Q \\left ( \\sqrt{\\frac{3\\log_2 M}{(M - 1)(2M - 1)} \\frac{E_b}{n_0}}\\right)\n$$</div>\n\n<p>例子：相移键控 MPSK</p>\n<div>$$\n\\begin{align*}\n    S_{MPSK}(t) =& \\sum\\limits_{n}^{}g(t - nT_s)A\\cos(\\omega_c t + \\phi_n)\\\\\n    =& \\left [\\sum\\limits_{n}^{}A\\cos \\phi_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}A\\sin \\phi_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$</div>\n\n<ul>\n<li>所有符号的模相同</li>\n<li>幅角在 $[0, 2\\pi]$ 均匀分布</li>\n</ul>\n<p>可以用星座图表示：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_5.jpg\" alt=\"alt\"></p>\n<p>根据信号的 $I, Q$ 表示</p>\n<p>计算 MPSK 的 SER:</p>\n<p>考虑星座点 $(A, 0)$</p>\n<p>接收信号的分布函数为</p>\n<div>$$\nf(a, b) - \\frac{1}{2\\pi \\sigma_n^2}\\exp \\left ( -\\frac{(a - A)^2 + b^2}{2\\sigma_n^2} \\right)\n$$</div>\n\n<p>变换到极坐标系</p>\n<div>$$\nf(\\rho, \\theta) = \\frac{\\rho}{2\\pi\\sigma_n^2}\\exp \\left ( -\\frac{\\rho^2 + A^2 - 2A\\rho\\cos\\theta}{2\\sigma_n^2} \\right)\\\\\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{A^2}{2\\sigma_n^2}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - A/\\sigma_n\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$</div>\n\n<p>误符号率可以表示为</p>\n<div>$$\nP_{s, MPSK} = 1 - \\int_{-\\pi/M}^{\\pi/M}f(\\theta)\\mathrm d\\theta\n$$</div>\n\n<p>用信噪比表示：</p>\n<div>$$\nf(\\theta) = \\int_{0}^{\\infty}f(\\rho, \\theta)\\mathrm d\\rho = \\frac{1}{2\\pi}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\n$$</div>\n\n<p>如果 $S&#x2F;N$ 很大：</p>\n<div>$$\n\\begin{align*}\n    \\int_{0}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho \\approx& \\int_{-\\infty}^{\\infty}\\rho\\exp \\left (-\\frac{(\\rho - \\sqrt{S/N}\\cos\\theta)^2}{2} \\right)\\mathrm d\\rho\\\\\n    =& \\sqrt{\\frac{S}{N}}\\cos\\theta\n\\end{align*}\n$$</div>\n\n<p>利用高信噪比近似：</p>\n<div>$$\nf(\\theta) = \\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\n$$</div>\n\n<p>当 M 比较大时：</p>\n<div>$$\n\\begin{align*}\n    P_{s, MPSK} =& 1 - \\int_{-\\pi/M}^{\\pi/M}\\sqrt{\\frac{S}{2\\pi N}}\\cos\\theta \\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    \\approx& \\frac{2}{\\sqrt{\\pi}}\\int_{\\pi/M}^{\\infty}\\sqrt{\\frac{S}{2N}}\\cos\\theta\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}}\\int_{\\pi/M}^{\\infty}\\exp \\left ( -\\frac{S}{2N}\\sin^2\\theta \\right)\\mathrm d\\sqrt{\\frac{S}{N}}\\sin\\theta\\\\\n    =& \\frac{2}{\\sqrt{2\\pi}} \\int_{\\sqrt{S/N}\\sin\\pi/M}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\mathrm du\\\\\n    =& 2Q \\left ( \\sqrt{\\frac{S}{N}}\\sin\\frac{\\pi}{M} \\right)\n\\end{align*}\n$$</div>\n\n<p>换算成 BER， $E_b&#x2F;n_0$</p>\n<div>$$\nP_{b, MPSK} = \\frac{2}{\\log_2M}Q \\left ( \\sqrt{2\\log_2M\\frac{E_b}{n_0}}\\sin\\frac{\\pi}{M} \\right)\n$$</div>\n\n<p>一个简单的方法：</p>\n<p>看起来像是先射箭后画靶。</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_7.jpg\" alt=\"alt\"></p>\n<p>例子2：正交幅度调制 QAM</p>\n<p>信号表示</p>\n<div>$$\n\\begin{align*}\n    S_{MQAM}(t) =& \\left [\\sum\\limits_{n}^{}a_n g(t - nT_s) \\right]\\cos \\omega_c t + \\left [\\sum\\limits_{n}^{}b_n g(t - nT_s) \\right]( - \\sin \\omega_c t)\n\\end{align*}\n$$</div>\n\n<p>I,Q 两路的电平集合：</p>\n<div>$$\na_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\nb_n\\in \\lbrace \\pm A, \\dots, \\pm(M - 1)A \\rbrace\\\\\n$$</div>\n\n<p>QAM是一种典型的星座图，它分布于复平面的格点上，其符号的实虚部均为奇数（便于分析）</p>\n<p>解调过程：</p>\n<p>I 路信息提取：乘以同相载波 $\\cos\\omega_c t$，再低通滤波</p>\n<p>Q 路信息提取：乘以同相载波 $-\\sin\\omega_c t$，再低通滤波</p>\n<p>差错分析：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_8.jpg\" alt=\"alt\"></p>\n<p>（通过后面的分析可以发现，降低误码率的关键是将符号间的最小距离最大化）</p>\n<p>计算各符号的差错概率：</p>\n<p>四个角：</p>\n<div>$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$</div>\n\n<p>$4(L - 2)$ 个边点：</p>\n<div>$$\nP_s = 1 - \\left [ 1 - Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]\n$$</div>\n\n<p>$(L - 2)^2$ 个内点：</p>\n<div>$$\nP_s = 1 - \\left [ 1 - 2Q \\left ( \\frac{A}{\\sigma} \\right) \\right]^2\n$$</div>\n\n<p>计算平均 SEP：</p>\n<div>$$\n\\begin{align*}\n    P_s =& \\frac{1}{L^2}\\lbrace 4(2Q - Q^2) + 4(L - 2)(3Q - 2Q^2) + (L - 2)^2(4Q - 4Q^2) \\rbrace\\\\\n    \\approx& \\frac{4L^2 - 4L}{L^2}Q \\left ( \\frac{A}{\\sigma_n} \\right)\n\\end{align*}\n$$</div>\n\n<p>省略了 $Q$ 的高阶量。</p>\n<p>计算平均功率：</p>\n<div>$$\nS = 2 \\times \\frac{2A^2}{L}[1^2 + 3^2 + \\dots + (L - 1)^2] = \\frac{2(L^2 - 1)}{3}A^2\n$$</div>\n\n<p>是同A的LPAM功率的两倍。因为MQAM有两路LPAM</p>\n<p>得到 SEP：</p>\n<div>$$\nP_s = \\frac{4M - 4L}{M} Q \\left (\\sqrt{\\frac{3}{2(M - 1)}\\frac{S}{N}}  \\right)\\\\\nM = L^2\n$$</div>\n\n<p>得到 BEP：</p>\n<div>$$\nP_b = 4 \\left (1 - \\frac{1}{\\sqrt M}  \\right) Q \\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right) \\approx 4Q\\left (\\sqrt{\\frac{3\\log_2M}{2(M - 1)}\\frac{E_b}{n_0}}  \\right)\\\\\n$$</div>\n\n<p>注意到MQAM可以看成两路正交的MPAM</p>\n<div>$$\n\\begin{align*}\n    P_{s, MQAM} =& 1 - (1 - P_{LPAM})^2\\\\\n    \\approx& 2P_{LPAM}\\\\\n    =& 4 \\left ( 1 - \\frac{1}{\\sqrt M} \\right)Q \\left ( \\sqrt{\\frac{3}{(M - 1)}\\frac{S/2}{N}} \\right)\n\\end{align*}\n$$</div>\n\n<p>这个推导方式更简单。</p>\n<p>QAM 是在独立解映射条件下最好的方案。但是距离高斯信道容量还有一定距离。要达到更好的信道容量，可以采用联合解映射，将译码过程联合起来。</p>\n<p>例子3：频移键控 FSK</p>\n<p>一般来说，信号表达式和调制框图的相互反演是比较容易做的</p>\n<p>相对于PAM，PSK和QAM，FSK占用更大的频带，</p>\n<p>相干解调</p>\n<p>Coherent Demodulation</p>\n<ul>\n<li><p>反思FSK非相干解调方式，如果对每个频率的载波进行匹配，则可以提高信噪比</p>\n</li>\n<li><p>这种方法需要本地子载波</p>\n</li>\n<li><p>解调器的结构和非相干解调很像</p>\n</li>\n<li><p>无法用星座图方法表示，但是可以用类似的信号空间表示</p>\n</li>\n<li><p>若MFSK载频等间隔，则调制阶数约高，占用带宽越大</p>\n</li>\n<li><p>如果每次可以选择多个载频，甚至控制载频幅度，则可承载的符号量可以获得极大提升。由此便引申出OFDM技术</p>\n</li>\n</ul>\n<ul>\n<li>通过调制FSK的每个载波的幅度相位，可以承载更多的信息</li>\n</ul>\n<p>星座图没法表述 FSK. 可以使用信号空间方法来表示。</p>\n<p>差错分析：</p>\n<p>FSK 的判决门限为棱锥形状：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_9.jpg\" alt=\"alt\"></p>\n<p>根据对称性，可以只考虑一个符号的差错概率。</p>\n<p>考虑 FSK 信号</p>\n<div>$$\n[A, 0, \\dots, 0]\n$$</div>\n\n<p>匹配滤波的输出为</p>\n<div>$$\n[A + n_1, n_2, \\dots, n_M]\n$$</div>\n\n<p>正确判决：信号落在本棱锥中</p>\n<div>$$\nA + n_1 \\gt n_i, i = 2, \\dots, M\n$$</div>\n\n<p>被判决符号的条件分布为</p>\n<div>$$\nf_{[A + n_1, n_2, \\dots, n_M]}(\\vec r) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\n$$</div>\n\n<p>不满足正确判决条件的概率为</p>\n<div>$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\prod_{i = 2}^M \\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i\\mathrm dr_1\\\\\n    =&1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{(r_1 - A)^2}{2\\sigma^2} \\right)\\left (\\int_{-\\infty}^{r_1}\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left ( -\\frac{r_i^2}{2\\sigma^2} \\right)\\mathrm dr_i  \\right)^{M - 1}\\mathrm dr_1\n\\end{align*}\n$$</div>\n\n<p>记 $x &#x3D; \\frac{r_1}{\\sigma}$</p>\n<div>$$\n\\begin{align*}\n    P_s =& 1 - \\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi }}\\exp \\left ( -\\frac{(x - A/\\sigma)^2}{2} \\right)\\left (1 - Q(x)\\right)^{M - 1}\\mathrm dx\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\frac{A}{\\sigma}  \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$</div>\n\n<div>$$\n\\frac{A}{\\sigma} = \\sqrt{\\frac{S}{N}} = \\sqrt{\\log_2M\\frac{2E_b}{n_0}}\n$$</div>\n\n<p>可得 SEP 的表达式</p>\n<div>$$\n\\begin{align*}\n    P_s =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\frac{S}{N}} \\right)\\right)^{M - 1}\\mathrm du\\\\\n    =& 1 - \\frac{1}{\\sqrt{2\\pi }}\\int_{-\\infty}^{\\infty}\\exp \\left ( -\\frac{u^2}{2} \\right)\\left (1 - Q \\left (u + \\sqrt{\\log_2M\\frac{2E_b}{n_0}} \\right)\\right)^{M - 1}\\mathrm du\n\\end{align*}\n$$</div>\n\n<p>另一种简单估界：</p>\n<p><img src=\"/../images/%E9%80%9A%E7%BD%91/5_10.jpg\" alt=\"alt\"></p>\n<p>正交 2FSK 信号在最佳接收条件时的错误概率为</p>\n<div>$$\nP_{b,NCFSK} = Q(\\sqrt{E_b/n_0})\n$$</div>\n\n<p>随着 M 的增加，MFSK 的差错性能渐优，这是以带宽的占用为代价的。</p>\n<p>PAM, QAM, ASK 等技术随着符号个数的增加，差错性能是越来越差。</p>\n<p>FDM——Frequency Division Multiplexing</p>\n<ul>\n<li>先将各路信号调制到不同频段，然后复用整个<br>通信带宽</li>\n<li>信道的非线性会在FDM系统中产生交调失真与<br>高次谐波，引起路际串话，因此，对信道的非<br>线性失真要求很高。此外，FDM用到的模拟滤<br>波器设计较为复杂。</li>\n</ul>\n<h4 id=\"OFDM-基本原理\"><a href=\"#OFDM-基本原理\" class=\"headerlink\" title=\"OFDM 基本原理\"></a>OFDM 基本原理</h4><p>Orthogonal Frequency division multiplexing</p>\n<ul>\n<li>把一串高速数据流分解为若干速率低得多的子数据流。</li>\n<li>将每个子数据流放置在对应的子载波上。</li>\n<li>将多个子载波合成，一起并行传输。</li>\n<li>优点：频谱利用率高。</li>\n</ul>\n<p>正交性的定义：</p>\n<div>$$\n\\int_{0}^{T}S_1(t)S_2(t)\\mathrm dt = 0\n$$</div>\n\n<p>设相邻子载波的频率间隔为 $1 &#x2F; T$，$T$ 为 OFDM 符号的持续时间，则<br>任意一对子载波的内积满足</p>\n<div>$$\n\\frac{1}{T}\\int_{0}^{T}e^{j2\\pi \\frac{k_1}{T}t}e^{-j2\\pi \\frac{k_2}{T}t}\\mathrm dt = \\begin{cases}\n    1, k_1 = k_2\\\\\n    0, k_1 \\ne k_2\n\\end{cases}\n$$</div>\n\n<p>带宽 $W$ 和 $B$ 的区别：</p>\n<p>物理带宽 $W$</p>\n<p>信号带宽 $B$：半功率带宽(3dB)，等效噪声带宽，谱零点带宽，功率比例带宽，最低功率谱带宽</p>\n<h4 id=\"带通信号的表示方法\"><a href=\"#带通信号的表示方法\" class=\"headerlink\" title=\"带通信号的表示方法\"></a>带通信号的表示方法</h4><div>$$\nx(t) = A(t) \\cos [\\omega_c t + \\varphi (t)]\\\\\n$$</div>\n\n<p>同相分量：$x_I(t) &#x3D; A(t) \\cos(\\varphi(t))$</p>\n<p>正交分量：$x_Q(t) &#x3D; A(t) \\sin(\\varphi(t))$</p>\n<p>与幅度相位的关系：</p>\n<div>$$\nA(t) = \\sqrt{x_I^2(t) + x_Q^2(t)}\\\\\n\\varphi(t) = \\tan^{-1} \\left [ \\frac{x_Q(t)}{x_I(t)} \\right]\n$$</div>\n\n<p>带通信号的基带表示的方法</p>\n<div>$$\nx_{bb}(t) = x_I(t) + jx_Q(t)\\\\\n$$</div>\n\n<p>解析信号表示</p>\n<div>$$\nx_A(t) = x_{bb}(t)e^{j\\omega_ct}\\\\\nx(t) = \\real \\lbrace {x_A(t)} \\rbrace = \\real \\lbrace x_{bb}(t)e^{j\\omega_ct} \\rbrace\n$$</div>\n\n<p>原始带通信号是解析信号的实部</p>\n<p>从带通信号恢复基带信号？</p>\n<div>$$\n\\breve{x}(t) = x(t) \\circledast h(t)\\\\\nh(t) = \\frac{1}{\\pi t}\\\\\n\\breve{x}(t) = \\frac{1}{\\pi} \\int_{-\\infty}^{\\infty}\\frac{s(\\tau)}{t - \\tau}\\mathrm d\\tau\\\\\nH(f) = -j \\cdot \\text{sgn}(f) = \\begin{cases}\n    -j, &f\\gt 0\\\\\n    0, &f=0\\\\\n    j, &f < 0\n\\end{cases}\n$$</div>\n\n<p>构造解析信号</p>\n<div>$$\nx_A(t) = x(t) + j\\breve{x}(t)\\\\\n$$</div>\n\n<p>频谱分析</p>\n<div>$$\nX_A(\\omega) = [1 + \\text{sgn}(\\omega)]X(\\omega) = \\begin{cases}\n    2X(\\omega), &\\omega \\gt 0\\\\\n    X(0) = 0, &\\omega = 0\\\\\n    0, &\\omega \\lt 0\n\\end{cases}\\\\\nX_{bb} = X_A(\\omega + \\omega_c)\n$$</div>\n\n<p>带通信道</p>\n<p>具有实数值的信道冲激响应（CIR） $h(t)$</p>\n<p>等效的解析冲激响应 $h_A(t) &#x3D; h(t) + j\\breve{h}(t)$</p>\n<p>任意载波频率 $\\omega_c$ 的等效基带冲激响应CIR</p>\n<div>$$\nh_{bb}(t) = h_A(t) \\cdot e^{-j\\omega_c t}\n$$</div>\n\n<p>带通收发信号关系 $y(t) &#x3D; x(t) * h(t)$，则</p>\n<div>$$\nY(\\omega) = H(\\omega) X(\\omega)\\\\\nY_A(\\omega) = H_A(\\omega)X_A(\\omega)\\\\\nY_A(\\omega) = [H(\\omega) \\cdot \\frac{1}{2}\\left (1 + \\text{sgn}(\\omega)  \\right)]X_A(\\omega) = \\left [ \\frac{1}{2}H_A(\\omega) \\right]X_A(\\omega)\n$$</div>\n\n<p>$H_A(\\omega)$ 只有正半轴部分</p>\n<div>$$\nY_{bb}(\\omega) = Y_A(\\omega + \\omega_c) = \\left [ \\frac{1}{2}H_A(\\omega + \\omega_c) \\right]X_A(\\omega + \\omega_c) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$</div>\n\n<p>基带等效系统</p>\n<div>$$\ny_{bb}(t) = \\frac{1}{2}h_{bb}(t) * x_{bb}(t)\\\\\nY_{bb}(\\omega) = H(\\omega + \\omega_c) X_{bb}(\\omega)\n$$</div>\n\n<p>基带时域转移函数 $\\frac{1}{2}h_{bb}(t)$</p>\n<p>基带频域转移函数 $H(\\omega + \\omega_c)$</p>\n<p>用正交基观点构造了信号波形</p>\n<div>$$\nx(t) = \\sqrt{2}\\cos 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^I_kg(t - kT_s) + \\sqrt{2}\\sin 2\\pi f_c t \\sum\\limits_{k=-\\infty}^{\\infty}x^Q_kg(t - kT_s)\n$$</div>\n\n<p>投影后的噪声：</p>\n<div>$$\nE \\lbrace n_k^In_l^Q \\rbrace = 0\\\\\nE \\lbrace n_k^In_l^I \\rbrace = \\delta_{kl}\\\\\nE \\lbrace n_k^Qn_l^Q \\rbrace = \\delta_{kl}\n$$</div>\n\n<p>等效符号差错模型</p>\n<div>$$\ny_k = x_k + n_k\\\\\nn_k \\sim \\mathcal{CN}(0, n_0)\n$$</div>\n\n<h2 id=\"差错控制\"><a href=\"#差错控制\" class=\"headerlink\" title=\"差错控制\"></a>差错控制</h2><p>差错控制的分类：</p>\n<ul>\n<li>检错重发 （ARQ）</li>\n<li>前向纠错 （FEC）</li>\n</ul>\n<p>前向纠错的分类：</p>\n<ul>\n<li>线性码，非线性码</li>\n<li>分组码（重点），卷积码</li>\n<li>系统码，非系统码</li>\n</ul>\n<p>编码增益</p>\n<p>给定误比特率的情况下，采用纠错编码后，$E_b&#x2F;n_0$的减小量称为编码增益。</p>\n<p>简单例子：</p>\n<p>重复编码</p>\n<p>BSC 重传三次：</p>\n<div>$$\n3p_e^2(1 - p_e) + p_e^3 \\approx 3p_e^2\n$$</div>\n\n<p>信道编码：通过合理得增加冗余信息，纠正信道传输中可能出现的错误</p>\n<ul>\n<li>又称为纠错码（Error Correction Coding）</li>\n</ul>\n<p>理想信道编码的局限性：</p>\n<ul>\n<li>码长无穷大</li>\n<li>没发现代数结构，复杂度太大</li>\n</ul>\n<p>如何实用化：</p>\n<ul>\n<li>有限长。代价：误码率非零，效率低</li>\n<li>有代数结构。优点：便于译码</li>\n</ul>\n<p>评价标准</p>\n<ul>\n<li>误比特率：评价可靠性</li>\n<li>码率：评价有效性</li>\n</ul>\n<h3 id=\"分组码\"><a href=\"#分组码\" class=\"headerlink\" title=\"分组码\"></a>分组码</h3><p>奇偶监督码</p>\n<ul>\n<li>检错，而非纠错</li>\n<li>电路实现简单</li>\n</ul>\n<p>漏检概率：</p>\n<div>$$\nP_m =\\sum\\limits_{i=1}^{\\lfloor\\frac{n}{2}\\rfloor}\\binom{n}{2i}\\varepsilon^{2i}(1 - \\varepsilon)^{n - 2i}\n$$</div>\n\n<p>群计数码</p>\n<ul>\n<li>累计信息码元中1的个数，以二进制形式放在信息码元后面</li>\n<li>检错能力<ul>\n<li>强于奇偶校验码</li>\n<li>当{1变0数量&#x3D;0变1数}时，无法检出</li>\n</ul>\n</li>\n</ul>\n<p>纠错码的直观表示</p>\n<ul>\n<li>码字<ul>\n<li>对应 $n$ 维空间的点</li>\n</ul>\n</li>\n</ul>\n<p>Hamming 距离：两个码字之间不同码元的个数</p>\n<p><strong>Hamming 距离</strong></p>\n<ul>\n<li>$x_m$ 和 $x_m^\\prime$ 中不同取值的位置数 $d_H(\\mathbf x_m, \\mathbf x_m^\\prime)$</li>\n<li>即模2和中1的个数</li>\n</ul>\n<p>汉明码重</p>\n<ul>\n<li>二进制向量 $\\mathbf x_m$ 1的个数 $w(\\mathbf x_m)$</li>\n</ul>\n<p>最小距离</p>\n<p>一个分组码中任意两个码字的最小汉明距离 $d_{\\text{min}}$</p>\n<h4 id=\"n-k-纠错码\"><a href=\"#n-k-纠错码\" class=\"headerlink\" title=\"(n,k)纠错码\"></a>(n,k)纠错码</h4><div>$$\nB = E + A, \\forall A \\in \\chi\\\\\nS = BH^T = EH^T\\\\\n$$</div>\n\n<p>$S$ 与 $A$ 无关，$A$ 只是无用的陪同（coset）。</p>\n<p>陪集首：上述陪集的特征由 $S &#x3D; EH^T$ 标识，我们称 $E$ 为陪集首。</p>\n<p>陪集首一般选择集合中 “1” 最少的元素，这是为了优先标识错误数量较小的差错，这一类差错发生的概率较大。</p>\n<p>码重：</p>\n<div>$$\nw(A) =\\sum\\limits_{i=1}^{n}\\mathbf 1 \\lbrace a_i = 1 \\rbrace = d_H(A, 0)\n$$</div>\n\n<p>001 -&gt; 0,0,0,0,0,1 -&gt; 101</p>\n<p>010 -&gt; 0,0,0,0,1,0 -&gt; 011</p>\n<p>011 -&gt; 0,0,0,1,0,0 -&gt; 110</p>\n<p>100 -&gt; 0,0,1,0,0,0 -&gt; 001</p>\n<p>101 -&gt; 0,1,0,0,0,0 -&gt; 010</p>\n<p>110 -&gt; 1,0,0,0,0,0 -&gt; 100</p>\n<p>111 -&gt; 0,1,0,0,0,1 -&gt; 111</p>\n<h4 id=\"交织器\"><a href=\"#交织器\" class=\"headerlink\" title=\"交织器\"></a>交织器</h4><p>线性码的改进：</p>\n<ul>\n<li>上述线性码，均适合于纠正零散错误</li>\n<li>Hamming码对于2个以上的差错就无能为力</li>\n<li>若差错总是成对出现，则Hamming码基本没用</li>\n<li>在通信系统中，往往存在不可抗拒的突发错误</li>\n</ul>\n<p>例如：无线信道的衰落引起的误码</p>\n<p>抗突发误码的方法：交织器</p>\n<p>基本原理</p>\n<ul>\n<li>为了对付突发的信道差错，交织器改变发送码元的时<br>间顺序</li>\n<li>将原本相邻的码元在时间上的距离最大化</li>\n<li>例子：考虑一个（n, k）分组码，其交织后的输出为</li>\n</ul>\n<p>将突发误码转换成零星误码</p>\n<p>交织器的性能：</p>\n<p>宽度</p>\n<ul>\n<li>就是分组码的码长n</li>\n<li>决定于所采用的分组码</li>\n</ul>\n<p>深度</p>\n<ul>\n<li>深度m决定了相邻码元交织后的间隔</li>\n<li>m又称交织深度</li>\n<li>若分组码能纠b个突发错误，则交织后能纠mb个突发错误</li>\n</ul>\n<p>解交织：</p>\n<ul>\n<li>从另一个角度来看，解交织打散了突发误码</li>\n<li>化整为零后的零散误码，就可以交给解码器对付了</li>\n</ul>\n<h3 id=\"卷积码\"><a href=\"#卷积码\" class=\"headerlink\" title=\"卷积码\"></a>卷积码</h3><p>输入无限长的激励，则输出信号无限长，</p>\n<p>若冲激响应有限，则输出只与某一段输入有关</p>\n<p>卷积码的参数 $n, k, N$</p>\n<p>约束长度，信息码位，每次输出</p>\n<p>使用树状图进行分类讨论</p>\n<p>树状图的冗余：</p>\n<ul>\n<li>树状图具有很多冗余表示</li>\n</ul>\n<p>树状图的应用：计算最小码距</p>\n<ul>\n<li>分组码的最小码距定义为非零码字的最小码重</li>\n<li>和分组码不同，卷积码没有分组的概念</li>\n<li>约束长度隐含了某种独立性，可以只考虑 $kN$ 的信息比特编码后的非零码字，也就是考虑 $nN$ 个非零的编码输出位</li>\n</ul>\n<p>状态图的应用</p>\n<ul>\n<li>自由距：无限长信息序列编码后的最小汉明距离</li>\n<li>自由距不等于最小距</li>\n</ul>\n<p>自由距等于寄存器从零状态开始，经过非零状态，然后回到零状态的输出1的个数的最小值</p>\n<p>卷积码的译码</p>\n<h4 id=\"维特比译码\"><a href=\"#维特比译码\" class=\"headerlink\" title=\"维特比译码\"></a>维特比译码</h4><p>网格图</p>\n<p>最大似然下的最优译码</p>\n<ul>\n<li>低复杂度</li>\n<li>采用最小汉明距离作为代价函数</li>\n</ul>\n<p>采用动态规划的卷积码译码成为 viterbi 译码</p>\n<ul>\n<li>viterbi 译码的起始状态是 0 状态</li>\n<li>viterbi 译码没有确定的代价函数，</li>\n</ul>\n<p>分组码译码可以知道是否译码错误了。通过校验矩阵来校验就行了。</p>\n<p>但是 viterbi 译码并不能肯定译码结果是否正确。</p>\n<h3 id=\"硬判决和软判决\"><a href=\"#硬判决和软判决\" class=\"headerlink\" title=\"硬判决和软判决\"></a>硬判决和软判决</h3><p>硬判决：任务是检测和矫正误码</p>\n<p>软判决：应用于卷积&#x2F; Viterbi 译码器，迭代译码  </p>\n<h3 id=\"检错重发-ARQ\"><a href=\"#检错重发-ARQ\" class=\"headerlink\" title=\"检错重发 ARQ\"></a>检错重发 ARQ</h3><p>$P_c &#x3D; (1 - \\varepsilon)^n$ 为正确概率</p>\n<p>$P_d$ 检出错误概率</p>\n<p>$P_m$ 漏检概率</p>\n<div>$$\nP_c + P_d + P_m = 1\n$$</div>\n\n<p>总分组差错概率</p>\n<div>$$\nP_b = P_m + P_dP_m + P_d^2P_m + \\dots = \\frac{P_m}{1 - P_d} = \\frac{P_m}{P_c + P_m}\n$$</div>\n\n<h4 id=\"停等ARQ\"><a href=\"#停等ARQ\" class=\"headerlink\" title=\"停等ARQ\"></a>停等ARQ</h4><p>收到上一个 ACK&#x2F;NAK 再发送下一个包或者重传上一个包</p>\n<p>假设发送方一直传输（一次就能传输成功），吞吐量的上限为</p>\n<div>$$\n\\eta_{sw, 0} = \\frac{k}{T_DR}\\\\\nT_D = T_m + 2 T_d + T_c + T_a = T_m + T_{dca} = \\frac{k}{n + T_{dca}R}\n$$</div>\n\n<p>若有完美的差错检出能力 $P_d &#x3D; 1 - (1 - \\varepsilon)^n$</p>\n<p>则</p>\n<div>$$\n\\eta_{sw} = \\frac{k/n}{1 + T_{dca}R/n}(1 - \\varepsilon)^n\n$$</div>\n\n<h4 id=\"返回-N-ARQ\"><a href=\"#返回-N-ARQ\" class=\"headerlink\" title=\"返回 N-ARQ\"></a>返回 N-ARQ</h4><p>不等 ACK&#x2F;NAK 返回就传下一个包，若检错则重传从错误开始的所有包</p>\n<div>$$\n\\eta_{GBN, 0} = \\frac{k}{n}\n$$</div>\n\n"},{"title":"Statistical Signal Processing","katex":true,"date":"2024-02-26T03:12:57.000Z","_content":"\n## 参数估计\n\n分类：\n\n* 经典估计\n* 贝叶斯估计\n\n准则：\n\n* MSE，均方误差\n\n$$\n\\hat \\theta = f(\\bm{x})\n$$\n\n### MSE\n\n$$\n\\text{mse}(\\hat \\theta) = E \\lbrace(\\theta - \\hat \\theta)^2\\rbrace = \\text{var}(\\hat \\theta) + b^2(\\hat \\theta)\\\\\nb^2(\\hat \\theta) = E(\\hat \\theta) - \\theta\n$$\n\n现实中无法直接计算 MSE，因为涉及到真值 $\\theta$，但是 $\\theta$ 是我们要求的参数。\n\n### MVU\n\n最小方差无偏估计\n\nMVU, Minimum Variance Unbiased\n\n无偏：\n\n$$\nE(\\hat \\theta) = \\theta, a \\lt \\theta \\lt b\n$$\n\n无偏的含义：$\\hat \\theta$ 的求法需要对取值范围内任意的 $\\theta$ 进行估计。\n\n无偏估计是否一定存在？不一定。\n\n最小方差：\n\n$$\n\\min \\text{var}\\lbrace\\hat\\theta\\rbrace\n$$\n\nMVU的内涵：估计值的发散程度最小（最小方差），平均意义上靠近真值（MVU）。是对 MSE 的迂回实现。\n\n### 克拉美罗界定理(CRLB)\n\n假设 $p(\\bm{x};\\theta)$ 满足正则条件：\n\n$$\nE \\left [ \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta} \\right] = 0\n$$\n\n则\n\n$$\n\\text{var}(\\hat\\theta) \\ge \\frac{1}{E \\left [\\left( \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta}\\right)^2 \\right]} = - \\frac{1}{E \\left [ \\frac{\\partial^2\\ln p(\\bm{x};\\theta)}{\\partial\\theta^2} \\right]}\n$$\n\n等号成立的充要条件：找到函数 $I, g$\n\n$$\n\\frac{\\partial \\ln p(\\bm{x};\\theta)}{\\partial \\theta}= I(\\theta)(g(\\bm{x}) - \\theta)\\\\\n\\hat \\theta = g(\\bm{x})\n$$\n\n此时有 $\\text{var}(\\hat\\theta) =1 / I(\\theta)$。\n\n### 求解MVU\n\n$$\n\\frac{\\partial \\ln p(\\bm{x};A)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A) = \\frac{N}{\\sigma^2}\\left (\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)  \\right)\n$$\n\n$$\ng(\\bm{x}) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]\\\\\nI(\\theta) = \\frac{N}{\\sigma^2}\n$$\n\n有效估计量：能达到克拉美罗下界的估计量，是MVU的子集。\n\n### 参数变换的克拉美罗界\n\n若\n\n$$\n\\alpha = g(\\theta)\n$$\n\n则\n\n$$\nCRLB(\\hat \\alpha) = \\left(\\frac{\\partial g(\\theta)}{\\partial \\theta}\\right)^2CRLB(\\hat \\theta)\n$$\n\n对于高斯分布有\n\n$$\nE(x^2) = \\mu^2 + \\sigma^2\\\\\nE(x^4) = \\mu^4 + 6\\mu^2\\sigma^2 + 3\\sigma^4\n$$\n\n当数据量很大时\n\n有效估计量靠近真值：$N \\rightarrow \\infty, \\hat\\theta \\rightarrow \\theta$\n\n非线性变换渐进有效,可以看成线性函数：$g(\\hat \\theta) \\approx g(\\theta) + \\frac{\\partial g(\\theta)}{\\partial\\theta}(\\hat \\theta - \\theta)$\n\n### 矢量参数的克拉美罗界\n\n$$\nE \\left [ \\frac{\\partial \\ln p(\\bm{x};\\bm{\\theta})}{\\partial \\bm{\\theta}} \\right] = 0\n$$\n\n$$\n\\alpha = g(\\theta)\n$$\n\n![](../images/StaSP/1_1.jpg)\n\n注意：$\\bm T(\\bm x)$ 的维度要和 $\\bm \\theta$ 的维度相同\n\n## 线性模型方法\n\n$$\nx = H\\theta + w, w \\sim N(0, \\sigma^2I)\n$$\n\n$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2}(x - H\\theta)^T(x - H\\theta) \\rbrace\n$$\n\n$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\theta} = \\frac{H^TH}{\\sigma^2}\\lbrace (H^TH)^{-1}H^Tx - \\theta \\rbrace\n$$\n\n从而\n\n$$\n\\hat \\theta = (H^TH)^{-1}H^Tx\\\\\nC_{\\hat\\theta} = \\sigma^2(H^TH)^{-1}\n$$\n\n这个 MVU 估计量满足\n\n$$\n\\hat \\theta \\sim N(\\theta, \\sigma^2(H^TH)^{-1})\n$$\n\n* 要求观测数据与待估计参数间呈线性关系\n* 要求噪声是高斯白噪声\n* 要求观测矩阵是满秩的\n* 所得估计量是有效估计量\n\n一般信号模型\n\n$$\nx = H\\theta + s + w, s已知，w \\sim N(0, C)\n$$\n\n结论\n\n$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}(x - s)\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$\n\n## 充分统计量方法\n\n$$\np(x|T(x);\\theta) = p(x|T(x))\n$$\n\n则称 $T(x)$ 为充分统计量\n\n充分统计量的性质:\n\n* 一旦充分统计量确定，似然函数就与待估计参数无关\n* 充分统计量依赖于待估计参数。待估计参数变化，其相应的充分计量一般也会变化\n* 所谓“充分”，是相对于原始观测数据而言的原始观测量总是充分统计量，但通常不是最小集\n* 充分统计量并不唯一\n\n若\n\n$$\n\\int_{-\\infty}^{\\infty}v(T)p(T;\\theta)\\mathrm dT = 0\n$$\n\n对所有的 $\\theta$ 并非都满足，只对零函数 $v(T) = 0$ 成立，则称充分统计量是完备的。\n\n* 一般地，当待估计参数发生变化时，充分统计量也会发生变化\n* 一旦充分统计量确定以后，似然函数就与待估计参数无关\n\n### Neyman-Fisher因子分解定理\n\n如果概率密度函数（或概率质量函数，对于离散随机变量）$p(x; \\theta)$ 可以被分解为\n\n$$\np(x; \\theta) = g(T(x); \\theta) \\cdot h(x)\n$$\n\n其中：\n\n- $g(T(x); \\theta)$ 是一个只通过统计量 $T(x)$ 并依赖于参数 $\\theta$ 的函数。\n- $h(x)$ 是只与观测数据 $x$ 相关的函数，与参数 $\\theta$ 无关。\n\n那么，统计量 $T(x)$ 是参数 $\\theta$ 的充分统计量。反之，如果 $T(x)$ 是参数 $\\theta$ 的充分统计量，那么概率密度函数 $p(x; \\theta)$ 必然可以分解为上述形式。\n\n### Rao-Black-Lehmann-Scheffe(RBLS)定理\n\n若 $\\breve\\theta$ 是$\\theta$的无偏估计，$T(x)$是$\\theta$的充分统计量，那么$\\hat \\theta=E(\\breve{\\theta}|T(x))$\n\n1. 是$\\theta$ 的一个适用的估计量(与$\\theta$无关)\n2. 无偏的\n3. 对所有的 $\\theta$，它的方差小于等于$\\breve\\theta$ 的方差\n4. 若$T(x)$是完备的，那么$\\theta$是MVU估计量\n\n#### 矢量参数的 RBLS\n\n![](../images/StaSP/2_1.jpg)\n\n![](../images/StaSP/2_2.png)\n\n## BLUE\n\n### 定义\n\n直接求出数据->参数的映射 $\\bm A_{p \\times N}$：\n\n$$\n\\bm x = \\bm H \\theta\\\\\n\\hat {\\theta}_{p \\times 1} = \\bm A\\bm x\n$$\n\n无偏性：\n\n$$\n\\theta = E(\\hat\\theta) = \\bm AE(\\bm x) = \\bm AH\\theta\\\\\n\\Rightarrow AH = I_{p \\times p}\n$$\n\n最佳（最小方差）\n\n$$\n\\min \\lbrace a_i^TCa_i \\rbrace, A = [a_1, a_2, \\dots, a_n]^T\n$$\n\n其中\n\n$$\nC = E \\lbrace (x - E(x))(x - E(x))^T \\rbrace\n$$\n\n### 高斯-马尔可夫定理\n\n如果数据具有一般线性模型的形式\n\n$$\n\\bm x = \\bm H \\theta + w\n$$\n\n其中 $\\bm H$ 为已知 $N \\times p$ 矩阵，$\\theta$ 为待估计参数，$w$ 是均值为零、协方差为 $\\bm C$ 的噪声矢量（**不一定为高斯**），则 BLUE 估计量为\n\n$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}x\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$\n\n* 若为高斯噪声，则BLUE为MVU，且为有效估计量\n\n## MLE\n\n### 定义\n\n$$\n\\hat \\theta = \\arg\\max\\limits_\\theta p(\\bm{x};\\theta)\n$$\n\n如果 PDF 可导\n\n$$\n\\frac{\\partial p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\\\\\n\\Rightarrow\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\n$$\n\n若有效估计量存在，$\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = I(\\theta)(g(x) - \\theta)$，则可以使用最大似然估计方法求得结果。\n\n### MLE 的性质\n\n如果数据 $\\bm x$ 的 PDF $p(\\bm x;\\theta)$ 满足“正则”条件，那么\n对于足够多的数据记录，未知参数 $\\theta$ 的 MLE 渐近服从\n\n$$\n\\hat\\theta \\stackrel{a}{\\sim} N(\\theta, I^{-1}\\theta)\n$$\n\n其中 $\\theta$ 是在未知参数真值处计算的 Fisher 信息。\n\nMLE是渐近无偏的\n\nMLE渐近达到CRLB\n\nMLE是渐近有效的\n\nMLE是渐近最佳的\n\n* MLE的方差（协方差）可大于、等于、小于CRLB！（不同于MVU估计）\n* 但数据量足够多时，将与CRLB接近\n* 因此，可利用CRLB评估MLE的性能\n\n“足够多”数据：大量能带来新信息的数据\n\n**MLE的不变性**\n\n若参数 $\\alpha = g(\\theta)$，则\n\n$$\n\\hat\\alpha = g(\\hat\\theta)\n$$\n\n若 $g$ 非一对一函数，那么 $\\hat\\alpha$ 是使修正后的似然函数 $p_T(\\bm x;\\alpha)$ 最大者\n\n$$\n\\hat\\alpha = \\arg\\max_\\alpha p_T(\\bm x; \\alpha)\\\\\np_T(\\bm x; \\alpha) = \\max_{\\theta: \\alpha=g(\\theta)}p(\\bm x; \\theta)\n$$\n\n该性质对函数 $g$ 无线性变换要求，对任意函数均成立。\n\n对比MVU\n\n* 无偏性、有效性仅对线性变换成立\n* 对非线性变换不能保持（但渐近无偏、渐近有效）\n\n对一般线性模型，MLE是MVU，达到了CRLB，是有效的、最佳的！\n\n![1711254850893](../images/StaSP/1711254850893.png)\n\n## 最小二乘估计(LS)\n\n### 线性最小二乘估计\n\n![1711339154789](../images/StaSP/1711339154789.png)\n\n### 加权最小二乘估计\n\n![1711339192281](../images/StaSP/1711339192281.png)\n\n### 约束最小二乘估计\n\n![1711339216759](../images/StaSP/1711339216759.png)\n\n### 比较\n\n![1711339249863](../images/StaSP/1711339249863.png)\n\n## 经典估计方法比较\n\n### 噪声电平估计问题\n\n$$\nx[n] = A + w[n]\n$$\n\n其中 $w[n] \\sim N(0, \\sigma^2)$，待估计参数 $\\theta = [A, \\sigma^2]^T$\n\n#### MVU估计\n\n$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2} \\sum\\limits_{n=0}^{N - 1}(x[n] - A)^2\\rbrace\n$$\n\n$$\n\\frac{\\partial \\ln p (x;\\theta)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$\n\n$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\sigma^2} = \\frac{N}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$\n\n![1711339773571](../images/StaSP/1711339773571.png)\n\n![1711339786814](../images/StaSP/1711339786814.png)\n\n#### 线性模型\n\n$$\n\\hat\\theta = (\\bm H^T\\bm H)^{-1}\\bm  H^T x\n$$\n\n![1711339831807](../images/StaSP/1711339831807.png)\n\n#### BLUE\n\n$$\n\\hat\\theta = (\\bm H^T\\bm C^{-1}\\bm H)^{-1}\\bm  H^T\\bm C^{-1} x\n$$\n\n![1711339865703](../images/StaSP/1711339865703.png)\n\n#### 充分统计量\n\n![1711340151724](../images/StaSP/1711340151724.png)\n\n![1711340163113](../images/StaSP/1711340163113.png)\n\n![1711340177961](../images/StaSP/1711340177961.png)\n\n#### MLE\n\n![1711340277148](../images/StaSP/1711340277148.png)\n\n#### LSE\n\n![1711340293644](../images/StaSP/1711340293644.png)\n\n## 贝叶斯估计\n\n贝叶斯MSE：\nBmse$\\left(\\hat{\\theta}\\right)=E\\left(\\left(\\theta-\\hat{\\theta}\\right)^2\\right)$\n\n\n$=\\int\\int\\left(\\theta-\\hat{\\theta}\\right)^{2}p\\big(\\mathbf{x},\\theta\\big)d\\mathbf{x}d\\theta$ $=\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p\\big(\\boldsymbol{x}|\\theta\\big)p\\big(\\theta\\big)d\\boldsymbol{x}d\\theta$\n $=\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p(x|\\theta)dxp(\\theta)d\\theta$\n\n$\\hat{\\theta}=E\\big(\\theta|x\\big)$\n\n多余参数：未知，但不感兴趣的参数\n 解决思路：通过积分消除多余参数的影响\n (1) 后验概率中存多余参数时：\n\n$$\np(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x}) \\Rightarrow p (\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\int p(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x})\\:d\\boldsymbol{\\alpha}\n$$\n\n(2) 条件概率中存在多余参数时：\n\n$$\np(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\frac{p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{\\int p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}\n$$\n\n$$\n\\text{若现只有 }p(x|\\theta,\\alpha)\\text{,而无 }p(x|\\theta)\n$$\n 此时可通过积分方式解决\n\n$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha\\mid\\theta)d\\alpha \n$$\n\n进一步地，若待估计参数与多余参数相互独立，\n\n$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha)d\\alpha \n$$\n\n矢量参数下贝叶斯估计\n若 θ 是 $p{\\times}1$ 的矢量参数，那么为了估计其中某个参数 $\\theta_i$, 可以将剩余参数当作多余参数，因此对$\\theta_i$ 的MMSE为\n\n$$\n\\hat{\\theta}_i=E\\left(\\theta_i\\mid x\\right)=\\int\\theta_ip(\\theta_i\\mid x)d\\theta_i\n$$\n 其中\n\n$$\np(\\theta_i\\mid x)=\\int\\cdots\\int p(\\theta\\mid x)d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p\n$$\n\n$$\n\\hat{\\theta}_i=\\int\\theta_i\\left(\\int\\cdots\\int p(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})\\underline{d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p}\\right)d\\theta_i=\\int\\theta_ip(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})d\\boldsymbol{\\theta}\n$$\n\n$$\n\\Longrightarrow\\hat{\\theta}=\\begin{bmatrix}\\theta_1p(\\theta|x)d\\theta\\\\\\int\\theta_2p(\\theta|x)d\\theta\\\\\\vdots\\\\\\int\\theta_pp(\\theta|x)d\\theta\\end{bmatrix}=\\int\\theta_P(\\theta|x)d\\theta=E(\\theta|x)\n$$\n\nWoodbury 恒等式：\n\n$$\n\\left(\\mathbf{B}+\\boldsymbol{u}\\boldsymbol{u}^T\\right)^{-1}=\\mathbf{B}^{-1}-\\frac{\\mathbf{B}^{-1}\\boldsymbol{u}\\boldsymbol{u}^T\\mathbf{B}^{-1}}{1+\\boldsymbol{u}^T\\mathbf{B}^{-1}\\boldsymbol{u}}\n$$\n\n### 贝叶斯风险\n\n$$\n\\Re=\\iint C(\\varepsilon)p(x,\\theta)dxd\\theta \n$$\n\n#### 二次型误差\n\n$$\nC(\\varepsilon) = \\begin{pmatrix}\\theta-\\hat{\\theta}\\end{pmatrix}^2\n$$\n\n这就是 MMSE\n\n此时为平均值。\n\n#### 绝对误差\n\n$$\nC(\\varepsilon)=\\begin{vmatrix}\\theta-\\hat{\\theta}\\end{vmatrix}\n$$\n\n> Leibnitz 准则\n> $\\frac{\\partial}{\\partial u}\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}h\\big(u,v\\big)dv=\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}\\frac{\\partial h\\big(u,v\\big)}{\\partial u}dv+\\frac{\\partial\\phi_2\\big(u\\big)}{\\partial u}h\\big(u,\\phi_2\\big(u\\big)\\big)-\\frac{\\partial\\phi_1\\big(u\\big)}{\\partial u}h\\big(u,\\phi_1\\big(u\\big))$\n\n此时\n\n$$\n\\int_{-\\infty}^{\\hat{\\theta}}p\\big(\\theta|x\\big)d\\theta=\\int_{\\hat{\\theta}}^{+\\infty}p\\big(\\theta|x\\big)d\\theta \n$$\n\n为中位数\n\n#### 成功失败型误差\n\n$$\nC(\\varepsilon)=\\begin{cases}0,\\left|\\theta-\\hat{\\theta}\\right|<\\delta\\\\1,\\left|\\theta-\\hat{\\theta}\\right|\\geq\\delta\\end{cases}\n$$\n\n此时 \n\n$$\n\\hat{\\theta}=\\arg\\max_{\\theta}p(\\theta|x)\n$$\n\n即 $\\hat{\\theta}$ 是后验PDF的最大值 (众数) \n\nMAP maximum a posteriori\n\n根据贝叶斯公式\n\n$$\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\{p(x|\\theta)p(\\theta)\\right\\}\\\\\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\{\\ln p\\big(x|\\theta\\big)+\\ln p\\big(\\theta\\big)\\right\\}\n$$\n\n#### 三值比较\n一般而言，“三值”并不相等，因此三种估计量往往不同\n\n特例：高斯时“三值”相等，三种估计方法等价\n\n大数据量时先验信息不起作用，最大后验概率估计（MAP）将转变为（贝叶斯）最大似然估计（MLE）\n\n### 线性贝叶斯估计\n\n线性贝叶斯估计(LMMSE), 也称线性最小意味着：\n\n$$\n\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$\n\n即限定估计量与观察数据间呈线性关系，然最小化 \n$$\n\\mathrm{Bmse}\\Big(\\hat{\\theta}\\Big)=E\\Big[\\Big(\\theta-\\hat{\\theta}\\Big)^{2}\\Big]\n$$\n\n即，LMMSE:\n\n$$\n\\min\\left\\{E\\left[\\left(\\theta-\\hat{\\theta}\\right)^2\\right]\\right\\}\\\\s.t.\\quad\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$\n\n解得估计量：\n\n$$\n\\hat{\\theta}=E\\left(\\theta\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(x-E\\left(x\\right)\\right)\\\\\\mathrm{Bmse}\\left(\\hat{\\theta}\\right)=\\mathbf{C}_{\\theta\\theta}-\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\mathbf{C}_{x\\theta}\n$$\n\n对比 MMSE：\n\n附加了线性约束\n- 可得显示解——好求\n- 仅需一阶矩和二阶矩\n\n无附加约束\n- 可能难以求得显示解\n- 需PDF\n- 全局最优\n- 仅在“线性”中最优\n\n#### 矢量参数情况\n\n待估计参数$\\boldsymbol{\\theta}=\\begin{bmatrix}\\theta_1,\\theta_2,...,\\theta_p\\end{bmatrix}^T$,其每个参数的 LMMSE 定义为\n\n$$\n\\begin{aligned}&\\min E\\bigg[\\bigg(\\theta_{i}-\\hat{\\theta}_{i}\\bigg)^{2}\\bigg]\\\\&s.t.\\hat{\\theta}_{i}=\\sum_{n=0}^{N-1}a_{in}x[n]+a_{iN}\\end{aligned}\n$$\n\n$$\n\\hat{\\boldsymbol{\\theta}}=\\begin{bmatrix}E(\\theta_1)\\\\E(\\theta_2)\\\\\\vdots\\\\E(\\theta_p)\\end{bmatrix}+\\begin{bmatrix}\\mathbf{C}_{\\theta_1x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\mathbf{C}_{\\theta_2x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\vdots\\\\\\mathbf{C}_{\\theta_px}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\end{bmatrix}\\\\\n=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x} - E(\\boldsymbol{x})\\right)\n$$\n\n### 序贯LMMSE\n\n白噪声电平估计\n\n$$\nx[n]=A+w[n],n=0,1,...,N\n$$\n\n$$\nA\\sim N\\big(0,\\sigma_{A}^{2}\\big)\\\\\nw[n]\\sim N\\left(0,\\sigma^{2}\\right)\n$$\n\n解得\n\n$$\n\\begin{aligned}\n&E(\\theta)=0 \\\\\n&\\mathbf{C}_{\\theta x}=E\\left(\\left(\\theta-E\\left(\\theta\\right)\\right)\\left(x-E\\left(x\\right)\\right)^{T}\\right) \\\\\n&=E\\left(\\left(A-0\\right)\\left(x-0\\right)^{T}\\right) \\\\\n&=E\\Big(A\\big(A\\mathbf{1}+\\mathbf{w}\\big)^{T}\\Big) \\\\\n&=\\sigma_{A}^{2}\\mathbf{1}^{T}\n\\end{aligned}\\\\\n\\begin{aligned}\n\\mathbf{C}_{xx}& =E\\left(\\left(x-E\\left(x\\right)\\right)\\left(x-E\\left(x\\right)\\right)^T\\right)  \\\\\n&=E\\left(\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)^T\\right) \\\\\n&=E\\left\\{A\\mathbf{1}\\mathbf{1}^TA+A\\mathbf{1}\\boldsymbol{w}^T+\\boldsymbol{w}\\mathbf{1}^TA+\\boldsymbol{w}\\boldsymbol{w}^T\\right\\} \\\\\n&=\\sigma_A^2\\mathbf{1}\\mathbf{1}^T+\\sigma^2\\mathbf{I}\n\\end{aligned}\\\\\n\\begin{aligned}\\mathbf{C}_{\\theta\\theta}&=\\sigma_A^2\\\\\\mathbf{C}_{x\\theta}&=\\mathbf{C}_{\\theta x}^T\\\\&=\\sigma_A^2\\mathbf{1}\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\\hat{A}&=\\frac{\\sigma_{A}^{2}}{\\sigma_{A}^{2}+\\frac{\\sigma^{2}}{N}}\\\\\\mathrm{Bmse}&\\left(\\hat{A}\\right)=\\frac{1}{N}\\end{aligned}\n$$\n\n记\n\n$$\n\\hat{A}[N-1]=\\frac{\\sigma_A^2}{\\sigma_A^2+\\frac{\\sigma^2}{N}}\\frac{1}{N}\\sum_{n=0}^{N-1}x[n]\n$$\n\n则\n\n$$\n\\hat{A}[N]=\\hat{A}[N-1]+\\underbrace{\\frac{\\sigma_A^2}{\\left(N+1\\right)\\sigma_A^2+\\sigma^2}}_{K[N]，增益因子}\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$\n\n$$\n\\frac{\\frac1{\\sigma^2}}{\\frac1{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}+\\frac1{\\sigma^2}}=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\\\\=\\frac{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}}{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}+\\sigma^2}=\\frac{\\sigma_A^2}{\\left(N\\sigma_A^2+\\sigma^2\\right)+\\sigma_A^2}=K\\begin{bmatrix}N\\end{bmatrix}\n$$\n\n一般方法\n\n序贯计算方法估计量更新：\n\n$$\n\\hat{A}[N]=\\hat{A}[N-1]+K[N]\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$\n\n增益因子：\n\n$$\nK\\left[N\\right]=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\n$$\n\n最小贝叶斯MSE更新：\n\n$$\n\\mathrm{Bmse}\\Big(\\hat{A}[N]\\Big)\\boldsymbol{=}\\Big(1\\boldsymbol{-}K[N]\\Big)\\mathrm{Bmse}\\Big(\\hat{A}[N\\boldsymbol{-}1]\\Big)\n$$\n\n初始化：\n\n$$\n\\hat{A}[-1]=E(A)\\\\\n\\text{Bmse}\\left ( \\hat{A} [ - 1] \\right ) = \\text{var}\\left ( A\\right ) \n$$\n\n## 维纳滤波\n\n### 滤波\n\n假定观测数据是零均值、宽平稳的，信号也是零均值、宽平稳的，信号与噪声不相关\n\n$$\nx[n] = s[n] + w[n], n = 0, 1, \\dots, N - 1\n$$\n\n$$\n\\theta=s[n]\\text{ 用 }x[0],x[1],x[2],...,x[n]\\text{来估计}$$\n\n![1713150769252](../images/StaSP/1713150769252.png)\n\n利用 LMMSE 可得\n$$\n\\hat{s}[n]=r_{ss}^{'T}\\left(\\mathbf{R}_{ss}+\\mathbf{R}_{ww}\\right)^{-1}\\boldsymbol{x}\n$$\n从而得到维纳-霍夫滤波方程\n$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}n\\end{bmatrix}&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h^{(n)}\\begin{bmatrix}0\\end{bmatrix}\\\\h^{(n)}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\h^{(n)}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{ss}\\begin{bmatrix}0\\end{bmatrix}\\\\r_{ss}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\r_{ss}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}\n$$\n### 平滑\n$$\n\\theta=s[n]\\text{用 }...,x[-1],x[0],x[1],x[2],...,\\text{来估计}\n$$\n![1713152016025](../images/StaSP/1713152016025.png)\n\nLMMSE:\n$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$\n令 $h[k] = a_{N-k}$\n\n> 正交原理：误差与每一个观测数据正交\n> $$\n> E\\left(\\left(\\theta-\\hat{\\theta}\\right)x[m]\\right)=0\n> $$\n> 正交原理不依赖于任务是平滑、滤波还是预测，是普遍适用的，证明如下：\n> ![1713152987612](../images/StaSP/1713152987612.png)\n> ![1713152970273](../images/StaSP/1713152970273.png)\n在 LMMSE\n$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$\n中令 $h[k]=a_{n-k}$\n\n则有\n$$\n\\hat s[n] = \\sum\\limits_{k=-\\infty}^{\\infty}h[k]x[n-k]\n$$\n可得\n$$\nr_{ss}\\begin{bmatrix}n\\end{bmatrix}=h\\begin{bmatrix}n\\end{bmatrix}*r_{xx}\\begin{bmatrix}n\\end{bmatrix}\n$$\n无限维纳平滑器的频率响应\n$$\nH\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{xx}\\left(f\\right)}\\quad=\\frac{P_{ss}\\left(f\\right)}{P_{ss}\\left(f\\right)+P_{ww}\\left(f\\right)}\\quad=\\frac{\\eta\\left(f\\right)}{\\eta\\left(f\\right)+1}\\quad\\text{,其中 }\\eta\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{ww}\\left(f\\right)}\n$$\n### 预测\n\n可以用来进行预测\n$$\n\\theta=x[N-1+l]\\text{ 用 }x[0],x[1],x[2],...,x[N-1]\\text{ 来估计}\n$$\n![1713150674892](../images/StaSP/1713150674892.png)\n\n依然用 LMMSE 可以得到线性预测维纳-霍夫滤波方程\n$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h\\begin{bmatrix}1\\end{bmatrix}\\\\h\\begin{bmatrix}2\\end{bmatrix}\\\\\\vdots\\\\h\\begin{bmatrix}N\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{xx}\\begin{bmatrix}l\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}l+1\\end{bmatrix}\\\\\\vdots\\\\r_{xx}\\begin{bmatrix}N-1+l\\end{bmatrix}\\end{bmatrix}\n$$\n### 应用\n\n信道均衡问题\n\n![1713151589324](../images/StaSP/1713151589324.png)\n\n## 卡尔曼滤波\n\n如何估计电压？\n\n### 模型 1：当成确定参数\n$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2})\n$$\n\n$$\n\\hat A = \\sum\\limits_{n=0}^{N - 1}x[n] = \\bar x\n$$\n### 模型2：当成某个随机变量\n$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2}), A \\sim N(\\mu_A, \\sigma_A^{2})\n$$\n贝叶斯一般线性模型：\n$$\n\\boldsymbol{x}=\\mathbf{H}\\boldsymbol{\\theta}+\\boldsymbol{w}\\quad\\text{其中 }\\boldsymbol{\\theta}{\\sim}N\\begin{pmatrix}\\boldsymbol{\\mu}_\\theta,\\mathbf{C}_\\theta\\end{pmatrix}\\text{,}\\boldsymbol{w}{\\sim}N\\begin{pmatrix}\\boldsymbol{0},\\mathbf{C}_w\\end{pmatrix}\\\\\nE\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E\\left(\\boldsymbol{x}\\right)\\right)=\\boldsymbol{\\mu}_\\theta+\\mathbf{C}_{\\theta|x}\\mathbf{H}^T\\mathbf{C}_w^{-1}\\left(\\boldsymbol{x}-\\mathbf{H}\\boldsymbol{\\mu}_\\theta\\right)\\\\\n\\text{其中,}\\mathbf{C}_{\\theta|x}=\\left(\\mathbf{C}_\\theta^{-1}+\\mathbf{H}^T\\mathbf{C}_w^{-1}\\mathbf{H}\\right)^{-1}\n$$\n\n$$\n\\hat{A}=\\mu_A+\\frac{\\frac1{\\sigma^2/N}}{\\frac1{\\sigma_A^2}+\\frac1{\\sigma^2/N}}(\\overline{x}-\\mu_A)\n$$\n### 模型3：当成未知且随时间变化的量\n$$\nx[n]=A[n]+w[n],n=0,1,...,N-1\n$$\n\n$$\n\\mathrm{MVU}\\text{估计量:}\\hat{\\boldsymbol{\\theta}}=\\left(\\mathbf{H}^T\\mathbf{H}\\right)^{-1}\\mathbf{H}^T\\boldsymbol{x}\\\\\n\\begin{aligned}&\\boldsymbol{\\theta}=&\\begin{bmatrix}A[0],A[1],...,A[N-1]\\end{bmatrix}^T\\\\&\\mathbf{H}=\\mathbf{I}\\end{aligned}\\\\\n\\hat{A}[n]=x[n]\n$$\n### 动态信号模型\n\n一阶高斯-马尔可夫信号模型：\n$$\ns[n]=as[n-1]+u[n],n\\geq0\n$$\n其中，$u[n]$是均值为零方差为 $\\sigma_u^2$ 的高斯白噪声，称为驱动噪声或激励噪声。信号初值s$[-1]\\sim N(\\mu_s,\\sigma_s^2)$与激励噪声$u[n]$相互独立。\n\n均值：\n$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\\\\nE\\left(s[n]\\right)=a^{n+1}E\\left(s[-1]\\right)+\\sum_{k=0}^na^kE\\left(u[n-k]\\right)=a^{n+1}\\mu_s\\\\\nc_s[m,n] = a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^m\\sum_{l=0}^na^{k+l}E\\left(u[m-k]u[n-l]\\right)\\\\\nE\\left(u[m-k]u[n-l]\\right)=\\begin{cases}\\sigma_u^2,&l=n-m+k\\\\0,&\\mathrm{others}\\end{cases}\n$$\n协方差：\n$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m+n+2}\\sigma_s^2+\\sum_{k=m-n}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\\\\nm \\lt n, c_s\\begin{bmatrix}m,n\\end{bmatrix}=a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{n-m}\\sum_{k=0}^ma^{2k}=c_s\\begin{bmatrix}n,m\\end{bmatrix}\n$$\n方差和二阶矩：\n$$\n\\begin{aligned}\n\\operatorname{var}(s[n])& =E\\left(\\left(s[n]-E\\left(s[n]\\right)\\right)\\left(s[n]-E\\left(s[n]\\right)\\right)\\right)  \\\\\n&=c_s[n,n] \\\\\n&=a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\n\\end{aligned}\\\\\n\\text{当 }m\\geq n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{m-n}\\sum_{k=0}^{n}a^{2k}\\\\\\text{当 }m<n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{n-m}\\sum^{m}a^{2k}=r_{ss}\\left[n,m\\right]\n$$\n#### 平稳性\n$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=a^{n+1}\\mu_s\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\end{aligned}\n$$\n不是宽平稳的。\n\n通常要求 $|a| \\lt 1$，当取 $n \\rarr \\infty$ 时\n$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=0\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\frac{1-a^{2n+2}}{1-a^2}=\\frac{\\sigma_u^2a^{m-n}}{1-a^2}=r_{ss}\\left[k\\right]\\end{aligned}\n$$\n此时是宽平稳（WSS）的。\n\n#### 递推特性\n$$\nE\\left(s[n]\\right)=aE\\left(s[n-1]\\right)+E\\left(u[n]\\right)=aE\\left(s[n-1]\\right)\n$$\n\n$$\n\\operatorname{var}\\left(s[n]\\right)=E\\left(\\left(s[n]-E(s[n])\\right)\\left(s[n]-E(s[n])\\right)\\right) = a^2\\operatorname{var}\\left(s[n-1]\\right)+\\sigma_u^2\n$$\n\n$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m-n}\\operatorname{var}\\left(s[n]\\right) = a^{m-n}\\left(a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\\right)\\\\\nm \\le n, c_s\\left[m,n\\right]=c_s\\left[n,m\\right]=a^{n-m}\\operatorname{var}\\left(s\\left[m\\right]\\right)\n$$\n### 卡尔曼滤波\n\n状态方程：$s[n]=as\\left[n-1\\right]+u\\left[n\\right]$\n\n观测方程：$x[n]=s\\left[n\\right]+w[n]$\n\n驱动噪声 $u[n]$ 相互独立且 $u[n] \\sim N(0, \\sigma^2)$，观测噪声 $w[n]$ 相互独立且 $w[n] \\sim N(0, \\sigma^2)$，起始条件 $s[-1] \\sim N(0, \\sigma_s^2)$。假定 $s[-1], u[n], w[n]$ 之间相互独立。\n\n* 提高估计性能：利用待估计参数的内在联系提高性能\n* 减小运算量：通过“老”估计量更新得到“新”估计量\n\n性质：\n\n对联合高斯独立数据矢量可加性：\n\n若$\\theta,x_1,x_2$是联合高斯的，数据矢量$x_1,x_2$ 相互独立，则MMSE估计量为：\n$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x_1}\\mathbf{C}_{x_1x_1}^{-1}\\left(\\boldsymbol{x}_1-E\\left(\\boldsymbol{x}_1\\right)\\right)+\\mathbf{C}_{\\theta x_2}\\mathbf{C}_{x_2x_2}^{-1}\\left(\\boldsymbol{x}_2-E\\left(\\boldsymbol{x}_2\\right)\\right)\n$$\n对待估计参数的可加性：\n\n若 $\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2$, 则相应的MMSE估计量是可加的，即\n$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1\\mid\\boldsymbol{x}\\right)+E\\left(\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)\n$$\n线性变换的不变性：\n\n若$\\alpha=\\mathbf{A\\theta}+\\boldsymbol{b},\\quad\\theta$ 的MMSE估计量是 $\\theta$, 则 $\\alpha$ 的MMSE估计量为：\n$$\n\\hat{\\alpha}=\\mathbf{A}\\hat{\\theta}+b\n$$\n定义：\n$$\n\\hat{s}[n-1]=E\\left(s[n-1]|x[0],x[1],...,x[n-1]\\right)\\triangleq\\hat{s}[n-1\\mid n-1]\\\\\nM\\begin{bmatrix}n-1\\end{bmatrix}=E\\left(\\left(s\\begin{bmatrix}n-1\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n-1\\end{bmatrix}\\right)^2\\right)\\\\\n\\hat s[n] \\triangleq\\hat{s}[n\\mid n]\n$$\n其中，前面的 n 表示被估计的信号下表，后面的 n 表示估计量用到的数据中最新的那个数据的下标。\n\n如果能够提取出第 n 个数据点带来的新的信息，并加入之前已有的估计量，就可更新估计量：\n$$\n\\begin{aligned}\n\\hat{s}\\Big[n|n\\Big]& =E\\left(s[n]|x[0],x[1],...,x[n-1],x[n]\\right)  \\\\\n&=E\\left(s[n]|x[0],x[1],...,x[n-1],\\tilde{x}[n]\\right) \\\\\n&=\\underbrace{E\\left(s[n]|x[0],x[1],...,x[n-1]\\right)}_{先前数据估计}+\\underbrace{E\\left(s[n]|\\tilde{x}[n]\\right)}_{新息估计}\n\\end{aligned}\n$$\n新息与已有的数据正交。\n$$\n\\tilde{x}[n]=x[n]-\\hat{x}[n|n-1]\n$$\n“先前数据估计”怎么求解？\n$$\n\\begin{aligned}\n\\hat{s}[n\\mid n-1]& =E\\left(as[n-1]+u[n]|x[0],x[1],...,x[n-1]\\right)  \\\\\n&=E\\left(as[n-1]|x[0],x[1],...,x[n-1]\\right)+E\\left(u[n]|x[0],x[1],...,x[n-1]\\right) \\\\\n&=aE\\left(s\\begin{bmatrix}n-1\\end{bmatrix}|x\\begin{bmatrix}0\\end{bmatrix},x\\begin{bmatrix}1\\end{bmatrix},...,x\\begin{bmatrix}n-1\\end{bmatrix}\\right)\\\\\n&=a\\hat{s}\\begin{bmatrix}n-1|n-1\\end{bmatrix} \\\\\n\\end{aligned}\n$$\n#### 预测\n\n求解新息\n$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=E\\left(s[n]\\right)+\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\left(\\tilde{x}[n]-E\\left(\\tilde{x}[n]\\right)\\right)\n$$\n\n$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\rArr E(s[n]) = 0\\\\\n$$\n\n$$\n\\begin{gathered}\nE\\left(\\tilde{x}[n]\\right)=E\\left(x[n]-\\hat{x}[n\\mid n-1]\\right) \\\\\nE\\left(x[n]\\right)=E\\left(s[n]+w[n]\\right)=0 \\\\\nE\\left(\\hat{x}[n\\mid n-1]\\right)=E\\left(\\sum_{k=0}^{n-1}a[k]x[k]\\right) \n\\end{gathered}\\\\\n\\rArr E\\left(\\hat{x}[n\\mid n-1]\\right)=0\\\\\n\\rArr E(\\tilde x[n]) = 0\n$$\n因此，\n$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\tilde{x}[n]=\\underbrace{\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}}_{卡尔曼增益}\\left(x[n]-\\hat{x}[n\\mid n-1]\\right)\n$$\n#### 最小预测 MSE\n\n$\\mathbf{C}_{s\\tilde{x}}\\text{的求解}$\n$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\tilde{x}[n]\\right)  \\\\\n&=E\\Big(s[n]\\Big(x[n]-\\hat{x}\\Big[n|n-1\\Big]\\Big)\\Big)\n\\end{aligned}\n$$\n其中\n$$\n\\begin{aligned}\\hat{x}\\left[n|n-1\\right]&=E\\left(x[n]|x[0],x[1],...x[n-1]\\right)=E\\left(s[n]+w[n]|x[0],x[1],...x[n-1]\\right)\\\\&=E\\left(s[n]|x[0],x[1],...x[n-1]\\right)=\\hat{s}\\left[n|n-1\\right]\\end{aligned}\n$$\n因此\n$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\left(s[n]+w[n]-\\hat{s}[n|n-1]\\right)\\right)  \\\\\n&=E\\left(s[n]w[n]+s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right) \\\\\n&=E\\Big(s[n]\\Big(s[n]-\\hat{s}\\Big[n|n-1\\Big]\\Big)\\Big)\\\\\n&=E\\left(s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)-E\\left(\\hat{s}[n|n-1]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n|n-1]\\right)\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&\\triangleq M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\n\\end{aligned}\n$$\n求解 $M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}$\n$$\n\\begin{aligned}\n&M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\\\\n&=E\\left(\\left(as\\begin{bmatrix}n-1\\end{bmatrix}+u\\begin{bmatrix}n\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n|n-1\\end{bmatrix}\\right)^2\\right)\\\\\n&=E\\left(\\left(a\\left(s[n-1]-\\hat{s}[n-1\\mid n-1]\\right)+u[n]\\right)^2\\right) \\\\\n&=E\\left(a^2\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)^2+u^2\\left[n\\right]+2a\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)u\\left[n\\right]\\right) \\\\\n&=a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2\n\\end{aligned}\n$$\n#### 卡尔曼增益\n\n$\\mathbf{C}_{\\tilde{x}\\tilde{x}}\\text{的求解}$\n$$\n\\\\\n\\begin{aligned}\n\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=E\\left(\\left(\\tilde{x}[n]-E(\\tilde{x}[n])\\right)^2\\right) = E\\left(\\tilde{x}^2[n]\\right) = E\\left(\\left(x[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right)\\\\\n&=E\\left(\\left(s[n]+w[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right) \\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)^2+w^2\\left[n\\right]+2\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)w[n]\\right) \\\\\n&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\n\\end{aligned}\n$$\n结合\n$$\n\\begin{aligned}\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\\\\\\mathbf{C}_{s\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\end{aligned}\n$$\n我们得到了卡尔曼增益\n$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\underbrace{\\frac{M\\left[n\\mid n-1\\right]}{M\\left[n\\mid n-1\\right]+\\sigma_n^2}}_{卡尔曼增益 K[n]}\\tilde{x}[n]\n$$\n#### 修正\n$$\n\\hat{s}\\left[n\\mid n\\right]=\\underbrace{\\hat{s}\\left[n\\mid n-1\\right]}_{预测}+\\underbrace{K\\left[n\\right]\\left(x\\left[n\\right]-\\hat{s}\\left[n\\mid n-1\\right]\\right)}_{新息修正}\n$$\n#### 最小 MSE\n\nMSE 修正：\n$$\nM[n|n] = (1 - K[n])M[n|n - 1]\n$$\n### 非零均值信号模型\n\n![1714360809348](../images/StaSP/1714360809348.png)\n\n初始化：$\\hat{s} [ - 1|- 1] = E\\begin{pmatrix} s[ - 1] \\end{pmatrix} = \\mu _s$ $M[ - 1|- 1] = E\\left ( \\begin{pmatrix} s[ - 1] - \\hat{s} [ - 1|- 1] \\end{pmatrix} ^2\\right ) = \\sigma _s^2$\n\n估计量预测：$\\hat{s}[n|n-1]=a\\hat{s}[n-1|n-1]$\n\nMSE预测：$M\\left[n\\mid n-1\\right]=a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2$\n\n卡尔曼增益：$K[n]=\\frac{M\\left[n|n-1\\right]}{M\\left[n|n-1\\right]+\\sigma_n^2}$\n\n估计量修正：$\\hat{s}[n|n]=\\hat{s}[n|n-1]+K[n]\\left(x[n]-\\hat{s}[n|n-1]\\right)$\n\nMSE修正: $M\\left [ n\\mid n\\right ] = \\left ( 1- K\\left [ n\\right ] \\right ) M\\left [ n\\mid n- 1\\right ]$\n\n### 矢量状态-标量观测信号模型\n\n![1714360717248](../images/StaSP/1714360717248.png)\n\n### 矢量状态-矢量观测信号模型\n\n![1714360742651](../images/StaSP/1714360742651.png)\n\n### 非线性信号模型\n\n![1714360782259](../images/StaSP/1714360782259.png)\n\n![1714361011137](../images/StaSP/1714361011137.png)\n\n![1714361027958](../images/StaSP/1714361027958.png)\n\n### 总结\n\n* 不同时刻的待估计参数并不完全一样，但是存在某些内在联系\n* 卡尔曼滤波利用这种联系进行 LMMSE 估计，并减少了运算量\n* 如果信号与噪声是高斯的，则卡尔曼滤波在 MMSE 准则下最佳，否则，在 LMMSE 准则下是最佳的。\n\n## 信号检测基本准则与方法\n\n之前一直在研究连续型的问题（回归/估计），这里研究离散型的问题（分类/检测）。\n\n### Neyman-Pearson 准则\n\n适用于没有先验信息、代价不好量化的场景。\n\n两种假设：\n$$\n\\begin{aligned}&H_0:x[n]=w[n],n=0,1,...,N-1\\\\&H_1:x[n]=s[n]+w[n],n=0,1,...,N-1\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n&P\\left(H_1;H_0\\right):\\text{ 虚警概率}\\left(P_{FA},\\text{有时简记为}P_F\\right)\\\\\n&P\\left(H_0;H_1\\right):\\text{ 漏检概率 }\\left(P_M\\right)\\\\\n&P\\left(H_1;H_1\\right):\\text{ 检测概率 }\\left(P_D\\right)\\end{aligned}\n$$\n要求：在虚警概率一定情况下，使检测概率最大化\n\n检测概率和虚警概率之间追求折中，不可能两者都改善。\n\n对给定的虚警概率 $P_{FA}=\\alpha$ ,使检测概率 $P_D$ 最大的判决为\n$$\nL(x)=\\frac{p(x;H_1)}{p(x;H_0)}>\\gamma\n$$\n其中门限由 $P_{FA}=\\int_{\\lbrace\\mathbf{x}:L(\\mathbf{x})>\\gamma\\rbrace}p(\\boldsymbol{x};H_0)d\\boldsymbol{x}=\\alpha$ 决定\n\n\n对于信号检测问题：\n$$\nH_0:\\boldsymbol{x}\\sim N\\left(\\boldsymbol{0},\\sigma^2\\mathbf{I}\\right)\\\\H_1:\\boldsymbol{x}\\sim N\\left(A\\mathbf{1},\\sigma^2\\mathbf{I}\\right)\n$$\n\nNP 检测器：\n$$\n\\frac{p\\left(\\boldsymbol{x};H_1\\right)}{p\\left(\\boldsymbol{x};H_0\\right)}=\\frac{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2\\right\\}}{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}}>\\gamma\\\\\\quad\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2+\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}>\\gamma \n$$\n\n$$\n-\\frac1{2\\sigma^2}\\Bigg(-2A\\sum_{n=0}^{N-1}x[n]+NA^2\\Bigg)>\\ln\\gamma\\\\\\frac1N\\sum_{n=0}^{N-1}x[n]>\\frac{\\sigma^2}{NA}\\ln\\gamma+\\frac A2\n$$\n称为检测统计量。若均值大于门限，则判为有信号，否则为无信号。\n\n使用方法：\n$$\n\\begin{aligned}\n&\\text{检测统计量:}T(x)=\\frac1N\\sum_{n=0}^{N-1}x[n]\\sim\\begin{cases}N\\Big(0,\\sigma^2\\Big/_N\\Big),&H_0\\\\[2ex]N\\Big(A,\\sigma^2\\Big/_N\\Big),&H_1\\end{cases} \\\\\n&\\text{虚警概率:}P_{FA}=Pr\\left(T\\left(\\boldsymbol{x}\\right)>\\gamma^{'};H_0\\right)=Q\\left(\\frac{\\gamma^{'}}{\\sqrt{\\sigma^2/N}}\\right) \\\\\n&\\text{门限设置:}\\gamma^{\\prime}=\\sqrt{\\frac{\\sigma^2}N}Q^{-1}\\left(P_{FA}\\right) \\\\\n& \\begin{aligned}&\\text{相应的检测概率:}\\\\&P_{D}=Pr\\Big(T\\big(\\boldsymbol{x}\\big)>\\gamma^{'};H_{1}\\Big)=Q\\Bigg(\\frac{\\gamma^{'}-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)=Q\\Bigg(\\frac{\\sqrt{\\frac{\\sigma^{2}}{N}}Q^{-1}\\big(P_{FA}\\big)-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)\\end{aligned}  \\\\\n&=Q\\Bigg(Q^{-1}\\big(P_{F_A}\\big)-\\sqrt{\\frac{NA^2}{\\sigma^2}}\\Bigg)\n\\end{aligned}\n$$\n### 检测性能分析\n\n接收机工作特性曲线（ROC, receiver operating characteristics）\n\n![1714966200160](../images/StaSP/1714966200160.png)\n\n直观理解：\n\n![1714966230536](../images/StaSP/1714966230536.png)\n\n多次观测的好处\n\n- 从数学角度：不同假设下的pdf分隔更开，更易区分不同假设\n- 从信号处理角度：增加信号预检测积分时间，获得更多的能量用于检测\n- 从信息论角度：多的观测数据带来了新的信息\n\n\n### 最小错误概率准则\n$$\n\\begin{aligned}\nP_{e}& =\\Pr\\left\\{\\text{判}H_0,H_1\\text{为真}\\right\\}+\\Pr\\left\\{\\text{判}H_1,H_0\\text{为真}\\right\\}  \\\\\n&=P\\big(H_0,H_1\\big)+P\\big(H_1,H_0\\big) \\\\\n&=P\\big(H_1\\big)P\\big(H_0|H_1\\big)+P\\big(H_0\\big)P\\big(H_1|H_0\\big) \\\\\n&=P\\big(H_1\\big)\\int_{R_0}p\\big(\\boldsymbol{x}|H_1\\big)d\\boldsymbol{x}+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}|H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\big(H_1\\big)\\Bigg(1-\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_1\\big)d\\boldsymbol{x}\\Bigg)+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\left(H_1\\right)+\\int_{R_1}\\left\\{P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\n\\end{aligned}\n$$\n为了使错误最小，需要在积分式小于零的区域积分，即\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$\n最小错误概率准则可推导出最大后验概率检测器：\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$\n等价于\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)P\\left(H_1\\right)}{p\\left(\\boldsymbol{x}\\right)}>\\frac{p\\left(\\boldsymbol{x}\\mid H_0\\right)P\\left(H_0\\right)}{p\\left(\\boldsymbol{x}\\right)}\\\\p\\left(H_1\\mid\\boldsymbol{x}\\right)>p\\left(H_0\\mid\\boldsymbol{x}\\right)\n$$\n若先验概率相同，则为最大似然检测器：\n$$\np\\left(x\\mid H_1\\right)>p\\left(x\\mid H_0\\right)\n$$\n### 二元贝叶斯风险准则\n\n引入判错代价\n$$\nR=C_{01}P\\left(H_1\\right)P\\left(H_0\\mid H_1\\right)+C_{10}P\\left(H_0\\right)P\\left(H_1\\mid H_0\\right)\n$$\n进一步泛化：\n$$\nR=C_{00}P\\big(H_0\\big)P\\big(H_0|H_0\\big)+C_{10}P\\big(H_0\\big)P\\big(H_1|H_0\\big)\\\\+C_{01}P\\big(H_1\\big)P\\big(H_0|H_1\\big)+C_{11}P\\big(H_1\\big)P\\big(H_1|H_1\\big)\n$$\n\n$$\n\\begin{aligned}\\text{R}&=C_{00}P\\left(H_0\\right)+C_{01}P\\left(H_1\\right)\\\\&+\\int_{R_1}\\left\\{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\\end{aligned}\n$$\n因此，有了最小贝叶斯风险判决准则：\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)}{\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$\n风险一致条件下（$C_{00}=C_{11}=0,C_{10}=C_{01}=1$），回到最小错误概率准则。\n\n### 多元贝叶斯风险准则\n\n贝叶斯风险：\n$$\n\\begin{aligned}\n\\text{R}& =\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_i,H_j\\Big)  \\\\\n&=\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}\\int_{R_i}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_j\\mid x\\Big)p(x)dx\n\\end{aligned}\n$$\n\n应选择使平均风险$C_i\\left(\\boldsymbol{x}\\right)=\\sum_{j=0}^{M-1}C_{ij}P\\left(H_j\\mid\\boldsymbol{x}\\right)$最小的假设\n\n在风险一致条件下\n$$\nC_{ij}=\\begin{cases}0,&i=j\\\\1,&i\\neq j\\end{cases}\n$$\n\n$$\n\\begin{aligned}C_{i}\\left(\\boldsymbol{x}\\right)&=\\sum_{j=0\\atop j\\neq i}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)\\\\&=\\sum_{j=0}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)-\\underline{P\\Big(H_i\\mid\\boldsymbol{x}\\Big)}_{最大化这个}\\end{aligned}\n$$\n因此等价于最大后验准则：\n$$\n\\max_iP(H_i\\mid\\boldsymbol{x})\n$$\n\n若此时先验概率相同，则为最大似然准则。\n\n## 总结知识点\n\n### 估计理论\n\nMAP 估计通常不能使用参数变换，变换后的参数不一定是 MAP。但是 MLE 可以。\n\nLS 方法与 BLUE 等 MVU 的衍生方法有一点不同，就是基础的 LS 没有使用协方差矩阵，但是加权的 LS 可以用协方差矩阵修正结果。\n\n贝叶斯方法和经典方法的区别在于是否把估计量的真值看作一个随机变量。它们都以“平均误差最小”为目标。\n\n### 检测理论\n\n贝叶斯风险：让平均的风险最小化。\n\n未知多余参数如果影响最终的判决结果，可以用贝叶斯方法或者GLRT方法处理。","source":"_posts/StaSP.md","raw":"---\ntitle: Statistical Signal Processing\nkatex: true\ndate: 2024-02-26 11:12:57\ntags:\n---\n\n## 参数估计\n\n分类：\n\n* 经典估计\n* 贝叶斯估计\n\n准则：\n\n* MSE，均方误差\n\n$$\n\\hat \\theta = f(\\bm{x})\n$$\n\n### MSE\n\n$$\n\\text{mse}(\\hat \\theta) = E \\lbrace(\\theta - \\hat \\theta)^2\\rbrace = \\text{var}(\\hat \\theta) + b^2(\\hat \\theta)\\\\\nb^2(\\hat \\theta) = E(\\hat \\theta) - \\theta\n$$\n\n现实中无法直接计算 MSE，因为涉及到真值 $\\theta$，但是 $\\theta$ 是我们要求的参数。\n\n### MVU\n\n最小方差无偏估计\n\nMVU, Minimum Variance Unbiased\n\n无偏：\n\n$$\nE(\\hat \\theta) = \\theta, a \\lt \\theta \\lt b\n$$\n\n无偏的含义：$\\hat \\theta$ 的求法需要对取值范围内任意的 $\\theta$ 进行估计。\n\n无偏估计是否一定存在？不一定。\n\n最小方差：\n\n$$\n\\min \\text{var}\\lbrace\\hat\\theta\\rbrace\n$$\n\nMVU的内涵：估计值的发散程度最小（最小方差），平均意义上靠近真值（MVU）。是对 MSE 的迂回实现。\n\n### 克拉美罗界定理(CRLB)\n\n假设 $p(\\bm{x};\\theta)$ 满足正则条件：\n\n$$\nE \\left [ \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta} \\right] = 0\n$$\n\n则\n\n$$\n\\text{var}(\\hat\\theta) \\ge \\frac{1}{E \\left [\\left( \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta}\\right)^2 \\right]} = - \\frac{1}{E \\left [ \\frac{\\partial^2\\ln p(\\bm{x};\\theta)}{\\partial\\theta^2} \\right]}\n$$\n\n等号成立的充要条件：找到函数 $I, g$\n\n$$\n\\frac{\\partial \\ln p(\\bm{x};\\theta)}{\\partial \\theta}= I(\\theta)(g(\\bm{x}) - \\theta)\\\\\n\\hat \\theta = g(\\bm{x})\n$$\n\n此时有 $\\text{var}(\\hat\\theta) =1 / I(\\theta)$。\n\n### 求解MVU\n\n$$\n\\frac{\\partial \\ln p(\\bm{x};A)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A) = \\frac{N}{\\sigma^2}\\left (\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)  \\right)\n$$\n\n$$\ng(\\bm{x}) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]\\\\\nI(\\theta) = \\frac{N}{\\sigma^2}\n$$\n\n有效估计量：能达到克拉美罗下界的估计量，是MVU的子集。\n\n### 参数变换的克拉美罗界\n\n若\n\n$$\n\\alpha = g(\\theta)\n$$\n\n则\n\n$$\nCRLB(\\hat \\alpha) = \\left(\\frac{\\partial g(\\theta)}{\\partial \\theta}\\right)^2CRLB(\\hat \\theta)\n$$\n\n对于高斯分布有\n\n$$\nE(x^2) = \\mu^2 + \\sigma^2\\\\\nE(x^4) = \\mu^4 + 6\\mu^2\\sigma^2 + 3\\sigma^4\n$$\n\n当数据量很大时\n\n有效估计量靠近真值：$N \\rightarrow \\infty, \\hat\\theta \\rightarrow \\theta$\n\n非线性变换渐进有效,可以看成线性函数：$g(\\hat \\theta) \\approx g(\\theta) + \\frac{\\partial g(\\theta)}{\\partial\\theta}(\\hat \\theta - \\theta)$\n\n### 矢量参数的克拉美罗界\n\n$$\nE \\left [ \\frac{\\partial \\ln p(\\bm{x};\\bm{\\theta})}{\\partial \\bm{\\theta}} \\right] = 0\n$$\n\n$$\n\\alpha = g(\\theta)\n$$\n\n![](../images/StaSP/1_1.jpg)\n\n注意：$\\bm T(\\bm x)$ 的维度要和 $\\bm \\theta$ 的维度相同\n\n## 线性模型方法\n\n$$\nx = H\\theta + w, w \\sim N(0, \\sigma^2I)\n$$\n\n$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2}(x - H\\theta)^T(x - H\\theta) \\rbrace\n$$\n\n$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\theta} = \\frac{H^TH}{\\sigma^2}\\lbrace (H^TH)^{-1}H^Tx - \\theta \\rbrace\n$$\n\n从而\n\n$$\n\\hat \\theta = (H^TH)^{-1}H^Tx\\\\\nC_{\\hat\\theta} = \\sigma^2(H^TH)^{-1}\n$$\n\n这个 MVU 估计量满足\n\n$$\n\\hat \\theta \\sim N(\\theta, \\sigma^2(H^TH)^{-1})\n$$\n\n* 要求观测数据与待估计参数间呈线性关系\n* 要求噪声是高斯白噪声\n* 要求观测矩阵是满秩的\n* 所得估计量是有效估计量\n\n一般信号模型\n\n$$\nx = H\\theta + s + w, s已知，w \\sim N(0, C)\n$$\n\n结论\n\n$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}(x - s)\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$\n\n## 充分统计量方法\n\n$$\np(x|T(x);\\theta) = p(x|T(x))\n$$\n\n则称 $T(x)$ 为充分统计量\n\n充分统计量的性质:\n\n* 一旦充分统计量确定，似然函数就与待估计参数无关\n* 充分统计量依赖于待估计参数。待估计参数变化，其相应的充分计量一般也会变化\n* 所谓“充分”，是相对于原始观测数据而言的原始观测量总是充分统计量，但通常不是最小集\n* 充分统计量并不唯一\n\n若\n\n$$\n\\int_{-\\infty}^{\\infty}v(T)p(T;\\theta)\\mathrm dT = 0\n$$\n\n对所有的 $\\theta$ 并非都满足，只对零函数 $v(T) = 0$ 成立，则称充分统计量是完备的。\n\n* 一般地，当待估计参数发生变化时，充分统计量也会发生变化\n* 一旦充分统计量确定以后，似然函数就与待估计参数无关\n\n### Neyman-Fisher因子分解定理\n\n如果概率密度函数（或概率质量函数，对于离散随机变量）$p(x; \\theta)$ 可以被分解为\n\n$$\np(x; \\theta) = g(T(x); \\theta) \\cdot h(x)\n$$\n\n其中：\n\n- $g(T(x); \\theta)$ 是一个只通过统计量 $T(x)$ 并依赖于参数 $\\theta$ 的函数。\n- $h(x)$ 是只与观测数据 $x$ 相关的函数，与参数 $\\theta$ 无关。\n\n那么，统计量 $T(x)$ 是参数 $\\theta$ 的充分统计量。反之，如果 $T(x)$ 是参数 $\\theta$ 的充分统计量，那么概率密度函数 $p(x; \\theta)$ 必然可以分解为上述形式。\n\n### Rao-Black-Lehmann-Scheffe(RBLS)定理\n\n若 $\\breve\\theta$ 是$\\theta$的无偏估计，$T(x)$是$\\theta$的充分统计量，那么$\\hat \\theta=E(\\breve{\\theta}|T(x))$\n\n1. 是$\\theta$ 的一个适用的估计量(与$\\theta$无关)\n2. 无偏的\n3. 对所有的 $\\theta$，它的方差小于等于$\\breve\\theta$ 的方差\n4. 若$T(x)$是完备的，那么$\\theta$是MVU估计量\n\n#### 矢量参数的 RBLS\n\n![](../images/StaSP/2_1.jpg)\n\n![](../images/StaSP/2_2.png)\n\n## BLUE\n\n### 定义\n\n直接求出数据->参数的映射 $\\bm A_{p \\times N}$：\n\n$$\n\\bm x = \\bm H \\theta\\\\\n\\hat {\\theta}_{p \\times 1} = \\bm A\\bm x\n$$\n\n无偏性：\n\n$$\n\\theta = E(\\hat\\theta) = \\bm AE(\\bm x) = \\bm AH\\theta\\\\\n\\Rightarrow AH = I_{p \\times p}\n$$\n\n最佳（最小方差）\n\n$$\n\\min \\lbrace a_i^TCa_i \\rbrace, A = [a_1, a_2, \\dots, a_n]^T\n$$\n\n其中\n\n$$\nC = E \\lbrace (x - E(x))(x - E(x))^T \\rbrace\n$$\n\n### 高斯-马尔可夫定理\n\n如果数据具有一般线性模型的形式\n\n$$\n\\bm x = \\bm H \\theta + w\n$$\n\n其中 $\\bm H$ 为已知 $N \\times p$ 矩阵，$\\theta$ 为待估计参数，$w$ 是均值为零、协方差为 $\\bm C$ 的噪声矢量（**不一定为高斯**），则 BLUE 估计量为\n\n$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}x\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$\n\n* 若为高斯噪声，则BLUE为MVU，且为有效估计量\n\n## MLE\n\n### 定义\n\n$$\n\\hat \\theta = \\arg\\max\\limits_\\theta p(\\bm{x};\\theta)\n$$\n\n如果 PDF 可导\n\n$$\n\\frac{\\partial p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\\\\\n\\Rightarrow\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\n$$\n\n若有效估计量存在，$\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = I(\\theta)(g(x) - \\theta)$，则可以使用最大似然估计方法求得结果。\n\n### MLE 的性质\n\n如果数据 $\\bm x$ 的 PDF $p(\\bm x;\\theta)$ 满足“正则”条件，那么\n对于足够多的数据记录，未知参数 $\\theta$ 的 MLE 渐近服从\n\n$$\n\\hat\\theta \\stackrel{a}{\\sim} N(\\theta, I^{-1}\\theta)\n$$\n\n其中 $\\theta$ 是在未知参数真值处计算的 Fisher 信息。\n\nMLE是渐近无偏的\n\nMLE渐近达到CRLB\n\nMLE是渐近有效的\n\nMLE是渐近最佳的\n\n* MLE的方差（协方差）可大于、等于、小于CRLB！（不同于MVU估计）\n* 但数据量足够多时，将与CRLB接近\n* 因此，可利用CRLB评估MLE的性能\n\n“足够多”数据：大量能带来新信息的数据\n\n**MLE的不变性**\n\n若参数 $\\alpha = g(\\theta)$，则\n\n$$\n\\hat\\alpha = g(\\hat\\theta)\n$$\n\n若 $g$ 非一对一函数，那么 $\\hat\\alpha$ 是使修正后的似然函数 $p_T(\\bm x;\\alpha)$ 最大者\n\n$$\n\\hat\\alpha = \\arg\\max_\\alpha p_T(\\bm x; \\alpha)\\\\\np_T(\\bm x; \\alpha) = \\max_{\\theta: \\alpha=g(\\theta)}p(\\bm x; \\theta)\n$$\n\n该性质对函数 $g$ 无线性变换要求，对任意函数均成立。\n\n对比MVU\n\n* 无偏性、有效性仅对线性变换成立\n* 对非线性变换不能保持（但渐近无偏、渐近有效）\n\n对一般线性模型，MLE是MVU，达到了CRLB，是有效的、最佳的！\n\n![1711254850893](../images/StaSP/1711254850893.png)\n\n## 最小二乘估计(LS)\n\n### 线性最小二乘估计\n\n![1711339154789](../images/StaSP/1711339154789.png)\n\n### 加权最小二乘估计\n\n![1711339192281](../images/StaSP/1711339192281.png)\n\n### 约束最小二乘估计\n\n![1711339216759](../images/StaSP/1711339216759.png)\n\n### 比较\n\n![1711339249863](../images/StaSP/1711339249863.png)\n\n## 经典估计方法比较\n\n### 噪声电平估计问题\n\n$$\nx[n] = A + w[n]\n$$\n\n其中 $w[n] \\sim N(0, \\sigma^2)$，待估计参数 $\\theta = [A, \\sigma^2]^T$\n\n#### MVU估计\n\n$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2} \\sum\\limits_{n=0}^{N - 1}(x[n] - A)^2\\rbrace\n$$\n\n$$\n\\frac{\\partial \\ln p (x;\\theta)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$\n\n$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\sigma^2} = \\frac{N}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$\n\n![1711339773571](../images/StaSP/1711339773571.png)\n\n![1711339786814](../images/StaSP/1711339786814.png)\n\n#### 线性模型\n\n$$\n\\hat\\theta = (\\bm H^T\\bm H)^{-1}\\bm  H^T x\n$$\n\n![1711339831807](../images/StaSP/1711339831807.png)\n\n#### BLUE\n\n$$\n\\hat\\theta = (\\bm H^T\\bm C^{-1}\\bm H)^{-1}\\bm  H^T\\bm C^{-1} x\n$$\n\n![1711339865703](../images/StaSP/1711339865703.png)\n\n#### 充分统计量\n\n![1711340151724](../images/StaSP/1711340151724.png)\n\n![1711340163113](../images/StaSP/1711340163113.png)\n\n![1711340177961](../images/StaSP/1711340177961.png)\n\n#### MLE\n\n![1711340277148](../images/StaSP/1711340277148.png)\n\n#### LSE\n\n![1711340293644](../images/StaSP/1711340293644.png)\n\n## 贝叶斯估计\n\n贝叶斯MSE：\nBmse$\\left(\\hat{\\theta}\\right)=E\\left(\\left(\\theta-\\hat{\\theta}\\right)^2\\right)$\n\n\n$=\\int\\int\\left(\\theta-\\hat{\\theta}\\right)^{2}p\\big(\\mathbf{x},\\theta\\big)d\\mathbf{x}d\\theta$ $=\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p\\big(\\boldsymbol{x}|\\theta\\big)p\\big(\\theta\\big)d\\boldsymbol{x}d\\theta$\n $=\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p(x|\\theta)dxp(\\theta)d\\theta$\n\n$\\hat{\\theta}=E\\big(\\theta|x\\big)$\n\n多余参数：未知，但不感兴趣的参数\n 解决思路：通过积分消除多余参数的影响\n (1) 后验概率中存多余参数时：\n\n$$\np(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x}) \\Rightarrow p (\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\int p(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x})\\:d\\boldsymbol{\\alpha}\n$$\n\n(2) 条件概率中存在多余参数时：\n\n$$\np(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\frac{p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{\\int p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}\n$$\n\n$$\n\\text{若现只有 }p(x|\\theta,\\alpha)\\text{,而无 }p(x|\\theta)\n$$\n 此时可通过积分方式解决\n\n$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha\\mid\\theta)d\\alpha \n$$\n\n进一步地，若待估计参数与多余参数相互独立，\n\n$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha)d\\alpha \n$$\n\n矢量参数下贝叶斯估计\n若 θ 是 $p{\\times}1$ 的矢量参数，那么为了估计其中某个参数 $\\theta_i$, 可以将剩余参数当作多余参数，因此对$\\theta_i$ 的MMSE为\n\n$$\n\\hat{\\theta}_i=E\\left(\\theta_i\\mid x\\right)=\\int\\theta_ip(\\theta_i\\mid x)d\\theta_i\n$$\n 其中\n\n$$\np(\\theta_i\\mid x)=\\int\\cdots\\int p(\\theta\\mid x)d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p\n$$\n\n$$\n\\hat{\\theta}_i=\\int\\theta_i\\left(\\int\\cdots\\int p(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})\\underline{d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p}\\right)d\\theta_i=\\int\\theta_ip(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})d\\boldsymbol{\\theta}\n$$\n\n$$\n\\Longrightarrow\\hat{\\theta}=\\begin{bmatrix}\\theta_1p(\\theta|x)d\\theta\\\\\\int\\theta_2p(\\theta|x)d\\theta\\\\\\vdots\\\\\\int\\theta_pp(\\theta|x)d\\theta\\end{bmatrix}=\\int\\theta_P(\\theta|x)d\\theta=E(\\theta|x)\n$$\n\nWoodbury 恒等式：\n\n$$\n\\left(\\mathbf{B}+\\boldsymbol{u}\\boldsymbol{u}^T\\right)^{-1}=\\mathbf{B}^{-1}-\\frac{\\mathbf{B}^{-1}\\boldsymbol{u}\\boldsymbol{u}^T\\mathbf{B}^{-1}}{1+\\boldsymbol{u}^T\\mathbf{B}^{-1}\\boldsymbol{u}}\n$$\n\n### 贝叶斯风险\n\n$$\n\\Re=\\iint C(\\varepsilon)p(x,\\theta)dxd\\theta \n$$\n\n#### 二次型误差\n\n$$\nC(\\varepsilon) = \\begin{pmatrix}\\theta-\\hat{\\theta}\\end{pmatrix}^2\n$$\n\n这就是 MMSE\n\n此时为平均值。\n\n#### 绝对误差\n\n$$\nC(\\varepsilon)=\\begin{vmatrix}\\theta-\\hat{\\theta}\\end{vmatrix}\n$$\n\n> Leibnitz 准则\n> $\\frac{\\partial}{\\partial u}\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}h\\big(u,v\\big)dv=\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}\\frac{\\partial h\\big(u,v\\big)}{\\partial u}dv+\\frac{\\partial\\phi_2\\big(u\\big)}{\\partial u}h\\big(u,\\phi_2\\big(u\\big)\\big)-\\frac{\\partial\\phi_1\\big(u\\big)}{\\partial u}h\\big(u,\\phi_1\\big(u\\big))$\n\n此时\n\n$$\n\\int_{-\\infty}^{\\hat{\\theta}}p\\big(\\theta|x\\big)d\\theta=\\int_{\\hat{\\theta}}^{+\\infty}p\\big(\\theta|x\\big)d\\theta \n$$\n\n为中位数\n\n#### 成功失败型误差\n\n$$\nC(\\varepsilon)=\\begin{cases}0,\\left|\\theta-\\hat{\\theta}\\right|<\\delta\\\\1,\\left|\\theta-\\hat{\\theta}\\right|\\geq\\delta\\end{cases}\n$$\n\n此时 \n\n$$\n\\hat{\\theta}=\\arg\\max_{\\theta}p(\\theta|x)\n$$\n\n即 $\\hat{\\theta}$ 是后验PDF的最大值 (众数) \n\nMAP maximum a posteriori\n\n根据贝叶斯公式\n\n$$\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\{p(x|\\theta)p(\\theta)\\right\\}\\\\\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\{\\ln p\\big(x|\\theta\\big)+\\ln p\\big(\\theta\\big)\\right\\}\n$$\n\n#### 三值比较\n一般而言，“三值”并不相等，因此三种估计量往往不同\n\n特例：高斯时“三值”相等，三种估计方法等价\n\n大数据量时先验信息不起作用，最大后验概率估计（MAP）将转变为（贝叶斯）最大似然估计（MLE）\n\n### 线性贝叶斯估计\n\n线性贝叶斯估计(LMMSE), 也称线性最小意味着：\n\n$$\n\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$\n\n即限定估计量与观察数据间呈线性关系，然最小化 \n$$\n\\mathrm{Bmse}\\Big(\\hat{\\theta}\\Big)=E\\Big[\\Big(\\theta-\\hat{\\theta}\\Big)^{2}\\Big]\n$$\n\n即，LMMSE:\n\n$$\n\\min\\left\\{E\\left[\\left(\\theta-\\hat{\\theta}\\right)^2\\right]\\right\\}\\\\s.t.\\quad\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$\n\n解得估计量：\n\n$$\n\\hat{\\theta}=E\\left(\\theta\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(x-E\\left(x\\right)\\right)\\\\\\mathrm{Bmse}\\left(\\hat{\\theta}\\right)=\\mathbf{C}_{\\theta\\theta}-\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\mathbf{C}_{x\\theta}\n$$\n\n对比 MMSE：\n\n附加了线性约束\n- 可得显示解——好求\n- 仅需一阶矩和二阶矩\n\n无附加约束\n- 可能难以求得显示解\n- 需PDF\n- 全局最优\n- 仅在“线性”中最优\n\n#### 矢量参数情况\n\n待估计参数$\\boldsymbol{\\theta}=\\begin{bmatrix}\\theta_1,\\theta_2,...,\\theta_p\\end{bmatrix}^T$,其每个参数的 LMMSE 定义为\n\n$$\n\\begin{aligned}&\\min E\\bigg[\\bigg(\\theta_{i}-\\hat{\\theta}_{i}\\bigg)^{2}\\bigg]\\\\&s.t.\\hat{\\theta}_{i}=\\sum_{n=0}^{N-1}a_{in}x[n]+a_{iN}\\end{aligned}\n$$\n\n$$\n\\hat{\\boldsymbol{\\theta}}=\\begin{bmatrix}E(\\theta_1)\\\\E(\\theta_2)\\\\\\vdots\\\\E(\\theta_p)\\end{bmatrix}+\\begin{bmatrix}\\mathbf{C}_{\\theta_1x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\mathbf{C}_{\\theta_2x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\vdots\\\\\\mathbf{C}_{\\theta_px}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\end{bmatrix}\\\\\n=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x} - E(\\boldsymbol{x})\\right)\n$$\n\n### 序贯LMMSE\n\n白噪声电平估计\n\n$$\nx[n]=A+w[n],n=0,1,...,N\n$$\n\n$$\nA\\sim N\\big(0,\\sigma_{A}^{2}\\big)\\\\\nw[n]\\sim N\\left(0,\\sigma^{2}\\right)\n$$\n\n解得\n\n$$\n\\begin{aligned}\n&E(\\theta)=0 \\\\\n&\\mathbf{C}_{\\theta x}=E\\left(\\left(\\theta-E\\left(\\theta\\right)\\right)\\left(x-E\\left(x\\right)\\right)^{T}\\right) \\\\\n&=E\\left(\\left(A-0\\right)\\left(x-0\\right)^{T}\\right) \\\\\n&=E\\Big(A\\big(A\\mathbf{1}+\\mathbf{w}\\big)^{T}\\Big) \\\\\n&=\\sigma_{A}^{2}\\mathbf{1}^{T}\n\\end{aligned}\\\\\n\\begin{aligned}\n\\mathbf{C}_{xx}& =E\\left(\\left(x-E\\left(x\\right)\\right)\\left(x-E\\left(x\\right)\\right)^T\\right)  \\\\\n&=E\\left(\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)^T\\right) \\\\\n&=E\\left\\{A\\mathbf{1}\\mathbf{1}^TA+A\\mathbf{1}\\boldsymbol{w}^T+\\boldsymbol{w}\\mathbf{1}^TA+\\boldsymbol{w}\\boldsymbol{w}^T\\right\\} \\\\\n&=\\sigma_A^2\\mathbf{1}\\mathbf{1}^T+\\sigma^2\\mathbf{I}\n\\end{aligned}\\\\\n\\begin{aligned}\\mathbf{C}_{\\theta\\theta}&=\\sigma_A^2\\\\\\mathbf{C}_{x\\theta}&=\\mathbf{C}_{\\theta x}^T\\\\&=\\sigma_A^2\\mathbf{1}\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\\hat{A}&=\\frac{\\sigma_{A}^{2}}{\\sigma_{A}^{2}+\\frac{\\sigma^{2}}{N}}\\\\\\mathrm{Bmse}&\\left(\\hat{A}\\right)=\\frac{1}{N}\\end{aligned}\n$$\n\n记\n\n$$\n\\hat{A}[N-1]=\\frac{\\sigma_A^2}{\\sigma_A^2+\\frac{\\sigma^2}{N}}\\frac{1}{N}\\sum_{n=0}^{N-1}x[n]\n$$\n\n则\n\n$$\n\\hat{A}[N]=\\hat{A}[N-1]+\\underbrace{\\frac{\\sigma_A^2}{\\left(N+1\\right)\\sigma_A^2+\\sigma^2}}_{K[N]，增益因子}\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$\n\n$$\n\\frac{\\frac1{\\sigma^2}}{\\frac1{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}+\\frac1{\\sigma^2}}=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\\\\=\\frac{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}}{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}+\\sigma^2}=\\frac{\\sigma_A^2}{\\left(N\\sigma_A^2+\\sigma^2\\right)+\\sigma_A^2}=K\\begin{bmatrix}N\\end{bmatrix}\n$$\n\n一般方法\n\n序贯计算方法估计量更新：\n\n$$\n\\hat{A}[N]=\\hat{A}[N-1]+K[N]\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$\n\n增益因子：\n\n$$\nK\\left[N\\right]=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\n$$\n\n最小贝叶斯MSE更新：\n\n$$\n\\mathrm{Bmse}\\Big(\\hat{A}[N]\\Big)\\boldsymbol{=}\\Big(1\\boldsymbol{-}K[N]\\Big)\\mathrm{Bmse}\\Big(\\hat{A}[N\\boldsymbol{-}1]\\Big)\n$$\n\n初始化：\n\n$$\n\\hat{A}[-1]=E(A)\\\\\n\\text{Bmse}\\left ( \\hat{A} [ - 1] \\right ) = \\text{var}\\left ( A\\right ) \n$$\n\n## 维纳滤波\n\n### 滤波\n\n假定观测数据是零均值、宽平稳的，信号也是零均值、宽平稳的，信号与噪声不相关\n\n$$\nx[n] = s[n] + w[n], n = 0, 1, \\dots, N - 1\n$$\n\n$$\n\\theta=s[n]\\text{ 用 }x[0],x[1],x[2],...,x[n]\\text{来估计}$$\n\n![1713150769252](../images/StaSP/1713150769252.png)\n\n利用 LMMSE 可得\n$$\n\\hat{s}[n]=r_{ss}^{'T}\\left(\\mathbf{R}_{ss}+\\mathbf{R}_{ww}\\right)^{-1}\\boldsymbol{x}\n$$\n从而得到维纳-霍夫滤波方程\n$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}n\\end{bmatrix}&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h^{(n)}\\begin{bmatrix}0\\end{bmatrix}\\\\h^{(n)}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\h^{(n)}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{ss}\\begin{bmatrix}0\\end{bmatrix}\\\\r_{ss}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\r_{ss}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}\n$$\n### 平滑\n$$\n\\theta=s[n]\\text{用 }...,x[-1],x[0],x[1],x[2],...,\\text{来估计}\n$$\n![1713152016025](../images/StaSP/1713152016025.png)\n\nLMMSE:\n$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$\n令 $h[k] = a_{N-k}$\n\n> 正交原理：误差与每一个观测数据正交\n> $$\n> E\\left(\\left(\\theta-\\hat{\\theta}\\right)x[m]\\right)=0\n> $$\n> 正交原理不依赖于任务是平滑、滤波还是预测，是普遍适用的，证明如下：\n> ![1713152987612](../images/StaSP/1713152987612.png)\n> ![1713152970273](../images/StaSP/1713152970273.png)\n在 LMMSE\n$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$\n中令 $h[k]=a_{n-k}$\n\n则有\n$$\n\\hat s[n] = \\sum\\limits_{k=-\\infty}^{\\infty}h[k]x[n-k]\n$$\n可得\n$$\nr_{ss}\\begin{bmatrix}n\\end{bmatrix}=h\\begin{bmatrix}n\\end{bmatrix}*r_{xx}\\begin{bmatrix}n\\end{bmatrix}\n$$\n无限维纳平滑器的频率响应\n$$\nH\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{xx}\\left(f\\right)}\\quad=\\frac{P_{ss}\\left(f\\right)}{P_{ss}\\left(f\\right)+P_{ww}\\left(f\\right)}\\quad=\\frac{\\eta\\left(f\\right)}{\\eta\\left(f\\right)+1}\\quad\\text{,其中 }\\eta\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{ww}\\left(f\\right)}\n$$\n### 预测\n\n可以用来进行预测\n$$\n\\theta=x[N-1+l]\\text{ 用 }x[0],x[1],x[2],...,x[N-1]\\text{ 来估计}\n$$\n![1713150674892](../images/StaSP/1713150674892.png)\n\n依然用 LMMSE 可以得到线性预测维纳-霍夫滤波方程\n$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h\\begin{bmatrix}1\\end{bmatrix}\\\\h\\begin{bmatrix}2\\end{bmatrix}\\\\\\vdots\\\\h\\begin{bmatrix}N\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{xx}\\begin{bmatrix}l\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}l+1\\end{bmatrix}\\\\\\vdots\\\\r_{xx}\\begin{bmatrix}N-1+l\\end{bmatrix}\\end{bmatrix}\n$$\n### 应用\n\n信道均衡问题\n\n![1713151589324](../images/StaSP/1713151589324.png)\n\n## 卡尔曼滤波\n\n如何估计电压？\n\n### 模型 1：当成确定参数\n$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2})\n$$\n\n$$\n\\hat A = \\sum\\limits_{n=0}^{N - 1}x[n] = \\bar x\n$$\n### 模型2：当成某个随机变量\n$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2}), A \\sim N(\\mu_A, \\sigma_A^{2})\n$$\n贝叶斯一般线性模型：\n$$\n\\boldsymbol{x}=\\mathbf{H}\\boldsymbol{\\theta}+\\boldsymbol{w}\\quad\\text{其中 }\\boldsymbol{\\theta}{\\sim}N\\begin{pmatrix}\\boldsymbol{\\mu}_\\theta,\\mathbf{C}_\\theta\\end{pmatrix}\\text{,}\\boldsymbol{w}{\\sim}N\\begin{pmatrix}\\boldsymbol{0},\\mathbf{C}_w\\end{pmatrix}\\\\\nE\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E\\left(\\boldsymbol{x}\\right)\\right)=\\boldsymbol{\\mu}_\\theta+\\mathbf{C}_{\\theta|x}\\mathbf{H}^T\\mathbf{C}_w^{-1}\\left(\\boldsymbol{x}-\\mathbf{H}\\boldsymbol{\\mu}_\\theta\\right)\\\\\n\\text{其中,}\\mathbf{C}_{\\theta|x}=\\left(\\mathbf{C}_\\theta^{-1}+\\mathbf{H}^T\\mathbf{C}_w^{-1}\\mathbf{H}\\right)^{-1}\n$$\n\n$$\n\\hat{A}=\\mu_A+\\frac{\\frac1{\\sigma^2/N}}{\\frac1{\\sigma_A^2}+\\frac1{\\sigma^2/N}}(\\overline{x}-\\mu_A)\n$$\n### 模型3：当成未知且随时间变化的量\n$$\nx[n]=A[n]+w[n],n=0,1,...,N-1\n$$\n\n$$\n\\mathrm{MVU}\\text{估计量:}\\hat{\\boldsymbol{\\theta}}=\\left(\\mathbf{H}^T\\mathbf{H}\\right)^{-1}\\mathbf{H}^T\\boldsymbol{x}\\\\\n\\begin{aligned}&\\boldsymbol{\\theta}=&\\begin{bmatrix}A[0],A[1],...,A[N-1]\\end{bmatrix}^T\\\\&\\mathbf{H}=\\mathbf{I}\\end{aligned}\\\\\n\\hat{A}[n]=x[n]\n$$\n### 动态信号模型\n\n一阶高斯-马尔可夫信号模型：\n$$\ns[n]=as[n-1]+u[n],n\\geq0\n$$\n其中，$u[n]$是均值为零方差为 $\\sigma_u^2$ 的高斯白噪声，称为驱动噪声或激励噪声。信号初值s$[-1]\\sim N(\\mu_s,\\sigma_s^2)$与激励噪声$u[n]$相互独立。\n\n均值：\n$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\\\\nE\\left(s[n]\\right)=a^{n+1}E\\left(s[-1]\\right)+\\sum_{k=0}^na^kE\\left(u[n-k]\\right)=a^{n+1}\\mu_s\\\\\nc_s[m,n] = a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^m\\sum_{l=0}^na^{k+l}E\\left(u[m-k]u[n-l]\\right)\\\\\nE\\left(u[m-k]u[n-l]\\right)=\\begin{cases}\\sigma_u^2,&l=n-m+k\\\\0,&\\mathrm{others}\\end{cases}\n$$\n协方差：\n$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m+n+2}\\sigma_s^2+\\sum_{k=m-n}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\\\\nm \\lt n, c_s\\begin{bmatrix}m,n\\end{bmatrix}=a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{n-m}\\sum_{k=0}^ma^{2k}=c_s\\begin{bmatrix}n,m\\end{bmatrix}\n$$\n方差和二阶矩：\n$$\n\\begin{aligned}\n\\operatorname{var}(s[n])& =E\\left(\\left(s[n]-E\\left(s[n]\\right)\\right)\\left(s[n]-E\\left(s[n]\\right)\\right)\\right)  \\\\\n&=c_s[n,n] \\\\\n&=a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\n\\end{aligned}\\\\\n\\text{当 }m\\geq n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{m-n}\\sum_{k=0}^{n}a^{2k}\\\\\\text{当 }m<n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{n-m}\\sum^{m}a^{2k}=r_{ss}\\left[n,m\\right]\n$$\n#### 平稳性\n$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=a^{n+1}\\mu_s\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\end{aligned}\n$$\n不是宽平稳的。\n\n通常要求 $|a| \\lt 1$，当取 $n \\rarr \\infty$ 时\n$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=0\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\frac{1-a^{2n+2}}{1-a^2}=\\frac{\\sigma_u^2a^{m-n}}{1-a^2}=r_{ss}\\left[k\\right]\\end{aligned}\n$$\n此时是宽平稳（WSS）的。\n\n#### 递推特性\n$$\nE\\left(s[n]\\right)=aE\\left(s[n-1]\\right)+E\\left(u[n]\\right)=aE\\left(s[n-1]\\right)\n$$\n\n$$\n\\operatorname{var}\\left(s[n]\\right)=E\\left(\\left(s[n]-E(s[n])\\right)\\left(s[n]-E(s[n])\\right)\\right) = a^2\\operatorname{var}\\left(s[n-1]\\right)+\\sigma_u^2\n$$\n\n$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m-n}\\operatorname{var}\\left(s[n]\\right) = a^{m-n}\\left(a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\\right)\\\\\nm \\le n, c_s\\left[m,n\\right]=c_s\\left[n,m\\right]=a^{n-m}\\operatorname{var}\\left(s\\left[m\\right]\\right)\n$$\n### 卡尔曼滤波\n\n状态方程：$s[n]=as\\left[n-1\\right]+u\\left[n\\right]$\n\n观测方程：$x[n]=s\\left[n\\right]+w[n]$\n\n驱动噪声 $u[n]$ 相互独立且 $u[n] \\sim N(0, \\sigma^2)$，观测噪声 $w[n]$ 相互独立且 $w[n] \\sim N(0, \\sigma^2)$，起始条件 $s[-1] \\sim N(0, \\sigma_s^2)$。假定 $s[-1], u[n], w[n]$ 之间相互独立。\n\n* 提高估计性能：利用待估计参数的内在联系提高性能\n* 减小运算量：通过“老”估计量更新得到“新”估计量\n\n性质：\n\n对联合高斯独立数据矢量可加性：\n\n若$\\theta,x_1,x_2$是联合高斯的，数据矢量$x_1,x_2$ 相互独立，则MMSE估计量为：\n$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x_1}\\mathbf{C}_{x_1x_1}^{-1}\\left(\\boldsymbol{x}_1-E\\left(\\boldsymbol{x}_1\\right)\\right)+\\mathbf{C}_{\\theta x_2}\\mathbf{C}_{x_2x_2}^{-1}\\left(\\boldsymbol{x}_2-E\\left(\\boldsymbol{x}_2\\right)\\right)\n$$\n对待估计参数的可加性：\n\n若 $\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2$, 则相应的MMSE估计量是可加的，即\n$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1\\mid\\boldsymbol{x}\\right)+E\\left(\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)\n$$\n线性变换的不变性：\n\n若$\\alpha=\\mathbf{A\\theta}+\\boldsymbol{b},\\quad\\theta$ 的MMSE估计量是 $\\theta$, 则 $\\alpha$ 的MMSE估计量为：\n$$\n\\hat{\\alpha}=\\mathbf{A}\\hat{\\theta}+b\n$$\n定义：\n$$\n\\hat{s}[n-1]=E\\left(s[n-1]|x[0],x[1],...,x[n-1]\\right)\\triangleq\\hat{s}[n-1\\mid n-1]\\\\\nM\\begin{bmatrix}n-1\\end{bmatrix}=E\\left(\\left(s\\begin{bmatrix}n-1\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n-1\\end{bmatrix}\\right)^2\\right)\\\\\n\\hat s[n] \\triangleq\\hat{s}[n\\mid n]\n$$\n其中，前面的 n 表示被估计的信号下表，后面的 n 表示估计量用到的数据中最新的那个数据的下标。\n\n如果能够提取出第 n 个数据点带来的新的信息，并加入之前已有的估计量，就可更新估计量：\n$$\n\\begin{aligned}\n\\hat{s}\\Big[n|n\\Big]& =E\\left(s[n]|x[0],x[1],...,x[n-1],x[n]\\right)  \\\\\n&=E\\left(s[n]|x[0],x[1],...,x[n-1],\\tilde{x}[n]\\right) \\\\\n&=\\underbrace{E\\left(s[n]|x[0],x[1],...,x[n-1]\\right)}_{先前数据估计}+\\underbrace{E\\left(s[n]|\\tilde{x}[n]\\right)}_{新息估计}\n\\end{aligned}\n$$\n新息与已有的数据正交。\n$$\n\\tilde{x}[n]=x[n]-\\hat{x}[n|n-1]\n$$\n“先前数据估计”怎么求解？\n$$\n\\begin{aligned}\n\\hat{s}[n\\mid n-1]& =E\\left(as[n-1]+u[n]|x[0],x[1],...,x[n-1]\\right)  \\\\\n&=E\\left(as[n-1]|x[0],x[1],...,x[n-1]\\right)+E\\left(u[n]|x[0],x[1],...,x[n-1]\\right) \\\\\n&=aE\\left(s\\begin{bmatrix}n-1\\end{bmatrix}|x\\begin{bmatrix}0\\end{bmatrix},x\\begin{bmatrix}1\\end{bmatrix},...,x\\begin{bmatrix}n-1\\end{bmatrix}\\right)\\\\\n&=a\\hat{s}\\begin{bmatrix}n-1|n-1\\end{bmatrix} \\\\\n\\end{aligned}\n$$\n#### 预测\n\n求解新息\n$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=E\\left(s[n]\\right)+\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\left(\\tilde{x}[n]-E\\left(\\tilde{x}[n]\\right)\\right)\n$$\n\n$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\rArr E(s[n]) = 0\\\\\n$$\n\n$$\n\\begin{gathered}\nE\\left(\\tilde{x}[n]\\right)=E\\left(x[n]-\\hat{x}[n\\mid n-1]\\right) \\\\\nE\\left(x[n]\\right)=E\\left(s[n]+w[n]\\right)=0 \\\\\nE\\left(\\hat{x}[n\\mid n-1]\\right)=E\\left(\\sum_{k=0}^{n-1}a[k]x[k]\\right) \n\\end{gathered}\\\\\n\\rArr E\\left(\\hat{x}[n\\mid n-1]\\right)=0\\\\\n\\rArr E(\\tilde x[n]) = 0\n$$\n因此，\n$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\tilde{x}[n]=\\underbrace{\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}}_{卡尔曼增益}\\left(x[n]-\\hat{x}[n\\mid n-1]\\right)\n$$\n#### 最小预测 MSE\n\n$\\mathbf{C}_{s\\tilde{x}}\\text{的求解}$\n$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\tilde{x}[n]\\right)  \\\\\n&=E\\Big(s[n]\\Big(x[n]-\\hat{x}\\Big[n|n-1\\Big]\\Big)\\Big)\n\\end{aligned}\n$$\n其中\n$$\n\\begin{aligned}\\hat{x}\\left[n|n-1\\right]&=E\\left(x[n]|x[0],x[1],...x[n-1]\\right)=E\\left(s[n]+w[n]|x[0],x[1],...x[n-1]\\right)\\\\&=E\\left(s[n]|x[0],x[1],...x[n-1]\\right)=\\hat{s}\\left[n|n-1\\right]\\end{aligned}\n$$\n因此\n$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\left(s[n]+w[n]-\\hat{s}[n|n-1]\\right)\\right)  \\\\\n&=E\\left(s[n]w[n]+s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right) \\\\\n&=E\\Big(s[n]\\Big(s[n]-\\hat{s}\\Big[n|n-1\\Big]\\Big)\\Big)\\\\\n&=E\\left(s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)-E\\left(\\hat{s}[n|n-1]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n|n-1]\\right)\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&\\triangleq M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\n\\end{aligned}\n$$\n求解 $M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}$\n$$\n\\begin{aligned}\n&M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\\\\n&=E\\left(\\left(as\\begin{bmatrix}n-1\\end{bmatrix}+u\\begin{bmatrix}n\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n|n-1\\end{bmatrix}\\right)^2\\right)\\\\\n&=E\\left(\\left(a\\left(s[n-1]-\\hat{s}[n-1\\mid n-1]\\right)+u[n]\\right)^2\\right) \\\\\n&=E\\left(a^2\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)^2+u^2\\left[n\\right]+2a\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)u\\left[n\\right]\\right) \\\\\n&=a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2\n\\end{aligned}\n$$\n#### 卡尔曼增益\n\n$\\mathbf{C}_{\\tilde{x}\\tilde{x}}\\text{的求解}$\n$$\n\\\\\n\\begin{aligned}\n\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=E\\left(\\left(\\tilde{x}[n]-E(\\tilde{x}[n])\\right)^2\\right) = E\\left(\\tilde{x}^2[n]\\right) = E\\left(\\left(x[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right)\\\\\n&=E\\left(\\left(s[n]+w[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right) \\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)^2+w^2\\left[n\\right]+2\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)w[n]\\right) \\\\\n&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\n\\end{aligned}\n$$\n结合\n$$\n\\begin{aligned}\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\\\\\\mathbf{C}_{s\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\end{aligned}\n$$\n我们得到了卡尔曼增益\n$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\underbrace{\\frac{M\\left[n\\mid n-1\\right]}{M\\left[n\\mid n-1\\right]+\\sigma_n^2}}_{卡尔曼增益 K[n]}\\tilde{x}[n]\n$$\n#### 修正\n$$\n\\hat{s}\\left[n\\mid n\\right]=\\underbrace{\\hat{s}\\left[n\\mid n-1\\right]}_{预测}+\\underbrace{K\\left[n\\right]\\left(x\\left[n\\right]-\\hat{s}\\left[n\\mid n-1\\right]\\right)}_{新息修正}\n$$\n#### 最小 MSE\n\nMSE 修正：\n$$\nM[n|n] = (1 - K[n])M[n|n - 1]\n$$\n### 非零均值信号模型\n\n![1714360809348](../images/StaSP/1714360809348.png)\n\n初始化：$\\hat{s} [ - 1|- 1] = E\\begin{pmatrix} s[ - 1] \\end{pmatrix} = \\mu _s$ $M[ - 1|- 1] = E\\left ( \\begin{pmatrix} s[ - 1] - \\hat{s} [ - 1|- 1] \\end{pmatrix} ^2\\right ) = \\sigma _s^2$\n\n估计量预测：$\\hat{s}[n|n-1]=a\\hat{s}[n-1|n-1]$\n\nMSE预测：$M\\left[n\\mid n-1\\right]=a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2$\n\n卡尔曼增益：$K[n]=\\frac{M\\left[n|n-1\\right]}{M\\left[n|n-1\\right]+\\sigma_n^2}$\n\n估计量修正：$\\hat{s}[n|n]=\\hat{s}[n|n-1]+K[n]\\left(x[n]-\\hat{s}[n|n-1]\\right)$\n\nMSE修正: $M\\left [ n\\mid n\\right ] = \\left ( 1- K\\left [ n\\right ] \\right ) M\\left [ n\\mid n- 1\\right ]$\n\n### 矢量状态-标量观测信号模型\n\n![1714360717248](../images/StaSP/1714360717248.png)\n\n### 矢量状态-矢量观测信号模型\n\n![1714360742651](../images/StaSP/1714360742651.png)\n\n### 非线性信号模型\n\n![1714360782259](../images/StaSP/1714360782259.png)\n\n![1714361011137](../images/StaSP/1714361011137.png)\n\n![1714361027958](../images/StaSP/1714361027958.png)\n\n### 总结\n\n* 不同时刻的待估计参数并不完全一样，但是存在某些内在联系\n* 卡尔曼滤波利用这种联系进行 LMMSE 估计，并减少了运算量\n* 如果信号与噪声是高斯的，则卡尔曼滤波在 MMSE 准则下最佳，否则，在 LMMSE 准则下是最佳的。\n\n## 信号检测基本准则与方法\n\n之前一直在研究连续型的问题（回归/估计），这里研究离散型的问题（分类/检测）。\n\n### Neyman-Pearson 准则\n\n适用于没有先验信息、代价不好量化的场景。\n\n两种假设：\n$$\n\\begin{aligned}&H_0:x[n]=w[n],n=0,1,...,N-1\\\\&H_1:x[n]=s[n]+w[n],n=0,1,...,N-1\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n&P\\left(H_1;H_0\\right):\\text{ 虚警概率}\\left(P_{FA},\\text{有时简记为}P_F\\right)\\\\\n&P\\left(H_0;H_1\\right):\\text{ 漏检概率 }\\left(P_M\\right)\\\\\n&P\\left(H_1;H_1\\right):\\text{ 检测概率 }\\left(P_D\\right)\\end{aligned}\n$$\n要求：在虚警概率一定情况下，使检测概率最大化\n\n检测概率和虚警概率之间追求折中，不可能两者都改善。\n\n对给定的虚警概率 $P_{FA}=\\alpha$ ,使检测概率 $P_D$ 最大的判决为\n$$\nL(x)=\\frac{p(x;H_1)}{p(x;H_0)}>\\gamma\n$$\n其中门限由 $P_{FA}=\\int_{\\lbrace\\mathbf{x}:L(\\mathbf{x})>\\gamma\\rbrace}p(\\boldsymbol{x};H_0)d\\boldsymbol{x}=\\alpha$ 决定\n\n\n对于信号检测问题：\n$$\nH_0:\\boldsymbol{x}\\sim N\\left(\\boldsymbol{0},\\sigma^2\\mathbf{I}\\right)\\\\H_1:\\boldsymbol{x}\\sim N\\left(A\\mathbf{1},\\sigma^2\\mathbf{I}\\right)\n$$\n\nNP 检测器：\n$$\n\\frac{p\\left(\\boldsymbol{x};H_1\\right)}{p\\left(\\boldsymbol{x};H_0\\right)}=\\frac{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2\\right\\}}{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}}>\\gamma\\\\\\quad\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2+\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}>\\gamma \n$$\n\n$$\n-\\frac1{2\\sigma^2}\\Bigg(-2A\\sum_{n=0}^{N-1}x[n]+NA^2\\Bigg)>\\ln\\gamma\\\\\\frac1N\\sum_{n=0}^{N-1}x[n]>\\frac{\\sigma^2}{NA}\\ln\\gamma+\\frac A2\n$$\n称为检测统计量。若均值大于门限，则判为有信号，否则为无信号。\n\n使用方法：\n$$\n\\begin{aligned}\n&\\text{检测统计量:}T(x)=\\frac1N\\sum_{n=0}^{N-1}x[n]\\sim\\begin{cases}N\\Big(0,\\sigma^2\\Big/_N\\Big),&H_0\\\\[2ex]N\\Big(A,\\sigma^2\\Big/_N\\Big),&H_1\\end{cases} \\\\\n&\\text{虚警概率:}P_{FA}=Pr\\left(T\\left(\\boldsymbol{x}\\right)>\\gamma^{'};H_0\\right)=Q\\left(\\frac{\\gamma^{'}}{\\sqrt{\\sigma^2/N}}\\right) \\\\\n&\\text{门限设置:}\\gamma^{\\prime}=\\sqrt{\\frac{\\sigma^2}N}Q^{-1}\\left(P_{FA}\\right) \\\\\n& \\begin{aligned}&\\text{相应的检测概率:}\\\\&P_{D}=Pr\\Big(T\\big(\\boldsymbol{x}\\big)>\\gamma^{'};H_{1}\\Big)=Q\\Bigg(\\frac{\\gamma^{'}-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)=Q\\Bigg(\\frac{\\sqrt{\\frac{\\sigma^{2}}{N}}Q^{-1}\\big(P_{FA}\\big)-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)\\end{aligned}  \\\\\n&=Q\\Bigg(Q^{-1}\\big(P_{F_A}\\big)-\\sqrt{\\frac{NA^2}{\\sigma^2}}\\Bigg)\n\\end{aligned}\n$$\n### 检测性能分析\n\n接收机工作特性曲线（ROC, receiver operating characteristics）\n\n![1714966200160](../images/StaSP/1714966200160.png)\n\n直观理解：\n\n![1714966230536](../images/StaSP/1714966230536.png)\n\n多次观测的好处\n\n- 从数学角度：不同假设下的pdf分隔更开，更易区分不同假设\n- 从信号处理角度：增加信号预检测积分时间，获得更多的能量用于检测\n- 从信息论角度：多的观测数据带来了新的信息\n\n\n### 最小错误概率准则\n$$\n\\begin{aligned}\nP_{e}& =\\Pr\\left\\{\\text{判}H_0,H_1\\text{为真}\\right\\}+\\Pr\\left\\{\\text{判}H_1,H_0\\text{为真}\\right\\}  \\\\\n&=P\\big(H_0,H_1\\big)+P\\big(H_1,H_0\\big) \\\\\n&=P\\big(H_1\\big)P\\big(H_0|H_1\\big)+P\\big(H_0\\big)P\\big(H_1|H_0\\big) \\\\\n&=P\\big(H_1\\big)\\int_{R_0}p\\big(\\boldsymbol{x}|H_1\\big)d\\boldsymbol{x}+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}|H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\big(H_1\\big)\\Bigg(1-\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_1\\big)d\\boldsymbol{x}\\Bigg)+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\left(H_1\\right)+\\int_{R_1}\\left\\{P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\n\\end{aligned}\n$$\n为了使错误最小，需要在积分式小于零的区域积分，即\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$\n最小错误概率准则可推导出最大后验概率检测器：\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$\n等价于\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)P\\left(H_1\\right)}{p\\left(\\boldsymbol{x}\\right)}>\\frac{p\\left(\\boldsymbol{x}\\mid H_0\\right)P\\left(H_0\\right)}{p\\left(\\boldsymbol{x}\\right)}\\\\p\\left(H_1\\mid\\boldsymbol{x}\\right)>p\\left(H_0\\mid\\boldsymbol{x}\\right)\n$$\n若先验概率相同，则为最大似然检测器：\n$$\np\\left(x\\mid H_1\\right)>p\\left(x\\mid H_0\\right)\n$$\n### 二元贝叶斯风险准则\n\n引入判错代价\n$$\nR=C_{01}P\\left(H_1\\right)P\\left(H_0\\mid H_1\\right)+C_{10}P\\left(H_0\\right)P\\left(H_1\\mid H_0\\right)\n$$\n进一步泛化：\n$$\nR=C_{00}P\\big(H_0\\big)P\\big(H_0|H_0\\big)+C_{10}P\\big(H_0\\big)P\\big(H_1|H_0\\big)\\\\+C_{01}P\\big(H_1\\big)P\\big(H_0|H_1\\big)+C_{11}P\\big(H_1\\big)P\\big(H_1|H_1\\big)\n$$\n\n$$\n\\begin{aligned}\\text{R}&=C_{00}P\\left(H_0\\right)+C_{01}P\\left(H_1\\right)\\\\&+\\int_{R_1}\\left\\{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\\end{aligned}\n$$\n因此，有了最小贝叶斯风险判决准则：\n$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)}{\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$\n风险一致条件下（$C_{00}=C_{11}=0,C_{10}=C_{01}=1$），回到最小错误概率准则。\n\n### 多元贝叶斯风险准则\n\n贝叶斯风险：\n$$\n\\begin{aligned}\n\\text{R}& =\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_i,H_j\\Big)  \\\\\n&=\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}\\int_{R_i}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_j\\mid x\\Big)p(x)dx\n\\end{aligned}\n$$\n\n应选择使平均风险$C_i\\left(\\boldsymbol{x}\\right)=\\sum_{j=0}^{M-1}C_{ij}P\\left(H_j\\mid\\boldsymbol{x}\\right)$最小的假设\n\n在风险一致条件下\n$$\nC_{ij}=\\begin{cases}0,&i=j\\\\1,&i\\neq j\\end{cases}\n$$\n\n$$\n\\begin{aligned}C_{i}\\left(\\boldsymbol{x}\\right)&=\\sum_{j=0\\atop j\\neq i}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)\\\\&=\\sum_{j=0}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)-\\underline{P\\Big(H_i\\mid\\boldsymbol{x}\\Big)}_{最大化这个}\\end{aligned}\n$$\n因此等价于最大后验准则：\n$$\n\\max_iP(H_i\\mid\\boldsymbol{x})\n$$\n\n若此时先验概率相同，则为最大似然准则。\n\n## 总结知识点\n\n### 估计理论\n\nMAP 估计通常不能使用参数变换，变换后的参数不一定是 MAP。但是 MLE 可以。\n\nLS 方法与 BLUE 等 MVU 的衍生方法有一点不同，就是基础的 LS 没有使用协方差矩阵，但是加权的 LS 可以用协方差矩阵修正结果。\n\n贝叶斯方法和经典方法的区别在于是否把估计量的真值看作一个随机变量。它们都以“平均误差最小”为目标。\n\n### 检测理论\n\n贝叶斯风险：让平均的风险最小化。\n\n未知多余参数如果影响最终的判决结果，可以用贝叶斯方法或者GLRT方法处理。","slug":"StaSP","published":1,"updated":"2024-06-02T07:31:01.576Z","_id":"clu516ie40000qkugfnh9gwzk","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"参数估计\"><a href=\"#参数估计\" class=\"headerlink\" title=\"参数估计\"></a>参数估计</h2><p>分类：</p>\n<ul>\n<li>经典估计</li>\n<li>贝叶斯估计</li>\n</ul>\n<p>准则：</p>\n<ul>\n<li>MSE，均方误差</li>\n</ul>\n<div>$$\n\\hat \\theta = f(\\bm{x})\n$$</div>\n\n<h3 id=\"MSE\"><a href=\"#MSE\" class=\"headerlink\" title=\"MSE\"></a>MSE</h3><div>$$\n\\text{mse}(\\hat \\theta) = E \\lbrace(\\theta - \\hat \\theta)^2\\rbrace = \\text{var}(\\hat \\theta) + b^2(\\hat \\theta)\\\\\nb^2(\\hat \\theta) = E(\\hat \\theta) - \\theta\n$$</div>\n\n<p>现实中无法直接计算 MSE，因为涉及到真值 $\\theta$，但是 $\\theta$ 是我们要求的参数。</p>\n<h3 id=\"MVU\"><a href=\"#MVU\" class=\"headerlink\" title=\"MVU\"></a>MVU</h3><p>最小方差无偏估计</p>\n<p>MVU, Minimum Variance Unbiased</p>\n<p>无偏：</p>\n<div>$$\nE(\\hat \\theta) = \\theta, a \\lt \\theta \\lt b\n$$</div>\n\n<p>无偏的含义：$\\hat \\theta$ 的求法需要对取值范围内任意的 $\\theta$ 进行估计。</p>\n<p>无偏估计是否一定存在？不一定。</p>\n<p>最小方差：</p>\n<div>$$\n\\min \\text{var}\\lbrace\\hat\\theta\\rbrace\n$$</div>\n\n<p>MVU的内涵：估计值的发散程度最小（最小方差），平均意义上靠近真值（MVU）。是对 MSE 的迂回实现。</p>\n<h3 id=\"克拉美罗界定理-CRLB\"><a href=\"#克拉美罗界定理-CRLB\" class=\"headerlink\" title=\"克拉美罗界定理(CRLB)\"></a>克拉美罗界定理(CRLB)</h3><p>假设 $p(\\bm{x};\\theta)$ 满足正则条件：</p>\n<div>$$\nE \\left [ \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta} \\right] = 0\n$$</div>\n\n<p>则</p>\n<div>$$\n\\text{var}(\\hat\\theta) \\ge \\frac{1}{E \\left [\\left( \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta}\\right)^2 \\right]} = - \\frac{1}{E \\left [ \\frac{\\partial^2\\ln p(\\bm{x};\\theta)}{\\partial\\theta^2} \\right]}\n$$</div>\n\n<p>等号成立的充要条件：找到函数 $I, g$</p>\n<div>$$\n\\frac{\\partial \\ln p(\\bm{x};\\theta)}{\\partial \\theta}= I(\\theta)(g(\\bm{x}) - \\theta)\\\\\n\\hat \\theta = g(\\bm{x})\n$$</div>\n\n<p>此时有 $\\text{var}(\\hat\\theta) &#x3D;1 &#x2F; I(\\theta)$。</p>\n<h3 id=\"求解MVU\"><a href=\"#求解MVU\" class=\"headerlink\" title=\"求解MVU\"></a>求解MVU</h3><div>$$\n\\frac{\\partial \\ln p(\\bm{x};A)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A) = \\frac{N}{\\sigma^2}\\left (\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)  \\right)\n$$</div>\n\n<div>$$\ng(\\bm{x}) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]\\\\\nI(\\theta) = \\frac{N}{\\sigma^2}\n$$</div>\n\n<p>有效估计量：能达到克拉美罗下界的估计量，是MVU的子集。</p>\n<h3 id=\"参数变换的克拉美罗界\"><a href=\"#参数变换的克拉美罗界\" class=\"headerlink\" title=\"参数变换的克拉美罗界\"></a>参数变换的克拉美罗界</h3><p>若</p>\n<div>$$\n\\alpha = g(\\theta)\n$$</div>\n\n<p>则</p>\n<div>$$\nCRLB(\\hat \\alpha) = \\left(\\frac{\\partial g(\\theta)}{\\partial \\theta}\\right)^2CRLB(\\hat \\theta)\n$$</div>\n\n<p>对于高斯分布有</p>\n<div>$$\nE(x^2) = \\mu^2 + \\sigma^2\\\\\nE(x^4) = \\mu^4 + 6\\mu^2\\sigma^2 + 3\\sigma^4\n$$</div>\n\n<p>当数据量很大时</p>\n<p>有效估计量靠近真值：$N \\rightarrow \\infty, \\hat\\theta \\rightarrow \\theta$</p>\n<p>非线性变换渐进有效,可以看成线性函数：$g(\\hat \\theta) \\approx g(\\theta) + \\frac{\\partial g(\\theta)}{\\partial\\theta}(\\hat \\theta - \\theta)$</p>\n<h3 id=\"矢量参数的克拉美罗界\"><a href=\"#矢量参数的克拉美罗界\" class=\"headerlink\" title=\"矢量参数的克拉美罗界\"></a>矢量参数的克拉美罗界</h3><div>$$\nE \\left [ \\frac{\\partial \\ln p(\\bm{x};\\bm{\\theta})}{\\partial \\bm{\\theta}} \\right] = 0\n$$</div>\n\n<div>$$\n\\alpha = g(\\theta)\n$$</div>\n\n<p><img src=\"/../images/StaSP/1_1.jpg\" loading=\"lazy\"></p>\n<p>注意：$\\bm T(\\bm x)$ 的维度要和 $\\bm \\theta$ 的维度相同</p>\n<h2 id=\"线性模型方法\"><a href=\"#线性模型方法\" class=\"headerlink\" title=\"线性模型方法\"></a>线性模型方法</h2><div>$$\nx = H\\theta + w, w \\sim N(0, \\sigma^2I)\n$$</div>\n\n<div>$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2}(x - H\\theta)^T(x - H\\theta) \\rbrace\n$$</div>\n\n<div>$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\theta} = \\frac{H^TH}{\\sigma^2}\\lbrace (H^TH)^{-1}H^Tx - \\theta \\rbrace\n$$</div>\n\n<p>从而</p>\n<div>$$\n\\hat \\theta = (H^TH)^{-1}H^Tx\\\\\nC_{\\hat\\theta} = \\sigma^2(H^TH)^{-1}\n$$</div>\n\n<p>这个 MVU 估计量满足</p>\n<div>$$\n\\hat \\theta \\sim N(\\theta, \\sigma^2(H^TH)^{-1})\n$$</div>\n\n<ul>\n<li>要求观测数据与待估计参数间呈线性关系</li>\n<li>要求噪声是高斯白噪声</li>\n<li>要求观测矩阵是满秩的</li>\n<li>所得估计量是有效估计量</li>\n</ul>\n<p>一般信号模型</p>\n<div>$$\nx = H\\theta + s + w, s已知，w \\sim N(0, C)\n$$</div>\n\n<p>结论</p>\n<div>$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}(x - s)\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$</div>\n\n<h2 id=\"充分统计量方法\"><a href=\"#充分统计量方法\" class=\"headerlink\" title=\"充分统计量方法\"></a>充分统计量方法</h2><div>$$\np(x|T(x);\\theta) = p(x|T(x))\n$$</div>\n\n<p>则称 $T(x)$ 为充分统计量</p>\n<p>充分统计量的性质:</p>\n<ul>\n<li>一旦充分统计量确定，似然函数就与待估计参数无关</li>\n<li>充分统计量依赖于待估计参数。待估计参数变化，其相应的充分计量一般也会变化</li>\n<li>所谓“充分”，是相对于原始观测数据而言的原始观测量总是充分统计量，但通常不是最小集</li>\n<li>充分统计量并不唯一</li>\n</ul>\n<p>若</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}v(T)p(T;\\theta)\\mathrm dT = 0\n$$</div>\n\n<p>对所有的 $\\theta$ 并非都满足，只对零函数 $v(T) &#x3D; 0$ 成立，则称充分统计量是完备的。</p>\n<ul>\n<li>一般地，当待估计参数发生变化时，充分统计量也会发生变化</li>\n<li>一旦充分统计量确定以后，似然函数就与待估计参数无关</li>\n</ul>\n<h3 id=\"Neyman-Fisher因子分解定理\"><a href=\"#Neyman-Fisher因子分解定理\" class=\"headerlink\" title=\"Neyman-Fisher因子分解定理\"></a>Neyman-Fisher因子分解定理</h3><p>如果概率密度函数（或概率质量函数，对于离散随机变量）$p(x; \\theta)$ 可以被分解为</p>\n<div>$$\np(x; \\theta) = g(T(x); \\theta) \\cdot h(x)\n$$</div>\n\n<p>其中：</p>\n<ul>\n<li>$g(T(x); \\theta)$ 是一个只通过统计量 $T(x)$ 并依赖于参数 $\\theta$ 的函数。</li>\n<li>$h(x)$ 是只与观测数据 $x$ 相关的函数，与参数 $\\theta$ 无关。</li>\n</ul>\n<p>那么，统计量 $T(x)$ 是参数 $\\theta$ 的充分统计量。反之，如果 $T(x)$ 是参数 $\\theta$ 的充分统计量，那么概率密度函数 $p(x; \\theta)$ 必然可以分解为上述形式。</p>\n<h3 id=\"Rao-Black-Lehmann-Scheffe-RBLS-定理\"><a href=\"#Rao-Black-Lehmann-Scheffe-RBLS-定理\" class=\"headerlink\" title=\"Rao-Black-Lehmann-Scheffe(RBLS)定理\"></a>Rao-Black-Lehmann-Scheffe(RBLS)定理</h3><p>若 $\\breve\\theta$ 是$\\theta$的无偏估计，$T(x)$是$\\theta$的充分统计量，那么$\\hat \\theta&#x3D;E(\\breve{\\theta}|T(x))$</p>\n<ol>\n<li>是$\\theta$ 的一个适用的估计量(与$\\theta$无关)</li>\n<li>无偏的</li>\n<li>对所有的 $\\theta$，它的方差小于等于$\\breve\\theta$ 的方差</li>\n<li>若$T(x)$是完备的，那么$\\theta$是MVU估计量</li>\n</ol>\n<h4 id=\"矢量参数的-RBLS\"><a href=\"#矢量参数的-RBLS\" class=\"headerlink\" title=\"矢量参数的 RBLS\"></a>矢量参数的 RBLS</h4><p><img src=\"/../images/StaSP/2_1.jpg\" loading=\"lazy\"></p>\n<p><img src=\"/../images/StaSP/2_2.png\" loading=\"lazy\"></p>\n<h2 id=\"BLUE\"><a href=\"#BLUE\" class=\"headerlink\" title=\"BLUE\"></a>BLUE</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>直接求出数据-&gt;参数的映射 $\\bm A_{p \\times N}$：</p>\n<div>$$\n\\bm x = \\bm H \\theta\\\\\n\\hat {\\theta}_{p \\times 1} = \\bm A\\bm x\n$$</div>\n\n<p>无偏性：</p>\n<div>$$\n\\theta = E(\\hat\\theta) = \\bm AE(\\bm x) = \\bm AH\\theta\\\\\n\\Rightarrow AH = I_{p \\times p}\n$$</div>\n\n<p>最佳（最小方差）</p>\n<div>$$\n\\min \\lbrace a_i^TCa_i \\rbrace, A = [a_1, a_2, \\dots, a_n]^T\n$$</div>\n\n<p>其中</p>\n<div>$$\nC = E \\lbrace (x - E(x))(x - E(x))^T \\rbrace\n$$</div>\n\n<h3 id=\"高斯-马尔可夫定理\"><a href=\"#高斯-马尔可夫定理\" class=\"headerlink\" title=\"高斯-马尔可夫定理\"></a>高斯-马尔可夫定理</h3><p>如果数据具有一般线性模型的形式</p>\n<div>$$\n\\bm x = \\bm H \\theta + w\n$$</div>\n\n<p>其中 $\\bm H$ 为已知 $N \\times p$ 矩阵，$\\theta$ 为待估计参数，$w$ 是均值为零、协方差为 $\\bm C$ 的噪声矢量（<strong>不一定为高斯</strong>），则 BLUE 估计量为</p>\n<div>$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}x\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$</div>\n\n<ul>\n<li>若为高斯噪声，则BLUE为MVU，且为有效估计量</li>\n</ul>\n<h2 id=\"MLE\"><a href=\"#MLE\" class=\"headerlink\" title=\"MLE\"></a>MLE</h2><h3 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h3><div>$$\n\\hat \\theta = \\arg\\max\\limits_\\theta p(\\bm{x};\\theta)\n$$</div>\n\n<p>如果 PDF 可导</p>\n<div>$$\n\\frac{\\partial p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\\\\\n\\Rightarrow\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\n$$</div>\n\n<p>若有效估计量存在，$\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} &#x3D; I(\\theta)(g(x) - \\theta)$，则可以使用最大似然估计方法求得结果。</p>\n<h3 id=\"MLE-的性质\"><a href=\"#MLE-的性质\" class=\"headerlink\" title=\"MLE 的性质\"></a>MLE 的性质</h3><p>如果数据 $\\bm x$ 的 PDF $p(\\bm x;\\theta)$ 满足“正则”条件，那么<br>对于足够多的数据记录，未知参数 $\\theta$ 的 MLE 渐近服从</p>\n<div>$$\n\\hat\\theta \\stackrel{a}{\\sim} N(\\theta, I^{-1}\\theta)\n$$</div>\n\n<p>其中 $\\theta$ 是在未知参数真值处计算的 Fisher 信息。</p>\n<p>MLE是渐近无偏的</p>\n<p>MLE渐近达到CRLB</p>\n<p>MLE是渐近有效的</p>\n<p>MLE是渐近最佳的</p>\n<ul>\n<li>MLE的方差（协方差）可大于、等于、小于CRLB！（不同于MVU估计）</li>\n<li>但数据量足够多时，将与CRLB接近</li>\n<li>因此，可利用CRLB评估MLE的性能</li>\n</ul>\n<p>“足够多”数据：大量能带来新信息的数据</p>\n<p><strong>MLE的不变性</strong></p>\n<p>若参数 $\\alpha &#x3D; g(\\theta)$，则</p>\n<div>$$\n\\hat\\alpha = g(\\hat\\theta)\n$$</div>\n\n<p>若 $g$ 非一对一函数，那么 $\\hat\\alpha$ 是使修正后的似然函数 $p_T(\\bm x;\\alpha)$ 最大者</p>\n<div>$$\n\\hat\\alpha = \\arg\\max_\\alpha p_T(\\bm x; \\alpha)\\\\\np_T(\\bm x; \\alpha) = \\max_{\\theta: \\alpha=g(\\theta)}p(\\bm x; \\theta)\n$$</div>\n\n<p>该性质对函数 $g$ 无线性变换要求，对任意函数均成立。</p>\n<p>对比MVU</p>\n<ul>\n<li>无偏性、有效性仅对线性变换成立</li>\n<li>对非线性变换不能保持（但渐近无偏、渐近有效）</li>\n</ul>\n<p>对一般线性模型，MLE是MVU，达到了CRLB，是有效的、最佳的！</p>\n<p><img src=\"/../images/StaSP/1711254850893.png\" alt=\"1711254850893\" loading=\"lazy\"></p>\n<h2 id=\"最小二乘估计-LS\"><a href=\"#最小二乘估计-LS\" class=\"headerlink\" title=\"最小二乘估计(LS)\"></a>最小二乘估计(LS)</h2><h3 id=\"线性最小二乘估计\"><a href=\"#线性最小二乘估计\" class=\"headerlink\" title=\"线性最小二乘估计\"></a>线性最小二乘估计</h3><p><img src=\"/../images/StaSP/1711339154789.png\" alt=\"1711339154789\" loading=\"lazy\"></p>\n<h3 id=\"加权最小二乘估计\"><a href=\"#加权最小二乘估计\" class=\"headerlink\" title=\"加权最小二乘估计\"></a>加权最小二乘估计</h3><p><img src=\"/../images/StaSP/1711339192281.png\" alt=\"1711339192281\" loading=\"lazy\"></p>\n<h3 id=\"约束最小二乘估计\"><a href=\"#约束最小二乘估计\" class=\"headerlink\" title=\"约束最小二乘估计\"></a>约束最小二乘估计</h3><p><img src=\"/../images/StaSP/1711339216759.png\" alt=\"1711339216759\" loading=\"lazy\"></p>\n<h3 id=\"比较\"><a href=\"#比较\" class=\"headerlink\" title=\"比较\"></a>比较</h3><p><img src=\"/../images/StaSP/1711339249863.png\" alt=\"1711339249863\" loading=\"lazy\"></p>\n<h2 id=\"经典估计方法比较\"><a href=\"#经典估计方法比较\" class=\"headerlink\" title=\"经典估计方法比较\"></a>经典估计方法比较</h2><h3 id=\"噪声电平估计问题\"><a href=\"#噪声电平估计问题\" class=\"headerlink\" title=\"噪声电平估计问题\"></a>噪声电平估计问题</h3><div>$$\nx[n] = A + w[n]\n$$</div>\n\n<p>其中 $w[n] \\sim N(0, \\sigma^2)$，待估计参数 $\\theta &#x3D; [A, \\sigma^2]^T$</p>\n<h4 id=\"MVU估计\"><a href=\"#MVU估计\" class=\"headerlink\" title=\"MVU估计\"></a>MVU估计</h4><div>$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2} \\sum\\limits_{n=0}^{N - 1}(x[n] - A)^2\\rbrace\n$$</div>\n\n<div>$$\n\\frac{\\partial \\ln p (x;\\theta)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$</div>\n\n<div>$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\sigma^2} = \\frac{N}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$</div>\n\n<p><img src=\"/../images/StaSP/1711339773571.png\" alt=\"1711339773571\" loading=\"lazy\"></p>\n<p><img src=\"/../images/StaSP/1711339786814.png\" alt=\"1711339786814\" loading=\"lazy\"></p>\n<h4 id=\"线性模型\"><a href=\"#线性模型\" class=\"headerlink\" title=\"线性模型\"></a>线性模型</h4><div>$$\n\\hat\\theta = (\\bm H^T\\bm H)^{-1}\\bm  H^T x\n$$</div>\n\n<p><img src=\"/../images/StaSP/1711339831807.png\" alt=\"1711339831807\" loading=\"lazy\"></p>\n<h4 id=\"BLUE-1\"><a href=\"#BLUE-1\" class=\"headerlink\" title=\"BLUE\"></a>BLUE</h4><div>$$\n\\hat\\theta = (\\bm H^T\\bm C^{-1}\\bm H)^{-1}\\bm  H^T\\bm C^{-1} x\n$$</div>\n\n<p><img src=\"/../images/StaSP/1711339865703.png\" alt=\"1711339865703\" loading=\"lazy\"></p>\n<h4 id=\"充分统计量\"><a href=\"#充分统计量\" class=\"headerlink\" title=\"充分统计量\"></a>充分统计量</h4><p><img src=\"/../images/StaSP/1711340151724.png\" alt=\"1711340151724\" loading=\"lazy\"></p>\n<p><img src=\"/../images/StaSP/1711340163113.png\" alt=\"1711340163113\" loading=\"lazy\"></p>\n<p><img src=\"/../images/StaSP/1711340177961.png\" alt=\"1711340177961\" loading=\"lazy\"></p>\n<h4 id=\"MLE-1\"><a href=\"#MLE-1\" class=\"headerlink\" title=\"MLE\"></a>MLE</h4><p><img src=\"/../images/StaSP/1711340277148.png\" alt=\"1711340277148\" loading=\"lazy\"></p>\n<h4 id=\"LSE\"><a href=\"#LSE\" class=\"headerlink\" title=\"LSE\"></a>LSE</h4><p><img src=\"/../images/StaSP/1711340293644.png\" alt=\"1711340293644\" loading=\"lazy\"></p>\n<h2 id=\"贝叶斯估计\"><a href=\"#贝叶斯估计\" class=\"headerlink\" title=\"贝叶斯估计\"></a>贝叶斯估计</h2><p>贝叶斯MSE：<br>Bmse$\\left(\\hat{\\theta}\\right)&#x3D;E\\left(\\left(\\theta-\\hat{\\theta}\\right)^2\\right)$</p>\n<p>$&#x3D;\\int\\int\\left(\\theta-\\hat{\\theta}\\right)^{2}p\\big(\\mathbf{x},\\theta\\big)d\\mathbf{x}d\\theta$ $&#x3D;\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p\\big(\\boldsymbol{x}|\\theta\\big)p\\big(\\theta\\big)d\\boldsymbol{x}d\\theta$<br> $&#x3D;\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p(x|\\theta)dxp(\\theta)d\\theta$</p>\n<p>$\\hat{\\theta}&#x3D;E\\big(\\theta|x\\big)$</p>\n<p>多余参数：未知，但不感兴趣的参数<br> 解决思路：通过积分消除多余参数的影响<br> (1) 后验概率中存多余参数时：</p>\n<div>$$\np(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x}) \\Rightarrow p (\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\int p(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x})\\:d\\boldsymbol{\\alpha}\n$$</div>\n\n<p>(2) 条件概率中存在多余参数时：</p>\n<div>$$\np(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\frac{p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{\\int p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}\n$$</div>\n\n<div>$$\n\\text{若现只有 }p(x|\\theta,\\alpha)\\text{,而无 }p(x|\\theta)\n$$</div>\n 此时可通过积分方式解决\n\n<div>$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha\\mid\\theta)d\\alpha \n$$</div>\n\n<p>进一步地，若待估计参数与多余参数相互独立，</p>\n<div>$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha)d\\alpha \n$$</div>\n\n<p>矢量参数下贝叶斯估计<br>若 θ 是 $p{\\times}1$ 的矢量参数，那么为了估计其中某个参数 $\\theta_i$, 可以将剩余参数当作多余参数，因此对$\\theta_i$ 的MMSE为</p>\n<div>$$\n\\hat{\\theta}_i=E\\left(\\theta_i\\mid x\\right)=\\int\\theta_ip(\\theta_i\\mid x)d\\theta_i\n$$</div>\n 其中\n\n<div>$$\np(\\theta_i\\mid x)=\\int\\cdots\\int p(\\theta\\mid x)d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p\n$$</div>\n\n<div>$$\n\\hat{\\theta}_i=\\int\\theta_i\\left(\\int\\cdots\\int p(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})\\underline{d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p}\\right)d\\theta_i=\\int\\theta_ip(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})d\\boldsymbol{\\theta}\n$$</div>\n\n<div>$$\n\\Longrightarrow\\hat{\\theta}=\\begin{bmatrix}\\theta_1p(\\theta|x)d\\theta\\\\\\int\\theta_2p(\\theta|x)d\\theta\\\\\\vdots\\\\\\int\\theta_pp(\\theta|x)d\\theta\\end{bmatrix}=\\int\\theta_P(\\theta|x)d\\theta=E(\\theta|x)\n$$</div>\n\n<p>Woodbury 恒等式：</p>\n<div>$$\n\\left(\\mathbf{B}+\\boldsymbol{u}\\boldsymbol{u}^T\\right)^{-1}=\\mathbf{B}^{-1}-\\frac{\\mathbf{B}^{-1}\\boldsymbol{u}\\boldsymbol{u}^T\\mathbf{B}^{-1}}{1+\\boldsymbol{u}^T\\mathbf{B}^{-1}\\boldsymbol{u}}\n$$</div>\n\n<h3 id=\"贝叶斯风险\"><a href=\"#贝叶斯风险\" class=\"headerlink\" title=\"贝叶斯风险\"></a>贝叶斯风险</h3><div>$$\n\\Re=\\iint C(\\varepsilon)p(x,\\theta)dxd\\theta \n$$</div>\n\n<h4 id=\"二次型误差\"><a href=\"#二次型误差\" class=\"headerlink\" title=\"二次型误差\"></a>二次型误差</h4><div>$$\nC(\\varepsilon) = \\begin{pmatrix}\\theta-\\hat{\\theta}\\end{pmatrix}^2\n$$</div>\n\n<p>这就是 MMSE</p>\n<p>此时为平均值。</p>\n<h4 id=\"绝对误差\"><a href=\"#绝对误差\" class=\"headerlink\" title=\"绝对误差\"></a>绝对误差</h4><div>$$\nC(\\varepsilon)=\\begin{vmatrix}\\theta-\\hat{\\theta}\\end{vmatrix}\n$$</div>\n\n<blockquote>\n<p>Leibnitz 准则<br>$\\frac{\\partial}{\\partial u}\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}h\\big(u,v\\big)dv&#x3D;\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}\\frac{\\partial h\\big(u,v\\big)}{\\partial u}dv+\\frac{\\partial\\phi_2\\big(u\\big)}{\\partial u}h\\big(u,\\phi_2\\big(u\\big)\\big)-\\frac{\\partial\\phi_1\\big(u\\big)}{\\partial u}h\\big(u,\\phi_1\\big(u\\big))$</p>\n</blockquote>\n<p>此时</p>\n<div>$$\n\\int_{-\\infty}^{\\hat{\\theta}}p\\big(\\theta|x\\big)d\\theta=\\int_{\\hat{\\theta}}^{+\\infty}p\\big(\\theta|x\\big)d\\theta \n$$</div>\n\n<p>为中位数</p>\n<h4 id=\"成功失败型误差\"><a href=\"#成功失败型误差\" class=\"headerlink\" title=\"成功失败型误差\"></a>成功失败型误差</h4><div>$$\nC(\\varepsilon)=\\begin{cases}0,\\left|\\theta-\\hat{\\theta}\\right|<\\delta\\\\1,\\left|\\theta-\\hat{\\theta}\\right|\\geq\\delta\\end{cases}\n$$</div>\n\n<p>此时 </p>\n<div>$$\n\\hat{\\theta}=\\arg\\max_{\\theta}p(\\theta|x)\n$$</div>\n\n<p>即 $\\hat{\\theta}$ 是后验PDF的最大值 (众数) </p>\n<p>MAP maximum a posteriori</p>\n<p>根据贝叶斯公式</p>\n<div>$$\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\lbracep(x|\\theta)p(\\theta)\\right\\rbrace\\\\\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\{\\ln p\\big(x|\\theta\\big)+\\ln p\\big(\\theta\\big)\\right\\}\n$$</div>\n\n<h4 id=\"三值比较\"><a href=\"#三值比较\" class=\"headerlink\" title=\"三值比较\"></a>三值比较</h4><p>一般而言，“三值”并不相等，因此三种估计量往往不同</p>\n<p>特例：高斯时“三值”相等，三种估计方法等价</p>\n<p>大数据量时先验信息不起作用，最大后验概率估计（MAP）将转变为（贝叶斯）最大似然估计（MLE）</p>\n<h3 id=\"线性贝叶斯估计\"><a href=\"#线性贝叶斯估计\" class=\"headerlink\" title=\"线性贝叶斯估计\"></a>线性贝叶斯估计</h3><p>线性贝叶斯估计(LMMSE), 也称线性最小意味着：</p>\n<div>$$\n\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$</div>\n\n<p>即限定估计量与观察数据间呈线性关系，然最小化 </p>\n<div>$$\n\\mathrm{Bmse}\\Big(\\hat{\\theta}\\Big)=E\\Big[\\Big(\\theta-\\hat{\\theta}\\Big)^{2}\\Big]\n$$</div>\n\n<p>即，LMMSE:</p>\n<div>$$\n\\min\\left\\{E\\left[\\left(\\theta-\\hat{\\theta}\\right)^2\\right]\\right\\}\\\\s.t.\\quad\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$</div>\n\n<p>解得估计量：</p>\n<div>$$\n\\hat{\\theta}=E\\left(\\theta\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(x-E\\left(x\\right)\\right)\\\\\\mathrm{Bmse}\\left(\\hat{\\theta}\\right)=\\mathbf{C}_{\\theta\\theta}-\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\mathbf{C}_{x\\theta}\n$$</div>\n\n<p>对比 MMSE：</p>\n<p>附加了线性约束</p>\n<ul>\n<li>可得显示解——好求</li>\n<li>仅需一阶矩和二阶矩</li>\n</ul>\n<p>无附加约束</p>\n<ul>\n<li>可能难以求得显示解</li>\n<li>需PDF</li>\n<li>全局最优</li>\n<li>仅在“线性”中最优</li>\n</ul>\n<h4 id=\"矢量参数情况\"><a href=\"#矢量参数情况\" class=\"headerlink\" title=\"矢量参数情况\"></a>矢量参数情况</h4><p>待估计参数$\\boldsymbol{\\theta}&#x3D;\\begin{bmatrix}\\theta_1,\\theta_2,…,\\theta_p\\end{bmatrix}^T$,其每个参数的 LMMSE 定义为</p>\n<div>$$\n\\begin{aligned}&\\min E\\bigg[\\bigg(\\theta_{i}-\\hat{\\theta}_{i}\\bigg)^{2}\\bigg]\\\\&s.t.\\hat{\\theta}_{i}=\\sum_{n=0}^{N-1}a_{in}x[n]+a_{iN}\\end{aligned}\n$$</div>\n\n<div>$$\n\\hat{\\boldsymbol{\\theta}}=\\begin{bmatrix}E(\\theta_1)\\\\E(\\theta_2)\\\\\\vdots\\\\E(\\theta_p)\\end{bmatrix}+\\begin{bmatrix}\\mathbf{C}_{\\theta_1x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\mathbf{C}_{\\theta_2x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\vdots\\\\\\mathbf{C}_{\\theta_px}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\end{bmatrix}\\\\\n=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x} - E(\\boldsymbol{x})\\right)\n$$</div>\n\n<h3 id=\"序贯LMMSE\"><a href=\"#序贯LMMSE\" class=\"headerlink\" title=\"序贯LMMSE\"></a>序贯LMMSE</h3><p>白噪声电平估计</p>\n<div>$$\nx[n]=A+w[n],n=0,1,...,N\n$$</div>\n\n<div>$$\nA\\sim N\\big(0,\\sigma_{A}^{2}\\big)\\\\\nw[n]\\sim N\\left(0,\\sigma^{2}\\right)\n$$</div>\n\n<p>解得</p>\n<div>$$\n\\begin{aligned}\n&E(\\theta)=0 \\\\\n&\\mathbf{C}_{\\theta x}=E\\left(\\left(\\theta-E\\left(\\theta\\right)\\right)\\left(x-E\\left(x\\right)\\right)^{T}\\right) \\\\\n&=E\\left(\\left(A-0\\right)\\left(x-0\\right)^{T}\\right) \\\\\n&=E\\Big(A\\big(A\\mathbf{1}+\\mathbf{w}\\big)^{T}\\Big) \\\\\n&=\\sigma_{A}^{2}\\mathbf{1}^{T}\n\\end{aligned}\\\\\n\\begin{aligned}\n\\mathbf{C}_{xx}& =E\\left(\\left(x-E\\left(x\\right)\\right)\\left(x-E\\left(x\\right)\\right)^T\\right)  \\\\\n&=E\\left(\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)^T\\right) \\\\\n&=E\\left\\{A\\mathbf{1}\\mathbf{1}^TA+A\\mathbf{1}\\boldsymbol{w}^T+\\boldsymbol{w}\\mathbf{1}^TA+\\boldsymbol{w}\\boldsymbol{w}^T\\right\\} \\\\\n&=\\sigma_A^2\\mathbf{1}\\mathbf{1}^T+\\sigma^2\\mathbf{I}\n\\end{aligned}\\\\\n\\begin{aligned}\\mathbf{C}_{\\theta\\theta}&=\\sigma_A^2\\\\\\mathbf{C}_{x\\theta}&=\\mathbf{C}_{\\theta x}^T\\\\&=\\sigma_A^2\\mathbf{1}\\end{aligned}\n$$</div>\n\n<div>$$\n\\begin{aligned}\\hat{A}&=\\frac{\\sigma_{A}^{2}}{\\sigma_{A}^{2}+\\frac{\\sigma^{2}}{N}}\\\\\\mathrm{Bmse}&\\left(\\hat{A}\\right)=\\frac{1}{N}\\end{aligned}\n$$</div>\n\n<p>记</p>\n<div>$$\n\\hat{A}[N-1]=\\frac{\\sigma_A^2}{\\sigma_A^2+\\frac{\\sigma^2}{N}}\\frac{1}{N}\\sum_{n=0}^{N-1}x[n]\n$$</div>\n\n<p>则</p>\n<div>$$\n\\hat{A}[N]=\\hat{A}[N-1]+\\underbrace{\\frac{\\sigma_A^2}{\\left(N+1\\right)\\sigma_A^2+\\sigma^2}}_{K[N]，增益因子}\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$</div>\n\n<div>$$\n\\frac{\\frac1{\\sigma^2}}{\\frac1{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}+\\frac1{\\sigma^2}}=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\\\\=\\frac{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}}{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}+\\sigma^2}=\\frac{\\sigma_A^2}{\\left(N\\sigma_A^2+\\sigma^2\\right)+\\sigma_A^2}=K\\begin{bmatrix}N\\end{bmatrix}\n$$</div>\n\n<p>一般方法</p>\n<p>序贯计算方法估计量更新：</p>\n<div>$$\n\\hat{A}[N]=\\hat{A}[N-1]+K[N]\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$</div>\n\n<p>增益因子：</p>\n<div>$$\nK\\left[N\\right]=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\n$$</div>\n\n<p>最小贝叶斯MSE更新：</p>\n<div>$$\n\\mathrm{Bmse}\\Big(\\hat{A}[N]\\Big)\\boldsymbol{=}\\Big(1\\boldsymbol{-}K[N]\\Big)\\mathrm{Bmse}\\Big(\\hat{A}[N\\boldsymbol{-}1]\\Big)\n$$</div>\n\n<p>初始化：</p>\n<div>$$\n\\hat{A}[-1]=E(A)\\\\\n\\text{Bmse}\\left ( \\hat{A} [ - 1] \\right ) = \\text{var}\\left ( A\\right ) \n$$</div>\n\n<h2 id=\"维纳滤波\"><a href=\"#维纳滤波\" class=\"headerlink\" title=\"维纳滤波\"></a>维纳滤波</h2><h3 id=\"滤波\"><a href=\"#滤波\" class=\"headerlink\" title=\"滤波\"></a>滤波</h3><p>假定观测数据是零均值、宽平稳的，信号也是零均值、宽平稳的，信号与噪声不相关</p>\n<div>$$\nx[n] = s[n] + w[n], n = 0, 1, \\dots, N - 1\n$$</div>\n\n<div>$$\n\\theta=s[n]\\text{ 用 }x[0],x[1],x[2],...,x[n]\\text{来估计}$$</div>\n\n<p><img src=\"/../images/StaSP/1713150769252.png\" alt=\"1713150769252\" loading=\"lazy\"></p>\n<p>利用 LMMSE 可得</p>\n<div>$$\n\\hat{s}[n]=r_{ss}^{'T}\\left(\\mathbf{R}_{ss}+\\mathbf{R}_{ww}\\right)^{-1}\\boldsymbol{x}\n$$</div>\n从而得到维纳-霍夫滤波方程\n<div>$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}n\\end{bmatrix}&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h^{(n)}\\begin{bmatrix}0\\end{bmatrix}\\\\h^{(n)}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\h^{(n)}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{ss}\\begin{bmatrix}0\\end{bmatrix}\\\\r_{ss}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\r_{ss}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}\n$$</div>\n### 平滑\n<div>$$\n\\theta=s[n]\\text{用 }...,x[-1],x[0],x[1],x[2],...,\\text{来估计}\n$$</div>\n![1713152016025](../images/StaSP/1713152016025.png)\n\n<p>LMMSE:</p>\n<div>$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$</div>\n令 $h[k] = a_{N-k}$\n\n<blockquote>\n<p>正交原理：误差与每一个观测数据正交</p>\n<div>$$\nE\\left(\\left(\\theta-\\hat{\\theta}\\right)x[m]\\right)=0\n$$</div>\n正交原理不依赖于任务是平滑、滤波还是预测，是普遍适用的，证明如下：\n![1713152987612](../images/StaSP/1713152987612.png)\n![1713152970273](../images/StaSP/1713152970273.png)\n在 LMMSE\n</blockquote>\n<div>$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$</div>\n中令 $h[k]=a_{n-k}$\n\n<p>则有</p>\n<div>$$\n\\hat s[n] = \\sum\\limits_{k=-\\infty}^{\\infty}h[k]x[n-k]\n$$</div>\n可得\n<div>$$\nr_{ss}\\begin{bmatrix}n\\end{bmatrix}=h\\begin{bmatrix}n\\end{bmatrix}*r_{xx}\\begin{bmatrix}n\\end{bmatrix}\n$$</div>\n无限维纳平滑器的频率响应\n<div>$$\nH\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{xx}\\left(f\\right)}\\quad=\\frac{P_{ss}\\left(f\\right)}{P_{ss}\\left(f\\right)+P_{ww}\\left(f\\right)}\\quad=\\frac{\\eta\\left(f\\right)}{\\eta\\left(f\\right)+1}\\quad\\text{,其中 }\\eta\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{ww}\\left(f\\right)}\n$$</div>\n### 预测\n\n<p>可以用来进行预测</p>\n<div>$$\n\\theta=x[N-1+l]\\text{ 用 }x[0],x[1],x[2],...,x[N-1]\\text{ 来估计}\n$$</div>\n![1713150674892](../images/StaSP/1713150674892.png)\n\n<p>依然用 LMMSE 可以得到线性预测维纳-霍夫滤波方程</p>\n<div>$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h\\begin{bmatrix}1\\end{bmatrix}\\\\h\\begin{bmatrix}2\\end{bmatrix}\\\\\\vdots\\\\h\\begin{bmatrix}N\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{xx}\\begin{bmatrix}l\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}l+1\\end{bmatrix}\\\\\\vdots\\\\r_{xx}\\begin{bmatrix}N-1+l\\end{bmatrix}\\end{bmatrix}\n$$</div>\n### 应用\n\n<p>信道均衡问题</p>\n<p><img src=\"/../images/StaSP/1713151589324.png\" alt=\"1713151589324\" loading=\"lazy\"></p>\n<h2 id=\"卡尔曼滤波\"><a href=\"#卡尔曼滤波\" class=\"headerlink\" title=\"卡尔曼滤波\"></a>卡尔曼滤波</h2><p>如何估计电压？</p>\n<h3 id=\"模型-1：当成确定参数\"><a href=\"#模型-1：当成确定参数\" class=\"headerlink\" title=\"模型 1：当成确定参数\"></a>模型 1：当成确定参数</h3><div>$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2})\n$$</div>\n\n<div>$$\n\\hat A = \\sum\\limits_{n=0}^{N - 1}x[n] = \\bar x\n$$</div>\n### 模型2：当成某个随机变量\n<div>$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2}), A \\sim N(\\mu_A, \\sigma_A^{2})\n$$</div>\n贝叶斯一般线性模型：\n<div>$$\n\\boldsymbol{x}=\\mathbf{H}\\boldsymbol{\\theta}+\\boldsymbol{w}\\quad\\text{其中 }\\boldsymbol{\\theta}{\\sim}N\\begin{pmatrix}\\boldsymbol{\\mu}_\\theta,\\mathbf{C}_\\theta\\end{pmatrix}\\text{,}\\boldsymbol{w}{\\sim}N\\begin{pmatrix}\\boldsymbol{0},\\mathbf{C}_w\\end{pmatrix}\\\\\nE\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E\\left(\\boldsymbol{x}\\right)\\right)=\\boldsymbol{\\mu}_\\theta+\\mathbf{C}_{\\theta|x}\\mathbf{H}^T\\mathbf{C}_w^{-1}\\left(\\boldsymbol{x}-\\mathbf{H}\\boldsymbol{\\mu}_\\theta\\right)\\\\\n\\text{其中,}\\mathbf{C}_{\\theta|x}=\\left(\\mathbf{C}_\\theta^{-1}+\\mathbf{H}^T\\mathbf{C}_w^{-1}\\mathbf{H}\\right)^{-1}\n$$</div>\n\n<div>$$\n\\hat{A}=\\mu_A+\\frac{\\frac1{\\sigma^2/N}}{\\frac1{\\sigma_A^2}+\\frac1{\\sigma^2/N}}(\\overline{x}-\\mu_A)\n$$</div>\n### 模型3：当成未知且随时间变化的量\n<div>$$\nx[n]=A[n]+w[n],n=0,1,...,N-1\n$$</div>\n\n<div>$$\n\\mathrm{MVU}\\text{估计量:}\\hat{\\boldsymbol{\\theta}}=\\left(\\mathbf{H}^T\\mathbf{H}\\right)^{-1}\\mathbf{H}^T\\boldsymbol{x}\\\\\n\\begin{aligned}&\\boldsymbol{\\theta}=&\\begin{bmatrix}A[0],A[1],...,A[N-1]\\end{bmatrix}^T\\\\&\\mathbf{H}=\\mathbf{I}\\end{aligned}\\\\\n\\hat{A}[n]=x[n]\n$$</div>\n### 动态信号模型\n\n<p>一阶高斯-马尔可夫信号模型：</p>\n<div>$$\ns[n]=as[n-1]+u[n],n\\geq0\n$$</div>\n其中，$u[n]$是均值为零方差为 $\\sigma_u^2$ 的高斯白噪声，称为驱动噪声或激励噪声。信号初值s$[-1]\\sim N(\\mu_s,\\sigma_s^2)$与激励噪声$u[n]$相互独立。\n\n<p>均值：</p>\n<div>$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\\\\nE\\left(s[n]\\right)=a^{n+1}E\\left(s[-1]\\right)+\\sum_{k=0}^na^kE\\left(u[n-k]\\right)=a^{n+1}\\mu_s\\\\\nc_s[m,n] = a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^m\\sum_{l=0}^na^{k+l}E\\left(u[m-k]u[n-l]\\right)\\\\\nE\\left(u[m-k]u[n-l]\\right)=\\begin{cases}\\sigma_u^2,&l=n-m+k\\\\0,&\\mathrm{others}\\end{cases}\n$$</div>\n协方差：\n<div>$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m+n+2}\\sigma_s^2+\\sum_{k=m-n}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\\\\nm \\lt n, c_s\\begin{bmatrix}m,n\\end{bmatrix}=a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{n-m}\\sum_{k=0}^ma^{2k}=c_s\\begin{bmatrix}n,m\\end{bmatrix}\n$$</div>\n方差和二阶矩：\n<div>$$\n\\begin{aligned}\n\\operatorname{var}(s[n])& =E\\left(\\left(s[n]-E\\left(s[n]\\right)\\right)\\left(s[n]-E\\left(s[n]\\right)\\right)\\right)  \\\\\n&=c_s[n,n] \\\\\n&=a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\n\\end{aligned}\\\\\n\\text{当 }m\\geq n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{m-n}\\sum_{k=0}^{n}a^{2k}\\\\\\text{当 }m<n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{n-m}\\sum^{m}a^{2k}=r_{ss}\\left[n,m\\right]\n$$</div>\n#### 平稳性\n<div>$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=a^{n+1}\\mu_s\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\end{aligned}\n$$</div>\n不是宽平稳的。\n\n<p>通常要求 $|a| \\lt 1$，当取 $n \\rarr \\infty$ 时</p>\n<div>$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=0\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\frac{1-a^{2n+2}}{1-a^2}=\\frac{\\sigma_u^2a^{m-n}}{1-a^2}=r_{ss}\\left[k\\right]\\end{aligned}\n$$</div>\n此时是宽平稳（WSS）的。\n\n<h4 id=\"递推特性\"><a href=\"#递推特性\" class=\"headerlink\" title=\"递推特性\"></a>递推特性</h4><div>$$\nE\\left(s[n]\\right)=aE\\left(s[n-1]\\right)+E\\left(u[n]\\right)=aE\\left(s[n-1]\\right)\n$$</div>\n\n<div>$$\n\\operatorname{var}\\left(s[n]\\right)=E\\left(\\left(s[n]-E(s[n])\\right)\\left(s[n]-E(s[n])\\right)\\right) = a^2\\operatorname{var}\\left(s[n-1]\\right)+\\sigma_u^2\n$$</div>\n\n<div>$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m-n}\\operatorname{var}\\left(s[n]\\right) = a^{m-n}\\left(a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\\right)\\\\\nm \\le n, c_s\\left[m,n\\right]=c_s\\left[n,m\\right]=a^{n-m}\\operatorname{var}\\left(s\\left[m\\right]\\right)\n$$</div>\n### 卡尔曼滤波\n\n<p>状态方程：$s[n]&#x3D;as\\left[n-1\\right]+u\\left[n\\right]$</p>\n<p>观测方程：$x[n]&#x3D;s\\left[n\\right]+w[n]$</p>\n<p>驱动噪声 $u[n]$ 相互独立且 $u[n] \\sim N(0, \\sigma^2)$，观测噪声 $w[n]$ 相互独立且 $w[n] \\sim N(0, \\sigma^2)$，起始条件 $s[-1] \\sim N(0, \\sigma_s^2)$。假定 $s[-1], u[n], w[n]$ 之间相互独立。</p>\n<ul>\n<li>提高估计性能：利用待估计参数的内在联系提高性能</li>\n<li>减小运算量：通过“老”估计量更新得到“新”估计量</li>\n</ul>\n<p>性质：</p>\n<p>对联合高斯独立数据矢量可加性：</p>\n<p>若$\\theta,x_1,x_2$是联合高斯的，数据矢量$x_1,x_2$ 相互独立，则MMSE估计量为：</p>\n<div>$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x_1}\\mathbf{C}_{x_1x_1}^{-1}\\left(\\boldsymbol{x}_1-E\\left(\\boldsymbol{x}_1\\right)\\right)+\\mathbf{C}_{\\theta x_2}\\mathbf{C}_{x_2x_2}^{-1}\\left(\\boldsymbol{x}_2-E\\left(\\boldsymbol{x}_2\\right)\\right)\n$$</div>\n对待估计参数的可加性：\n\n<p>若 $\\boldsymbol{\\theta}&#x3D;\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2$, 则相应的MMSE估计量是可加的，即</p>\n<div>$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1\\mid\\boldsymbol{x}\\right)+E\\left(\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)\n$$</div>\n线性变换的不变性：\n\n<p>若$\\alpha&#x3D;\\mathbf{A\\theta}+\\boldsymbol{b},\\quad\\theta$ 的MMSE估计量是 $\\theta$, 则 $\\alpha$ 的MMSE估计量为：</p>\n<div>$$\n\\hat{\\alpha}=\\mathbf{A}\\hat{\\theta}+b\n$$</div>\n定义：\n<div>$$\n\\hat{s}[n-1]=E\\left(s[n-1]|x[0],x[1],...,x[n-1]\\right)\\triangleq\\hat{s}[n-1\\mid n-1]\\\\\nM\\begin{bmatrix}n-1\\end{bmatrix}=E\\left(\\left(s\\begin{bmatrix}n-1\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n-1\\end{bmatrix}\\right)^2\\right)\\\\\n\\hat s[n] \\triangleq\\hat{s}[n\\mid n]\n$$</div>\n其中，前面的 n 表示被估计的信号下表，后面的 n 表示估计量用到的数据中最新的那个数据的下标。\n\n<p>如果能够提取出第 n 个数据点带来的新的信息，并加入之前已有的估计量，就可更新估计量：</p>\n<div>$$\n\\begin{aligned}\n\\hat{s}\\Big[n|n\\Big]& =E\\left(s[n]|x[0],x[1],...,x[n-1],x[n]\\right)  \\\\\n&=E\\left(s[n]|x[0],x[1],...,x[n-1],\\tilde{x}[n]\\right) \\\\\n&=\\underbrace{E\\left(s[n]|x[0],x[1],...,x[n-1]\\right)}_{先前数据估计}+\\underbrace{E\\left(s[n]|\\tilde{x}[n]\\right)}_{新息估计}\n\\end{aligned}\n$$</div>\n新息与已有的数据正交。\n<div>$$\n\\tilde{x}[n]=x[n]-\\hat{x}[n|n-1]\n$$</div>\n“先前数据估计”怎么求解？\n<div>$$\n\\begin{aligned}\n\\hat{s}[n\\mid n-1]& =E\\left(as[n-1]+u[n]|x[0],x[1],...,x[n-1]\\right)  \\\\\n&=E\\left(as[n-1]|x[0],x[1],...,x[n-1]\\right)+E\\left(u[n]|x[0],x[1],...,x[n-1]\\right) \\\\\n&=aE\\left(s\\begin{bmatrix}n-1\\end{bmatrix}|x\\begin{bmatrix}0\\end{bmatrix},x\\begin{bmatrix}1\\end{bmatrix},...,x\\begin{bmatrix}n-1\\end{bmatrix}\\right)\\\\\n&=a\\hat{s}\\begin{bmatrix}n-1|n-1\\end{bmatrix} \\\\\n\\end{aligned}\n$$</div>\n#### 预测\n\n<p>求解新息</p>\n<div>$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=E\\left(s[n]\\right)+\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\left(\\tilde{x}[n]-E\\left(\\tilde{x}[n]\\right)\\right)\n$$</div>\n\n<div>$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\rArr E(s[n]) = 0\\\\\n$$</div>\n\n<div>$$\n\\begin{gathered}\nE\\left(\\tilde{x}[n]\\right)=E\\left(x[n]-\\hat{x}[n\\mid n-1]\\right) \\\\\nE\\left(x[n]\\right)=E\\left(s[n]+w[n]\\right)=0 \\\\\nE\\left(\\hat{x}[n\\mid n-1]\\right)=E\\left(\\sum_{k=0}^{n-1}a[k]x[k]\\right) \n\\end{gathered}\\\\\n\\rArr E\\left(\\hat{x}[n\\mid n-1]\\right)=0\\\\\n\\rArr E(\\tilde x[n]) = 0\n$$</div>\n因此，\n<div>$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\tilde{x}[n]=\\underbrace{\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}}_{卡尔曼增益}\\left(x[n]-\\hat{x}[n\\mid n-1]\\right)\n$$</div>\n#### 最小预测 MSE\n\n<p>$\\mathbf{C}_{s\\tilde{x}}\\text{的求解}$</p>\n<div>$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\tilde{x}[n]\\right)  \\\\\n&=E\\Big(s[n]\\Big(x[n]-\\hat{x}\\Big[n|n-1\\Big]\\Big)\\Big)\n\\end{aligned}\n$$</div>\n其中\n<div>$$\n\\begin{aligned}\\hat{x}\\left[n|n-1\\right]&=E\\left(x[n]|x[0],x[1],...x[n-1]\\right)=E\\left(s[n]+w[n]|x[0],x[1],...x[n-1]\\right)\\\\&=E\\left(s[n]|x[0],x[1],...x[n-1]\\right)=\\hat{s}\\left[n|n-1\\right]\\end{aligned}\n$$</div>\n因此\n<div>$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\left(s[n]+w[n]-\\hat{s}[n|n-1]\\right)\\right)  \\\\\n&=E\\left(s[n]w[n]+s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right) \\\\\n&=E\\Big(s[n]\\Big(s[n]-\\hat{s}\\Big[n|n-1\\Big]\\Big)\\Big)\\\\\n&=E\\left(s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)-E\\left(\\hat{s}[n|n-1]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n|n-1]\\right)\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&\\triangleq M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\n\\end{aligned}\n$$</div>\n求解 $M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}$\n<div>$$\n\\begin{aligned}\n&M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\\\\n&=E\\left(\\left(as\\begin{bmatrix}n-1\\end{bmatrix}+u\\begin{bmatrix}n\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n|n-1\\end{bmatrix}\\right)^2\\right)\\\\\n&=E\\left(\\left(a\\left(s[n-1]-\\hat{s}[n-1\\mid n-1]\\right)+u[n]\\right)^2\\right) \\\\\n&=E\\left(a^2\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)^2+u^2\\left[n\\right]+2a\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)u\\left[n\\right]\\right) \\\\\n&=a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2\n\\end{aligned}\n$$</div>\n#### 卡尔曼增益\n\n<p>$\\mathbf{C}_{\\tilde{x}\\tilde{x}}\\text{的求解}$</p>\n<div>$$\n\\\\\n\\begin{aligned}\n\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=E\\left(\\left(\\tilde{x}[n]-E(\\tilde{x}[n])\\right)^2\\right) = E\\left(\\tilde{x}^2[n]\\right) = E\\left(\\left(x[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right)\\\\\n&=E\\left(\\left(s[n]+w[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right) \\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)^2+w^2\\left[n\\right]+2\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)w[n]\\right) \\\\\n&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\n\\end{aligned}\n$$</div>\n结合\n<div>$$\n\\begin{aligned}\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\\\\\\mathbf{C}_{s\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\end{aligned}\n$$</div>\n我们得到了卡尔曼增益\n<div>$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\underbrace{\\frac{M\\left[n\\mid n-1\\right]}{M\\left[n\\mid n-1\\right]+\\sigma_n^2}}_{卡尔曼增益 K[n]}\\tilde{x}[n]\n$$</div>\n#### 修正\n<div>$$\n\\hat{s}\\left[n\\mid n\\right]=\\underbrace{\\hat{s}\\left[n\\mid n-1\\right]}_{预测}+\\underbrace{K\\left[n\\right]\\left(x\\left[n\\right]-\\hat{s}\\left[n\\mid n-1\\right]\\right)}_{新息修正}\n$$</div>\n#### 最小 MSE\n\n<p>MSE 修正：</p>\n<div>$$\nM[n|n] = (1 - K[n])M[n|n - 1]\n$$</div>\n### 非零均值信号模型\n\n<p><img src=\"/../images/StaSP/1714360809348.png\" alt=\"1714360809348\" loading=\"lazy\"></p>\n<p>初始化：$\\hat{s} [ - 1|- 1] &#x3D; E\\begin{pmatrix} s[ - 1] \\end{pmatrix} &#x3D; \\mu _s$ $M[ - 1|- 1] &#x3D; E\\left ( \\begin{pmatrix} s[ - 1] - \\hat{s} [ - 1|- 1] \\end{pmatrix} ^2\\right ) &#x3D; \\sigma _s^2$</p>\n<p>估计量预测：$\\hat{s}[n|n-1]&#x3D;a\\hat{s}[n-1|n-1]$</p>\n<p>MSE预测：$M\\left[n\\mid n-1\\right]&#x3D;a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2$</p>\n<p>卡尔曼增益：$K[n]&#x3D;\\frac{M\\left[n|n-1\\right]}{M\\left[n|n-1\\right]+\\sigma_n^2}$</p>\n<p>估计量修正：$\\hat{s}[n|n]&#x3D;\\hat{s}[n|n-1]+K[n]\\left(x[n]-\\hat{s}[n|n-1]\\right)$</p>\n<p>MSE修正: $M\\left [ n\\mid n\\right ] &#x3D; \\left ( 1- K\\left [ n\\right ] \\right ) M\\left [ n\\mid n- 1\\right ]$</p>\n<h3 id=\"矢量状态-标量观测信号模型\"><a href=\"#矢量状态-标量观测信号模型\" class=\"headerlink\" title=\"矢量状态-标量观测信号模型\"></a>矢量状态-标量观测信号模型</h3><p><img src=\"/../images/StaSP/1714360717248.png\" alt=\"1714360717248\" loading=\"lazy\"></p>\n<h3 id=\"矢量状态-矢量观测信号模型\"><a href=\"#矢量状态-矢量观测信号模型\" class=\"headerlink\" title=\"矢量状态-矢量观测信号模型\"></a>矢量状态-矢量观测信号模型</h3><p><img src=\"/../images/StaSP/1714360742651.png\" alt=\"1714360742651\" loading=\"lazy\"></p>\n<h3 id=\"非线性信号模型\"><a href=\"#非线性信号模型\" class=\"headerlink\" title=\"非线性信号模型\"></a>非线性信号模型</h3><p><img src=\"/../images/StaSP/1714360782259.png\" alt=\"1714360782259\" loading=\"lazy\"></p>\n<p><img src=\"/../images/StaSP/1714361011137.png\" alt=\"1714361011137\" loading=\"lazy\"></p>\n<p><img src=\"/../images/StaSP/1714361027958.png\" alt=\"1714361027958\" loading=\"lazy\"></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>不同时刻的待估计参数并不完全一样，但是存在某些内在联系</li>\n<li>卡尔曼滤波利用这种联系进行 LMMSE 估计，并减少了运算量</li>\n<li>如果信号与噪声是高斯的，则卡尔曼滤波在 MMSE 准则下最佳，否则，在 LMMSE 准则下是最佳的。</li>\n</ul>\n<h2 id=\"信号检测基本准则与方法\"><a href=\"#信号检测基本准则与方法\" class=\"headerlink\" title=\"信号检测基本准则与方法\"></a>信号检测基本准则与方法</h2><p>之前一直在研究连续型的问题（回归&#x2F;估计），这里研究离散型的问题（分类&#x2F;检测）。</p>\n<h3 id=\"Neyman-Pearson-准则\"><a href=\"#Neyman-Pearson-准则\" class=\"headerlink\" title=\"Neyman-Pearson 准则\"></a>Neyman-Pearson 准则</h3><p>适用于没有先验信息、代价不好量化的场景。</p>\n<p>两种假设：</p>\n<div>$$\n\\begin{aligned}&H_0:x[n]=w[n],n=0,1,...,N-1\\\\&H_1:x[n]=s[n]+w[n],n=0,1,...,N-1\\end{aligned}\n$$</div>\n\n<div>$$\n\\begin{aligned}\n&P\\left(H_1;H_0\\right):\\text{ 虚警概率}\\left(P_{FA},\\text{有时简记为}P_F\\right)\\\\\n&P\\left(H_0;H_1\\right):\\text{ 漏检概率 }\\left(P_M\\right)\\\\\n&P\\left(H_1;H_1\\right):\\text{ 检测概率 }\\left(P_D\\right)\\end{aligned}\n$$</div>\n要求：在虚警概率一定情况下，使检测概率最大化\n\n<p>检测概率和虚警概率之间追求折中，不可能两者都改善。</p>\n<p>对给定的虚警概率 $P_{FA}&#x3D;\\alpha$ ,使检测概率 $P_D$ 最大的判决为</p>\n<div>$$\nL(x)=\\frac{p(x;H_1)}{p(x;H_0)}>\\gamma\n$$</div>\n其中门限由 $P_{FA}=\\int_{\\lbrace\\mathbf{x}:L(\\mathbf{x})>\\gamma\\rbrace}p(\\boldsymbol{x};H_0)d\\boldsymbol{x}=\\alpha$ 决定\n\n\n<p>对于信号检测问题：</p>\n<div>$$\nH_0:\\boldsymbol{x}\\sim N\\left(\\boldsymbol{0},\\sigma^2\\mathbf{I}\\right)\\\\H_1:\\boldsymbol{x}\\sim N\\left(A\\mathbf{1},\\sigma^2\\mathbf{I}\\right)\n$$</div>\n\n<p>NP 检测器：</p>\n<div>$$\n\\frac{p\\left(\\boldsymbol{x};H_1\\right)}{p\\left(\\boldsymbol{x};H_0\\right)}=\\frac{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2\\right\\}}{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}}>\\gamma\\\\\\quad\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2+\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}>\\gamma \n$$</div>\n\n<div>$$\n-\\frac1{2\\sigma^2}\\Bigg(-2A\\sum_{n=0}^{N-1}x[n]+NA^2\\Bigg)>\\ln\\gamma\\\\\\frac1N\\sum_{n=0}^{N-1}x[n]>\\frac{\\sigma^2}{NA}\\ln\\gamma+\\frac A2\n$$</div>\n称为检测统计量。若均值大于门限，则判为有信号，否则为无信号。\n\n<p>使用方法：</p>\n<div>$$\n\\begin{aligned}\n&\\text{检测统计量:}T(x)=\\frac1N\\sum_{n=0}^{N-1}x[n]\\sim\\begin{cases}N\\Big(0,\\sigma^2\\Big/_N\\Big),&H_0\\\\[2ex]N\\Big(A,\\sigma^2\\Big/_N\\Big),&H_1\\end{cases} \\\\\n&\\text{虚警概率:}P_{FA}=Pr\\left(T\\left(\\boldsymbol{x}\\right)>\\gamma^{'};H_0\\right)=Q\\left(\\frac{\\gamma^{'}}{\\sqrt{\\sigma^2/N}}\\right) \\\\\n&\\text{门限设置:}\\gamma^{\\prime}=\\sqrt{\\frac{\\sigma^2}N}Q^{-1}\\left(P_{FA}\\right) \\\\\n& \\begin{aligned}&\\text{相应的检测概率:}\\\\&P_{D}=Pr\\Big(T\\big(\\boldsymbol{x}\\big)>\\gamma^{'};H_{1}\\Big)=Q\\Bigg(\\frac{\\gamma^{'}-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)=Q\\Bigg(\\frac{\\sqrt{\\frac{\\sigma^{2}}{N}}Q^{-1}\\big(P_{FA}\\big)-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)\\end{aligned}  \\\\\n&=Q\\Bigg(Q^{-1}\\big(P_{F_A}\\big)-\\sqrt{\\frac{NA^2}{\\sigma^2}}\\Bigg)\n\\end{aligned}\n$$</div>\n### 检测性能分析\n\n<p>接收机工作特性曲线（ROC, receiver operating characteristics）</p>\n<p><img src=\"/../images/StaSP/1714966200160.png\" alt=\"1714966200160\" loading=\"lazy\"></p>\n<p>直观理解：</p>\n<p><img src=\"/../images/StaSP/1714966230536.png\" alt=\"1714966230536\" loading=\"lazy\"></p>\n<p>多次观测的好处</p>\n<ul>\n<li>从数学角度：不同假设下的pdf分隔更开，更易区分不同假设</li>\n<li>从信号处理角度：增加信号预检测积分时间，获得更多的能量用于检测</li>\n<li>从信息论角度：多的观测数据带来了新的信息</li>\n</ul>\n<h3 id=\"最小错误概率准则\"><a href=\"#最小错误概率准则\" class=\"headerlink\" title=\"最小错误概率准则\"></a>最小错误概率准则</h3><div>$$\n\\begin{aligned}\nP_{e}& =\\Pr\\left\\{\\text{判}H_0,H_1\\text{为真}\\right\\}+\\Pr\\left\\{\\text{判}H_1,H_0\\text{为真}\\right\\}  \\\\\n&=P\\big(H_0,H_1\\big)+P\\big(H_1,H_0\\big) \\\\\n&=P\\big(H_1\\big)P\\big(H_0|H_1\\big)+P\\big(H_0\\big)P\\big(H_1|H_0\\big) \\\\\n&=P\\big(H_1\\big)\\int_{R_0}p\\big(\\boldsymbol{x}|H_1\\big)d\\boldsymbol{x}+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}|H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\big(H_1\\big)\\Bigg(1-\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_1\\big)d\\boldsymbol{x}\\Bigg)+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\left(H_1\\right)+\\int_{R_1}\\left\\{P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\n\\end{aligned}\n$$</div>\n为了使错误最小，需要在积分式小于零的区域积分，即\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$</div>\n最小错误概率准则可推导出最大后验概率检测器：\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$</div>\n等价于\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)P\\left(H_1\\right)}{p\\left(\\boldsymbol{x}\\right)}>\\frac{p\\left(\\boldsymbol{x}\\mid H_0\\right)P\\left(H_0\\right)}{p\\left(\\boldsymbol{x}\\right)}\\\\p\\left(H_1\\mid\\boldsymbol{x}\\right)>p\\left(H_0\\mid\\boldsymbol{x}\\right)\n$$</div>\n若先验概率相同，则为最大似然检测器：\n<div>$$\np\\left(x\\mid H_1\\right)>p\\left(x\\mid H_0\\right)\n$$</div>\n### 二元贝叶斯风险准则\n\n<p>引入判错代价</p>\n<div>$$\nR=C_{01}P\\left(H_1\\right)P\\left(H_0\\mid H_1\\right)+C_{10}P\\left(H_0\\right)P\\left(H_1\\mid H_0\\right)\n$$</div>\n进一步泛化：\n<div>$$\nR=C_{00}P\\big(H_0\\big)P\\big(H_0|H_0\\big)+C_{10}P\\big(H_0\\big)P\\big(H_1|H_0\\big)\\\\+C_{01}P\\big(H_1\\big)P\\big(H_0|H_1\\big)+C_{11}P\\big(H_1\\big)P\\big(H_1|H_1\\big)\n$$</div>\n\n<div>$$\n\\begin{aligned}\\text{R}&=C_{00}P\\left(H_0\\right)+C_{01}P\\left(H_1\\right)\\\\&+\\int_{R_1}\\left\\{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\\end{aligned}\n$$</div>\n因此，有了最小贝叶斯风险判决准则：\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)}{\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$</div>\n风险一致条件下（$C_{00}=C_{11}=0,C_{10}=C_{01}=1$），回到最小错误概率准则。\n\n<h3 id=\"多元贝叶斯风险准则\"><a href=\"#多元贝叶斯风险准则\" class=\"headerlink\" title=\"多元贝叶斯风险准则\"></a>多元贝叶斯风险准则</h3><p>贝叶斯风险：</p>\n<div>$$\n\\begin{aligned}\n\\text{R}& =\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_i,H_j\\Big)  \\\\\n&=\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}\\int_{R_i}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_j\\mid x\\Big)p(x)dx\n\\end{aligned}\n$$</div>\n\n<p>应选择使平均风险$C_i\\left(\\boldsymbol{x}\\right)&#x3D;\\sum_{j&#x3D;0}^{M-1}C_{ij}P\\left(H_j\\mid\\boldsymbol{x}\\right)$最小的假设</p>\n<p>在风险一致条件下</p>\n<div>$$\nC_{ij}=\\begin{cases}0,&i=j\\\\1,&i\\neq j\\end{cases}\n$$</div>\n\n<div>$$\n\\begin{aligned}C_{i}\\left(\\boldsymbol{x}\\right)&=\\sum_{j=0\\atop j\\neq i}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)\\\\&=\\sum_{j=0}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)-\\underline{P\\Big(H_i\\mid\\boldsymbol{x}\\Big)}_{最大化这个}\\end{aligned}\n$$</div>\n因此等价于最大后验准则：\n<div>$$\n\\max_iP(H_i\\mid\\boldsymbol{x})\n$$</div>\n\n<p>若此时先验概率相同，则为最大似然准则。</p>\n<h2 id=\"总结知识点\"><a href=\"#总结知识点\" class=\"headerlink\" title=\"总结知识点\"></a>总结知识点</h2><h3 id=\"估计理论\"><a href=\"#估计理论\" class=\"headerlink\" title=\"估计理论\"></a>估计理论</h3><p>MAP 估计通常不能使用参数变换，变换后的参数不一定是 MAP。但是 MLE 可以。</p>\n<p>LS 方法与 BLUE 等 MVU 的衍生方法有一点不同，就是基础的 LS 没有使用协方差矩阵，但是加权的 LS 可以用协方差矩阵修正结果。</p>\n<p>贝叶斯方法和经典方法的区别在于是否把估计量的真值看作一个随机变量。它们都以“平均误差最小”为目标。</p>\n<h3 id=\"检测理论\"><a href=\"#检测理论\" class=\"headerlink\" title=\"检测理论\"></a>检测理论</h3><p>贝叶斯风险：让平均的风险最小化。</p>\n<p>未知多余参数如果影响最终的判决结果，可以用贝叶斯方法或者GLRT方法处理。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"参数估计\"><a href=\"#参数估计\" class=\"headerlink\" title=\"参数估计\"></a>参数估计</h2><p>分类：</p>\n<ul>\n<li>经典估计</li>\n<li>贝叶斯估计</li>\n</ul>\n<p>准则：</p>\n<ul>\n<li>MSE，均方误差</li>\n</ul>\n<div>$$\n\\hat \\theta = f(\\bm{x})\n$$</div>\n\n<h3 id=\"MSE\"><a href=\"#MSE\" class=\"headerlink\" title=\"MSE\"></a>MSE</h3><div>$$\n\\text{mse}(\\hat \\theta) = E \\lbrace(\\theta - \\hat \\theta)^2\\rbrace = \\text{var}(\\hat \\theta) + b^2(\\hat \\theta)\\\\\nb^2(\\hat \\theta) = E(\\hat \\theta) - \\theta\n$$</div>\n\n<p>现实中无法直接计算 MSE，因为涉及到真值 $\\theta$，但是 $\\theta$ 是我们要求的参数。</p>\n<h3 id=\"MVU\"><a href=\"#MVU\" class=\"headerlink\" title=\"MVU\"></a>MVU</h3><p>最小方差无偏估计</p>\n<p>MVU, Minimum Variance Unbiased</p>\n<p>无偏：</p>\n<div>$$\nE(\\hat \\theta) = \\theta, a \\lt \\theta \\lt b\n$$</div>\n\n<p>无偏的含义：$\\hat \\theta$ 的求法需要对取值范围内任意的 $\\theta$ 进行估计。</p>\n<p>无偏估计是否一定存在？不一定。</p>\n<p>最小方差：</p>\n<div>$$\n\\min \\text{var}\\lbrace\\hat\\theta\\rbrace\n$$</div>\n\n<p>MVU的内涵：估计值的发散程度最小（最小方差），平均意义上靠近真值（MVU）。是对 MSE 的迂回实现。</p>\n<h3 id=\"克拉美罗界定理-CRLB\"><a href=\"#克拉美罗界定理-CRLB\" class=\"headerlink\" title=\"克拉美罗界定理(CRLB)\"></a>克拉美罗界定理(CRLB)</h3><p>假设 $p(\\bm{x};\\theta)$ 满足正则条件：</p>\n<div>$$\nE \\left [ \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta} \\right] = 0\n$$</div>\n\n<p>则</p>\n<div>$$\n\\text{var}(\\hat\\theta) \\ge \\frac{1}{E \\left [\\left( \\frac{\\partial\\ln p(\\bm{x};\\theta)}{\\partial\\theta}\\right)^2 \\right]} = - \\frac{1}{E \\left [ \\frac{\\partial^2\\ln p(\\bm{x};\\theta)}{\\partial\\theta^2} \\right]}\n$$</div>\n\n<p>等号成立的充要条件：找到函数 $I, g$</p>\n<div>$$\n\\frac{\\partial \\ln p(\\bm{x};\\theta)}{\\partial \\theta}= I(\\theta)(g(\\bm{x}) - \\theta)\\\\\n\\hat \\theta = g(\\bm{x})\n$$</div>\n\n<p>此时有 $\\text{var}(\\hat\\theta) &#x3D;1 &#x2F; I(\\theta)$。</p>\n<h3 id=\"求解MVU\"><a href=\"#求解MVU\" class=\"headerlink\" title=\"求解MVU\"></a>求解MVU</h3><div>$$\n\\frac{\\partial \\ln p(\\bm{x};A)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A) = \\frac{N}{\\sigma^2}\\left (\\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)  \\right)\n$$</div>\n\n<div>$$\ng(\\bm{x}) = \\frac{1}{N}\\sum\\limits_{n=0}^{N - 1}x[n]\\\\\nI(\\theta) = \\frac{N}{\\sigma^2}\n$$</div>\n\n<p>有效估计量：能达到克拉美罗下界的估计量，是MVU的子集。</p>\n<h3 id=\"参数变换的克拉美罗界\"><a href=\"#参数变换的克拉美罗界\" class=\"headerlink\" title=\"参数变换的克拉美罗界\"></a>参数变换的克拉美罗界</h3><p>若</p>\n<div>$$\n\\alpha = g(\\theta)\n$$</div>\n\n<p>则</p>\n<div>$$\nCRLB(\\hat \\alpha) = \\left(\\frac{\\partial g(\\theta)}{\\partial \\theta}\\right)^2CRLB(\\hat \\theta)\n$$</div>\n\n<p>对于高斯分布有</p>\n<div>$$\nE(x^2) = \\mu^2 + \\sigma^2\\\\\nE(x^4) = \\mu^4 + 6\\mu^2\\sigma^2 + 3\\sigma^4\n$$</div>\n\n<p>当数据量很大时</p>\n<p>有效估计量靠近真值：$N \\rightarrow \\infty, \\hat\\theta \\rightarrow \\theta$</p>\n<p>非线性变换渐进有效,可以看成线性函数：$g(\\hat \\theta) \\approx g(\\theta) + \\frac{\\partial g(\\theta)}{\\partial\\theta}(\\hat \\theta - \\theta)$</p>\n<h3 id=\"矢量参数的克拉美罗界\"><a href=\"#矢量参数的克拉美罗界\" class=\"headerlink\" title=\"矢量参数的克拉美罗界\"></a>矢量参数的克拉美罗界</h3><div>$$\nE \\left [ \\frac{\\partial \\ln p(\\bm{x};\\bm{\\theta})}{\\partial \\bm{\\theta}} \\right] = 0\n$$</div>\n\n<div>$$\n\\alpha = g(\\theta)\n$$</div>\n\n<p><img src=\"/../images/StaSP/1_1.jpg\"></p>\n<p>注意：$\\bm T(\\bm x)$ 的维度要和 $\\bm \\theta$ 的维度相同</p>\n<h2 id=\"线性模型方法\"><a href=\"#线性模型方法\" class=\"headerlink\" title=\"线性模型方法\"></a>线性模型方法</h2><div>$$\nx = H\\theta + w, w \\sim N(0, \\sigma^2I)\n$$</div>\n\n<div>$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2}(x - H\\theta)^T(x - H\\theta) \\rbrace\n$$</div>\n\n<div>$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\theta} = \\frac{H^TH}{\\sigma^2}\\lbrace (H^TH)^{-1}H^Tx - \\theta \\rbrace\n$$</div>\n\n<p>从而</p>\n<div>$$\n\\hat \\theta = (H^TH)^{-1}H^Tx\\\\\nC_{\\hat\\theta} = \\sigma^2(H^TH)^{-1}\n$$</div>\n\n<p>这个 MVU 估计量满足</p>\n<div>$$\n\\hat \\theta \\sim N(\\theta, \\sigma^2(H^TH)^{-1})\n$$</div>\n\n<ul>\n<li>要求观测数据与待估计参数间呈线性关系</li>\n<li>要求噪声是高斯白噪声</li>\n<li>要求观测矩阵是满秩的</li>\n<li>所得估计量是有效估计量</li>\n</ul>\n<p>一般信号模型</p>\n<div>$$\nx = H\\theta + s + w, s已知，w \\sim N(0, C)\n$$</div>\n\n<p>结论</p>\n<div>$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}(x - s)\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$</div>\n\n<h2 id=\"充分统计量方法\"><a href=\"#充分统计量方法\" class=\"headerlink\" title=\"充分统计量方法\"></a>充分统计量方法</h2><div>$$\np(x|T(x);\\theta) = p(x|T(x))\n$$</div>\n\n<p>则称 $T(x)$ 为充分统计量</p>\n<p>充分统计量的性质:</p>\n<ul>\n<li>一旦充分统计量确定，似然函数就与待估计参数无关</li>\n<li>充分统计量依赖于待估计参数。待估计参数变化，其相应的充分计量一般也会变化</li>\n<li>所谓“充分”，是相对于原始观测数据而言的原始观测量总是充分统计量，但通常不是最小集</li>\n<li>充分统计量并不唯一</li>\n</ul>\n<p>若</p>\n<div>$$\n\\int_{-\\infty}^{\\infty}v(T)p(T;\\theta)\\mathrm dT = 0\n$$</div>\n\n<p>对所有的 $\\theta$ 并非都满足，只对零函数 $v(T) &#x3D; 0$ 成立，则称充分统计量是完备的。</p>\n<ul>\n<li>一般地，当待估计参数发生变化时，充分统计量也会发生变化</li>\n<li>一旦充分统计量确定以后，似然函数就与待估计参数无关</li>\n</ul>\n<h3 id=\"Neyman-Fisher因子分解定理\"><a href=\"#Neyman-Fisher因子分解定理\" class=\"headerlink\" title=\"Neyman-Fisher因子分解定理\"></a>Neyman-Fisher因子分解定理</h3><p>如果概率密度函数（或概率质量函数，对于离散随机变量）$p(x; \\theta)$ 可以被分解为</p>\n<div>$$\np(x; \\theta) = g(T(x); \\theta) \\cdot h(x)\n$$</div>\n\n<p>其中：</p>\n<ul>\n<li>$g(T(x); \\theta)$ 是一个只通过统计量 $T(x)$ 并依赖于参数 $\\theta$ 的函数。</li>\n<li>$h(x)$ 是只与观测数据 $x$ 相关的函数，与参数 $\\theta$ 无关。</li>\n</ul>\n<p>那么，统计量 $T(x)$ 是参数 $\\theta$ 的充分统计量。反之，如果 $T(x)$ 是参数 $\\theta$ 的充分统计量，那么概率密度函数 $p(x; \\theta)$ 必然可以分解为上述形式。</p>\n<h3 id=\"Rao-Black-Lehmann-Scheffe-RBLS-定理\"><a href=\"#Rao-Black-Lehmann-Scheffe-RBLS-定理\" class=\"headerlink\" title=\"Rao-Black-Lehmann-Scheffe(RBLS)定理\"></a>Rao-Black-Lehmann-Scheffe(RBLS)定理</h3><p>若 $\\breve\\theta$ 是$\\theta$的无偏估计，$T(x)$是$\\theta$的充分统计量，那么$\\hat \\theta&#x3D;E(\\breve{\\theta}|T(x))$</p>\n<ol>\n<li>是$\\theta$ 的一个适用的估计量(与$\\theta$无关)</li>\n<li>无偏的</li>\n<li>对所有的 $\\theta$，它的方差小于等于$\\breve\\theta$ 的方差</li>\n<li>若$T(x)$是完备的，那么$\\theta$是MVU估计量</li>\n</ol>\n<h4 id=\"矢量参数的-RBLS\"><a href=\"#矢量参数的-RBLS\" class=\"headerlink\" title=\"矢量参数的 RBLS\"></a>矢量参数的 RBLS</h4><p><img src=\"/../images/StaSP/2_1.jpg\"></p>\n<p><img src=\"/../images/StaSP/2_2.png\"></p>\n<h2 id=\"BLUE\"><a href=\"#BLUE\" class=\"headerlink\" title=\"BLUE\"></a>BLUE</h2><h3 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h3><p>直接求出数据-&gt;参数的映射 $\\bm A_{p \\times N}$：</p>\n<div>$$\n\\bm x = \\bm H \\theta\\\\\n\\hat {\\theta}_{p \\times 1} = \\bm A\\bm x\n$$</div>\n\n<p>无偏性：</p>\n<div>$$\n\\theta = E(\\hat\\theta) = \\bm AE(\\bm x) = \\bm AH\\theta\\\\\n\\Rightarrow AH = I_{p \\times p}\n$$</div>\n\n<p>最佳（最小方差）</p>\n<div>$$\n\\min \\lbrace a_i^TCa_i \\rbrace, A = [a_1, a_2, \\dots, a_n]^T\n$$</div>\n\n<p>其中</p>\n<div>$$\nC = E \\lbrace (x - E(x))(x - E(x))^T \\rbrace\n$$</div>\n\n<h3 id=\"高斯-马尔可夫定理\"><a href=\"#高斯-马尔可夫定理\" class=\"headerlink\" title=\"高斯-马尔可夫定理\"></a>高斯-马尔可夫定理</h3><p>如果数据具有一般线性模型的形式</p>\n<div>$$\n\\bm x = \\bm H \\theta + w\n$$</div>\n\n<p>其中 $\\bm H$ 为已知 $N \\times p$ 矩阵，$\\theta$ 为待估计参数，$w$ 是均值为零、协方差为 $\\bm C$ 的噪声矢量（<strong>不一定为高斯</strong>），则 BLUE 估计量为</p>\n<div>$$\n\\hat \\theta = (H^TC^{-1}H)^{-1}H^TC^{-1}x\\\\\nC_{\\hat\\theta} = (H^TC^{-1}H)^{-1}\n$$</div>\n\n<ul>\n<li>若为高斯噪声，则BLUE为MVU，且为有效估计量</li>\n</ul>\n<h2 id=\"MLE\"><a href=\"#MLE\" class=\"headerlink\" title=\"MLE\"></a>MLE</h2><h3 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h3><div>$$\n\\hat \\theta = \\arg\\max\\limits_\\theta p(\\bm{x};\\theta)\n$$</div>\n\n<p>如果 PDF 可导</p>\n<div>$$\n\\frac{\\partial p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\\\\\n\\Rightarrow\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} = 0\n$$</div>\n\n<p>若有效估计量存在，$\\frac{\\partial \\ln p(\\bm x; \\theta)}{\\partial \\theta}\\bigg|_{\\hat\\theta} &#x3D; I(\\theta)(g(x) - \\theta)$，则可以使用最大似然估计方法求得结果。</p>\n<h3 id=\"MLE-的性质\"><a href=\"#MLE-的性质\" class=\"headerlink\" title=\"MLE 的性质\"></a>MLE 的性质</h3><p>如果数据 $\\bm x$ 的 PDF $p(\\bm x;\\theta)$ 满足“正则”条件，那么<br>对于足够多的数据记录，未知参数 $\\theta$ 的 MLE 渐近服从</p>\n<div>$$\n\\hat\\theta \\stackrel{a}{\\sim} N(\\theta, I^{-1}\\theta)\n$$</div>\n\n<p>其中 $\\theta$ 是在未知参数真值处计算的 Fisher 信息。</p>\n<p>MLE是渐近无偏的</p>\n<p>MLE渐近达到CRLB</p>\n<p>MLE是渐近有效的</p>\n<p>MLE是渐近最佳的</p>\n<ul>\n<li>MLE的方差（协方差）可大于、等于、小于CRLB！（不同于MVU估计）</li>\n<li>但数据量足够多时，将与CRLB接近</li>\n<li>因此，可利用CRLB评估MLE的性能</li>\n</ul>\n<p>“足够多”数据：大量能带来新信息的数据</p>\n<p><strong>MLE的不变性</strong></p>\n<p>若参数 $\\alpha &#x3D; g(\\theta)$，则</p>\n<div>$$\n\\hat\\alpha = g(\\hat\\theta)\n$$</div>\n\n<p>若 $g$ 非一对一函数，那么 $\\hat\\alpha$ 是使修正后的似然函数 $p_T(\\bm x;\\alpha)$ 最大者</p>\n<div>$$\n\\hat\\alpha = \\arg\\max_\\alpha p_T(\\bm x; \\alpha)\\\\\np_T(\\bm x; \\alpha) = \\max_{\\theta: \\alpha=g(\\theta)}p(\\bm x; \\theta)\n$$</div>\n\n<p>该性质对函数 $g$ 无线性变换要求，对任意函数均成立。</p>\n<p>对比MVU</p>\n<ul>\n<li>无偏性、有效性仅对线性变换成立</li>\n<li>对非线性变换不能保持（但渐近无偏、渐近有效）</li>\n</ul>\n<p>对一般线性模型，MLE是MVU，达到了CRLB，是有效的、最佳的！</p>\n<p><img src=\"/../images/StaSP/1711254850893.png\" alt=\"1711254850893\"></p>\n<h2 id=\"最小二乘估计-LS\"><a href=\"#最小二乘估计-LS\" class=\"headerlink\" title=\"最小二乘估计(LS)\"></a>最小二乘估计(LS)</h2><h3 id=\"线性最小二乘估计\"><a href=\"#线性最小二乘估计\" class=\"headerlink\" title=\"线性最小二乘估计\"></a>线性最小二乘估计</h3><p><img src=\"/../images/StaSP/1711339154789.png\" alt=\"1711339154789\"></p>\n<h3 id=\"加权最小二乘估计\"><a href=\"#加权最小二乘估计\" class=\"headerlink\" title=\"加权最小二乘估计\"></a>加权最小二乘估计</h3><p><img src=\"/../images/StaSP/1711339192281.png\" alt=\"1711339192281\"></p>\n<h3 id=\"约束最小二乘估计\"><a href=\"#约束最小二乘估计\" class=\"headerlink\" title=\"约束最小二乘估计\"></a>约束最小二乘估计</h3><p><img src=\"/../images/StaSP/1711339216759.png\" alt=\"1711339216759\"></p>\n<h3 id=\"比较\"><a href=\"#比较\" class=\"headerlink\" title=\"比较\"></a>比较</h3><p><img src=\"/../images/StaSP/1711339249863.png\" alt=\"1711339249863\"></p>\n<h2 id=\"经典估计方法比较\"><a href=\"#经典估计方法比较\" class=\"headerlink\" title=\"经典估计方法比较\"></a>经典估计方法比较</h2><h3 id=\"噪声电平估计问题\"><a href=\"#噪声电平估计问题\" class=\"headerlink\" title=\"噪声电平估计问题\"></a>噪声电平估计问题</h3><div>$$\nx[n] = A + w[n]\n$$</div>\n\n<p>其中 $w[n] \\sim N(0, \\sigma^2)$，待估计参数 $\\theta &#x3D; [A, \\sigma^2]^T$</p>\n<h4 id=\"MVU估计\"><a href=\"#MVU估计\" class=\"headerlink\" title=\"MVU估计\"></a>MVU估计</h4><div>$$\np(x;\\theta) = \\frac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\lbrace -\\frac{1}{2\\sigma^2} \\sum\\limits_{n=0}^{N - 1}(x[n] - A)^2\\rbrace\n$$</div>\n\n<div>$$\n\\frac{\\partial \\ln p (x;\\theta)}{\\partial A} = \\frac{1}{\\sigma^2}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$</div>\n\n<div>$$\n\\frac{\\partial \\ln p(x;\\theta)}{\\partial \\sigma^2} = \\frac{N}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum\\limits_{n=0}^{N - 1}(x[n] - A)\n$$</div>\n\n<p><img src=\"/../images/StaSP/1711339773571.png\" alt=\"1711339773571\"></p>\n<p><img src=\"/../images/StaSP/1711339786814.png\" alt=\"1711339786814\"></p>\n<h4 id=\"线性模型\"><a href=\"#线性模型\" class=\"headerlink\" title=\"线性模型\"></a>线性模型</h4><div>$$\n\\hat\\theta = (\\bm H^T\\bm H)^{-1}\\bm  H^T x\n$$</div>\n\n<p><img src=\"/../images/StaSP/1711339831807.png\" alt=\"1711339831807\"></p>\n<h4 id=\"BLUE-1\"><a href=\"#BLUE-1\" class=\"headerlink\" title=\"BLUE\"></a>BLUE</h4><div>$$\n\\hat\\theta = (\\bm H^T\\bm C^{-1}\\bm H)^{-1}\\bm  H^T\\bm C^{-1} x\n$$</div>\n\n<p><img src=\"/../images/StaSP/1711339865703.png\" alt=\"1711339865703\"></p>\n<h4 id=\"充分统计量\"><a href=\"#充分统计量\" class=\"headerlink\" title=\"充分统计量\"></a>充分统计量</h4><p><img src=\"/../images/StaSP/1711340151724.png\" alt=\"1711340151724\"></p>\n<p><img src=\"/../images/StaSP/1711340163113.png\" alt=\"1711340163113\"></p>\n<p><img src=\"/../images/StaSP/1711340177961.png\" alt=\"1711340177961\"></p>\n<h4 id=\"MLE-1\"><a href=\"#MLE-1\" class=\"headerlink\" title=\"MLE\"></a>MLE</h4><p><img src=\"/../images/StaSP/1711340277148.png\" alt=\"1711340277148\"></p>\n<h4 id=\"LSE\"><a href=\"#LSE\" class=\"headerlink\" title=\"LSE\"></a>LSE</h4><p><img src=\"/../images/StaSP/1711340293644.png\" alt=\"1711340293644\"></p>\n<h2 id=\"贝叶斯估计\"><a href=\"#贝叶斯估计\" class=\"headerlink\" title=\"贝叶斯估计\"></a>贝叶斯估计</h2><p>贝叶斯MSE：<br>Bmse$\\left(\\hat{\\theta}\\right)&#x3D;E\\left(\\left(\\theta-\\hat{\\theta}\\right)^2\\right)$</p>\n<p>$&#x3D;\\int\\int\\left(\\theta-\\hat{\\theta}\\right)^{2}p\\big(\\mathbf{x},\\theta\\big)d\\mathbf{x}d\\theta$ $&#x3D;\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p\\big(\\boldsymbol{x}|\\theta\\big)p\\big(\\theta\\big)d\\boldsymbol{x}d\\theta$<br> $&#x3D;\\iint\\left(\\theta-\\hat{\\theta}\\right)^2p(x|\\theta)dxp(\\theta)d\\theta$</p>\n<p>$\\hat{\\theta}&#x3D;E\\big(\\theta|x\\big)$</p>\n<p>多余参数：未知，但不感兴趣的参数<br> 解决思路：通过积分消除多余参数的影响<br> (1) 后验概率中存多余参数时：</p>\n<div>$$\np(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x}) \\Rightarrow p (\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\int p(\\boldsymbol{\\theta},\\boldsymbol{\\alpha}\\mid\\boldsymbol{x})\\:d\\boldsymbol{\\alpha}\n$$</div>\n\n<p>(2) 条件概率中存在多余参数时：</p>\n<div>$$\np(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})=\\frac{p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{\\int p(\\boldsymbol{x}\\mid\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})d\\boldsymbol{\\theta}}\n$$</div>\n\n<div>$$\n\\text{若现只有 }p(x|\\theta,\\alpha)\\text{,而无 }p(x|\\theta)\n$$</div>\n 此时可通过积分方式解决\n\n<div>$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha\\mid\\theta)d\\alpha \n$$</div>\n\n<p>进一步地，若待估计参数与多余参数相互独立，</p>\n<div>$$\np(x\\mid\\theta)=\\int p(x\\mid\\theta,\\alpha)p(\\alpha)d\\alpha \n$$</div>\n\n<p>矢量参数下贝叶斯估计<br>若 θ 是 $p{\\times}1$ 的矢量参数，那么为了估计其中某个参数 $\\theta_i$, 可以将剩余参数当作多余参数，因此对$\\theta_i$ 的MMSE为</p>\n<div>$$\n\\hat{\\theta}_i=E\\left(\\theta_i\\mid x\\right)=\\int\\theta_ip(\\theta_i\\mid x)d\\theta_i\n$$</div>\n 其中\n\n<div>$$\np(\\theta_i\\mid x)=\\int\\cdots\\int p(\\theta\\mid x)d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p\n$$</div>\n\n<div>$$\n\\hat{\\theta}_i=\\int\\theta_i\\left(\\int\\cdots\\int p(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})\\underline{d\\theta_1\\cdots d\\theta_{i-1}d\\theta_{i+1}\\cdots d\\theta_p}\\right)d\\theta_i=\\int\\theta_ip(\\boldsymbol{\\theta}\\mid\\boldsymbol{x})d\\boldsymbol{\\theta}\n$$</div>\n\n<div>$$\n\\Longrightarrow\\hat{\\theta}=\\begin{bmatrix}\\theta_1p(\\theta|x)d\\theta\\\\\\int\\theta_2p(\\theta|x)d\\theta\\\\\\vdots\\\\\\int\\theta_pp(\\theta|x)d\\theta\\end{bmatrix}=\\int\\theta_P(\\theta|x)d\\theta=E(\\theta|x)\n$$</div>\n\n<p>Woodbury 恒等式：</p>\n<div>$$\n\\left(\\mathbf{B}+\\boldsymbol{u}\\boldsymbol{u}^T\\right)^{-1}=\\mathbf{B}^{-1}-\\frac{\\mathbf{B}^{-1}\\boldsymbol{u}\\boldsymbol{u}^T\\mathbf{B}^{-1}}{1+\\boldsymbol{u}^T\\mathbf{B}^{-1}\\boldsymbol{u}}\n$$</div>\n\n<h3 id=\"贝叶斯风险\"><a href=\"#贝叶斯风险\" class=\"headerlink\" title=\"贝叶斯风险\"></a>贝叶斯风险</h3><div>$$\n\\Re=\\iint C(\\varepsilon)p(x,\\theta)dxd\\theta \n$$</div>\n\n<h4 id=\"二次型误差\"><a href=\"#二次型误差\" class=\"headerlink\" title=\"二次型误差\"></a>二次型误差</h4><div>$$\nC(\\varepsilon) = \\begin{pmatrix}\\theta-\\hat{\\theta}\\end{pmatrix}^2\n$$</div>\n\n<p>这就是 MMSE</p>\n<p>此时为平均值。</p>\n<h4 id=\"绝对误差\"><a href=\"#绝对误差\" class=\"headerlink\" title=\"绝对误差\"></a>绝对误差</h4><div>$$\nC(\\varepsilon)=\\begin{vmatrix}\\theta-\\hat{\\theta}\\end{vmatrix}\n$$</div>\n\n<blockquote>\n<p>Leibnitz 准则<br>$\\frac{\\partial}{\\partial u}\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}h\\big(u,v\\big)dv&#x3D;\\int\\limits_{\\phi_1(u)}^{\\phi_2(u)}\\frac{\\partial h\\big(u,v\\big)}{\\partial u}dv+\\frac{\\partial\\phi_2\\big(u\\big)}{\\partial u}h\\big(u,\\phi_2\\big(u\\big)\\big)-\\frac{\\partial\\phi_1\\big(u\\big)}{\\partial u}h\\big(u,\\phi_1\\big(u\\big))$</p>\n</blockquote>\n<p>此时</p>\n<div>$$\n\\int_{-\\infty}^{\\hat{\\theta}}p\\big(\\theta|x\\big)d\\theta=\\int_{\\hat{\\theta}}^{+\\infty}p\\big(\\theta|x\\big)d\\theta \n$$</div>\n\n<p>为中位数</p>\n<h4 id=\"成功失败型误差\"><a href=\"#成功失败型误差\" class=\"headerlink\" title=\"成功失败型误差\"></a>成功失败型误差</h4><div>$$\nC(\\varepsilon)=\\begin{cases}0,\\left|\\theta-\\hat{\\theta}\\right|<\\delta\\\\1,\\left|\\theta-\\hat{\\theta}\\right|\\geq\\delta\\end{cases}\n$$</div>\n\n<p>此时 </p>\n<div>$$\n\\hat{\\theta}=\\arg\\max_{\\theta}p(\\theta|x)\n$$</div>\n\n<p>即 $\\hat{\\theta}$ 是后验PDF的最大值 (众数) </p>\n<p>MAP maximum a posteriori</p>\n<p>根据贝叶斯公式</p>\n<div>$$\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\lbracep(x|\\theta)p(\\theta)\\right\\rbrace\\\\\n\\hat{\\theta}=\\arg\\max_{\\theta}\\left\\{\\ln p\\big(x|\\theta\\big)+\\ln p\\big(\\theta\\big)\\right\\}\n$$</div>\n\n<h4 id=\"三值比较\"><a href=\"#三值比较\" class=\"headerlink\" title=\"三值比较\"></a>三值比较</h4><p>一般而言，“三值”并不相等，因此三种估计量往往不同</p>\n<p>特例：高斯时“三值”相等，三种估计方法等价</p>\n<p>大数据量时先验信息不起作用，最大后验概率估计（MAP）将转变为（贝叶斯）最大似然估计（MLE）</p>\n<h3 id=\"线性贝叶斯估计\"><a href=\"#线性贝叶斯估计\" class=\"headerlink\" title=\"线性贝叶斯估计\"></a>线性贝叶斯估计</h3><p>线性贝叶斯估计(LMMSE), 也称线性最小意味着：</p>\n<div>$$\n\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$</div>\n\n<p>即限定估计量与观察数据间呈线性关系，然最小化 </p>\n<div>$$\n\\mathrm{Bmse}\\Big(\\hat{\\theta}\\Big)=E\\Big[\\Big(\\theta-\\hat{\\theta}\\Big)^{2}\\Big]\n$$</div>\n\n<p>即，LMMSE:</p>\n<div>$$\n\\min\\left\\{E\\left[\\left(\\theta-\\hat{\\theta}\\right)^2\\right]\\right\\}\\\\s.t.\\quad\\hat{\\theta}=\\sum_{n=0}^{N-1}a_nx[n]+a_N\n$$</div>\n\n<p>解得估计量：</p>\n<div>$$\n\\hat{\\theta}=E\\left(\\theta\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(x-E\\left(x\\right)\\right)\\\\\\mathrm{Bmse}\\left(\\hat{\\theta}\\right)=\\mathbf{C}_{\\theta\\theta}-\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\mathbf{C}_{x\\theta}\n$$</div>\n\n<p>对比 MMSE：</p>\n<p>附加了线性约束</p>\n<ul>\n<li>可得显示解——好求</li>\n<li>仅需一阶矩和二阶矩</li>\n</ul>\n<p>无附加约束</p>\n<ul>\n<li>可能难以求得显示解</li>\n<li>需PDF</li>\n<li>全局最优</li>\n<li>仅在“线性”中最优</li>\n</ul>\n<h4 id=\"矢量参数情况\"><a href=\"#矢量参数情况\" class=\"headerlink\" title=\"矢量参数情况\"></a>矢量参数情况</h4><p>待估计参数$\\boldsymbol{\\theta}&#x3D;\\begin{bmatrix}\\theta_1,\\theta_2,…,\\theta_p\\end{bmatrix}^T$,其每个参数的 LMMSE 定义为</p>\n<div>$$\n\\begin{aligned}&\\min E\\bigg[\\bigg(\\theta_{i}-\\hat{\\theta}_{i}\\bigg)^{2}\\bigg]\\\\&s.t.\\hat{\\theta}_{i}=\\sum_{n=0}^{N-1}a_{in}x[n]+a_{iN}\\end{aligned}\n$$</div>\n\n<div>$$\n\\hat{\\boldsymbol{\\theta}}=\\begin{bmatrix}E(\\theta_1)\\\\E(\\theta_2)\\\\\\vdots\\\\E(\\theta_p)\\end{bmatrix}+\\begin{bmatrix}\\mathbf{C}_{\\theta_1x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\mathbf{C}_{\\theta_2x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\\\\\vdots\\\\\\mathbf{C}_{\\theta_px}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E(\\boldsymbol{x})\\right)\\end{bmatrix}\\\\\n=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x} - E(\\boldsymbol{x})\\right)\n$$</div>\n\n<h3 id=\"序贯LMMSE\"><a href=\"#序贯LMMSE\" class=\"headerlink\" title=\"序贯LMMSE\"></a>序贯LMMSE</h3><p>白噪声电平估计</p>\n<div>$$\nx[n]=A+w[n],n=0,1,...,N\n$$</div>\n\n<div>$$\nA\\sim N\\big(0,\\sigma_{A}^{2}\\big)\\\\\nw[n]\\sim N\\left(0,\\sigma^{2}\\right)\n$$</div>\n\n<p>解得</p>\n<div>$$\n\\begin{aligned}\n&E(\\theta)=0 \\\\\n&\\mathbf{C}_{\\theta x}=E\\left(\\left(\\theta-E\\left(\\theta\\right)\\right)\\left(x-E\\left(x\\right)\\right)^{T}\\right) \\\\\n&=E\\left(\\left(A-0\\right)\\left(x-0\\right)^{T}\\right) \\\\\n&=E\\Big(A\\big(A\\mathbf{1}+\\mathbf{w}\\big)^{T}\\Big) \\\\\n&=\\sigma_{A}^{2}\\mathbf{1}^{T}\n\\end{aligned}\\\\\n\\begin{aligned}\n\\mathbf{C}_{xx}& =E\\left(\\left(x-E\\left(x\\right)\\right)\\left(x-E\\left(x\\right)\\right)^T\\right)  \\\\\n&=E\\left(\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)\\left(A\\mathbf{1}+\\boldsymbol{w}\\right)^T\\right) \\\\\n&=E\\left\\{A\\mathbf{1}\\mathbf{1}^TA+A\\mathbf{1}\\boldsymbol{w}^T+\\boldsymbol{w}\\mathbf{1}^TA+\\boldsymbol{w}\\boldsymbol{w}^T\\right\\} \\\\\n&=\\sigma_A^2\\mathbf{1}\\mathbf{1}^T+\\sigma^2\\mathbf{I}\n\\end{aligned}\\\\\n\\begin{aligned}\\mathbf{C}_{\\theta\\theta}&=\\sigma_A^2\\\\\\mathbf{C}_{x\\theta}&=\\mathbf{C}_{\\theta x}^T\\\\&=\\sigma_A^2\\mathbf{1}\\end{aligned}\n$$</div>\n\n<div>$$\n\\begin{aligned}\\hat{A}&=\\frac{\\sigma_{A}^{2}}{\\sigma_{A}^{2}+\\frac{\\sigma^{2}}{N}}\\\\\\mathrm{Bmse}&\\left(\\hat{A}\\right)=\\frac{1}{N}\\end{aligned}\n$$</div>\n\n<p>记</p>\n<div>$$\n\\hat{A}[N-1]=\\frac{\\sigma_A^2}{\\sigma_A^2+\\frac{\\sigma^2}{N}}\\frac{1}{N}\\sum_{n=0}^{N-1}x[n]\n$$</div>\n\n<p>则</p>\n<div>$$\n\\hat{A}[N]=\\hat{A}[N-1]+\\underbrace{\\frac{\\sigma_A^2}{\\left(N+1\\right)\\sigma_A^2+\\sigma^2}}_{K[N]，增益因子}\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$</div>\n\n<div>$$\n\\frac{\\frac1{\\sigma^2}}{\\frac1{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}+\\frac1{\\sigma^2}}=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\\\\=\\frac{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}}{\\frac{\\sigma_A^2\\sigma^2}{N\\sigma_A^2+\\sigma^2}+\\sigma^2}=\\frac{\\sigma_A^2}{\\left(N\\sigma_A^2+\\sigma^2\\right)+\\sigma_A^2}=K\\begin{bmatrix}N\\end{bmatrix}\n$$</div>\n\n<p>一般方法</p>\n<p>序贯计算方法估计量更新：</p>\n<div>$$\n\\hat{A}[N]=\\hat{A}[N-1]+K[N]\\Big(x[N]-\\hat{A}[N-1]\\Big)\n$$</div>\n\n<p>增益因子：</p>\n<div>$$\nK\\left[N\\right]=\\frac{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)}{\\mathrm{Bmse}\\left(\\hat{A}\\left[N-1\\right]\\right)+\\sigma^2}\n$$</div>\n\n<p>最小贝叶斯MSE更新：</p>\n<div>$$\n\\mathrm{Bmse}\\Big(\\hat{A}[N]\\Big)\\boldsymbol{=}\\Big(1\\boldsymbol{-}K[N]\\Big)\\mathrm{Bmse}\\Big(\\hat{A}[N\\boldsymbol{-}1]\\Big)\n$$</div>\n\n<p>初始化：</p>\n<div>$$\n\\hat{A}[-1]=E(A)\\\\\n\\text{Bmse}\\left ( \\hat{A} [ - 1] \\right ) = \\text{var}\\left ( A\\right ) \n$$</div>\n\n<h2 id=\"维纳滤波\"><a href=\"#维纳滤波\" class=\"headerlink\" title=\"维纳滤波\"></a>维纳滤波</h2><h3 id=\"滤波\"><a href=\"#滤波\" class=\"headerlink\" title=\"滤波\"></a>滤波</h3><p>假定观测数据是零均值、宽平稳的，信号也是零均值、宽平稳的，信号与噪声不相关</p>\n<div>$$\nx[n] = s[n] + w[n], n = 0, 1, \\dots, N - 1\n$$</div>\n\n<div>$$\n\\theta=s[n]\\text{ 用 }x[0],x[1],x[2],...,x[n]\\text{来估计}$$</div>\n\n<p><img src=\"/../images/StaSP/1713150769252.png\" alt=\"1713150769252\"></p>\n<p>利用 LMMSE 可得</p>\n<div>$$\n\\hat{s}[n]=r_{ss}^{'T}\\left(\\mathbf{R}_{ss}+\\mathbf{R}_{ww}\\right)^{-1}\\boldsymbol{x}\n$$</div>\n从而得到维纳-霍夫滤波方程\n<div>$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}n\\end{bmatrix}&r_{xx}\\begin{bmatrix}n-1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h^{(n)}\\begin{bmatrix}0\\end{bmatrix}\\\\h^{(n)}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\h^{(n)}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{ss}\\begin{bmatrix}0\\end{bmatrix}\\\\r_{ss}\\begin{bmatrix}1\\end{bmatrix}\\\\\\vdots\\\\r_{ss}\\begin{bmatrix}n\\end{bmatrix}\\end{bmatrix}\n$$</div>\n### 平滑\n<div>$$\n\\theta=s[n]\\text{用 }...,x[-1],x[0],x[1],x[2],...,\\text{来估计}\n$$</div>\n![1713152016025](../images/StaSP/1713152016025.png)\n\n<p>LMMSE:</p>\n<div>$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$</div>\n令 $h[k] = a_{N-k}$\n\n<blockquote>\n<p>正交原理：误差与每一个观测数据正交</p>\n<div>$$\nE\\left(\\left(\\theta-\\hat{\\theta}\\right)x[m]\\right)=0\n$$</div>\n正交原理不依赖于任务是平滑、滤波还是预测，是普遍适用的，证明如下：\n![1713152987612](../images/StaSP/1713152987612.png)\n![1713152970273](../images/StaSP/1713152970273.png)\n在 LMMSE\n</blockquote>\n<div>$$\n\\hat{s}[n]=\\sum_{k=-\\infty}^\\infty a_kx[k]\n$$</div>\n中令 $h[k]=a_{n-k}$\n\n<p>则有</p>\n<div>$$\n\\hat s[n] = \\sum\\limits_{k=-\\infty}^{\\infty}h[k]x[n-k]\n$$</div>\n可得\n<div>$$\nr_{ss}\\begin{bmatrix}n\\end{bmatrix}=h\\begin{bmatrix}n\\end{bmatrix}*r_{xx}\\begin{bmatrix}n\\end{bmatrix}\n$$</div>\n无限维纳平滑器的频率响应\n<div>$$\nH\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{xx}\\left(f\\right)}\\quad=\\frac{P_{ss}\\left(f\\right)}{P_{ss}\\left(f\\right)+P_{ww}\\left(f\\right)}\\quad=\\frac{\\eta\\left(f\\right)}{\\eta\\left(f\\right)+1}\\quad\\text{,其中 }\\eta\\left(f\\right)=\\frac{P_{ss}\\left(f\\right)}{P_{ww}\\left(f\\right)}\n$$</div>\n### 预测\n\n<p>可以用来进行预测</p>\n<div>$$\n\\theta=x[N-1+l]\\text{ 用 }x[0],x[1],x[2],...,x[N-1]\\text{ 来估计}\n$$</div>\n![1713150674892](../images/StaSP/1713150674892.png)\n\n<p>依然用 LMMSE 可以得到线性预测维纳-霍夫滤波方程</p>\n<div>$$\n\\begin{bmatrix}r_{xx}\\begin{bmatrix}0\\end{bmatrix}&r_{xx}\\begin{bmatrix}1\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}1\\end{bmatrix}&r_{xx}\\begin{bmatrix}0\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\r_{xx}\\begin{bmatrix}N-1\\end{bmatrix}&r_{xx}\\begin{bmatrix}N-2\\end{bmatrix}&\\cdots&r_{xx}\\begin{bmatrix}0\\end{bmatrix}\\end{bmatrix}\\begin{bmatrix}h\\begin{bmatrix}1\\end{bmatrix}\\\\h\\begin{bmatrix}2\\end{bmatrix}\\\\\\vdots\\\\h\\begin{bmatrix}N\\end{bmatrix}\\end{bmatrix}=\\begin{bmatrix}r_{xx}\\begin{bmatrix}l\\end{bmatrix}\\\\r_{xx}\\begin{bmatrix}l+1\\end{bmatrix}\\\\\\vdots\\\\r_{xx}\\begin{bmatrix}N-1+l\\end{bmatrix}\\end{bmatrix}\n$$</div>\n### 应用\n\n<p>信道均衡问题</p>\n<p><img src=\"/../images/StaSP/1713151589324.png\" alt=\"1713151589324\"></p>\n<h2 id=\"卡尔曼滤波\"><a href=\"#卡尔曼滤波\" class=\"headerlink\" title=\"卡尔曼滤波\"></a>卡尔曼滤波</h2><p>如何估计电压？</p>\n<h3 id=\"模型-1：当成确定参数\"><a href=\"#模型-1：当成确定参数\" class=\"headerlink\" title=\"模型 1：当成确定参数\"></a>模型 1：当成确定参数</h3><div>$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2})\n$$</div>\n\n<div>$$\n\\hat A = \\sum\\limits_{n=0}^{N - 1}x[n] = \\bar x\n$$</div>\n### 模型2：当成某个随机变量\n<div>$$\nx[n] = A + w[n], w[n] \\sim N(0, \\sigma^{2}), A \\sim N(\\mu_A, \\sigma_A^{2})\n$$</div>\n贝叶斯一般线性模型：\n<div>$$\n\\boldsymbol{x}=\\mathbf{H}\\boldsymbol{\\theta}+\\boldsymbol{w}\\quad\\text{其中 }\\boldsymbol{\\theta}{\\sim}N\\begin{pmatrix}\\boldsymbol{\\mu}_\\theta,\\mathbf{C}_\\theta\\end{pmatrix}\\text{,}\\boldsymbol{w}{\\sim}N\\begin{pmatrix}\\boldsymbol{0},\\mathbf{C}_w\\end{pmatrix}\\\\\nE\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x}\\mathbf{C}_{xx}^{-1}\\left(\\boldsymbol{x}-E\\left(\\boldsymbol{x}\\right)\\right)=\\boldsymbol{\\mu}_\\theta+\\mathbf{C}_{\\theta|x}\\mathbf{H}^T\\mathbf{C}_w^{-1}\\left(\\boldsymbol{x}-\\mathbf{H}\\boldsymbol{\\mu}_\\theta\\right)\\\\\n\\text{其中,}\\mathbf{C}_{\\theta|x}=\\left(\\mathbf{C}_\\theta^{-1}+\\mathbf{H}^T\\mathbf{C}_w^{-1}\\mathbf{H}\\right)^{-1}\n$$</div>\n\n<div>$$\n\\hat{A}=\\mu_A+\\frac{\\frac1{\\sigma^2/N}}{\\frac1{\\sigma_A^2}+\\frac1{\\sigma^2/N}}(\\overline{x}-\\mu_A)\n$$</div>\n### 模型3：当成未知且随时间变化的量\n<div>$$\nx[n]=A[n]+w[n],n=0,1,...,N-1\n$$</div>\n\n<div>$$\n\\mathrm{MVU}\\text{估计量:}\\hat{\\boldsymbol{\\theta}}=\\left(\\mathbf{H}^T\\mathbf{H}\\right)^{-1}\\mathbf{H}^T\\boldsymbol{x}\\\\\n\\begin{aligned}&\\boldsymbol{\\theta}=&\\begin{bmatrix}A[0],A[1],...,A[N-1]\\end{bmatrix}^T\\\\&\\mathbf{H}=\\mathbf{I}\\end{aligned}\\\\\n\\hat{A}[n]=x[n]\n$$</div>\n### 动态信号模型\n\n<p>一阶高斯-马尔可夫信号模型：</p>\n<div>$$\ns[n]=as[n-1]+u[n],n\\geq0\n$$</div>\n其中，$u[n]$是均值为零方差为 $\\sigma_u^2$ 的高斯白噪声，称为驱动噪声或激励噪声。信号初值s$[-1]\\sim N(\\mu_s,\\sigma_s^2)$与激励噪声$u[n]$相互独立。\n\n<p>均值：</p>\n<div>$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\\\\nE\\left(s[n]\\right)=a^{n+1}E\\left(s[-1]\\right)+\\sum_{k=0}^na^kE\\left(u[n-k]\\right)=a^{n+1}\\mu_s\\\\\nc_s[m,n] = a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^m\\sum_{l=0}^na^{k+l}E\\left(u[m-k]u[n-l]\\right)\\\\\nE\\left(u[m-k]u[n-l]\\right)=\\begin{cases}\\sigma_u^2,&l=n-m+k\\\\0,&\\mathrm{others}\\end{cases}\n$$</div>\n协方差：\n<div>$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m+n+2}\\sigma_s^2+\\sum_{k=m-n}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\\\\nm \\lt n, c_s\\begin{bmatrix}m,n\\end{bmatrix}=a^{m+n+2}\\sigma_s^2+\\sum_{k=0}^ma^{2k+n-m}\\sigma_u^2=a^{m+n+2}\\sigma_s^2+\\sigma_u^2a^{n-m}\\sum_{k=0}^ma^{2k}=c_s\\begin{bmatrix}n,m\\end{bmatrix}\n$$</div>\n方差和二阶矩：\n<div>$$\n\\begin{aligned}\n\\operatorname{var}(s[n])& =E\\left(\\left(s[n]-E\\left(s[n]\\right)\\right)\\left(s[n]-E\\left(s[n]\\right)\\right)\\right)  \\\\\n&=c_s[n,n] \\\\\n&=a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\n\\end{aligned}\\\\\n\\text{当 }m\\geq n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{m-n}\\sum_{k=0}^{n}a^{2k}\\\\\\text{当 }m<n\\text{ 时}\\\\r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_{s}^{2}+\\sigma_{s}^{2}\\right)+\\sigma_{u}^{2}a^{n-m}\\sum^{m}a^{2k}=r_{ss}\\left[n,m\\right]\n$$</div>\n#### 平稳性\n<div>$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=a^{n+1}\\mu_s\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\sum_{k=0}^na^{2k}\\end{aligned}\n$$</div>\n不是宽平稳的。\n\n<p>通常要求 $|a| \\lt 1$，当取 $n \\rarr \\infty$ 时</p>\n<div>$$\n\\begin{aligned}&E\\left(s\\left[n\\right]\\right)=0\\\\&r_{ss}\\left[m,n\\right]=a^{m+n+2}\\left(\\mu_s^2+\\sigma_s^2\\right)+\\sigma_u^2a^{m-n}\\frac{1-a^{2n+2}}{1-a^2}=\\frac{\\sigma_u^2a^{m-n}}{1-a^2}=r_{ss}\\left[k\\right]\\end{aligned}\n$$</div>\n此时是宽平稳（WSS）的。\n\n<h4 id=\"递推特性\"><a href=\"#递推特性\" class=\"headerlink\" title=\"递推特性\"></a>递推特性</h4><div>$$\nE\\left(s[n]\\right)=aE\\left(s[n-1]\\right)+E\\left(u[n]\\right)=aE\\left(s[n-1]\\right)\n$$</div>\n\n<div>$$\n\\operatorname{var}\\left(s[n]\\right)=E\\left(\\left(s[n]-E(s[n])\\right)\\left(s[n]-E(s[n])\\right)\\right) = a^2\\operatorname{var}\\left(s[n-1]\\right)+\\sigma_u^2\n$$</div>\n\n<div>$$\nm \\ge n, c_s\\left[m,n\\right]=a^{m-n}\\operatorname{var}\\left(s[n]\\right) = a^{m-n}\\left(a^{2n+2}\\sigma_s^2+\\sigma_u^2\\sum_{k=0}^na^{2k}\\right)\\\\\nm \\le n, c_s\\left[m,n\\right]=c_s\\left[n,m\\right]=a^{n-m}\\operatorname{var}\\left(s\\left[m\\right]\\right)\n$$</div>\n### 卡尔曼滤波\n\n<p>状态方程：$s[n]&#x3D;as\\left[n-1\\right]+u\\left[n\\right]$</p>\n<p>观测方程：$x[n]&#x3D;s\\left[n\\right]+w[n]$</p>\n<p>驱动噪声 $u[n]$ 相互独立且 $u[n] \\sim N(0, \\sigma^2)$，观测噪声 $w[n]$ 相互独立且 $w[n] \\sim N(0, \\sigma^2)$，起始条件 $s[-1] \\sim N(0, \\sigma_s^2)$。假定 $s[-1], u[n], w[n]$ 之间相互独立。</p>\n<ul>\n<li>提高估计性能：利用待估计参数的内在联系提高性能</li>\n<li>减小运算量：通过“老”估计量更新得到“新”估计量</li>\n</ul>\n<p>性质：</p>\n<p>对联合高斯独立数据矢量可加性：</p>\n<p>若$\\theta,x_1,x_2$是联合高斯的，数据矢量$x_1,x_2$ 相互独立，则MMSE估计量为：</p>\n<div>$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\right)+\\mathbf{C}_{\\theta x_1}\\mathbf{C}_{x_1x_1}^{-1}\\left(\\boldsymbol{x}_1-E\\left(\\boldsymbol{x}_1\\right)\\right)+\\mathbf{C}_{\\theta x_2}\\mathbf{C}_{x_2x_2}^{-1}\\left(\\boldsymbol{x}_2-E\\left(\\boldsymbol{x}_2\\right)\\right)\n$$</div>\n对待估计参数的可加性：\n\n<p>若 $\\boldsymbol{\\theta}&#x3D;\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2$, 则相应的MMSE估计量是可加的，即</p>\n<div>$$\n\\hat{\\theta}=E\\left(\\boldsymbol{\\theta}\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1+\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)=E\\left(\\boldsymbol{\\theta}_1\\mid\\boldsymbol{x}\\right)+E\\left(\\boldsymbol{\\theta}_2\\mid\\boldsymbol{x}\\right)\n$$</div>\n线性变换的不变性：\n\n<p>若$\\alpha&#x3D;\\mathbf{A\\theta}+\\boldsymbol{b},\\quad\\theta$ 的MMSE估计量是 $\\theta$, 则 $\\alpha$ 的MMSE估计量为：</p>\n<div>$$\n\\hat{\\alpha}=\\mathbf{A}\\hat{\\theta}+b\n$$</div>\n定义：\n<div>$$\n\\hat{s}[n-1]=E\\left(s[n-1]|x[0],x[1],...,x[n-1]\\right)\\triangleq\\hat{s}[n-1\\mid n-1]\\\\\nM\\begin{bmatrix}n-1\\end{bmatrix}=E\\left(\\left(s\\begin{bmatrix}n-1\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n-1\\end{bmatrix}\\right)^2\\right)\\\\\n\\hat s[n] \\triangleq\\hat{s}[n\\mid n]\n$$</div>\n其中，前面的 n 表示被估计的信号下表，后面的 n 表示估计量用到的数据中最新的那个数据的下标。\n\n<p>如果能够提取出第 n 个数据点带来的新的信息，并加入之前已有的估计量，就可更新估计量：</p>\n<div>$$\n\\begin{aligned}\n\\hat{s}\\Big[n|n\\Big]& =E\\left(s[n]|x[0],x[1],...,x[n-1],x[n]\\right)  \\\\\n&=E\\left(s[n]|x[0],x[1],...,x[n-1],\\tilde{x}[n]\\right) \\\\\n&=\\underbrace{E\\left(s[n]|x[0],x[1],...,x[n-1]\\right)}_{先前数据估计}+\\underbrace{E\\left(s[n]|\\tilde{x}[n]\\right)}_{新息估计}\n\\end{aligned}\n$$</div>\n新息与已有的数据正交。\n<div>$$\n\\tilde{x}[n]=x[n]-\\hat{x}[n|n-1]\n$$</div>\n“先前数据估计”怎么求解？\n<div>$$\n\\begin{aligned}\n\\hat{s}[n\\mid n-1]& =E\\left(as[n-1]+u[n]|x[0],x[1],...,x[n-1]\\right)  \\\\\n&=E\\left(as[n-1]|x[0],x[1],...,x[n-1]\\right)+E\\left(u[n]|x[0],x[1],...,x[n-1]\\right) \\\\\n&=aE\\left(s\\begin{bmatrix}n-1\\end{bmatrix}|x\\begin{bmatrix}0\\end{bmatrix},x\\begin{bmatrix}1\\end{bmatrix},...,x\\begin{bmatrix}n-1\\end{bmatrix}\\right)\\\\\n&=a\\hat{s}\\begin{bmatrix}n-1|n-1\\end{bmatrix} \\\\\n\\end{aligned}\n$$</div>\n#### 预测\n\n<p>求解新息</p>\n<div>$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=E\\left(s[n]\\right)+\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\left(\\tilde{x}[n]-E\\left(\\tilde{x}[n]\\right)\\right)\n$$</div>\n\n<div>$$\ns[n]=a^{n+1}s[-1]+\\sum_{k=0}^na^ku[n-k]\\rArr E(s[n]) = 0\\\\\n$$</div>\n\n<div>$$\n\\begin{gathered}\nE\\left(\\tilde{x}[n]\\right)=E\\left(x[n]-\\hat{x}[n\\mid n-1]\\right) \\\\\nE\\left(x[n]\\right)=E\\left(s[n]+w[n]\\right)=0 \\\\\nE\\left(\\hat{x}[n\\mid n-1]\\right)=E\\left(\\sum_{k=0}^{n-1}a[k]x[k]\\right) \n\\end{gathered}\\\\\n\\rArr E\\left(\\hat{x}[n\\mid n-1]\\right)=0\\\\\n\\rArr E(\\tilde x[n]) = 0\n$$</div>\n因此，\n<div>$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}\\tilde{x}[n]=\\underbrace{\\mathbf{C}_{s\\tilde{x}}\\mathbf{C}_{\\tilde{x}\\tilde{x}}^{-1}}_{卡尔曼增益}\\left(x[n]-\\hat{x}[n\\mid n-1]\\right)\n$$</div>\n#### 最小预测 MSE\n\n<p>$\\mathbf{C}_{s\\tilde{x}}\\text{的求解}$</p>\n<div>$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\tilde{x}[n]\\right)  \\\\\n&=E\\Big(s[n]\\Big(x[n]-\\hat{x}\\Big[n|n-1\\Big]\\Big)\\Big)\n\\end{aligned}\n$$</div>\n其中\n<div>$$\n\\begin{aligned}\\hat{x}\\left[n|n-1\\right]&=E\\left(x[n]|x[0],x[1],...x[n-1]\\right)=E\\left(s[n]+w[n]|x[0],x[1],...x[n-1]\\right)\\\\&=E\\left(s[n]|x[0],x[1],...x[n-1]\\right)=\\hat{s}\\left[n|n-1\\right]\\end{aligned}\n$$</div>\n因此\n<div>$$\n\\begin{aligned}\nC_{s\\tilde{x}}& =E\\left(s[n]\\left(s[n]+w[n]-\\hat{s}[n|n-1]\\right)\\right)  \\\\\n&=E\\left(s[n]w[n]+s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right) \\\\\n&=E\\Big(s[n]\\Big(s[n]-\\hat{s}\\Big[n|n-1\\Big]\\Big)\\Big)\\\\\n&=E\\left(s[n]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)-E\\left(\\hat{s}[n|n-1]\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n|n-1]\\right)\\left(s[n]-\\hat{s}[n|n-1]\\right)\\right)\\\\\n&\\triangleq M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\n\\end{aligned}\n$$</div>\n求解 $M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}$\n<div>$$\n\\begin{aligned}\n&M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\\\\n&=E\\left(\\left(as\\begin{bmatrix}n-1\\end{bmatrix}+u\\begin{bmatrix}n\\end{bmatrix}-\\hat{s}\\begin{bmatrix}n|n-1\\end{bmatrix}\\right)^2\\right)\\\\\n&=E\\left(\\left(a\\left(s[n-1]-\\hat{s}[n-1\\mid n-1]\\right)+u[n]\\right)^2\\right) \\\\\n&=E\\left(a^2\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)^2+u^2\\left[n\\right]+2a\\left(s\\left[n-1\\right]-\\hat{s}\\left[n-1\\mid n-1\\right]\\right)u\\left[n\\right]\\right) \\\\\n&=a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2\n\\end{aligned}\n$$</div>\n#### 卡尔曼增益\n\n<p>$\\mathbf{C}_{\\tilde{x}\\tilde{x}}\\text{的求解}$</p>\n<div>$$\n\\\\\n\\begin{aligned}\n\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=E\\left(\\left(\\tilde{x}[n]-E(\\tilde{x}[n])\\right)^2\\right) = E\\left(\\tilde{x}^2[n]\\right) = E\\left(\\left(x[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right)\\\\\n&=E\\left(\\left(s[n]+w[n]-\\hat{s}[n\\mid n-1]\\right)^2\\right) \\\\\n&=E\\left(\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)^2+w^2\\left[n\\right]+2\\left(s[n]-\\hat{s}[n\\mid n-1]\\right)w[n]\\right) \\\\\n&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\n\\end{aligned}\n$$</div>\n结合\n<div>$$\n\\begin{aligned}\\mathbf{C}_{\\tilde{x}\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}+\\sigma_n^2\\\\\\mathbf{C}_{s\\tilde{x}}&=M\\begin{bmatrix}n\\mid n-1\\end{bmatrix}\\end{aligned}\n$$</div>\n我们得到了卡尔曼增益\n<div>$$\nE\\left(s[n]|\\tilde{x}[n]\\right)=\\underbrace{\\frac{M\\left[n\\mid n-1\\right]}{M\\left[n\\mid n-1\\right]+\\sigma_n^2}}_{卡尔曼增益 K[n]}\\tilde{x}[n]\n$$</div>\n#### 修正\n<div>$$\n\\hat{s}\\left[n\\mid n\\right]=\\underbrace{\\hat{s}\\left[n\\mid n-1\\right]}_{预测}+\\underbrace{K\\left[n\\right]\\left(x\\left[n\\right]-\\hat{s}\\left[n\\mid n-1\\right]\\right)}_{新息修正}\n$$</div>\n#### 最小 MSE\n\n<p>MSE 修正：</p>\n<div>$$\nM[n|n] = (1 - K[n])M[n|n - 1]\n$$</div>\n### 非零均值信号模型\n\n<p><img src=\"/../images/StaSP/1714360809348.png\" alt=\"1714360809348\"></p>\n<p>初始化：$\\hat{s} [ - 1|- 1] &#x3D; E\\begin{pmatrix} s[ - 1] \\end{pmatrix} &#x3D; \\mu _s$ $M[ - 1|- 1] &#x3D; E\\left ( \\begin{pmatrix} s[ - 1] - \\hat{s} [ - 1|- 1] \\end{pmatrix} ^2\\right ) &#x3D; \\sigma _s^2$</p>\n<p>估计量预测：$\\hat{s}[n|n-1]&#x3D;a\\hat{s}[n-1|n-1]$</p>\n<p>MSE预测：$M\\left[n\\mid n-1\\right]&#x3D;a^2M\\left[n-1\\mid n-1\\right]+\\sigma_u^2$</p>\n<p>卡尔曼增益：$K[n]&#x3D;\\frac{M\\left[n|n-1\\right]}{M\\left[n|n-1\\right]+\\sigma_n^2}$</p>\n<p>估计量修正：$\\hat{s}[n|n]&#x3D;\\hat{s}[n|n-1]+K[n]\\left(x[n]-\\hat{s}[n|n-1]\\right)$</p>\n<p>MSE修正: $M\\left [ n\\mid n\\right ] &#x3D; \\left ( 1- K\\left [ n\\right ] \\right ) M\\left [ n\\mid n- 1\\right ]$</p>\n<h3 id=\"矢量状态-标量观测信号模型\"><a href=\"#矢量状态-标量观测信号模型\" class=\"headerlink\" title=\"矢量状态-标量观测信号模型\"></a>矢量状态-标量观测信号模型</h3><p><img src=\"/../images/StaSP/1714360717248.png\" alt=\"1714360717248\"></p>\n<h3 id=\"矢量状态-矢量观测信号模型\"><a href=\"#矢量状态-矢量观测信号模型\" class=\"headerlink\" title=\"矢量状态-矢量观测信号模型\"></a>矢量状态-矢量观测信号模型</h3><p><img src=\"/../images/StaSP/1714360742651.png\" alt=\"1714360742651\"></p>\n<h3 id=\"非线性信号模型\"><a href=\"#非线性信号模型\" class=\"headerlink\" title=\"非线性信号模型\"></a>非线性信号模型</h3><p><img src=\"/../images/StaSP/1714360782259.png\" alt=\"1714360782259\"></p>\n<p><img src=\"/../images/StaSP/1714361011137.png\" alt=\"1714361011137\"></p>\n<p><img src=\"/../images/StaSP/1714361027958.png\" alt=\"1714361027958\"></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ul>\n<li>不同时刻的待估计参数并不完全一样，但是存在某些内在联系</li>\n<li>卡尔曼滤波利用这种联系进行 LMMSE 估计，并减少了运算量</li>\n<li>如果信号与噪声是高斯的，则卡尔曼滤波在 MMSE 准则下最佳，否则，在 LMMSE 准则下是最佳的。</li>\n</ul>\n<h2 id=\"信号检测基本准则与方法\"><a href=\"#信号检测基本准则与方法\" class=\"headerlink\" title=\"信号检测基本准则与方法\"></a>信号检测基本准则与方法</h2><p>之前一直在研究连续型的问题（回归&#x2F;估计），这里研究离散型的问题（分类&#x2F;检测）。</p>\n<h3 id=\"Neyman-Pearson-准则\"><a href=\"#Neyman-Pearson-准则\" class=\"headerlink\" title=\"Neyman-Pearson 准则\"></a>Neyman-Pearson 准则</h3><p>适用于没有先验信息、代价不好量化的场景。</p>\n<p>两种假设：</p>\n<div>$$\n\\begin{aligned}&H_0:x[n]=w[n],n=0,1,...,N-1\\\\&H_1:x[n]=s[n]+w[n],n=0,1,...,N-1\\end{aligned}\n$$</div>\n\n<div>$$\n\\begin{aligned}\n&P\\left(H_1;H_0\\right):\\text{ 虚警概率}\\left(P_{FA},\\text{有时简记为}P_F\\right)\\\\\n&P\\left(H_0;H_1\\right):\\text{ 漏检概率 }\\left(P_M\\right)\\\\\n&P\\left(H_1;H_1\\right):\\text{ 检测概率 }\\left(P_D\\right)\\end{aligned}\n$$</div>\n要求：在虚警概率一定情况下，使检测概率最大化\n\n<p>检测概率和虚警概率之间追求折中，不可能两者都改善。</p>\n<p>对给定的虚警概率 $P_{FA}&#x3D;\\alpha$ ,使检测概率 $P_D$ 最大的判决为</p>\n<div>$$\nL(x)=\\frac{p(x;H_1)}{p(x;H_0)}>\\gamma\n$$</div>\n其中门限由 $P_{FA}=\\int_{\\lbrace\\mathbf{x}:L(\\mathbf{x})>\\gamma\\rbrace}p(\\boldsymbol{x};H_0)d\\boldsymbol{x}=\\alpha$ 决定\n\n\n<p>对于信号检测问题：</p>\n<div>$$\nH_0:\\boldsymbol{x}\\sim N\\left(\\boldsymbol{0},\\sigma^2\\mathbf{I}\\right)\\\\H_1:\\boldsymbol{x}\\sim N\\left(A\\mathbf{1},\\sigma^2\\mathbf{I}\\right)\n$$</div>\n\n<p>NP 检测器：</p>\n<div>$$\n\\frac{p\\left(\\boldsymbol{x};H_1\\right)}{p\\left(\\boldsymbol{x};H_0\\right)}=\\frac{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2\\right\\}}{\\frac1{\\left(2\\pi\\sigma^2\\right)^{N/2}}\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}}>\\gamma\\\\\\quad\\exp\\left\\{-\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}\\left(x[n]-A\\right)^2+\\frac1{2\\sigma^2}\\sum_{n=0}^{N-1}x^2[n]\\right\\}>\\gamma \n$$</div>\n\n<div>$$\n-\\frac1{2\\sigma^2}\\Bigg(-2A\\sum_{n=0}^{N-1}x[n]+NA^2\\Bigg)>\\ln\\gamma\\\\\\frac1N\\sum_{n=0}^{N-1}x[n]>\\frac{\\sigma^2}{NA}\\ln\\gamma+\\frac A2\n$$</div>\n称为检测统计量。若均值大于门限，则判为有信号，否则为无信号。\n\n<p>使用方法：</p>\n<div>$$\n\\begin{aligned}\n&\\text{检测统计量:}T(x)=\\frac1N\\sum_{n=0}^{N-1}x[n]\\sim\\begin{cases}N\\Big(0,\\sigma^2\\Big/_N\\Big),&H_0\\\\[2ex]N\\Big(A,\\sigma^2\\Big/_N\\Big),&H_1\\end{cases} \\\\\n&\\text{虚警概率:}P_{FA}=Pr\\left(T\\left(\\boldsymbol{x}\\right)>\\gamma^{'};H_0\\right)=Q\\left(\\frac{\\gamma^{'}}{\\sqrt{\\sigma^2/N}}\\right) \\\\\n&\\text{门限设置:}\\gamma^{\\prime}=\\sqrt{\\frac{\\sigma^2}N}Q^{-1}\\left(P_{FA}\\right) \\\\\n& \\begin{aligned}&\\text{相应的检测概率:}\\\\&P_{D}=Pr\\Big(T\\big(\\boldsymbol{x}\\big)>\\gamma^{'};H_{1}\\Big)=Q\\Bigg(\\frac{\\gamma^{'}-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)=Q\\Bigg(\\frac{\\sqrt{\\frac{\\sigma^{2}}{N}}Q^{-1}\\big(P_{FA}\\big)-A}{\\sqrt{\\sigma^{2}/N}}\\Bigg)\\end{aligned}  \\\\\n&=Q\\Bigg(Q^{-1}\\big(P_{F_A}\\big)-\\sqrt{\\frac{NA^2}{\\sigma^2}}\\Bigg)\n\\end{aligned}\n$$</div>\n### 检测性能分析\n\n<p>接收机工作特性曲线（ROC, receiver operating characteristics）</p>\n<p><img src=\"/../images/StaSP/1714966200160.png\" alt=\"1714966200160\"></p>\n<p>直观理解：</p>\n<p><img src=\"/../images/StaSP/1714966230536.png\" alt=\"1714966230536\"></p>\n<p>多次观测的好处</p>\n<ul>\n<li>从数学角度：不同假设下的pdf分隔更开，更易区分不同假设</li>\n<li>从信号处理角度：增加信号预检测积分时间，获得更多的能量用于检测</li>\n<li>从信息论角度：多的观测数据带来了新的信息</li>\n</ul>\n<h3 id=\"最小错误概率准则\"><a href=\"#最小错误概率准则\" class=\"headerlink\" title=\"最小错误概率准则\"></a>最小错误概率准则</h3><div>$$\n\\begin{aligned}\nP_{e}& =\\Pr\\left\\{\\text{判}H_0,H_1\\text{为真}\\right\\}+\\Pr\\left\\{\\text{判}H_1,H_0\\text{为真}\\right\\}  \\\\\n&=P\\big(H_0,H_1\\big)+P\\big(H_1,H_0\\big) \\\\\n&=P\\big(H_1\\big)P\\big(H_0|H_1\\big)+P\\big(H_0\\big)P\\big(H_1|H_0\\big) \\\\\n&=P\\big(H_1\\big)\\int_{R_0}p\\big(\\boldsymbol{x}|H_1\\big)d\\boldsymbol{x}+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}|H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\big(H_1\\big)\\Bigg(1-\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_1\\big)d\\boldsymbol{x}\\Bigg)+P\\big(H_0\\big)\\int_{R_1}p\\big(\\boldsymbol{x}\\mid H_0\\big)d\\boldsymbol{x} \\\\\n&=P\\left(H_1\\right)+\\int_{R_1}\\left\\{P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\n\\end{aligned}\n$$</div>\n为了使错误最小，需要在积分式小于零的区域积分，即\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$</div>\n最小错误概率准则可推导出最大后验概率检测器：\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{P\\left(H_0\\right)}{P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$</div>\n等价于\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)P\\left(H_1\\right)}{p\\left(\\boldsymbol{x}\\right)}>\\frac{p\\left(\\boldsymbol{x}\\mid H_0\\right)P\\left(H_0\\right)}{p\\left(\\boldsymbol{x}\\right)}\\\\p\\left(H_1\\mid\\boldsymbol{x}\\right)>p\\left(H_0\\mid\\boldsymbol{x}\\right)\n$$</div>\n若先验概率相同，则为最大似然检测器：\n<div>$$\np\\left(x\\mid H_1\\right)>p\\left(x\\mid H_0\\right)\n$$</div>\n### 二元贝叶斯风险准则\n\n<p>引入判错代价</p>\n<div>$$\nR=C_{01}P\\left(H_1\\right)P\\left(H_0\\mid H_1\\right)+C_{10}P\\left(H_0\\right)P\\left(H_1\\mid H_0\\right)\n$$</div>\n进一步泛化：\n<div>$$\nR=C_{00}P\\big(H_0\\big)P\\big(H_0|H_0\\big)+C_{10}P\\big(H_0\\big)P\\big(H_1|H_0\\big)\\\\+C_{01}P\\big(H_1\\big)P\\big(H_0|H_1\\big)+C_{11}P\\big(H_1\\big)P\\big(H_1|H_1\\big)\n$$</div>\n\n<div>$$\n\\begin{aligned}\\text{R}&=C_{00}P\\left(H_0\\right)+C_{01}P\\left(H_1\\right)\\\\&+\\int_{R_1}\\left\\{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)p\\left(\\boldsymbol{x}\\mid H_0\\right)-\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)p\\left(\\boldsymbol{x}\\mid H_1\\right)\\right\\}d\\boldsymbol{x}\\end{aligned}\n$$</div>\n因此，有了最小贝叶斯风险判决准则：\n<div>$$\n\\frac{p\\left(\\boldsymbol{x}\\mid H_1\\right)}{p\\left(\\boldsymbol{x}\\mid H_0\\right)}>\\frac{\\left(C_{10}-C_{00}\\right)P\\left(H_0\\right)}{\\left(C_{01}-C_{11}\\right)P\\left(H_1\\right)}\\text{ 时,判 }H_1\n$$</div>\n风险一致条件下（$C_{00}=C_{11}=0,C_{10}=C_{01}=1$），回到最小错误概率准则。\n\n<h3 id=\"多元贝叶斯风险准则\"><a href=\"#多元贝叶斯风险准则\" class=\"headerlink\" title=\"多元贝叶斯风险准则\"></a>多元贝叶斯风险准则</h3><p>贝叶斯风险：</p>\n<div>$$\n\\begin{aligned}\n\\text{R}& =\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_i,H_j\\Big)  \\\\\n&=\\sum_{i=0}^{M-1}\\sum_{j=0}^{M-1}C_{ij}\\int_{R_i}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(x,H_j\\Big)dx \\\\\n&=\\sum_{i=0}^{M-1}\\int_{R_i}\\sum_{j=0}^{M-1}C_{ij}P\\Big(H_j\\mid x\\Big)p(x)dx\n\\end{aligned}\n$$</div>\n\n<p>应选择使平均风险$C_i\\left(\\boldsymbol{x}\\right)&#x3D;\\sum_{j&#x3D;0}^{M-1}C_{ij}P\\left(H_j\\mid\\boldsymbol{x}\\right)$最小的假设</p>\n<p>在风险一致条件下</p>\n<div>$$\nC_{ij}=\\begin{cases}0,&i=j\\\\1,&i\\neq j\\end{cases}\n$$</div>\n\n<div>$$\n\\begin{aligned}C_{i}\\left(\\boldsymbol{x}\\right)&=\\sum_{j=0\\atop j\\neq i}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)\\\\&=\\sum_{j=0}^{M-1}P\\Big(H_j\\mid\\boldsymbol{x}\\Big)-\\underline{P\\Big(H_i\\mid\\boldsymbol{x}\\Big)}_{最大化这个}\\end{aligned}\n$$</div>\n因此等价于最大后验准则：\n<div>$$\n\\max_iP(H_i\\mid\\boldsymbol{x})\n$$</div>\n\n<p>若此时先验概率相同，则为最大似然准则。</p>\n<h2 id=\"总结知识点\"><a href=\"#总结知识点\" class=\"headerlink\" title=\"总结知识点\"></a>总结知识点</h2><h3 id=\"估计理论\"><a href=\"#估计理论\" class=\"headerlink\" title=\"估计理论\"></a>估计理论</h3><p>MAP 估计通常不能使用参数变换，变换后的参数不一定是 MAP。但是 MLE 可以。</p>\n<p>LS 方法与 BLUE 等 MVU 的衍生方法有一点不同，就是基础的 LS 没有使用协方差矩阵，但是加权的 LS 可以用协方差矩阵修正结果。</p>\n<p>贝叶斯方法和经典方法的区别在于是否把估计量的真值看作一个随机变量。它们都以“平均误差最小”为目标。</p>\n<h3 id=\"检测理论\"><a href=\"#检测理论\" class=\"headerlink\" title=\"检测理论\"></a>检测理论</h3><p>贝叶斯风险：让平均的风险最小化。</p>\n<p>未知多余参数如果影响最终的判决结果，可以用贝叶斯方法或者GLRT方法处理。</p>\n"},{"title":"Deep Reinforcement Learning","katex":true,"date":"2024-04-10T05:34:06.000Z","_content":"## Policy Graident\n\n带权重的梯度下降方法\n\n$$\n\\nabla_\\theta J(\\theta)=\\mathbb{E}_{\\pi_\\theta}[\\nabla_\\theta\\log\\pi_\\theta(a_t|s_t)R(\\tau)]\n$$\n\n## A2C\n\n$$\n\\Delta\\theta=\\alpha\\nabla_\\theta(log\\pi_\\theta(s,a))\\hat{q}_w(s,a)\\\\\n\\Delta w=\\beta\\left(R(s,a)+\\gamma\\hat{q}_{w}(s_{t+1},a_{t+1})-\\hat{q}_{w}(s_{t},a_{t})\\right)\\nabla_{w}\\hat{q}_{w}(s_{t},a_{t})\\\\\n$$\n\n## Model-Based RL\n\n### Model-Based RL\n\nIf we know the dynamics of some process:\n\nObjective in a Stochastic World\n\nThe dynamics are stochastic\n\nThe expectation under these actions in such a stochastic world.\n\n$$\n\\begin{aligned}p_\\theta(\\mathbf{s}_1,\\ldots,\\mathbf{s}_T\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T)&=p(\\mathbf{s}_1)\\prod_{t=1}^Tp(\\mathbf{s}_{t+1}\\mid\\mathbf{s}_t,\\mathbf{a}_t)\\\\\\mathbf{a}_1,\\ldots,\\mathbf{a}_T&=\\arg\\max_{\\mathbf{a}_1,\\ldots,\\mathbf{a}_T}E\\left[\\sum_tr(\\mathbf{s}_t,\\mathbf{a}_t)\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T\\right]\\end{aligned}\n$$\n\nIt is suboptimal.\n\n#### Open Loop Planning\n\nGuess and check (Random Shooting)\n\n* Pick action sequences uniformly in the action space\n* Calculate the Result\n\nBetter: Cross Entropy Method\n\nExample: MCTS\n\n#### Trajectory Optimization with Derivatives\n\nLQR? Linear Quadratic Regulator\n\n$$\nx_{t+1} = Ax_t+ Bu_t\\\\\nc(x_t, u_t) = x_t^TQx_t + u_t^TRu_t\n$$\n\n\nThe Q and R are symmetric and ponlositive definite. If not positive, you may optimize the result into negative inf.\n\n\n\nValue Iteration\n\n### Model-Free RL\n\nIf the model is not known?\n\nmodelbased RL:\n\n* base policy to collect dataset\n* learning dynamics model from dataset\n* plan through dynamics model and give actions\n* Execute the actions and add the result into data set\n\nModel predictive control (MPC)\n\n\n* base policy to collect dataset\n* learning dynamics model from dataset\n* plan through dynamics model and give actions\n* only execute the first planned action\n* append the $(s, a, s^\\prime)$ to dataset\n\n### Model-based RL with a policy\n\nWhy Model based RL with a learned model?\n\n* Data-efficiency\n  * Dont need to act in real world\n* Multi-task with a model\n  * reuse the world model\n\nBut they are unstable and worse asymptotic performance.\n1. If the model biased toword the positive side\n    * the actions overfit to the learned model\n2. if the trajectory is really long\n    * Accumulated errors\n\nTo resolve 1: use uncertainty\n\nOptimize towards expectation of rewards rather than rewards\n\nTwo types of uncertainty\n* Aleatoric or statistical: The reality itself has uncertainty (e.g. Dice)\n* Epistemic or model uncertainty: You are uncertain about the true function\n\nIf use output entropy, it can't tell apart the type of uncertainty. We need to measure the epistemic uncertainty.\n\nHow to measure?\n\nWe use the collected data to train the model, maximize $\\log(D|\\theta)$ by changing $\\theta$\n\nCan we instead to measure $\\log(\\theta|D)$ -- the model uncertainty!\n\nbut it is rather intractable.\n\nModel Ensemble!\n\nTraining multiple models, see if they agree with each other. We have to make the models different(variant).\n\nThe randomness and SGD is enough to make the models different.\n\n* Every time drag one model and give actions\n* calculate the reward\n* add the data into dataset and update policy\n\nTo resolve 2 (long rollouts can be error-prone), we can always use short rollouts.\n\ncombine the real and model data to improve policy\n\nExample: DYNA-style MBRL\n\nAlso can try Baysian Neural Networks.\n\n### Value-Equivalent Model\n\nYou dont have to stimulate the world, just simplify the value fuction ensuring to keep the value is approximately the same with the real one.\n\nUse mean square error.\n\n### Model-Base RL with images\n\n## Imitation Learning\n\nAccumulate Error and Covariate Shiift\n\nDAgger:\n* Train a policy from human data $D$\n* Run the policy to get dataset $D_\\pi$\n* Ask human to label $D_\\pi$ with actions $a_t$\n* Aggregate: $D \\larr D \\cup D_\\pi$\n\nTechniques: Dataset Resampling / Reweighting\n\nTechniques: Pre-Trained Models to extract representations\n\nMSE gives the mean value, while the cross-entropy gives the probability. If a task has a probability with 50% left, 50% right, the MSE will give an answer \"go forward\".\n\nLeverage Demonstrations in DRL\n\nDQfD: Deep Q-Learning from Demonstrations\n","source":"_posts/DRL.md","raw":"---\ntitle: Deep Reinforcement Learning\nkatex: true\ndate: 2024-04-10 13:34:06\ntags:\n---\n## Policy Graident\n\n带权重的梯度下降方法\n\n$$\n\\nabla_\\theta J(\\theta)=\\mathbb{E}_{\\pi_\\theta}[\\nabla_\\theta\\log\\pi_\\theta(a_t|s_t)R(\\tau)]\n$$\n\n## A2C\n\n$$\n\\Delta\\theta=\\alpha\\nabla_\\theta(log\\pi_\\theta(s,a))\\hat{q}_w(s,a)\\\\\n\\Delta w=\\beta\\left(R(s,a)+\\gamma\\hat{q}_{w}(s_{t+1},a_{t+1})-\\hat{q}_{w}(s_{t},a_{t})\\right)\\nabla_{w}\\hat{q}_{w}(s_{t},a_{t})\\\\\n$$\n\n## Model-Based RL\n\n### Model-Based RL\n\nIf we know the dynamics of some process:\n\nObjective in a Stochastic World\n\nThe dynamics are stochastic\n\nThe expectation under these actions in such a stochastic world.\n\n$$\n\\begin{aligned}p_\\theta(\\mathbf{s}_1,\\ldots,\\mathbf{s}_T\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T)&=p(\\mathbf{s}_1)\\prod_{t=1}^Tp(\\mathbf{s}_{t+1}\\mid\\mathbf{s}_t,\\mathbf{a}_t)\\\\\\mathbf{a}_1,\\ldots,\\mathbf{a}_T&=\\arg\\max_{\\mathbf{a}_1,\\ldots,\\mathbf{a}_T}E\\left[\\sum_tr(\\mathbf{s}_t,\\mathbf{a}_t)\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T\\right]\\end{aligned}\n$$\n\nIt is suboptimal.\n\n#### Open Loop Planning\n\nGuess and check (Random Shooting)\n\n* Pick action sequences uniformly in the action space\n* Calculate the Result\n\nBetter: Cross Entropy Method\n\nExample: MCTS\n\n#### Trajectory Optimization with Derivatives\n\nLQR? Linear Quadratic Regulator\n\n$$\nx_{t+1} = Ax_t+ Bu_t\\\\\nc(x_t, u_t) = x_t^TQx_t + u_t^TRu_t\n$$\n\n\nThe Q and R are symmetric and ponlositive definite. If not positive, you may optimize the result into negative inf.\n\n\n\nValue Iteration\n\n### Model-Free RL\n\nIf the model is not known?\n\nmodelbased RL:\n\n* base policy to collect dataset\n* learning dynamics model from dataset\n* plan through dynamics model and give actions\n* Execute the actions and add the result into data set\n\nModel predictive control (MPC)\n\n\n* base policy to collect dataset\n* learning dynamics model from dataset\n* plan through dynamics model and give actions\n* only execute the first planned action\n* append the $(s, a, s^\\prime)$ to dataset\n\n### Model-based RL with a policy\n\nWhy Model based RL with a learned model?\n\n* Data-efficiency\n  * Dont need to act in real world\n* Multi-task with a model\n  * reuse the world model\n\nBut they are unstable and worse asymptotic performance.\n1. If the model biased toword the positive side\n    * the actions overfit to the learned model\n2. if the trajectory is really long\n    * Accumulated errors\n\nTo resolve 1: use uncertainty\n\nOptimize towards expectation of rewards rather than rewards\n\nTwo types of uncertainty\n* Aleatoric or statistical: The reality itself has uncertainty (e.g. Dice)\n* Epistemic or model uncertainty: You are uncertain about the true function\n\nIf use output entropy, it can't tell apart the type of uncertainty. We need to measure the epistemic uncertainty.\n\nHow to measure?\n\nWe use the collected data to train the model, maximize $\\log(D|\\theta)$ by changing $\\theta$\n\nCan we instead to measure $\\log(\\theta|D)$ -- the model uncertainty!\n\nbut it is rather intractable.\n\nModel Ensemble!\n\nTraining multiple models, see if they agree with each other. We have to make the models different(variant).\n\nThe randomness and SGD is enough to make the models different.\n\n* Every time drag one model and give actions\n* calculate the reward\n* add the data into dataset and update policy\n\nTo resolve 2 (long rollouts can be error-prone), we can always use short rollouts.\n\ncombine the real and model data to improve policy\n\nExample: DYNA-style MBRL\n\nAlso can try Baysian Neural Networks.\n\n### Value-Equivalent Model\n\nYou dont have to stimulate the world, just simplify the value fuction ensuring to keep the value is approximately the same with the real one.\n\nUse mean square error.\n\n### Model-Base RL with images\n\n## Imitation Learning\n\nAccumulate Error and Covariate Shiift\n\nDAgger:\n* Train a policy from human data $D$\n* Run the policy to get dataset $D_\\pi$\n* Ask human to label $D_\\pi$ with actions $a_t$\n* Aggregate: $D \\larr D \\cup D_\\pi$\n\nTechniques: Dataset Resampling / Reweighting\n\nTechniques: Pre-Trained Models to extract representations\n\nMSE gives the mean value, while the cross-entropy gives the probability. If a task has a probability with 50% left, 50% right, the MSE will give an answer \"go forward\".\n\nLeverage Demonstrations in DRL\n\nDQfD: Deep Q-Learning from Demonstrations\n","slug":"DRL","published":1,"updated":"2024-04-17T06:54:56.587Z","_id":"clv3g63kk0000uwugagbvg383","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"Policy-Graident\"><a href=\"#Policy-Graident\" class=\"headerlink\" title=\"Policy Graident\"></a>Policy Graident</h2><p>带权重的梯度下降方法</p>\n<div>$$\n\\nabla_\\theta J(\\theta)=\\mathbb{E}_{\\pi_\\theta}[\\nabla_\\theta\\log\\pi_\\theta(a_t|s_t)R(\\tau)]\n$$</div>\n\n<h2 id=\"A2C\"><a href=\"#A2C\" class=\"headerlink\" title=\"A2C\"></a>A2C</h2><div>$$\n\\Delta\\theta=\\alpha\\nabla_\\theta(log\\pi_\\theta(s,a))\\hat{q}_w(s,a)\\\\\n\\Delta w=\\beta\\left(R(s,a)+\\gamma\\hat{q}_{w}(s_{t+1},a_{t+1})-\\hat{q}_{w}(s_{t},a_{t})\\right)\\nabla_{w}\\hat{q}_{w}(s_{t},a_{t})\\\\\n$$</div>\n\n<h2 id=\"Model-Based-RL\"><a href=\"#Model-Based-RL\" class=\"headerlink\" title=\"Model-Based RL\"></a>Model-Based RL</h2><h3 id=\"Model-Based-RL-1\"><a href=\"#Model-Based-RL-1\" class=\"headerlink\" title=\"Model-Based RL\"></a>Model-Based RL</h3><p>If we know the dynamics of some process:</p>\n<p>Objective in a Stochastic World</p>\n<p>The dynamics are stochastic</p>\n<p>The expectation under these actions in such a stochastic world.</p>\n<div>$$\n\\begin{aligned}p_\\theta(\\mathbf{s}_1,\\ldots,\\mathbf{s}_T\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T)&=p(\\mathbf{s}_1)\\prod_{t=1}^Tp(\\mathbf{s}_{t+1}\\mid\\mathbf{s}_t,\\mathbf{a}_t)\\\\\\mathbf{a}_1,\\ldots,\\mathbf{a}_T&=\\arg\\max_{\\mathbf{a}_1,\\ldots,\\mathbf{a}_T}E\\left[\\sum_tr(\\mathbf{s}_t,\\mathbf{a}_t)\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T\\right]\\end{aligned}\n$$</div>\n\n<p>It is suboptimal.</p>\n<h4 id=\"Open-Loop-Planning\"><a href=\"#Open-Loop-Planning\" class=\"headerlink\" title=\"Open Loop Planning\"></a>Open Loop Planning</h4><p>Guess and check (Random Shooting)</p>\n<ul>\n<li>Pick action sequences uniformly in the action space</li>\n<li>Calculate the Result</li>\n</ul>\n<p>Better: Cross Entropy Method</p>\n<p>Example: MCTS</p>\n<h4 id=\"Trajectory-Optimization-with-Derivatives\"><a href=\"#Trajectory-Optimization-with-Derivatives\" class=\"headerlink\" title=\"Trajectory Optimization with Derivatives\"></a>Trajectory Optimization with Derivatives</h4><p>LQR? Linear Quadratic Regulator</p>\n<div>$$\nx_{t+1} = Ax_t+ Bu_t\\\\\nc(x_t, u_t) = x_t^TQx_t + u_t^TRu_t\n$$</div>\n\n\n<p>The Q and R are symmetric and ponlositive definite. If not positive, you may optimize the result into negative inf.</p>\n<p>Value Iteration</p>\n<h3 id=\"Model-Free-RL\"><a href=\"#Model-Free-RL\" class=\"headerlink\" title=\"Model-Free RL\"></a>Model-Free RL</h3><p>If the model is not known?</p>\n<p>modelbased RL:</p>\n<ul>\n<li>base policy to collect dataset</li>\n<li>learning dynamics model from dataset</li>\n<li>plan through dynamics model and give actions</li>\n<li>Execute the actions and add the result into data set</li>\n</ul>\n<p>Model predictive control (MPC)</p>\n<ul>\n<li>base policy to collect dataset</li>\n<li>learning dynamics model from dataset</li>\n<li>plan through dynamics model and give actions</li>\n<li>only execute the first planned action</li>\n<li>append the $(s, a, s^\\prime)$ to dataset</li>\n</ul>\n<h3 id=\"Model-based-RL-with-a-policy\"><a href=\"#Model-based-RL-with-a-policy\" class=\"headerlink\" title=\"Model-based RL with a policy\"></a>Model-based RL with a policy</h3><p>Why Model based RL with a learned model?</p>\n<ul>\n<li>Data-efficiency<ul>\n<li>Dont need to act in real world</li>\n</ul>\n</li>\n<li>Multi-task with a model<ul>\n<li>reuse the world model</li>\n</ul>\n</li>\n</ul>\n<p>But they are unstable and worse asymptotic performance.</p>\n<ol>\n<li>If the model biased toword the positive side<ul>\n<li>the actions overfit to the learned model</li>\n</ul>\n</li>\n<li>if the trajectory is really long<ul>\n<li>Accumulated errors</li>\n</ul>\n</li>\n</ol>\n<p>To resolve 1: use uncertainty</p>\n<p>Optimize towards expectation of rewards rather than rewards</p>\n<p>Two types of uncertainty</p>\n<ul>\n<li>Aleatoric or statistical: The reality itself has uncertainty (e.g. Dice)</li>\n<li>Epistemic or model uncertainty: You are uncertain about the true function</li>\n</ul>\n<p>If use output entropy, it can’t tell apart the type of uncertainty. We need to measure the epistemic uncertainty.</p>\n<p>How to measure?</p>\n<p>We use the collected data to train the model, maximize $\\log(D|\\theta)$ by changing $\\theta$</p>\n<p>Can we instead to measure $\\log(\\theta|D)$ – the model uncertainty!</p>\n<p>but it is rather intractable.</p>\n<p>Model Ensemble!</p>\n<p>Training multiple models, see if they agree with each other. We have to make the models different(variant).</p>\n<p>The randomness and SGD is enough to make the models different.</p>\n<ul>\n<li>Every time drag one model and give actions</li>\n<li>calculate the reward</li>\n<li>add the data into dataset and update policy</li>\n</ul>\n<p>To resolve 2 (long rollouts can be error-prone), we can always use short rollouts.</p>\n<p>combine the real and model data to improve policy</p>\n<p>Example: DYNA-style MBRL</p>\n<p>Also can try Baysian Neural Networks.</p>\n<h3 id=\"Value-Equivalent-Model\"><a href=\"#Value-Equivalent-Model\" class=\"headerlink\" title=\"Value-Equivalent Model\"></a>Value-Equivalent Model</h3><p>You dont have to stimulate the world, just simplify the value fuction ensuring to keep the value is approximately the same with the real one.</p>\n<p>Use mean square error.</p>\n<h3 id=\"Model-Base-RL-with-images\"><a href=\"#Model-Base-RL-with-images\" class=\"headerlink\" title=\"Model-Base RL with images\"></a>Model-Base RL with images</h3><h2 id=\"Imitation-Learning\"><a href=\"#Imitation-Learning\" class=\"headerlink\" title=\"Imitation Learning\"></a>Imitation Learning</h2><p>Accumulate Error and Covariate Shiift</p>\n<p>DAgger:</p>\n<ul>\n<li>Train a policy from human data $D$</li>\n<li>Run the policy to get dataset $D_\\pi$</li>\n<li>Ask human to label $D_\\pi$ with actions $a_t$</li>\n<li>Aggregate: $D \\larr D \\cup D_\\pi$</li>\n</ul>\n<p>Techniques: Dataset Resampling &#x2F; Reweighting</p>\n<p>Techniques: Pre-Trained Models to extract representations</p>\n<p>MSE gives the mean value, while the cross-entropy gives the probability. If a task has a probability with 50% left, 50% right, the MSE will give an answer “go forward”.</p>\n<p>Leverage Demonstrations in DRL</p>\n<p>DQfD: Deep Q-Learning from Demonstrations</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Policy-Graident\"><a href=\"#Policy-Graident\" class=\"headerlink\" title=\"Policy Graident\"></a>Policy Graident</h2><p>带权重的梯度下降方法</p>\n<div>$$\n\\nabla_\\theta J(\\theta)=\\mathbb{E}_{\\pi_\\theta}[\\nabla_\\theta\\log\\pi_\\theta(a_t|s_t)R(\\tau)]\n$$</div>\n\n<h2 id=\"A2C\"><a href=\"#A2C\" class=\"headerlink\" title=\"A2C\"></a>A2C</h2><div>$$\n\\Delta\\theta=\\alpha\\nabla_\\theta(log\\pi_\\theta(s,a))\\hat{q}_w(s,a)\\\\\n\\Delta w=\\beta\\left(R(s,a)+\\gamma\\hat{q}_{w}(s_{t+1},a_{t+1})-\\hat{q}_{w}(s_{t},a_{t})\\right)\\nabla_{w}\\hat{q}_{w}(s_{t},a_{t})\\\\\n$$</div>\n\n<h2 id=\"Model-Based-RL\"><a href=\"#Model-Based-RL\" class=\"headerlink\" title=\"Model-Based RL\"></a>Model-Based RL</h2><h3 id=\"Model-Based-RL-1\"><a href=\"#Model-Based-RL-1\" class=\"headerlink\" title=\"Model-Based RL\"></a>Model-Based RL</h3><p>If we know the dynamics of some process:</p>\n<p>Objective in a Stochastic World</p>\n<p>The dynamics are stochastic</p>\n<p>The expectation under these actions in such a stochastic world.</p>\n<div>$$\n\\begin{aligned}p_\\theta(\\mathbf{s}_1,\\ldots,\\mathbf{s}_T\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T)&=p(\\mathbf{s}_1)\\prod_{t=1}^Tp(\\mathbf{s}_{t+1}\\mid\\mathbf{s}_t,\\mathbf{a}_t)\\\\\\mathbf{a}_1,\\ldots,\\mathbf{a}_T&=\\arg\\max_{\\mathbf{a}_1,\\ldots,\\mathbf{a}_T}E\\left[\\sum_tr(\\mathbf{s}_t,\\mathbf{a}_t)\\mid\\mathbf{a}_1,\\ldots,\\mathbf{a}_T\\right]\\end{aligned}\n$$</div>\n\n<p>It is suboptimal.</p>\n<h4 id=\"Open-Loop-Planning\"><a href=\"#Open-Loop-Planning\" class=\"headerlink\" title=\"Open Loop Planning\"></a>Open Loop Planning</h4><p>Guess and check (Random Shooting)</p>\n<ul>\n<li>Pick action sequences uniformly in the action space</li>\n<li>Calculate the Result</li>\n</ul>\n<p>Better: Cross Entropy Method</p>\n<p>Example: MCTS</p>\n<h4 id=\"Trajectory-Optimization-with-Derivatives\"><a href=\"#Trajectory-Optimization-with-Derivatives\" class=\"headerlink\" title=\"Trajectory Optimization with Derivatives\"></a>Trajectory Optimization with Derivatives</h4><p>LQR? Linear Quadratic Regulator</p>\n<div>$$\nx_{t+1} = Ax_t+ Bu_t\\\\\nc(x_t, u_t) = x_t^TQx_t + u_t^TRu_t\n$$</div>\n\n\n<p>The Q and R are symmetric and ponlositive definite. If not positive, you may optimize the result into negative inf.</p>\n<p>Value Iteration</p>\n<h3 id=\"Model-Free-RL\"><a href=\"#Model-Free-RL\" class=\"headerlink\" title=\"Model-Free RL\"></a>Model-Free RL</h3><p>If the model is not known?</p>\n<p>modelbased RL:</p>\n<ul>\n<li>base policy to collect dataset</li>\n<li>learning dynamics model from dataset</li>\n<li>plan through dynamics model and give actions</li>\n<li>Execute the actions and add the result into data set</li>\n</ul>\n<p>Model predictive control (MPC)</p>\n<ul>\n<li>base policy to collect dataset</li>\n<li>learning dynamics model from dataset</li>\n<li>plan through dynamics model and give actions</li>\n<li>only execute the first planned action</li>\n<li>append the $(s, a, s^\\prime)$ to dataset</li>\n</ul>\n<h3 id=\"Model-based-RL-with-a-policy\"><a href=\"#Model-based-RL-with-a-policy\" class=\"headerlink\" title=\"Model-based RL with a policy\"></a>Model-based RL with a policy</h3><p>Why Model based RL with a learned model?</p>\n<ul>\n<li>Data-efficiency<ul>\n<li>Dont need to act in real world</li>\n</ul>\n</li>\n<li>Multi-task with a model<ul>\n<li>reuse the world model</li>\n</ul>\n</li>\n</ul>\n<p>But they are unstable and worse asymptotic performance.</p>\n<ol>\n<li>If the model biased toword the positive side<ul>\n<li>the actions overfit to the learned model</li>\n</ul>\n</li>\n<li>if the trajectory is really long<ul>\n<li>Accumulated errors</li>\n</ul>\n</li>\n</ol>\n<p>To resolve 1: use uncertainty</p>\n<p>Optimize towards expectation of rewards rather than rewards</p>\n<p>Two types of uncertainty</p>\n<ul>\n<li>Aleatoric or statistical: The reality itself has uncertainty (e.g. Dice)</li>\n<li>Epistemic or model uncertainty: You are uncertain about the true function</li>\n</ul>\n<p>If use output entropy, it can’t tell apart the type of uncertainty. We need to measure the epistemic uncertainty.</p>\n<p>How to measure?</p>\n<p>We use the collected data to train the model, maximize $\\log(D|\\theta)$ by changing $\\theta$</p>\n<p>Can we instead to measure $\\log(\\theta|D)$ – the model uncertainty!</p>\n<p>but it is rather intractable.</p>\n<p>Model Ensemble!</p>\n<p>Training multiple models, see if they agree with each other. We have to make the models different(variant).</p>\n<p>The randomness and SGD is enough to make the models different.</p>\n<ul>\n<li>Every time drag one model and give actions</li>\n<li>calculate the reward</li>\n<li>add the data into dataset and update policy</li>\n</ul>\n<p>To resolve 2 (long rollouts can be error-prone), we can always use short rollouts.</p>\n<p>combine the real and model data to improve policy</p>\n<p>Example: DYNA-style MBRL</p>\n<p>Also can try Baysian Neural Networks.</p>\n<h3 id=\"Value-Equivalent-Model\"><a href=\"#Value-Equivalent-Model\" class=\"headerlink\" title=\"Value-Equivalent Model\"></a>Value-Equivalent Model</h3><p>You dont have to stimulate the world, just simplify the value fuction ensuring to keep the value is approximately the same with the real one.</p>\n<p>Use mean square error.</p>\n<h3 id=\"Model-Base-RL-with-images\"><a href=\"#Model-Base-RL-with-images\" class=\"headerlink\" title=\"Model-Base RL with images\"></a>Model-Base RL with images</h3><h2 id=\"Imitation-Learning\"><a href=\"#Imitation-Learning\" class=\"headerlink\" title=\"Imitation Learning\"></a>Imitation Learning</h2><p>Accumulate Error and Covariate Shiift</p>\n<p>DAgger:</p>\n<ul>\n<li>Train a policy from human data $D$</li>\n<li>Run the policy to get dataset $D_\\pi$</li>\n<li>Ask human to label $D_\\pi$ with actions $a_t$</li>\n<li>Aggregate: $D \\larr D \\cup D_\\pi$</li>\n</ul>\n<p>Techniques: Dataset Resampling &#x2F; Reweighting</p>\n<p>Techniques: Pre-Trained Models to extract representations</p>\n<p>MSE gives the mean value, while the cross-entropy gives the probability. If a task has a probability with 50% left, 50% right, the MSE will give an answer “go forward”.</p>\n<p>Leverage Demonstrations in DRL</p>\n<p>DQfD: Deep Q-Learning from Demonstrations</p>\n"},{"title":"操作系统","katex":false,"date":"2024-04-16T11:21:41.000Z","_content":"资源分配图\n\n![1713266591628](../images/OS/1713266591628.png)\n\n## 存储器管理\n","source":"_posts/OS.md","raw":"---\ntitle: 操作系统\nkatex: false\ndate: 2024-04-16 19:21:41\ntags:\n---\n资源分配图\n\n![1713266591628](../images/OS/1713266591628.png)\n\n## 存储器管理\n","slug":"OS","published":1,"updated":"2024-04-16T13:27:35.033Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clv3g63kl0001uwug5iin4bmi","content":"<p>资源分配图</p>\n<p><img src=\"/../images/OS/1713266591628.png\" alt=\"1713266591628\" loading=\"lazy\"></p>\n<h2 id=\"存储器管理\"><a href=\"#存储器管理\" class=\"headerlink\" title=\"存储器管理\"></a>存储器管理</h2>","site":{"data":{}},"excerpt":"","more":"<p>资源分配图</p>\n<p><img src=\"/../images/OS/1713266591628.png\" alt=\"1713266591628\"></p>\n<h2 id=\"存储器管理\"><a href=\"#存储器管理\" class=\"headerlink\" title=\"存储器管理\"></a>存储器管理</h2>"},{"title":"固体物理","katex":true,"date":"2024-04-16T02:06:07.000Z","_content":"## 外场中电子运动状态的变化\n\n### 布洛赫电子\n\n#### 布洛赫定理\n\n$$\n\\psi(x+R_n)=e^{ik\\cdot R_n}\\psi(x)\n$$\n\n布洛赫波函数：\n\n$$\n\\boxed{\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}}\n$$\n\n薛定谔方程在周期势场 $V(r)$的本征解。与 $V(r)$有相同的周期。\n\n简约布里渊区和周期布里渊区图景\n\n![1713239832006](../images/SolidPhysics/1713239832006.png)\n\n#### 一维近自由电子近似\n\n利用微扰求解薛定谔方程\n\n零级哈密顿量是自由电子的哈密顿量(索末菲模型),周期性势场的作用看成是微扰\n适用于解释参与共有化运动的外层价电子的运动状态\n\n$$\nH=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+V(x)=H_0+H^{\\prime}\\\\\nV(x)=\\overline{V}+\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}anx\\biggr]\n$$\n\n$$\n\\begin{aligned}&H_0=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+\\overline{V}\\\\&H'=\\sum_{n\\neq0}V_n\\exp\\left(i\\frac{2\\pi nx}a\\right)\\end{aligned}\n$$\n\n基态（零级解）\n\n$$\nE_k^0=\\frac{\\hbar^2k^2}{2m_0}+\\overline{V}\\\\\n\\psi_k^{(0)}=\\frac1{\\sqrt{L}}e^{ikx}\n$$\n\n$$\nk=\\frac{2\\pi l_x}{Na}\n$$\n\n利用波恩卡曼条件看作准连续。\n\n周期性势场的一级微扰\n\n$$\n\\Delta V=\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}{a}nx\\biggr]\n$$\n\n一级修正：\n\n$$\nE_k^{(1)}=\\int\\left(\\psi_k^0\\right)^*[\\Delta V]\\psi_k^0dx=\\left\\langle k|\\Delta V|k\\right\\rangle=0\n$$\n\n二级修正：\n\n$$\nE_k^{(2)}=\\sum_{k^{\\prime}}\\frac{\\left|\\left\\langle k^{\\prime}|\\Delta V|k\\right\\rangle\\right|^2}{E_k^0-E_{k^{\\prime}}^0}\n$$\n\n非简并情况下：\n\n$$\nE_k^{(2)}=\\sum_{n\\neq0}\\frac{\\left|V_n\\right|^2}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi}an\\right)^2\\right]}\n$$\n\nk’对应的波可以看作k状态波在周期性势场各频率分量对应的散射波->自由电子波函数经过周期势场的散射后改变了原有的能量。\n\n波函数的一级修正\n\n$$\n\\psi_k=\\frac1{\\sqrt{L}}e^{ikx}\\left\\{1+\\sum_{n=0}\\frac{V_n}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi n}a\\right)^2\\right]}\\cdot exp\\left[i\\frac{2\\pi}anx\\right]\\right\\}\n$$\n\n$$\n\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}\n$$\n\n被周期函数调幅的平面波。\n\n![1713240457384](../images/SolidPhysics/1713240457384.png)\n\n如果 k 的取值在布里渊区边界 $k=-\\frac{n\\pi}a$，散射波矢$k’=k+\\frac{2\\pi n}a=\\frac{\\pi n}a$，即布拉格定律 $2dsin\\theta=n\\lambda$。此时电子的波函数是 $k$ 和 $k'$ 两个平面波叠加的驻波。\n\n简并状态的处理方法\n\n在布里渊区边界，存在简并状态，能量相等。\n\n### 准经典运动\n\n引入准经典粒子——波包\n\n自由电子和晶体电子速度的定义：\n\n$$\nv(k_0) = \\frac1\\hbar \\bigg[\\frac{d E(k)}{dk}\\bigg]_{k_0}\\\\\nE(k) = \\hbar\\omega\n$$\n\n速度方向垂直于等能面，如果等能面为球面， 速度的方向与 $k$ 相同。\n\n晶体电子的加速度\n\n$$\n\\hbar\\frac{dk}{dt} = F\n$$\n\n由此定义电子的准动量（晶体动量）为 $\\hbar k$。可定义有效质量：\n\n$$\n\\frac{d\\upsilon_a}{dt}=\\frac1{\\hbar^2}\\sum_\\beta F_\\beta\\cdot\\frac{\\partial^2}{\\partial k_\\beta\\partial k_\\alpha}E(k)\\\\\n\\frac{d\\vec{\\upsilon}}{dt}=\\frac1{m_0}\\vec{F}\n$$\n\n有效质量的“倒数”（矩阵的逆）：\n\n$$\n\\frac1{m_{\\alpha\\beta}^*}=\\frac1{\\hbar^2}\\frac{\\partial^2E}{\\partial k_\\alpha\\partial k_\\beta}\n$$\n\n$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_y\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_y^2}&\\dfrac{\\partial^2E}{\\partial k_y\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_z\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_z\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$\n\n选取 $(k_x, k_y, k_z)$ 的主轴方向时\n\n$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&0&0\\\\0&\\dfrac{\\partial^2E}{\\partial k_y^2}&0\\\\\\\\0&0&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$\n\n注意：各方向上的有效质量一般不同\n\n(1) 质量是标量，而有效质量是张量\n晶体中的电子，加速度和外力的方向可以不一致\n (2)质量常值，有效质量是变值，有正有负\n能带顶附近<0 能带底附近>0\n有效质量$m^{*}$与电子质量$m$之间可以有很大的差别， 因为有效质量中实际包含了周期势场的作用\n\n晶体所表现出来的有效质量，原因在于电子波在晶体中传播时与晶格交换动量。\n\n正有效质量状态出现在能带底附近，体现电子从外场获得的动量，加速度为正。\n\n 负有效质量状态出现在能带顶附近，由电子从外场获得动量不足以弥补与晶格的碰撞，加速度为负。\n\n#### 恒定电场下运动\n\n在周期布里渊图景；\n\n在 $k$ 空间里匀速运动\n\n![1713234834861](../images/SolidPhysics/1713234834861.png)\n\n在实际空间中，电子的运动相当复杂：\n\n![1713234874686](../images/SolidPhysics/1713234874686.png)\n\n质量无穷大：驻波解。\n\n拐点不一定是 $\\pi/2a$，结合实际情况。\n\n![1713235941206](../images/SolidPhysics/1713235941206.png)\n\n![1713235941206](../images/SolidPhysics/1713235941206.png)\n\n理想情况（无散射），电子的运动产生震荡的电流。\n\n实际情况下，很难观察到来回震荡。\n\n![1713236189430](../images/SolidPhysics/1713236189430.png)\n\n![1713236233045](../images/SolidPhysics/1713236233045.png)\n\n实际情况：带隙部分反射\n\n存在势垒穿透\n\n隧穿几率：\n\n$$\nf\\propto E\\exp\\left[-\\frac{\\pi^2}\\hbar\\left(2m_0E_g\\right)^{1/2}\\left(\\frac{E_g}{qE}\\right)\\right]\n$$\n\n![1713236269885](../images/SolidPhysics/1713236269885.png)\n\n准经典运动只适合描述弱电场下电子在同一能带中的运动。\n\n### 导体、绝缘体和半导体的能带解释\n\n#### 满带不导电\n\n不加电场：$E(k)=E(-k)$，占据正反方向波矢的概率相等， 相反速度的电子数量也相等，相互抵消；\n\n加电场：k空间里匀速移动，边界上移出的粒子和移入的粒子是一样的，仍然均匀填充。\n\n#### 部分填充能带产生电流\n\n无外场：净电流为0\n\n有外场：k空间分布向一方移动，有净电流\n\n#### 导体的能带模型\n\n部分填充的能带称为导带\n\n![1713236929581](../images/SolidPhysics/1713236929581.png)\n\n#### 非导体的能带模型\n\n电子恰好填满最低的一系列能带，再高的能带全空\n\n满带不导电，空带也不导电\n\n![1713236984022](../images/SolidPhysics/1713236984022.png)\n\n最高的满带的电子容易被激发到上面的空带，从而使两个带皆变成未满带，产生一定的导电性\n\n![1713237069207](../images/SolidPhysics/1713237069207.png)\n\n总结：\n\n![1713237158982](../images/SolidPhysics/1713237158982.png)\n\n#### 半导体能带模型\n\n常温下，T=0K时的满带电子容易被激发到上面的空带，\n从而使两个带皆变成未满带，产生一定的导电性\n\n![1713237357342](../images/SolidPhysics/1713237357342.png)\n\n近满带和空穴\n\n* 速度是电子的速度\n* 但电荷为正\n\n空穴的波矢：\n\n空穴的有效质量，在能带顶部为k_\\mathrm{h}=-k_\\mathrm{e}\n\n正：\n\n$$\n\\frac1{m_h^*}=-\\left(\\frac1{\\hbar^2}\\cdot\\frac{d^2E}{dk^2}\\right)\n$$\n\n## 金属和半导体中的输运过程\n\n### 金属中的电子输运过程\n\n各向同性晶体中的电导率：\n\n$$\n\\sigma_0=\\frac{ne^2\\tau\\left(E_F\\right)}{m^*}\n$$\n\n1. 电子的质量 →有效质量 (能带理论的必然结果)\n2. 弛豫时间只由费米面附近的电子状态决定(量子统计的结果)\n\n### 半导体电子输运过程\n\nE-k 关系：\n\n考虑三维能带的顶部和底部的 E-k 关系，并引入有效质量得到抛物线近似：\n\n$$\nE\\left(k\\right)=E\\left(k_0\\right)+\\frac{\\hbar^2\\left(k_x-k_{0x}\\right)^2}{2m_x^*}+\\frac{\\hbar^2\\left(k_y-k_{0y}\\right)^2}{2m_y^*}+\\frac{\\hbar^2\\left(k_z-k_{0z}\\right)^2}{2m_z^*}\n$$\n\n间接带隙：价带的顶部和导带的底部并不是同一个简约波矢k\n\n直接带隙：价带的顶部和导带的底部是同一个简约波矢k\n\n![1715048162767](../images/SolidPhysics/1715048162767.png)\n\n近似成自由电子：\n\n![1715048234147](../images/SolidPhysics/1715048234147.png)\n\n将自由电子的质量替换为：电子或空穴的有效质量\n\n将自由电子的能量替换为：与导带底或价带顶的能量差\n\n$E_-$: 电子的；$E_+$：空穴的。\n\n$$\nN_-(E)=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\sqrt{(E-E_-)}\\\\N_+(E)=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\sqrt{(E_+-E)}\n$$\n\n费米能量应在 $E_-$ 和 $E_+$ 之间。\n\n$$\nf(E)=\\frac1{e^{(E-E_F)/k_BT}+1}\\approx e^{-(E-E_F)/k_BT}<<1\n$$\n\n据此计算电子的浓度：\n\n$$\n\\begin{aligned}\n&n=\\int_{E_-}^\\infty f(E)N_-(E)dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\int_{E_-}^\\infty e^{-(E-E_F)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_{E_-}^\\infty e^{-(E-E_-)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_0^\\infty\\xi^{1/2}e^{-\\xi}d\\xi  \\\\\n&=\\frac{2(2\\pi m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}=N_-e^{-(E_--E_F)/k_BT}\n\\end{aligned}\n$$\n\n$N_-$ 为有效能级密度。\n\n空穴的浓度：\n\n$$\n\\begin{aligned}\n&p=\\int_{-\\infty}^{E_+}(1-f(E))N_+(E)dE \\\\\n&=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\int_{-\\infty}^{E_+}e^{-(E_F-E)/k_BT}\\sqrt{(E_+-E)}dE \\\\\n&=N_+e^{-(E_F-E_+)/k_BT}\n\\end{aligned}\n$$\n\n$$\nN_+=\\frac{2(2\\pi m_+^*k_BT)^{3/2}}{h^3}\n$$\n\n在计算价带空穴数时可以等效地用价带顶能级E+代替整个价带，价带的空穴数就如同在价带顶E+处集中了N+个能态所含有的空穴数\n\n反直觉的事实：电子浓度与空穴浓度的乘积仅与禁带宽度和温度有关，与费米能级无关。温度一样，电子浓度越高，空穴浓度就越低。\n\n$$\nnp=N_-N_+exp\\biggl(-\\frac{E_--E_+}{k_BT}\\biggr)=N_-N_+exp\\biggl(-\\frac{E_g}{k_BT}\\biggr)\n$$\n\n#### 本征激发\n\n无杂质及缺陷的半导体称为本征半导体\n\n$$\nn_i=n=p=\\left(N_-N_+\\right)^{1/2}e^{-E_g/2k_BT}\n$$\n\n电子数目与空穴数目相同。\n\n$$\n\\begin{aligned}\n&E_{Fi}=E_--k_BT\\ln(N_-/n_i) \\\\\n&=E_++k_BT\\ln(N_+/n_i) \\\\\n&=\\frac12(E_-+E_+)+\\frac12k_BT\\ln(N_+/N_-) \\\\\n&=\\frac12(E_-+E_+)+\\frac34k_BT\\ln(m_+^*/m_-^*)\n\\end{aligned}\n$$\n\n多数半导体的密度分布和金属相反：导带能级密度更大， 价带的更小，也就是说 $N_+>N_-$，即随着温度的升高费米能级在上升。而金属，随着温度的升高，费米能级是下降的。\n\n在一般情况下，由于$k_BT$较小，且$m_h*$和$m_e*$相差不大， 所以，本征半导体的费米能$E_{Fi}$近似地在带隙的中间。\n\n#### 一般半导体\n\n$E_F$ 升高，则电子浓度增大，空穴浓度减小。\n\n通过掺杂来改变载流子的类型和浓度。\n\n#### 杂质与杂质激发\n\n掺杂形成了杂质能级，只在掺杂原子局部地区存在。\n\n处在杂质能级的电子实际上处于束缚态，只在掺杂原子附近存在，对导电性没有贡献。所以，电子从杂质原子跑出来，并不会形成“空穴”，这些“空穴”处于束缚态，并不会导电。\n\n![1715051145151](../images/SolidPhysics/1715051145151.png)\n\n![1715051313166](../images/SolidPhysics/1715051313166.png)\n\n浅能级杂质\n\n- 上述由替位杂质所形成的施主和受主\n- 能级靠近导带或价带，又称为浅能级杂质\n- 杂质能级对电子或空穴的束缚能很小\n- 电子很容易从施主能级跃迁或跃迁到受主能级\n- 载流子将以杂质跃迁产生为主\n\n深能级杂质\n\n\u0001 大多数是多重能级\no 如Au在硅中，有施主能级也有受主能级\no 金为1价，施主能级靠近价带(!)，受主能级靠近禁带中部(!)\n\u0001 深能级杂质附加势作用距离短，1～2个原子\n\u0001 深能级杂质和缺陷影响\no 有效的复合中心，降低载流子寿命\no 做补偿杂质，提高材料电阻率\n\n施主杂质激发\n\n假设N型半导体只含一种施主,浓度$N_D$,能级$E_D$\n\n那么导带中电子数目显然与空的施主能级的数目相等\n\n$$\nn=N_D[1-f(E_D)]=N_D\\left[\\frac{e^{(E_D-E_F)/k_BT}}{e^{(E_D-E_F)/k_BT}+1}\\right]=N_D\\frac1{1+e^{-(E_D-E_F)/k_BT}}\n$$\n\n$E_F$ 在掺杂半导体里求不出来，因此尝试消去它，得到：\n\n温度很低时（$E_i >> k_BT$），少量施主电离激发电子\n\n$$\nn\\approx\\frac{\\left[4\\left(\\frac{N_D}{N_-}\\right)e^{E_i/k_BT}\\right]^{1/2}}{\\left(\\frac2{N_-}\\right)e^{E_i/k_BT}}=\\left(N_-N_D\\right)^{1/2}e^{-E_i/2k_BT}\n$$\n\n温度很高时（$E_i >> k_BT$），全部施主电离激发电子\n\n$$\n\\begin{aligned}n=&\\frac{-1+\\left[1+2{\\left(\\frac{N_D}{N_-}\\right)}e^{E_i/k_BT}+...\\right]}{\\frac2{N_-}e^{E_i/k_BT}}\\approx N_D\\\\\\end{aligned}\n$$\n\n一般室温下热激发到导带的电子数也符合上式，按指数关系随温度升高而增加 （慎用！）\n\n空穴的浓度是\n\n$$\np = (n_i)^2/n\n$$\n\n费米能级\n\n$$\n\\begin{aligned}\nE_{F}& =E_--k_BT\\ln(N_-/n)  \\\\\n&=E_{Fi}+k_BT\\ln(n/n_i)\n\\end{aligned}\n$$\n\n施主杂质的浓度越高，费米能级越靠近导带\n\n受主类似：\n\n温度很低时（$E_i >> k_BT$）\n\n$$\np\\thickapprox\\left(N_AN_+\\right)^{1/2}e^{-E_i/2k_BT}\n$$\n\n温度很高时（$E_i << k_BT$）\n\n$$\np\\approx N_A\n$$\n\n$$\n\\begin{aligned}&E_F=E_++k_BT\\ln(N_+/p)\\\\&=E_{Fi}-k_BT\\ln(p/n_i)\\end{aligned}\n$$\n\n受主杂质的浓度越高，费米能级越靠近价带\n\n考虑施主和受主能级简并和电子自旋取向时引入施主和受主能级基态简并因子gD和gA。\n\n$$\nn=\\frac{-1+\\left[1+4\\left(\\frac{g_DN_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}}\\\\p=\\frac{-1+\\left[1+4\\left(\\frac{g_AN_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}}\n$$\n\n![1715053184570](../images/SolidPhysics/1715053184570.png)\n\n中间的平台区域意味着施主已经给出了所有电子。\n\n在足够高的温度下，由满带到导带的电子激发（本征激发）将成为主要的。\n\n![1715053408715](../images/SolidPhysics/1715053408715.png)\n\n在足够高的温度下，费米能级同样也接近本征费米能级。\n\n以上讨论的是非简并半导体。\n\n对于简并半导体，不能再使用玻尔兹曼分布，只能使用费米-狄拉克分布。\n\n#### 补偿半导体的载流子浓度\n\n完全电离条件下\n\n$$\nn_0+N_a=p_0+N_d\\\\\np_0 = n_i^2/n_0\n$$\n\n$$\nn_0=\\frac{(N_d-N_a)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\\\\\np_0=\\frac{(N_a-N_d)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\n$$\n\nn-type 和 p-type 的效果可以相互抵消。\n\n由于补偿半导体中掺有两种杂质，所以会产生杂质的补偿作用，从而其中能够参加导电的多数载流子，就只有由那些未被补偿的杂质来提供；因此补偿半导体中有效的载流子浓度很小，故电阻率很高。虽然补偿半导体的电阻率很高，但它**不同于未掺杂的本征半导体。**\n\n总的杂质浓度\n\n$$\nN_{doping}{=}N_A{+}N_D\n$$\n\n### 载流子的迁移（漂移）运动\n\n迁移率 $\\mu$：单位电场下载流子的平均漂移速度\n\n$$\n\\sigma=nq\\mu\n$$\n\n$$\nj=nq\\left(\\mu E\\right)\\\\\n\\sigma=\\frac{nq^2\\tau}{m^*}=nq\\frac{q\\tau}{m^*}=nq\\mu\\\\\n\\mu=\\frac{q\\tau}{m^*}\n$$\n\n$$\n\\sigma=nq\\mu_-+pq\\mu_+\n$$\n\n多子导电：\n\n$$\n\\sigma\\approx\\begin{cases}nq\\mu_-&(n\\text{型 })\\\\pq\\mu_+&(p\\text{型 })&\\end{cases}\n$$\n\n迁移率决定于有效质量以及平均弛豫时间\n\n$$\n\\mu_-=\\frac{q\\tau_{cn}}{m_-^*}\\quad\\mu_+=\\frac{q\\tau_{cp}}{m_+^*}\n$$\n\n在低温下，杂质的散射是主要的。温度升高时载流子热运动的速度增大，电离杂质的散射作用相应减弱，从而使迁移率增大。\n\n在较高温度下，晶格的散射是主要的，温度升高，声子的散射增大，因而迁移率随温度的升高而下降。\n\n半导体的电导率σ除了与迁移率有关外，还与载流子的浓度有关。而载流子的浓度随温度的升高以指数形式增加（饱和区除外）。因此除饱和区外，电导率主要以指数形式随温度的升高而迅速增大，表现出很强的热敏性。但是，不是温度越高就越好的，温度升高后，掺杂的特性就没了，导电能力主要由本征激发决定，相当于半导体退化成了一块普通的电阻，也没有什么 PN 结了。\n\n这与金属的电导率有明显不同。因为金属的载流子（电子或空穴）浓度与温度无关，温度升高时，传导电子的迁移率因与声子的碰撞更加频繁而减小，所以金属的导电率温度系数为负，温度升高，电导率下降。\n\n## PN 结\n\n### 功函数\n\n金属发射电流与温度有关，符合指数规律：\n\n$$\nj\\propto e^{\\large-\\frac{W}{k_BT}}\n$$\n\n其中 $W$ 称功函数。\n\n经典理论：\n\n$$\nj=-n_0q\\left(\\frac{k_BT}{2\\pi m}\\right)^{1/2}e^{-\\frac\\chi{k_BT}}\n$$\n\n功函数：\n\n$$\nW = \\chi\n$$\n\n统计分布：\n\n$$\ndn=n_0\\left(\\frac m{2\\pi k_BT}\\right)^{3/2}e^{-\\frac{m\\upsilon^2}{2k_BT}}d\\upsilon\n$$\n\n量子理论：\n\n$$\nj=-q\\frac{4\\pi m{\\left(k_BT\\right)}^2}{\\left(2\\pi\\hbar\\right)^3}e^{-\\left(\\chi-E_F\\right)/k_BT}\n$$\n\n功函数\n\n$$\nW = \\chi - E_F\n$$\n\n统计分布：\n\n$$\ndn=2{\\left(\\frac m{2\\pi\\hbar}\\right)}^3\\frac1{e^{\\left(\\frac12m\\upsilon^2-E_F\\right)/k_BT}+1}d\\upsilon\n$$\n\n金属有接触电势，从费米能级高的地方流向费米能级低的。\n\n![1715657785337](../images/SolidPhysics/1715657785337.png)\n\n$$\nV_A - V_B = (W_B - W_A)/q\n$$\n\n平衡态下，费米能级变为相等，电子不再流动。\n\n### PN 结\n\n载流子扩散运动：\n\n![1715658350241](../images/SolidPhysics/1715658350241.png)\n\n非平衡载流子：复合运动\n\n在外界的作用下，半导体中的电子浓度n和空穴浓度p有可\n能偏离平衡值。例如半导体的本征光吸收产生电子—空穴\n对，用Δn＝n－n0，Δp＝p－p0表示超出热平衡的多余载流\n子，称为非平衡载流子。通常情况下，由于电中性要求，\nΔn＝Δp\n\n我们最关心的是非平衡的少数载流子，因为少子的浓度变化大，通常采用准费米能级 $E_{Fn}, E_{Fp}$。多子的费米能级不变。\n\n$$\n\\begin{aligned}n_0+\\Delta n&=n_i\\exp(\\frac{E_{Fn}-E_{Fi}}{kT})\\\\\\left(n_0+\\Delta n\\right)\\cdot\\left(p_0+\\Delta p\\right)>n_i^2\\\\p_0+\\Delta p&=n_i\\exp(\\frac{E_{Fi}-E_{Fp}}{kT})\\end{aligned}\n$$\n\n![1715658620805](../images/SolidPhysics/1715658620805.png)\n\n外界作用下， 非平衡态要恢复到平衡态。非平衡的载流子会消失，消失的过程叫复合，导带的多余电子落回价带，多余的电子和空穴成对消失。\n\n复合速率：\n\n$$\n\\frac{d\\Delta n}{dt}=-\\frac{\\Delta n}{\\tau}\\\\\\text{其解为:}\\quad\\Delta n=(\\Delta n)_0\\exp(-t/\\tau)\n$$\n\n$\\tau$ 称为非平衡载流子寿命\n\n#### 非平衡载流子的扩散和复合\n\n直接复合：复合率 $R=\\alpha_r\\cdot n\\cdot p$\n\n间接复合：通过杂质能级的间接复合（与杂质浓度呈正比，与非平衡载流子浓度呈正比，深能级更强）\n\n非平衡状态下，过剩电子的复合率一定等于过剩空穴的复合率\n\n$$\nR_n^{\\prime}=R_p^{\\prime}\n$$\n\n扩散复合过程的稳定分布：\n\n$$\n-\\frac d{dx}\\Bigg(-D\\frac{dN}{dx}\\Bigg)-\\frac N\\tau=0\\\\N=N_0e^{-x/L},L=\\sqrt{D\\tau}\n$$\n\n扩散长度L：表面非平衡载流子深入材料内部的距离，随扩散系数和复合寿命增加而增加\n\n$$\n\\text{扩散流密度 }=-D\\frac{dN}{dx}=N_0\\frac DLe^{-x/L}\n$$\n\n扩散速度D/L：界面处载流子以速度D/L运动\n\n漂移 + 扩散 的总电流密度：\n\n$$\nJ=qn\\mu_nE_x+qp\\mu_pE_x+qD_n\\frac{dn}{dx}-qD_p\\frac{dp}{dx}\n$$\n\n爱因斯坦关系：\n\n$$\n\\frac{D_n}{\\mu_n}=\\frac{k_\\text{B}T}q\\quad\\frac{D_p}{\\mu_p}=\\frac{k_\\text{B}T}q\n$$\n\n#### PN 结的接触电势差\n\n![1715659347111](../images/SolidPhysics/1715659347111.png)\n\n$$\neV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\\\\qV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\n$$\n\n$$\n\n\n$$\n\n$V_D$ 等于接触前的费米能级差。\n\n![1715659894626](../images/SolidPhysics/1715659894626.png)\n\n### 正向偏压-载流子扩散运动产生电流\n\np 区看电子，n 区看空穴：\n\n![1716257709851](../images/SolidPhysics/1716257709851.png)\n\n0 表示热平衡时候的浓度。\n\n### 反向偏压-漂移作用增强\n\n![1716257832298](../images/SolidPhysics/1716257832298.png)\n\n![1716257919907](../images/SolidPhysics/1716257919907.png)\n\n正向注入：\n\n当PN结加正向偏压时：$\\mathsf{PN}$结势垒降低为$q(V_D-V)$扩散作用增强\n\n反向抽取：\n\n当PN结加反向偏压时：$\\mathsf{PN}$结势垒升高为$q(V_D+V)$漂移作用增强\n\n反向抽取时载流子的复合率为负数，就是说在不断地产生新的载流子（电子-空穴对）。PN结的反向电流实质上就是产生电流。\n\n![1716258157706](../images/SolidPhysics/1716258157706.png)\n\n### PN 结的击穿\n\n![1716258191070](../images/SolidPhysics/1716258191070.png)\n\n### 双极性晶体管\n\n![1716258575169](../images/SolidPhysics/1716258575169.png)\n\n## 异质结与肖特基结\n\n### 半导体异质结\n\n真空能级：电子自由运动所占据的最低能量。\n\n![1716259850103](../images/SolidPhysics/1716259850103.png)\n\n![1716260746330](../images/SolidPhysics/1716260746330.png)\n\n![1716259893782](../images/SolidPhysics/1716259893782.png)\n\n导带能级差：$\\Delta E_C=\\chi_1-\\chi_2$\n价带能级差：$\\Delta E_v=(\\chi_2+E_{g^2})-(\\chi_1+E_{g^1})=E_{g^2}-E_{g^1}-\\Delta E_{g^2}$\n导带能级差+价带能级差 =带隙宽度差\n注：此为一般半导体物理书中的结果\n\n![1716260901275](../images/SolidPhysics/1716260901275.png)\n\n### 同质结的注入比\n\n总电流：$j= j_n+ j_p= j_s\\left ( e^{qV/ K_BT}- 1\\right )$\n\n注入比定义：总电流中，电子电流与空穴电流的比例\n普通PN结(同质结)\n\n注入到$p$区的电子电流密度为：$j_n= q\\frac {D_n}{L_n}n_P^0\\left ( e^{qV/ k_BT}- 1\\right )$\n\n注入到$n$区的空穴电流密度为：$j_p= q\\frac {D_p}{L_p}p_N^0\\left ( e^{qV/ k_BT}- 1\\right )$\n\n总电流：$j= j_n+ j_p= j_s\\left ( e^{qV/ k_BT}- 1\\right )$\n注入比定义：总电流中，电子电流与空穴电流的比例\n正偏压下的电子注入比：\n\n$$\n\\begin{aligned}&\\frac{j_n}{j_p}=\\frac{D_nn_P^0}{L_n}\\frac{D_pp_N^0}{L_p}=\\frac{D_nL_pn_P^0}{D_pL_np_N^0}\\\\&n_P^0=\\frac{n_i^2}{p_P}\\approx\\frac{n_i^2}{N_A}\\\\&p_{N}^{0}=\\frac{n_{i}^{2}}{n_{N}}\\approx\\frac{n_{i}^{2}}{N_{D}}\\\\&\\frac{j_n}{j_p}=\\frac{D_nL_pN_D}{D_pL_nN_A}\\end{aligned}\n$$\n\n提高注入比的办法,提高N型区的施主杂质浓度\n\n![1716261236429](../images/SolidPhysics/1716261236429.png)\n\n结中电子注入比：\n\n$$\n\\begin{aligned}&\\frac{J_n}{J_p}=\\frac{D_nn_P^0}{L_n}\\left/\\frac{D_pp_N^0}{L_p}\\right.=\\frac{D_nL_pN_D}{D_pL_nN_A}e^{\\frac{E_{gN}-E_{gP}}{k_BT}}\\end{aligned}\n$$\n\n异质结构的优点：\n\n也就是说，N型区的带隙宽度比p型区带隙宽度大，\n可以进一步以指数级增加注入比\n\n提高注入比的意义\n提高晶体管放大系数-异质结双极晶体管HBT\n\n![1716261409659](../images/SolidPhysics/1716261409659.png)\n\n### 激光器\n\n本征光吸收\n\n光照激发价带电子到导带， 形成电子-空穴对的过程\n\n$$\n\\hbar\\omega\\geq E_{_g}\n$$\n\n准动量守恒——竖直跃迁\n\n应当照射结区（空间电荷区）\n\n![1716261766058](../images/SolidPhysics/1716261766058.png)\n\n![1716261781489](../images/SolidPhysics/1716261781489.png)\n\n二维电子气体系提高电子迁移率\n\n![1716262583215](../images/SolidPhysics/1716262583215.png)\n\n![1716262570823](../images/SolidPhysics/1716262570823.png)\n\n### 肖特基结\n\n功函数的物理本质是真空能级与费米能级的差\n\n亲合能：从导带底部到真空能级的能量（真空-导带底）\n\n![1716263334906](../images/SolidPhysics/1716263334906.png)\n\n金属与 N 型半导体的接触：\n\n![1716263526504](../images/SolidPhysics/1716263526504.png)\n\n![1716263538645](../images/SolidPhysics/1716263538645.png)\n\n$$\n\\boxed{\\begin{array}{c}\\text{肖特基势垒}\\\\\\phi_{B0}=\\left(\\phi_m-\\chi\\right)\\end{array}}\n$$\n\n$$\n\\boxed{\\begin{array}{c}\\text{内建电势差}\\\\\\\\V_{bi}=\\left(\\phi_{B0}-\\phi_n\\right)\\end{array}}\n$$\n\n考虑偏压：\n\n![1716263918247](../images/SolidPhysics/1716263918247.png)\n\n![1716263941957](../images/SolidPhysics/1716263941957.png)\n\n![1716863556246](../images/SolidPhysics/1716863556246.png)\n\n欧姆接触\n\n![1716864038557](../images/SolidPhysics/1716864038557.png)\n\n![1716864050264](../images/SolidPhysics/1716864050264.png)\n\n欧姆接触是指金属与半导体的接触，而其接触面的电阻值远小于半导体本身的电阻，不产生明显的附加阻抗，而且不会使半导体内部的平衡载流子浓度发生显著的改变\n\n区分电子和空穴的本质是迁移率的不同。\n\n## 格波\n\n### 一维单原子链\n\n相邻原子间距为\n\n$$\na+(\\mu_{n+1}-\\mu_n)=a+\\delta\n$$\n\n相邻原子的作用力\n\n$$\nF=-\\frac{\\partial\\nu}{\\partial\\delta}\\approx-\\beta\\delta\n$$\n\n左右两边一个原子对中间原子的作用力\n\n$$\nF_{n,n-1}=-\\beta\\left(\\mu_n-\\mu_{n-1}\\right)\\\\\nF_{n,n+1}=-\\beta\\left(\\mu_n-\\mu_{n+1}\\right)\\\\\nF_n=\\beta(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n)\n$$\n\n相邻原子之间的耦合运动方程组\n\n$$\nm\\ddot{\\mu}_n=\\beta\\left(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n\\right)\n$$\n\n通过坐标变换简化方程组，得到简谐振动解\n\n$$\n\\mu_n=Ae^{i(\\omega t-qX_n)}\n$$\n\n其中 $X_n=na$ 是第 n 个原子的平衡位置\n\n将解代入运动方程：\n\n$$\nm{\\left(i\\omega\\right)}^2Ae^{i(\\omega t-qX_n)}=\\beta Ae^{i(\\omega t-qna)}{\\left(e^{-iqa}+e^{iqa}-2\\right)}\n$$\n\n得到色散关系\n\n$$\n\\omega^2=\\frac{2\\beta}m\\Big(1-\\cos\\alpha q\\Big)=\\frac{4\\beta}m\\sin^2\\Bigg(\\frac{aq}2\\Bigg)\n$$\n\n![1716868157804](../images/SolidPhysics/1716868157804.png)\n\n格波有意义的取值只在第一布里渊区，我们只关心格点位置处的取值。\n\n![1716868762789](../images/SolidPhysics/1716868762789.png)\n\n![1717467825452](../images/SolidPhysics/1717467825452.png)\n\n波恩卡门条件下的环状链模型\n\n![1716869179928](../images/SolidPhysics/1716869179928.png)\n\n![1716869156196](../images/SolidPhysics/1716869156196.png)\n\n![1717467681404](../images/SolidPhysics/1717467681404.png)\n\n![1717467815166](../images/SolidPhysics/1717467815166.png)\n\n![1717467885133](../images/SolidPhysics/1717467885133.png)\n\n### 一维双原子链结构\n\n![1717467940325](../images/SolidPhysics/1717467940325.png)\n\nP原子质量：m\n Q原子质量：M\n\n$$\nm\\ddot{\\mu}_{2n}=\\beta(\\mu_{2n+1}+\\mu_{2n-1}-2\\mu_{2n})\\\\M\\ddot{\\mu}_{2n+1}=\\beta(\\mu_{2n+2}+\\mu_{2n}-2\\mu_{2n+1})\n$$\n\n![1717468003069](../images/SolidPhysics/1717468003069.png)\n\n![1717468014637](../images/SolidPhysics/1717468014637.png)\n\n![1717468150691](../images/SolidPhysics/1717468150691.png)\n\n波数 q 的取值范围：\n\n$$\n-\\frac\\pi{2a}<q\\leq\\frac\\pi{2a}\n$$\n\n原胞变大，倒格矢变小，布里渊区变小\n\n$$\nN\\cdot\\left(2aq\\right)=2\\pi h,h=[-N/2,+N/2]\\quad q=\\frac{h\\pi}{Na}\n$$\n\n对于双原子链，有2N个原子，也有2N个格波\n\n![1717468250438](../images/SolidPhysics/1717468250438.png)\n\n![1717468279238](../images/SolidPhysics/1717468279238.png)\n\n![1717468352260](../images/SolidPhysics/1717468352260.png)\n\n![1717468364464](../images/SolidPhysics/1717468364464.png)\n\n相邻原子振动相反，振幅反比于原子质量\n\n对于声学波，相邻原子同步运动,原胞中两种原子的运动是完全一致的振幅和位相\n\n![1717469037238](../images/SolidPhysics/1717469037238.png)\n\n![1717469080107](../images/SolidPhysics/1717469080107.png)\n\n![1717469005887](../images/SolidPhysics/1717469005887.png)\n\nk 代表的是移动一个原胞后的位相差。\n\n简单晶格没有能带折叠，所以没有光学波。\n\n![1717469702087](../images/SolidPhysics/1717469702087.png)\n\n![1717470027229](../images/SolidPhysics/1717470027229.png)\n\n如果问的是“多少个”光学波/声学波，还得×一个 N\n\n横波才能简并，纵波不能。\n\n硅的晶格中虽然只有硅一种原子，但是由于是复式晶格结构，等同于有两种原子，因此也有声学波和光学波\n\n金属铅(Pb)属于面心立方的简单晶格结构，没有光学波只有三支声学波（注：不同方向上有简并）\n\n纵波的速度总是比横波快。\n\n### 晶格振动的量子化——声子\n\n一维谐振子\n\n![1717470756612](../images/SolidPhysics/1717470756612.png)\n\n### 固体热容\n\n$$\nC_V=\\left(\\frac{\\partial\\overline{E}}{\\partial T}\\right)_V\n$$\n\n固体热容主要来自于两个部分\n\n晶格热容：来源于固体的晶格热运动\n\n电子热容：来源于电子的热运动仅在,极低温下，对于金属比较显著，相比晶格热容，一般可忽略不计\n\n![1717473776761](../images/SolidPhysics/1717473776761.png)\n\n经典模型\n\n![1717473805195](../images/SolidPhysics/1717473805195.png)\n\n量子模型\n\n![1718071135404](../images/SolidPhysics/1718071135404.png)\n\n高温情况下\n\n![1718071202034](../images/SolidPhysics/1718071202034.png)\n\n在较高温度时，杜隆-珀替定律成立。即当振子的能量远远大于能量的量子( ħωq)时，量子化效应就可以忽略\n\n![1718071363760](../images/SolidPhysics/1718071363760.png)\n\n爱因斯坦模型\n\n基本假设\n\n晶格中所有原子都具有统一振动频率$\\omega_0$\n\n所有原子的振动是独立的\n\n假设有$N$个原子\n\n![1718071563960](../images/SolidPhysics/1718071563960.png)\n\n![1718071692546](../images/SolidPhysics/1718071692546.png)\n\n爱因斯坦模型较经典模型的改进明显，阐明低温热容趋于零的基本原因\n\n爱因斯坦模型低温段热容下降很陡，与实验值有不相符的问题\n\n原子与原子间的相互作用是很强的，晶格振动是以格波的形式存在，不同格波之间的频率不完全相同，而且有一定分布爱因斯坦模型等效于所有的格波频率相同过于简单\n\n德拜模型\n\n![1718071922789](../images/SolidPhysics/1718071922789.png)\n\n![1718072084533](../images/SolidPhysics/1718072084533.png)\n\n![1718072235738](../images/SolidPhysics/1718072235738.png)\n\n![1718072255786](../images/SolidPhysics/1718072255786.png)\n\n![1718072474995](../images/SolidPhysics/1718072474995.png)\n\n德拜温度\n\n$$\n\\Theta_D=\\frac{\\hbar\\omega_m}{k_B}\n$$\n\n$$\n\\omega_m=\\overline{C}\\bigg[6\\pi^2\\frac NV\\bigg]^{1/3}\n$$\n\n![1718072707268](../images/SolidPhysics/1718072707268.png)\n\n![1718072997880](../images/SolidPhysics/1718072997880.png)\n","source":"_posts/SolidPhysics.md","raw":"---\ntitle: 固体物理\nkatex: true\ndate: 2024-04-16 10:06:07\ntags:\n---\n## 外场中电子运动状态的变化\n\n### 布洛赫电子\n\n#### 布洛赫定理\n\n$$\n\\psi(x+R_n)=e^{ik\\cdot R_n}\\psi(x)\n$$\n\n布洛赫波函数：\n\n$$\n\\boxed{\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}}\n$$\n\n薛定谔方程在周期势场 $V(r)$的本征解。与 $V(r)$有相同的周期。\n\n简约布里渊区和周期布里渊区图景\n\n![1713239832006](../images/SolidPhysics/1713239832006.png)\n\n#### 一维近自由电子近似\n\n利用微扰求解薛定谔方程\n\n零级哈密顿量是自由电子的哈密顿量(索末菲模型),周期性势场的作用看成是微扰\n适用于解释参与共有化运动的外层价电子的运动状态\n\n$$\nH=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+V(x)=H_0+H^{\\prime}\\\\\nV(x)=\\overline{V}+\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}anx\\biggr]\n$$\n\n$$\n\\begin{aligned}&H_0=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+\\overline{V}\\\\&H'=\\sum_{n\\neq0}V_n\\exp\\left(i\\frac{2\\pi nx}a\\right)\\end{aligned}\n$$\n\n基态（零级解）\n\n$$\nE_k^0=\\frac{\\hbar^2k^2}{2m_0}+\\overline{V}\\\\\n\\psi_k^{(0)}=\\frac1{\\sqrt{L}}e^{ikx}\n$$\n\n$$\nk=\\frac{2\\pi l_x}{Na}\n$$\n\n利用波恩卡曼条件看作准连续。\n\n周期性势场的一级微扰\n\n$$\n\\Delta V=\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}{a}nx\\biggr]\n$$\n\n一级修正：\n\n$$\nE_k^{(1)}=\\int\\left(\\psi_k^0\\right)^*[\\Delta V]\\psi_k^0dx=\\left\\langle k|\\Delta V|k\\right\\rangle=0\n$$\n\n二级修正：\n\n$$\nE_k^{(2)}=\\sum_{k^{\\prime}}\\frac{\\left|\\left\\langle k^{\\prime}|\\Delta V|k\\right\\rangle\\right|^2}{E_k^0-E_{k^{\\prime}}^0}\n$$\n\n非简并情况下：\n\n$$\nE_k^{(2)}=\\sum_{n\\neq0}\\frac{\\left|V_n\\right|^2}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi}an\\right)^2\\right]}\n$$\n\nk’对应的波可以看作k状态波在周期性势场各频率分量对应的散射波->自由电子波函数经过周期势场的散射后改变了原有的能量。\n\n波函数的一级修正\n\n$$\n\\psi_k=\\frac1{\\sqrt{L}}e^{ikx}\\left\\{1+\\sum_{n=0}\\frac{V_n}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi n}a\\right)^2\\right]}\\cdot exp\\left[i\\frac{2\\pi}anx\\right]\\right\\}\n$$\n\n$$\n\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}\n$$\n\n被周期函数调幅的平面波。\n\n![1713240457384](../images/SolidPhysics/1713240457384.png)\n\n如果 k 的取值在布里渊区边界 $k=-\\frac{n\\pi}a$，散射波矢$k’=k+\\frac{2\\pi n}a=\\frac{\\pi n}a$，即布拉格定律 $2dsin\\theta=n\\lambda$。此时电子的波函数是 $k$ 和 $k'$ 两个平面波叠加的驻波。\n\n简并状态的处理方法\n\n在布里渊区边界，存在简并状态，能量相等。\n\n### 准经典运动\n\n引入准经典粒子——波包\n\n自由电子和晶体电子速度的定义：\n\n$$\nv(k_0) = \\frac1\\hbar \\bigg[\\frac{d E(k)}{dk}\\bigg]_{k_0}\\\\\nE(k) = \\hbar\\omega\n$$\n\n速度方向垂直于等能面，如果等能面为球面， 速度的方向与 $k$ 相同。\n\n晶体电子的加速度\n\n$$\n\\hbar\\frac{dk}{dt} = F\n$$\n\n由此定义电子的准动量（晶体动量）为 $\\hbar k$。可定义有效质量：\n\n$$\n\\frac{d\\upsilon_a}{dt}=\\frac1{\\hbar^2}\\sum_\\beta F_\\beta\\cdot\\frac{\\partial^2}{\\partial k_\\beta\\partial k_\\alpha}E(k)\\\\\n\\frac{d\\vec{\\upsilon}}{dt}=\\frac1{m_0}\\vec{F}\n$$\n\n有效质量的“倒数”（矩阵的逆）：\n\n$$\n\\frac1{m_{\\alpha\\beta}^*}=\\frac1{\\hbar^2}\\frac{\\partial^2E}{\\partial k_\\alpha\\partial k_\\beta}\n$$\n\n$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_y\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_y^2}&\\dfrac{\\partial^2E}{\\partial k_y\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_z\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_z\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$\n\n选取 $(k_x, k_y, k_z)$ 的主轴方向时\n\n$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&0&0\\\\0&\\dfrac{\\partial^2E}{\\partial k_y^2}&0\\\\\\\\0&0&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$\n\n注意：各方向上的有效质量一般不同\n\n(1) 质量是标量，而有效质量是张量\n晶体中的电子，加速度和外力的方向可以不一致\n (2)质量常值，有效质量是变值，有正有负\n能带顶附近<0 能带底附近>0\n有效质量$m^{*}$与电子质量$m$之间可以有很大的差别， 因为有效质量中实际包含了周期势场的作用\n\n晶体所表现出来的有效质量，原因在于电子波在晶体中传播时与晶格交换动量。\n\n正有效质量状态出现在能带底附近，体现电子从外场获得的动量，加速度为正。\n\n 负有效质量状态出现在能带顶附近，由电子从外场获得动量不足以弥补与晶格的碰撞，加速度为负。\n\n#### 恒定电场下运动\n\n在周期布里渊图景；\n\n在 $k$ 空间里匀速运动\n\n![1713234834861](../images/SolidPhysics/1713234834861.png)\n\n在实际空间中，电子的运动相当复杂：\n\n![1713234874686](../images/SolidPhysics/1713234874686.png)\n\n质量无穷大：驻波解。\n\n拐点不一定是 $\\pi/2a$，结合实际情况。\n\n![1713235941206](../images/SolidPhysics/1713235941206.png)\n\n![1713235941206](../images/SolidPhysics/1713235941206.png)\n\n理想情况（无散射），电子的运动产生震荡的电流。\n\n实际情况下，很难观察到来回震荡。\n\n![1713236189430](../images/SolidPhysics/1713236189430.png)\n\n![1713236233045](../images/SolidPhysics/1713236233045.png)\n\n实际情况：带隙部分反射\n\n存在势垒穿透\n\n隧穿几率：\n\n$$\nf\\propto E\\exp\\left[-\\frac{\\pi^2}\\hbar\\left(2m_0E_g\\right)^{1/2}\\left(\\frac{E_g}{qE}\\right)\\right]\n$$\n\n![1713236269885](../images/SolidPhysics/1713236269885.png)\n\n准经典运动只适合描述弱电场下电子在同一能带中的运动。\n\n### 导体、绝缘体和半导体的能带解释\n\n#### 满带不导电\n\n不加电场：$E(k)=E(-k)$，占据正反方向波矢的概率相等， 相反速度的电子数量也相等，相互抵消；\n\n加电场：k空间里匀速移动，边界上移出的粒子和移入的粒子是一样的，仍然均匀填充。\n\n#### 部分填充能带产生电流\n\n无外场：净电流为0\n\n有外场：k空间分布向一方移动，有净电流\n\n#### 导体的能带模型\n\n部分填充的能带称为导带\n\n![1713236929581](../images/SolidPhysics/1713236929581.png)\n\n#### 非导体的能带模型\n\n电子恰好填满最低的一系列能带，再高的能带全空\n\n满带不导电，空带也不导电\n\n![1713236984022](../images/SolidPhysics/1713236984022.png)\n\n最高的满带的电子容易被激发到上面的空带，从而使两个带皆变成未满带，产生一定的导电性\n\n![1713237069207](../images/SolidPhysics/1713237069207.png)\n\n总结：\n\n![1713237158982](../images/SolidPhysics/1713237158982.png)\n\n#### 半导体能带模型\n\n常温下，T=0K时的满带电子容易被激发到上面的空带，\n从而使两个带皆变成未满带，产生一定的导电性\n\n![1713237357342](../images/SolidPhysics/1713237357342.png)\n\n近满带和空穴\n\n* 速度是电子的速度\n* 但电荷为正\n\n空穴的波矢：\n\n空穴的有效质量，在能带顶部为k_\\mathrm{h}=-k_\\mathrm{e}\n\n正：\n\n$$\n\\frac1{m_h^*}=-\\left(\\frac1{\\hbar^2}\\cdot\\frac{d^2E}{dk^2}\\right)\n$$\n\n## 金属和半导体中的输运过程\n\n### 金属中的电子输运过程\n\n各向同性晶体中的电导率：\n\n$$\n\\sigma_0=\\frac{ne^2\\tau\\left(E_F\\right)}{m^*}\n$$\n\n1. 电子的质量 →有效质量 (能带理论的必然结果)\n2. 弛豫时间只由费米面附近的电子状态决定(量子统计的结果)\n\n### 半导体电子输运过程\n\nE-k 关系：\n\n考虑三维能带的顶部和底部的 E-k 关系，并引入有效质量得到抛物线近似：\n\n$$\nE\\left(k\\right)=E\\left(k_0\\right)+\\frac{\\hbar^2\\left(k_x-k_{0x}\\right)^2}{2m_x^*}+\\frac{\\hbar^2\\left(k_y-k_{0y}\\right)^2}{2m_y^*}+\\frac{\\hbar^2\\left(k_z-k_{0z}\\right)^2}{2m_z^*}\n$$\n\n间接带隙：价带的顶部和导带的底部并不是同一个简约波矢k\n\n直接带隙：价带的顶部和导带的底部是同一个简约波矢k\n\n![1715048162767](../images/SolidPhysics/1715048162767.png)\n\n近似成自由电子：\n\n![1715048234147](../images/SolidPhysics/1715048234147.png)\n\n将自由电子的质量替换为：电子或空穴的有效质量\n\n将自由电子的能量替换为：与导带底或价带顶的能量差\n\n$E_-$: 电子的；$E_+$：空穴的。\n\n$$\nN_-(E)=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\sqrt{(E-E_-)}\\\\N_+(E)=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\sqrt{(E_+-E)}\n$$\n\n费米能量应在 $E_-$ 和 $E_+$ 之间。\n\n$$\nf(E)=\\frac1{e^{(E-E_F)/k_BT}+1}\\approx e^{-(E-E_F)/k_BT}<<1\n$$\n\n据此计算电子的浓度：\n\n$$\n\\begin{aligned}\n&n=\\int_{E_-}^\\infty f(E)N_-(E)dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\int_{E_-}^\\infty e^{-(E-E_F)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_{E_-}^\\infty e^{-(E-E_-)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_0^\\infty\\xi^{1/2}e^{-\\xi}d\\xi  \\\\\n&=\\frac{2(2\\pi m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}=N_-e^{-(E_--E_F)/k_BT}\n\\end{aligned}\n$$\n\n$N_-$ 为有效能级密度。\n\n空穴的浓度：\n\n$$\n\\begin{aligned}\n&p=\\int_{-\\infty}^{E_+}(1-f(E))N_+(E)dE \\\\\n&=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\int_{-\\infty}^{E_+}e^{-(E_F-E)/k_BT}\\sqrt{(E_+-E)}dE \\\\\n&=N_+e^{-(E_F-E_+)/k_BT}\n\\end{aligned}\n$$\n\n$$\nN_+=\\frac{2(2\\pi m_+^*k_BT)^{3/2}}{h^3}\n$$\n\n在计算价带空穴数时可以等效地用价带顶能级E+代替整个价带，价带的空穴数就如同在价带顶E+处集中了N+个能态所含有的空穴数\n\n反直觉的事实：电子浓度与空穴浓度的乘积仅与禁带宽度和温度有关，与费米能级无关。温度一样，电子浓度越高，空穴浓度就越低。\n\n$$\nnp=N_-N_+exp\\biggl(-\\frac{E_--E_+}{k_BT}\\biggr)=N_-N_+exp\\biggl(-\\frac{E_g}{k_BT}\\biggr)\n$$\n\n#### 本征激发\n\n无杂质及缺陷的半导体称为本征半导体\n\n$$\nn_i=n=p=\\left(N_-N_+\\right)^{1/2}e^{-E_g/2k_BT}\n$$\n\n电子数目与空穴数目相同。\n\n$$\n\\begin{aligned}\n&E_{Fi}=E_--k_BT\\ln(N_-/n_i) \\\\\n&=E_++k_BT\\ln(N_+/n_i) \\\\\n&=\\frac12(E_-+E_+)+\\frac12k_BT\\ln(N_+/N_-) \\\\\n&=\\frac12(E_-+E_+)+\\frac34k_BT\\ln(m_+^*/m_-^*)\n\\end{aligned}\n$$\n\n多数半导体的密度分布和金属相反：导带能级密度更大， 价带的更小，也就是说 $N_+>N_-$，即随着温度的升高费米能级在上升。而金属，随着温度的升高，费米能级是下降的。\n\n在一般情况下，由于$k_BT$较小，且$m_h*$和$m_e*$相差不大， 所以，本征半导体的费米能$E_{Fi}$近似地在带隙的中间。\n\n#### 一般半导体\n\n$E_F$ 升高，则电子浓度增大，空穴浓度减小。\n\n通过掺杂来改变载流子的类型和浓度。\n\n#### 杂质与杂质激发\n\n掺杂形成了杂质能级，只在掺杂原子局部地区存在。\n\n处在杂质能级的电子实际上处于束缚态，只在掺杂原子附近存在，对导电性没有贡献。所以，电子从杂质原子跑出来，并不会形成“空穴”，这些“空穴”处于束缚态，并不会导电。\n\n![1715051145151](../images/SolidPhysics/1715051145151.png)\n\n![1715051313166](../images/SolidPhysics/1715051313166.png)\n\n浅能级杂质\n\n- 上述由替位杂质所形成的施主和受主\n- 能级靠近导带或价带，又称为浅能级杂质\n- 杂质能级对电子或空穴的束缚能很小\n- 电子很容易从施主能级跃迁或跃迁到受主能级\n- 载流子将以杂质跃迁产生为主\n\n深能级杂质\n\n\u0001 大多数是多重能级\no 如Au在硅中，有施主能级也有受主能级\no 金为1价，施主能级靠近价带(!)，受主能级靠近禁带中部(!)\n\u0001 深能级杂质附加势作用距离短，1～2个原子\n\u0001 深能级杂质和缺陷影响\no 有效的复合中心，降低载流子寿命\no 做补偿杂质，提高材料电阻率\n\n施主杂质激发\n\n假设N型半导体只含一种施主,浓度$N_D$,能级$E_D$\n\n那么导带中电子数目显然与空的施主能级的数目相等\n\n$$\nn=N_D[1-f(E_D)]=N_D\\left[\\frac{e^{(E_D-E_F)/k_BT}}{e^{(E_D-E_F)/k_BT}+1}\\right]=N_D\\frac1{1+e^{-(E_D-E_F)/k_BT}}\n$$\n\n$E_F$ 在掺杂半导体里求不出来，因此尝试消去它，得到：\n\n温度很低时（$E_i >> k_BT$），少量施主电离激发电子\n\n$$\nn\\approx\\frac{\\left[4\\left(\\frac{N_D}{N_-}\\right)e^{E_i/k_BT}\\right]^{1/2}}{\\left(\\frac2{N_-}\\right)e^{E_i/k_BT}}=\\left(N_-N_D\\right)^{1/2}e^{-E_i/2k_BT}\n$$\n\n温度很高时（$E_i >> k_BT$），全部施主电离激发电子\n\n$$\n\\begin{aligned}n=&\\frac{-1+\\left[1+2{\\left(\\frac{N_D}{N_-}\\right)}e^{E_i/k_BT}+...\\right]}{\\frac2{N_-}e^{E_i/k_BT}}\\approx N_D\\\\\\end{aligned}\n$$\n\n一般室温下热激发到导带的电子数也符合上式，按指数关系随温度升高而增加 （慎用！）\n\n空穴的浓度是\n\n$$\np = (n_i)^2/n\n$$\n\n费米能级\n\n$$\n\\begin{aligned}\nE_{F}& =E_--k_BT\\ln(N_-/n)  \\\\\n&=E_{Fi}+k_BT\\ln(n/n_i)\n\\end{aligned}\n$$\n\n施主杂质的浓度越高，费米能级越靠近导带\n\n受主类似：\n\n温度很低时（$E_i >> k_BT$）\n\n$$\np\\thickapprox\\left(N_AN_+\\right)^{1/2}e^{-E_i/2k_BT}\n$$\n\n温度很高时（$E_i << k_BT$）\n\n$$\np\\approx N_A\n$$\n\n$$\n\\begin{aligned}&E_F=E_++k_BT\\ln(N_+/p)\\\\&=E_{Fi}-k_BT\\ln(p/n_i)\\end{aligned}\n$$\n\n受主杂质的浓度越高，费米能级越靠近价带\n\n考虑施主和受主能级简并和电子自旋取向时引入施主和受主能级基态简并因子gD和gA。\n\n$$\nn=\\frac{-1+\\left[1+4\\left(\\frac{g_DN_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}}\\\\p=\\frac{-1+\\left[1+4\\left(\\frac{g_AN_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}}\n$$\n\n![1715053184570](../images/SolidPhysics/1715053184570.png)\n\n中间的平台区域意味着施主已经给出了所有电子。\n\n在足够高的温度下，由满带到导带的电子激发（本征激发）将成为主要的。\n\n![1715053408715](../images/SolidPhysics/1715053408715.png)\n\n在足够高的温度下，费米能级同样也接近本征费米能级。\n\n以上讨论的是非简并半导体。\n\n对于简并半导体，不能再使用玻尔兹曼分布，只能使用费米-狄拉克分布。\n\n#### 补偿半导体的载流子浓度\n\n完全电离条件下\n\n$$\nn_0+N_a=p_0+N_d\\\\\np_0 = n_i^2/n_0\n$$\n\n$$\nn_0=\\frac{(N_d-N_a)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\\\\\np_0=\\frac{(N_a-N_d)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\n$$\n\nn-type 和 p-type 的效果可以相互抵消。\n\n由于补偿半导体中掺有两种杂质，所以会产生杂质的补偿作用，从而其中能够参加导电的多数载流子，就只有由那些未被补偿的杂质来提供；因此补偿半导体中有效的载流子浓度很小，故电阻率很高。虽然补偿半导体的电阻率很高，但它**不同于未掺杂的本征半导体。**\n\n总的杂质浓度\n\n$$\nN_{doping}{=}N_A{+}N_D\n$$\n\n### 载流子的迁移（漂移）运动\n\n迁移率 $\\mu$：单位电场下载流子的平均漂移速度\n\n$$\n\\sigma=nq\\mu\n$$\n\n$$\nj=nq\\left(\\mu E\\right)\\\\\n\\sigma=\\frac{nq^2\\tau}{m^*}=nq\\frac{q\\tau}{m^*}=nq\\mu\\\\\n\\mu=\\frac{q\\tau}{m^*}\n$$\n\n$$\n\\sigma=nq\\mu_-+pq\\mu_+\n$$\n\n多子导电：\n\n$$\n\\sigma\\approx\\begin{cases}nq\\mu_-&(n\\text{型 })\\\\pq\\mu_+&(p\\text{型 })&\\end{cases}\n$$\n\n迁移率决定于有效质量以及平均弛豫时间\n\n$$\n\\mu_-=\\frac{q\\tau_{cn}}{m_-^*}\\quad\\mu_+=\\frac{q\\tau_{cp}}{m_+^*}\n$$\n\n在低温下，杂质的散射是主要的。温度升高时载流子热运动的速度增大，电离杂质的散射作用相应减弱，从而使迁移率增大。\n\n在较高温度下，晶格的散射是主要的，温度升高，声子的散射增大，因而迁移率随温度的升高而下降。\n\n半导体的电导率σ除了与迁移率有关外，还与载流子的浓度有关。而载流子的浓度随温度的升高以指数形式增加（饱和区除外）。因此除饱和区外，电导率主要以指数形式随温度的升高而迅速增大，表现出很强的热敏性。但是，不是温度越高就越好的，温度升高后，掺杂的特性就没了，导电能力主要由本征激发决定，相当于半导体退化成了一块普通的电阻，也没有什么 PN 结了。\n\n这与金属的电导率有明显不同。因为金属的载流子（电子或空穴）浓度与温度无关，温度升高时，传导电子的迁移率因与声子的碰撞更加频繁而减小，所以金属的导电率温度系数为负，温度升高，电导率下降。\n\n## PN 结\n\n### 功函数\n\n金属发射电流与温度有关，符合指数规律：\n\n$$\nj\\propto e^{\\large-\\frac{W}{k_BT}}\n$$\n\n其中 $W$ 称功函数。\n\n经典理论：\n\n$$\nj=-n_0q\\left(\\frac{k_BT}{2\\pi m}\\right)^{1/2}e^{-\\frac\\chi{k_BT}}\n$$\n\n功函数：\n\n$$\nW = \\chi\n$$\n\n统计分布：\n\n$$\ndn=n_0\\left(\\frac m{2\\pi k_BT}\\right)^{3/2}e^{-\\frac{m\\upsilon^2}{2k_BT}}d\\upsilon\n$$\n\n量子理论：\n\n$$\nj=-q\\frac{4\\pi m{\\left(k_BT\\right)}^2}{\\left(2\\pi\\hbar\\right)^3}e^{-\\left(\\chi-E_F\\right)/k_BT}\n$$\n\n功函数\n\n$$\nW = \\chi - E_F\n$$\n\n统计分布：\n\n$$\ndn=2{\\left(\\frac m{2\\pi\\hbar}\\right)}^3\\frac1{e^{\\left(\\frac12m\\upsilon^2-E_F\\right)/k_BT}+1}d\\upsilon\n$$\n\n金属有接触电势，从费米能级高的地方流向费米能级低的。\n\n![1715657785337](../images/SolidPhysics/1715657785337.png)\n\n$$\nV_A - V_B = (W_B - W_A)/q\n$$\n\n平衡态下，费米能级变为相等，电子不再流动。\n\n### PN 结\n\n载流子扩散运动：\n\n![1715658350241](../images/SolidPhysics/1715658350241.png)\n\n非平衡载流子：复合运动\n\n在外界的作用下，半导体中的电子浓度n和空穴浓度p有可\n能偏离平衡值。例如半导体的本征光吸收产生电子—空穴\n对，用Δn＝n－n0，Δp＝p－p0表示超出热平衡的多余载流\n子，称为非平衡载流子。通常情况下，由于电中性要求，\nΔn＝Δp\n\n我们最关心的是非平衡的少数载流子，因为少子的浓度变化大，通常采用准费米能级 $E_{Fn}, E_{Fp}$。多子的费米能级不变。\n\n$$\n\\begin{aligned}n_0+\\Delta n&=n_i\\exp(\\frac{E_{Fn}-E_{Fi}}{kT})\\\\\\left(n_0+\\Delta n\\right)\\cdot\\left(p_0+\\Delta p\\right)>n_i^2\\\\p_0+\\Delta p&=n_i\\exp(\\frac{E_{Fi}-E_{Fp}}{kT})\\end{aligned}\n$$\n\n![1715658620805](../images/SolidPhysics/1715658620805.png)\n\n外界作用下， 非平衡态要恢复到平衡态。非平衡的载流子会消失，消失的过程叫复合，导带的多余电子落回价带，多余的电子和空穴成对消失。\n\n复合速率：\n\n$$\n\\frac{d\\Delta n}{dt}=-\\frac{\\Delta n}{\\tau}\\\\\\text{其解为:}\\quad\\Delta n=(\\Delta n)_0\\exp(-t/\\tau)\n$$\n\n$\\tau$ 称为非平衡载流子寿命\n\n#### 非平衡载流子的扩散和复合\n\n直接复合：复合率 $R=\\alpha_r\\cdot n\\cdot p$\n\n间接复合：通过杂质能级的间接复合（与杂质浓度呈正比，与非平衡载流子浓度呈正比，深能级更强）\n\n非平衡状态下，过剩电子的复合率一定等于过剩空穴的复合率\n\n$$\nR_n^{\\prime}=R_p^{\\prime}\n$$\n\n扩散复合过程的稳定分布：\n\n$$\n-\\frac d{dx}\\Bigg(-D\\frac{dN}{dx}\\Bigg)-\\frac N\\tau=0\\\\N=N_0e^{-x/L},L=\\sqrt{D\\tau}\n$$\n\n扩散长度L：表面非平衡载流子深入材料内部的距离，随扩散系数和复合寿命增加而增加\n\n$$\n\\text{扩散流密度 }=-D\\frac{dN}{dx}=N_0\\frac DLe^{-x/L}\n$$\n\n扩散速度D/L：界面处载流子以速度D/L运动\n\n漂移 + 扩散 的总电流密度：\n\n$$\nJ=qn\\mu_nE_x+qp\\mu_pE_x+qD_n\\frac{dn}{dx}-qD_p\\frac{dp}{dx}\n$$\n\n爱因斯坦关系：\n\n$$\n\\frac{D_n}{\\mu_n}=\\frac{k_\\text{B}T}q\\quad\\frac{D_p}{\\mu_p}=\\frac{k_\\text{B}T}q\n$$\n\n#### PN 结的接触电势差\n\n![1715659347111](../images/SolidPhysics/1715659347111.png)\n\n$$\neV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\\\\qV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\n$$\n\n$$\n\n\n$$\n\n$V_D$ 等于接触前的费米能级差。\n\n![1715659894626](../images/SolidPhysics/1715659894626.png)\n\n### 正向偏压-载流子扩散运动产生电流\n\np 区看电子，n 区看空穴：\n\n![1716257709851](../images/SolidPhysics/1716257709851.png)\n\n0 表示热平衡时候的浓度。\n\n### 反向偏压-漂移作用增强\n\n![1716257832298](../images/SolidPhysics/1716257832298.png)\n\n![1716257919907](../images/SolidPhysics/1716257919907.png)\n\n正向注入：\n\n当PN结加正向偏压时：$\\mathsf{PN}$结势垒降低为$q(V_D-V)$扩散作用增强\n\n反向抽取：\n\n当PN结加反向偏压时：$\\mathsf{PN}$结势垒升高为$q(V_D+V)$漂移作用增强\n\n反向抽取时载流子的复合率为负数，就是说在不断地产生新的载流子（电子-空穴对）。PN结的反向电流实质上就是产生电流。\n\n![1716258157706](../images/SolidPhysics/1716258157706.png)\n\n### PN 结的击穿\n\n![1716258191070](../images/SolidPhysics/1716258191070.png)\n\n### 双极性晶体管\n\n![1716258575169](../images/SolidPhysics/1716258575169.png)\n\n## 异质结与肖特基结\n\n### 半导体异质结\n\n真空能级：电子自由运动所占据的最低能量。\n\n![1716259850103](../images/SolidPhysics/1716259850103.png)\n\n![1716260746330](../images/SolidPhysics/1716260746330.png)\n\n![1716259893782](../images/SolidPhysics/1716259893782.png)\n\n导带能级差：$\\Delta E_C=\\chi_1-\\chi_2$\n价带能级差：$\\Delta E_v=(\\chi_2+E_{g^2})-(\\chi_1+E_{g^1})=E_{g^2}-E_{g^1}-\\Delta E_{g^2}$\n导带能级差+价带能级差 =带隙宽度差\n注：此为一般半导体物理书中的结果\n\n![1716260901275](../images/SolidPhysics/1716260901275.png)\n\n### 同质结的注入比\n\n总电流：$j= j_n+ j_p= j_s\\left ( e^{qV/ K_BT}- 1\\right )$\n\n注入比定义：总电流中，电子电流与空穴电流的比例\n普通PN结(同质结)\n\n注入到$p$区的电子电流密度为：$j_n= q\\frac {D_n}{L_n}n_P^0\\left ( e^{qV/ k_BT}- 1\\right )$\n\n注入到$n$区的空穴电流密度为：$j_p= q\\frac {D_p}{L_p}p_N^0\\left ( e^{qV/ k_BT}- 1\\right )$\n\n总电流：$j= j_n+ j_p= j_s\\left ( e^{qV/ k_BT}- 1\\right )$\n注入比定义：总电流中，电子电流与空穴电流的比例\n正偏压下的电子注入比：\n\n$$\n\\begin{aligned}&\\frac{j_n}{j_p}=\\frac{D_nn_P^0}{L_n}\\frac{D_pp_N^0}{L_p}=\\frac{D_nL_pn_P^0}{D_pL_np_N^0}\\\\&n_P^0=\\frac{n_i^2}{p_P}\\approx\\frac{n_i^2}{N_A}\\\\&p_{N}^{0}=\\frac{n_{i}^{2}}{n_{N}}\\approx\\frac{n_{i}^{2}}{N_{D}}\\\\&\\frac{j_n}{j_p}=\\frac{D_nL_pN_D}{D_pL_nN_A}\\end{aligned}\n$$\n\n提高注入比的办法,提高N型区的施主杂质浓度\n\n![1716261236429](../images/SolidPhysics/1716261236429.png)\n\n结中电子注入比：\n\n$$\n\\begin{aligned}&\\frac{J_n}{J_p}=\\frac{D_nn_P^0}{L_n}\\left/\\frac{D_pp_N^0}{L_p}\\right.=\\frac{D_nL_pN_D}{D_pL_nN_A}e^{\\frac{E_{gN}-E_{gP}}{k_BT}}\\end{aligned}\n$$\n\n异质结构的优点：\n\n也就是说，N型区的带隙宽度比p型区带隙宽度大，\n可以进一步以指数级增加注入比\n\n提高注入比的意义\n提高晶体管放大系数-异质结双极晶体管HBT\n\n![1716261409659](../images/SolidPhysics/1716261409659.png)\n\n### 激光器\n\n本征光吸收\n\n光照激发价带电子到导带， 形成电子-空穴对的过程\n\n$$\n\\hbar\\omega\\geq E_{_g}\n$$\n\n准动量守恒——竖直跃迁\n\n应当照射结区（空间电荷区）\n\n![1716261766058](../images/SolidPhysics/1716261766058.png)\n\n![1716261781489](../images/SolidPhysics/1716261781489.png)\n\n二维电子气体系提高电子迁移率\n\n![1716262583215](../images/SolidPhysics/1716262583215.png)\n\n![1716262570823](../images/SolidPhysics/1716262570823.png)\n\n### 肖特基结\n\n功函数的物理本质是真空能级与费米能级的差\n\n亲合能：从导带底部到真空能级的能量（真空-导带底）\n\n![1716263334906](../images/SolidPhysics/1716263334906.png)\n\n金属与 N 型半导体的接触：\n\n![1716263526504](../images/SolidPhysics/1716263526504.png)\n\n![1716263538645](../images/SolidPhysics/1716263538645.png)\n\n$$\n\\boxed{\\begin{array}{c}\\text{肖特基势垒}\\\\\\phi_{B0}=\\left(\\phi_m-\\chi\\right)\\end{array}}\n$$\n\n$$\n\\boxed{\\begin{array}{c}\\text{内建电势差}\\\\\\\\V_{bi}=\\left(\\phi_{B0}-\\phi_n\\right)\\end{array}}\n$$\n\n考虑偏压：\n\n![1716263918247](../images/SolidPhysics/1716263918247.png)\n\n![1716263941957](../images/SolidPhysics/1716263941957.png)\n\n![1716863556246](../images/SolidPhysics/1716863556246.png)\n\n欧姆接触\n\n![1716864038557](../images/SolidPhysics/1716864038557.png)\n\n![1716864050264](../images/SolidPhysics/1716864050264.png)\n\n欧姆接触是指金属与半导体的接触，而其接触面的电阻值远小于半导体本身的电阻，不产生明显的附加阻抗，而且不会使半导体内部的平衡载流子浓度发生显著的改变\n\n区分电子和空穴的本质是迁移率的不同。\n\n## 格波\n\n### 一维单原子链\n\n相邻原子间距为\n\n$$\na+(\\mu_{n+1}-\\mu_n)=a+\\delta\n$$\n\n相邻原子的作用力\n\n$$\nF=-\\frac{\\partial\\nu}{\\partial\\delta}\\approx-\\beta\\delta\n$$\n\n左右两边一个原子对中间原子的作用力\n\n$$\nF_{n,n-1}=-\\beta\\left(\\mu_n-\\mu_{n-1}\\right)\\\\\nF_{n,n+1}=-\\beta\\left(\\mu_n-\\mu_{n+1}\\right)\\\\\nF_n=\\beta(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n)\n$$\n\n相邻原子之间的耦合运动方程组\n\n$$\nm\\ddot{\\mu}_n=\\beta\\left(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n\\right)\n$$\n\n通过坐标变换简化方程组，得到简谐振动解\n\n$$\n\\mu_n=Ae^{i(\\omega t-qX_n)}\n$$\n\n其中 $X_n=na$ 是第 n 个原子的平衡位置\n\n将解代入运动方程：\n\n$$\nm{\\left(i\\omega\\right)}^2Ae^{i(\\omega t-qX_n)}=\\beta Ae^{i(\\omega t-qna)}{\\left(e^{-iqa}+e^{iqa}-2\\right)}\n$$\n\n得到色散关系\n\n$$\n\\omega^2=\\frac{2\\beta}m\\Big(1-\\cos\\alpha q\\Big)=\\frac{4\\beta}m\\sin^2\\Bigg(\\frac{aq}2\\Bigg)\n$$\n\n![1716868157804](../images/SolidPhysics/1716868157804.png)\n\n格波有意义的取值只在第一布里渊区，我们只关心格点位置处的取值。\n\n![1716868762789](../images/SolidPhysics/1716868762789.png)\n\n![1717467825452](../images/SolidPhysics/1717467825452.png)\n\n波恩卡门条件下的环状链模型\n\n![1716869179928](../images/SolidPhysics/1716869179928.png)\n\n![1716869156196](../images/SolidPhysics/1716869156196.png)\n\n![1717467681404](../images/SolidPhysics/1717467681404.png)\n\n![1717467815166](../images/SolidPhysics/1717467815166.png)\n\n![1717467885133](../images/SolidPhysics/1717467885133.png)\n\n### 一维双原子链结构\n\n![1717467940325](../images/SolidPhysics/1717467940325.png)\n\nP原子质量：m\n Q原子质量：M\n\n$$\nm\\ddot{\\mu}_{2n}=\\beta(\\mu_{2n+1}+\\mu_{2n-1}-2\\mu_{2n})\\\\M\\ddot{\\mu}_{2n+1}=\\beta(\\mu_{2n+2}+\\mu_{2n}-2\\mu_{2n+1})\n$$\n\n![1717468003069](../images/SolidPhysics/1717468003069.png)\n\n![1717468014637](../images/SolidPhysics/1717468014637.png)\n\n![1717468150691](../images/SolidPhysics/1717468150691.png)\n\n波数 q 的取值范围：\n\n$$\n-\\frac\\pi{2a}<q\\leq\\frac\\pi{2a}\n$$\n\n原胞变大，倒格矢变小，布里渊区变小\n\n$$\nN\\cdot\\left(2aq\\right)=2\\pi h,h=[-N/2,+N/2]\\quad q=\\frac{h\\pi}{Na}\n$$\n\n对于双原子链，有2N个原子，也有2N个格波\n\n![1717468250438](../images/SolidPhysics/1717468250438.png)\n\n![1717468279238](../images/SolidPhysics/1717468279238.png)\n\n![1717468352260](../images/SolidPhysics/1717468352260.png)\n\n![1717468364464](../images/SolidPhysics/1717468364464.png)\n\n相邻原子振动相反，振幅反比于原子质量\n\n对于声学波，相邻原子同步运动,原胞中两种原子的运动是完全一致的振幅和位相\n\n![1717469037238](../images/SolidPhysics/1717469037238.png)\n\n![1717469080107](../images/SolidPhysics/1717469080107.png)\n\n![1717469005887](../images/SolidPhysics/1717469005887.png)\n\nk 代表的是移动一个原胞后的位相差。\n\n简单晶格没有能带折叠，所以没有光学波。\n\n![1717469702087](../images/SolidPhysics/1717469702087.png)\n\n![1717470027229](../images/SolidPhysics/1717470027229.png)\n\n如果问的是“多少个”光学波/声学波，还得×一个 N\n\n横波才能简并，纵波不能。\n\n硅的晶格中虽然只有硅一种原子，但是由于是复式晶格结构，等同于有两种原子，因此也有声学波和光学波\n\n金属铅(Pb)属于面心立方的简单晶格结构，没有光学波只有三支声学波（注：不同方向上有简并）\n\n纵波的速度总是比横波快。\n\n### 晶格振动的量子化——声子\n\n一维谐振子\n\n![1717470756612](../images/SolidPhysics/1717470756612.png)\n\n### 固体热容\n\n$$\nC_V=\\left(\\frac{\\partial\\overline{E}}{\\partial T}\\right)_V\n$$\n\n固体热容主要来自于两个部分\n\n晶格热容：来源于固体的晶格热运动\n\n电子热容：来源于电子的热运动仅在,极低温下，对于金属比较显著，相比晶格热容，一般可忽略不计\n\n![1717473776761](../images/SolidPhysics/1717473776761.png)\n\n经典模型\n\n![1717473805195](../images/SolidPhysics/1717473805195.png)\n\n量子模型\n\n![1718071135404](../images/SolidPhysics/1718071135404.png)\n\n高温情况下\n\n![1718071202034](../images/SolidPhysics/1718071202034.png)\n\n在较高温度时，杜隆-珀替定律成立。即当振子的能量远远大于能量的量子( ħωq)时，量子化效应就可以忽略\n\n![1718071363760](../images/SolidPhysics/1718071363760.png)\n\n爱因斯坦模型\n\n基本假设\n\n晶格中所有原子都具有统一振动频率$\\omega_0$\n\n所有原子的振动是独立的\n\n假设有$N$个原子\n\n![1718071563960](../images/SolidPhysics/1718071563960.png)\n\n![1718071692546](../images/SolidPhysics/1718071692546.png)\n\n爱因斯坦模型较经典模型的改进明显，阐明低温热容趋于零的基本原因\n\n爱因斯坦模型低温段热容下降很陡，与实验值有不相符的问题\n\n原子与原子间的相互作用是很强的，晶格振动是以格波的形式存在，不同格波之间的频率不完全相同，而且有一定分布爱因斯坦模型等效于所有的格波频率相同过于简单\n\n德拜模型\n\n![1718071922789](../images/SolidPhysics/1718071922789.png)\n\n![1718072084533](../images/SolidPhysics/1718072084533.png)\n\n![1718072235738](../images/SolidPhysics/1718072235738.png)\n\n![1718072255786](../images/SolidPhysics/1718072255786.png)\n\n![1718072474995](../images/SolidPhysics/1718072474995.png)\n\n德拜温度\n\n$$\n\\Theta_D=\\frac{\\hbar\\omega_m}{k_B}\n$$\n\n$$\n\\omega_m=\\overline{C}\\bigg[6\\pi^2\\frac NV\\bigg]^{1/3}\n$$\n\n![1718072707268](../images/SolidPhysics/1718072707268.png)\n\n![1718072997880](../images/SolidPhysics/1718072997880.png)\n","slug":"SolidPhysics","published":1,"updated":"2024-06-11T02:30:00.585Z","_id":"clv3g63km0002uwugbdidb177","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"外场中电子运动状态的变化\"><a href=\"#外场中电子运动状态的变化\" class=\"headerlink\" title=\"外场中电子运动状态的变化\"></a>外场中电子运动状态的变化</h2><h3 id=\"布洛赫电子\"><a href=\"#布洛赫电子\" class=\"headerlink\" title=\"布洛赫电子\"></a>布洛赫电子</h3><h4 id=\"布洛赫定理\"><a href=\"#布洛赫定理\" class=\"headerlink\" title=\"布洛赫定理\"></a>布洛赫定理</h4><div>$$\n\\psi(x+R_n)=e^{ik\\cdot R_n}\\psi(x)\n$$</div>\n\n<p>布洛赫波函数：</p>\n<div>$$\n\\boxed{\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}}\n$$</div>\n\n<p>薛定谔方程在周期势场 $V(r)$的本征解。与 $V(r)$有相同的周期。</p>\n<p>简约布里渊区和周期布里渊区图景</p>\n<p><img src=\"/../images/SolidPhysics/1713239832006.png\" alt=\"1713239832006\" loading=\"lazy\"></p>\n<h4 id=\"一维近自由电子近似\"><a href=\"#一维近自由电子近似\" class=\"headerlink\" title=\"一维近自由电子近似\"></a>一维近自由电子近似</h4><p>利用微扰求解薛定谔方程</p>\n<p>零级哈密顿量是自由电子的哈密顿量(索末菲模型),周期性势场的作用看成是微扰<br>适用于解释参与共有化运动的外层价电子的运动状态</p>\n<div>$$\nH=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+V(x)=H_0+H^{\\prime}\\\\\nV(x)=\\overline{V}+\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}anx\\biggr]\n$$</div>\n\n<div>$$\n\\begin{aligned}&H_0=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+\\overline{V}\\\\&H'=\\sum_{n\\neq0}V_n\\exp\\left(i\\frac{2\\pi nx}a\\right)\\end{aligned}\n$$</div>\n\n<p>基态（零级解）</p>\n<div>$$\nE_k^0=\\frac{\\hbar^2k^2}{2m_0}+\\overline{V}\\\\\n\\psi_k^{(0)}=\\frac1{\\sqrt{L}}e^{ikx}\n$$</div>\n\n<div>$$\nk=\\frac{2\\pi l_x}{Na}\n$$</div>\n\n<p>利用波恩卡曼条件看作准连续。</p>\n<p>周期性势场的一级微扰</p>\n<div>$$\n\\Delta V=\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}{a}nx\\biggr]\n$$</div>\n\n<p>一级修正：</p>\n<div>$$\nE_k^{(1)}=\\int\\left(\\psi_k^0\\right)^*[\\Delta V]\\psi_k^0dx=\\left\\langle k|\\Delta V|k\\right\\rangle=0\n$$</div>\n\n<p>二级修正：</p>\n<div>$$\nE_k^{(2)}=\\sum_{k^{\\prime}}\\frac{\\left|\\left\\langle k^{\\prime}|\\Delta V|k\\right\\rangle\\right|^2}{E_k^0-E_{k^{\\prime}}^0}\n$$</div>\n\n<p>非简并情况下：</p>\n<div>$$\nE_k^{(2)}=\\sum_{n\\neq0}\\frac{\\left|V_n\\right|^2}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi}an\\right)^2\\right]}\n$$</div>\n\n<p>k’对应的波可以看作k状态波在周期性势场各频率分量对应的散射波-&gt;自由电子波函数经过周期势场的散射后改变了原有的能量。</p>\n<p>波函数的一级修正</p>\n<div>$$\n\\psi_k=\\frac1{\\sqrt{L}}e^{ikx}\\left\\lbrace1+\\sum_{n=0}\\frac{V_n}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi n}a\\right)^2\\right]}\\cdot exp\\left[i\\frac{2\\pi}anx\\right]\\right\\rbrace\n$$</div>\n\n<div>$$\n\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}\n$$</div>\n\n<p>被周期函数调幅的平面波。</p>\n<p><img src=\"/../images/SolidPhysics/1713240457384.png\" alt=\"1713240457384\" loading=\"lazy\"></p>\n<p>如果 k 的取值在布里渊区边界 $k&#x3D;-\\frac{n\\pi}a$，散射波矢$k’&#x3D;k+\\frac{2\\pi n}a&#x3D;\\frac{\\pi n}a$，即布拉格定律 $2dsin\\theta&#x3D;n\\lambda$。此时电子的波函数是 $k$ 和 $k’$ 两个平面波叠加的驻波。</p>\n<p>简并状态的处理方法</p>\n<p>在布里渊区边界，存在简并状态，能量相等。</p>\n<h3 id=\"准经典运动\"><a href=\"#准经典运动\" class=\"headerlink\" title=\"准经典运动\"></a>准经典运动</h3><p>引入准经典粒子——波包</p>\n<p>自由电子和晶体电子速度的定义：</p>\n<div>$$\nv(k_0) = \\frac1\\hbar \\bigg[\\frac{d E(k)}{dk}\\bigg]_{k_0}\\\\\nE(k) = \\hbar\\omega\n$$</div>\n\n<p>速度方向垂直于等能面，如果等能面为球面， 速度的方向与 $k$ 相同。</p>\n<p>晶体电子的加速度</p>\n<div>$$\n\\hbar\\frac{dk}{dt} = F\n$$</div>\n\n<p>由此定义电子的准动量（晶体动量）为 $\\hbar k$。可定义有效质量：</p>\n<div>$$\n\\frac{d\\upsilon_a}{dt}=\\frac1{\\hbar^2}\\sum_\\beta F_\\beta\\cdot\\frac{\\partial^2}{\\partial k_\\beta\\partial k_\\alpha}E(k)\\\\\n\\frac{d\\vec{\\upsilon}}{dt}=\\frac1{m_0}\\vec{F}\n$$</div>\n\n<p>有效质量的“倒数”（矩阵的逆）：</p>\n<div>$$\n\\frac1{m_{\\alpha\\beta}^*}=\\frac1{\\hbar^2}\\frac{\\partial^2E}{\\partial k_\\alpha\\partial k_\\beta}\n$$</div>\n\n<div>$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_y\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_y^2}&\\dfrac{\\partial^2E}{\\partial k_y\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_z\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_z\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$</div>\n\n<p>选取 $(k_x, k_y, k_z)$ 的主轴方向时</p>\n<div>$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&0&0\\\\0&\\dfrac{\\partial^2E}{\\partial k_y^2}&0\\\\\\\\0&0&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$</div>\n\n<p>注意：各方向上的有效质量一般不同</p>\n<p>(1) 质量是标量，而有效质量是张量<br>晶体中的电子，加速度和外力的方向可以不一致<br> (2)质量常值，有效质量是变值，有正有负<br>能带顶附近&lt;0 能带底附近&gt;0<br>有效质量$m^{*}$与电子质量$m$之间可以有很大的差别， 因为有效质量中实际包含了周期势场的作用</p>\n<p>晶体所表现出来的有效质量，原因在于电子波在晶体中传播时与晶格交换动量。</p>\n<p>正有效质量状态出现在能带底附近，体现电子从外场获得的动量，加速度为正。</p>\n<p> 负有效质量状态出现在能带顶附近，由电子从外场获得动量不足以弥补与晶格的碰撞，加速度为负。</p>\n<h4 id=\"恒定电场下运动\"><a href=\"#恒定电场下运动\" class=\"headerlink\" title=\"恒定电场下运动\"></a>恒定电场下运动</h4><p>在周期布里渊图景；</p>\n<p>在 $k$ 空间里匀速运动</p>\n<p><img src=\"/../images/SolidPhysics/1713234834861.png\" alt=\"1713234834861\" loading=\"lazy\"></p>\n<p>在实际空间中，电子的运动相当复杂：</p>\n<p><img src=\"/../images/SolidPhysics/1713234874686.png\" alt=\"1713234874686\" loading=\"lazy\"></p>\n<p>质量无穷大：驻波解。</p>\n<p>拐点不一定是 $\\pi&#x2F;2a$，结合实际情况。</p>\n<p><img src=\"/../images/SolidPhysics/1713235941206.png\" alt=\"1713235941206\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1713235941206.png\" alt=\"1713235941206\" loading=\"lazy\"></p>\n<p>理想情况（无散射），电子的运动产生震荡的电流。</p>\n<p>实际情况下，很难观察到来回震荡。</p>\n<p><img src=\"/../images/SolidPhysics/1713236189430.png\" alt=\"1713236189430\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1713236233045.png\" alt=\"1713236233045\" loading=\"lazy\"></p>\n<p>实际情况：带隙部分反射</p>\n<p>存在势垒穿透</p>\n<p>隧穿几率：</p>\n<div>$$\nf\\propto E\\exp\\left[-\\frac{\\pi^2}\\hbar\\left(2m_0E_g\\right)^{1/2}\\left(\\frac{E_g}{qE}\\right)\\right]\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1713236269885.png\" alt=\"1713236269885\" loading=\"lazy\"></p>\n<p>准经典运动只适合描述弱电场下电子在同一能带中的运动。</p>\n<h3 id=\"导体、绝缘体和半导体的能带解释\"><a href=\"#导体、绝缘体和半导体的能带解释\" class=\"headerlink\" title=\"导体、绝缘体和半导体的能带解释\"></a>导体、绝缘体和半导体的能带解释</h3><h4 id=\"满带不导电\"><a href=\"#满带不导电\" class=\"headerlink\" title=\"满带不导电\"></a>满带不导电</h4><p>不加电场：$E(k)&#x3D;E(-k)$，占据正反方向波矢的概率相等， 相反速度的电子数量也相等，相互抵消；</p>\n<p>加电场：k空间里匀速移动，边界上移出的粒子和移入的粒子是一样的，仍然均匀填充。</p>\n<h4 id=\"部分填充能带产生电流\"><a href=\"#部分填充能带产生电流\" class=\"headerlink\" title=\"部分填充能带产生电流\"></a>部分填充能带产生电流</h4><p>无外场：净电流为0</p>\n<p>有外场：k空间分布向一方移动，有净电流</p>\n<h4 id=\"导体的能带模型\"><a href=\"#导体的能带模型\" class=\"headerlink\" title=\"导体的能带模型\"></a>导体的能带模型</h4><p>部分填充的能带称为导带</p>\n<p><img src=\"/../images/SolidPhysics/1713236929581.png\" alt=\"1713236929581\" loading=\"lazy\"></p>\n<h4 id=\"非导体的能带模型\"><a href=\"#非导体的能带模型\" class=\"headerlink\" title=\"非导体的能带模型\"></a>非导体的能带模型</h4><p>电子恰好填满最低的一系列能带，再高的能带全空</p>\n<p>满带不导电，空带也不导电</p>\n<p><img src=\"/../images/SolidPhysics/1713236984022.png\" alt=\"1713236984022\" loading=\"lazy\"></p>\n<p>最高的满带的电子容易被激发到上面的空带，从而使两个带皆变成未满带，产生一定的导电性</p>\n<p><img src=\"/../images/SolidPhysics/1713237069207.png\" alt=\"1713237069207\" loading=\"lazy\"></p>\n<p>总结：</p>\n<p><img src=\"/../images/SolidPhysics/1713237158982.png\" alt=\"1713237158982\" loading=\"lazy\"></p>\n<h4 id=\"半导体能带模型\"><a href=\"#半导体能带模型\" class=\"headerlink\" title=\"半导体能带模型\"></a>半导体能带模型</h4><p>常温下，T&#x3D;0K时的满带电子容易被激发到上面的空带，<br>从而使两个带皆变成未满带，产生一定的导电性</p>\n<p><img src=\"/../images/SolidPhysics/1713237357342.png\" alt=\"1713237357342\" loading=\"lazy\"></p>\n<p>近满带和空穴</p>\n<ul>\n<li>速度是电子的速度</li>\n<li>但电荷为正</li>\n</ul>\n<p>空穴的波矢：</p>\n<p>空穴的有效质量，在能带顶部为k_\\mathrm{h}&#x3D;-k_\\mathrm{e}</p>\n<p>正：</p>\n<div>$$\n\\frac1{m_h^*}=-\\left(\\frac1{\\hbar^2}\\cdot\\frac{d^2E}{dk^2}\\right)\n$$</div>\n\n<h2 id=\"金属和半导体中的输运过程\"><a href=\"#金属和半导体中的输运过程\" class=\"headerlink\" title=\"金属和半导体中的输运过程\"></a>金属和半导体中的输运过程</h2><h3 id=\"金属中的电子输运过程\"><a href=\"#金属中的电子输运过程\" class=\"headerlink\" title=\"金属中的电子输运过程\"></a>金属中的电子输运过程</h3><p>各向同性晶体中的电导率：</p>\n<div>$$\n\\sigma_0=\\frac{ne^2\\tau\\left(E_F\\right)}{m^*}\n$$</div>\n\n<ol>\n<li>电子的质量 →有效质量 (能带理论的必然结果)</li>\n<li>弛豫时间只由费米面附近的电子状态决定(量子统计的结果)</li>\n</ol>\n<h3 id=\"半导体电子输运过程\"><a href=\"#半导体电子输运过程\" class=\"headerlink\" title=\"半导体电子输运过程\"></a>半导体电子输运过程</h3><p>E-k 关系：</p>\n<p>考虑三维能带的顶部和底部的 E-k 关系，并引入有效质量得到抛物线近似：</p>\n<div>$$\nE\\left(k\\right)=E\\left(k_0\\right)+\\frac{\\hbar^2\\left(k_x-k_{0x}\\right)^2}{2m_x^*}+\\frac{\\hbar^2\\left(k_y-k_{0y}\\right)^2}{2m_y^*}+\\frac{\\hbar^2\\left(k_z-k_{0z}\\right)^2}{2m_z^*}\n$$</div>\n\n<p>间接带隙：价带的顶部和导带的底部并不是同一个简约波矢k</p>\n<p>直接带隙：价带的顶部和导带的底部是同一个简约波矢k</p>\n<p><img src=\"/../images/SolidPhysics/1715048162767.png\" alt=\"1715048162767\" loading=\"lazy\"></p>\n<p>近似成自由电子：</p>\n<p><img src=\"/../images/SolidPhysics/1715048234147.png\" alt=\"1715048234147\" loading=\"lazy\"></p>\n<p>将自由电子的质量替换为：电子或空穴的有效质量</p>\n<p>将自由电子的能量替换为：与导带底或价带顶的能量差</p>\n<p>$E_-$: 电子的；$E_+$：空穴的。</p>\n<div>$$\nN_-(E)=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\sqrt{(E-E_-)}\\\\N_+(E)=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\sqrt{(E_+-E)}\n$$</div>\n\n<p>费米能量应在 $E_-$ 和 $E_+$ 之间。</p>\n<div>$$\nf(E)=\\frac1{e^{(E-E_F)/k_BT}+1}\\approx e^{-(E-E_F)/k_BT}<<1\n$$</div>\n\n<p>据此计算电子的浓度：</p>\n<div>$$\n\\begin{aligned}\n&n=\\int_{E_-}^\\infty f(E)N_-(E)dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\int_{E_-}^\\infty e^{-(E-E_F)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_{E_-}^\\infty e^{-(E-E_-)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_0^\\infty\\xi^{1/2}e^{-\\xi}d\\xi  \\\\\n&=\\frac{2(2\\pi m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}=N_-e^{-(E_--E_F)/k_BT}\n\\end{aligned}\n$$</div>\n\n<p>$N_-$ 为有效能级密度。</p>\n<p>空穴的浓度：</p>\n<div>$$\n\\begin{aligned}\n&p=\\int_{-\\infty}^{E_+}(1-f(E))N_+(E)dE \\\\\n&=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\int_{-\\infty}^{E_+}e^{-(E_F-E)/k_BT}\\sqrt{(E_+-E)}dE \\\\\n&=N_+e^{-(E_F-E_+)/k_BT}\n\\end{aligned}\n$$</div>\n\n<div>$$\nN_+=\\frac{2(2\\pi m_+^*k_BT)^{3/2}}{h^3}\n$$</div>\n\n<p>在计算价带空穴数时可以等效地用价带顶能级E+代替整个价带，价带的空穴数就如同在价带顶E+处集中了N+个能态所含有的空穴数</p>\n<p>反直觉的事实：电子浓度与空穴浓度的乘积仅与禁带宽度和温度有关，与费米能级无关。温度一样，电子浓度越高，空穴浓度就越低。</p>\n<div>$$\nnp=N_-N_+exp\\biggl(-\\frac{E_--E_+}{k_BT}\\biggr)=N_-N_+exp\\biggl(-\\frac{E_g}{k_BT}\\biggr)\n$$</div>\n\n<h4 id=\"本征激发\"><a href=\"#本征激发\" class=\"headerlink\" title=\"本征激发\"></a>本征激发</h4><p>无杂质及缺陷的半导体称为本征半导体</p>\n<div>$$\nn_i=n=p=\\left(N_-N_+\\right)^{1/2}e^{-E_g/2k_BT}\n$$</div>\n\n<p>电子数目与空穴数目相同。</p>\n<div>$$\n\\begin{aligned}\n&E_{Fi}=E_--k_BT\\ln(N_-/n_i) \\\\\n&=E_++k_BT\\ln(N_+/n_i) \\\\\n&=\\frac12(E_-+E_+)+\\frac12k_BT\\ln(N_+/N_-) \\\\\n&=\\frac12(E_-+E_+)+\\frac34k_BT\\ln(m_+^*/m_-^*)\n\\end{aligned}\n$$</div>\n\n<p>多数半导体的密度分布和金属相反：导带能级密度更大， 价带的更小，也就是说 $N_+&gt;N_-$，即随着温度的升高费米能级在上升。而金属，随着温度的升高，费米能级是下降的。</p>\n<p>在一般情况下，由于$k_BT$较小，且$m_h*$和$m_e*$相差不大， 所以，本征半导体的费米能$E_{Fi}$近似地在带隙的中间。</p>\n<h4 id=\"一般半导体\"><a href=\"#一般半导体\" class=\"headerlink\" title=\"一般半导体\"></a>一般半导体</h4><p>$E_F$ 升高，则电子浓度增大，空穴浓度减小。</p>\n<p>通过掺杂来改变载流子的类型和浓度。</p>\n<h4 id=\"杂质与杂质激发\"><a href=\"#杂质与杂质激发\" class=\"headerlink\" title=\"杂质与杂质激发\"></a>杂质与杂质激发</h4><p>掺杂形成了杂质能级，只在掺杂原子局部地区存在。</p>\n<p>处在杂质能级的电子实际上处于束缚态，只在掺杂原子附近存在，对导电性没有贡献。所以，电子从杂质原子跑出来，并不会形成“空穴”，这些“空穴”处于束缚态，并不会导电。</p>\n<p><img src=\"/../images/SolidPhysics/1715051145151.png\" alt=\"1715051145151\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1715051313166.png\" alt=\"1715051313166\" loading=\"lazy\"></p>\n<p>浅能级杂质</p>\n<ul>\n<li>上述由替位杂质所形成的施主和受主</li>\n<li>能级靠近导带或价带，又称为浅能级杂质</li>\n<li>杂质能级对电子或空穴的束缚能很小</li>\n<li>电子很容易从施主能级跃迁或跃迁到受主能级</li>\n<li>载流子将以杂质跃迁产生为主</li>\n</ul>\n<p>深能级杂质</p>\n<p>\u0001 大多数是多重能级<br>o 如Au在硅中，有施主能级也有受主能级<br>o 金为1价，施主能级靠近价带(!)，受主能级靠近禁带中部(!)<br>\u0001 深能级杂质附加势作用距离短，1～2个原子<br>\u0001 深能级杂质和缺陷影响<br>o 有效的复合中心，降低载流子寿命<br>o 做补偿杂质，提高材料电阻率</p>\n<p>施主杂质激发</p>\n<p>假设N型半导体只含一种施主,浓度$N_D$,能级$E_D$</p>\n<p>那么导带中电子数目显然与空的施主能级的数目相等</p>\n<div>$$\nn=N_D[1-f(E_D)]=N_D\\left[\\frac{e^{(E_D-E_F)/k_BT}}{e^{(E_D-E_F)/k_BT}+1}\\right]=N_D\\frac1{1+e^{-(E_D-E_F)/k_BT}}\n$$</div>\n\n<p>$E_F$ 在掺杂半导体里求不出来，因此尝试消去它，得到：</p>\n<p>温度很低时（$E_i &gt;&gt; k_BT$），少量施主电离激发电子</p>\n<div>$$\nn\\approx\\frac{\\left[4\\left(\\frac{N_D}{N_-}\\right)e^{E_i/k_BT}\\right]^{1/2}}{\\left(\\frac2{N_-}\\right)e^{E_i/k_BT}}=\\left(N_-N_D\\right)^{1/2}e^{-E_i/2k_BT}\n$$</div>\n\n<p>温度很高时（$E_i &gt;&gt; k_BT$），全部施主电离激发电子</p>\n<div>$$\n\\begin{aligned}n=&\\frac{-1+\\left[1+2{\\left(\\frac{N_D}{N_-}\\right)}e^{E_i/k_BT}+...\\right]}{\\frac2{N_-}e^{E_i/k_BT}}\\approx N_D\\\\\\end{aligned}\n$$</div>\n\n<p>一般室温下热激发到导带的电子数也符合上式，按指数关系随温度升高而增加 （慎用！）</p>\n<p>空穴的浓度是</p>\n<div>$$\np = (n_i)^2/n\n$$</div>\n\n<p>费米能级</p>\n<div>$$\n\\begin{aligned}\nE_{F}& =E_--k_BT\\ln(N_-/n)  \\\\\n&=E_{Fi}+k_BT\\ln(n/n_i)\n\\end{aligned}\n$$</div>\n\n<p>施主杂质的浓度越高，费米能级越靠近导带</p>\n<p>受主类似：</p>\n<p>温度很低时（$E_i &gt;&gt; k_BT$）</p>\n<div>$$\np\\thickapprox\\left(N_AN_+\\right)^{1/2}e^{-E_i/2k_BT}\n$$</div>\n\n<p>温度很高时（$E_i &lt;&lt; k_BT$）</p>\n<div>$$\np\\approx N_A\n$$</div>\n\n<div>$$\n\\begin{aligned}&E_F=E_++k_BT\\ln(N_+/p)\\\\&=E_{Fi}-k_BT\\ln(p/n_i)\\end{aligned}\n$$</div>\n\n<p>受主杂质的浓度越高，费米能级越靠近价带</p>\n<p>考虑施主和受主能级简并和电子自旋取向时引入施主和受主能级基态简并因子gD和gA。</p>\n<div>$$\nn=\\frac{-1+\\left[1+4\\left(\\frac{g_DN_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}}\\\\p=\\frac{-1+\\left[1+4\\left(\\frac{g_AN_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}}\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1715053184570.png\" alt=\"1715053184570\" loading=\"lazy\"></p>\n<p>中间的平台区域意味着施主已经给出了所有电子。</p>\n<p>在足够高的温度下，由满带到导带的电子激发（本征激发）将成为主要的。</p>\n<p><img src=\"/../images/SolidPhysics/1715053408715.png\" alt=\"1715053408715\" loading=\"lazy\"></p>\n<p>在足够高的温度下，费米能级同样也接近本征费米能级。</p>\n<p>以上讨论的是非简并半导体。</p>\n<p>对于简并半导体，不能再使用玻尔兹曼分布，只能使用费米-狄拉克分布。</p>\n<h4 id=\"补偿半导体的载流子浓度\"><a href=\"#补偿半导体的载流子浓度\" class=\"headerlink\" title=\"补偿半导体的载流子浓度\"></a>补偿半导体的载流子浓度</h4><p>完全电离条件下</p>\n<div>$$\nn_0+N_a=p_0+N_d\\\\\np_0 = n_i^2/n_0\n$$</div>\n\n<div>$$\nn_0=\\frac{(N_d-N_a)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\\\\\np_0=\\frac{(N_a-N_d)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\n$$</div>\n\n<p>n-type 和 p-type 的效果可以相互抵消。</p>\n<p>由于补偿半导体中掺有两种杂质，所以会产生杂质的补偿作用，从而其中能够参加导电的多数载流子，就只有由那些未被补偿的杂质来提供；因此补偿半导体中有效的载流子浓度很小，故电阻率很高。虽然补偿半导体的电阻率很高，但它<strong>不同于未掺杂的本征半导体。</strong></p>\n<p>总的杂质浓度</p>\n<div>$$\nN_{doping}{=}N_A{+}N_D\n$$</div>\n\n<h3 id=\"载流子的迁移（漂移）运动\"><a href=\"#载流子的迁移（漂移）运动\" class=\"headerlink\" title=\"载流子的迁移（漂移）运动\"></a>载流子的迁移（漂移）运动</h3><p>迁移率 $\\mu$：单位电场下载流子的平均漂移速度</p>\n<div>$$\n\\sigma=nq\\mu\n$$</div>\n\n<div>$$\nj=nq\\left(\\mu E\\right)\\\\\n\\sigma=\\frac{nq^2\\tau}{m^*}=nq\\frac{q\\tau}{m^*}=nq\\mu\\\\\n\\mu=\\frac{q\\tau}{m^*}\n$$</div>\n\n<div>$$\n\\sigma=nq\\mu_-+pq\\mu_+\n$$</div>\n\n<p>多子导电：</p>\n<div>$$\n\\sigma\\approx\\begin{cases}nq\\mu_-&(n\\text{型 })\\\\pq\\mu_+&(p\\text{型 })&\\end{cases}\n$$</div>\n\n<p>迁移率决定于有效质量以及平均弛豫时间</p>\n<div>$$\n\\mu_-=\\frac{q\\tau_{cn}}{m_-^*}\\quad\\mu_+=\\frac{q\\tau_{cp}}{m_+^*}\n$$</div>\n\n<p>在低温下，杂质的散射是主要的。温度升高时载流子热运动的速度增大，电离杂质的散射作用相应减弱，从而使迁移率增大。</p>\n<p>在较高温度下，晶格的散射是主要的，温度升高，声子的散射增大，因而迁移率随温度的升高而下降。</p>\n<p>半导体的电导率σ除了与迁移率有关外，还与载流子的浓度有关。而载流子的浓度随温度的升高以指数形式增加（饱和区除外）。因此除饱和区外，电导率主要以指数形式随温度的升高而迅速增大，表现出很强的热敏性。但是，不是温度越高就越好的，温度升高后，掺杂的特性就没了，导电能力主要由本征激发决定，相当于半导体退化成了一块普通的电阻，也没有什么 PN 结了。</p>\n<p>这与金属的电导率有明显不同。因为金属的载流子（电子或空穴）浓度与温度无关，温度升高时，传导电子的迁移率因与声子的碰撞更加频繁而减小，所以金属的导电率温度系数为负，温度升高，电导率下降。</p>\n<h2 id=\"PN-结\"><a href=\"#PN-结\" class=\"headerlink\" title=\"PN 结\"></a>PN 结</h2><h3 id=\"功函数\"><a href=\"#功函数\" class=\"headerlink\" title=\"功函数\"></a>功函数</h3><p>金属发射电流与温度有关，符合指数规律：</p>\n<div>$$\nj\\propto e^{\\large-\\frac{W}{k_BT}}\n$$</div>\n\n<p>其中 $W$ 称功函数。</p>\n<p>经典理论：</p>\n<div>$$\nj=-n_0q\\left(\\frac{k_BT}{2\\pi m}\\right)^{1/2}e^{-\\frac\\chi{k_BT}}\n$$</div>\n\n<p>功函数：</p>\n<div>$$\nW = \\chi\n$$</div>\n\n<p>统计分布：</p>\n<div>$$\ndn=n_0\\left(\\frac m{2\\pi k_BT}\\right)^{3/2}e^{-\\frac{m\\upsilon^2}{2k_BT}}d\\upsilon\n$$</div>\n\n<p>量子理论：</p>\n<div>$$\nj=-q\\frac{4\\pi m{\\left(k_BT\\right)}^2}{\\left(2\\pi\\hbar\\right)^3}e^{-\\left(\\chi-E_F\\right)/k_BT}\n$$</div>\n\n<p>功函数</p>\n<div>$$\nW = \\chi - E_F\n$$</div>\n\n<p>统计分布：</p>\n<div>$$\ndn=2{\\left(\\frac m{2\\pi\\hbar}\\right)}^3\\frac1{e^{\\left(\\frac12m\\upsilon^2-E_F\\right)/k_BT}+1}d\\upsilon\n$$</div>\n\n<p>金属有接触电势，从费米能级高的地方流向费米能级低的。</p>\n<p><img src=\"/../images/SolidPhysics/1715657785337.png\" alt=\"1715657785337\" loading=\"lazy\"></p>\n<div>$$\nV_A - V_B = (W_B - W_A)/q\n$$</div>\n\n<p>平衡态下，费米能级变为相等，电子不再流动。</p>\n<h3 id=\"PN-结-1\"><a href=\"#PN-结-1\" class=\"headerlink\" title=\"PN 结\"></a>PN 结</h3><p>载流子扩散运动：</p>\n<p><img src=\"/../images/SolidPhysics/1715658350241.png\" alt=\"1715658350241\" loading=\"lazy\"></p>\n<p>非平衡载流子：复合运动</p>\n<p>在外界的作用下，半导体中的电子浓度n和空穴浓度p有可<br>能偏离平衡值。例如半导体的本征光吸收产生电子—空穴<br>对，用Δn＝n－n0，Δp＝p－p0表示超出热平衡的多余载流<br>子，称为非平衡载流子。通常情况下，由于电中性要求，<br>Δn＝Δp</p>\n<p>我们最关心的是非平衡的少数载流子，因为少子的浓度变化大，通常采用准费米能级 $E_{Fn}, E_{Fp}$。多子的费米能级不变。</p>\n<div>$$\n\\begin{aligned}n_0+\\Delta n&=n_i\\exp(\\frac{E_{Fn}-E_{Fi}}{kT})\\\\\\left(n_0+\\Delta n\\right)\\cdot\\left(p_0+\\Delta p\\right)>n_i^2\\\\p_0+\\Delta p&=n_i\\exp(\\frac{E_{Fi}-E_{Fp}}{kT})\\end{aligned}\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1715658620805.png\" alt=\"1715658620805\" loading=\"lazy\"></p>\n<p>外界作用下， 非平衡态要恢复到平衡态。非平衡的载流子会消失，消失的过程叫复合，导带的多余电子落回价带，多余的电子和空穴成对消失。</p>\n<p>复合速率：</p>\n<div>$$\n\\frac{d\\Delta n}{dt}=-\\frac{\\Delta n}{\\tau}\\\\\\text{其解为:}\\quad\\Delta n=(\\Delta n)_0\\exp(-t/\\tau)\n$$</div>\n\n<p>$\\tau$ 称为非平衡载流子寿命</p>\n<h4 id=\"非平衡载流子的扩散和复合\"><a href=\"#非平衡载流子的扩散和复合\" class=\"headerlink\" title=\"非平衡载流子的扩散和复合\"></a>非平衡载流子的扩散和复合</h4><p>直接复合：复合率 $R&#x3D;\\alpha_r\\cdot n\\cdot p$</p>\n<p>间接复合：通过杂质能级的间接复合（与杂质浓度呈正比，与非平衡载流子浓度呈正比，深能级更强）</p>\n<p>非平衡状态下，过剩电子的复合率一定等于过剩空穴的复合率</p>\n<div>$$\nR_n^{\\prime}=R_p^{\\prime}\n$$</div>\n\n<p>扩散复合过程的稳定分布：</p>\n<div>$$\n-\\frac d{dx}\\Bigg(-D\\frac{dN}{dx}\\Bigg)-\\frac N\\tau=0\\\\N=N_0e^{-x/L},L=\\sqrt{D\\tau}\n$$</div>\n\n<p>扩散长度L：表面非平衡载流子深入材料内部的距离，随扩散系数和复合寿命增加而增加</p>\n<div>$$\n\\text{扩散流密度 }=-D\\frac{dN}{dx}=N_0\\frac DLe^{-x/L}\n$$</div>\n\n<p>扩散速度D&#x2F;L：界面处载流子以速度D&#x2F;L运动</p>\n<p>漂移 + 扩散 的总电流密度：</p>\n<div>$$\nJ=qn\\mu_nE_x+qp\\mu_pE_x+qD_n\\frac{dn}{dx}-qD_p\\frac{dp}{dx}\n$$</div>\n\n<p>爱因斯坦关系：</p>\n<div>$$\n\\frac{D_n}{\\mu_n}=\\frac{k_\\text{B}T}q\\quad\\frac{D_p}{\\mu_p}=\\frac{k_\\text{B}T}q\n$$</div>\n\n<h4 id=\"PN-结的接触电势差\"><a href=\"#PN-结的接触电势差\" class=\"headerlink\" title=\"PN 结的接触电势差\"></a>PN 结的接触电势差</h4><p><img src=\"/../images/SolidPhysics/1715659347111.png\" alt=\"1715659347111\" loading=\"lazy\"></p>\n<div>$$\neV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\\\\qV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\n$$</div>\n\n<div>$$\n\n\n<p>$$</div></p>\n<p>$V_D$ 等于接触前的费米能级差。</p>\n<p><img src=\"/../images/SolidPhysics/1715659894626.png\" alt=\"1715659894626\" loading=\"lazy\"></p>\n<h3 id=\"正向偏压-载流子扩散运动产生电流\"><a href=\"#正向偏压-载流子扩散运动产生电流\" class=\"headerlink\" title=\"正向偏压-载流子扩散运动产生电流\"></a>正向偏压-载流子扩散运动产生电流</h3><p>p 区看电子，n 区看空穴：</p>\n<p><img src=\"/../images/SolidPhysics/1716257709851.png\" alt=\"1716257709851\" loading=\"lazy\"></p>\n<p>0 表示热平衡时候的浓度。</p>\n<h3 id=\"反向偏压-漂移作用增强\"><a href=\"#反向偏压-漂移作用增强\" class=\"headerlink\" title=\"反向偏压-漂移作用增强\"></a>反向偏压-漂移作用增强</h3><p><img src=\"/../images/SolidPhysics/1716257832298.png\" alt=\"1716257832298\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716257919907.png\" alt=\"1716257919907\" loading=\"lazy\"></p>\n<p>正向注入：</p>\n<p>当PN结加正向偏压时：$\\mathsf{PN}$结势垒降低为$q(V_D-V)$扩散作用增强</p>\n<p>反向抽取：</p>\n<p>当PN结加反向偏压时：$\\mathsf{PN}$结势垒升高为$q(V_D+V)$漂移作用增强</p>\n<p>反向抽取时载流子的复合率为负数，就是说在不断地产生新的载流子（电子-空穴对）。PN结的反向电流实质上就是产生电流。</p>\n<p><img src=\"/../images/SolidPhysics/1716258157706.png\" alt=\"1716258157706\" loading=\"lazy\"></p>\n<h3 id=\"PN-结的击穿\"><a href=\"#PN-结的击穿\" class=\"headerlink\" title=\"PN 结的击穿\"></a>PN 结的击穿</h3><p><img src=\"/../images/SolidPhysics/1716258191070.png\" alt=\"1716258191070\" loading=\"lazy\"></p>\n<h3 id=\"双极性晶体管\"><a href=\"#双极性晶体管\" class=\"headerlink\" title=\"双极性晶体管\"></a>双极性晶体管</h3><p><img src=\"/../images/SolidPhysics/1716258575169.png\" alt=\"1716258575169\" loading=\"lazy\"></p>\n<h2 id=\"异质结与肖特基结\"><a href=\"#异质结与肖特基结\" class=\"headerlink\" title=\"异质结与肖特基结\"></a>异质结与肖特基结</h2><h3 id=\"半导体异质结\"><a href=\"#半导体异质结\" class=\"headerlink\" title=\"半导体异质结\"></a>半导体异质结</h3><p>真空能级：电子自由运动所占据的最低能量。</p>\n<p><img src=\"/../images/SolidPhysics/1716259850103.png\" alt=\"1716259850103\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716260746330.png\" alt=\"1716260746330\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716259893782.png\" alt=\"1716259893782\" loading=\"lazy\"></p>\n<p>导带能级差：$\\Delta E_C&#x3D;\\chi_1-\\chi_2$<br>价带能级差：$\\Delta E_v&#x3D;(\\chi_2+E_{g^2})-(\\chi_1+E_{g^1})&#x3D;E_{g^2}-E_{g^1}-\\Delta E_{g^2}$<br>导带能级差+价带能级差 &#x3D;带隙宽度差<br>注：此为一般半导体物理书中的结果</p>\n<p><img src=\"/../images/SolidPhysics/1716260901275.png\" alt=\"1716260901275\" loading=\"lazy\"></p>\n<h3 id=\"同质结的注入比\"><a href=\"#同质结的注入比\" class=\"headerlink\" title=\"同质结的注入比\"></a>同质结的注入比</h3><p>总电流：$j&#x3D; j_n+ j_p&#x3D; j_s\\left ( e^{qV&#x2F; K_BT}- 1\\right )$</p>\n<p>注入比定义：总电流中，电子电流与空穴电流的比例<br>普通PN结(同质结)</p>\n<p>注入到$p$区的电子电流密度为：$j_n&#x3D; q\\frac {D_n}{L_n}n_P^0\\left ( e^{qV&#x2F; k_BT}- 1\\right )$</p>\n<p>注入到$n$区的空穴电流密度为：$j_p&#x3D; q\\frac {D_p}{L_p}p_N^0\\left ( e^{qV&#x2F; k_BT}- 1\\right )$</p>\n<p>总电流：$j&#x3D; j_n+ j_p&#x3D; j_s\\left ( e^{qV&#x2F; k_BT}- 1\\right )$<br>注入比定义：总电流中，电子电流与空穴电流的比例<br>正偏压下的电子注入比：</p>\n<div>$$\n\\begin{aligned}&\\frac{j_n}{j_p}=\\frac{D_nn_P^0}{L_n}\\frac{D_pp_N^0}{L_p}=\\frac{D_nL_pn_P^0}{D_pL_np_N^0}\\\\&n_P^0=\\frac{n_i^2}{p_P}\\approx\\frac{n_i^2}{N_A}\\\\&p_{N}^{0}=\\frac{n_{i}^{2}}{n_{N}}\\approx\\frac{n_{i}^{2}}{N_{D}}\\\\&\\frac{j_n}{j_p}=\\frac{D_nL_pN_D}{D_pL_nN_A}\\end{aligned}\n$$</div>\n\n<p>提高注入比的办法,提高N型区的施主杂质浓度</p>\n<p><img src=\"/../images/SolidPhysics/1716261236429.png\" alt=\"1716261236429\" loading=\"lazy\"></p>\n<p>结中电子注入比：</p>\n<div>$$\n\\begin{aligned}&\\frac{J_n}{J_p}=\\frac{D_nn_P^0}{L_n}\\left/\\frac{D_pp_N^0}{L_p}\\right.=\\frac{D_nL_pN_D}{D_pL_nN_A}e^{\\frac{E_{gN}-E_{gP}}{k_BT}}\\end{aligned}\n$$</div>\n\n<p>异质结构的优点：</p>\n<p>也就是说，N型区的带隙宽度比p型区带隙宽度大，<br>可以进一步以指数级增加注入比</p>\n<p>提高注入比的意义<br>提高晶体管放大系数-异质结双极晶体管HBT</p>\n<p><img src=\"/../images/SolidPhysics/1716261409659.png\" alt=\"1716261409659\" loading=\"lazy\"></p>\n<h3 id=\"激光器\"><a href=\"#激光器\" class=\"headerlink\" title=\"激光器\"></a>激光器</h3><p>本征光吸收</p>\n<p>光照激发价带电子到导带， 形成电子-空穴对的过程</p>\n<div>$$\n\\hbar\\omega\\geq E_{_g}\n$$</div>\n\n<p>准动量守恒——竖直跃迁</p>\n<p>应当照射结区（空间电荷区）</p>\n<p><img src=\"/../images/SolidPhysics/1716261766058.png\" alt=\"1716261766058\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716261781489.png\" alt=\"1716261781489\" loading=\"lazy\"></p>\n<p>二维电子气体系提高电子迁移率</p>\n<p><img src=\"/../images/SolidPhysics/1716262583215.png\" alt=\"1716262583215\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716262570823.png\" alt=\"1716262570823\" loading=\"lazy\"></p>\n<h3 id=\"肖特基结\"><a href=\"#肖特基结\" class=\"headerlink\" title=\"肖特基结\"></a>肖特基结</h3><p>功函数的物理本质是真空能级与费米能级的差</p>\n<p>亲合能：从导带底部到真空能级的能量（真空-导带底）</p>\n<p><img src=\"/../images/SolidPhysics/1716263334906.png\" alt=\"1716263334906\" loading=\"lazy\"></p>\n<p>金属与 N 型半导体的接触：</p>\n<p><img src=\"/../images/SolidPhysics/1716263526504.png\" alt=\"1716263526504\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716263538645.png\" alt=\"1716263538645\" loading=\"lazy\"></p>\n<div>$$\n\\boxed{\\begin{array}{c}\\text{肖特基势垒}\\\\\\phi_{B0}=\\left(\\phi_m-\\chi\\right)\\end{array}}\n$$</div>\n\n<div>$$\n\\boxed{\\begin{array}{c}\\text{内建电势差}\\\\\\\\V_{bi}=\\left(\\phi_{B0}-\\phi_n\\right)\\end{array}}\n$$</div>\n\n<p>考虑偏压：</p>\n<p><img src=\"/../images/SolidPhysics/1716263918247.png\" alt=\"1716263918247\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716263941957.png\" alt=\"1716263941957\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716863556246.png\" alt=\"1716863556246\" loading=\"lazy\"></p>\n<p>欧姆接触</p>\n<p><img src=\"/../images/SolidPhysics/1716864038557.png\" alt=\"1716864038557\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716864050264.png\" alt=\"1716864050264\" loading=\"lazy\"></p>\n<p>欧姆接触是指金属与半导体的接触，而其接触面的电阻值远小于半导体本身的电阻，不产生明显的附加阻抗，而且不会使半导体内部的平衡载流子浓度发生显著的改变</p>\n<p>区分电子和空穴的本质是迁移率的不同。</p>\n<h2 id=\"格波\"><a href=\"#格波\" class=\"headerlink\" title=\"格波\"></a>格波</h2><h3 id=\"一维单原子链\"><a href=\"#一维单原子链\" class=\"headerlink\" title=\"一维单原子链\"></a>一维单原子链</h3><p>相邻原子间距为</p>\n<div>$$\na+(\\mu_{n+1}-\\mu_n)=a+\\delta\n$$</div>\n\n<p>相邻原子的作用力</p>\n<div>$$\nF=-\\frac{\\partial\\nu}{\\partial\\delta}\\approx-\\beta\\delta\n$$</div>\n\n<p>左右两边一个原子对中间原子的作用力</p>\n<div>$$\nF_{n,n-1}=-\\beta\\left(\\mu_n-\\mu_{n-1}\\right)\\\\\nF_{n,n+1}=-\\beta\\left(\\mu_n-\\mu_{n+1}\\right)\\\\\nF_n=\\beta(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n)\n$$</div>\n\n<p>相邻原子之间的耦合运动方程组</p>\n<div>$$\nm\\ddot{\\mu}_n=\\beta\\left(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n\\right)\n$$</div>\n\n<p>通过坐标变换简化方程组，得到简谐振动解</p>\n<div>$$\n\\mu_n=Ae^{i(\\omega t-qX_n)}\n$$</div>\n\n<p>其中 $X_n&#x3D;na$ 是第 n 个原子的平衡位置</p>\n<p>将解代入运动方程：</p>\n<div>$$\nm{\\left(i\\omega\\right)}^2Ae^{i(\\omega t-qX_n)}=\\beta Ae^{i(\\omega t-qna)}{\\left(e^{-iqa}+e^{iqa}-2\\right)}\n$$</div>\n\n<p>得到色散关系</p>\n<div>$$\n\\omega^2=\\frac{2\\beta}m\\Big(1-\\cos\\alpha q\\Big)=\\frac{4\\beta}m\\sin^2\\Bigg(\\frac{aq}2\\Bigg)\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1716868157804.png\" alt=\"1716868157804\" loading=\"lazy\"></p>\n<p>格波有意义的取值只在第一布里渊区，我们只关心格点位置处的取值。</p>\n<p><img src=\"/../images/SolidPhysics/1716868762789.png\" alt=\"1716868762789\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467825452.png\" alt=\"1717467825452\" loading=\"lazy\"></p>\n<p>波恩卡门条件下的环状链模型</p>\n<p><img src=\"/../images/SolidPhysics/1716869179928.png\" alt=\"1716869179928\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1716869156196.png\" alt=\"1716869156196\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467681404.png\" alt=\"1717467681404\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467815166.png\" alt=\"1717467815166\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467885133.png\" alt=\"1717467885133\" loading=\"lazy\"></p>\n<h3 id=\"一维双原子链结构\"><a href=\"#一维双原子链结构\" class=\"headerlink\" title=\"一维双原子链结构\"></a>一维双原子链结构</h3><p><img src=\"/../images/SolidPhysics/1717467940325.png\" alt=\"1717467940325\" loading=\"lazy\"></p>\n<p>P原子质量：m<br> Q原子质量：M</p>\n<div>$$\nm\\ddot{\\mu}_{2n}=\\beta(\\mu_{2n+1}+\\mu_{2n-1}-2\\mu_{2n})\\\\M\\ddot{\\mu}_{2n+1}=\\beta(\\mu_{2n+2}+\\mu_{2n}-2\\mu_{2n+1})\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1717468003069.png\" alt=\"1717468003069\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468014637.png\" alt=\"1717468014637\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468150691.png\" alt=\"1717468150691\" loading=\"lazy\"></p>\n<p>波数 q 的取值范围：</p>\n<div>$$\n-\\frac\\pi{2a}<q\\leq\\frac\\pi{2a}\n$$</div>\n\n<p>原胞变大，倒格矢变小，布里渊区变小</p>\n<div>$$\nN\\cdot\\left(2aq\\right)=2\\pi h,h=[-N/2,+N/2]\\quad q=\\frac{h\\pi}{Na}\n$$</div>\n\n<p>对于双原子链，有2N个原子，也有2N个格波</p>\n<p><img src=\"/../images/SolidPhysics/1717468250438.png\" alt=\"1717468250438\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468279238.png\" alt=\"1717468279238\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468352260.png\" alt=\"1717468352260\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468364464.png\" alt=\"1717468364464\" loading=\"lazy\"></p>\n<p>相邻原子振动相反，振幅反比于原子质量</p>\n<p>对于声学波，相邻原子同步运动,原胞中两种原子的运动是完全一致的振幅和位相</p>\n<p><img src=\"/../images/SolidPhysics/1717469037238.png\" alt=\"1717469037238\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717469080107.png\" alt=\"1717469080107\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717469005887.png\" alt=\"1717469005887\" loading=\"lazy\"></p>\n<p>k 代表的是移动一个原胞后的位相差。</p>\n<p>简单晶格没有能带折叠，所以没有光学波。</p>\n<p><img src=\"/../images/SolidPhysics/1717469702087.png\" alt=\"1717469702087\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1717470027229.png\" alt=\"1717470027229\" loading=\"lazy\"></p>\n<p>如果问的是“多少个”光学波&#x2F;声学波，还得×一个 N</p>\n<p>横波才能简并，纵波不能。</p>\n<p>硅的晶格中虽然只有硅一种原子，但是由于是复式晶格结构，等同于有两种原子，因此也有声学波和光学波</p>\n<p>金属铅(Pb)属于面心立方的简单晶格结构，没有光学波只有三支声学波（注：不同方向上有简并）</p>\n<p>纵波的速度总是比横波快。</p>\n<h3 id=\"晶格振动的量子化——声子\"><a href=\"#晶格振动的量子化——声子\" class=\"headerlink\" title=\"晶格振动的量子化——声子\"></a>晶格振动的量子化——声子</h3><p>一维谐振子</p>\n<p><img src=\"/../images/SolidPhysics/1717470756612.png\" alt=\"1717470756612\" loading=\"lazy\"></p>\n<h3 id=\"固体热容\"><a href=\"#固体热容\" class=\"headerlink\" title=\"固体热容\"></a>固体热容</h3><div>$$\nC_V=\\left(\\frac{\\partial\\overline{E}}{\\partial T}\\right)_V\n$$</div>\n\n<p>固体热容主要来自于两个部分</p>\n<p>晶格热容：来源于固体的晶格热运动</p>\n<p>电子热容：来源于电子的热运动仅在,极低温下，对于金属比较显著，相比晶格热容，一般可忽略不计</p>\n<p><img src=\"/../images/SolidPhysics/1717473776761.png\" alt=\"1717473776761\" loading=\"lazy\"></p>\n<p>经典模型</p>\n<p><img src=\"/../images/SolidPhysics/1717473805195.png\" alt=\"1717473805195\" loading=\"lazy\"></p>\n<p>量子模型</p>\n<p><img src=\"/../images/SolidPhysics/1718071135404.png\" alt=\"1718071135404\" loading=\"lazy\"></p>\n<p>高温情况下</p>\n<p><img src=\"/../images/SolidPhysics/1718071202034.png\" alt=\"1718071202034\" loading=\"lazy\"></p>\n<p>在较高温度时，杜隆-珀替定律成立。即当振子的能量远远大于能量的量子( ħωq)时，量子化效应就可以忽略</p>\n<p><img src=\"/../images/SolidPhysics/1718071363760.png\" alt=\"1718071363760\" loading=\"lazy\"></p>\n<p>爱因斯坦模型</p>\n<p>基本假设</p>\n<p>晶格中所有原子都具有统一振动频率$\\omega_0$</p>\n<p>所有原子的振动是独立的</p>\n<p>假设有$N$个原子</p>\n<p><img src=\"/../images/SolidPhysics/1718071563960.png\" alt=\"1718071563960\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1718071692546.png\" alt=\"1718071692546\" loading=\"lazy\"></p>\n<p>爱因斯坦模型较经典模型的改进明显，阐明低温热容趋于零的基本原因</p>\n<p>爱因斯坦模型低温段热容下降很陡，与实验值有不相符的问题</p>\n<p>原子与原子间的相互作用是很强的，晶格振动是以格波的形式存在，不同格波之间的频率不完全相同，而且有一定分布爱因斯坦模型等效于所有的格波频率相同过于简单</p>\n<p>德拜模型</p>\n<p><img src=\"/../images/SolidPhysics/1718071922789.png\" alt=\"1718071922789\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072084533.png\" alt=\"1718072084533\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072235738.png\" alt=\"1718072235738\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072255786.png\" alt=\"1718072255786\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072474995.png\" alt=\"1718072474995\" loading=\"lazy\"></p>\n<p>德拜温度</p>\n<div>$$\n\\Theta_D=\\frac{\\hbar\\omega_m}{k_B}\n$$</div>\n\n<div>$$\n\\omega_m=\\overline{C}\\bigg[6\\pi^2\\frac NV\\bigg]^{1/3}\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1718072707268.png\" alt=\"1718072707268\" loading=\"lazy\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072997880.png\" alt=\"1718072997880\" loading=\"lazy\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"外场中电子运动状态的变化\"><a href=\"#外场中电子运动状态的变化\" class=\"headerlink\" title=\"外场中电子运动状态的变化\"></a>外场中电子运动状态的变化</h2><h3 id=\"布洛赫电子\"><a href=\"#布洛赫电子\" class=\"headerlink\" title=\"布洛赫电子\"></a>布洛赫电子</h3><h4 id=\"布洛赫定理\"><a href=\"#布洛赫定理\" class=\"headerlink\" title=\"布洛赫定理\"></a>布洛赫定理</h4><div>$$\n\\psi(x+R_n)=e^{ik\\cdot R_n}\\psi(x)\n$$</div>\n\n<p>布洛赫波函数：</p>\n<div>$$\n\\boxed{\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}}\n$$</div>\n\n<p>薛定谔方程在周期势场 $V(r)$的本征解。与 $V(r)$有相同的周期。</p>\n<p>简约布里渊区和周期布里渊区图景</p>\n<p><img src=\"/../images/SolidPhysics/1713239832006.png\" alt=\"1713239832006\"></p>\n<h4 id=\"一维近自由电子近似\"><a href=\"#一维近自由电子近似\" class=\"headerlink\" title=\"一维近自由电子近似\"></a>一维近自由电子近似</h4><p>利用微扰求解薛定谔方程</p>\n<p>零级哈密顿量是自由电子的哈密顿量(索末菲模型),周期性势场的作用看成是微扰<br>适用于解释参与共有化运动的外层价电子的运动状态</p>\n<div>$$\nH=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+V(x)=H_0+H^{\\prime}\\\\\nV(x)=\\overline{V}+\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}anx\\biggr]\n$$</div>\n\n<div>$$\n\\begin{aligned}&H_0=-\\frac{\\hbar^2}{2m_0}\\frac{d^2}{dx^2}+\\overline{V}\\\\&H'=\\sum_{n\\neq0}V_n\\exp\\left(i\\frac{2\\pi nx}a\\right)\\end{aligned}\n$$</div>\n\n<p>基态（零级解）</p>\n<div>$$\nE_k^0=\\frac{\\hbar^2k^2}{2m_0}+\\overline{V}\\\\\n\\psi_k^{(0)}=\\frac1{\\sqrt{L}}e^{ikx}\n$$</div>\n\n<div>$$\nk=\\frac{2\\pi l_x}{Na}\n$$</div>\n\n<p>利用波恩卡曼条件看作准连续。</p>\n<p>周期性势场的一级微扰</p>\n<div>$$\n\\Delta V=\\sum_{n\\neq0}V_nexp\\biggl[i\\frac{2\\pi}{a}nx\\biggr]\n$$</div>\n\n<p>一级修正：</p>\n<div>$$\nE_k^{(1)}=\\int\\left(\\psi_k^0\\right)^*[\\Delta V]\\psi_k^0dx=\\left\\langle k|\\Delta V|k\\right\\rangle=0\n$$</div>\n\n<p>二级修正：</p>\n<div>$$\nE_k^{(2)}=\\sum_{k^{\\prime}}\\frac{\\left|\\left\\langle k^{\\prime}|\\Delta V|k\\right\\rangle\\right|^2}{E_k^0-E_{k^{\\prime}}^0}\n$$</div>\n\n<p>非简并情况下：</p>\n<div>$$\nE_k^{(2)}=\\sum_{n\\neq0}\\frac{\\left|V_n\\right|^2}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi}an\\right)^2\\right]}\n$$</div>\n\n<p>k’对应的波可以看作k状态波在周期性势场各频率分量对应的散射波-&gt;自由电子波函数经过周期势场的散射后改变了原有的能量。</p>\n<p>波函数的一级修正</p>\n<div>$$\n\\psi_k=\\frac1{\\sqrt{L}}e^{ikx}\\left\\lbrace1+\\sum_{n=0}\\frac{V_n}{\\frac{\\hbar^2}{2m_0}\\left[k^2-\\left(k+\\frac{2\\pi n}a\\right)^2\\right]}\\cdot exp\\left[i\\frac{2\\pi}anx\\right]\\right\\rbrace\n$$</div>\n\n<div>$$\n\\vec{\\psi(r)}=e^{i\\vec{k}\\cdot\\vec{r}}\\vec{u(r)}\n$$</div>\n\n<p>被周期函数调幅的平面波。</p>\n<p><img src=\"/../images/SolidPhysics/1713240457384.png\" alt=\"1713240457384\"></p>\n<p>如果 k 的取值在布里渊区边界 $k&#x3D;-\\frac{n\\pi}a$，散射波矢$k’&#x3D;k+\\frac{2\\pi n}a&#x3D;\\frac{\\pi n}a$，即布拉格定律 $2dsin\\theta&#x3D;n\\lambda$。此时电子的波函数是 $k$ 和 $k’$ 两个平面波叠加的驻波。</p>\n<p>简并状态的处理方法</p>\n<p>在布里渊区边界，存在简并状态，能量相等。</p>\n<h3 id=\"准经典运动\"><a href=\"#准经典运动\" class=\"headerlink\" title=\"准经典运动\"></a>准经典运动</h3><p>引入准经典粒子——波包</p>\n<p>自由电子和晶体电子速度的定义：</p>\n<div>$$\nv(k_0) = \\frac1\\hbar \\bigg[\\frac{d E(k)}{dk}\\bigg]_{k_0}\\\\\nE(k) = \\hbar\\omega\n$$</div>\n\n<p>速度方向垂直于等能面，如果等能面为球面， 速度的方向与 $k$ 相同。</p>\n<p>晶体电子的加速度</p>\n<div>$$\n\\hbar\\frac{dk}{dt} = F\n$$</div>\n\n<p>由此定义电子的准动量（晶体动量）为 $\\hbar k$。可定义有效质量：</p>\n<div>$$\n\\frac{d\\upsilon_a}{dt}=\\frac1{\\hbar^2}\\sum_\\beta F_\\beta\\cdot\\frac{\\partial^2}{\\partial k_\\beta\\partial k_\\alpha}E(k)\\\\\n\\frac{d\\vec{\\upsilon}}{dt}=\\frac1{m_0}\\vec{F}\n$$</div>\n\n<p>有效质量的“倒数”（矩阵的逆）：</p>\n<div>$$\n\\frac1{m_{\\alpha\\beta}^*}=\\frac1{\\hbar^2}\\frac{\\partial^2E}{\\partial k_\\alpha\\partial k_\\beta}\n$$</div>\n\n<div>$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_x\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_y\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_y^2}&\\dfrac{\\partial^2E}{\\partial k_y\\partial k_z}\\\\\\dfrac{\\partial^2E}{\\partial k_z\\partial k_x}&\\dfrac{\\partial^2E}{\\partial k_z\\partial k_y}&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$</div>\n\n<p>选取 $(k_x, k_y, k_z)$ 的主轴方向时</p>\n<div>$$\n\\begin{pmatrix}\\dot{\\nu}_x\\\\\\dot{\\nu}_y\\\\\\dot{\\nu}_z\\end{pmatrix}=\\dfrac{1}{\\hbar^2}\\begin{pmatrix}\\dfrac{\\partial^2E}{\\partial k_x^2}&0&0\\\\0&\\dfrac{\\partial^2E}{\\partial k_y^2}&0\\\\\\\\0&0&\\dfrac{\\partial^2E}{\\partial k_z^2}\\end{pmatrix}\\begin{pmatrix}F_x\\\\F_y\\\\F_z\\end{pmatrix}\n$$</div>\n\n<p>注意：各方向上的有效质量一般不同</p>\n<p>(1) 质量是标量，而有效质量是张量<br>晶体中的电子，加速度和外力的方向可以不一致<br> (2)质量常值，有效质量是变值，有正有负<br>能带顶附近&lt;0 能带底附近&gt;0<br>有效质量$m^{*}$与电子质量$m$之间可以有很大的差别， 因为有效质量中实际包含了周期势场的作用</p>\n<p>晶体所表现出来的有效质量，原因在于电子波在晶体中传播时与晶格交换动量。</p>\n<p>正有效质量状态出现在能带底附近，体现电子从外场获得的动量，加速度为正。</p>\n<p> 负有效质量状态出现在能带顶附近，由电子从外场获得动量不足以弥补与晶格的碰撞，加速度为负。</p>\n<h4 id=\"恒定电场下运动\"><a href=\"#恒定电场下运动\" class=\"headerlink\" title=\"恒定电场下运动\"></a>恒定电场下运动</h4><p>在周期布里渊图景；</p>\n<p>在 $k$ 空间里匀速运动</p>\n<p><img src=\"/../images/SolidPhysics/1713234834861.png\" alt=\"1713234834861\"></p>\n<p>在实际空间中，电子的运动相当复杂：</p>\n<p><img src=\"/../images/SolidPhysics/1713234874686.png\" alt=\"1713234874686\"></p>\n<p>质量无穷大：驻波解。</p>\n<p>拐点不一定是 $\\pi&#x2F;2a$，结合实际情况。</p>\n<p><img src=\"/../images/SolidPhysics/1713235941206.png\" alt=\"1713235941206\"></p>\n<p><img src=\"/../images/SolidPhysics/1713235941206.png\" alt=\"1713235941206\"></p>\n<p>理想情况（无散射），电子的运动产生震荡的电流。</p>\n<p>实际情况下，很难观察到来回震荡。</p>\n<p><img src=\"/../images/SolidPhysics/1713236189430.png\" alt=\"1713236189430\"></p>\n<p><img src=\"/../images/SolidPhysics/1713236233045.png\" alt=\"1713236233045\"></p>\n<p>实际情况：带隙部分反射</p>\n<p>存在势垒穿透</p>\n<p>隧穿几率：</p>\n<div>$$\nf\\propto E\\exp\\left[-\\frac{\\pi^2}\\hbar\\left(2m_0E_g\\right)^{1/2}\\left(\\frac{E_g}{qE}\\right)\\right]\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1713236269885.png\" alt=\"1713236269885\"></p>\n<p>准经典运动只适合描述弱电场下电子在同一能带中的运动。</p>\n<h3 id=\"导体、绝缘体和半导体的能带解释\"><a href=\"#导体、绝缘体和半导体的能带解释\" class=\"headerlink\" title=\"导体、绝缘体和半导体的能带解释\"></a>导体、绝缘体和半导体的能带解释</h3><h4 id=\"满带不导电\"><a href=\"#满带不导电\" class=\"headerlink\" title=\"满带不导电\"></a>满带不导电</h4><p>不加电场：$E(k)&#x3D;E(-k)$，占据正反方向波矢的概率相等， 相反速度的电子数量也相等，相互抵消；</p>\n<p>加电场：k空间里匀速移动，边界上移出的粒子和移入的粒子是一样的，仍然均匀填充。</p>\n<h4 id=\"部分填充能带产生电流\"><a href=\"#部分填充能带产生电流\" class=\"headerlink\" title=\"部分填充能带产生电流\"></a>部分填充能带产生电流</h4><p>无外场：净电流为0</p>\n<p>有外场：k空间分布向一方移动，有净电流</p>\n<h4 id=\"导体的能带模型\"><a href=\"#导体的能带模型\" class=\"headerlink\" title=\"导体的能带模型\"></a>导体的能带模型</h4><p>部分填充的能带称为导带</p>\n<p><img src=\"/../images/SolidPhysics/1713236929581.png\" alt=\"1713236929581\"></p>\n<h4 id=\"非导体的能带模型\"><a href=\"#非导体的能带模型\" class=\"headerlink\" title=\"非导体的能带模型\"></a>非导体的能带模型</h4><p>电子恰好填满最低的一系列能带，再高的能带全空</p>\n<p>满带不导电，空带也不导电</p>\n<p><img src=\"/../images/SolidPhysics/1713236984022.png\" alt=\"1713236984022\"></p>\n<p>最高的满带的电子容易被激发到上面的空带，从而使两个带皆变成未满带，产生一定的导电性</p>\n<p><img src=\"/../images/SolidPhysics/1713237069207.png\" alt=\"1713237069207\"></p>\n<p>总结：</p>\n<p><img src=\"/../images/SolidPhysics/1713237158982.png\" alt=\"1713237158982\"></p>\n<h4 id=\"半导体能带模型\"><a href=\"#半导体能带模型\" class=\"headerlink\" title=\"半导体能带模型\"></a>半导体能带模型</h4><p>常温下，T&#x3D;0K时的满带电子容易被激发到上面的空带，<br>从而使两个带皆变成未满带，产生一定的导电性</p>\n<p><img src=\"/../images/SolidPhysics/1713237357342.png\" alt=\"1713237357342\"></p>\n<p>近满带和空穴</p>\n<ul>\n<li>速度是电子的速度</li>\n<li>但电荷为正</li>\n</ul>\n<p>空穴的波矢：</p>\n<p>空穴的有效质量，在能带顶部为k_\\mathrm{h}&#x3D;-k_\\mathrm{e}</p>\n<p>正：</p>\n<div>$$\n\\frac1{m_h^*}=-\\left(\\frac1{\\hbar^2}\\cdot\\frac{d^2E}{dk^2}\\right)\n$$</div>\n\n<h2 id=\"金属和半导体中的输运过程\"><a href=\"#金属和半导体中的输运过程\" class=\"headerlink\" title=\"金属和半导体中的输运过程\"></a>金属和半导体中的输运过程</h2><h3 id=\"金属中的电子输运过程\"><a href=\"#金属中的电子输运过程\" class=\"headerlink\" title=\"金属中的电子输运过程\"></a>金属中的电子输运过程</h3><p>各向同性晶体中的电导率：</p>\n<div>$$\n\\sigma_0=\\frac{ne^2\\tau\\left(E_F\\right)}{m^*}\n$$</div>\n\n<ol>\n<li>电子的质量 →有效质量 (能带理论的必然结果)</li>\n<li>弛豫时间只由费米面附近的电子状态决定(量子统计的结果)</li>\n</ol>\n<h3 id=\"半导体电子输运过程\"><a href=\"#半导体电子输运过程\" class=\"headerlink\" title=\"半导体电子输运过程\"></a>半导体电子输运过程</h3><p>E-k 关系：</p>\n<p>考虑三维能带的顶部和底部的 E-k 关系，并引入有效质量得到抛物线近似：</p>\n<div>$$\nE\\left(k\\right)=E\\left(k_0\\right)+\\frac{\\hbar^2\\left(k_x-k_{0x}\\right)^2}{2m_x^*}+\\frac{\\hbar^2\\left(k_y-k_{0y}\\right)^2}{2m_y^*}+\\frac{\\hbar^2\\left(k_z-k_{0z}\\right)^2}{2m_z^*}\n$$</div>\n\n<p>间接带隙：价带的顶部和导带的底部并不是同一个简约波矢k</p>\n<p>直接带隙：价带的顶部和导带的底部是同一个简约波矢k</p>\n<p><img src=\"/../images/SolidPhysics/1715048162767.png\" alt=\"1715048162767\"></p>\n<p>近似成自由电子：</p>\n<p><img src=\"/../images/SolidPhysics/1715048234147.png\" alt=\"1715048234147\"></p>\n<p>将自由电子的质量替换为：电子或空穴的有效质量</p>\n<p>将自由电子的能量替换为：与导带底或价带顶的能量差</p>\n<p>$E_-$: 电子的；$E_+$：空穴的。</p>\n<div>$$\nN_-(E)=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\sqrt{(E-E_-)}\\\\N_+(E)=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\sqrt{(E_+-E)}\n$$</div>\n\n<p>费米能量应在 $E_-$ 和 $E_+$ 之间。</p>\n<div>$$\nf(E)=\\frac1{e^{(E-E_F)/k_BT}+1}\\approx e^{-(E-E_F)/k_BT}<<1\n$$</div>\n\n<p>据此计算电子的浓度：</p>\n<div>$$\n\\begin{aligned}\n&n=\\int_{E_-}^\\infty f(E)N_-(E)dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}\\int_{E_-}^\\infty e^{-(E-E_F)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_{E_-}^\\infty e^{-(E-E_-)/k_BT}\\sqrt{(E-E_-)}dE \\\\\n&=\\frac{4\\pi(2m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}\\int_0^\\infty\\xi^{1/2}e^{-\\xi}d\\xi  \\\\\n&=\\frac{2(2\\pi m_-^*k_BT)^{3/2}}{h^3}e^{-(E_--E_F)/k_BT}=N_-e^{-(E_--E_F)/k_BT}\n\\end{aligned}\n$$</div>\n\n<p>$N_-$ 为有效能级密度。</p>\n<p>空穴的浓度：</p>\n<div>$$\n\\begin{aligned}\n&p=\\int_{-\\infty}^{E_+}(1-f(E))N_+(E)dE \\\\\n&=\\frac{4\\pi(2m_+^*)^{3/2}}{h^3}\\int_{-\\infty}^{E_+}e^{-(E_F-E)/k_BT}\\sqrt{(E_+-E)}dE \\\\\n&=N_+e^{-(E_F-E_+)/k_BT}\n\\end{aligned}\n$$</div>\n\n<div>$$\nN_+=\\frac{2(2\\pi m_+^*k_BT)^{3/2}}{h^3}\n$$</div>\n\n<p>在计算价带空穴数时可以等效地用价带顶能级E+代替整个价带，价带的空穴数就如同在价带顶E+处集中了N+个能态所含有的空穴数</p>\n<p>反直觉的事实：电子浓度与空穴浓度的乘积仅与禁带宽度和温度有关，与费米能级无关。温度一样，电子浓度越高，空穴浓度就越低。</p>\n<div>$$\nnp=N_-N_+exp\\biggl(-\\frac{E_--E_+}{k_BT}\\biggr)=N_-N_+exp\\biggl(-\\frac{E_g}{k_BT}\\biggr)\n$$</div>\n\n<h4 id=\"本征激发\"><a href=\"#本征激发\" class=\"headerlink\" title=\"本征激发\"></a>本征激发</h4><p>无杂质及缺陷的半导体称为本征半导体</p>\n<div>$$\nn_i=n=p=\\left(N_-N_+\\right)^{1/2}e^{-E_g/2k_BT}\n$$</div>\n\n<p>电子数目与空穴数目相同。</p>\n<div>$$\n\\begin{aligned}\n&E_{Fi}=E_--k_BT\\ln(N_-/n_i) \\\\\n&=E_++k_BT\\ln(N_+/n_i) \\\\\n&=\\frac12(E_-+E_+)+\\frac12k_BT\\ln(N_+/N_-) \\\\\n&=\\frac12(E_-+E_+)+\\frac34k_BT\\ln(m_+^*/m_-^*)\n\\end{aligned}\n$$</div>\n\n<p>多数半导体的密度分布和金属相反：导带能级密度更大， 价带的更小，也就是说 $N_+&gt;N_-$，即随着温度的升高费米能级在上升。而金属，随着温度的升高，费米能级是下降的。</p>\n<p>在一般情况下，由于$k_BT$较小，且$m_h*$和$m_e*$相差不大， 所以，本征半导体的费米能$E_{Fi}$近似地在带隙的中间。</p>\n<h4 id=\"一般半导体\"><a href=\"#一般半导体\" class=\"headerlink\" title=\"一般半导体\"></a>一般半导体</h4><p>$E_F$ 升高，则电子浓度增大，空穴浓度减小。</p>\n<p>通过掺杂来改变载流子的类型和浓度。</p>\n<h4 id=\"杂质与杂质激发\"><a href=\"#杂质与杂质激发\" class=\"headerlink\" title=\"杂质与杂质激发\"></a>杂质与杂质激发</h4><p>掺杂形成了杂质能级，只在掺杂原子局部地区存在。</p>\n<p>处在杂质能级的电子实际上处于束缚态，只在掺杂原子附近存在，对导电性没有贡献。所以，电子从杂质原子跑出来，并不会形成“空穴”，这些“空穴”处于束缚态，并不会导电。</p>\n<p><img src=\"/../images/SolidPhysics/1715051145151.png\" alt=\"1715051145151\"></p>\n<p><img src=\"/../images/SolidPhysics/1715051313166.png\" alt=\"1715051313166\"></p>\n<p>浅能级杂质</p>\n<ul>\n<li>上述由替位杂质所形成的施主和受主</li>\n<li>能级靠近导带或价带，又称为浅能级杂质</li>\n<li>杂质能级对电子或空穴的束缚能很小</li>\n<li>电子很容易从施主能级跃迁或跃迁到受主能级</li>\n<li>载流子将以杂质跃迁产生为主</li>\n</ul>\n<p>深能级杂质</p>\n<p>\u0001 大多数是多重能级<br>o 如Au在硅中，有施主能级也有受主能级<br>o 金为1价，施主能级靠近价带(!)，受主能级靠近禁带中部(!)<br>\u0001 深能级杂质附加势作用距离短，1～2个原子<br>\u0001 深能级杂质和缺陷影响<br>o 有效的复合中心，降低载流子寿命<br>o 做补偿杂质，提高材料电阻率</p>\n<p>施主杂质激发</p>\n<p>假设N型半导体只含一种施主,浓度$N_D$,能级$E_D$</p>\n<p>那么导带中电子数目显然与空的施主能级的数目相等</p>\n<div>$$\nn=N_D[1-f(E_D)]=N_D\\left[\\frac{e^{(E_D-E_F)/k_BT}}{e^{(E_D-E_F)/k_BT}+1}\\right]=N_D\\frac1{1+e^{-(E_D-E_F)/k_BT}}\n$$</div>\n\n<p>$E_F$ 在掺杂半导体里求不出来，因此尝试消去它，得到：</p>\n<p>温度很低时（$E_i &gt;&gt; k_BT$），少量施主电离激发电子</p>\n<div>$$\nn\\approx\\frac{\\left[4\\left(\\frac{N_D}{N_-}\\right)e^{E_i/k_BT}\\right]^{1/2}}{\\left(\\frac2{N_-}\\right)e^{E_i/k_BT}}=\\left(N_-N_D\\right)^{1/2}e^{-E_i/2k_BT}\n$$</div>\n\n<p>温度很高时（$E_i &gt;&gt; k_BT$），全部施主电离激发电子</p>\n<div>$$\n\\begin{aligned}n=&\\frac{-1+\\left[1+2{\\left(\\frac{N_D}{N_-}\\right)}e^{E_i/k_BT}+...\\right]}{\\frac2{N_-}e^{E_i/k_BT}}\\approx N_D\\\\\\end{aligned}\n$$</div>\n\n<p>一般室温下热激发到导带的电子数也符合上式，按指数关系随温度升高而增加 （慎用！）</p>\n<p>空穴的浓度是</p>\n<div>$$\np = (n_i)^2/n\n$$</div>\n\n<p>费米能级</p>\n<div>$$\n\\begin{aligned}\nE_{F}& =E_--k_BT\\ln(N_-/n)  \\\\\n&=E_{Fi}+k_BT\\ln(n/n_i)\n\\end{aligned}\n$$</div>\n\n<p>施主杂质的浓度越高，费米能级越靠近导带</p>\n<p>受主类似：</p>\n<p>温度很低时（$E_i &gt;&gt; k_BT$）</p>\n<div>$$\np\\thickapprox\\left(N_AN_+\\right)^{1/2}e^{-E_i/2k_BT}\n$$</div>\n\n<p>温度很高时（$E_i &lt;&lt; k_BT$）</p>\n<div>$$\np\\approx N_A\n$$</div>\n\n<div>$$\n\\begin{aligned}&E_F=E_++k_BT\\ln(N_+/p)\\\\&=E_{Fi}-k_BT\\ln(p/n_i)\\end{aligned}\n$$</div>\n\n<p>受主杂质的浓度越高，费米能级越靠近价带</p>\n<p>考虑施主和受主能级简并和电子自旋取向时引入施主和受主能级基态简并因子gD和gA。</p>\n<div>$$\nn=\\frac{-1+\\left[1+4\\left(\\frac{g_DN_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_D}{N_-}\\right)e^{E_i/k_\\mathrm{B}T}}\\\\p=\\frac{-1+\\left[1+4\\left(\\frac{g_AN_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}\\right]^{1/2}}{2\\left(\\frac{g_A}{N_+}\\right)e^{E_i/k_\\mathrm{B}T}}\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1715053184570.png\" alt=\"1715053184570\"></p>\n<p>中间的平台区域意味着施主已经给出了所有电子。</p>\n<p>在足够高的温度下，由满带到导带的电子激发（本征激发）将成为主要的。</p>\n<p><img src=\"/../images/SolidPhysics/1715053408715.png\" alt=\"1715053408715\"></p>\n<p>在足够高的温度下，费米能级同样也接近本征费米能级。</p>\n<p>以上讨论的是非简并半导体。</p>\n<p>对于简并半导体，不能再使用玻尔兹曼分布，只能使用费米-狄拉克分布。</p>\n<h4 id=\"补偿半导体的载流子浓度\"><a href=\"#补偿半导体的载流子浓度\" class=\"headerlink\" title=\"补偿半导体的载流子浓度\"></a>补偿半导体的载流子浓度</h4><p>完全电离条件下</p>\n<div>$$\nn_0+N_a=p_0+N_d\\\\\np_0 = n_i^2/n_0\n$$</div>\n\n<div>$$\nn_0=\\frac{(N_d-N_a)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\\\\\np_0=\\frac{(N_a-N_d)}2+\\sqrt{\\left(\\frac{(N_d-N_a)}2\\right)^2+n_i^2}\n$$</div>\n\n<p>n-type 和 p-type 的效果可以相互抵消。</p>\n<p>由于补偿半导体中掺有两种杂质，所以会产生杂质的补偿作用，从而其中能够参加导电的多数载流子，就只有由那些未被补偿的杂质来提供；因此补偿半导体中有效的载流子浓度很小，故电阻率很高。虽然补偿半导体的电阻率很高，但它<strong>不同于未掺杂的本征半导体。</strong></p>\n<p>总的杂质浓度</p>\n<div>$$\nN_{doping}{=}N_A{+}N_D\n$$</div>\n\n<h3 id=\"载流子的迁移（漂移）运动\"><a href=\"#载流子的迁移（漂移）运动\" class=\"headerlink\" title=\"载流子的迁移（漂移）运动\"></a>载流子的迁移（漂移）运动</h3><p>迁移率 $\\mu$：单位电场下载流子的平均漂移速度</p>\n<div>$$\n\\sigma=nq\\mu\n$$</div>\n\n<div>$$\nj=nq\\left(\\mu E\\right)\\\\\n\\sigma=\\frac{nq^2\\tau}{m^*}=nq\\frac{q\\tau}{m^*}=nq\\mu\\\\\n\\mu=\\frac{q\\tau}{m^*}\n$$</div>\n\n<div>$$\n\\sigma=nq\\mu_-+pq\\mu_+\n$$</div>\n\n<p>多子导电：</p>\n<div>$$\n\\sigma\\approx\\begin{cases}nq\\mu_-&(n\\text{型 })\\\\pq\\mu_+&(p\\text{型 })&\\end{cases}\n$$</div>\n\n<p>迁移率决定于有效质量以及平均弛豫时间</p>\n<div>$$\n\\mu_-=\\frac{q\\tau_{cn}}{m_-^*}\\quad\\mu_+=\\frac{q\\tau_{cp}}{m_+^*}\n$$</div>\n\n<p>在低温下，杂质的散射是主要的。温度升高时载流子热运动的速度增大，电离杂质的散射作用相应减弱，从而使迁移率增大。</p>\n<p>在较高温度下，晶格的散射是主要的，温度升高，声子的散射增大，因而迁移率随温度的升高而下降。</p>\n<p>半导体的电导率σ除了与迁移率有关外，还与载流子的浓度有关。而载流子的浓度随温度的升高以指数形式增加（饱和区除外）。因此除饱和区外，电导率主要以指数形式随温度的升高而迅速增大，表现出很强的热敏性。但是，不是温度越高就越好的，温度升高后，掺杂的特性就没了，导电能力主要由本征激发决定，相当于半导体退化成了一块普通的电阻，也没有什么 PN 结了。</p>\n<p>这与金属的电导率有明显不同。因为金属的载流子（电子或空穴）浓度与温度无关，温度升高时，传导电子的迁移率因与声子的碰撞更加频繁而减小，所以金属的导电率温度系数为负，温度升高，电导率下降。</p>\n<h2 id=\"PN-结\"><a href=\"#PN-结\" class=\"headerlink\" title=\"PN 结\"></a>PN 结</h2><h3 id=\"功函数\"><a href=\"#功函数\" class=\"headerlink\" title=\"功函数\"></a>功函数</h3><p>金属发射电流与温度有关，符合指数规律：</p>\n<div>$$\nj\\propto e^{\\large-\\frac{W}{k_BT}}\n$$</div>\n\n<p>其中 $W$ 称功函数。</p>\n<p>经典理论：</p>\n<div>$$\nj=-n_0q\\left(\\frac{k_BT}{2\\pi m}\\right)^{1/2}e^{-\\frac\\chi{k_BT}}\n$$</div>\n\n<p>功函数：</p>\n<div>$$\nW = \\chi\n$$</div>\n\n<p>统计分布：</p>\n<div>$$\ndn=n_0\\left(\\frac m{2\\pi k_BT}\\right)^{3/2}e^{-\\frac{m\\upsilon^2}{2k_BT}}d\\upsilon\n$$</div>\n\n<p>量子理论：</p>\n<div>$$\nj=-q\\frac{4\\pi m{\\left(k_BT\\right)}^2}{\\left(2\\pi\\hbar\\right)^3}e^{-\\left(\\chi-E_F\\right)/k_BT}\n$$</div>\n\n<p>功函数</p>\n<div>$$\nW = \\chi - E_F\n$$</div>\n\n<p>统计分布：</p>\n<div>$$\ndn=2{\\left(\\frac m{2\\pi\\hbar}\\right)}^3\\frac1{e^{\\left(\\frac12m\\upsilon^2-E_F\\right)/k_BT}+1}d\\upsilon\n$$</div>\n\n<p>金属有接触电势，从费米能级高的地方流向费米能级低的。</p>\n<p><img src=\"/../images/SolidPhysics/1715657785337.png\" alt=\"1715657785337\"></p>\n<div>$$\nV_A - V_B = (W_B - W_A)/q\n$$</div>\n\n<p>平衡态下，费米能级变为相等，电子不再流动。</p>\n<h3 id=\"PN-结-1\"><a href=\"#PN-结-1\" class=\"headerlink\" title=\"PN 结\"></a>PN 结</h3><p>载流子扩散运动：</p>\n<p><img src=\"/../images/SolidPhysics/1715658350241.png\" alt=\"1715658350241\"></p>\n<p>非平衡载流子：复合运动</p>\n<p>在外界的作用下，半导体中的电子浓度n和空穴浓度p有可<br>能偏离平衡值。例如半导体的本征光吸收产生电子—空穴<br>对，用Δn＝n－n0，Δp＝p－p0表示超出热平衡的多余载流<br>子，称为非平衡载流子。通常情况下，由于电中性要求，<br>Δn＝Δp</p>\n<p>我们最关心的是非平衡的少数载流子，因为少子的浓度变化大，通常采用准费米能级 $E_{Fn}, E_{Fp}$。多子的费米能级不变。</p>\n<div>$$\n\\begin{aligned}n_0+\\Delta n&=n_i\\exp(\\frac{E_{Fn}-E_{Fi}}{kT})\\\\\\left(n_0+\\Delta n\\right)\\cdot\\left(p_0+\\Delta p\\right)>n_i^2\\\\p_0+\\Delta p&=n_i\\exp(\\frac{E_{Fi}-E_{Fp}}{kT})\\end{aligned}\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1715658620805.png\" alt=\"1715658620805\"></p>\n<p>外界作用下， 非平衡态要恢复到平衡态。非平衡的载流子会消失，消失的过程叫复合，导带的多余电子落回价带，多余的电子和空穴成对消失。</p>\n<p>复合速率：</p>\n<div>$$\n\\frac{d\\Delta n}{dt}=-\\frac{\\Delta n}{\\tau}\\\\\\text{其解为:}\\quad\\Delta n=(\\Delta n)_0\\exp(-t/\\tau)\n$$</div>\n\n<p>$\\tau$ 称为非平衡载流子寿命</p>\n<h4 id=\"非平衡载流子的扩散和复合\"><a href=\"#非平衡载流子的扩散和复合\" class=\"headerlink\" title=\"非平衡载流子的扩散和复合\"></a>非平衡载流子的扩散和复合</h4><p>直接复合：复合率 $R&#x3D;\\alpha_r\\cdot n\\cdot p$</p>\n<p>间接复合：通过杂质能级的间接复合（与杂质浓度呈正比，与非平衡载流子浓度呈正比，深能级更强）</p>\n<p>非平衡状态下，过剩电子的复合率一定等于过剩空穴的复合率</p>\n<div>$$\nR_n^{\\prime}=R_p^{\\prime}\n$$</div>\n\n<p>扩散复合过程的稳定分布：</p>\n<div>$$\n-\\frac d{dx}\\Bigg(-D\\frac{dN}{dx}\\Bigg)-\\frac N\\tau=0\\\\N=N_0e^{-x/L},L=\\sqrt{D\\tau}\n$$</div>\n\n<p>扩散长度L：表面非平衡载流子深入材料内部的距离，随扩散系数和复合寿命增加而增加</p>\n<div>$$\n\\text{扩散流密度 }=-D\\frac{dN}{dx}=N_0\\frac DLe^{-x/L}\n$$</div>\n\n<p>扩散速度D&#x2F;L：界面处载流子以速度D&#x2F;L运动</p>\n<p>漂移 + 扩散 的总电流密度：</p>\n<div>$$\nJ=qn\\mu_nE_x+qp\\mu_pE_x+qD_n\\frac{dn}{dx}-qD_p\\frac{dp}{dx}\n$$</div>\n\n<p>爱因斯坦关系：</p>\n<div>$$\n\\frac{D_n}{\\mu_n}=\\frac{k_\\text{B}T}q\\quad\\frac{D_p}{\\mu_p}=\\frac{k_\\text{B}T}q\n$$</div>\n\n<h4 id=\"PN-结的接触电势差\"><a href=\"#PN-结的接触电势差\" class=\"headerlink\" title=\"PN 结的接触电势差\"></a>PN 结的接触电势差</h4><p><img src=\"/../images/SolidPhysics/1715659347111.png\" alt=\"1715659347111\"></p>\n<div>$$\neV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\\\\qV_D=\\left(E_F\\right)_N-\\left(E_F\\right)_P\n$$</div>\n\n<div>$$\n\n\n<p>$$</div></p>\n<p>$V_D$ 等于接触前的费米能级差。</p>\n<p><img src=\"/../images/SolidPhysics/1715659894626.png\" alt=\"1715659894626\"></p>\n<h3 id=\"正向偏压-载流子扩散运动产生电流\"><a href=\"#正向偏压-载流子扩散运动产生电流\" class=\"headerlink\" title=\"正向偏压-载流子扩散运动产生电流\"></a>正向偏压-载流子扩散运动产生电流</h3><p>p 区看电子，n 区看空穴：</p>\n<p><img src=\"/../images/SolidPhysics/1716257709851.png\" alt=\"1716257709851\"></p>\n<p>0 表示热平衡时候的浓度。</p>\n<h3 id=\"反向偏压-漂移作用增强\"><a href=\"#反向偏压-漂移作用增强\" class=\"headerlink\" title=\"反向偏压-漂移作用增强\"></a>反向偏压-漂移作用增强</h3><p><img src=\"/../images/SolidPhysics/1716257832298.png\" alt=\"1716257832298\"></p>\n<p><img src=\"/../images/SolidPhysics/1716257919907.png\" alt=\"1716257919907\"></p>\n<p>正向注入：</p>\n<p>当PN结加正向偏压时：$\\mathsf{PN}$结势垒降低为$q(V_D-V)$扩散作用增强</p>\n<p>反向抽取：</p>\n<p>当PN结加反向偏压时：$\\mathsf{PN}$结势垒升高为$q(V_D+V)$漂移作用增强</p>\n<p>反向抽取时载流子的复合率为负数，就是说在不断地产生新的载流子（电子-空穴对）。PN结的反向电流实质上就是产生电流。</p>\n<p><img src=\"/../images/SolidPhysics/1716258157706.png\" alt=\"1716258157706\"></p>\n<h3 id=\"PN-结的击穿\"><a href=\"#PN-结的击穿\" class=\"headerlink\" title=\"PN 结的击穿\"></a>PN 结的击穿</h3><p><img src=\"/../images/SolidPhysics/1716258191070.png\" alt=\"1716258191070\"></p>\n<h3 id=\"双极性晶体管\"><a href=\"#双极性晶体管\" class=\"headerlink\" title=\"双极性晶体管\"></a>双极性晶体管</h3><p><img src=\"/../images/SolidPhysics/1716258575169.png\" alt=\"1716258575169\"></p>\n<h2 id=\"异质结与肖特基结\"><a href=\"#异质结与肖特基结\" class=\"headerlink\" title=\"异质结与肖特基结\"></a>异质结与肖特基结</h2><h3 id=\"半导体异质结\"><a href=\"#半导体异质结\" class=\"headerlink\" title=\"半导体异质结\"></a>半导体异质结</h3><p>真空能级：电子自由运动所占据的最低能量。</p>\n<p><img src=\"/../images/SolidPhysics/1716259850103.png\" alt=\"1716259850103\"></p>\n<p><img src=\"/../images/SolidPhysics/1716260746330.png\" alt=\"1716260746330\"></p>\n<p><img src=\"/../images/SolidPhysics/1716259893782.png\" alt=\"1716259893782\"></p>\n<p>导带能级差：$\\Delta E_C&#x3D;\\chi_1-\\chi_2$<br>价带能级差：$\\Delta E_v&#x3D;(\\chi_2+E_{g^2})-(\\chi_1+E_{g^1})&#x3D;E_{g^2}-E_{g^1}-\\Delta E_{g^2}$<br>导带能级差+价带能级差 &#x3D;带隙宽度差<br>注：此为一般半导体物理书中的结果</p>\n<p><img src=\"/../images/SolidPhysics/1716260901275.png\" alt=\"1716260901275\"></p>\n<h3 id=\"同质结的注入比\"><a href=\"#同质结的注入比\" class=\"headerlink\" title=\"同质结的注入比\"></a>同质结的注入比</h3><p>总电流：$j&#x3D; j_n+ j_p&#x3D; j_s\\left ( e^{qV&#x2F; K_BT}- 1\\right )$</p>\n<p>注入比定义：总电流中，电子电流与空穴电流的比例<br>普通PN结(同质结)</p>\n<p>注入到$p$区的电子电流密度为：$j_n&#x3D; q\\frac {D_n}{L_n}n_P^0\\left ( e^{qV&#x2F; k_BT}- 1\\right )$</p>\n<p>注入到$n$区的空穴电流密度为：$j_p&#x3D; q\\frac {D_p}{L_p}p_N^0\\left ( e^{qV&#x2F; k_BT}- 1\\right )$</p>\n<p>总电流：$j&#x3D; j_n+ j_p&#x3D; j_s\\left ( e^{qV&#x2F; k_BT}- 1\\right )$<br>注入比定义：总电流中，电子电流与空穴电流的比例<br>正偏压下的电子注入比：</p>\n<div>$$\n\\begin{aligned}&\\frac{j_n}{j_p}=\\frac{D_nn_P^0}{L_n}\\frac{D_pp_N^0}{L_p}=\\frac{D_nL_pn_P^0}{D_pL_np_N^0}\\\\&n_P^0=\\frac{n_i^2}{p_P}\\approx\\frac{n_i^2}{N_A}\\\\&p_{N}^{0}=\\frac{n_{i}^{2}}{n_{N}}\\approx\\frac{n_{i}^{2}}{N_{D}}\\\\&\\frac{j_n}{j_p}=\\frac{D_nL_pN_D}{D_pL_nN_A}\\end{aligned}\n$$</div>\n\n<p>提高注入比的办法,提高N型区的施主杂质浓度</p>\n<p><img src=\"/../images/SolidPhysics/1716261236429.png\" alt=\"1716261236429\"></p>\n<p>结中电子注入比：</p>\n<div>$$\n\\begin{aligned}&\\frac{J_n}{J_p}=\\frac{D_nn_P^0}{L_n}\\left/\\frac{D_pp_N^0}{L_p}\\right.=\\frac{D_nL_pN_D}{D_pL_nN_A}e^{\\frac{E_{gN}-E_{gP}}{k_BT}}\\end{aligned}\n$$</div>\n\n<p>异质结构的优点：</p>\n<p>也就是说，N型区的带隙宽度比p型区带隙宽度大，<br>可以进一步以指数级增加注入比</p>\n<p>提高注入比的意义<br>提高晶体管放大系数-异质结双极晶体管HBT</p>\n<p><img src=\"/../images/SolidPhysics/1716261409659.png\" alt=\"1716261409659\"></p>\n<h3 id=\"激光器\"><a href=\"#激光器\" class=\"headerlink\" title=\"激光器\"></a>激光器</h3><p>本征光吸收</p>\n<p>光照激发价带电子到导带， 形成电子-空穴对的过程</p>\n<div>$$\n\\hbar\\omega\\geq E_{_g}\n$$</div>\n\n<p>准动量守恒——竖直跃迁</p>\n<p>应当照射结区（空间电荷区）</p>\n<p><img src=\"/../images/SolidPhysics/1716261766058.png\" alt=\"1716261766058\"></p>\n<p><img src=\"/../images/SolidPhysics/1716261781489.png\" alt=\"1716261781489\"></p>\n<p>二维电子气体系提高电子迁移率</p>\n<p><img src=\"/../images/SolidPhysics/1716262583215.png\" alt=\"1716262583215\"></p>\n<p><img src=\"/../images/SolidPhysics/1716262570823.png\" alt=\"1716262570823\"></p>\n<h3 id=\"肖特基结\"><a href=\"#肖特基结\" class=\"headerlink\" title=\"肖特基结\"></a>肖特基结</h3><p>功函数的物理本质是真空能级与费米能级的差</p>\n<p>亲合能：从导带底部到真空能级的能量（真空-导带底）</p>\n<p><img src=\"/../images/SolidPhysics/1716263334906.png\" alt=\"1716263334906\"></p>\n<p>金属与 N 型半导体的接触：</p>\n<p><img src=\"/../images/SolidPhysics/1716263526504.png\" alt=\"1716263526504\"></p>\n<p><img src=\"/../images/SolidPhysics/1716263538645.png\" alt=\"1716263538645\"></p>\n<div>$$\n\\boxed{\\begin{array}{c}\\text{肖特基势垒}\\\\\\phi_{B0}=\\left(\\phi_m-\\chi\\right)\\end{array}}\n$$</div>\n\n<div>$$\n\\boxed{\\begin{array}{c}\\text{内建电势差}\\\\\\\\V_{bi}=\\left(\\phi_{B0}-\\phi_n\\right)\\end{array}}\n$$</div>\n\n<p>考虑偏压：</p>\n<p><img src=\"/../images/SolidPhysics/1716263918247.png\" alt=\"1716263918247\"></p>\n<p><img src=\"/../images/SolidPhysics/1716263941957.png\" alt=\"1716263941957\"></p>\n<p><img src=\"/../images/SolidPhysics/1716863556246.png\" alt=\"1716863556246\"></p>\n<p>欧姆接触</p>\n<p><img src=\"/../images/SolidPhysics/1716864038557.png\" alt=\"1716864038557\"></p>\n<p><img src=\"/../images/SolidPhysics/1716864050264.png\" alt=\"1716864050264\"></p>\n<p>欧姆接触是指金属与半导体的接触，而其接触面的电阻值远小于半导体本身的电阻，不产生明显的附加阻抗，而且不会使半导体内部的平衡载流子浓度发生显著的改变</p>\n<p>区分电子和空穴的本质是迁移率的不同。</p>\n<h2 id=\"格波\"><a href=\"#格波\" class=\"headerlink\" title=\"格波\"></a>格波</h2><h3 id=\"一维单原子链\"><a href=\"#一维单原子链\" class=\"headerlink\" title=\"一维单原子链\"></a>一维单原子链</h3><p>相邻原子间距为</p>\n<div>$$\na+(\\mu_{n+1}-\\mu_n)=a+\\delta\n$$</div>\n\n<p>相邻原子的作用力</p>\n<div>$$\nF=-\\frac{\\partial\\nu}{\\partial\\delta}\\approx-\\beta\\delta\n$$</div>\n\n<p>左右两边一个原子对中间原子的作用力</p>\n<div>$$\nF_{n,n-1}=-\\beta\\left(\\mu_n-\\mu_{n-1}\\right)\\\\\nF_{n,n+1}=-\\beta\\left(\\mu_n-\\mu_{n+1}\\right)\\\\\nF_n=\\beta(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n)\n$$</div>\n\n<p>相邻原子之间的耦合运动方程组</p>\n<div>$$\nm\\ddot{\\mu}_n=\\beta\\left(\\mu_{n+1}+\\mu_{n-1}-2\\mu_n\\right)\n$$</div>\n\n<p>通过坐标变换简化方程组，得到简谐振动解</p>\n<div>$$\n\\mu_n=Ae^{i(\\omega t-qX_n)}\n$$</div>\n\n<p>其中 $X_n&#x3D;na$ 是第 n 个原子的平衡位置</p>\n<p>将解代入运动方程：</p>\n<div>$$\nm{\\left(i\\omega\\right)}^2Ae^{i(\\omega t-qX_n)}=\\beta Ae^{i(\\omega t-qna)}{\\left(e^{-iqa}+e^{iqa}-2\\right)}\n$$</div>\n\n<p>得到色散关系</p>\n<div>$$\n\\omega^2=\\frac{2\\beta}m\\Big(1-\\cos\\alpha q\\Big)=\\frac{4\\beta}m\\sin^2\\Bigg(\\frac{aq}2\\Bigg)\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1716868157804.png\" alt=\"1716868157804\"></p>\n<p>格波有意义的取值只在第一布里渊区，我们只关心格点位置处的取值。</p>\n<p><img src=\"/../images/SolidPhysics/1716868762789.png\" alt=\"1716868762789\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467825452.png\" alt=\"1717467825452\"></p>\n<p>波恩卡门条件下的环状链模型</p>\n<p><img src=\"/../images/SolidPhysics/1716869179928.png\" alt=\"1716869179928\"></p>\n<p><img src=\"/../images/SolidPhysics/1716869156196.png\" alt=\"1716869156196\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467681404.png\" alt=\"1717467681404\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467815166.png\" alt=\"1717467815166\"></p>\n<p><img src=\"/../images/SolidPhysics/1717467885133.png\" alt=\"1717467885133\"></p>\n<h3 id=\"一维双原子链结构\"><a href=\"#一维双原子链结构\" class=\"headerlink\" title=\"一维双原子链结构\"></a>一维双原子链结构</h3><p><img src=\"/../images/SolidPhysics/1717467940325.png\" alt=\"1717467940325\"></p>\n<p>P原子质量：m<br> Q原子质量：M</p>\n<div>$$\nm\\ddot{\\mu}_{2n}=\\beta(\\mu_{2n+1}+\\mu_{2n-1}-2\\mu_{2n})\\\\M\\ddot{\\mu}_{2n+1}=\\beta(\\mu_{2n+2}+\\mu_{2n}-2\\mu_{2n+1})\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1717468003069.png\" alt=\"1717468003069\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468014637.png\" alt=\"1717468014637\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468150691.png\" alt=\"1717468150691\"></p>\n<p>波数 q 的取值范围：</p>\n<div>$$\n-\\frac\\pi{2a}<q\\leq\\frac\\pi{2a}\n$$</div>\n\n<p>原胞变大，倒格矢变小，布里渊区变小</p>\n<div>$$\nN\\cdot\\left(2aq\\right)=2\\pi h,h=[-N/2,+N/2]\\quad q=\\frac{h\\pi}{Na}\n$$</div>\n\n<p>对于双原子链，有2N个原子，也有2N个格波</p>\n<p><img src=\"/../images/SolidPhysics/1717468250438.png\" alt=\"1717468250438\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468279238.png\" alt=\"1717468279238\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468352260.png\" alt=\"1717468352260\"></p>\n<p><img src=\"/../images/SolidPhysics/1717468364464.png\" alt=\"1717468364464\"></p>\n<p>相邻原子振动相反，振幅反比于原子质量</p>\n<p>对于声学波，相邻原子同步运动,原胞中两种原子的运动是完全一致的振幅和位相</p>\n<p><img src=\"/../images/SolidPhysics/1717469037238.png\" alt=\"1717469037238\"></p>\n<p><img src=\"/../images/SolidPhysics/1717469080107.png\" alt=\"1717469080107\"></p>\n<p><img src=\"/../images/SolidPhysics/1717469005887.png\" alt=\"1717469005887\"></p>\n<p>k 代表的是移动一个原胞后的位相差。</p>\n<p>简单晶格没有能带折叠，所以没有光学波。</p>\n<p><img src=\"/../images/SolidPhysics/1717469702087.png\" alt=\"1717469702087\"></p>\n<p><img src=\"/../images/SolidPhysics/1717470027229.png\" alt=\"1717470027229\"></p>\n<p>如果问的是“多少个”光学波&#x2F;声学波，还得×一个 N</p>\n<p>横波才能简并，纵波不能。</p>\n<p>硅的晶格中虽然只有硅一种原子，但是由于是复式晶格结构，等同于有两种原子，因此也有声学波和光学波</p>\n<p>金属铅(Pb)属于面心立方的简单晶格结构，没有光学波只有三支声学波（注：不同方向上有简并）</p>\n<p>纵波的速度总是比横波快。</p>\n<h3 id=\"晶格振动的量子化——声子\"><a href=\"#晶格振动的量子化——声子\" class=\"headerlink\" title=\"晶格振动的量子化——声子\"></a>晶格振动的量子化——声子</h3><p>一维谐振子</p>\n<p><img src=\"/../images/SolidPhysics/1717470756612.png\" alt=\"1717470756612\"></p>\n<h3 id=\"固体热容\"><a href=\"#固体热容\" class=\"headerlink\" title=\"固体热容\"></a>固体热容</h3><div>$$\nC_V=\\left(\\frac{\\partial\\overline{E}}{\\partial T}\\right)_V\n$$</div>\n\n<p>固体热容主要来自于两个部分</p>\n<p>晶格热容：来源于固体的晶格热运动</p>\n<p>电子热容：来源于电子的热运动仅在,极低温下，对于金属比较显著，相比晶格热容，一般可忽略不计</p>\n<p><img src=\"/../images/SolidPhysics/1717473776761.png\" alt=\"1717473776761\"></p>\n<p>经典模型</p>\n<p><img src=\"/../images/SolidPhysics/1717473805195.png\" alt=\"1717473805195\"></p>\n<p>量子模型</p>\n<p><img src=\"/../images/SolidPhysics/1718071135404.png\" alt=\"1718071135404\"></p>\n<p>高温情况下</p>\n<p><img src=\"/../images/SolidPhysics/1718071202034.png\" alt=\"1718071202034\"></p>\n<p>在较高温度时，杜隆-珀替定律成立。即当振子的能量远远大于能量的量子( ħωq)时，量子化效应就可以忽略</p>\n<p><img src=\"/../images/SolidPhysics/1718071363760.png\" alt=\"1718071363760\"></p>\n<p>爱因斯坦模型</p>\n<p>基本假设</p>\n<p>晶格中所有原子都具有统一振动频率$\\omega_0$</p>\n<p>所有原子的振动是独立的</p>\n<p>假设有$N$个原子</p>\n<p><img src=\"/../images/SolidPhysics/1718071563960.png\" alt=\"1718071563960\"></p>\n<p><img src=\"/../images/SolidPhysics/1718071692546.png\" alt=\"1718071692546\"></p>\n<p>爱因斯坦模型较经典模型的改进明显，阐明低温热容趋于零的基本原因</p>\n<p>爱因斯坦模型低温段热容下降很陡，与实验值有不相符的问题</p>\n<p>原子与原子间的相互作用是很强的，晶格振动是以格波的形式存在，不同格波之间的频率不完全相同，而且有一定分布爱因斯坦模型等效于所有的格波频率相同过于简单</p>\n<p>德拜模型</p>\n<p><img src=\"/../images/SolidPhysics/1718071922789.png\" alt=\"1718071922789\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072084533.png\" alt=\"1718072084533\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072235738.png\" alt=\"1718072235738\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072255786.png\" alt=\"1718072255786\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072474995.png\" alt=\"1718072474995\"></p>\n<p>德拜温度</p>\n<div>$$\n\\Theta_D=\\frac{\\hbar\\omega_m}{k_B}\n$$</div>\n\n<div>$$\n\\omega_m=\\overline{C}\\bigg[6\\pi^2\\frac NV\\bigg]^{1/3}\n$$</div>\n\n<p><img src=\"/../images/SolidPhysics/1718072707268.png\" alt=\"1718072707268\"></p>\n<p><img src=\"/../images/SolidPhysics/1718072997880.png\" alt=\"1718072997880\"></p>\n"},{"title":"DigiRL","katex":true,"date":"2024-07-17T15:53:27.000Z","_content":"## DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning\n\nLLM (VLM) +RL 的完美之作！在 Pretraining 的基础上进行 Offline RL，然后在执行任务时通过 Online RL 更新参数，特色是能够从多轮交互中学习、更新参数，而不是通过专家知识微调一个单步交互模型。实验也做得非常详细。不过 RL 的部分我还看不太懂，需要继续学习。\n\n![1721230554686](../images/Mobile-LLM/1721230554686.png)\n\nAction Space 定义为点击、滑动、输入、home 键、返回等操作，参数包含屏幕上的归一化 (x, y) 坐标。另外引入的一个设定是界面的随机性，界面可能有随时更新、加载中、小广告、身份识别等干扰出现。\n\n![1721231007829](../images/Mobile-LLM/1721231007829.png)\n\n## RL 算法部分\n\n首先本文将手机操作问题建模为一个 MDP 过程。\n\n然后采用了 AWR 算法，计算策略梯度。似乎用到了蒙特卡洛？\n\nInstruction-Level Value Function 有什么作用？这里似乎是说 task set 的难度方差太大，需要用难度适中的数据去训练 actor model，所以提出了则个 Value Function 来过滤一部分数据。\n\n![1721232302611](../images/DigiRL/1721232302611.png)\n\n首先，定义 Advantage 为一个状态的 Q 值（按照当前策略，未来所有步的期望值）减去 Value function：\n\n$$\nA^\\pi(s_h,a_h,c)=Q^\\pi(s_h,a_h,c)-V^\\pi(s_h,c).\n$$\n\nAWR 算法的 Actor 优化目标是一个加权的 MLE：\n\n$$\n\\arg\\max_\\pi\\mathbb{E}_\\nu\\left[\\log\\pi(a|s,c)\\cdot\\exp\\left(A(s,a,c)/\\beta\\right)\\right]\n$$\n\n在论文中没有用这个公式，而是用 hard filtering 替代：\n\n$$\n\\mathcal{L}(\\pi)=-\\mathbb{E}_{\\mathrm{filter}(\\nu)}[\\log\\pi(a|s,c)].\n$$\n\nStep Advantage 的估计采用的是 GAE (Generalized Advantage Estimation) 的简化版：\n\n$$\nA^{\\mathrm{step}}(s_h,a_h,c):=\\lambda^{H-h}r(s_H,a_H,c)+(1-\\lambda^{H-h}r(s_H,a_H,c))(V^{\\mathrm{step}}(s_{h+1},c)+r(s_h,a_h,c)-V^{\\mathrm{step}}(s_h,c))\n$$\n\n之所以可以这么做，是因为任务的奖励只有在最后一步有，成功了是1，失败了是0，第一项是高方差的 MC，第二项是高偏差的估计器。随着 h 增加，第一项的权重越来越大，第二项权重则越来越小。这两项综合起来有利于均衡方差与偏差。\n\n此外，我们还要定义 Instruct Advantage，用来评估一条 traj 的学习价值：\n\n![1721316686785](../images/DigiRL/1721316686785.png)\n\n个人理解，traj 的学习价值取决于 traj 奖励值和指令平均奖励的差。\n\ntraj 的奖励值就是当前这条路径拿到的奖励总和。\n\n“指令平均奖励”就是当前指令下获得奖励的期望值，取决于任务的难易程度，因为它是对该任务所有 traj 的平均，任务越难，奖励更难拿到，指令平均奖励越低。\n\n那么，traj 的奖励值越高，traj 的学习价值就越高，直觉上即成功的任务（奖励为1）有学习价值，但是失败的任务（奖励为0）不值得学习；\n\n指令平均奖励越高，traj 的学习价值越低，这是因为指令平均奖励高，意味着这个任务很简单，不值得学习。\n\n关于估计器的训练，采用的是交叉熵损失而不是传统的 MSE 损失，这是因为交叉熵损失通常在 transformer 架构上更好用：\n\n![1721316668685](../images/DigiRL/1721316668685.png)\n\n而且巧妙的点在于这个任务的奖励只有 1 或 0，因此估计器其实可以看作一个二分类，交叉熵就只有两项。\n\n最终的 pipeline：\n\n* 训练 Step-level 和 Instruct-level 的估计器 V；\n* 用估计器 V 计算学习价值 A，通过学习价值过滤掉一部分无效 traj 和 step；\n  * 具体而言，Instruct-level 选取 top-p 条 traj；\n  * Step-level 选取阈值大于 1/H 的 step.\n* 在过滤后的 traj 上采用 MLE 准则训练模型。\n\n## 模型架构\n\n在 AutoUI-Base 的基础上进行训练，固定 image encoder 不动。\n\n### Instruction and Step Level Value Functions\n\n输入：采用 image encoder 与 RoBERTa 分别对界面截图和指令进行 embedding，拼接起来。\n\n用 2 层的 MLP 来预测 Value function。\n\n### Actor\n\n在离线学习阶段，通过运行原始的 AutoUI-Base 来采集 traj。在 offline 阶段，跳过了 instruction-level filtering，用所有的 instruction 来训练，用以充分地利用数据。\n\nDecoder 具体要输出什么？是文本吗？那数值是怎么处理的？大模型能很好地理解数值吗？（9.11 > 9.8？？）\n\n答：按照 Auto-GUI 的说法，确实是文本，点击屏幕需要用到一个 0~1 之间的 4 位小数。感觉这样肯定有很多问题，例如语言模型怎么理解空间关系和数值关系？它是不是只是背下了 UI 的数字信息？UI 的理解和识别工作应该已经有很多了。\n\n如果要验证这点，可以设计一个空间方位相关的 Instruction，例如让它点击按钮 A 上方的那个按钮，语言模型不可能回答出来。或者，将按钮平移一段距离，看模型对于按钮位置的预测是否出现了一致的平移？\n\n我比较相信的一种可能是，Image Encoder 在编码时确实把 UI 的位置坐标信息和语义信息编码进了 Embedding 中，并且在 Decoding 阶段确实被识别了出来，这样想倒也是自洽的。如何验证？\n\n## 评测部分\n\n评测采用的是 Gemini-1.5-pro，据论文报告结果和人类的评估接近。评测标准是通过一个端到端的观察，判断是否完成了任务。\n\n## 消融实验和分析\n\n### 错误分析\n\n整体上，所有测试的 Agent 存在三种错误：\n\n* 很难从错误中纠正\n* 在中途卡住，例如搜索之后不知道点搜索按钮\n* 到达了错误的目标，例如走错了网购网站\n\n错误1、3貌似都是任务规划层面的问题，而不是操作执行的问题，模型之所以出错是因为它没有产生正确的意图，而不是它不理解 UI 界面本身。错误 2 是一个 UI 理解的问题。也就是说，作者可能认为模型在 planning 方面的问题是最主要的。当然作者并没有严格区分这二者，因为训练时就是以多轮操作执行为目标进行训练的。当然，这二者可能确实是无法分开的，因为不理解 UI 界面的逻辑，就无法进行正确的任务规划。\n\n作者认为，预训练模型之所以为什么会出现这样的错误，是因为它们无法应对动态性强的环境，进入了之前从未见过的界面时候就不知道怎么从其中出来了。相反，DigiRL 通过收集 Rollouts 数据，学会了从错误中学习，从而纠正自己的错误。\n\n我觉得这个说法有点牵强，首先这个只能解释错误类型 1、3，不能解释类型2。并不是所有模型都在预训练时接受了特定的 APP 界面相关的数据，例如 GPT-4V，AITW 的手机界面对于他来说，都是“没见过”的界面，而且点搜索按钮这件事没有太多的动态性，这跟动态性没什么关系，这个例子根本上说明的是它不理解 UI 界面语言：\n\n![1721554892738](../images/DigiRL/1721554892738.png)\n\n它没有理解界面的内容，认为搜索框右边那个×号是搜索的意思。实际上，这个任务确实有些 tricky，因为浏览器是不提供搜索键的，回车键在这个场景中充当了搜索键的作用。GPT-4V 首先应该理解到右下角那个箭头指的是回车，第二步是认识到回车键在浏览器场景下的搜索意义。\n\n我倾向于 GPT-4V 没有理解第一步，也就是图标本身表示回车，可能它会认为这就是一个箭头。第二步对这样的模型而言应该是非常简单就能转过来的。而且更致命的是，这个 UI 里回车根本没标上数字，那 GPT-4V 即使知道要点回车，它也没有选择的机会。比如下面这个例子：\n\n![1721555459238](../images/DigiRL/1721555459238.png)\n\n很好笑的是，它知道“键盘上有一个搜索按钮”，但是这个按钮没标数字，它只好点击了和那个回车键距离最近的 24 号，然后它就成功点进了广告。排除广告干扰这件事本身可能相当重要，需要专门的对齐工作。\n\n这里的例子全是 GPT-4V 的，感觉没什么看头，毕竟是附录，可能写得没那么认真。\n\n![1721555695196](../images/DigiRL/1721555695196.png)\n\n网购这件事可能相对比较困难一点，可以看到主要的困难都是在点击按钮和走错界面上（除了 Gemini 完全无法正常 work，hh），模型产生了正确的意图，但是点错了地方，即使是论文自己的模型也没能幸免，毕竟 Image Encoder 是固定不动的。也就是说模型对于 UI 操作的理解并不充分。\n\n总体而言，错误类型可以分成 3 类：\n\n* 任务规划错误：Recover from mistakes, Fail at all\n* UI 理解错误：包括两个子类：\n  * 不可交互，仅可阅读的 UI 元素意义理解错误：Quit Early, wrong page\n  * 可交互 UI 元素的理解错误：Click on link or type\n\nDigiRL 的工作，主要解决了任务规划方面的错误，因为模型可以接受奖励信号，判断整条 trace 是否做错了。仔细想想这对于 GPT-4V 是不公平的，因为没人告诉 4V 是否做错了，4V 也不可能接受 1000 条 traj 的 Online Training，信息量自然少了很多。\n\n但是对比而言，模型主要的错误可能还是在 UI 理解上。模型对于 UI 元素理解的能力还是很差，像 4V 这种模型甚至也会有理解错误。VLM 的能力还任重道远。\n\n因此其实后续工作可以探讨的还有很多：\n\n* UI 理解与交互，个人认为是目前手机 Agent 最关键的点；\n* 任务规划，这个就接着 DigiRL 的思路，RL 的方法虽然成功实现了 Online Training，但是先验知识利用不足，需要 1k 量级的数据去学会一个没见过的任务，能不能做到像 ChatGPT 那样 ICL 就能直接拿下一个新任务？（这个可能很难，需要大量的标注数据）\n* 异常页面处理，包括怎么鉴别误导页面，怎么从广告、弹窗、警告等非常规界面中退出，这个也许很新颖，至少我想不到有什么工作在做这个，但是这个事情可能对于 wild env 的 Agent 非常重要。\n","source":"_posts/DigiRL.md","raw":"---\ntitle: DigiRL\nkatex: true\ndate: 2024-07-17 23:53:27\ntags: \n  - paper\n  - Mobile\n  - RL\n  - LLM\n---\n## DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning\n\nLLM (VLM) +RL 的完美之作！在 Pretraining 的基础上进行 Offline RL，然后在执行任务时通过 Online RL 更新参数，特色是能够从多轮交互中学习、更新参数，而不是通过专家知识微调一个单步交互模型。实验也做得非常详细。不过 RL 的部分我还看不太懂，需要继续学习。\n\n![1721230554686](../images/Mobile-LLM/1721230554686.png)\n\nAction Space 定义为点击、滑动、输入、home 键、返回等操作，参数包含屏幕上的归一化 (x, y) 坐标。另外引入的一个设定是界面的随机性，界面可能有随时更新、加载中、小广告、身份识别等干扰出现。\n\n![1721231007829](../images/Mobile-LLM/1721231007829.png)\n\n## RL 算法部分\n\n首先本文将手机操作问题建模为一个 MDP 过程。\n\n然后采用了 AWR 算法，计算策略梯度。似乎用到了蒙特卡洛？\n\nInstruction-Level Value Function 有什么作用？这里似乎是说 task set 的难度方差太大，需要用难度适中的数据去训练 actor model，所以提出了则个 Value Function 来过滤一部分数据。\n\n![1721232302611](../images/DigiRL/1721232302611.png)\n\n首先，定义 Advantage 为一个状态的 Q 值（按照当前策略，未来所有步的期望值）减去 Value function：\n\n$$\nA^\\pi(s_h,a_h,c)=Q^\\pi(s_h,a_h,c)-V^\\pi(s_h,c).\n$$\n\nAWR 算法的 Actor 优化目标是一个加权的 MLE：\n\n$$\n\\arg\\max_\\pi\\mathbb{E}_\\nu\\left[\\log\\pi(a|s,c)\\cdot\\exp\\left(A(s,a,c)/\\beta\\right)\\right]\n$$\n\n在论文中没有用这个公式，而是用 hard filtering 替代：\n\n$$\n\\mathcal{L}(\\pi)=-\\mathbb{E}_{\\mathrm{filter}(\\nu)}[\\log\\pi(a|s,c)].\n$$\n\nStep Advantage 的估计采用的是 GAE (Generalized Advantage Estimation) 的简化版：\n\n$$\nA^{\\mathrm{step}}(s_h,a_h,c):=\\lambda^{H-h}r(s_H,a_H,c)+(1-\\lambda^{H-h}r(s_H,a_H,c))(V^{\\mathrm{step}}(s_{h+1},c)+r(s_h,a_h,c)-V^{\\mathrm{step}}(s_h,c))\n$$\n\n之所以可以这么做，是因为任务的奖励只有在最后一步有，成功了是1，失败了是0，第一项是高方差的 MC，第二项是高偏差的估计器。随着 h 增加，第一项的权重越来越大，第二项权重则越来越小。这两项综合起来有利于均衡方差与偏差。\n\n此外，我们还要定义 Instruct Advantage，用来评估一条 traj 的学习价值：\n\n![1721316686785](../images/DigiRL/1721316686785.png)\n\n个人理解，traj 的学习价值取决于 traj 奖励值和指令平均奖励的差。\n\ntraj 的奖励值就是当前这条路径拿到的奖励总和。\n\n“指令平均奖励”就是当前指令下获得奖励的期望值，取决于任务的难易程度，因为它是对该任务所有 traj 的平均，任务越难，奖励更难拿到，指令平均奖励越低。\n\n那么，traj 的奖励值越高，traj 的学习价值就越高，直觉上即成功的任务（奖励为1）有学习价值，但是失败的任务（奖励为0）不值得学习；\n\n指令平均奖励越高，traj 的学习价值越低，这是因为指令平均奖励高，意味着这个任务很简单，不值得学习。\n\n关于估计器的训练，采用的是交叉熵损失而不是传统的 MSE 损失，这是因为交叉熵损失通常在 transformer 架构上更好用：\n\n![1721316668685](../images/DigiRL/1721316668685.png)\n\n而且巧妙的点在于这个任务的奖励只有 1 或 0，因此估计器其实可以看作一个二分类，交叉熵就只有两项。\n\n最终的 pipeline：\n\n* 训练 Step-level 和 Instruct-level 的估计器 V；\n* 用估计器 V 计算学习价值 A，通过学习价值过滤掉一部分无效 traj 和 step；\n  * 具体而言，Instruct-level 选取 top-p 条 traj；\n  * Step-level 选取阈值大于 1/H 的 step.\n* 在过滤后的 traj 上采用 MLE 准则训练模型。\n\n## 模型架构\n\n在 AutoUI-Base 的基础上进行训练，固定 image encoder 不动。\n\n### Instruction and Step Level Value Functions\n\n输入：采用 image encoder 与 RoBERTa 分别对界面截图和指令进行 embedding，拼接起来。\n\n用 2 层的 MLP 来预测 Value function。\n\n### Actor\n\n在离线学习阶段，通过运行原始的 AutoUI-Base 来采集 traj。在 offline 阶段，跳过了 instruction-level filtering，用所有的 instruction 来训练，用以充分地利用数据。\n\nDecoder 具体要输出什么？是文本吗？那数值是怎么处理的？大模型能很好地理解数值吗？（9.11 > 9.8？？）\n\n答：按照 Auto-GUI 的说法，确实是文本，点击屏幕需要用到一个 0~1 之间的 4 位小数。感觉这样肯定有很多问题，例如语言模型怎么理解空间关系和数值关系？它是不是只是背下了 UI 的数字信息？UI 的理解和识别工作应该已经有很多了。\n\n如果要验证这点，可以设计一个空间方位相关的 Instruction，例如让它点击按钮 A 上方的那个按钮，语言模型不可能回答出来。或者，将按钮平移一段距离，看模型对于按钮位置的预测是否出现了一致的平移？\n\n我比较相信的一种可能是，Image Encoder 在编码时确实把 UI 的位置坐标信息和语义信息编码进了 Embedding 中，并且在 Decoding 阶段确实被识别了出来，这样想倒也是自洽的。如何验证？\n\n## 评测部分\n\n评测采用的是 Gemini-1.5-pro，据论文报告结果和人类的评估接近。评测标准是通过一个端到端的观察，判断是否完成了任务。\n\n## 消融实验和分析\n\n### 错误分析\n\n整体上，所有测试的 Agent 存在三种错误：\n\n* 很难从错误中纠正\n* 在中途卡住，例如搜索之后不知道点搜索按钮\n* 到达了错误的目标，例如走错了网购网站\n\n错误1、3貌似都是任务规划层面的问题，而不是操作执行的问题，模型之所以出错是因为它没有产生正确的意图，而不是它不理解 UI 界面本身。错误 2 是一个 UI 理解的问题。也就是说，作者可能认为模型在 planning 方面的问题是最主要的。当然作者并没有严格区分这二者，因为训练时就是以多轮操作执行为目标进行训练的。当然，这二者可能确实是无法分开的，因为不理解 UI 界面的逻辑，就无法进行正确的任务规划。\n\n作者认为，预训练模型之所以为什么会出现这样的错误，是因为它们无法应对动态性强的环境，进入了之前从未见过的界面时候就不知道怎么从其中出来了。相反，DigiRL 通过收集 Rollouts 数据，学会了从错误中学习，从而纠正自己的错误。\n\n我觉得这个说法有点牵强，首先这个只能解释错误类型 1、3，不能解释类型2。并不是所有模型都在预训练时接受了特定的 APP 界面相关的数据，例如 GPT-4V，AITW 的手机界面对于他来说，都是“没见过”的界面，而且点搜索按钮这件事没有太多的动态性，这跟动态性没什么关系，这个例子根本上说明的是它不理解 UI 界面语言：\n\n![1721554892738](../images/DigiRL/1721554892738.png)\n\n它没有理解界面的内容，认为搜索框右边那个×号是搜索的意思。实际上，这个任务确实有些 tricky，因为浏览器是不提供搜索键的，回车键在这个场景中充当了搜索键的作用。GPT-4V 首先应该理解到右下角那个箭头指的是回车，第二步是认识到回车键在浏览器场景下的搜索意义。\n\n我倾向于 GPT-4V 没有理解第一步，也就是图标本身表示回车，可能它会认为这就是一个箭头。第二步对这样的模型而言应该是非常简单就能转过来的。而且更致命的是，这个 UI 里回车根本没标上数字，那 GPT-4V 即使知道要点回车，它也没有选择的机会。比如下面这个例子：\n\n![1721555459238](../images/DigiRL/1721555459238.png)\n\n很好笑的是，它知道“键盘上有一个搜索按钮”，但是这个按钮没标数字，它只好点击了和那个回车键距离最近的 24 号，然后它就成功点进了广告。排除广告干扰这件事本身可能相当重要，需要专门的对齐工作。\n\n这里的例子全是 GPT-4V 的，感觉没什么看头，毕竟是附录，可能写得没那么认真。\n\n![1721555695196](../images/DigiRL/1721555695196.png)\n\n网购这件事可能相对比较困难一点，可以看到主要的困难都是在点击按钮和走错界面上（除了 Gemini 完全无法正常 work，hh），模型产生了正确的意图，但是点错了地方，即使是论文自己的模型也没能幸免，毕竟 Image Encoder 是固定不动的。也就是说模型对于 UI 操作的理解并不充分。\n\n总体而言，错误类型可以分成 3 类：\n\n* 任务规划错误：Recover from mistakes, Fail at all\n* UI 理解错误：包括两个子类：\n  * 不可交互，仅可阅读的 UI 元素意义理解错误：Quit Early, wrong page\n  * 可交互 UI 元素的理解错误：Click on link or type\n\nDigiRL 的工作，主要解决了任务规划方面的错误，因为模型可以接受奖励信号，判断整条 trace 是否做错了。仔细想想这对于 GPT-4V 是不公平的，因为没人告诉 4V 是否做错了，4V 也不可能接受 1000 条 traj 的 Online Training，信息量自然少了很多。\n\n但是对比而言，模型主要的错误可能还是在 UI 理解上。模型对于 UI 元素理解的能力还是很差，像 4V 这种模型甚至也会有理解错误。VLM 的能力还任重道远。\n\n因此其实后续工作可以探讨的还有很多：\n\n* UI 理解与交互，个人认为是目前手机 Agent 最关键的点；\n* 任务规划，这个就接着 DigiRL 的思路，RL 的方法虽然成功实现了 Online Training，但是先验知识利用不足，需要 1k 量级的数据去学会一个没见过的任务，能不能做到像 ChatGPT 那样 ICL 就能直接拿下一个新任务？（这个可能很难，需要大量的标注数据）\n* 异常页面处理，包括怎么鉴别误导页面，怎么从广告、弹窗、警告等非常规界面中退出，这个也许很新颖，至少我想不到有什么工作在做这个，但是这个事情可能对于 wild env 的 Agent 非常重要。\n","slug":"DigiRL","published":1,"updated":"2024-07-21T10:17:03.738Z","_id":"clysv8fd20000k8ugfm2m25v9","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"DigiRL-Training-In-The-Wild-Device-Control-Agents-with-Autonomous-Reinforcement-Learning\"><a href=\"#DigiRL-Training-In-The-Wild-Device-Control-Agents-with-Autonomous-Reinforcement-Learning\" class=\"headerlink\" title=\"DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning\"></a>DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning</h2><p>LLM (VLM) +RL 的完美之作！在 Pretraining 的基础上进行 Offline RL，然后在执行任务时通过 Online RL 更新参数，特色是能够从多轮交互中学习、更新参数，而不是通过专家知识微调一个单步交互模型。实验也做得非常详细。不过 RL 的部分我还看不太懂，需要继续学习。</p>\n<p><img src=\"/../images/Mobile-LLM/1721230554686.png\" alt=\"1721230554686\" loading=\"lazy\"></p>\n<p>Action Space 定义为点击、滑动、输入、home 键、返回等操作，参数包含屏幕上的归一化 (x, y) 坐标。另外引入的一个设定是界面的随机性，界面可能有随时更新、加载中、小广告、身份识别等干扰出现。</p>\n<p><img src=\"/../images/Mobile-LLM/1721231007829.png\" alt=\"1721231007829\" loading=\"lazy\"></p>\n<h2 id=\"RL-算法部分\"><a href=\"#RL-算法部分\" class=\"headerlink\" title=\"RL 算法部分\"></a>RL 算法部分</h2><p>首先本文将手机操作问题建模为一个 MDP 过程。</p>\n<p>然后采用了 AWR 算法，计算策略梯度。似乎用到了蒙特卡洛？</p>\n<p>Instruction-Level Value Function 有什么作用？这里似乎是说 task set 的难度方差太大，需要用难度适中的数据去训练 actor model，所以提出了则个 Value Function 来过滤一部分数据。</p>\n<p><img src=\"/../images/DigiRL/1721232302611.png\" alt=\"1721232302611\" loading=\"lazy\"></p>\n<p>首先，定义 Advantage 为一个状态的 Q 值（按照当前策略，未来所有步的期望值）减去 Value function：</p>\n<div>$$\nA^\\pi(s_h,a_h,c)=Q^\\pi(s_h,a_h,c)-V^\\pi(s_h,c).\n$$</div>\n\n<p>AWR 算法的 Actor 优化目标是一个加权的 MLE：</p>\n<div>$$\n\\arg\\max_\\pi\\mathbb{E}_\\nu\\left[\\log\\pi(a|s,c)\\cdot\\exp\\left(A(s,a,c)/\\beta\\right)\\right]\n$$</div>\n\n<p>在论文中没有用这个公式，而是用 hard filtering 替代：</p>\n<div>$$\n\\mathcal{L}(\\pi)=-\\mathbb{E}_{\\mathrm{filter}(\\nu)}[\\log\\pi(a|s,c)].\n$$</div>\n\n<p>Step Advantage 的估计采用的是 GAE (Generalized Advantage Estimation) 的简化版：</p>\n<div>$$\nA^{\\mathrm{step}}(s_h,a_h,c):=\\lambda^{H-h}r(s_H,a_H,c)+(1-\\lambda^{H-h}r(s_H,a_H,c))(V^{\\mathrm{step}}(s_{h+1},c)+r(s_h,a_h,c)-V^{\\mathrm{step}}(s_h,c))\n$$</div>\n\n<p>之所以可以这么做，是因为任务的奖励只有在最后一步有，成功了是1，失败了是0，第一项是高方差的 MC，第二项是高偏差的估计器。随着 h 增加，第一项的权重越来越大，第二项权重则越来越小。这两项综合起来有利于均衡方差与偏差。</p>\n<p>此外，我们还要定义 Instruct Advantage，用来评估一条 traj 的学习价值：</p>\n<p><img src=\"/../images/DigiRL/1721316686785.png\" alt=\"1721316686785\" loading=\"lazy\"></p>\n<p>个人理解，traj 的学习价值取决于 traj 奖励值和指令平均奖励的差。</p>\n<p>traj 的奖励值就是当前这条路径拿到的奖励总和。</p>\n<p>“指令平均奖励”就是当前指令下获得奖励的期望值，取决于任务的难易程度，因为它是对该任务所有 traj 的平均，任务越难，奖励更难拿到，指令平均奖励越低。</p>\n<p>那么，traj 的奖励值越高，traj 的学习价值就越高，直觉上即成功的任务（奖励为1）有学习价值，但是失败的任务（奖励为0）不值得学习；</p>\n<p>指令平均奖励越高，traj 的学习价值越低，这是因为指令平均奖励高，意味着这个任务很简单，不值得学习。</p>\n<p>关于估计器的训练，采用的是交叉熵损失而不是传统的 MSE 损失，这是因为交叉熵损失通常在 transformer 架构上更好用：</p>\n<p><img src=\"/../images/DigiRL/1721316668685.png\" alt=\"1721316668685\" loading=\"lazy\"></p>\n<p>而且巧妙的点在于这个任务的奖励只有 1 或 0，因此估计器其实可以看作一个二分类，交叉熵就只有两项。</p>\n<p>最终的 pipeline：</p>\n<ul>\n<li>训练 Step-level 和 Instruct-level 的估计器 V；</li>\n<li>用估计器 V 计算学习价值 A，通过学习价值过滤掉一部分无效 traj 和 step；<ul>\n<li>具体而言，Instruct-level 选取 top-p 条 traj；</li>\n<li>Step-level 选取阈值大于 1&#x2F;H 的 step.</li>\n</ul>\n</li>\n<li>在过滤后的 traj 上采用 MLE 准则训练模型。</li>\n</ul>\n<h2 id=\"模型架构\"><a href=\"#模型架构\" class=\"headerlink\" title=\"模型架构\"></a>模型架构</h2><p>在 AutoUI-Base 的基础上进行训练，固定 image encoder 不动。</p>\n<h3 id=\"Instruction-and-Step-Level-Value-Functions\"><a href=\"#Instruction-and-Step-Level-Value-Functions\" class=\"headerlink\" title=\"Instruction and Step Level Value Functions\"></a>Instruction and Step Level Value Functions</h3><p>输入：采用 image encoder 与 RoBERTa 分别对界面截图和指令进行 embedding，拼接起来。</p>\n<p>用 2 层的 MLP 来预测 Value function。</p>\n<h3 id=\"Actor\"><a href=\"#Actor\" class=\"headerlink\" title=\"Actor\"></a>Actor</h3><p>在离线学习阶段，通过运行原始的 AutoUI-Base 来采集 traj。在 offline 阶段，跳过了 instruction-level filtering，用所有的 instruction 来训练，用以充分地利用数据。</p>\n<p>Decoder 具体要输出什么？是文本吗？那数值是怎么处理的？大模型能很好地理解数值吗？（9.11 &gt; 9.8？？）</p>\n<p>答：按照 Auto-GUI 的说法，确实是文本，点击屏幕需要用到一个 0~1 之间的 4 位小数。感觉这样肯定有很多问题，例如语言模型怎么理解空间关系和数值关系？它是不是只是背下了 UI 的数字信息？UI 的理解和识别工作应该已经有很多了。</p>\n<p>如果要验证这点，可以设计一个空间方位相关的 Instruction，例如让它点击按钮 A 上方的那个按钮，语言模型不可能回答出来。或者，将按钮平移一段距离，看模型对于按钮位置的预测是否出现了一致的平移？</p>\n<p>我比较相信的一种可能是，Image Encoder 在编码时确实把 UI 的位置坐标信息和语义信息编码进了 Embedding 中，并且在 Decoding 阶段确实被识别了出来，这样想倒也是自洽的。如何验证？</p>\n<h2 id=\"评测部分\"><a href=\"#评测部分\" class=\"headerlink\" title=\"评测部分\"></a>评测部分</h2><p>评测采用的是 Gemini-1.5-pro，据论文报告结果和人类的评估接近。评测标准是通过一个端到端的观察，判断是否完成了任务。</p>\n<h2 id=\"消融实验和分析\"><a href=\"#消融实验和分析\" class=\"headerlink\" title=\"消融实验和分析\"></a>消融实验和分析</h2><h3 id=\"错误分析\"><a href=\"#错误分析\" class=\"headerlink\" title=\"错误分析\"></a>错误分析</h3><p>整体上，所有测试的 Agent 存在三种错误：</p>\n<ul>\n<li>很难从错误中纠正</li>\n<li>在中途卡住，例如搜索之后不知道点搜索按钮</li>\n<li>到达了错误的目标，例如走错了网购网站</li>\n</ul>\n<p>错误1、3貌似都是任务规划层面的问题，而不是操作执行的问题，模型之所以出错是因为它没有产生正确的意图，而不是它不理解 UI 界面本身。错误 2 是一个 UI 理解的问题。也就是说，作者可能认为模型在 planning 方面的问题是最主要的。当然作者并没有严格区分这二者，因为训练时就是以多轮操作执行为目标进行训练的。当然，这二者可能确实是无法分开的，因为不理解 UI 界面的逻辑，就无法进行正确的任务规划。</p>\n<p>作者认为，预训练模型之所以为什么会出现这样的错误，是因为它们无法应对动态性强的环境，进入了之前从未见过的界面时候就不知道怎么从其中出来了。相反，DigiRL 通过收集 Rollouts 数据，学会了从错误中学习，从而纠正自己的错误。</p>\n<p>我觉得这个说法有点牵强，首先这个只能解释错误类型 1、3，不能解释类型2。并不是所有模型都在预训练时接受了特定的 APP 界面相关的数据，例如 GPT-4V，AITW 的手机界面对于他来说，都是“没见过”的界面，而且点搜索按钮这件事没有太多的动态性，这跟动态性没什么关系，这个例子根本上说明的是它不理解 UI 界面语言：</p>\n<p><img src=\"/../images/DigiRL/1721554892738.png\" alt=\"1721554892738\" loading=\"lazy\"></p>\n<p>它没有理解界面的内容，认为搜索框右边那个×号是搜索的意思。实际上，这个任务确实有些 tricky，因为浏览器是不提供搜索键的，回车键在这个场景中充当了搜索键的作用。GPT-4V 首先应该理解到右下角那个箭头指的是回车，第二步是认识到回车键在浏览器场景下的搜索意义。</p>\n<p>我倾向于 GPT-4V 没有理解第一步，也就是图标本身表示回车，可能它会认为这就是一个箭头。第二步对这样的模型而言应该是非常简单就能转过来的。而且更致命的是，这个 UI 里回车根本没标上数字，那 GPT-4V 即使知道要点回车，它也没有选择的机会。比如下面这个例子：</p>\n<p><img src=\"/../images/DigiRL/1721555459238.png\" alt=\"1721555459238\" loading=\"lazy\"></p>\n<p>很好笑的是，它知道“键盘上有一个搜索按钮”，但是这个按钮没标数字，它只好点击了和那个回车键距离最近的 24 号，然后它就成功点进了广告。排除广告干扰这件事本身可能相当重要，需要专门的对齐工作。</p>\n<p>这里的例子全是 GPT-4V 的，感觉没什么看头，毕竟是附录，可能写得没那么认真。</p>\n<p><img src=\"/../images/DigiRL/1721555695196.png\" alt=\"1721555695196\" loading=\"lazy\"></p>\n<p>网购这件事可能相对比较困难一点，可以看到主要的困难都是在点击按钮和走错界面上（除了 Gemini 完全无法正常 work，hh），模型产生了正确的意图，但是点错了地方，即使是论文自己的模型也没能幸免，毕竟 Image Encoder 是固定不动的。也就是说模型对于 UI 操作的理解并不充分。</p>\n<p>总体而言，错误类型可以分成 3 类：</p>\n<ul>\n<li>任务规划错误：Recover from mistakes, Fail at all</li>\n<li>UI 理解错误：包括两个子类：<ul>\n<li>不可交互，仅可阅读的 UI 元素意义理解错误：Quit Early, wrong page</li>\n<li>可交互 UI 元素的理解错误：Click on link or type</li>\n</ul>\n</li>\n</ul>\n<p>DigiRL 的工作，主要解决了任务规划方面的错误，因为模型可以接受奖励信号，判断整条 trace 是否做错了。仔细想想这对于 GPT-4V 是不公平的，因为没人告诉 4V 是否做错了，4V 也不可能接受 1000 条 traj 的 Online Training，信息量自然少了很多。</p>\n<p>但是对比而言，模型主要的错误可能还是在 UI 理解上。模型对于 UI 元素理解的能力还是很差，像 4V 这种模型甚至也会有理解错误。VLM 的能力还任重道远。</p>\n<p>因此其实后续工作可以探讨的还有很多：</p>\n<ul>\n<li>UI 理解与交互，个人认为是目前手机 Agent 最关键的点；</li>\n<li>任务规划，这个就接着 DigiRL 的思路，RL 的方法虽然成功实现了 Online Training，但是先验知识利用不足，需要 1k 量级的数据去学会一个没见过的任务，能不能做到像 ChatGPT 那样 ICL 就能直接拿下一个新任务？（这个可能很难，需要大量的标注数据）</li>\n<li>异常页面处理，包括怎么鉴别误导页面，怎么从广告、弹窗、警告等非常规界面中退出，这个也许很新颖，至少我想不到有什么工作在做这个，但是这个事情可能对于 wild env 的 Agent 非常重要。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"DigiRL-Training-In-The-Wild-Device-Control-Agents-with-Autonomous-Reinforcement-Learning\"><a href=\"#DigiRL-Training-In-The-Wild-Device-Control-Agents-with-Autonomous-Reinforcement-Learning\" class=\"headerlink\" title=\"DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning\"></a>DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning</h2><p>LLM (VLM) +RL 的完美之作！在 Pretraining 的基础上进行 Offline RL，然后在执行任务时通过 Online RL 更新参数，特色是能够从多轮交互中学习、更新参数，而不是通过专家知识微调一个单步交互模型。实验也做得非常详细。不过 RL 的部分我还看不太懂，需要继续学习。</p>\n<p><img src=\"/../images/Mobile-LLM/1721230554686.png\" alt=\"1721230554686\"></p>\n<p>Action Space 定义为点击、滑动、输入、home 键、返回等操作，参数包含屏幕上的归一化 (x, y) 坐标。另外引入的一个设定是界面的随机性，界面可能有随时更新、加载中、小广告、身份识别等干扰出现。</p>\n<p><img src=\"/../images/Mobile-LLM/1721231007829.png\" alt=\"1721231007829\"></p>\n<h2 id=\"RL-算法部分\"><a href=\"#RL-算法部分\" class=\"headerlink\" title=\"RL 算法部分\"></a>RL 算法部分</h2><p>首先本文将手机操作问题建模为一个 MDP 过程。</p>\n<p>然后采用了 AWR 算法，计算策略梯度。似乎用到了蒙特卡洛？</p>\n<p>Instruction-Level Value Function 有什么作用？这里似乎是说 task set 的难度方差太大，需要用难度适中的数据去训练 actor model，所以提出了则个 Value Function 来过滤一部分数据。</p>\n<p><img src=\"/../images/DigiRL/1721232302611.png\" alt=\"1721232302611\"></p>\n<p>首先，定义 Advantage 为一个状态的 Q 值（按照当前策略，未来所有步的期望值）减去 Value function：</p>\n<div>$$\nA^\\pi(s_h,a_h,c)=Q^\\pi(s_h,a_h,c)-V^\\pi(s_h,c).\n$$</div>\n\n<p>AWR 算法的 Actor 优化目标是一个加权的 MLE：</p>\n<div>$$\n\\arg\\max_\\pi\\mathbb{E}_\\nu\\left[\\log\\pi(a|s,c)\\cdot\\exp\\left(A(s,a,c)/\\beta\\right)\\right]\n$$</div>\n\n<p>在论文中没有用这个公式，而是用 hard filtering 替代：</p>\n<div>$$\n\\mathcal{L}(\\pi)=-\\mathbb{E}_{\\mathrm{filter}(\\nu)}[\\log\\pi(a|s,c)].\n$$</div>\n\n<p>Step Advantage 的估计采用的是 GAE (Generalized Advantage Estimation) 的简化版：</p>\n<div>$$\nA^{\\mathrm{step}}(s_h,a_h,c):=\\lambda^{H-h}r(s_H,a_H,c)+(1-\\lambda^{H-h}r(s_H,a_H,c))(V^{\\mathrm{step}}(s_{h+1},c)+r(s_h,a_h,c)-V^{\\mathrm{step}}(s_h,c))\n$$</div>\n\n<p>之所以可以这么做，是因为任务的奖励只有在最后一步有，成功了是1，失败了是0，第一项是高方差的 MC，第二项是高偏差的估计器。随着 h 增加，第一项的权重越来越大，第二项权重则越来越小。这两项综合起来有利于均衡方差与偏差。</p>\n<p>此外，我们还要定义 Instruct Advantage，用来评估一条 traj 的学习价值：</p>\n<p><img src=\"/../images/DigiRL/1721316686785.png\" alt=\"1721316686785\"></p>\n<p>个人理解，traj 的学习价值取决于 traj 奖励值和指令平均奖励的差。</p>\n<p>traj 的奖励值就是当前这条路径拿到的奖励总和。</p>\n<p>“指令平均奖励”就是当前指令下获得奖励的期望值，取决于任务的难易程度，因为它是对该任务所有 traj 的平均，任务越难，奖励更难拿到，指令平均奖励越低。</p>\n<p>那么，traj 的奖励值越高，traj 的学习价值就越高，直觉上即成功的任务（奖励为1）有学习价值，但是失败的任务（奖励为0）不值得学习；</p>\n<p>指令平均奖励越高，traj 的学习价值越低，这是因为指令平均奖励高，意味着这个任务很简单，不值得学习。</p>\n<p>关于估计器的训练，采用的是交叉熵损失而不是传统的 MSE 损失，这是因为交叉熵损失通常在 transformer 架构上更好用：</p>\n<p><img src=\"/../images/DigiRL/1721316668685.png\" alt=\"1721316668685\"></p>\n<p>而且巧妙的点在于这个任务的奖励只有 1 或 0，因此估计器其实可以看作一个二分类，交叉熵就只有两项。</p>\n<p>最终的 pipeline：</p>\n<ul>\n<li>训练 Step-level 和 Instruct-level 的估计器 V；</li>\n<li>用估计器 V 计算学习价值 A，通过学习价值过滤掉一部分无效 traj 和 step；<ul>\n<li>具体而言，Instruct-level 选取 top-p 条 traj；</li>\n<li>Step-level 选取阈值大于 1&#x2F;H 的 step.</li>\n</ul>\n</li>\n<li>在过滤后的 traj 上采用 MLE 准则训练模型。</li>\n</ul>\n<h2 id=\"模型架构\"><a href=\"#模型架构\" class=\"headerlink\" title=\"模型架构\"></a>模型架构</h2><p>在 AutoUI-Base 的基础上进行训练，固定 image encoder 不动。</p>\n<h3 id=\"Instruction-and-Step-Level-Value-Functions\"><a href=\"#Instruction-and-Step-Level-Value-Functions\" class=\"headerlink\" title=\"Instruction and Step Level Value Functions\"></a>Instruction and Step Level Value Functions</h3><p>输入：采用 image encoder 与 RoBERTa 分别对界面截图和指令进行 embedding，拼接起来。</p>\n<p>用 2 层的 MLP 来预测 Value function。</p>\n<h3 id=\"Actor\"><a href=\"#Actor\" class=\"headerlink\" title=\"Actor\"></a>Actor</h3><p>在离线学习阶段，通过运行原始的 AutoUI-Base 来采集 traj。在 offline 阶段，跳过了 instruction-level filtering，用所有的 instruction 来训练，用以充分地利用数据。</p>\n<p>Decoder 具体要输出什么？是文本吗？那数值是怎么处理的？大模型能很好地理解数值吗？（9.11 &gt; 9.8？？）</p>\n<p>答：按照 Auto-GUI 的说法，确实是文本，点击屏幕需要用到一个 0~1 之间的 4 位小数。感觉这样肯定有很多问题，例如语言模型怎么理解空间关系和数值关系？它是不是只是背下了 UI 的数字信息？UI 的理解和识别工作应该已经有很多了。</p>\n<p>如果要验证这点，可以设计一个空间方位相关的 Instruction，例如让它点击按钮 A 上方的那个按钮，语言模型不可能回答出来。或者，将按钮平移一段距离，看模型对于按钮位置的预测是否出现了一致的平移？</p>\n<p>我比较相信的一种可能是，Image Encoder 在编码时确实把 UI 的位置坐标信息和语义信息编码进了 Embedding 中，并且在 Decoding 阶段确实被识别了出来，这样想倒也是自洽的。如何验证？</p>\n<h2 id=\"评测部分\"><a href=\"#评测部分\" class=\"headerlink\" title=\"评测部分\"></a>评测部分</h2><p>评测采用的是 Gemini-1.5-pro，据论文报告结果和人类的评估接近。评测标准是通过一个端到端的观察，判断是否完成了任务。</p>\n<h2 id=\"消融实验和分析\"><a href=\"#消融实验和分析\" class=\"headerlink\" title=\"消融实验和分析\"></a>消融实验和分析</h2><h3 id=\"错误分析\"><a href=\"#错误分析\" class=\"headerlink\" title=\"错误分析\"></a>错误分析</h3><p>整体上，所有测试的 Agent 存在三种错误：</p>\n<ul>\n<li>很难从错误中纠正</li>\n<li>在中途卡住，例如搜索之后不知道点搜索按钮</li>\n<li>到达了错误的目标，例如走错了网购网站</li>\n</ul>\n<p>错误1、3貌似都是任务规划层面的问题，而不是操作执行的问题，模型之所以出错是因为它没有产生正确的意图，而不是它不理解 UI 界面本身。错误 2 是一个 UI 理解的问题。也就是说，作者可能认为模型在 planning 方面的问题是最主要的。当然作者并没有严格区分这二者，因为训练时就是以多轮操作执行为目标进行训练的。当然，这二者可能确实是无法分开的，因为不理解 UI 界面的逻辑，就无法进行正确的任务规划。</p>\n<p>作者认为，预训练模型之所以为什么会出现这样的错误，是因为它们无法应对动态性强的环境，进入了之前从未见过的界面时候就不知道怎么从其中出来了。相反，DigiRL 通过收集 Rollouts 数据，学会了从错误中学习，从而纠正自己的错误。</p>\n<p>我觉得这个说法有点牵强，首先这个只能解释错误类型 1、3，不能解释类型2。并不是所有模型都在预训练时接受了特定的 APP 界面相关的数据，例如 GPT-4V，AITW 的手机界面对于他来说，都是“没见过”的界面，而且点搜索按钮这件事没有太多的动态性，这跟动态性没什么关系，这个例子根本上说明的是它不理解 UI 界面语言：</p>\n<p><img src=\"/../images/DigiRL/1721554892738.png\" alt=\"1721554892738\"></p>\n<p>它没有理解界面的内容，认为搜索框右边那个×号是搜索的意思。实际上，这个任务确实有些 tricky，因为浏览器是不提供搜索键的，回车键在这个场景中充当了搜索键的作用。GPT-4V 首先应该理解到右下角那个箭头指的是回车，第二步是认识到回车键在浏览器场景下的搜索意义。</p>\n<p>我倾向于 GPT-4V 没有理解第一步，也就是图标本身表示回车，可能它会认为这就是一个箭头。第二步对这样的模型而言应该是非常简单就能转过来的。而且更致命的是，这个 UI 里回车根本没标上数字，那 GPT-4V 即使知道要点回车，它也没有选择的机会。比如下面这个例子：</p>\n<p><img src=\"/../images/DigiRL/1721555459238.png\" alt=\"1721555459238\"></p>\n<p>很好笑的是，它知道“键盘上有一个搜索按钮”，但是这个按钮没标数字，它只好点击了和那个回车键距离最近的 24 号，然后它就成功点进了广告。排除广告干扰这件事本身可能相当重要，需要专门的对齐工作。</p>\n<p>这里的例子全是 GPT-4V 的，感觉没什么看头，毕竟是附录，可能写得没那么认真。</p>\n<p><img src=\"/../images/DigiRL/1721555695196.png\" alt=\"1721555695196\"></p>\n<p>网购这件事可能相对比较困难一点，可以看到主要的困难都是在点击按钮和走错界面上（除了 Gemini 完全无法正常 work，hh），模型产生了正确的意图，但是点错了地方，即使是论文自己的模型也没能幸免，毕竟 Image Encoder 是固定不动的。也就是说模型对于 UI 操作的理解并不充分。</p>\n<p>总体而言，错误类型可以分成 3 类：</p>\n<ul>\n<li>任务规划错误：Recover from mistakes, Fail at all</li>\n<li>UI 理解错误：包括两个子类：<ul>\n<li>不可交互，仅可阅读的 UI 元素意义理解错误：Quit Early, wrong page</li>\n<li>可交互 UI 元素的理解错误：Click on link or type</li>\n</ul>\n</li>\n</ul>\n<p>DigiRL 的工作，主要解决了任务规划方面的错误，因为模型可以接受奖励信号，判断整条 trace 是否做错了。仔细想想这对于 GPT-4V 是不公平的，因为没人告诉 4V 是否做错了，4V 也不可能接受 1000 条 traj 的 Online Training，信息量自然少了很多。</p>\n<p>但是对比而言，模型主要的错误可能还是在 UI 理解上。模型对于 UI 元素理解的能力还是很差，像 4V 这种模型甚至也会有理解错误。VLM 的能力还任重道远。</p>\n<p>因此其实后续工作可以探讨的还有很多：</p>\n<ul>\n<li>UI 理解与交互，个人认为是目前手机 Agent 最关键的点；</li>\n<li>任务规划，这个就接着 DigiRL 的思路，RL 的方法虽然成功实现了 Online Training，但是先验知识利用不足，需要 1k 量级的数据去学会一个没见过的任务，能不能做到像 ChatGPT 那样 ICL 就能直接拿下一个新任务？（这个可能很难，需要大量的标注数据）</li>\n<li>异常页面处理，包括怎么鉴别误导页面，怎么从广告、弹窗、警告等非常规界面中退出，这个也许很新颖，至少我想不到有什么工作在做这个，但是这个事情可能对于 wild env 的 Agent 非常重要。</li>\n</ul>\n"},{"title":"Mobile-LLM 论文阅读","katex":false,"date":"2024-06-09T12:42:26.000Z","_content":"## 综述\n\nPersonal LLM Agents: Insights and Survey about the Capability, Efficiency and Security\n\n## 数据集\n\nVideoGUI: A Benchmark for GUI Automation from Instructional Videos，把 GUI 能力划分为三层：High Level 表示高层次的操作意图。Middle Level 为用自然语言描述的单步操作，Atomic-action 为使用固定格式描述的准确操作。整个 pipeline 都是人标的，包括视频挑选，标注，验证，task 数量较少，86 个 full task，463 个 subtask。\n\n![1721718047655](../images/Mobile-LLM/1721718047655.png)\n\nGUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents，从 Youtube 上爬取视频数据+人类录频操作数据，提取关键帧，以及 QA 文本。关键帧的标注由人类完成，包括：执行的操作， 关键帧转移的目标，使用的软件或者网站，鼠标操作，键盘输入等。迷惑的是为什么人类操作还要录屏，既然最后是提取关键帧，那可以直接在人操作的时候提取关键帧？\n\n谷歌： Onthe Effects of Data Scale on Computer Control Agents，在安卓场景下人标gui sft数据，有测试集\n\n谷歌：Android in the Wild: A Large-Scale Dataset for Android Device Control\n\n输入为 image 和 text instruction。包含 30 K 的数据，Google Apps 的占比最大。\n\n![1717937154526](../images/Mobile-LLM/1717937154526.png)\n\nWorld of Bits (WoB): Use only keyboard & mouse，输入为彩色图像，DOM 文档，请求。支持通过众包构造新的数据。\n\nOpenAI Universe: Game, Web tasks，输入数据只有图像，操作键盘和鼠标。\n\nAndroidEnv: A Reinforcement Learning Platform for Android: 在 android emulator 上运行的虚拟环境。\n\n（MoTIF）A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility：人类标注，有 feasible 字段。\n\n![1718009240031](../images/Mobile-LLM/1718009240031.png)\n\nPIXELHELP: Mapping Natural Language Instructions to Mobile UI Action Sequences\n\n## 模型\n\n### RL-based method\n\n中间步骤奖励非常重要。稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。\n\n泛化性差，不像 LLM 具有大量先验知识。\n\nApp-Buddy:  PPO based method, Interact with DOM.\n\n![1717937734857](../images/Mobile-LLM/1717937734857.png)\n\nREINFORCEMENT LEARNING ON WEB INTERFACES USING WORKFLOW-GUIDED EXPLORATION： 稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。但是 BC 方法容易过拟合，因此通过从示例中导出 workflow policy，再从 workflow policy 中采样新的 policy 的方法来获取新的 trace。\n\n![1717940196994](../images/Mobile-LLM/1717940196994.png)\n\n### LLM Agents\n\n#### Prompt Engineering\n\nExplore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation，从 trace 中学习 subtasks，然后封装成 api，在后续执行任务时可以直接调用。也是纯文本推理。\n\nM3A，SeeAct 都是采用截图标注，然后推理，速度会慢很多。\n\nAutoDroid: LLM-powered Task Automation in Android (MobiCom 24)\n\nExploration + Execution 范式，基于 VH/DOM 的 UI 表示。\n\n![1718003623779](../images/Mobile-LLM/1718003623779.png)\n\nGPT4 成功率相当可观，finetune小模型的效果接近 GPT 3.5：\n\n![1718003792356](../images/Mobile-LLM/1718003792356.png)\n\n离线部分：随机探索 + 生成 App Memory，对 UTG(UI Transition Graph) 进行分析，LLM 生成每个页面和每个 UI 元素的描述，并构建 embedding vector base。\n\n在线部分：根据 embedding vector base 筛选 UI 元素，只留下那些重要的 UI 元素，并且利用 APP Memory 中的元素生成 Guide 辅助模型进行决策。\n\nResponsible Task Automation: Empowering Large Language Models as Responsible Task Automators\n\nDroidBot-GPT: GPT-powered UI Automation for Android\n\n![1717939486804](../images/Mobile-LLM/1717939486804.png)\n\nAppAgent: Multimodal Agents as Smartphone Users：利用 GPT4-V 进行探索+部署，支持 learn from demonstration。\n\n#### Multimodal\n\nCogAgent: A Visual Language Model for GUI Agents，从结果来看 Auto GUI 还是挺能打的，700M 的 encoder-decoder 和 18B 的 CogAgent （CogVLM-17B 改造而来）不相上下。\n\n![1721962899191](../images/Mobile-LLM/1721962899191.png)\n\n模型架构如下。设计上采用一个低分辨率的图像编码器来识别大部分 UI 元素和布局，高分辨率的编码器用来识别文字（这个有证据吗？仅仅有一个简单的消融实验）。比较反直觉的是，在 OCR 领域模型应该采用更小的隐藏层，而不像通用领域那样需要很大的隐藏层，所以高分辨率编码器反而参数更少，只有 0.30 B。而且，这东西每层都跟 Decoder 做特征融合，不直接使用高分辨率是因为 CogVLM 原来的架构就支持 224*224（经典数字），太大了在 Self Attention 阶段计算量会爆炸，所以这里通过压缩隐藏层大小 + Cross Attention 来降低计算量。\n\n对齐方面，人标了2k条，然后把 Mind2Web 和 AITW 的数据拿过来用 GPT-4 标了 VQA 的数据集。\n\n输出格式包括 Plan，Action，Operation，Operation 部分同样是让大模型生成操作和坐标数据，我依然很好奇到底 VLM 能不能理解坐标信息。\n\n![1721962961205](../images/Mobile-LLM/1721962961205.png)\n\nAuto GUI: You Only Look at Screens: Multimodal Chain-of-Action Agents\n\n![1717937675502](../images/Mobile-LLM/1717937675502.png)\n\n微软 Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators，大小模型协同，一个模型负责 planning，一个模型负责 executing，同时，在这个过程中实现隐私保护。这个过程会通过一个语言模型根据屏幕截图 + low level commands 来判断命令是否可执行、是否执行成功。当然，仅仅用 Decoder 做二元判断似乎有点浪费，感觉是个分类器就能做，用 bert 说不定更好。另外，Vision Encoder 在识别图片中文字这一块擅长吗？模型架构来自于 pix2seq，它原本是做目标检测的。\n\n![1721792120662](../images/Mobile-LLM/1721792120662.png)\n\n![1721792309928](../images/Mobile-LLM/1721792309928.png)\n\nMETA-GUI: Towards Multi-modal Conversational Agents on Mobile GUI\n\n![1718009413946](../images/Mobile-LLM/1718009413946.png)\n\n### UI Understanding and Representation\n\nActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces：UI 理解，leveraged the temporal con\nnections between UIs in a UI sequence to design their pretraining tasks\n\nUIBert: Learning Generic Multimodal Representations for UI Understanding：self-alignment among different multimodal features in a single UI， use trainable lightweight encoders\n\n### LLM + RL\n\n[Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach](https://arxiv.org/pdf/2306.03604)\n\n### Code-based Methods\n\n## Topics\n\n长序列的任务执行\n\n多模态 GUI Agent\n\n隐私保护\n\n用户偏好/个性化的 Agent\n\nProactive Agent\n\nShow me how to do/高效的策略更新方法\n\nRL training in sparse reward\n\nLLM as Reward Model\n\nAction & Workflow embedding\n\n寻找 UI 的表征/ UI Understanding\n\n## Paper Reading\n\n### 20240725\n\nShareGPT4Video: Improving Video Understanding and Generation with Better Captions：视频数据理解，或许有助于 GUI Agent 的训练。提出了一个 Differential Sliding-window Captioning 的方案，让 GPT4o 根据上一帧和当前帧之间的差别来输出 Caption，最后加上一个 Summary 来描述整个视频的 pipeline。这里的关键是如何选关键帧，原文采用一个 CLIP Model，通过比较最后一帧和这一帧的相似性，选出差别较大的帧。\n\nLearning Transferable Visual Models From Natural Language Supervision\n\nPanda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers\n\n![1721924737611](../images/Mobile-LLM/1721924737611.png)\n\n### 20240629\n\nRead Agent：利用分页解决大模型长文本表现差的问题（Lost in middle）。\n\n### 大小模型协同\n\n[SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks](https://arxiv.org/pdf/2305.17390)。用 BC 的小模型进行 fast thinking, 然后让大模型进行 slow thinking / grounding.\n\n### Code Policy\n\n[AdaPlanner: Adaptive Planning from Feedback with Language Models](https://arxiv.org/pdf/2305.16653)\n\nCode as Policies: Language Model Programs for Embodied Control: 2209.07753, Use Code (Formal Language) in Embodied Agent.\n\n### FFN 的作用\n\n[Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space](https://arxiv.org/pdf/2203.14680)\n\n[Dissecting Recall of Factual Associations in Auto-Regressive Language Models](https://arxiv.org/pdf/2304.14767)\n\n### 杂项\n\nMatFormer：嵌套训练 FFN 参数，适配不同的设备。\n\nSADMoE：对 weight 聚类，将双层 MLP 转为 MoE\n\nDeja Vu：预测 attention 的激活值，动态分配空间\n","source":"_posts/Mobile-LLM.md","raw":"---\ntitle: Mobile-LLM 论文阅读\nkatex: false\ndate: 2024-06-09 20:42:26\ntags:\n  - paper\n  - survey\n  - Mobile\n  - LLM\n---\n## 综述\n\nPersonal LLM Agents: Insights and Survey about the Capability, Efficiency and Security\n\n## 数据集\n\nVideoGUI: A Benchmark for GUI Automation from Instructional Videos，把 GUI 能力划分为三层：High Level 表示高层次的操作意图。Middle Level 为用自然语言描述的单步操作，Atomic-action 为使用固定格式描述的准确操作。整个 pipeline 都是人标的，包括视频挑选，标注，验证，task 数量较少，86 个 full task，463 个 subtask。\n\n![1721718047655](../images/Mobile-LLM/1721718047655.png)\n\nGUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents，从 Youtube 上爬取视频数据+人类录频操作数据，提取关键帧，以及 QA 文本。关键帧的标注由人类完成，包括：执行的操作， 关键帧转移的目标，使用的软件或者网站，鼠标操作，键盘输入等。迷惑的是为什么人类操作还要录屏，既然最后是提取关键帧，那可以直接在人操作的时候提取关键帧？\n\n谷歌： Onthe Effects of Data Scale on Computer Control Agents，在安卓场景下人标gui sft数据，有测试集\n\n谷歌：Android in the Wild: A Large-Scale Dataset for Android Device Control\n\n输入为 image 和 text instruction。包含 30 K 的数据，Google Apps 的占比最大。\n\n![1717937154526](../images/Mobile-LLM/1717937154526.png)\n\nWorld of Bits (WoB): Use only keyboard & mouse，输入为彩色图像，DOM 文档，请求。支持通过众包构造新的数据。\n\nOpenAI Universe: Game, Web tasks，输入数据只有图像，操作键盘和鼠标。\n\nAndroidEnv: A Reinforcement Learning Platform for Android: 在 android emulator 上运行的虚拟环境。\n\n（MoTIF）A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility：人类标注，有 feasible 字段。\n\n![1718009240031](../images/Mobile-LLM/1718009240031.png)\n\nPIXELHELP: Mapping Natural Language Instructions to Mobile UI Action Sequences\n\n## 模型\n\n### RL-based method\n\n中间步骤奖励非常重要。稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。\n\n泛化性差，不像 LLM 具有大量先验知识。\n\nApp-Buddy:  PPO based method, Interact with DOM.\n\n![1717937734857](../images/Mobile-LLM/1717937734857.png)\n\nREINFORCEMENT LEARNING ON WEB INTERFACES USING WORKFLOW-GUIDED EXPLORATION： 稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。但是 BC 方法容易过拟合，因此通过从示例中导出 workflow policy，再从 workflow policy 中采样新的 policy 的方法来获取新的 trace。\n\n![1717940196994](../images/Mobile-LLM/1717940196994.png)\n\n### LLM Agents\n\n#### Prompt Engineering\n\nExplore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation，从 trace 中学习 subtasks，然后封装成 api，在后续执行任务时可以直接调用。也是纯文本推理。\n\nM3A，SeeAct 都是采用截图标注，然后推理，速度会慢很多。\n\nAutoDroid: LLM-powered Task Automation in Android (MobiCom 24)\n\nExploration + Execution 范式，基于 VH/DOM 的 UI 表示。\n\n![1718003623779](../images/Mobile-LLM/1718003623779.png)\n\nGPT4 成功率相当可观，finetune小模型的效果接近 GPT 3.5：\n\n![1718003792356](../images/Mobile-LLM/1718003792356.png)\n\n离线部分：随机探索 + 生成 App Memory，对 UTG(UI Transition Graph) 进行分析，LLM 生成每个页面和每个 UI 元素的描述，并构建 embedding vector base。\n\n在线部分：根据 embedding vector base 筛选 UI 元素，只留下那些重要的 UI 元素，并且利用 APP Memory 中的元素生成 Guide 辅助模型进行决策。\n\nResponsible Task Automation: Empowering Large Language Models as Responsible Task Automators\n\nDroidBot-GPT: GPT-powered UI Automation for Android\n\n![1717939486804](../images/Mobile-LLM/1717939486804.png)\n\nAppAgent: Multimodal Agents as Smartphone Users：利用 GPT4-V 进行探索+部署，支持 learn from demonstration。\n\n#### Multimodal\n\nCogAgent: A Visual Language Model for GUI Agents，从结果来看 Auto GUI 还是挺能打的，700M 的 encoder-decoder 和 18B 的 CogAgent （CogVLM-17B 改造而来）不相上下。\n\n![1721962899191](../images/Mobile-LLM/1721962899191.png)\n\n模型架构如下。设计上采用一个低分辨率的图像编码器来识别大部分 UI 元素和布局，高分辨率的编码器用来识别文字（这个有证据吗？仅仅有一个简单的消融实验）。比较反直觉的是，在 OCR 领域模型应该采用更小的隐藏层，而不像通用领域那样需要很大的隐藏层，所以高分辨率编码器反而参数更少，只有 0.30 B。而且，这东西每层都跟 Decoder 做特征融合，不直接使用高分辨率是因为 CogVLM 原来的架构就支持 224*224（经典数字），太大了在 Self Attention 阶段计算量会爆炸，所以这里通过压缩隐藏层大小 + Cross Attention 来降低计算量。\n\n对齐方面，人标了2k条，然后把 Mind2Web 和 AITW 的数据拿过来用 GPT-4 标了 VQA 的数据集。\n\n输出格式包括 Plan，Action，Operation，Operation 部分同样是让大模型生成操作和坐标数据，我依然很好奇到底 VLM 能不能理解坐标信息。\n\n![1721962961205](../images/Mobile-LLM/1721962961205.png)\n\nAuto GUI: You Only Look at Screens: Multimodal Chain-of-Action Agents\n\n![1717937675502](../images/Mobile-LLM/1717937675502.png)\n\n微软 Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators，大小模型协同，一个模型负责 planning，一个模型负责 executing，同时，在这个过程中实现隐私保护。这个过程会通过一个语言模型根据屏幕截图 + low level commands 来判断命令是否可执行、是否执行成功。当然，仅仅用 Decoder 做二元判断似乎有点浪费，感觉是个分类器就能做，用 bert 说不定更好。另外，Vision Encoder 在识别图片中文字这一块擅长吗？模型架构来自于 pix2seq，它原本是做目标检测的。\n\n![1721792120662](../images/Mobile-LLM/1721792120662.png)\n\n![1721792309928](../images/Mobile-LLM/1721792309928.png)\n\nMETA-GUI: Towards Multi-modal Conversational Agents on Mobile GUI\n\n![1718009413946](../images/Mobile-LLM/1718009413946.png)\n\n### UI Understanding and Representation\n\nActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces：UI 理解，leveraged the temporal con\nnections between UIs in a UI sequence to design their pretraining tasks\n\nUIBert: Learning Generic Multimodal Representations for UI Understanding：self-alignment among different multimodal features in a single UI， use trainable lightweight encoders\n\n### LLM + RL\n\n[Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach](https://arxiv.org/pdf/2306.03604)\n\n### Code-based Methods\n\n## Topics\n\n长序列的任务执行\n\n多模态 GUI Agent\n\n隐私保护\n\n用户偏好/个性化的 Agent\n\nProactive Agent\n\nShow me how to do/高效的策略更新方法\n\nRL training in sparse reward\n\nLLM as Reward Model\n\nAction & Workflow embedding\n\n寻找 UI 的表征/ UI Understanding\n\n## Paper Reading\n\n### 20240725\n\nShareGPT4Video: Improving Video Understanding and Generation with Better Captions：视频数据理解，或许有助于 GUI Agent 的训练。提出了一个 Differential Sliding-window Captioning 的方案，让 GPT4o 根据上一帧和当前帧之间的差别来输出 Caption，最后加上一个 Summary 来描述整个视频的 pipeline。这里的关键是如何选关键帧，原文采用一个 CLIP Model，通过比较最后一帧和这一帧的相似性，选出差别较大的帧。\n\nLearning Transferable Visual Models From Natural Language Supervision\n\nPanda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers\n\n![1721924737611](../images/Mobile-LLM/1721924737611.png)\n\n### 20240629\n\nRead Agent：利用分页解决大模型长文本表现差的问题（Lost in middle）。\n\n### 大小模型协同\n\n[SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks](https://arxiv.org/pdf/2305.17390)。用 BC 的小模型进行 fast thinking, 然后让大模型进行 slow thinking / grounding.\n\n### Code Policy\n\n[AdaPlanner: Adaptive Planning from Feedback with Language Models](https://arxiv.org/pdf/2305.16653)\n\nCode as Policies: Language Model Programs for Embodied Control: 2209.07753, Use Code (Formal Language) in Embodied Agent.\n\n### FFN 的作用\n\n[Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space](https://arxiv.org/pdf/2203.14680)\n\n[Dissecting Recall of Factual Associations in Auto-Regressive Language Models](https://arxiv.org/pdf/2304.14767)\n\n### 杂项\n\nMatFormer：嵌套训练 FFN 参数，适配不同的设备。\n\nSADMoE：对 weight 聚类，将双层 MLP 转为 MoE\n\nDeja Vu：预测 attention 的激活值，动态分配空间\n","slug":"Mobile-LLM","published":1,"updated":"2024-07-26T09:14:08.075Z","_id":"clysv8fd40001k8ugbhwmbmut","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security</p>\n<h2 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h2><p>VideoGUI: A Benchmark for GUI Automation from Instructional Videos，把 GUI 能力划分为三层：High Level 表示高层次的操作意图。Middle Level 为用自然语言描述的单步操作，Atomic-action 为使用固定格式描述的准确操作。整个 pipeline 都是人标的，包括视频挑选，标注，验证，task 数量较少，86 个 full task，463 个 subtask。</p>\n<p><img src=\"/../images/Mobile-LLM/1721718047655.png\" alt=\"1721718047655\" loading=\"lazy\"></p>\n<p>GUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents，从 Youtube 上爬取视频数据+人类录频操作数据，提取关键帧，以及 QA 文本。关键帧的标注由人类完成，包括：执行的操作， 关键帧转移的目标，使用的软件或者网站，鼠标操作，键盘输入等。迷惑的是为什么人类操作还要录屏，既然最后是提取关键帧，那可以直接在人操作的时候提取关键帧？</p>\n<p>谷歌： Onthe Effects of Data Scale on Computer Control Agents，在安卓场景下人标gui sft数据，有测试集</p>\n<p>谷歌：Android in the Wild: A Large-Scale Dataset for Android Device Control</p>\n<p>输入为 image 和 text instruction。包含 30 K 的数据，Google Apps 的占比最大。</p>\n<p><img src=\"/../images/Mobile-LLM/1717937154526.png\" alt=\"1717937154526\" loading=\"lazy\"></p>\n<p>World of Bits (WoB): Use only keyboard &amp; mouse，输入为彩色图像，DOM 文档，请求。支持通过众包构造新的数据。</p>\n<p>OpenAI Universe: Game, Web tasks，输入数据只有图像，操作键盘和鼠标。</p>\n<p>AndroidEnv: A Reinforcement Learning Platform for Android: 在 android emulator 上运行的虚拟环境。</p>\n<p>（MoTIF）A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility：人类标注，有 feasible 字段。</p>\n<p><img src=\"/../images/Mobile-LLM/1718009240031.png\" alt=\"1718009240031\" loading=\"lazy\"></p>\n<p>PIXELHELP: Mapping Natural Language Instructions to Mobile UI Action Sequences</p>\n<h2 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h2><h3 id=\"RL-based-method\"><a href=\"#RL-based-method\" class=\"headerlink\" title=\"RL-based method\"></a>RL-based method</h3><p>中间步骤奖励非常重要。稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。</p>\n<p>泛化性差，不像 LLM 具有大量先验知识。</p>\n<p>App-Buddy:  PPO based method, Interact with DOM.</p>\n<p><img src=\"/../images/Mobile-LLM/1717937734857.png\" alt=\"1717937734857\" loading=\"lazy\"></p>\n<p>REINFORCEMENT LEARNING ON WEB INTERFACES USING WORKFLOW-GUIDED EXPLORATION： 稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。但是 BC 方法容易过拟合，因此通过从示例中导出 workflow policy，再从 workflow policy 中采样新的 policy 的方法来获取新的 trace。</p>\n<p><img src=\"/../images/Mobile-LLM/1717940196994.png\" alt=\"1717940196994\" loading=\"lazy\"></p>\n<h3 id=\"LLM-Agents\"><a href=\"#LLM-Agents\" class=\"headerlink\" title=\"LLM Agents\"></a>LLM Agents</h3><h4 id=\"Prompt-Engineering\"><a href=\"#Prompt-Engineering\" class=\"headerlink\" title=\"Prompt Engineering\"></a>Prompt Engineering</h4><p>Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation，从 trace 中学习 subtasks，然后封装成 api，在后续执行任务时可以直接调用。也是纯文本推理。</p>\n<p>M3A，SeeAct 都是采用截图标注，然后推理，速度会慢很多。</p>\n<p>AutoDroid: LLM-powered Task Automation in Android (MobiCom 24)</p>\n<p>Exploration + Execution 范式，基于 VH&#x2F;DOM 的 UI 表示。</p>\n<p><img src=\"/../images/Mobile-LLM/1718003623779.png\" alt=\"1718003623779\" loading=\"lazy\"></p>\n<p>GPT4 成功率相当可观，finetune小模型的效果接近 GPT 3.5：</p>\n<p><img src=\"/../images/Mobile-LLM/1718003792356.png\" alt=\"1718003792356\" loading=\"lazy\"></p>\n<p>离线部分：随机探索 + 生成 App Memory，对 UTG(UI Transition Graph) 进行分析，LLM 生成每个页面和每个 UI 元素的描述，并构建 embedding vector base。</p>\n<p>在线部分：根据 embedding vector base 筛选 UI 元素，只留下那些重要的 UI 元素，并且利用 APP Memory 中的元素生成 Guide 辅助模型进行决策。</p>\n<p>Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators</p>\n<p>DroidBot-GPT: GPT-powered UI Automation for Android</p>\n<p><img src=\"/../images/Mobile-LLM/1717939486804.png\" alt=\"1717939486804\" loading=\"lazy\"></p>\n<p>AppAgent: Multimodal Agents as Smartphone Users：利用 GPT4-V 进行探索+部署，支持 learn from demonstration。</p>\n<h4 id=\"Multimodal\"><a href=\"#Multimodal\" class=\"headerlink\" title=\"Multimodal\"></a>Multimodal</h4><p>CogAgent: A Visual Language Model for GUI Agents，从结果来看 Auto GUI 还是挺能打的，700M 的 encoder-decoder 和 18B 的 CogAgent （CogVLM-17B 改造而来）不相上下。</p>\n<p><img src=\"/../images/Mobile-LLM/1721962899191.png\" alt=\"1721962899191\" loading=\"lazy\"></p>\n<p>模型架构如下。设计上采用一个低分辨率的图像编码器来识别大部分 UI 元素和布局，高分辨率的编码器用来识别文字（这个有证据吗？仅仅有一个简单的消融实验）。比较反直觉的是，在 OCR 领域模型应该采用更小的隐藏层，而不像通用领域那样需要很大的隐藏层，所以高分辨率编码器反而参数更少，只有 0.30 B。而且，这东西每层都跟 Decoder 做特征融合，不直接使用高分辨率是因为 CogVLM 原来的架构就支持 224*224（经典数字），太大了在 Self Attention 阶段计算量会爆炸，所以这里通过压缩隐藏层大小 + Cross Attention 来降低计算量。</p>\n<p>对齐方面，人标了2k条，然后把 Mind2Web 和 AITW 的数据拿过来用 GPT-4 标了 VQA 的数据集。</p>\n<p>输出格式包括 Plan，Action，Operation，Operation 部分同样是让大模型生成操作和坐标数据，我依然很好奇到底 VLM 能不能理解坐标信息。</p>\n<p><img src=\"/../images/Mobile-LLM/1721962961205.png\" alt=\"1721962961205\" loading=\"lazy\"></p>\n<p>Auto GUI: You Only Look at Screens: Multimodal Chain-of-Action Agents</p>\n<p><img src=\"/../images/Mobile-LLM/1717937675502.png\" alt=\"1717937675502\" loading=\"lazy\"></p>\n<p>微软 Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators，大小模型协同，一个模型负责 planning，一个模型负责 executing，同时，在这个过程中实现隐私保护。这个过程会通过一个语言模型根据屏幕截图 + low level commands 来判断命令是否可执行、是否执行成功。当然，仅仅用 Decoder 做二元判断似乎有点浪费，感觉是个分类器就能做，用 bert 说不定更好。另外，Vision Encoder 在识别图片中文字这一块擅长吗？模型架构来自于 pix2seq，它原本是做目标检测的。</p>\n<p><img src=\"/../images/Mobile-LLM/1721792120662.png\" alt=\"1721792120662\" loading=\"lazy\"></p>\n<p><img src=\"/../images/Mobile-LLM/1721792309928.png\" alt=\"1721792309928\" loading=\"lazy\"></p>\n<p>META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI</p>\n<p><img src=\"/../images/Mobile-LLM/1718009413946.png\" alt=\"1718009413946\" loading=\"lazy\"></p>\n<h3 id=\"UI-Understanding-and-Representation\"><a href=\"#UI-Understanding-and-Representation\" class=\"headerlink\" title=\"UI Understanding and Representation\"></a>UI Understanding and Representation</h3><p>ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces：UI 理解，leveraged the temporal con<br>nections between UIs in a UI sequence to design their pretraining tasks</p>\n<p>UIBert: Learning Generic Multimodal Representations for UI Understanding：self-alignment among different multimodal features in a single UI， use trainable lightweight encoders</p>\n<h3 id=\"LLM-RL\"><a href=\"#LLM-RL\" class=\"headerlink\" title=\"LLM + RL\"></a>LLM + RL</h3><p><a href=\"https://arxiv.org/pdf/2306.03604\">Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach</a></p>\n<h3 id=\"Code-based-Methods\"><a href=\"#Code-based-Methods\" class=\"headerlink\" title=\"Code-based Methods\"></a>Code-based Methods</h3><h2 id=\"Topics\"><a href=\"#Topics\" class=\"headerlink\" title=\"Topics\"></a>Topics</h2><p>长序列的任务执行</p>\n<p>多模态 GUI Agent</p>\n<p>隐私保护</p>\n<p>用户偏好&#x2F;个性化的 Agent</p>\n<p>Proactive Agent</p>\n<p>Show me how to do&#x2F;高效的策略更新方法</p>\n<p>RL training in sparse reward</p>\n<p>LLM as Reward Model</p>\n<p>Action &amp; Workflow embedding</p>\n<p>寻找 UI 的表征&#x2F; UI Understanding</p>\n<h2 id=\"Paper-Reading\"><a href=\"#Paper-Reading\" class=\"headerlink\" title=\"Paper Reading\"></a>Paper Reading</h2><h3 id=\"20240725\"><a href=\"#20240725\" class=\"headerlink\" title=\"20240725\"></a>20240725</h3><p>ShareGPT4Video: Improving Video Understanding and Generation with Better Captions：视频数据理解，或许有助于 GUI Agent 的训练。提出了一个 Differential Sliding-window Captioning 的方案，让 GPT4o 根据上一帧和当前帧之间的差别来输出 Caption，最后加上一个 Summary 来描述整个视频的 pipeline。这里的关键是如何选关键帧，原文采用一个 CLIP Model，通过比较最后一帧和这一帧的相似性，选出差别较大的帧。</p>\n<p>Learning Transferable Visual Models From Natural Language Supervision</p>\n<p>Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers</p>\n<p><img src=\"/../images/Mobile-LLM/1721924737611.png\" alt=\"1721924737611\" loading=\"lazy\"></p>\n<h3 id=\"20240629\"><a href=\"#20240629\" class=\"headerlink\" title=\"20240629\"></a>20240629</h3><p>Read Agent：利用分页解决大模型长文本表现差的问题（Lost in middle）。</p>\n<h3 id=\"大小模型协同\"><a href=\"#大小模型协同\" class=\"headerlink\" title=\"大小模型协同\"></a>大小模型协同</h3><p><a href=\"https://arxiv.org/pdf/2305.17390\">SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks</a>。用 BC 的小模型进行 fast thinking, 然后让大模型进行 slow thinking &#x2F; grounding.</p>\n<h3 id=\"Code-Policy\"><a href=\"#Code-Policy\" class=\"headerlink\" title=\"Code Policy\"></a>Code Policy</h3><p><a href=\"https://arxiv.org/pdf/2305.16653\">AdaPlanner: Adaptive Planning from Feedback with Language Models</a></p>\n<p>Code as Policies: Language Model Programs for Embodied Control: 2209.07753, Use Code (Formal Language) in Embodied Agent.</p>\n<h3 id=\"FFN-的作用\"><a href=\"#FFN-的作用\" class=\"headerlink\" title=\"FFN 的作用\"></a>FFN 的作用</h3><p><a href=\"https://arxiv.org/pdf/2203.14680\">Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space</a></p>\n<p><a href=\"https://arxiv.org/pdf/2304.14767\">Dissecting Recall of Factual Associations in Auto-Regressive Language Models</a></p>\n<h3 id=\"杂项\"><a href=\"#杂项\" class=\"headerlink\" title=\"杂项\"></a>杂项</h3><p>MatFormer：嵌套训练 FFN 参数，适配不同的设备。</p>\n<p>SADMoE：对 weight 聚类，将双层 MLP 转为 MoE</p>\n<p>Deja Vu：预测 attention 的激活值，动态分配空间</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security</p>\n<h2 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h2><p>VideoGUI: A Benchmark for GUI Automation from Instructional Videos，把 GUI 能力划分为三层：High Level 表示高层次的操作意图。Middle Level 为用自然语言描述的单步操作，Atomic-action 为使用固定格式描述的准确操作。整个 pipeline 都是人标的，包括视频挑选，标注，验证，task 数量较少，86 个 full task，463 个 subtask。</p>\n<p><img src=\"/../images/Mobile-LLM/1721718047655.png\" alt=\"1721718047655\"></p>\n<p>GUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents，从 Youtube 上爬取视频数据+人类录频操作数据，提取关键帧，以及 QA 文本。关键帧的标注由人类完成，包括：执行的操作， 关键帧转移的目标，使用的软件或者网站，鼠标操作，键盘输入等。迷惑的是为什么人类操作还要录屏，既然最后是提取关键帧，那可以直接在人操作的时候提取关键帧？</p>\n<p>谷歌： Onthe Effects of Data Scale on Computer Control Agents，在安卓场景下人标gui sft数据，有测试集</p>\n<p>谷歌：Android in the Wild: A Large-Scale Dataset for Android Device Control</p>\n<p>输入为 image 和 text instruction。包含 30 K 的数据，Google Apps 的占比最大。</p>\n<p><img src=\"/../images/Mobile-LLM/1717937154526.png\" alt=\"1717937154526\"></p>\n<p>World of Bits (WoB): Use only keyboard &amp; mouse，输入为彩色图像，DOM 文档，请求。支持通过众包构造新的数据。</p>\n<p>OpenAI Universe: Game, Web tasks，输入数据只有图像，操作键盘和鼠标。</p>\n<p>AndroidEnv: A Reinforcement Learning Platform for Android: 在 android emulator 上运行的虚拟环境。</p>\n<p>（MoTIF）A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility：人类标注，有 feasible 字段。</p>\n<p><img src=\"/../images/Mobile-LLM/1718009240031.png\" alt=\"1718009240031\"></p>\n<p>PIXELHELP: Mapping Natural Language Instructions to Mobile UI Action Sequences</p>\n<h2 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h2><h3 id=\"RL-based-method\"><a href=\"#RL-based-method\" class=\"headerlink\" title=\"RL-based method\"></a>RL-based method</h3><p>中间步骤奖励非常重要。稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。</p>\n<p>泛化性差，不像 LLM 具有大量先验知识。</p>\n<p>App-Buddy:  PPO based method, Interact with DOM.</p>\n<p><img src=\"/../images/Mobile-LLM/1717937734857.png\" alt=\"1717937734857\"></p>\n<p>REINFORCEMENT LEARNING ON WEB INTERFACES USING WORKFLOW-GUIDED EXPLORATION： 稀疏奖励下从0训练容易停滞不前，需要先行为克隆提升一定的性能，再执行 RL 算法。但是 BC 方法容易过拟合，因此通过从示例中导出 workflow policy，再从 workflow policy 中采样新的 policy 的方法来获取新的 trace。</p>\n<p><img src=\"/../images/Mobile-LLM/1717940196994.png\" alt=\"1717940196994\"></p>\n<h3 id=\"LLM-Agents\"><a href=\"#LLM-Agents\" class=\"headerlink\" title=\"LLM Agents\"></a>LLM Agents</h3><h4 id=\"Prompt-Engineering\"><a href=\"#Prompt-Engineering\" class=\"headerlink\" title=\"Prompt Engineering\"></a>Prompt Engineering</h4><p>Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation，从 trace 中学习 subtasks，然后封装成 api，在后续执行任务时可以直接调用。也是纯文本推理。</p>\n<p>M3A，SeeAct 都是采用截图标注，然后推理，速度会慢很多。</p>\n<p>AutoDroid: LLM-powered Task Automation in Android (MobiCom 24)</p>\n<p>Exploration + Execution 范式，基于 VH&#x2F;DOM 的 UI 表示。</p>\n<p><img src=\"/../images/Mobile-LLM/1718003623779.png\" alt=\"1718003623779\"></p>\n<p>GPT4 成功率相当可观，finetune小模型的效果接近 GPT 3.5：</p>\n<p><img src=\"/../images/Mobile-LLM/1718003792356.png\" alt=\"1718003792356\"></p>\n<p>离线部分：随机探索 + 生成 App Memory，对 UTG(UI Transition Graph) 进行分析，LLM 生成每个页面和每个 UI 元素的描述，并构建 embedding vector base。</p>\n<p>在线部分：根据 embedding vector base 筛选 UI 元素，只留下那些重要的 UI 元素，并且利用 APP Memory 中的元素生成 Guide 辅助模型进行决策。</p>\n<p>Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators</p>\n<p>DroidBot-GPT: GPT-powered UI Automation for Android</p>\n<p><img src=\"/../images/Mobile-LLM/1717939486804.png\" alt=\"1717939486804\"></p>\n<p>AppAgent: Multimodal Agents as Smartphone Users：利用 GPT4-V 进行探索+部署，支持 learn from demonstration。</p>\n<h4 id=\"Multimodal\"><a href=\"#Multimodal\" class=\"headerlink\" title=\"Multimodal\"></a>Multimodal</h4><p>CogAgent: A Visual Language Model for GUI Agents，从结果来看 Auto GUI 还是挺能打的，700M 的 encoder-decoder 和 18B 的 CogAgent （CogVLM-17B 改造而来）不相上下。</p>\n<p><img src=\"/../images/Mobile-LLM/1721962899191.png\" alt=\"1721962899191\"></p>\n<p>模型架构如下。设计上采用一个低分辨率的图像编码器来识别大部分 UI 元素和布局，高分辨率的编码器用来识别文字（这个有证据吗？仅仅有一个简单的消融实验）。比较反直觉的是，在 OCR 领域模型应该采用更小的隐藏层，而不像通用领域那样需要很大的隐藏层，所以高分辨率编码器反而参数更少，只有 0.30 B。而且，这东西每层都跟 Decoder 做特征融合，不直接使用高分辨率是因为 CogVLM 原来的架构就支持 224*224（经典数字），太大了在 Self Attention 阶段计算量会爆炸，所以这里通过压缩隐藏层大小 + Cross Attention 来降低计算量。</p>\n<p>对齐方面，人标了2k条，然后把 Mind2Web 和 AITW 的数据拿过来用 GPT-4 标了 VQA 的数据集。</p>\n<p>输出格式包括 Plan，Action，Operation，Operation 部分同样是让大模型生成操作和坐标数据，我依然很好奇到底 VLM 能不能理解坐标信息。</p>\n<p><img src=\"/../images/Mobile-LLM/1721962961205.png\" alt=\"1721962961205\"></p>\n<p>Auto GUI: You Only Look at Screens: Multimodal Chain-of-Action Agents</p>\n<p><img src=\"/../images/Mobile-LLM/1717937675502.png\" alt=\"1717937675502\"></p>\n<p>微软 Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators，大小模型协同，一个模型负责 planning，一个模型负责 executing，同时，在这个过程中实现隐私保护。这个过程会通过一个语言模型根据屏幕截图 + low level commands 来判断命令是否可执行、是否执行成功。当然，仅仅用 Decoder 做二元判断似乎有点浪费，感觉是个分类器就能做，用 bert 说不定更好。另外，Vision Encoder 在识别图片中文字这一块擅长吗？模型架构来自于 pix2seq，它原本是做目标检测的。</p>\n<p><img src=\"/../images/Mobile-LLM/1721792120662.png\" alt=\"1721792120662\"></p>\n<p><img src=\"/../images/Mobile-LLM/1721792309928.png\" alt=\"1721792309928\"></p>\n<p>META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI</p>\n<p><img src=\"/../images/Mobile-LLM/1718009413946.png\" alt=\"1718009413946\"></p>\n<h3 id=\"UI-Understanding-and-Representation\"><a href=\"#UI-Understanding-and-Representation\" class=\"headerlink\" title=\"UI Understanding and Representation\"></a>UI Understanding and Representation</h3><p>ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces：UI 理解，leveraged the temporal con<br>nections between UIs in a UI sequence to design their pretraining tasks</p>\n<p>UIBert: Learning Generic Multimodal Representations for UI Understanding：self-alignment among different multimodal features in a single UI， use trainable lightweight encoders</p>\n<h3 id=\"LLM-RL\"><a href=\"#LLM-RL\" class=\"headerlink\" title=\"LLM + RL\"></a>LLM + RL</h3><p><a href=\"https://arxiv.org/pdf/2306.03604\">Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach</a></p>\n<h3 id=\"Code-based-Methods\"><a href=\"#Code-based-Methods\" class=\"headerlink\" title=\"Code-based Methods\"></a>Code-based Methods</h3><h2 id=\"Topics\"><a href=\"#Topics\" class=\"headerlink\" title=\"Topics\"></a>Topics</h2><p>长序列的任务执行</p>\n<p>多模态 GUI Agent</p>\n<p>隐私保护</p>\n<p>用户偏好&#x2F;个性化的 Agent</p>\n<p>Proactive Agent</p>\n<p>Show me how to do&#x2F;高效的策略更新方法</p>\n<p>RL training in sparse reward</p>\n<p>LLM as Reward Model</p>\n<p>Action &amp; Workflow embedding</p>\n<p>寻找 UI 的表征&#x2F; UI Understanding</p>\n<h2 id=\"Paper-Reading\"><a href=\"#Paper-Reading\" class=\"headerlink\" title=\"Paper Reading\"></a>Paper Reading</h2><h3 id=\"20240725\"><a href=\"#20240725\" class=\"headerlink\" title=\"20240725\"></a>20240725</h3><p>ShareGPT4Video: Improving Video Understanding and Generation with Better Captions：视频数据理解，或许有助于 GUI Agent 的训练。提出了一个 Differential Sliding-window Captioning 的方案，让 GPT4o 根据上一帧和当前帧之间的差别来输出 Caption，最后加上一个 Summary 来描述整个视频的 pipeline。这里的关键是如何选关键帧，原文采用一个 CLIP Model，通过比较最后一帧和这一帧的相似性，选出差别较大的帧。</p>\n<p>Learning Transferable Visual Models From Natural Language Supervision</p>\n<p>Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers</p>\n<p><img src=\"/../images/Mobile-LLM/1721924737611.png\" alt=\"1721924737611\"></p>\n<h3 id=\"20240629\"><a href=\"#20240629\" class=\"headerlink\" title=\"20240629\"></a>20240629</h3><p>Read Agent：利用分页解决大模型长文本表现差的问题（Lost in middle）。</p>\n<h3 id=\"大小模型协同\"><a href=\"#大小模型协同\" class=\"headerlink\" title=\"大小模型协同\"></a>大小模型协同</h3><p><a href=\"https://arxiv.org/pdf/2305.17390\">SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks</a>。用 BC 的小模型进行 fast thinking, 然后让大模型进行 slow thinking &#x2F; grounding.</p>\n<h3 id=\"Code-Policy\"><a href=\"#Code-Policy\" class=\"headerlink\" title=\"Code Policy\"></a>Code Policy</h3><p><a href=\"https://arxiv.org/pdf/2305.16653\">AdaPlanner: Adaptive Planning from Feedback with Language Models</a></p>\n<p>Code as Policies: Language Model Programs for Embodied Control: 2209.07753, Use Code (Formal Language) in Embodied Agent.</p>\n<h3 id=\"FFN-的作用\"><a href=\"#FFN-的作用\" class=\"headerlink\" title=\"FFN 的作用\"></a>FFN 的作用</h3><p><a href=\"https://arxiv.org/pdf/2203.14680\">Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space</a></p>\n<p><a href=\"https://arxiv.org/pdf/2304.14767\">Dissecting Recall of Factual Associations in Auto-Regressive Language Models</a></p>\n<h3 id=\"杂项\"><a href=\"#杂项\" class=\"headerlink\" title=\"杂项\"></a>杂项</h3><p>MatFormer：嵌套训练 FFN 参数，适配不同的设备。</p>\n<p>SADMoE：对 weight 聚类，将双层 MLP 转为 MoE</p>\n<p>Deja Vu：预测 attention 的激活值，动态分配空间</p>\n"},{"title":"mathmagic","katex":true,"date":"2024-07-15T16:01:49.000Z","_content":"## 0716\n\np63\n\n![1721059328456](../images/mathmagic/1721059328456.png)\n\n![1721059341655](../images/mathmagic/1721059341655.png)\n\n疑问：为什么第一部分证明时，不需要判断 $f^{-1}(U)$ 是一个空集？因为 $U$ 的逆像在第一部分的定义至少包含了一个点 $a$。\n\n而在第二部分证明中，$U$ 被设定为一个任意的开集，因此不能保证逆像非空。\n\n\n## 20250815\n\n### 两个半正定矩阵的证明\n\n已知，$a_1, \\dots, a_n$ 全为非负的实数，可以证明矩阵\n\n$$\nC_{ij}=\\lbrace{\\min(a_i, a_j)}\\rbrace_{ij}, D_{ij}=(\\frac1{a_i + a_j})_{ij}\n$$\n\n均为半正定矩阵。\n\n两个证明的思路是类似的。对于第一个，\n\n$$\n\\min(a_i, a_j)=\\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx\n$$\n\n其中 $\\mathbb I[x \\le a]$ 是指示函数，当 $x \\le a$ 的时候取值为 1，$x \\gt a$ 时取值为 0.\n\n因此，对任意 $\\xi_i, \\xi_j$ 均有\n\n$$\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\min(a_i, a_j) = \\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty \\left(\\sum_{1\\le i \\le n}\\xi_i\\mathbb I[x \\le a_i]\\right)^2\\mathrm dx \\ge 0\n$$\n\n根据定义可知 $C_{ij}$ 为非负矩阵。\n\n同理，对于 $D_{ij}$\n\n$$\n\\frac1{a_i + a_j}=\\int_0^\\infty e^{-(a_i + a_j)x}\\mathrm dx= \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\frac1{a_i + a_j}=\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\left(\\sum_{1\\le i \\le n}\\xi_i e^{-a_ix}\\right)^2\\mathrm dx \\ge 0\n$$\n\n实际上，取\n\n$$\n\\frac1{a_i + a_j} = \\int_1^\\infty x^{-a_i-0.5}x^{-a_j-0.5}\\mathrm dx\n$$\n\n也是可以的，只需设 $x = e^t$ 就会发现是等价的。\n\n那么我们可以据此构造出很多的正定矩阵，把积分上限从无穷换成别的东西，也能得到一大堆公式。\n\n","source":"_posts/mathmagic.md","raw":"---\ntitle: mathmagic\nkatex: true\ndate: 2024-07-16 00:01:49\ntags:\n---\n## 0716\n\np63\n\n![1721059328456](../images/mathmagic/1721059328456.png)\n\n![1721059341655](../images/mathmagic/1721059341655.png)\n\n疑问：为什么第一部分证明时，不需要判断 $f^{-1}(U)$ 是一个空集？因为 $U$ 的逆像在第一部分的定义至少包含了一个点 $a$。\n\n而在第二部分证明中，$U$ 被设定为一个任意的开集，因此不能保证逆像非空。\n\n\n## 20250815\n\n### 两个半正定矩阵的证明\n\n已知，$a_1, \\dots, a_n$ 全为非负的实数，可以证明矩阵\n\n$$\nC_{ij}=\\lbrace{\\min(a_i, a_j)}\\rbrace_{ij}, D_{ij}=(\\frac1{a_i + a_j})_{ij}\n$$\n\n均为半正定矩阵。\n\n两个证明的思路是类似的。对于第一个，\n\n$$\n\\min(a_i, a_j)=\\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx\n$$\n\n其中 $\\mathbb I[x \\le a]$ 是指示函数，当 $x \\le a$ 的时候取值为 1，$x \\gt a$ 时取值为 0.\n\n因此，对任意 $\\xi_i, \\xi_j$ 均有\n\n$$\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\min(a_i, a_j) = \\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty \\left(\\sum_{1\\le i \\le n}\\xi_i\\mathbb I[x \\le a_i]\\right)^2\\mathrm dx \\ge 0\n$$\n\n根据定义可知 $C_{ij}$ 为非负矩阵。\n\n同理，对于 $D_{ij}$\n\n$$\n\\frac1{a_i + a_j}=\\int_0^\\infty e^{-(a_i + a_j)x}\\mathrm dx= \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\frac1{a_i + a_j}=\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\left(\\sum_{1\\le i \\le n}\\xi_i e^{-a_ix}\\right)^2\\mathrm dx \\ge 0\n$$\n\n实际上，取\n\n$$\n\\frac1{a_i + a_j} = \\int_1^\\infty x^{-a_i-0.5}x^{-a_j-0.5}\\mathrm dx\n$$\n\n也是可以的，只需设 $x = e^t$ 就会发现是等价的。\n\n那么我们可以据此构造出很多的正定矩阵，把积分上限从无穷换成别的东西，也能得到一大堆公式。\n\n","slug":"mathmagic","published":1,"updated":"2025-08-15T13:46:12.152Z","_id":"clysv8fde0004k8ug74wqblgu","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"0716\"><a href=\"#0716\" class=\"headerlink\" title=\"0716\"></a>0716</h2><p>p63</p>\n<p><img src=\"/../images/mathmagic/1721059328456.png\" alt=\"1721059328456\" loading=\"lazy\"></p>\n<p><img src=\"/../images/mathmagic/1721059341655.png\" alt=\"1721059341655\" loading=\"lazy\"></p>\n<p>疑问：为什么第一部分证明时，不需要判断 $f^{-1}(U)$ 是一个空集？因为 $U$ 的逆像在第一部分的定义至少包含了一个点 $a$。</p>\n<p>而在第二部分证明中，$U$ 被设定为一个任意的开集，因此不能保证逆像非空。</p>\n<h2 id=\"20250815\"><a href=\"#20250815\" class=\"headerlink\" title=\"20250815\"></a>20250815</h2><h3 id=\"两个半正定矩阵的证明\"><a href=\"#两个半正定矩阵的证明\" class=\"headerlink\" title=\"两个半正定矩阵的证明\"></a>两个半正定矩阵的证明</h3><p>已知，$a_1, \\dots, a_n$ 全为非负的实数，可以证明矩阵</p>\n<div>$$\nC_{ij}=\\lbrace{\\min(a_i, a_j)}\\rbrace_{ij}, D_{ij}=(\\frac1{a_i + a_j})_{ij}\n$$</div>\n\n<p>均为半正定矩阵。</p>\n<p>两个证明的思路是类似的。对于第一个，</p>\n<div>$$\n\\min(a_i, a_j)=\\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx\n$$</div>\n\n<p>其中 $\\mathbb I[x \\le a]$ 是指示函数，当 $x \\le a$ 的时候取值为 1，$x \\gt a$ 时取值为 0.</p>\n<p>因此，对任意 $\\xi_i, \\xi_j$ 均有</p>\n<div>$$\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\min(a_i, a_j) = \\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty \\left(\\sum_{1\\le i \\le n}\\xi_i\\mathbb I[x \\le a_i]\\right)^2\\mathrm dx \\ge 0\n$$</div>\n\n<p>根据定义可知 $C_{ij}$ 为非负矩阵。</p>\n<p>同理，对于 $D_{ij}$</p>\n<div>$$\n\\frac1{a_i + a_j}=\\int_0^\\infty e^{-(a_i + a_j)x}\\mathrm dx= \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\frac1{a_i + a_j}=\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\left(\\sum_{1\\le i \\le n}\\xi_i e^{-a_ix}\\right)^2\\mathrm dx \\ge 0\n$$</div>\n\n<p>实际上，取</p>\n<div>$$\n\\frac1{a_i + a_j} = \\int_1^\\infty x^{-a_i-0.5}x^{-a_j-0.5}\\mathrm dx\n$$</div>\n\n<p>也是可以的，只需设 $x &#x3D; e^t$ 就会发现是等价的。</p>\n<p>那么我们可以据此构造出很多的正定矩阵，把积分上限从无穷换成别的东西，也能得到一大堆公式。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"0716\"><a href=\"#0716\" class=\"headerlink\" title=\"0716\"></a>0716</h2><p>p63</p>\n<p><img src=\"/../images/mathmagic/1721059328456.png\" alt=\"1721059328456\"></p>\n<p><img src=\"/../images/mathmagic/1721059341655.png\" alt=\"1721059341655\"></p>\n<p>疑问：为什么第一部分证明时，不需要判断 $f^{-1}(U)$ 是一个空集？因为 $U$ 的逆像在第一部分的定义至少包含了一个点 $a$。</p>\n<p>而在第二部分证明中，$U$ 被设定为一个任意的开集，因此不能保证逆像非空。</p>\n<h2 id=\"20250815\"><a href=\"#20250815\" class=\"headerlink\" title=\"20250815\"></a>20250815</h2><h3 id=\"两个半正定矩阵的证明\"><a href=\"#两个半正定矩阵的证明\" class=\"headerlink\" title=\"两个半正定矩阵的证明\"></a>两个半正定矩阵的证明</h3><p>已知，$a_1, \\dots, a_n$ 全为非负的实数，可以证明矩阵</p>\n<div>$$\nC_{ij}=\\lbrace{\\min(a_i, a_j)}\\rbrace_{ij}, D_{ij}=(\\frac1{a_i + a_j})_{ij}\n$$</div>\n\n<p>均为半正定矩阵。</p>\n<p>两个证明的思路是类似的。对于第一个，</p>\n<div>$$\n\\min(a_i, a_j)=\\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx\n$$</div>\n\n<p>其中 $\\mathbb I[x \\le a]$ 是指示函数，当 $x \\le a$ 的时候取值为 1，$x \\gt a$ 时取值为 0.</p>\n<p>因此，对任意 $\\xi_i, \\xi_j$ 均有</p>\n<div>$$\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\min(a_i, a_j) = \\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j\\mathbb I[x \\le a_i] \\mathbb I[x \\le a_j]\\mathrm dx \\\\\n= \\int_0^\\infty \\left(\\sum_{1\\le i \\le n}\\xi_i\\mathbb I[x \\le a_i]\\right)^2\\mathrm dx \\ge 0\n$$</div>\n\n<p>根据定义可知 $C_{ij}$ 为非负矩阵。</p>\n<p>同理，对于 $D_{ij}$</p>\n<div>$$\n\\frac1{a_i + a_j}=\\int_0^\\infty e^{-(a_i + a_j)x}\\mathrm dx= \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\frac1{a_i + a_j}=\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j \\int_0^\\infty e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\sum_{1\\le i, j \\le n}\\xi_i\\xi_j e^{-a_ix}e^{-a_jx}\\mathrm dx\\\\\n=\\int_0^\\infty\\left(\\sum_{1\\le i \\le n}\\xi_i e^{-a_ix}\\right)^2\\mathrm dx \\ge 0\n$$</div>\n\n<p>实际上，取</p>\n<div>$$\n\\frac1{a_i + a_j} = \\int_1^\\infty x^{-a_i-0.5}x^{-a_j-0.5}\\mathrm dx\n$$</div>\n\n<p>也是可以的，只需设 $x &#x3D; e^t$ 就会发现是等价的。</p>\n<p>那么我们可以据此构造出很多的正定矩阵，把积分上限从无穷换成别的东西，也能得到一大堆公式。</p>\n"},{"title":"Llama3.1 report","katex":false,"date":"2024-07-25T03:53:04.000Z","_content":"这次开源了一个 405B 的 model. 并且之后据说还会放出多模态版本。\n\n\n## Language model post-training.\n\n## Multi-modal encoder pre-training.\n\n## Vision adapter training.\n","source":"_posts/llama3-1.md","raw":"---\ntitle: Llama3.1 report\nkatex: false\ndate: 2024-07-25 11:53:04\ntags: \n- LLM\n- multimodal\n---\n这次开源了一个 405B 的 model. 并且之后据说还会放出多模态版本。\n\n\n## Language model post-training.\n\n## Multi-modal encoder pre-training.\n\n## Vision adapter training.\n","slug":"llama3-1","published":1,"updated":"2024-07-25T04:15:43.430Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm5kyhfxi00005otg6v3l2ysp","content":"<p>这次开源了一个 405B 的 model. 并且之后据说还会放出多模态版本。</p>\n<h2 id=\"Language-model-post-training\"><a href=\"#Language-model-post-training\" class=\"headerlink\" title=\"Language model post-training.\"></a>Language model post-training.</h2><h2 id=\"Multi-modal-encoder-pre-training\"><a href=\"#Multi-modal-encoder-pre-training\" class=\"headerlink\" title=\"Multi-modal encoder pre-training.\"></a>Multi-modal encoder pre-training.</h2><h2 id=\"Vision-adapter-training\"><a href=\"#Vision-adapter-training\" class=\"headerlink\" title=\"Vision adapter training.\"></a>Vision adapter training.</h2>","site":{"data":{}},"excerpt":"","more":"<p>这次开源了一个 405B 的 model. 并且之后据说还会放出多模态版本。</p>\n<h2 id=\"Language-model-post-training\"><a href=\"#Language-model-post-training\" class=\"headerlink\" title=\"Language model post-training.\"></a>Language model post-training.</h2><h2 id=\"Multi-modal-encoder-pre-training\"><a href=\"#Multi-modal-encoder-pre-training\" class=\"headerlink\" title=\"Multi-modal encoder pre-training.\"></a>Multi-modal encoder pre-training.</h2><h2 id=\"Vision-adapter-training\"><a href=\"#Vision-adapter-training\" class=\"headerlink\" title=\"Vision adapter training.\"></a>Vision adapter training.</h2>"},{"title":"扩散模型（一）DDPM 原理学习","katex":true,"date":"2025-07-25T04:11:59.000Z","_content":"最近看了 lhy 的 Diffusion Model 教程，对于之前一直不理解的 Diffusion Model 的训练和推理过程终于获得了新的认识，还和 VAE，Flow-based 等方法构建起了统一的联系。这篇笔记作为对于 DDPM 论文公式推导的一个尝试。\n\n## 图像生成任务的优化目标\n\n一张图胜过千言万语，同样的一句话，可以生成无限的图像。因此，我们不能构建起从句子到图像的唯一映射。好在我们还有概率的工具：我们假设，所有的图像都是从某个概率分布中采样出来的，我们可以假设生图模型的提示词与图像的某个概率分布对应，生图模型的任务就是输入提示词，输出目标图像的概率分布，然后我们可以从图像的概率分布中采样出目标图像。\n\n然而，图像的概率分布异常复杂，仅凭人力无法给出其表达式，很难对其进行建模。于是，我们尝试从最简洁的高斯分布中采样，将高斯分布中的每一个向量对应于一张图片。现在，我们把复杂的概率分布变成了高斯分布，需要学习的只是（在给定提示词时）从向量到图片的映射。这就是 VAE(其实是 AE，VAE 更准确的说是生成一个概率分布) 的原理，刚刚提到的高斯分布的向量称为编码，把向量映射为图片的模型称为解码器（decoder）。而扩散模型某种意义上是多个 VAE decoder 的级联。\n\n（注意，接下来的推导同时适用于 VAE 和 Diffusion model）\n\n首先从高斯分布中采样一个向量 $z$，它通过生成模型，变成了一张图片 $x=G_{\\theta}(z)$。我们可以采样很多的 $z$，不停地生成 $x$，那么生成模型的功能就是把一个 $z$ 所在空间的高斯分布重新塑形成了 $x$ 空间的图像分布。我们把重塑得到的这个图像分布记为 $P_{\\theta}$，任意一张图像 $x$ 在这个分布的生成概率为 $P_{\\theta}(x)$。以上的 $\\theta$ 为可以训练的参数。可以看出，分布 $P_{\\theta}$ 不是直接由模型产生的，$G_{\\theta}$才是模型，而是间接地从高斯分布和模型 $G_{\\theta}$ 推出来的。\n\n那么，为了能够生成逼真的图像，我们希望生成模型的分布 $P_{\\theta}$ 和训练数据的分布 $P_{data}$ 越相近越好，从训练数据集中选择若干真实图像 $x^1, x^2, \\dots, x^m \\sim P_{data}$，那么优化目标就是尽可能增加它们的生成概率（最大化似然，Maximum Likelihood）：\n\n$$\n\\theta^* = \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\n$$\n\n（注：要学习图像的分布，所需的数据量是巨大的，大约是 1B 量级的图片才足以训练现有的 diffusion model。）\n\n为什么上面这个优化目标能够使得 $P_{\\theta}$ 接近 $P_{data}$ 呢？通过一番公式推导，我们可以把优化目标变成下列形式：\n\n$$\n\\begin{align*}\n\\theta^* &= \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\\\\\n&= \\argmax_{\\theta} \\sum_{i=1}^m\\log P_{\\theta}(x^i)\\\\\n&\\approx \\argmax_{\\theta} E_{x\\sim P_{data}}[\\log P_{\\theta}(x)]\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx - \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{data}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta}  \\int_x P_{data}(x)\\frac{\\log  P_{\\theta}(x)\\mathrm dx}{\\log  P_{data}(x)\\mathrm dx}\\\\\n&= \\argmin_{\\theta} KL[P_{data}||P_{\\theta}]\n\\end{align*}\n$$\n\n可以看出，最大化似然其实和最小化 KL 散度等价。其中约等号那一步是利用蒙特卡洛采样。而 KL 散度的意义正是“度量分布 p 和分布 q 之间的距离”，这个值越小，则两个概率分布越接近。\n\n## VAE 的优化过程\n\n接下来，我们优化一下 VAE。\n\n### 假设为高斯分布\n\n具体而言，对于 VAE 来说：\n\n$$\nP_{\\theta}(x) = \\int_z P_{\\theta}(x|z)P(z)\\mathrm dz\n$$\n\n而 $P_{\\theta}(x|z)$ 就是“给定高斯向量 $z$ ，产生图像 $x$ 的概率”，这不就是我们的解码器 $G_\\theta$ 吗！遗憾的是，$G_{\\theta}$ 是一个确定性的映射，不是一个概率，如果非要认为它是一个概率的话，它会变成只有在某几个特定点概率为 1，其他点的概率为 0：\n\n$$\nP_\\theta(x|z) = \\begin{cases}\n1, G_\\theta(z) = x\\\\\n0, G_\\theta(z) \\neq x\n\\end{cases}\n$$\n\n这好像不太好，我们假定图像是一个连续空间，如果 $P_{\\theta}(x|z)$ 只在几个特定的离散点非 0 的话，那目标函数就变成一个难以优化的东西了！离散的东西怎么求导呢？为了克服这个困难，我们决定将解码器 $G_{\\theta}$ 从一个确定性映射换成一个概率分布，要不就假设他是高斯分布吧：\n\n$$\nx|z \\sim \\mathcal N (G_\\theta(z), \\sigma^2 I)\\\\\nP_\\theta (x|z) \\propto \\exp(-||G_\\theta(z) - x||_2^2/2\\sigma^2)\n$$\n\n可以看到解码器 $G_{\\theta}$ 输出的不再是“向量对应的图像”，而是“向量对应图像的高斯分布均值”。“假设图像是高斯分布”是个很糟糕的假设，它看起来跟事实完全不符，不过，至少这个高斯的概率表达式可以拿去求导。随着梯度下降的次数增多，$G_\\theta (z)$ 应该会和 $x$ 越来越接近。\n\n### 求最大似然的下界\n\n我们回到最大似然形式的优化目标进行变形：\n\n$$\n\\log P_{\\theta}(x) = \\int_z q(z|x) \\log P_\\theta(x) \\mathrm dz\n$$\n\n（我们引入了一个 $q(z|x)$，这个东西可以是任何概率分布，上式始终成立）\n\n$$\n\\begin{align*}\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)q(z|x)}{q(z|x)P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz + \\underline{\\int_z q(z|x) \\log \\frac{q(z|x)}{P_{\\theta}(z|x)}\\mathrm dz}_{这是 KL 散度，始终大于0}\\\\\n&\\ge \\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz\\\\\n&= \\underline{E_{z\\sim q(z|x)}[\\log \\frac{P_{\\theta}(z, x)}{q(z|x)}]}_{VAE 的目标就是让这个取到最大值}\n\\end{align*}\n$$\n\n最后一行这个，就是目标的下界，是 VAE 最终的优化目标，如果我们能够把原始目标的下界变得最大，那么原始目标大概率也会尽可能地增大。这个下界其实就是 ELBO，保证了模型的最坏情况不会比下界更差。$q(z|x)$ 其实是一个编码器（把图像映射为向量），它输出的也是一个概率分布，不管这个编码器输出的概率分布长什么样，上面的公式都是成立的。VAE 有特殊的技巧来同时优化编码器和解码器（重参数化等等），不过这里就不多介绍了。我们还是来看看 Diffusion 吧。\n\n## DDPM 的优化过程\n\nDiffsion 的通俗理解应该很直观吧，如下图所示：\n\n![1753424129654](../images/DDPM/1753424129654.png)\n\nDiffusion 的本义是扩散，把一颗规则的方糖放到水里，它会逐渐溶解，糖分子扩散到溶液的每一处，最开始的方糖分子，分布是规则的，到了最后变成了完全无规律的分布，和完全随机分布没有区别。我们可以想想如何“溶解”图像，把图像和高斯信号不断地混合，每一步添加一点高斯噪声，图像就从最开始的规则分布 $x_0$ 变成了完全随机的高斯噪声 $x_T$。\n\n那么，反过来呢？随机从高斯分布中取出一个噪声 $x_T$，我们能否逆推出最开始的规则分布 $x_0$？这就是扩散模型所做的事情。扩散模型把 $x_T$ 一步一步去噪变成 $x_{T-1}, \\dots, x_{1}, x_0$，它每次接受 t 时刻带有噪声的图像 $x_t$，输出加噪之前的上一时刻图像 $x_{t-1}$。可以看出它和 VAE 其实有几分相似性，输入一个高斯向量，最终输出一张图像。实际上，我们可以把去噪过程的每一步都看作一次 VAE 解码，即 $z = x_t$，$x = x_{t-1}$，那么扩散模型实际上就是 T 个解码器被训练在了一个模型里面：\n\n$$\nP_{\\theta}(x_0) = \\int_{x_1:x_T} P(x_T)P_{\\theta}(x_{T-1}|x_T)\\dots P_{\\theta}(x_0|x_1)\\mathrm dx_1:x_T\n$$\n\n（注：还真有级联多个 VAE 的架构——HVAE. DDPM 可以看作它的一个特例，用加噪过程替代了编码器。）\n\n### 推导最大似然的下界\n\n依然是最大似然公式，扩散模型实际上就是 n 个 VAE 的级联：\n\n$$\n\\begin{align*}\n\\log P_{\\theta}(x_0) &= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta\n(x_0:x_T)q(x_1:x_T|x_0)}{q(x_1:x_T|x_0)P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T \\\\\n&+ \\underline{\\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{q(x_1:x_T|x_0)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T}_{KL 散度 \\ge 0}\\\\\n&\\ge \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\underline{E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]}_{ELBO}\n\\end{align*}\n$$\n\n以上推导和 VAE 完全一样。这里的 $x_0$ 就是最终的图像，和 VAE 的 $x$ 一样。在 VAE 里这个 q 项是个编码器，要训练的。但是在 Diffusion 里面，这里的 $q(x_1:x_T|x_0)$ 含义是加噪过程，即输入图像，输出加噪后的图像，它无需训练，是已经定义好的：\n\n$$\nq(x_1:x_T|x_0) = q(x_T|x_{T-1})\\dots q(x_1|x_0)\n$$\n\n### 从 ELBO 推导 DDPM 训练时的优化目标\n\n现在问题来了，为什么训练过程的 loss 公式跟我们朴素的理解完全不一样呢？我们还是从上一部分计算出的 ELBO 入手来分析这个问题。\n\n公式推导来自 [Understanding Diffusion Models: A Unified Perspective](https://arxiv.org/abs/2208.11970)。本文从多种角度采用不同的理论分析 Variational Diffusion Model，可见 Diffusion Model 是一种在数学上多么优美的架构。在优化 ELBO 这一部分，作者做了两种不同的等价变形来推导优化公式，其中一种思路比较简单直接，但是不利于用作真实的算法优化过程；另一种则是我们接下来要介绍的。\n\n首先要注意到一个变形技巧：\n\n$$\nq(x_t|x_{t-1}) = q(x_t|x_{t-1}, x_0)\n$$\n\n这是很显然的，因为加噪过程的第 t 步只依赖于第 t-1 步，你把原始图像加进来作为条件不会对概率造成任何影响。然而这个神秘操作却对我们接下来的计算至关重要：\n\n$$\n\\begin{align*}\n&E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^Tq(x_t|x_{t-1})}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{q(x_t|x_{t-1}, x_0)}_{注意这里用到了神秘技巧！}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{\\frac{q(x_{t-1}|x_t, x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{只是普通的贝叶斯}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)\\cdot \\underline{\\prod_{t=2}^T\\frac{q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{这里可以错位相消}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\frac{q(x_T|x_0)}{q(x_1|x_0)}\\cdot \\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_T|x_0)\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log P_{\\theta}(x_0|x_1) + \\log\\frac{P(x_T)}{q(x_T|x_0)} + \\log\\frac{\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] + E_{x_T\\sim q(x_T|x_0)}[\\log\\frac{P(x_T)}{q(x_T|x_0)}] + \\underline{\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]}_{这一项的化简写在后面了}\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] - KL[{q(x_T|x_0)}||P(x_T)] -\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n\\end{align*}\n$$\n\n其中，第三项的化简：\n\n$$\n\\begin{align*}\n&\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1},x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1}|x_t,x_0)q(x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)\\int_{x_{t-1}}q(x_{t-1}|x_t,x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\n\\end{align*}\n$$\n\n现在，我们得到了三项优化目标，它们的含义如下：\n\n1. $E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 为 reconstruction term，它表示的是最后一步重建，即从 $x_1$ 恢复原图 $x_0$ 的过程，可类比于 VAE 中的从高斯向量 z 恢复原图 x；\n2. $KL[{q(x_T|x_0)}||P(x_T)]$ 为 prior matching term，这是所有 VAE 类型的模型共有的。在这里，$P(x_T)$ 是一个高斯分布（想想，这就是扩散模型推理时输入的那个随机高斯向量），而 $q(x_T|x_0)$ 为加噪过程，图像加 T 步噪声后也近似为高斯，所以这一项实际上为 0。这里没有需要训练的参数，可以忽略；\n3. $E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$ 就是 denoising matching term，这里是什么 match 什么呢，是扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 去 Match 一个训练集里的去噪过程 $q(x_{t-1}|x_t, x_0)$。$q$ 原本是来自加噪过程的概率分布，但是我们已经通过贝叶斯把它转换成了去噪过程的概率，它现在作为一个 ground truth 信号去监督模型学习，含义是“已知了真实图像 $x_0$ 的情况下，去噪过程应该是什么样”。我们训练的模型在不知道真实图像的前提下学习这个由 $q$ 指导的去噪过程，它就能逐渐掌握如何生成一个真实图像了。\n\n### 真正的 DDPM 训练\n\nDDPM 的优化目标我们已经在上一部分推出完毕，但是和真正的公式好像还是有一些 gap？其实很简单，我们的公式里面把加噪过程的噪声分布写成了 $q$，但是实际上我们早就知道，这个 $q$ 其实代表的是一个高斯分布，那我们就可以把高斯分布的实际表达式代进去算了。在计算之前，我们再来详细分析一下“加噪过程”的细节。\n\n#### 加噪过程的细节\n\n![1753442174434](../images/DDPM/1753442174434.png)\n\n所谓的“加噪”运算，其实是把输入信号和标准高斯噪声按照某种比例混合：\n\n$$\nx_t = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$\n\n我们可以人为规定一组常数 $\\lbrace\\alpha_1, \\alpha_2, \\dots\\alpha_T\\rbrace$，表示不同时刻输入信号 $x_{t-1}$ 的强度。$\\alpha$ 越大，则输出的信号和输入信号越相似，越小，则输出信号越接近噪声。\n\n为什么系数要有根号？容易观察到，等号右侧的两个系数的平方之和等于 1。这是为了保证混合前后信号的方差保持不变。不难推导，两个方差为 1 的高斯信号按照上述 $\\alpha$ 的比例混合以后还是一个方差为 1 的高斯信号。\n\n然而，训练时我们不是一步步地从 $x_0$ 加噪一直到 $x_T$，这样实在太慢了！好在高斯信号是线性的东西，两个高斯加在一起还是高斯，我们就可以直接推导出 $x_t$ 和 $x_0$ 的关系：\n\n$$\n\\begin{align*}\nx_t &= \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t-1}}\\varepsilon_{t-1}) + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} +  \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&(设 \\varepsilon^*_{t-2} = \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1} \\sim \\mathcal N(0, I))\\\\\n&= {\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_t(1-\\alpha_{t-1}) + (1-\\alpha_t)}\\varepsilon^*_{t-2}}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_t\\alpha_{t-1}}\\varepsilon_{t-2}^*\\\\\n&=\\dots\\\\\n&=\\sqrt{\\alpha_t\\alpha_{t-1}\\dots\\alpha_1}x_0 + \\sqrt{1 - \\alpha_t\\alpha_{t-1}\\dots\\alpha_1}\\varepsilon^*_{0}\\\\\n&(\\varepsilon^*_0 \\sim \\mathcal N(0, I))\n\\end{align*}\n$$\n\n我们记 $\\bar{\\alpha_t} = \\alpha_t\\alpha_{t-1}\\dots\\alpha_1$，则上式可以写为\n\n$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$\n\n#### 计算 DDPM 的优化目标\n\n我们先来计算 denoising matching term $E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$。首先，根据上面推导出的 $x_t$ 与 $x_0$ 的关系，$q(x_t|x_0)$ 是均值为 $\\sqrt{\\bar\\alpha_t}x_{0}$ ，方差为 $({1 - \\bar\\alpha_t})I$ 的高斯分布。\n\n然而，去噪监督信号 $q(x_{t-1}|x_t, x_0)$ 看起来不太好算。我们可以通过贝叶斯公式把它转换为加噪过程：\n\n$$\n\\begin{align*}\nq(x_{t-1}|x_t, x_0)&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1}, x_0)}{q(x_{t}|x_0)}\\\\\n&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1})}{q(x_{t}|x_0)}\\\\\n\\end{align*}\n$$\n\n这里的分子和分母的项全部都是高斯分布，我们终于可以计算了，总而言之，计算结果还是一个高斯分布，均值为\n\n$$\n\\mu_q(x_t) = \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}\n$$\n\n方差为\n\n$$\n\\Sigma_q = \\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}I\n$$\n\n扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 的目标是预测噪声，那么把它建模为高斯分布就很显然了。我们假设它的均值为 $\\mu_\\theta(x_t)$ 是一个可学习的量（注意到这和我们在 VAE 里面假设 $G_\\theta(x)$ 的输出为高斯分布一致），方差和监督信号 $q(x_{t-1}|x_t, x_0)$ 的方差一样（已知）。\n\n根据 KL 散度公式\n\n$$\nD_{\\mathrm{KL}}(\\mathcal{N}(\\boldsymbol{x};\\boldsymbol{\\mu}_x,\\boldsymbol{\\Sigma}_x)\\parallel\\mathcal{N}(\\boldsymbol{y};\\boldsymbol{\\mu}_y,\\boldsymbol{\\Sigma}_y))=\\\\\n\\frac{1}{2}\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_y|}{|\\boldsymbol{\\Sigma}_x|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_y^{-1}\\boldsymbol{\\Sigma}_x)+(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)^T\\boldsymbol{\\Sigma}_y^{-1}(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)\\right]\n$$\n\n我们可以计算出\n\n$$\n\\begin{align*}\n&KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)] \\\\\n&= \\frac12\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_q|}{|\\boldsymbol{\\Sigma}_q|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_q^{-1}\\boldsymbol{\\Sigma}_q)+(\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q)^T\\boldsymbol{\\Sigma}_q^{-1}(\\boldsymbol{\\mu}_q-\\boldsymbol{\\mu}_q)\\right]\\\\\n&=\\frac12\\left[0-d+d+\\frac1{\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\right]\\\\\n&=\\frac1{2\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\\\\n\\end{align*}\n$$\n\n这也很符合直觉，毕竟高斯无非就是由均值和方差决定的，方差本来就是一样的，唯一剩下的不就是拟合均值了吗？高斯分布下拟合均值，那不就是用 MLE loss 吗？\n\n现在我们终于找到了 DDPM 的损失函数：\n\n$$\n\\begin{align*}\n&\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[||\\mu_\\theta(x_t)-\\mu_q(x_t)||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim }[||\\mu_\\theta(x_t)-\\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\mu_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n\\end{align*}\n$$\n\n其中 $c_1, c_2$ 是关于 $\\lbrace\\alpha_t\\rbrace$ 的表达式，与 $\\theta$ 无关。由于模型 $\\mu_\\theta$ 输入里面就包含 $x_t$，那么 $c_1x_t$ 项就不用让模型预测了，我们可以直接令\n\n$$\n\\mu_\\theta(x_t) = c_1x_t + c_2x_\\theta(x_t)\n$$\n\n则优化目标为\n\n$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||c_1x_t + c_2x_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\n\\end{align*}\n$$\n\n这下坏了，这不就是让我们的模型直接预测出原图 $x_0$ 吗！不要着急，我们继续分析 $x_0$。由 $x_t$ 和 $x_0$ 的关系可知\n\n$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\Leftrightarrow x_0 = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$\n\n这下 $\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t$ 对于 $x_\\theta(x_t)$ 来说又是已知项，于是我们进一步令\n\n$$\nx_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t)\n$$\n\n优化目标进一步化简：\n\n$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t) - \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t + \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\varepsilon_\\theta(x_t) -\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(\\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n\\end{align*}\n$$\n\n神奇的事情发生了！我们的模型现在唯一需要预测的就是这个噪声项 $\\varepsilon$ 长什么样。也就是说，现在的扩散模型 $\\varepsilon_\\theta$，输入是 $t$ 时刻含噪图像 $x_t$，要预测的是其含有的噪声 $\\varepsilon$！至此，我们已经推出了 DDPM 的训练目标。\n\n刚才我们推导的某一步里指出，我们的损失函数等价于预测原图 $x_0$。的确如此！事实上预测原图和预测噪声在原理上是等价的，它们只不过相差一些系数。但是也有论文指出，预测原图和预测噪声相比，predicting the noise puts more weight on lower noise levels，在 t 较小的情况上花费更多算力进行训练。\n\n另外，实际的 DDPM 会将时间 $t$ 也作为一个条件输入给模型 $\\varepsilon_\\theta$。我们实际上训练的是：\n\n$$\n\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$\n\n别忘了，这只是 ELBO 三项中的一项，denoise matching term。我们知道，prior matching 项与参数无关不用训练；还剩下一项 reconstruction，也就是 $E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 这一项需要计算。这一项其实也是类似的，我们假设模型预测高斯分布，均值为 $\\mu_\\theta(x_1)$，方差为 $(1-\\alpha_1)I$ 与 $x_1$ 一致：\n\n$$\n\\begin{align*}\n&E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log (\\frac{1}{\\sqrt{2\\pi(1 - \\alpha_1)}})\\exp [-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}]]\\\\\n&=E_{\\varepsilon\\sim N}[-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}] + C\\\\\n\\end{align*}\n$$\n\n因此，优化它为最大值等价于优化\n\n$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n\\end{align*}\n$$\n\n我们又故技重施，预测它的噪声：\n\n$$\n\\mu_\\theta(x_1) = \\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1)\\\\\n$$\n\n$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(x_1) - \\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon) - \\varepsilon||_2^2]\\\\\n\\end{align*}\n$$\n\n可以看出，这和第三项的优化目标是一样的！只不过此时 $t = 1$，而之前 $t$ 的范围是 $[2, T]$。\n\n因此，我们把上面两种情况综合起来就得到了最终的训练目标：\n\n$$\n\\argmin_\\theta E_{t\\sim U(1,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$\n\n你问我为什么 t = 1 的概率与其他的情况相同？我也不太清楚。按照 ELBO 的要求这两种情况的系数或许是不一样的，但是我们这里当它是一样的了。这个可能会导致一些 bias 的引入？不知道有没有论文讨论这个。\n\n至此，我们终于搞定了 DDPM 的训练过程！\n\n### DDPM 的推理过程\n\n推理过程就是给定时间 $t$ 和该时刻的图像 $x_{t}$，输出上一时刻的图像 $x_{t-1}$（本质上是去掉上一时刻的噪声）。推完上述的训练过程，我想推理公式已经呼之欲出了：\n\n$$\nx_0 \\approx x_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)\\\\\nx_{t-1} \\sim q(x_{t-1}|x_t, x_0) = \\mathcal N (\\mu_q(x_t), \\Sigma_q)\\\\\n（条件：t\\ge2）\n$$\n\n由此可以推出\n\n$$\n\\begin{align*}\nx_{t-1} &= \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t} + \\sqrt{\\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}}\\varepsilon\\\\\n&\\approx \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)(\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t))}{1-\\bar\\alpha_t} + \\sigma_t \\varepsilon\\\\\n&=\\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{(1-\\alpha_t)}{\\sqrt{1 - \\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)) + \\sigma_t \\varepsilon\n（条件：t\\ge2）\n\\end{align*}\n$$\n\n这就是推理过程的公式。其中 $\\varepsilon$ 为正态分布。\n\n不过要注意，这个噪声项 $\\varepsilon$ 的来源，可不是来自扩散模型 $\\varepsilon_\\theta(x_t, t)$ 的随机性，而是来自 $q(x_t|x_{t-1},x_0)$。$\\varepsilon_\\theta(x_t, t)$ 代表了从 $x_t$ 到 $x_0$ 相差多少噪声，这个噪声在给定 $x_t$ 和 $x_0$ 的情况下是固定的，它是一个确定值。虽然此时 $x_t$ 和 $x_0$ 都是确定的，但是从 $x_t$ 到 $x_{t-1}$ 的这个过程引入了新的高斯噪声，你即使知道 $x_t$ 和 $x_0$，仍然无法确定 $x_{t-1}$ 长什么样！这个随机项 $\\varepsilon$ 代表的就是（已知 $x_0$ 的情况下）从 $x_t$ 到 $x_{t-1}$ 的不确定性。\n\n上面的公式只适用于 $t\\ge2$ 的情况。很显然，$t=1$ 的时候你也没有 $q(x_{t-1}|x_{t}, x_0)$ 可用啊。请循其本，$t=1$ 的情况实际上来自于 ELBO 的 reconstruct term，需要用那里的公式解释。所以 $t = 1$ 的情况下，模型就直接输出最终图像就行了，不需要添加噪声项（因为噪声来自于 $q(x_{t-1}|x_{t}, x_0)$！）：\n\n$$\nx_0 \\approx x_\\theta(x_1) = \\frac{1}{\\sqrt{\\alpha_1}} x_1 - \\frac{\\sqrt{1 - \\alpha_1}}{\\sqrt{\\alpha_1}}\\varepsilon_\\theta(x_1, 1)\\\\\n$$\n\n不过我寻思一般 $T=1000$，最后一步恐怕噪声含量已经很低了。\n\n## 其他问题\n\n推理的时候，为什么不直接取概率最大的情况作为 $x_{t-1}$ 的值，也就直接让 $\\varepsilon = 0$？要是这么设定，我们之前的推导就白做了，要知道，我们之前全部都是假设每一步去噪都符合高斯分布，你直接让噪声等于零，其实等价于让每一步高斯的方差 $\\sigma_t^2$ 等于 0，直觉上好像退化成 auto encoder 了。在这种情况下，上面的所有公式肯定要发生变化。这个有空可以分析一下，如果我们让所有的 $\\sigma_t$ 都等于 0，会发生什么。\n\n第二个问题，为什么 VAE 输出的时候不需要添加这个噪声项？很显然，VAE 不存在 denoise matching term，它只有 reconstruct term，这一项是和 $t = 1$ 的扩散模型一样，不需要加噪声的。\n\n最后一个问题。既然图像 $x_0$ 是从噪声 $x_T$ 变过来的，明明每一步都是减去一个噪声，为什么减着减着就变成了一个有规律的图像？到底从哪一步开始，噪声不再是噪声，而是突然变得有规律了？听起来像一个谷堆悖论。这个问题我还没有想清楚，不过我觉得扩散模型就是在构建 $x_T$ 到 $x_0$ 的一个映射，只是这个映射要迭代很多步而已，所以或许从一开始噪声 $x_T$ 就已经注定了会对应 $x_0$，并不是在中间某一步突变的。Flow Matching 方法能够直接用一条直线构建这种映射，也许会把这个问题展示得更加清楚。（当然，去噪过程是有一定随机性的，也许它一开始想走到图像 A，走着走着突然就往图像 B 去跑了，所以这个问题大概还有更好的解释吧。）\n\n（那么，什么是 Score Matching 呢？）\n","source":"_posts/DDPM.md","raw":"---\ntitle: 扩散模型（一）DDPM 原理学习\nkatex: true\ndate: 2025-07-25 12:11:59\ntags:\n---\n最近看了 lhy 的 Diffusion Model 教程，对于之前一直不理解的 Diffusion Model 的训练和推理过程终于获得了新的认识，还和 VAE，Flow-based 等方法构建起了统一的联系。这篇笔记作为对于 DDPM 论文公式推导的一个尝试。\n\n## 图像生成任务的优化目标\n\n一张图胜过千言万语，同样的一句话，可以生成无限的图像。因此，我们不能构建起从句子到图像的唯一映射。好在我们还有概率的工具：我们假设，所有的图像都是从某个概率分布中采样出来的，我们可以假设生图模型的提示词与图像的某个概率分布对应，生图模型的任务就是输入提示词，输出目标图像的概率分布，然后我们可以从图像的概率分布中采样出目标图像。\n\n然而，图像的概率分布异常复杂，仅凭人力无法给出其表达式，很难对其进行建模。于是，我们尝试从最简洁的高斯分布中采样，将高斯分布中的每一个向量对应于一张图片。现在，我们把复杂的概率分布变成了高斯分布，需要学习的只是（在给定提示词时）从向量到图片的映射。这就是 VAE(其实是 AE，VAE 更准确的说是生成一个概率分布) 的原理，刚刚提到的高斯分布的向量称为编码，把向量映射为图片的模型称为解码器（decoder）。而扩散模型某种意义上是多个 VAE decoder 的级联。\n\n（注意，接下来的推导同时适用于 VAE 和 Diffusion model）\n\n首先从高斯分布中采样一个向量 $z$，它通过生成模型，变成了一张图片 $x=G_{\\theta}(z)$。我们可以采样很多的 $z$，不停地生成 $x$，那么生成模型的功能就是把一个 $z$ 所在空间的高斯分布重新塑形成了 $x$ 空间的图像分布。我们把重塑得到的这个图像分布记为 $P_{\\theta}$，任意一张图像 $x$ 在这个分布的生成概率为 $P_{\\theta}(x)$。以上的 $\\theta$ 为可以训练的参数。可以看出，分布 $P_{\\theta}$ 不是直接由模型产生的，$G_{\\theta}$才是模型，而是间接地从高斯分布和模型 $G_{\\theta}$ 推出来的。\n\n那么，为了能够生成逼真的图像，我们希望生成模型的分布 $P_{\\theta}$ 和训练数据的分布 $P_{data}$ 越相近越好，从训练数据集中选择若干真实图像 $x^1, x^2, \\dots, x^m \\sim P_{data}$，那么优化目标就是尽可能增加它们的生成概率（最大化似然，Maximum Likelihood）：\n\n$$\n\\theta^* = \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\n$$\n\n（注：要学习图像的分布，所需的数据量是巨大的，大约是 1B 量级的图片才足以训练现有的 diffusion model。）\n\n为什么上面这个优化目标能够使得 $P_{\\theta}$ 接近 $P_{data}$ 呢？通过一番公式推导，我们可以把优化目标变成下列形式：\n\n$$\n\\begin{align*}\n\\theta^* &= \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\\\\\n&= \\argmax_{\\theta} \\sum_{i=1}^m\\log P_{\\theta}(x^i)\\\\\n&\\approx \\argmax_{\\theta} E_{x\\sim P_{data}}[\\log P_{\\theta}(x)]\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx - \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{data}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta}  \\int_x P_{data}(x)\\frac{\\log  P_{\\theta}(x)\\mathrm dx}{\\log  P_{data}(x)\\mathrm dx}\\\\\n&= \\argmin_{\\theta} KL[P_{data}||P_{\\theta}]\n\\end{align*}\n$$\n\n可以看出，最大化似然其实和最小化 KL 散度等价。其中约等号那一步是利用蒙特卡洛采样。而 KL 散度的意义正是“度量分布 p 和分布 q 之间的距离”，这个值越小，则两个概率分布越接近。\n\n## VAE 的优化过程\n\n接下来，我们优化一下 VAE。\n\n### 假设为高斯分布\n\n具体而言，对于 VAE 来说：\n\n$$\nP_{\\theta}(x) = \\int_z P_{\\theta}(x|z)P(z)\\mathrm dz\n$$\n\n而 $P_{\\theta}(x|z)$ 就是“给定高斯向量 $z$ ，产生图像 $x$ 的概率”，这不就是我们的解码器 $G_\\theta$ 吗！遗憾的是，$G_{\\theta}$ 是一个确定性的映射，不是一个概率，如果非要认为它是一个概率的话，它会变成只有在某几个特定点概率为 1，其他点的概率为 0：\n\n$$\nP_\\theta(x|z) = \\begin{cases}\n1, G_\\theta(z) = x\\\\\n0, G_\\theta(z) \\neq x\n\\end{cases}\n$$\n\n这好像不太好，我们假定图像是一个连续空间，如果 $P_{\\theta}(x|z)$ 只在几个特定的离散点非 0 的话，那目标函数就变成一个难以优化的东西了！离散的东西怎么求导呢？为了克服这个困难，我们决定将解码器 $G_{\\theta}$ 从一个确定性映射换成一个概率分布，要不就假设他是高斯分布吧：\n\n$$\nx|z \\sim \\mathcal N (G_\\theta(z), \\sigma^2 I)\\\\\nP_\\theta (x|z) \\propto \\exp(-||G_\\theta(z) - x||_2^2/2\\sigma^2)\n$$\n\n可以看到解码器 $G_{\\theta}$ 输出的不再是“向量对应的图像”，而是“向量对应图像的高斯分布均值”。“假设图像是高斯分布”是个很糟糕的假设，它看起来跟事实完全不符，不过，至少这个高斯的概率表达式可以拿去求导。随着梯度下降的次数增多，$G_\\theta (z)$ 应该会和 $x$ 越来越接近。\n\n### 求最大似然的下界\n\n我们回到最大似然形式的优化目标进行变形：\n\n$$\n\\log P_{\\theta}(x) = \\int_z q(z|x) \\log P_\\theta(x) \\mathrm dz\n$$\n\n（我们引入了一个 $q(z|x)$，这个东西可以是任何概率分布，上式始终成立）\n\n$$\n\\begin{align*}\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)q(z|x)}{q(z|x)P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz + \\underline{\\int_z q(z|x) \\log \\frac{q(z|x)}{P_{\\theta}(z|x)}\\mathrm dz}_{这是 KL 散度，始终大于0}\\\\\n&\\ge \\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz\\\\\n&= \\underline{E_{z\\sim q(z|x)}[\\log \\frac{P_{\\theta}(z, x)}{q(z|x)}]}_{VAE 的目标就是让这个取到最大值}\n\\end{align*}\n$$\n\n最后一行这个，就是目标的下界，是 VAE 最终的优化目标，如果我们能够把原始目标的下界变得最大，那么原始目标大概率也会尽可能地增大。这个下界其实就是 ELBO，保证了模型的最坏情况不会比下界更差。$q(z|x)$ 其实是一个编码器（把图像映射为向量），它输出的也是一个概率分布，不管这个编码器输出的概率分布长什么样，上面的公式都是成立的。VAE 有特殊的技巧来同时优化编码器和解码器（重参数化等等），不过这里就不多介绍了。我们还是来看看 Diffusion 吧。\n\n## DDPM 的优化过程\n\nDiffsion 的通俗理解应该很直观吧，如下图所示：\n\n![1753424129654](../images/DDPM/1753424129654.png)\n\nDiffusion 的本义是扩散，把一颗规则的方糖放到水里，它会逐渐溶解，糖分子扩散到溶液的每一处，最开始的方糖分子，分布是规则的，到了最后变成了完全无规律的分布，和完全随机分布没有区别。我们可以想想如何“溶解”图像，把图像和高斯信号不断地混合，每一步添加一点高斯噪声，图像就从最开始的规则分布 $x_0$ 变成了完全随机的高斯噪声 $x_T$。\n\n那么，反过来呢？随机从高斯分布中取出一个噪声 $x_T$，我们能否逆推出最开始的规则分布 $x_0$？这就是扩散模型所做的事情。扩散模型把 $x_T$ 一步一步去噪变成 $x_{T-1}, \\dots, x_{1}, x_0$，它每次接受 t 时刻带有噪声的图像 $x_t$，输出加噪之前的上一时刻图像 $x_{t-1}$。可以看出它和 VAE 其实有几分相似性，输入一个高斯向量，最终输出一张图像。实际上，我们可以把去噪过程的每一步都看作一次 VAE 解码，即 $z = x_t$，$x = x_{t-1}$，那么扩散模型实际上就是 T 个解码器被训练在了一个模型里面：\n\n$$\nP_{\\theta}(x_0) = \\int_{x_1:x_T} P(x_T)P_{\\theta}(x_{T-1}|x_T)\\dots P_{\\theta}(x_0|x_1)\\mathrm dx_1:x_T\n$$\n\n（注：还真有级联多个 VAE 的架构——HVAE. DDPM 可以看作它的一个特例，用加噪过程替代了编码器。）\n\n### 推导最大似然的下界\n\n依然是最大似然公式，扩散模型实际上就是 n 个 VAE 的级联：\n\n$$\n\\begin{align*}\n\\log P_{\\theta}(x_0) &= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta\n(x_0:x_T)q(x_1:x_T|x_0)}{q(x_1:x_T|x_0)P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T \\\\\n&+ \\underline{\\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{q(x_1:x_T|x_0)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T}_{KL 散度 \\ge 0}\\\\\n&\\ge \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\underline{E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]}_{ELBO}\n\\end{align*}\n$$\n\n以上推导和 VAE 完全一样。这里的 $x_0$ 就是最终的图像，和 VAE 的 $x$ 一样。在 VAE 里这个 q 项是个编码器，要训练的。但是在 Diffusion 里面，这里的 $q(x_1:x_T|x_0)$ 含义是加噪过程，即输入图像，输出加噪后的图像，它无需训练，是已经定义好的：\n\n$$\nq(x_1:x_T|x_0) = q(x_T|x_{T-1})\\dots q(x_1|x_0)\n$$\n\n### 从 ELBO 推导 DDPM 训练时的优化目标\n\n现在问题来了，为什么训练过程的 loss 公式跟我们朴素的理解完全不一样呢？我们还是从上一部分计算出的 ELBO 入手来分析这个问题。\n\n公式推导来自 [Understanding Diffusion Models: A Unified Perspective](https://arxiv.org/abs/2208.11970)。本文从多种角度采用不同的理论分析 Variational Diffusion Model，可见 Diffusion Model 是一种在数学上多么优美的架构。在优化 ELBO 这一部分，作者做了两种不同的等价变形来推导优化公式，其中一种思路比较简单直接，但是不利于用作真实的算法优化过程；另一种则是我们接下来要介绍的。\n\n首先要注意到一个变形技巧：\n\n$$\nq(x_t|x_{t-1}) = q(x_t|x_{t-1}, x_0)\n$$\n\n这是很显然的，因为加噪过程的第 t 步只依赖于第 t-1 步，你把原始图像加进来作为条件不会对概率造成任何影响。然而这个神秘操作却对我们接下来的计算至关重要：\n\n$$\n\\begin{align*}\n&E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^Tq(x_t|x_{t-1})}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{q(x_t|x_{t-1}, x_0)}_{注意这里用到了神秘技巧！}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{\\frac{q(x_{t-1}|x_t, x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{只是普通的贝叶斯}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)\\cdot \\underline{\\prod_{t=2}^T\\frac{q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{这里可以错位相消}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\frac{q(x_T|x_0)}{q(x_1|x_0)}\\cdot \\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_T|x_0)\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log P_{\\theta}(x_0|x_1) + \\log\\frac{P(x_T)}{q(x_T|x_0)} + \\log\\frac{\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] + E_{x_T\\sim q(x_T|x_0)}[\\log\\frac{P(x_T)}{q(x_T|x_0)}] + \\underline{\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]}_{这一项的化简写在后面了}\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] - KL[{q(x_T|x_0)}||P(x_T)] -\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n\\end{align*}\n$$\n\n其中，第三项的化简：\n\n$$\n\\begin{align*}\n&\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1},x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1}|x_t,x_0)q(x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)\\int_{x_{t-1}}q(x_{t-1}|x_t,x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\n\\end{align*}\n$$\n\n现在，我们得到了三项优化目标，它们的含义如下：\n\n1. $E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 为 reconstruction term，它表示的是最后一步重建，即从 $x_1$ 恢复原图 $x_0$ 的过程，可类比于 VAE 中的从高斯向量 z 恢复原图 x；\n2. $KL[{q(x_T|x_0)}||P(x_T)]$ 为 prior matching term，这是所有 VAE 类型的模型共有的。在这里，$P(x_T)$ 是一个高斯分布（想想，这就是扩散模型推理时输入的那个随机高斯向量），而 $q(x_T|x_0)$ 为加噪过程，图像加 T 步噪声后也近似为高斯，所以这一项实际上为 0。这里没有需要训练的参数，可以忽略；\n3. $E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$ 就是 denoising matching term，这里是什么 match 什么呢，是扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 去 Match 一个训练集里的去噪过程 $q(x_{t-1}|x_t, x_0)$。$q$ 原本是来自加噪过程的概率分布，但是我们已经通过贝叶斯把它转换成了去噪过程的概率，它现在作为一个 ground truth 信号去监督模型学习，含义是“已知了真实图像 $x_0$ 的情况下，去噪过程应该是什么样”。我们训练的模型在不知道真实图像的前提下学习这个由 $q$ 指导的去噪过程，它就能逐渐掌握如何生成一个真实图像了。\n\n### 真正的 DDPM 训练\n\nDDPM 的优化目标我们已经在上一部分推出完毕，但是和真正的公式好像还是有一些 gap？其实很简单，我们的公式里面把加噪过程的噪声分布写成了 $q$，但是实际上我们早就知道，这个 $q$ 其实代表的是一个高斯分布，那我们就可以把高斯分布的实际表达式代进去算了。在计算之前，我们再来详细分析一下“加噪过程”的细节。\n\n#### 加噪过程的细节\n\n![1753442174434](../images/DDPM/1753442174434.png)\n\n所谓的“加噪”运算，其实是把输入信号和标准高斯噪声按照某种比例混合：\n\n$$\nx_t = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$\n\n我们可以人为规定一组常数 $\\lbrace\\alpha_1, \\alpha_2, \\dots\\alpha_T\\rbrace$，表示不同时刻输入信号 $x_{t-1}$ 的强度。$\\alpha$ 越大，则输出的信号和输入信号越相似，越小，则输出信号越接近噪声。\n\n为什么系数要有根号？容易观察到，等号右侧的两个系数的平方之和等于 1。这是为了保证混合前后信号的方差保持不变。不难推导，两个方差为 1 的高斯信号按照上述 $\\alpha$ 的比例混合以后还是一个方差为 1 的高斯信号。\n\n然而，训练时我们不是一步步地从 $x_0$ 加噪一直到 $x_T$，这样实在太慢了！好在高斯信号是线性的东西，两个高斯加在一起还是高斯，我们就可以直接推导出 $x_t$ 和 $x_0$ 的关系：\n\n$$\n\\begin{align*}\nx_t &= \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t-1}}\\varepsilon_{t-1}) + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} +  \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&(设 \\varepsilon^*_{t-2} = \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1} \\sim \\mathcal N(0, I))\\\\\n&= {\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_t(1-\\alpha_{t-1}) + (1-\\alpha_t)}\\varepsilon^*_{t-2}}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_t\\alpha_{t-1}}\\varepsilon_{t-2}^*\\\\\n&=\\dots\\\\\n&=\\sqrt{\\alpha_t\\alpha_{t-1}\\dots\\alpha_1}x_0 + \\sqrt{1 - \\alpha_t\\alpha_{t-1}\\dots\\alpha_1}\\varepsilon^*_{0}\\\\\n&(\\varepsilon^*_0 \\sim \\mathcal N(0, I))\n\\end{align*}\n$$\n\n我们记 $\\bar{\\alpha_t} = \\alpha_t\\alpha_{t-1}\\dots\\alpha_1$，则上式可以写为\n\n$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$\n\n#### 计算 DDPM 的优化目标\n\n我们先来计算 denoising matching term $E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$。首先，根据上面推导出的 $x_t$ 与 $x_0$ 的关系，$q(x_t|x_0)$ 是均值为 $\\sqrt{\\bar\\alpha_t}x_{0}$ ，方差为 $({1 - \\bar\\alpha_t})I$ 的高斯分布。\n\n然而，去噪监督信号 $q(x_{t-1}|x_t, x_0)$ 看起来不太好算。我们可以通过贝叶斯公式把它转换为加噪过程：\n\n$$\n\\begin{align*}\nq(x_{t-1}|x_t, x_0)&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1}, x_0)}{q(x_{t}|x_0)}\\\\\n&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1})}{q(x_{t}|x_0)}\\\\\n\\end{align*}\n$$\n\n这里的分子和分母的项全部都是高斯分布，我们终于可以计算了，总而言之，计算结果还是一个高斯分布，均值为\n\n$$\n\\mu_q(x_t) = \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}\n$$\n\n方差为\n\n$$\n\\Sigma_q = \\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}I\n$$\n\n扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 的目标是预测噪声，那么把它建模为高斯分布就很显然了。我们假设它的均值为 $\\mu_\\theta(x_t)$ 是一个可学习的量（注意到这和我们在 VAE 里面假设 $G_\\theta(x)$ 的输出为高斯分布一致），方差和监督信号 $q(x_{t-1}|x_t, x_0)$ 的方差一样（已知）。\n\n根据 KL 散度公式\n\n$$\nD_{\\mathrm{KL}}(\\mathcal{N}(\\boldsymbol{x};\\boldsymbol{\\mu}_x,\\boldsymbol{\\Sigma}_x)\\parallel\\mathcal{N}(\\boldsymbol{y};\\boldsymbol{\\mu}_y,\\boldsymbol{\\Sigma}_y))=\\\\\n\\frac{1}{2}\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_y|}{|\\boldsymbol{\\Sigma}_x|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_y^{-1}\\boldsymbol{\\Sigma}_x)+(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)^T\\boldsymbol{\\Sigma}_y^{-1}(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)\\right]\n$$\n\n我们可以计算出\n\n$$\n\\begin{align*}\n&KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)] \\\\\n&= \\frac12\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_q|}{|\\boldsymbol{\\Sigma}_q|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_q^{-1}\\boldsymbol{\\Sigma}_q)+(\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q)^T\\boldsymbol{\\Sigma}_q^{-1}(\\boldsymbol{\\mu}_q-\\boldsymbol{\\mu}_q)\\right]\\\\\n&=\\frac12\\left[0-d+d+\\frac1{\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\right]\\\\\n&=\\frac1{2\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\\\\n\\end{align*}\n$$\n\n这也很符合直觉，毕竟高斯无非就是由均值和方差决定的，方差本来就是一样的，唯一剩下的不就是拟合均值了吗？高斯分布下拟合均值，那不就是用 MLE loss 吗？\n\n现在我们终于找到了 DDPM 的损失函数：\n\n$$\n\\begin{align*}\n&\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[||\\mu_\\theta(x_t)-\\mu_q(x_t)||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim }[||\\mu_\\theta(x_t)-\\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\mu_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n\\end{align*}\n$$\n\n其中 $c_1, c_2$ 是关于 $\\lbrace\\alpha_t\\rbrace$ 的表达式，与 $\\theta$ 无关。由于模型 $\\mu_\\theta$ 输入里面就包含 $x_t$，那么 $c_1x_t$ 项就不用让模型预测了，我们可以直接令\n\n$$\n\\mu_\\theta(x_t) = c_1x_t + c_2x_\\theta(x_t)\n$$\n\n则优化目标为\n\n$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||c_1x_t + c_2x_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\n\\end{align*}\n$$\n\n这下坏了，这不就是让我们的模型直接预测出原图 $x_0$ 吗！不要着急，我们继续分析 $x_0$。由 $x_t$ 和 $x_0$ 的关系可知\n\n$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\Leftrightarrow x_0 = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$\n\n这下 $\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t$ 对于 $x_\\theta(x_t)$ 来说又是已知项，于是我们进一步令\n\n$$\nx_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t)\n$$\n\n优化目标进一步化简：\n\n$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t) - \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t + \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\varepsilon_\\theta(x_t) -\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(\\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n\\end{align*}\n$$\n\n神奇的事情发生了！我们的模型现在唯一需要预测的就是这个噪声项 $\\varepsilon$ 长什么样。也就是说，现在的扩散模型 $\\varepsilon_\\theta$，输入是 $t$ 时刻含噪图像 $x_t$，要预测的是其含有的噪声 $\\varepsilon$！至此，我们已经推出了 DDPM 的训练目标。\n\n刚才我们推导的某一步里指出，我们的损失函数等价于预测原图 $x_0$。的确如此！事实上预测原图和预测噪声在原理上是等价的，它们只不过相差一些系数。但是也有论文指出，预测原图和预测噪声相比，predicting the noise puts more weight on lower noise levels，在 t 较小的情况上花费更多算力进行训练。\n\n另外，实际的 DDPM 会将时间 $t$ 也作为一个条件输入给模型 $\\varepsilon_\\theta$。我们实际上训练的是：\n\n$$\n\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$\n\n别忘了，这只是 ELBO 三项中的一项，denoise matching term。我们知道，prior matching 项与参数无关不用训练；还剩下一项 reconstruction，也就是 $E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 这一项需要计算。这一项其实也是类似的，我们假设模型预测高斯分布，均值为 $\\mu_\\theta(x_1)$，方差为 $(1-\\alpha_1)I$ 与 $x_1$ 一致：\n\n$$\n\\begin{align*}\n&E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log (\\frac{1}{\\sqrt{2\\pi(1 - \\alpha_1)}})\\exp [-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}]]\\\\\n&=E_{\\varepsilon\\sim N}[-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}] + C\\\\\n\\end{align*}\n$$\n\n因此，优化它为最大值等价于优化\n\n$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n\\end{align*}\n$$\n\n我们又故技重施，预测它的噪声：\n\n$$\n\\mu_\\theta(x_1) = \\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1)\\\\\n$$\n\n$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(x_1) - \\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon) - \\varepsilon||_2^2]\\\\\n\\end{align*}\n$$\n\n可以看出，这和第三项的优化目标是一样的！只不过此时 $t = 1$，而之前 $t$ 的范围是 $[2, T]$。\n\n因此，我们把上面两种情况综合起来就得到了最终的训练目标：\n\n$$\n\\argmin_\\theta E_{t\\sim U(1,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$\n\n你问我为什么 t = 1 的概率与其他的情况相同？我也不太清楚。按照 ELBO 的要求这两种情况的系数或许是不一样的，但是我们这里当它是一样的了。这个可能会导致一些 bias 的引入？不知道有没有论文讨论这个。\n\n至此，我们终于搞定了 DDPM 的训练过程！\n\n### DDPM 的推理过程\n\n推理过程就是给定时间 $t$ 和该时刻的图像 $x_{t}$，输出上一时刻的图像 $x_{t-1}$（本质上是去掉上一时刻的噪声）。推完上述的训练过程，我想推理公式已经呼之欲出了：\n\n$$\nx_0 \\approx x_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)\\\\\nx_{t-1} \\sim q(x_{t-1}|x_t, x_0) = \\mathcal N (\\mu_q(x_t), \\Sigma_q)\\\\\n（条件：t\\ge2）\n$$\n\n由此可以推出\n\n$$\n\\begin{align*}\nx_{t-1} &= \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t} + \\sqrt{\\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}}\\varepsilon\\\\\n&\\approx \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)(\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t))}{1-\\bar\\alpha_t} + \\sigma_t \\varepsilon\\\\\n&=\\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{(1-\\alpha_t)}{\\sqrt{1 - \\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)) + \\sigma_t \\varepsilon\n（条件：t\\ge2）\n\\end{align*}\n$$\n\n这就是推理过程的公式。其中 $\\varepsilon$ 为正态分布。\n\n不过要注意，这个噪声项 $\\varepsilon$ 的来源，可不是来自扩散模型 $\\varepsilon_\\theta(x_t, t)$ 的随机性，而是来自 $q(x_t|x_{t-1},x_0)$。$\\varepsilon_\\theta(x_t, t)$ 代表了从 $x_t$ 到 $x_0$ 相差多少噪声，这个噪声在给定 $x_t$ 和 $x_0$ 的情况下是固定的，它是一个确定值。虽然此时 $x_t$ 和 $x_0$ 都是确定的，但是从 $x_t$ 到 $x_{t-1}$ 的这个过程引入了新的高斯噪声，你即使知道 $x_t$ 和 $x_0$，仍然无法确定 $x_{t-1}$ 长什么样！这个随机项 $\\varepsilon$ 代表的就是（已知 $x_0$ 的情况下）从 $x_t$ 到 $x_{t-1}$ 的不确定性。\n\n上面的公式只适用于 $t\\ge2$ 的情况。很显然，$t=1$ 的时候你也没有 $q(x_{t-1}|x_{t}, x_0)$ 可用啊。请循其本，$t=1$ 的情况实际上来自于 ELBO 的 reconstruct term，需要用那里的公式解释。所以 $t = 1$ 的情况下，模型就直接输出最终图像就行了，不需要添加噪声项（因为噪声来自于 $q(x_{t-1}|x_{t}, x_0)$！）：\n\n$$\nx_0 \\approx x_\\theta(x_1) = \\frac{1}{\\sqrt{\\alpha_1}} x_1 - \\frac{\\sqrt{1 - \\alpha_1}}{\\sqrt{\\alpha_1}}\\varepsilon_\\theta(x_1, 1)\\\\\n$$\n\n不过我寻思一般 $T=1000$，最后一步恐怕噪声含量已经很低了。\n\n## 其他问题\n\n推理的时候，为什么不直接取概率最大的情况作为 $x_{t-1}$ 的值，也就直接让 $\\varepsilon = 0$？要是这么设定，我们之前的推导就白做了，要知道，我们之前全部都是假设每一步去噪都符合高斯分布，你直接让噪声等于零，其实等价于让每一步高斯的方差 $\\sigma_t^2$ 等于 0，直觉上好像退化成 auto encoder 了。在这种情况下，上面的所有公式肯定要发生变化。这个有空可以分析一下，如果我们让所有的 $\\sigma_t$ 都等于 0，会发生什么。\n\n第二个问题，为什么 VAE 输出的时候不需要添加这个噪声项？很显然，VAE 不存在 denoise matching term，它只有 reconstruct term，这一项是和 $t = 1$ 的扩散模型一样，不需要加噪声的。\n\n最后一个问题。既然图像 $x_0$ 是从噪声 $x_T$ 变过来的，明明每一步都是减去一个噪声，为什么减着减着就变成了一个有规律的图像？到底从哪一步开始，噪声不再是噪声，而是突然变得有规律了？听起来像一个谷堆悖论。这个问题我还没有想清楚，不过我觉得扩散模型就是在构建 $x_T$ 到 $x_0$ 的一个映射，只是这个映射要迭代很多步而已，所以或许从一开始噪声 $x_T$ 就已经注定了会对应 $x_0$，并不是在中间某一步突变的。Flow Matching 方法能够直接用一条直线构建这种映射，也许会把这个问题展示得更加清楚。（当然，去噪过程是有一定随机性的，也许它一开始想走到图像 A，走着走着突然就往图像 B 去跑了，所以这个问题大概还有更好的解释吧。）\n\n（那么，什么是 Score Matching 呢？）\n","slug":"DDPM","published":1,"updated":"2025-08-10T12:14:57.325Z","_id":"cmdid4r8o0000s4tgffkbdotm","comments":1,"layout":"post","photos":[],"link":"","content":"<p>最近看了 lhy 的 Diffusion Model 教程，对于之前一直不理解的 Diffusion Model 的训练和推理过程终于获得了新的认识，还和 VAE，Flow-based 等方法构建起了统一的联系。这篇笔记作为对于 DDPM 论文公式推导的一个尝试。</p>\n<h2 id=\"图像生成任务的优化目标\"><a href=\"#图像生成任务的优化目标\" class=\"headerlink\" title=\"图像生成任务的优化目标\"></a>图像生成任务的优化目标</h2><p>一张图胜过千言万语，同样的一句话，可以生成无限的图像。因此，我们不能构建起从句子到图像的唯一映射。好在我们还有概率的工具：我们假设，所有的图像都是从某个概率分布中采样出来的，我们可以假设生图模型的提示词与图像的某个概率分布对应，生图模型的任务就是输入提示词，输出目标图像的概率分布，然后我们可以从图像的概率分布中采样出目标图像。</p>\n<p>然而，图像的概率分布异常复杂，仅凭人力无法给出其表达式，很难对其进行建模。于是，我们尝试从最简洁的高斯分布中采样，将高斯分布中的每一个向量对应于一张图片。现在，我们把复杂的概率分布变成了高斯分布，需要学习的只是（在给定提示词时）从向量到图片的映射。这就是 VAE(其实是 AE，VAE 更准确的说是生成一个概率分布) 的原理，刚刚提到的高斯分布的向量称为编码，把向量映射为图片的模型称为解码器（decoder）。而扩散模型某种意义上是多个 VAE decoder 的级联。</p>\n<p>（注意，接下来的推导同时适用于 VAE 和 Diffusion model）</p>\n<p>首先从高斯分布中采样一个向量 $z$，它通过生成模型，变成了一张图片 $x&#x3D;G_{\\theta}(z)$。我们可以采样很多的 $z$，不停地生成 $x$，那么生成模型的功能就是把一个 $z$ 所在空间的高斯分布重新塑形成了 $x$ 空间的图像分布。我们把重塑得到的这个图像分布记为 $P_{\\theta}$，任意一张图像 $x$ 在这个分布的生成概率为 $P_{\\theta}(x)$。以上的 $\\theta$ 为可以训练的参数。可以看出，分布 $P_{\\theta}$ 不是直接由模型产生的，$G_{\\theta}$才是模型，而是间接地从高斯分布和模型 $G_{\\theta}$ 推出来的。</p>\n<p>那么，为了能够生成逼真的图像，我们希望生成模型的分布 $P_{\\theta}$ 和训练数据的分布 $P_{data}$ 越相近越好，从训练数据集中选择若干真实图像 $x^1, x^2, \\dots, x^m \\sim P_{data}$，那么优化目标就是尽可能增加它们的生成概率（最大化似然，Maximum Likelihood）：</p>\n<div>$$\n\\theta^* = \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\n$$</div>\n\n<p>（注：要学习图像的分布，所需的数据量是巨大的，大约是 1B 量级的图片才足以训练现有的 diffusion model。）</p>\n<p>为什么上面这个优化目标能够使得 $P_{\\theta}$ 接近 $P_{data}$ 呢？通过一番公式推导，我们可以把优化目标变成下列形式：</p>\n<div>$$\n\\begin{align*}\n\\theta^* &= \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\\\\\n&= \\argmax_{\\theta} \\sum_{i=1}^m\\log P_{\\theta}(x^i)\\\\\n&\\approx \\argmax_{\\theta} E_{x\\sim P_{data}}[\\log P_{\\theta}(x)]\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx - \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{data}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta}  \\int_x P_{data}(x)\\frac{\\log  P_{\\theta}(x)\\mathrm dx}{\\log  P_{data}(x)\\mathrm dx}\\\\\n&= \\argmin_{\\theta} KL[P_{data}||P_{\\theta}]\n\\end{align*}\n$$</div>\n\n<p>可以看出，最大化似然其实和最小化 KL 散度等价。其中约等号那一步是利用蒙特卡洛采样。而 KL 散度的意义正是“度量分布 p 和分布 q 之间的距离”，这个值越小，则两个概率分布越接近。</p>\n<h2 id=\"VAE-的优化过程\"><a href=\"#VAE-的优化过程\" class=\"headerlink\" title=\"VAE 的优化过程\"></a>VAE 的优化过程</h2><p>接下来，我们优化一下 VAE。</p>\n<h3 id=\"假设为高斯分布\"><a href=\"#假设为高斯分布\" class=\"headerlink\" title=\"假设为高斯分布\"></a>假设为高斯分布</h3><p>具体而言，对于 VAE 来说：</p>\n<div>$$\nP_{\\theta}(x) = \\int_z P_{\\theta}(x|z)P(z)\\mathrm dz\n$$</div>\n\n<p>而 $P_{\\theta}(x|z)$ 就是“给定高斯向量 $z$ ，产生图像 $x$ 的概率”，这不就是我们的解码器 $G_\\theta$ 吗！遗憾的是，$G_{\\theta}$ 是一个确定性的映射，不是一个概率，如果非要认为它是一个概率的话，它会变成只有在某几个特定点概率为 1，其他点的概率为 0：</p>\n<div>$$\nP_\\theta(x|z) = \\begin{cases}\n1, G_\\theta(z) = x\\\\\n0, G_\\theta(z) \\neq x\n\\end{cases}\n$$</div>\n\n<p>这好像不太好，我们假定图像是一个连续空间，如果 $P_{\\theta}(x|z)$ 只在几个特定的离散点非 0 的话，那目标函数就变成一个难以优化的东西了！离散的东西怎么求导呢？为了克服这个困难，我们决定将解码器 $G_{\\theta}$ 从一个确定性映射换成一个概率分布，要不就假设他是高斯分布吧：</p>\n<div>$$\nx|z \\sim \\mathcal N (G_\\theta(z), \\sigma^2 I)\\\\\nP_\\theta (x|z) \\propto \\exp(-||G_\\theta(z) - x||_2^2/2\\sigma^2)\n$$</div>\n\n<p>可以看到解码器 $G_{\\theta}$ 输出的不再是“向量对应的图像”，而是“向量对应图像的高斯分布均值”。“假设图像是高斯分布”是个很糟糕的假设，它看起来跟事实完全不符，不过，至少这个高斯的概率表达式可以拿去求导。随着梯度下降的次数增多，$G_\\theta (z)$ 应该会和 $x$ 越来越接近。</p>\n<h3 id=\"求最大似然的下界\"><a href=\"#求最大似然的下界\" class=\"headerlink\" title=\"求最大似然的下界\"></a>求最大似然的下界</h3><p>我们回到最大似然形式的优化目标进行变形：</p>\n<div>$$\n\\log P_{\\theta}(x) = \\int_z q(z|x) \\log P_\\theta(x) \\mathrm dz\n$$</div>\n\n<p>（我们引入了一个 $q(z|x)$，这个东西可以是任何概率分布，上式始终成立）</p>\n<div>$$\n\\begin{align*}\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)q(z|x)}{q(z|x)P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz + \\underline{\\int_z q(z|x) \\log \\frac{q(z|x)}{P_{\\theta}(z|x)}\\mathrm dz}_{这是 KL 散度，始终大于0}\\\\\n&\\ge \\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz\\\\\n&= \\underline{E_{z\\sim q(z|x)}[\\log \\frac{P_{\\theta}(z, x)}{q(z|x)}]}_{VAE 的目标就是让这个取到最大值}\n\\end{align*}\n$$</div>\n\n<p>最后一行这个，就是目标的下界，是 VAE 最终的优化目标，如果我们能够把原始目标的下界变得最大，那么原始目标大概率也会尽可能地增大。这个下界其实就是 ELBO，保证了模型的最坏情况不会比下界更差。$q(z|x)$ 其实是一个编码器（把图像映射为向量），它输出的也是一个概率分布，不管这个编码器输出的概率分布长什么样，上面的公式都是成立的。VAE 有特殊的技巧来同时优化编码器和解码器（重参数化等等），不过这里就不多介绍了。我们还是来看看 Diffusion 吧。</p>\n<h2 id=\"DDPM-的优化过程\"><a href=\"#DDPM-的优化过程\" class=\"headerlink\" title=\"DDPM 的优化过程\"></a>DDPM 的优化过程</h2><p>Diffsion 的通俗理解应该很直观吧，如下图所示：</p>\n<p><img src=\"/../images/DDPM/1753424129654.png\" alt=\"1753424129654\" loading=\"lazy\"></p>\n<p>Diffusion 的本义是扩散，把一颗规则的方糖放到水里，它会逐渐溶解，糖分子扩散到溶液的每一处，最开始的方糖分子，分布是规则的，到了最后变成了完全无规律的分布，和完全随机分布没有区别。我们可以想想如何“溶解”图像，把图像和高斯信号不断地混合，每一步添加一点高斯噪声，图像就从最开始的规则分布 $x_0$ 变成了完全随机的高斯噪声 $x_T$。</p>\n<p>那么，反过来呢？随机从高斯分布中取出一个噪声 $x_T$，我们能否逆推出最开始的规则分布 $x_0$？这就是扩散模型所做的事情。扩散模型把 $x_T$ 一步一步去噪变成 $x_{T-1}, \\dots, x_{1}, x_0$，它每次接受 t 时刻带有噪声的图像 $x_t$，输出加噪之前的上一时刻图像 $x_{t-1}$。可以看出它和 VAE 其实有几分相似性，输入一个高斯向量，最终输出一张图像。实际上，我们可以把去噪过程的每一步都看作一次 VAE 解码，即 $z &#x3D; x_t$，$x &#x3D; x_{t-1}$，那么扩散模型实际上就是 T 个解码器被训练在了一个模型里面：</p>\n<div>$$\nP_{\\theta}(x_0) = \\int_{x_1:x_T} P(x_T)P_{\\theta}(x_{T-1}|x_T)\\dots P_{\\theta}(x_0|x_1)\\mathrm dx_1:x_T\n$$</div>\n\n<p>（注：还真有级联多个 VAE 的架构——HVAE. DDPM 可以看作它的一个特例，用加噪过程替代了编码器。）</p>\n<h3 id=\"推导最大似然的下界\"><a href=\"#推导最大似然的下界\" class=\"headerlink\" title=\"推导最大似然的下界\"></a>推导最大似然的下界</h3><p>依然是最大似然公式，扩散模型实际上就是 n 个 VAE 的级联：</p>\n<div>$$\n\\begin{align*}\n\\log P_{\\theta}(x_0) &= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta\n(x_0:x_T)q(x_1:x_T|x_0)}{q(x_1:x_T|x_0)P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T \\\\\n&+ \\underline{\\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{q(x_1:x_T|x_0)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T}_{KL 散度 \\ge 0}\\\\\n&\\ge \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\underline{E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]}_{ELBO}\n\\end{align*}\n$$</div>\n\n<p>以上推导和 VAE 完全一样。这里的 $x_0$ 就是最终的图像，和 VAE 的 $x$ 一样。在 VAE 里这个 q 项是个编码器，要训练的。但是在 Diffusion 里面，这里的 $q(x_1:x_T|x_0)$ 含义是加噪过程，即输入图像，输出加噪后的图像，它无需训练，是已经定义好的：</p>\n<div>$$\nq(x_1:x_T|x_0) = q(x_T|x_{T-1})\\dots q(x_1|x_0)\n$$</div>\n\n<h3 id=\"从-ELBO-推导-DDPM-训练时的优化目标\"><a href=\"#从-ELBO-推导-DDPM-训练时的优化目标\" class=\"headerlink\" title=\"从 ELBO 推导 DDPM 训练时的优化目标\"></a>从 ELBO 推导 DDPM 训练时的优化目标</h3><p>现在问题来了，为什么训练过程的 loss 公式跟我们朴素的理解完全不一样呢？我们还是从上一部分计算出的 ELBO 入手来分析这个问题。</p>\n<p>公式推导来自 <a href=\"https://arxiv.org/abs/2208.11970\">Understanding Diffusion Models: A Unified Perspective</a>。本文从多种角度采用不同的理论分析 Variational Diffusion Model，可见 Diffusion Model 是一种在数学上多么优美的架构。在优化 ELBO 这一部分，作者做了两种不同的等价变形来推导优化公式，其中一种思路比较简单直接，但是不利于用作真实的算法优化过程；另一种则是我们接下来要介绍的。</p>\n<p>首先要注意到一个变形技巧：</p>\n<div>$$\nq(x_t|x_{t-1}) = q(x_t|x_{t-1}, x_0)\n$$</div>\n\n<p>这是很显然的，因为加噪过程的第 t 步只依赖于第 t-1 步，你把原始图像加进来作为条件不会对概率造成任何影响。然而这个神秘操作却对我们接下来的计算至关重要：</p>\n<div>$$\n\\begin{align*}\n&E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^Tq(x_t|x_{t-1})}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{q(x_t|x_{t-1}, x_0)}_{注意这里用到了神秘技巧！}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{\\frac{q(x_{t-1}|x_t, x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{只是普通的贝叶斯}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)\\cdot \\underline{\\prod_{t=2}^T\\frac{q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{这里可以错位相消}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\frac{q(x_T|x_0)}{q(x_1|x_0)}\\cdot \\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_T|x_0)\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log P_{\\theta}(x_0|x_1) + \\log\\frac{P(x_T)}{q(x_T|x_0)} + \\log\\frac{\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] + E_{x_T\\sim q(x_T|x_0)}[\\log\\frac{P(x_T)}{q(x_T|x_0)}] + \\underline{\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]}_{这一项的化简写在后面了}\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] - KL[{q(x_T|x_0)}||P(x_T)] -\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n\\end{align*}\n$$</div>\n\n<p>其中，第三项的化简：</p>\n<div>$$\n\\begin{align*}\n&\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1},x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1}|x_t,x_0)q(x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)\\int_{x_{t-1}}q(x_{t-1}|x_t,x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\n\\end{align*}\n$$</div>\n\n<p>现在，我们得到了三项优化目标，它们的含义如下：</p>\n<ol>\n<li>$E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 为 reconstruction term，它表示的是最后一步重建，即从 $x_1$ 恢复原图 $x_0$ 的过程，可类比于 VAE 中的从高斯向量 z 恢复原图 x；</li>\n<li>$KL[{q(x_T|x_0)}||P(x_T)]$ 为 prior matching term，这是所有 VAE 类型的模型共有的。在这里，$P(x_T)$ 是一个高斯分布（想想，这就是扩散模型推理时输入的那个随机高斯向量），而 $q(x_T|x_0)$ 为加噪过程，图像加 T 步噪声后也近似为高斯，所以这一项实际上为 0。这里没有需要训练的参数，可以忽略；</li>\n<li>$E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$ 就是 denoising matching term，这里是什么 match 什么呢，是扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 去 Match 一个训练集里的去噪过程 $q(x_{t-1}|x_t, x_0)$。$q$ 原本是来自加噪过程的概率分布，但是我们已经通过贝叶斯把它转换成了去噪过程的概率，它现在作为一个 ground truth 信号去监督模型学习，含义是“已知了真实图像 $x_0$ 的情况下，去噪过程应该是什么样”。我们训练的模型在不知道真实图像的前提下学习这个由 $q$ 指导的去噪过程，它就能逐渐掌握如何生成一个真实图像了。</li>\n</ol>\n<h3 id=\"真正的-DDPM-训练\"><a href=\"#真正的-DDPM-训练\" class=\"headerlink\" title=\"真正的 DDPM 训练\"></a>真正的 DDPM 训练</h3><p>DDPM 的优化目标我们已经在上一部分推出完毕，但是和真正的公式好像还是有一些 gap？其实很简单，我们的公式里面把加噪过程的噪声分布写成了 $q$，但是实际上我们早就知道，这个 $q$ 其实代表的是一个高斯分布，那我们就可以把高斯分布的实际表达式代进去算了。在计算之前，我们再来详细分析一下“加噪过程”的细节。</p>\n<h4 id=\"加噪过程的细节\"><a href=\"#加噪过程的细节\" class=\"headerlink\" title=\"加噪过程的细节\"></a>加噪过程的细节</h4><p><img src=\"/../images/DDPM/1753442174434.png\" alt=\"1753442174434\" loading=\"lazy\"></p>\n<p>所谓的“加噪”运算，其实是把输入信号和标准高斯噪声按照某种比例混合：</p>\n<div>$$\nx_t = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$</div>\n\n<p>我们可以人为规定一组常数 $\\lbrace\\alpha_1, \\alpha_2, \\dots\\alpha_T\\rbrace$，表示不同时刻输入信号 $x_{t-1}$ 的强度。$\\alpha$ 越大，则输出的信号和输入信号越相似，越小，则输出信号越接近噪声。</p>\n<p>为什么系数要有根号？容易观察到，等号右侧的两个系数的平方之和等于 1。这是为了保证混合前后信号的方差保持不变。不难推导，两个方差为 1 的高斯信号按照上述 $\\alpha$ 的比例混合以后还是一个方差为 1 的高斯信号。</p>\n<p>然而，训练时我们不是一步步地从 $x_0$ 加噪一直到 $x_T$，这样实在太慢了！好在高斯信号是线性的东西，两个高斯加在一起还是高斯，我们就可以直接推导出 $x_t$ 和 $x_0$ 的关系：</p>\n<div>$$\n\\begin{align*}\nx_t &= \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t-1}}\\varepsilon_{t-1}) + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} +  \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&(设 \\varepsilon^*_{t-2} = \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1} \\sim \\mathcal N(0, I))\\\\\n&= {\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_t(1-\\alpha_{t-1}) + (1-\\alpha_t)}\\varepsilon^*_{t-2}}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_t\\alpha_{t-1}}\\varepsilon_{t-2}^*\\\\\n&=\\dots\\\\\n&=\\sqrt{\\alpha_t\\alpha_{t-1}\\dots\\alpha_1}x_0 + \\sqrt{1 - \\alpha_t\\alpha_{t-1}\\dots\\alpha_1}\\varepsilon^*_{0}\\\\\n&(\\varepsilon^*_0 \\sim \\mathcal N(0, I))\n\\end{align*}\n$$</div>\n\n<p>我们记 $\\bar{\\alpha_t} &#x3D; \\alpha_t\\alpha_{t-1}\\dots\\alpha_1$，则上式可以写为</p>\n<div>$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$</div>\n\n<h4 id=\"计算-DDPM-的优化目标\"><a href=\"#计算-DDPM-的优化目标\" class=\"headerlink\" title=\"计算 DDPM 的优化目标\"></a>计算 DDPM 的优化目标</h4><p>我们先来计算 denoising matching term $E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$。首先，根据上面推导出的 $x_t$ 与 $x_0$ 的关系，$q(x_t|x_0)$ 是均值为 $\\sqrt{\\bar\\alpha_t}x_{0}$ ，方差为 $({1 - \\bar\\alpha_t})I$ 的高斯分布。</p>\n<p>然而，去噪监督信号 $q(x_{t-1}|x_t, x_0)$ 看起来不太好算。我们可以通过贝叶斯公式把它转换为加噪过程：</p>\n<div>$$\n\\begin{align*}\nq(x_{t-1}|x_t, x_0)&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1}, x_0)}{q(x_{t}|x_0)}\\\\\n&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1})}{q(x_{t}|x_0)}\\\\\n\\end{align*}\n$$</div>\n\n<p>这里的分子和分母的项全部都是高斯分布，我们终于可以计算了，总而言之，计算结果还是一个高斯分布，均值为</p>\n<div>$$\n\\mu_q(x_t) = \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}\n$$</div>\n\n<p>方差为</p>\n<div>$$\n\\Sigma_q = \\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}I\n$$</div>\n\n<p>扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 的目标是预测噪声，那么把它建模为高斯分布就很显然了。我们假设它的均值为 $\\mu_\\theta(x_t)$ 是一个可学习的量（注意到这和我们在 VAE 里面假设 $G_\\theta(x)$ 的输出为高斯分布一致），方差和监督信号 $q(x_{t-1}|x_t, x_0)$ 的方差一样（已知）。</p>\n<p>根据 KL 散度公式</p>\n<div>$$\nD_{\\mathrm{KL}}(\\mathcal{N}(\\boldsymbol{x};\\boldsymbol{\\mu}_x,\\boldsymbol{\\Sigma}_x)\\parallel\\mathcal{N}(\\boldsymbol{y};\\boldsymbol{\\mu}_y,\\boldsymbol{\\Sigma}_y))=\\\\\n\\frac{1}{2}\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_y|}{|\\boldsymbol{\\Sigma}_x|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_y^{-1}\\boldsymbol{\\Sigma}_x)+(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)^T\\boldsymbol{\\Sigma}_y^{-1}(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)\\right]\n$$</div>\n\n<p>我们可以计算出</p>\n<div>$$\n\\begin{align*}\n&KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)] \\\\\n&= \\frac12\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_q|}{|\\boldsymbol{\\Sigma}_q|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_q^{-1}\\boldsymbol{\\Sigma}_q)+(\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q)^T\\boldsymbol{\\Sigma}_q^{-1}(\\boldsymbol{\\mu}_q-\\boldsymbol{\\mu}_q)\\right]\\\\\n&=\\frac12\\left[0-d+d+\\frac1{\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\right]\\\\\n&=\\frac1{2\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\\\\n\\end{align*}\n$$</div>\n\n<p>这也很符合直觉，毕竟高斯无非就是由均值和方差决定的，方差本来就是一样的，唯一剩下的不就是拟合均值了吗？高斯分布下拟合均值，那不就是用 MLE loss 吗？</p>\n<p>现在我们终于找到了 DDPM 的损失函数：</p>\n<div>$$\n\\begin{align*}\n&\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[||\\mu_\\theta(x_t)-\\mu_q(x_t)||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim }[||\\mu_\\theta(x_t)-\\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\mu_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n\\end{align*}\n$$</div>\n\n<p>其中 $c_1, c_2$ 是关于 $\\lbrace\\alpha_t\\rbrace$ 的表达式，与 $\\theta$ 无关。由于模型 $\\mu_\\theta$ 输入里面就包含 $x_t$，那么 $c_1x_t$ 项就不用让模型预测了，我们可以直接令</p>\n<div>$$\n\\mu_\\theta(x_t) = c_1x_t + c_2x_\\theta(x_t)\n$$</div>\n\n<p>则优化目标为</p>\n<div>$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||c_1x_t + c_2x_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\n\\end{align*}\n$$</div>\n\n<p>这下坏了，这不就是让我们的模型直接预测出原图 $x_0$ 吗！不要着急，我们继续分析 $x_0$。由 $x_t$ 和 $x_0$ 的关系可知</p>\n<div>$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\Leftrightarrow x_0 = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$</div>\n\n<p>这下 $\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t$ 对于 $x_\\theta(x_t)$ 来说又是已知项，于是我们进一步令</p>\n<div>$$\nx_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t)\n$$</div>\n\n<p>优化目标进一步化简：</p>\n<div>$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t) - \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t + \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\varepsilon_\\theta(x_t) -\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(\\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n\\end{align*}\n$$</div>\n\n<p>神奇的事情发生了！我们的模型现在唯一需要预测的就是这个噪声项 $\\varepsilon$ 长什么样。也就是说，现在的扩散模型 $\\varepsilon_\\theta$，输入是 $t$ 时刻含噪图像 $x_t$，要预测的是其含有的噪声 $\\varepsilon$！至此，我们已经推出了 DDPM 的训练目标。</p>\n<p>刚才我们推导的某一步里指出，我们的损失函数等价于预测原图 $x_0$。的确如此！事实上预测原图和预测噪声在原理上是等价的，它们只不过相差一些系数。但是也有论文指出，预测原图和预测噪声相比，predicting the noise puts more weight on lower noise levels，在 t 较小的情况上花费更多算力进行训练。</p>\n<p>另外，实际的 DDPM 会将时间 $t$ 也作为一个条件输入给模型 $\\varepsilon_\\theta$。我们实际上训练的是：</p>\n<div>$$\n\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$</div>\n\n<p>别忘了，这只是 ELBO 三项中的一项，denoise matching term。我们知道，prior matching 项与参数无关不用训练；还剩下一项 reconstruction，也就是 $E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 这一项需要计算。这一项其实也是类似的，我们假设模型预测高斯分布，均值为 $\\mu_\\theta(x_1)$，方差为 $(1-\\alpha_1)I$ 与 $x_1$ 一致：</p>\n<div>$$\n\\begin{align*}\n&E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log (\\frac{1}{\\sqrt{2\\pi(1 - \\alpha_1)}})\\exp [-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}]]\\\\\n&=E_{\\varepsilon\\sim N}[-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}] + C\\\\\n\\end{align*}\n$$</div>\n\n<p>因此，优化它为最大值等价于优化</p>\n<div>$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n\\end{align*}\n$$</div>\n\n<p>我们又故技重施，预测它的噪声：</p>\n<div>$$\n\\mu_\\theta(x_1) = \\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1)\\\\\n$$</div>\n\n<div>$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(x_1) - \\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon) - \\varepsilon||_2^2]\\\\\n\\end{align*}\n$$</div>\n\n<p>可以看出，这和第三项的优化目标是一样的！只不过此时 $t &#x3D; 1$，而之前 $t$ 的范围是 $[2, T]$。</p>\n<p>因此，我们把上面两种情况综合起来就得到了最终的训练目标：</p>\n<div>$$\n\\argmin_\\theta E_{t\\sim U(1,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$</div>\n\n<p>你问我为什么 t &#x3D; 1 的概率与其他的情况相同？我也不太清楚。按照 ELBO 的要求这两种情况的系数或许是不一样的，但是我们这里当它是一样的了。这个可能会导致一些 bias 的引入？不知道有没有论文讨论这个。</p>\n<p>至此，我们终于搞定了 DDPM 的训练过程！</p>\n<h3 id=\"DDPM-的推理过程\"><a href=\"#DDPM-的推理过程\" class=\"headerlink\" title=\"DDPM 的推理过程\"></a>DDPM 的推理过程</h3><p>推理过程就是给定时间 $t$ 和该时刻的图像 $x_{t}$，输出上一时刻的图像 $x_{t-1}$（本质上是去掉上一时刻的噪声）。推完上述的训练过程，我想推理公式已经呼之欲出了：</p>\n<div>$$\nx_0 \\approx x_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)\\\\\nx_{t-1} \\sim q(x_{t-1}|x_t, x_0) = \\mathcal N (\\mu_q(x_t), \\Sigma_q)\\\\\n（条件：t\\ge2）\n$$</div>\n\n<p>由此可以推出</p>\n<div>$$\n\\begin{align*}\nx_{t-1} &= \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t} + \\sqrt{\\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}}\\varepsilon\\\\\n&\\approx \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)(\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t))}{1-\\bar\\alpha_t} + \\sigma_t \\varepsilon\\\\\n&=\\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{(1-\\alpha_t)}{\\sqrt{1 - \\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)) + \\sigma_t \\varepsilon\n（条件：t\\ge2）\n\\end{align*}\n$$</div>\n\n<p>这就是推理过程的公式。其中 $\\varepsilon$ 为正态分布。</p>\n<p>不过要注意，这个噪声项 $\\varepsilon$ 的来源，可不是来自扩散模型 $\\varepsilon_\\theta(x_t, t)$ 的随机性，而是来自 $q(x_t|x_{t-1},x_0)$。$\\varepsilon_\\theta(x_t, t)$ 代表了从 $x_t$ 到 $x_0$ 相差多少噪声，这个噪声在给定 $x_t$ 和 $x_0$ 的情况下是固定的，它是一个确定值。虽然此时 $x_t$ 和 $x_0$ 都是确定的，但是从 $x_t$ 到 $x_{t-1}$ 的这个过程引入了新的高斯噪声，你即使知道 $x_t$ 和 $x_0$，仍然无法确定 $x_{t-1}$ 长什么样！这个随机项 $\\varepsilon$ 代表的就是（已知 $x_0$ 的情况下）从 $x_t$ 到 $x_{t-1}$ 的不确定性。</p>\n<p>上面的公式只适用于 $t\\ge2$ 的情况。很显然，$t&#x3D;1$ 的时候你也没有 $q(x_{t-1}|x_{t}, x_0)$ 可用啊。请循其本，$t&#x3D;1$ 的情况实际上来自于 ELBO 的 reconstruct term，需要用那里的公式解释。所以 $t &#x3D; 1$ 的情况下，模型就直接输出最终图像就行了，不需要添加噪声项（因为噪声来自于 $q(x_{t-1}|x_{t}, x_0)$！）：</p>\n<div>$$\nx_0 \\approx x_\\theta(x_1) = \\frac{1}{\\sqrt{\\alpha_1}} x_1 - \\frac{\\sqrt{1 - \\alpha_1}}{\\sqrt{\\alpha_1}}\\varepsilon_\\theta(x_1, 1)\\\\\n$$</div>\n\n<p>不过我寻思一般 $T&#x3D;1000$，最后一步恐怕噪声含量已经很低了。</p>\n<h2 id=\"其他问题\"><a href=\"#其他问题\" class=\"headerlink\" title=\"其他问题\"></a>其他问题</h2><p>推理的时候，为什么不直接取概率最大的情况作为 $x_{t-1}$ 的值，也就直接让 $\\varepsilon &#x3D; 0$？要是这么设定，我们之前的推导就白做了，要知道，我们之前全部都是假设每一步去噪都符合高斯分布，你直接让噪声等于零，其实等价于让每一步高斯的方差 $\\sigma_t^2$ 等于 0，直觉上好像退化成 auto encoder 了。在这种情况下，上面的所有公式肯定要发生变化。这个有空可以分析一下，如果我们让所有的 $\\sigma_t$ 都等于 0，会发生什么。</p>\n<p>第二个问题，为什么 VAE 输出的时候不需要添加这个噪声项？很显然，VAE 不存在 denoise matching term，它只有 reconstruct term，这一项是和 $t &#x3D; 1$ 的扩散模型一样，不需要加噪声的。</p>\n<p>最后一个问题。既然图像 $x_0$ 是从噪声 $x_T$ 变过来的，明明每一步都是减去一个噪声，为什么减着减着就变成了一个有规律的图像？到底从哪一步开始，噪声不再是噪声，而是突然变得有规律了？听起来像一个谷堆悖论。这个问题我还没有想清楚，不过我觉得扩散模型就是在构建 $x_T$ 到 $x_0$ 的一个映射，只是这个映射要迭代很多步而已，所以或许从一开始噪声 $x_T$ 就已经注定了会对应 $x_0$，并不是在中间某一步突变的。Flow Matching 方法能够直接用一条直线构建这种映射，也许会把这个问题展示得更加清楚。（当然，去噪过程是有一定随机性的，也许它一开始想走到图像 A，走着走着突然就往图像 B 去跑了，所以这个问题大概还有更好的解释吧。）</p>\n<p>（那么，什么是 Score Matching 呢？）</p>\n","site":{"data":{}},"excerpt":"","more":"<p>最近看了 lhy 的 Diffusion Model 教程，对于之前一直不理解的 Diffusion Model 的训练和推理过程终于获得了新的认识，还和 VAE，Flow-based 等方法构建起了统一的联系。这篇笔记作为对于 DDPM 论文公式推导的一个尝试。</p>\n<h2 id=\"图像生成任务的优化目标\"><a href=\"#图像生成任务的优化目标\" class=\"headerlink\" title=\"图像生成任务的优化目标\"></a>图像生成任务的优化目标</h2><p>一张图胜过千言万语，同样的一句话，可以生成无限的图像。因此，我们不能构建起从句子到图像的唯一映射。好在我们还有概率的工具：我们假设，所有的图像都是从某个概率分布中采样出来的，我们可以假设生图模型的提示词与图像的某个概率分布对应，生图模型的任务就是输入提示词，输出目标图像的概率分布，然后我们可以从图像的概率分布中采样出目标图像。</p>\n<p>然而，图像的概率分布异常复杂，仅凭人力无法给出其表达式，很难对其进行建模。于是，我们尝试从最简洁的高斯分布中采样，将高斯分布中的每一个向量对应于一张图片。现在，我们把复杂的概率分布变成了高斯分布，需要学习的只是（在给定提示词时）从向量到图片的映射。这就是 VAE(其实是 AE，VAE 更准确的说是生成一个概率分布) 的原理，刚刚提到的高斯分布的向量称为编码，把向量映射为图片的模型称为解码器（decoder）。而扩散模型某种意义上是多个 VAE decoder 的级联。</p>\n<p>（注意，接下来的推导同时适用于 VAE 和 Diffusion model）</p>\n<p>首先从高斯分布中采样一个向量 $z$，它通过生成模型，变成了一张图片 $x&#x3D;G_{\\theta}(z)$。我们可以采样很多的 $z$，不停地生成 $x$，那么生成模型的功能就是把一个 $z$ 所在空间的高斯分布重新塑形成了 $x$ 空间的图像分布。我们把重塑得到的这个图像分布记为 $P_{\\theta}$，任意一张图像 $x$ 在这个分布的生成概率为 $P_{\\theta}(x)$。以上的 $\\theta$ 为可以训练的参数。可以看出，分布 $P_{\\theta}$ 不是直接由模型产生的，$G_{\\theta}$才是模型，而是间接地从高斯分布和模型 $G_{\\theta}$ 推出来的。</p>\n<p>那么，为了能够生成逼真的图像，我们希望生成模型的分布 $P_{\\theta}$ 和训练数据的分布 $P_{data}$ 越相近越好，从训练数据集中选择若干真实图像 $x^1, x^2, \\dots, x^m \\sim P_{data}$，那么优化目标就是尽可能增加它们的生成概率（最大化似然，Maximum Likelihood）：</p>\n<div>$$\n\\theta^* = \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\n$$</div>\n\n<p>（注：要学习图像的分布，所需的数据量是巨大的，大约是 1B 量级的图片才足以训练现有的 diffusion model。）</p>\n<p>为什么上面这个优化目标能够使得 $P_{\\theta}$ 接近 $P_{data}$ 呢？通过一番公式推导，我们可以把优化目标变成下列形式：</p>\n<div>$$\n\\begin{align*}\n\\theta^* &= \\argmax_{\\theta} \\prod_{i=1}^mP_{\\theta}(x^i)\\\\\n&= \\argmax_{\\theta} \\sum_{i=1}^m\\log P_{\\theta}(x^i)\\\\\n&\\approx \\argmax_{\\theta} E_{x\\sim P_{data}}[\\log P_{\\theta}(x)]\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{\\theta}(x)\\mathrm dx - \\argmax_{\\theta} \\int_x P_{data}(x)\\log  P_{data}(x)\\mathrm dx\\\\\n&= \\argmax_{\\theta}  \\int_x P_{data}(x)\\frac{\\log  P_{\\theta}(x)\\mathrm dx}{\\log  P_{data}(x)\\mathrm dx}\\\\\n&= \\argmin_{\\theta} KL[P_{data}||P_{\\theta}]\n\\end{align*}\n$$</div>\n\n<p>可以看出，最大化似然其实和最小化 KL 散度等价。其中约等号那一步是利用蒙特卡洛采样。而 KL 散度的意义正是“度量分布 p 和分布 q 之间的距离”，这个值越小，则两个概率分布越接近。</p>\n<h2 id=\"VAE-的优化过程\"><a href=\"#VAE-的优化过程\" class=\"headerlink\" title=\"VAE 的优化过程\"></a>VAE 的优化过程</h2><p>接下来，我们优化一下 VAE。</p>\n<h3 id=\"假设为高斯分布\"><a href=\"#假设为高斯分布\" class=\"headerlink\" title=\"假设为高斯分布\"></a>假设为高斯分布</h3><p>具体而言，对于 VAE 来说：</p>\n<div>$$\nP_{\\theta}(x) = \\int_z P_{\\theta}(x|z)P(z)\\mathrm dz\n$$</div>\n\n<p>而 $P_{\\theta}(x|z)$ 就是“给定高斯向量 $z$ ，产生图像 $x$ 的概率”，这不就是我们的解码器 $G_\\theta$ 吗！遗憾的是，$G_{\\theta}$ 是一个确定性的映射，不是一个概率，如果非要认为它是一个概率的话，它会变成只有在某几个特定点概率为 1，其他点的概率为 0：</p>\n<div>$$\nP_\\theta(x|z) = \\begin{cases}\n1, G_\\theta(z) = x\\\\\n0, G_\\theta(z) \\neq x\n\\end{cases}\n$$</div>\n\n<p>这好像不太好，我们假定图像是一个连续空间，如果 $P_{\\theta}(x|z)$ 只在几个特定的离散点非 0 的话，那目标函数就变成一个难以优化的东西了！离散的东西怎么求导呢？为了克服这个困难，我们决定将解码器 $G_{\\theta}$ 从一个确定性映射换成一个概率分布，要不就假设他是高斯分布吧：</p>\n<div>$$\nx|z \\sim \\mathcal N (G_\\theta(z), \\sigma^2 I)\\\\\nP_\\theta (x|z) \\propto \\exp(-||G_\\theta(z) - x||_2^2/2\\sigma^2)\n$$</div>\n\n<p>可以看到解码器 $G_{\\theta}$ 输出的不再是“向量对应的图像”，而是“向量对应图像的高斯分布均值”。“假设图像是高斯分布”是个很糟糕的假设，它看起来跟事实完全不符，不过，至少这个高斯的概率表达式可以拿去求导。随着梯度下降的次数增多，$G_\\theta (z)$ 应该会和 $x$ 越来越接近。</p>\n<h3 id=\"求最大似然的下界\"><a href=\"#求最大似然的下界\" class=\"headerlink\" title=\"求最大似然的下界\"></a>求最大似然的下界</h3><p>我们回到最大似然形式的优化目标进行变形：</p>\n<div>$$\n\\log P_{\\theta}(x) = \\int_z q(z|x) \\log P_\\theta(x) \\mathrm dz\n$$</div>\n\n<p>（我们引入了一个 $q(z|x)$，这个东西可以是任何概率分布，上式始终成立）</p>\n<div>$$\n\\begin{align*}\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)q(z|x)}{q(z|x)P_{\\theta}(z|x)}\\mathrm dz\\\\\n&=\\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz + \\underline{\\int_z q(z|x) \\log \\frac{q(z|x)}{P_{\\theta}(z|x)}\\mathrm dz}_{这是 KL 散度，始终大于0}\\\\\n&\\ge \\int_z q(z|x) \\log \\frac{P_{\\theta}(z, x)}{q(z|x)}\\mathrm dz\\\\\n&= \\underline{E_{z\\sim q(z|x)}[\\log \\frac{P_{\\theta}(z, x)}{q(z|x)}]}_{VAE 的目标就是让这个取到最大值}\n\\end{align*}\n$$</div>\n\n<p>最后一行这个，就是目标的下界，是 VAE 最终的优化目标，如果我们能够把原始目标的下界变得最大，那么原始目标大概率也会尽可能地增大。这个下界其实就是 ELBO，保证了模型的最坏情况不会比下界更差。$q(z|x)$ 其实是一个编码器（把图像映射为向量），它输出的也是一个概率分布，不管这个编码器输出的概率分布长什么样，上面的公式都是成立的。VAE 有特殊的技巧来同时优化编码器和解码器（重参数化等等），不过这里就不多介绍了。我们还是来看看 Diffusion 吧。</p>\n<h2 id=\"DDPM-的优化过程\"><a href=\"#DDPM-的优化过程\" class=\"headerlink\" title=\"DDPM 的优化过程\"></a>DDPM 的优化过程</h2><p>Diffsion 的通俗理解应该很直观吧，如下图所示：</p>\n<p><img src=\"/../images/DDPM/1753424129654.png\" alt=\"1753424129654\"></p>\n<p>Diffusion 的本义是扩散，把一颗规则的方糖放到水里，它会逐渐溶解，糖分子扩散到溶液的每一处，最开始的方糖分子，分布是规则的，到了最后变成了完全无规律的分布，和完全随机分布没有区别。我们可以想想如何“溶解”图像，把图像和高斯信号不断地混合，每一步添加一点高斯噪声，图像就从最开始的规则分布 $x_0$ 变成了完全随机的高斯噪声 $x_T$。</p>\n<p>那么，反过来呢？随机从高斯分布中取出一个噪声 $x_T$，我们能否逆推出最开始的规则分布 $x_0$？这就是扩散模型所做的事情。扩散模型把 $x_T$ 一步一步去噪变成 $x_{T-1}, \\dots, x_{1}, x_0$，它每次接受 t 时刻带有噪声的图像 $x_t$，输出加噪之前的上一时刻图像 $x_{t-1}$。可以看出它和 VAE 其实有几分相似性，输入一个高斯向量，最终输出一张图像。实际上，我们可以把去噪过程的每一步都看作一次 VAE 解码，即 $z &#x3D; x_t$，$x &#x3D; x_{t-1}$，那么扩散模型实际上就是 T 个解码器被训练在了一个模型里面：</p>\n<div>$$\nP_{\\theta}(x_0) = \\int_{x_1:x_T} P(x_T)P_{\\theta}(x_{T-1}|x_T)\\dots P_{\\theta}(x_0|x_1)\\mathrm dx_1:x_T\n$$</div>\n\n<p>（注：还真有级联多个 VAE 的架构——HVAE. DDPM 可以看作它的一个特例，用加噪过程替代了编码器。）</p>\n<h3 id=\"推导最大似然的下界\"><a href=\"#推导最大似然的下界\" class=\"headerlink\" title=\"推导最大似然的下界\"></a>推导最大似然的下界</h3><p>依然是最大似然公式，扩散模型实际上就是 n 个 VAE 的级联：</p>\n<div>$$\n\\begin{align*}\n\\log P_{\\theta}(x_0) &= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log P_\\theta(x_0)\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta\n(x_0:x_T)q(x_1:x_T|x_0)}{q(x_1:x_T|x_0)P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T \\\\\n&+ \\underline{\\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{q(x_1:x_T|x_0)}{P_\\theta(x_1:x_T|x_0)}\\mathrm dx_1:x_T}_{KL 散度 \\ge 0}\\\\\n&\\ge \\int_{x_1:x_T}q(x_1:x_T|x_0)\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}\\mathrm dx_1:x_T\\\\\n&= \\underline{E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]}_{ELBO}\n\\end{align*}\n$$</div>\n\n<p>以上推导和 VAE 完全一样。这里的 $x_0$ 就是最终的图像，和 VAE 的 $x$ 一样。在 VAE 里这个 q 项是个编码器，要训练的。但是在 Diffusion 里面，这里的 $q(x_1:x_T|x_0)$ 含义是加噪过程，即输入图像，输出加噪后的图像，它无需训练，是已经定义好的：</p>\n<div>$$\nq(x_1:x_T|x_0) = q(x_T|x_{T-1})\\dots q(x_1|x_0)\n$$</div>\n\n<h3 id=\"从-ELBO-推导-DDPM-训练时的优化目标\"><a href=\"#从-ELBO-推导-DDPM-训练时的优化目标\" class=\"headerlink\" title=\"从 ELBO 推导 DDPM 训练时的优化目标\"></a>从 ELBO 推导 DDPM 训练时的优化目标</h3><p>现在问题来了，为什么训练过程的 loss 公式跟我们朴素的理解完全不一样呢？我们还是从上一部分计算出的 ELBO 入手来分析这个问题。</p>\n<p>公式推导来自 <a href=\"https://arxiv.org/abs/2208.11970\">Understanding Diffusion Models: A Unified Perspective</a>。本文从多种角度采用不同的理论分析 Variational Diffusion Model，可见 Diffusion Model 是一种在数学上多么优美的架构。在优化 ELBO 这一部分，作者做了两种不同的等价变形来推导优化公式，其中一种思路比较简单直接，但是不利于用作真实的算法优化过程；另一种则是我们接下来要介绍的。</p>\n<p>首先要注意到一个变形技巧：</p>\n<div>$$\nq(x_t|x_{t-1}) = q(x_t|x_{t-1}, x_0)\n$$</div>\n\n<p>这是很显然的，因为加噪过程的第 t 步只依赖于第 t-1 步，你把原始图像加进来作为条件不会对概率造成任何影响。然而这个神秘操作却对我们接下来的计算至关重要：</p>\n<div>$$\n\\begin{align*}\n&E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log \\frac{P_\\theta(x_0:x_T)}{q(x_1:x_T|x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^Tq(x_t|x_{t-1})}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{q(x_t|x_{t-1}, x_0)}_{注意这里用到了神秘技巧！}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\prod_{t=2}^T\\underline{\\frac{q(x_{t-1}|x_t, x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{只是普通的贝叶斯}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)\\cdot \\underline{\\prod_{t=2}^T\\frac{q(x_t|x_0)}{q(x_{t-1}|x_0)}}_{这里可以错位相消}}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_1|x_0)\\cdot\\frac{q(x_T|x_0)}{q(x_1|x_0)}\\cdot \\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log\\frac{P(x_T)P_{\\theta}(x_0|x_1)\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{q(x_T|x_0)\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1:x_T \\sim q(x_1:x_T|x_0)}[\\log P_{\\theta}(x_0|x_1) + \\log\\frac{P(x_T)}{q(x_T|x_0)} + \\log\\frac{\\prod_{t=2}^T P_{\\theta}(x_{t-1}|x_t)}{\\prod_{t=2}^Tq(x_{t-1}|x_t, x_0)}]\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] + E_{x_T\\sim q(x_T|x_0)}[\\log\\frac{P(x_T)}{q(x_T|x_0)}] + \\underline{\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]}_{这一项的化简写在后面了}\\\\\n&=E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)] - KL[{q(x_T|x_0)}||P(x_T)] -\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n\\end{align*}\n$$</div>\n\n<p>其中，第三项的化简：</p>\n<div>$$\n\\begin{align*}\n&\\sum_{t=2}^TE_{x_{t-1},x_t \\sim q(x_{t-1},x_t|x_0)}[\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}]\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1},x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_{t-1}, x_t}q(x_{t-1}|x_t,x_0)q(x_t|x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)\\int_{x_{t-1}}q(x_{t-1}|x_t,x_0)\\log\\frac{P_{\\theta}(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\mathrm dx_{t-1}\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T\\int_{x_t}q(x_t|x_0)KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]\\mathrm dx_t\\\\\n&=-\\sum_{t=2}^T E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\n\\end{align*}\n$$</div>\n\n<p>现在，我们得到了三项优化目标，它们的含义如下：</p>\n<ol>\n<li>$E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 为 reconstruction term，它表示的是最后一步重建，即从 $x_1$ 恢复原图 $x_0$ 的过程，可类比于 VAE 中的从高斯向量 z 恢复原图 x；</li>\n<li>$KL[{q(x_T|x_0)}||P(x_T)]$ 为 prior matching term，这是所有 VAE 类型的模型共有的。在这里，$P(x_T)$ 是一个高斯分布（想想，这就是扩散模型推理时输入的那个随机高斯向量），而 $q(x_T|x_0)$ 为加噪过程，图像加 T 步噪声后也近似为高斯，所以这一项实际上为 0。这里没有需要训练的参数，可以忽略；</li>\n<li>$E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$ 就是 denoising matching term，这里是什么 match 什么呢，是扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 去 Match 一个训练集里的去噪过程 $q(x_{t-1}|x_t, x_0)$。$q$ 原本是来自加噪过程的概率分布，但是我们已经通过贝叶斯把它转换成了去噪过程的概率，它现在作为一个 ground truth 信号去监督模型学习，含义是“已知了真实图像 $x_0$ 的情况下，去噪过程应该是什么样”。我们训练的模型在不知道真实图像的前提下学习这个由 $q$ 指导的去噪过程，它就能逐渐掌握如何生成一个真实图像了。</li>\n</ol>\n<h3 id=\"真正的-DDPM-训练\"><a href=\"#真正的-DDPM-训练\" class=\"headerlink\" title=\"真正的 DDPM 训练\"></a>真正的 DDPM 训练</h3><p>DDPM 的优化目标我们已经在上一部分推出完毕，但是和真正的公式好像还是有一些 gap？其实很简单，我们的公式里面把加噪过程的噪声分布写成了 $q$，但是实际上我们早就知道，这个 $q$ 其实代表的是一个高斯分布，那我们就可以把高斯分布的实际表达式代进去算了。在计算之前，我们再来详细分析一下“加噪过程”的细节。</p>\n<h4 id=\"加噪过程的细节\"><a href=\"#加噪过程的细节\" class=\"headerlink\" title=\"加噪过程的细节\"></a>加噪过程的细节</h4><p><img src=\"/../images/DDPM/1753442174434.png\" alt=\"1753442174434\"></p>\n<p>所谓的“加噪”运算，其实是把输入信号和标准高斯噪声按照某种比例混合：</p>\n<div>$$\nx_t = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$</div>\n\n<p>我们可以人为规定一组常数 $\\lbrace\\alpha_1, \\alpha_2, \\dots\\alpha_T\\rbrace$，表示不同时刻输入信号 $x_{t-1}$ 的强度。$\\alpha$ 越大，则输出的信号和输入信号越相似，越小，则输出信号越接近噪声。</p>\n<p>为什么系数要有根号？容易观察到，等号右侧的两个系数的平方之和等于 1。这是为了保证混合前后信号的方差保持不变。不难推导，两个方差为 1 的高斯信号按照上述 $\\alpha$ 的比例混合以后还是一个方差为 1 的高斯信号。</p>\n<p>然而，训练时我们不是一步步地从 $x_0$ 加噪一直到 $x_T$，这样实在太慢了！好在高斯信号是线性的东西，两个高斯加在一起还是高斯，我们就可以直接推导出 $x_t$ 和 $x_0$ 的关系：</p>\n<div>$$\n\\begin{align*}\nx_t &= \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t}(\\sqrt{\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t-1}}\\varepsilon_{t-1}) + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} +  \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1}\\\\\n&(设 \\varepsilon^*_{t-2} = \\sqrt{\\alpha_t(1-\\alpha_{t-1})}\\varepsilon_{t-2} + \\sqrt{1-\\alpha_t}\\varepsilon_{t-1} \\sim \\mathcal N(0, I))\\\\\n&= {\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_t(1-\\alpha_{t-1}) + (1-\\alpha_t)}\\varepsilon^*_{t-2}}\\\\\n&= \\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_t\\alpha_{t-1}}\\varepsilon_{t-2}^*\\\\\n&=\\dots\\\\\n&=\\sqrt{\\alpha_t\\alpha_{t-1}\\dots\\alpha_1}x_0 + \\sqrt{1 - \\alpha_t\\alpha_{t-1}\\dots\\alpha_1}\\varepsilon^*_{0}\\\\\n&(\\varepsilon^*_0 \\sim \\mathcal N(0, I))\n\\end{align*}\n$$</div>\n\n<p>我们记 $\\bar{\\alpha_t} &#x3D; \\alpha_t\\alpha_{t-1}\\dots\\alpha_1$，则上式可以写为</p>\n<div>$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$</div>\n\n<h4 id=\"计算-DDPM-的优化目标\"><a href=\"#计算-DDPM-的优化目标\" class=\"headerlink\" title=\"计算 DDPM 的优化目标\"></a>计算 DDPM 的优化目标</h4><p>我们先来计算 denoising matching term $E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]$。首先，根据上面推导出的 $x_t$ 与 $x_0$ 的关系，$q(x_t|x_0)$ 是均值为 $\\sqrt{\\bar\\alpha_t}x_{0}$ ，方差为 $({1 - \\bar\\alpha_t})I$ 的高斯分布。</p>\n<p>然而，去噪监督信号 $q(x_{t-1}|x_t, x_0)$ 看起来不太好算。我们可以通过贝叶斯公式把它转换为加噪过程：</p>\n<div>$$\n\\begin{align*}\nq(x_{t-1}|x_t, x_0)&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1}, x_0)}{q(x_{t}|x_0)}\\\\\n&=\\frac{q(x_{t-1}|x_0)q(x_{t}|x_{t-1})}{q(x_{t}|x_0)}\\\\\n\\end{align*}\n$$</div>\n\n<p>这里的分子和分母的项全部都是高斯分布，我们终于可以计算了，总而言之，计算结果还是一个高斯分布，均值为</p>\n<div>$$\n\\mu_q(x_t) = \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}\n$$</div>\n\n<p>方差为</p>\n<div>$$\n\\Sigma_q = \\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}I\n$$</div>\n\n<p>扩散模型 $P_{\\theta}(x_{t-1}|x_t)$ 的目标是预测噪声，那么把它建模为高斯分布就很显然了。我们假设它的均值为 $\\mu_\\theta(x_t)$ 是一个可学习的量（注意到这和我们在 VAE 里面假设 $G_\\theta(x)$ 的输出为高斯分布一致），方差和监督信号 $q(x_{t-1}|x_t, x_0)$ 的方差一样（已知）。</p>\n<p>根据 KL 散度公式</p>\n<div>$$\nD_{\\mathrm{KL}}(\\mathcal{N}(\\boldsymbol{x};\\boldsymbol{\\mu}_x,\\boldsymbol{\\Sigma}_x)\\parallel\\mathcal{N}(\\boldsymbol{y};\\boldsymbol{\\mu}_y,\\boldsymbol{\\Sigma}_y))=\\\\\n\\frac{1}{2}\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_y|}{|\\boldsymbol{\\Sigma}_x|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_y^{-1}\\boldsymbol{\\Sigma}_x)+(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)^T\\boldsymbol{\\Sigma}_y^{-1}(\\boldsymbol{\\mu}_y-\\boldsymbol{\\mu}_x)\\right]\n$$</div>\n\n<p>我们可以计算出</p>\n<div>$$\n\\begin{align*}\n&KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)] \\\\\n&= \\frac12\\left[\\log\\frac{|\\boldsymbol{\\Sigma}_q|}{|\\boldsymbol{\\Sigma}_q|}-d+\\mathrm{tr}(\\boldsymbol{\\Sigma}_q^{-1}\\boldsymbol{\\Sigma}_q)+(\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q)^T\\boldsymbol{\\Sigma}_q^{-1}(\\boldsymbol{\\mu}_q-\\boldsymbol{\\mu}_q)\\right]\\\\\n&=\\frac12\\left[0-d+d+\\frac1{\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\right]\\\\\n&=\\frac1{2\\sigma_q^2}||\\boldsymbol{\\mu}_\\theta-\\boldsymbol{\\mu}_q||^2_2\\\\\n\\end{align*}\n$$</div>\n\n<p>这也很符合直觉，毕竟高斯无非就是由均值和方差决定的，方差本来就是一样的，唯一剩下的不就是拟合均值了吗？高斯分布下拟合均值，那不就是用 MLE loss 吗？</p>\n<p>现在我们终于找到了 DDPM 的损失函数：</p>\n<div>$$\n\\begin{align*}\n&\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[KL[q(x_{t-1}|x_t, x_0)||P_{\\theta}(x_{t-1}|x_t)]]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim q(x_t|x_0)}[||\\mu_\\theta(x_t)-\\mu_q(x_t)||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim }[||\\mu_\\theta(x_t)-\\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\mu_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n\\end{align*}\n$$</div>\n\n<p>其中 $c_1, c_2$ 是关于 $\\lbrace\\alpha_t\\rbrace$ 的表达式，与 $\\theta$ 无关。由于模型 $\\mu_\\theta$ 输入里面就包含 $x_t$，那么 $c_1x_t$ 项就不用让模型预测了，我们可以直接令</p>\n<div>$$\n\\mu_\\theta(x_t) = c_1x_t + c_2x_\\theta(x_t)\n$$</div>\n\n<p>则优化目标为</p>\n<div>$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||c_1x_t + c_2x_\\theta(x_t)-c_1x_t - c_2x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\n\\end{align*}\n$$</div>\n\n<p>这下坏了，这不就是让我们的模型直接预测出原图 $x_0$ 吗！不要着急，我们继续分析 $x_0$。由 $x_t$ 和 $x_0$ 的关系可知</p>\n<div>$$\nx_t = \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\Leftrightarrow x_0 = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\n$$</div>\n\n<p>这下 $\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t$ 对于 $x_\\theta(x_t)$ 来说又是已知项，于是我们进一步令</p>\n<div>$$\nx_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t)\n$$</div>\n\n<p>优化目标进一步化简：</p>\n<div>$$\n\\begin{align*}\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||x_\\theta(x_t) - x_0||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t) - \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t + \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{x_t\\sim \\mathcal N(\\sqrt{\\bar\\alpha_t}x_{0}, ({1 - \\bar\\alpha_t})I)}[||\\varepsilon_\\theta(x_t) -\\varepsilon||^2_2]\\\\\n&=\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(\\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n\\end{align*}\n$$</div>\n\n<p>神奇的事情发生了！我们的模型现在唯一需要预测的就是这个噪声项 $\\varepsilon$ 长什么样。也就是说，现在的扩散模型 $\\varepsilon_\\theta$，输入是 $t$ 时刻含噪图像 $x_t$，要预测的是其含有的噪声 $\\varepsilon$！至此，我们已经推出了 DDPM 的训练目标。</p>\n<p>刚才我们推导的某一步里指出，我们的损失函数等价于预测原图 $x_0$。的确如此！事实上预测原图和预测噪声在原理上是等价的，它们只不过相差一些系数。但是也有论文指出，预测原图和预测噪声相比，predicting the noise puts more weight on lower noise levels，在 t 较小的情况上花费更多算力进行训练。</p>\n<p>另外，实际的 DDPM 会将时间 $t$ 也作为一个条件输入给模型 $\\varepsilon_\\theta$。我们实际上训练的是：</p>\n<div>$$\n\\argmin_\\theta E_{t\\sim U(2,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$</div>\n\n<p>别忘了，这只是 ELBO 三项中的一项，denoise matching term。我们知道，prior matching 项与参数无关不用训练；还剩下一项 reconstruction，也就是 $E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]$ 这一项需要计算。这一项其实也是类似的，我们假设模型预测高斯分布，均值为 $\\mu_\\theta(x_1)$，方差为 $(1-\\alpha_1)I$ 与 $x_1$ 一致：</p>\n<div>$$\n\\begin{align*}\n&E_{x_1\\sim q(x_1|x_0)}[\\log P_\\theta(x_0|x_1)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log P_\\theta(x_0|\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)]\\\\\n&=E_{\\varepsilon\\sim N}[\\log (\\frac{1}{\\sqrt{2\\pi(1 - \\alpha_1)}})\\exp [-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}]]\\\\\n&=E_{\\varepsilon\\sim N}[-\\frac{||\\mu_\\theta(x_1) - (\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon)||_2^2}{2({1 - \\alpha_1})}] + C\\\\\n\\end{align*}\n$$</div>\n\n<p>因此，优化它为最大值等价于优化</p>\n<div>$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n\\end{align*}\n$$</div>\n\n<p>我们又故技重施，预测它的噪声：</p>\n<div>$$\n\\mu_\\theta(x_1) = \\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1)\\\\\n$$</div>\n\n<div>$$\n\\begin{align*}\n&\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\mu_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon_\\theta(x_1) - \\sqrt\\alpha_1x_0-\\sqrt{1 - \\alpha_1}\\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(x_1) - \\varepsilon||_2^2]\\\\\n&=\\argmin_\\theta E_{\\varepsilon\\sim N}[||\\varepsilon_\\theta(\\sqrt\\alpha_1x_0+\\sqrt{1 - \\alpha_1}\\varepsilon) - \\varepsilon||_2^2]\\\\\n\\end{align*}\n$$</div>\n\n<p>可以看出，这和第三项的优化目标是一样的！只不过此时 $t &#x3D; 1$，而之前 $t$ 的范围是 $[2, T]$。</p>\n<p>因此，我们把上面两种情况综合起来就得到了最终的训练目标：</p>\n<div>$$\n\\argmin_\\theta E_{t\\sim U(1,T)} E_{\\varepsilon\\sim \\mathcal N(0, I)}[||\\varepsilon_\\theta(t, \\sqrt{\\bar\\alpha_t} x_{0} + \\sqrt{1 - \\bar\\alpha_t}\\varepsilon) -\\varepsilon||^2_2]\\\\\n$$</div>\n\n<p>你问我为什么 t &#x3D; 1 的概率与其他的情况相同？我也不太清楚。按照 ELBO 的要求这两种情况的系数或许是不一样的，但是我们这里当它是一样的了。这个可能会导致一些 bias 的引入？不知道有没有论文讨论这个。</p>\n<p>至此，我们终于搞定了 DDPM 的训练过程！</p>\n<h3 id=\"DDPM-的推理过程\"><a href=\"#DDPM-的推理过程\" class=\"headerlink\" title=\"DDPM 的推理过程\"></a>DDPM 的推理过程</h3><p>推理过程就是给定时间 $t$ 和该时刻的图像 $x_{t}$，输出上一时刻的图像 $x_{t-1}$（本质上是去掉上一时刻的噪声）。推完上述的训练过程，我想推理公式已经呼之欲出了：</p>\n<div>$$\nx_0 \\approx x_\\theta(x_t) = \\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)\\\\\nx_{t-1} \\sim q(x_{t-1}|x_t, x_0) = \\mathcal N (\\mu_q(x_t), \\Sigma_q)\\\\\n（条件：t\\ge2）\n$$</div>\n\n<p>由此可以推出</p>\n<div>$$\n\\begin{align*}\nx_{t-1} &= \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t} + \\sqrt{\\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}}\\varepsilon\\\\\n&\\approx \\frac{\\sqrt\\alpha_t (1 - \\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)(\\frac{1}{\\sqrt{\\bar\\alpha_t}} x_t - \\frac{\\sqrt{1 - \\bar\\alpha_t}}{\\sqrt{\\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t))}{1-\\bar\\alpha_t} + \\sigma_t \\varepsilon\\\\\n&=\\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{(1-\\alpha_t)}{\\sqrt{1 - \\bar\\alpha_t}}\\varepsilon_\\theta(x_t, t)) + \\sigma_t \\varepsilon\n（条件：t\\ge2）\n\\end{align*}\n$$</div>\n\n<p>这就是推理过程的公式。其中 $\\varepsilon$ 为正态分布。</p>\n<p>不过要注意，这个噪声项 $\\varepsilon$ 的来源，可不是来自扩散模型 $\\varepsilon_\\theta(x_t, t)$ 的随机性，而是来自 $q(x_t|x_{t-1},x_0)$。$\\varepsilon_\\theta(x_t, t)$ 代表了从 $x_t$ 到 $x_0$ 相差多少噪声，这个噪声在给定 $x_t$ 和 $x_0$ 的情况下是固定的，它是一个确定值。虽然此时 $x_t$ 和 $x_0$ 都是确定的，但是从 $x_t$ 到 $x_{t-1}$ 的这个过程引入了新的高斯噪声，你即使知道 $x_t$ 和 $x_0$，仍然无法确定 $x_{t-1}$ 长什么样！这个随机项 $\\varepsilon$ 代表的就是（已知 $x_0$ 的情况下）从 $x_t$ 到 $x_{t-1}$ 的不确定性。</p>\n<p>上面的公式只适用于 $t\\ge2$ 的情况。很显然，$t&#x3D;1$ 的时候你也没有 $q(x_{t-1}|x_{t}, x_0)$ 可用啊。请循其本，$t&#x3D;1$ 的情况实际上来自于 ELBO 的 reconstruct term，需要用那里的公式解释。所以 $t &#x3D; 1$ 的情况下，模型就直接输出最终图像就行了，不需要添加噪声项（因为噪声来自于 $q(x_{t-1}|x_{t}, x_0)$！）：</p>\n<div>$$\nx_0 \\approx x_\\theta(x_1) = \\frac{1}{\\sqrt{\\alpha_1}} x_1 - \\frac{\\sqrt{1 - \\alpha_1}}{\\sqrt{\\alpha_1}}\\varepsilon_\\theta(x_1, 1)\\\\\n$$</div>\n\n<p>不过我寻思一般 $T&#x3D;1000$，最后一步恐怕噪声含量已经很低了。</p>\n<h2 id=\"其他问题\"><a href=\"#其他问题\" class=\"headerlink\" title=\"其他问题\"></a>其他问题</h2><p>推理的时候，为什么不直接取概率最大的情况作为 $x_{t-1}$ 的值，也就直接让 $\\varepsilon &#x3D; 0$？要是这么设定，我们之前的推导就白做了，要知道，我们之前全部都是假设每一步去噪都符合高斯分布，你直接让噪声等于零，其实等价于让每一步高斯的方差 $\\sigma_t^2$ 等于 0，直觉上好像退化成 auto encoder 了。在这种情况下，上面的所有公式肯定要发生变化。这个有空可以分析一下，如果我们让所有的 $\\sigma_t$ 都等于 0，会发生什么。</p>\n<p>第二个问题，为什么 VAE 输出的时候不需要添加这个噪声项？很显然，VAE 不存在 denoise matching term，它只有 reconstruct term，这一项是和 $t &#x3D; 1$ 的扩散模型一样，不需要加噪声的。</p>\n<p>最后一个问题。既然图像 $x_0$ 是从噪声 $x_T$ 变过来的，明明每一步都是减去一个噪声，为什么减着减着就变成了一个有规律的图像？到底从哪一步开始，噪声不再是噪声，而是突然变得有规律了？听起来像一个谷堆悖论。这个问题我还没有想清楚，不过我觉得扩散模型就是在构建 $x_T$ 到 $x_0$ 的一个映射，只是这个映射要迭代很多步而已，所以或许从一开始噪声 $x_T$ 就已经注定了会对应 $x_0$，并不是在中间某一步突变的。Flow Matching 方法能够直接用一条直线构建这种映射，也许会把这个问题展示得更加清楚。（当然，去噪过程是有一定随机性的，也许它一开始想走到图像 A，走着走着突然就往图像 B 去跑了，所以这个问题大概还有更好的解释吧。）</p>\n<p>（那么，什么是 Score Matching 呢？）</p>\n"},{"title":"扩散模型（二）DDIM 学习","katex":true,"date":"2025-08-10T12:10:31.000Z","_content":"\n还记得我们在 DDPM 学习的最后讨论了“采样时为什么需要加入高斯噪声”，当时我们提到这是由 DDPM 扩散过程的定义决定的，如果不加则相当于令噪声项的方差等于 0，在这种情况下所有的公式都要重写。那么，要是令噪声的方差为 0 到底能不能行呢？凑巧的是，DDIM 就是这么做的。它重新定义了 DDPM 的扩散过程（不是一步一步加噪声，而是直接给原图像加不同级别的噪声），从而使得噪声项的方差变成了一个可调的参数！实验发现让这个可调的方差等于 0 的时候效果反而是最好的，速度也比 DDPM 更快。并且，当方差等于 0 的时候，图像扩散过程实际上可以表示为一个常微分方程，其中扩散模型预测的是噪声图像向原始图像移动的“速度”矢量，图像就是在这个速度的牵引下从一个噪声变成了有意义的图像。\n\n本文主要参考自苏剑林老师的博客：[生成扩散模型漫谈（四）：DDIM = 高观点DDPM](https://spaces.ac.cn/archives/9181)。\n\n## 背景设置\n\nDDPM 里面对于扩散过程的约束，是给定 $x_{t-1}$ 输出 $x_t$，即 $x_t$ 与 $x_{t-1}$ 的关系 $p(x_t|x_{t-1})$：\n\n$$\nx_t = \\alpha_tx_{t-1} + \\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\alpha_t^2 + \\beta_t^2 = 1\n$$\n\n然而，在 DDPM 的训练过程中，我们并没有用到这个公式一步步生成加噪图像。我们直接给原图 $x_0$ 混合一个高斯噪声一步到位得到 $x_t$，这样速度更快。这是等价的，上述方程不断迭代就得到了 $x_t$ 与 $x_0$ 的关系 $p(x_t|x_0)$：\n\n$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\bar\\alpha_t = \\alpha_t\\alpha_{t-1}\\dots\\alpha_0\n$$\n\n推理过程，我们想从 $x_t$ 还原出上一步 $x_{t-1}$，但是 $p(x_{t-1}|x_{t})$ 求不出来，用 $p(x_{t-1}|x_t,x_0)$ 估计它：\n\n$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0)\n$$\n\n训练过程，模型学习的是直接从 $x_t$ 预测 $x_0$（或者其噪声），跟扩散过程的定义 $p(x_t|x_{t-1})$ 没有任何关系！然而推理过程却需要一步步反推扩散过程得到结果，凭什么训练和推理过程不一致呢？\n\n对于这个问题，DDIM 可能会给我们一些启发。它做了一件疯狂的事情：推理可以扔掉扩散过程，让训练和推理过程更一致，不仅速度快，而且效果更好。\n\n现在，最基本的关系不再是 $x_t$ 与 $x_{t-1}$ 的关系，而是 $x_{t}$ 与 $x_{0}$ 的关系。为此，我们要把 $\\bar\\alpha_t$ 和 $\\bar\\beta_t$ 作为最基本的参数，而 $\\alpha_t$ 和 $\\beta_t$ 不再重要：\n\n$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\alpha_t = \\frac{\\bar\\alpha_t}{\\bar\\alpha_{t-1}}, \\beta_t = \\sqrt{1 - \\alpha_t^2}\n$$\n\n$x_1, x_2, \\dots, x_t$ 不再是一条马尔科夫链，而是相互独立的加噪过程，随着 $t$ 的增大，噪声的强度越来越大。\n\n## 推理过程\n\nDDIM 并不改变训练过程，它只是加速了推理过程。推理过程中，我们仍然需要从 $x_t$ 还原出“上一步” $x_{t-1}$，即计算 $p(x_{t-1}|x_t)$，根据贝叶斯公式：\n\n$$\np(x_{t-1}|x_t) = \\frac{p(x_t|x_{t-1})p(x_{t-1})}{p(x_t)}\n$$\n\n和 DDPM 一样，上面这个 $p(x_{t-1}|x_{t})$ 求不出来，改成用 $p(x_{t-1}|x_t,x_0)$ 估计它：\n\n$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0) = \\frac{p(x_t|x_{t-1})p(x_{t-1}|x_0)}{p(x_t|x_0)}\n$$\n\n但是，DDPM 里面我们是知道 $p(x_t|x_{t-1})$ 就是扩散过程，表达式是已知的，现在我们把它扔掉，左边这个概率就算不出来了吧？\n\n实则不然，把 $p(x_t|x_{t-1})$ 扔掉之后，我们反而更加自由了，直接设\n\n$$\np(x_{t-1}|x_t,x_0) = \\mathcal N(x_{t-1};\\kappa_tx_t + \\lambda_tx_0, \\sigma^2_tI)\n$$\n\n是否感觉非常奇怪？DDPM 里面，这三个待定系数 $\\kappa, \\lambda, \\sigma$ 是可以用贝叶斯公式全部求出来的。然而因为扔掉了 $p(x_t|x_{t-1})$ 的表达式，实际上会多出来一个可变参数。让我们看看：\n\n$$\n\\begin{align*}\nx_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_0 \\\\\n&= \\kappa_t(\\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon_1) + \\lambda_tx_0 + \\sigma_t\\varepsilon \\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\kappa_t\\bar\\beta_t\\varepsilon_1 + \\sigma_t\\varepsilon_0\\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2}\\varepsilon_2\\\\\n\\end{align*}\n$$\n\n第二行用到了背景设置中的“基本等式” $x_{t} = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$。根据基本等式我们还知道 $x_{t-1} = \\bar\\alpha_{t-1}x_{0} + \\bar\\beta_{t-1}\\varepsilon$，因此和上面的结果比较一下系数可得到：\n\n$$\n\\kappa_t\\bar\\alpha_t + \\lambda_t = \\bar\\alpha_{t-1}\\\\\n\\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2} = \\bar\\beta_{t-1}\n$$\n\n三个待定系数，两个方程，所以说会有一个可变参数。我们设方差项 $\\sigma_t^2$ 为可变参数，把 $\\kappa$ 和 $\\lambda$ 解出来：\n\n$$\n\\kappa_t = \\frac{\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\\\\\n\\lambda_t = \\bar\\alpha_{t-1} - \\frac{\\bar\\alpha_t\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\n$$\n\n> DDPM 里面这三个参数都可以求，怎么求出来的？其实就是多了一个方程可以把 $\\sigma_t$ 求出来。这个方程就是我们刚刚扔掉的扩散过程的方程，代表 $p(x_t|x_{t-1})$：\n> $$\n> \\begin{align*}\n> x_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1 \\\\\n> x_t &= \\alpha_tx_{t-1} + \\beta_t\\varepsilon_0\\\\\n> &= \\alpha_t(\\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1) + \\beta_t\\varepsilon_0\\\\\n> &= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\alpha_t\\sigma_t\\varepsilon_1 + \\beta_t\\varepsilon_0\\\\\n> &= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n>  (1 - \\kappa_t\\alpha_t)x_{t} &= \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n> \\end{align*}\n> $$\n> 由于 $x_{t} = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$，比较系数可得\n> $$\n> (1 - \\kappa_t\\alpha_t)\\bar\\alpha_{t} = \\alpha_t\\lambda_t\\\\\n> \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\\\\\n> $$\n> 第一个方程重复了，实际上就是多了一个方程\n> $$\n> (1 - \\kappa_t\\alpha_t)\\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\n> $$\n> 因此求得\n> $$\n> \n> $$","source":"_posts/DDIM.md","raw":"---\ntitle: 扩散模型（二）DDIM 学习\nkatex: true\ndate: 2025-08-10 20:10:31\ntags:\n---\n\n还记得我们在 DDPM 学习的最后讨论了“采样时为什么需要加入高斯噪声”，当时我们提到这是由 DDPM 扩散过程的定义决定的，如果不加则相当于令噪声项的方差等于 0，在这种情况下所有的公式都要重写。那么，要是令噪声的方差为 0 到底能不能行呢？凑巧的是，DDIM 就是这么做的。它重新定义了 DDPM 的扩散过程（不是一步一步加噪声，而是直接给原图像加不同级别的噪声），从而使得噪声项的方差变成了一个可调的参数！实验发现让这个可调的方差等于 0 的时候效果反而是最好的，速度也比 DDPM 更快。并且，当方差等于 0 的时候，图像扩散过程实际上可以表示为一个常微分方程，其中扩散模型预测的是噪声图像向原始图像移动的“速度”矢量，图像就是在这个速度的牵引下从一个噪声变成了有意义的图像。\n\n本文主要参考自苏剑林老师的博客：[生成扩散模型漫谈（四）：DDIM = 高观点DDPM](https://spaces.ac.cn/archives/9181)。\n\n## 背景设置\n\nDDPM 里面对于扩散过程的约束，是给定 $x_{t-1}$ 输出 $x_t$，即 $x_t$ 与 $x_{t-1}$ 的关系 $p(x_t|x_{t-1})$：\n\n$$\nx_t = \\alpha_tx_{t-1} + \\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\alpha_t^2 + \\beta_t^2 = 1\n$$\n\n然而，在 DDPM 的训练过程中，我们并没有用到这个公式一步步生成加噪图像。我们直接给原图 $x_0$ 混合一个高斯噪声一步到位得到 $x_t$，这样速度更快。这是等价的，上述方程不断迭代就得到了 $x_t$ 与 $x_0$ 的关系 $p(x_t|x_0)$：\n\n$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\bar\\alpha_t = \\alpha_t\\alpha_{t-1}\\dots\\alpha_0\n$$\n\n推理过程，我们想从 $x_t$ 还原出上一步 $x_{t-1}$，但是 $p(x_{t-1}|x_{t})$ 求不出来，用 $p(x_{t-1}|x_t,x_0)$ 估计它：\n\n$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0)\n$$\n\n训练过程，模型学习的是直接从 $x_t$ 预测 $x_0$（或者其噪声），跟扩散过程的定义 $p(x_t|x_{t-1})$ 没有任何关系！然而推理过程却需要一步步反推扩散过程得到结果，凭什么训练和推理过程不一致呢？\n\n对于这个问题，DDIM 可能会给我们一些启发。它做了一件疯狂的事情：推理可以扔掉扩散过程，让训练和推理过程更一致，不仅速度快，而且效果更好。\n\n现在，最基本的关系不再是 $x_t$ 与 $x_{t-1}$ 的关系，而是 $x_{t}$ 与 $x_{0}$ 的关系。为此，我们要把 $\\bar\\alpha_t$ 和 $\\bar\\beta_t$ 作为最基本的参数，而 $\\alpha_t$ 和 $\\beta_t$ 不再重要：\n\n$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\alpha_t = \\frac{\\bar\\alpha_t}{\\bar\\alpha_{t-1}}, \\beta_t = \\sqrt{1 - \\alpha_t^2}\n$$\n\n$x_1, x_2, \\dots, x_t$ 不再是一条马尔科夫链，而是相互独立的加噪过程，随着 $t$ 的增大，噪声的强度越来越大。\n\n## 推理过程\n\nDDIM 并不改变训练过程，它只是加速了推理过程。推理过程中，我们仍然需要从 $x_t$ 还原出“上一步” $x_{t-1}$，即计算 $p(x_{t-1}|x_t)$，根据贝叶斯公式：\n\n$$\np(x_{t-1}|x_t) = \\frac{p(x_t|x_{t-1})p(x_{t-1})}{p(x_t)}\n$$\n\n和 DDPM 一样，上面这个 $p(x_{t-1}|x_{t})$ 求不出来，改成用 $p(x_{t-1}|x_t,x_0)$ 估计它：\n\n$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0) = \\frac{p(x_t|x_{t-1})p(x_{t-1}|x_0)}{p(x_t|x_0)}\n$$\n\n但是，DDPM 里面我们是知道 $p(x_t|x_{t-1})$ 就是扩散过程，表达式是已知的，现在我们把它扔掉，左边这个概率就算不出来了吧？\n\n实则不然，把 $p(x_t|x_{t-1})$ 扔掉之后，我们反而更加自由了，直接设\n\n$$\np(x_{t-1}|x_t,x_0) = \\mathcal N(x_{t-1};\\kappa_tx_t + \\lambda_tx_0, \\sigma^2_tI)\n$$\n\n是否感觉非常奇怪？DDPM 里面，这三个待定系数 $\\kappa, \\lambda, \\sigma$ 是可以用贝叶斯公式全部求出来的。然而因为扔掉了 $p(x_t|x_{t-1})$ 的表达式，实际上会多出来一个可变参数。让我们看看：\n\n$$\n\\begin{align*}\nx_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_0 \\\\\n&= \\kappa_t(\\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon_1) + \\lambda_tx_0 + \\sigma_t\\varepsilon \\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\kappa_t\\bar\\beta_t\\varepsilon_1 + \\sigma_t\\varepsilon_0\\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2}\\varepsilon_2\\\\\n\\end{align*}\n$$\n\n第二行用到了背景设置中的“基本等式” $x_{t} = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$。根据基本等式我们还知道 $x_{t-1} = \\bar\\alpha_{t-1}x_{0} + \\bar\\beta_{t-1}\\varepsilon$，因此和上面的结果比较一下系数可得到：\n\n$$\n\\kappa_t\\bar\\alpha_t + \\lambda_t = \\bar\\alpha_{t-1}\\\\\n\\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2} = \\bar\\beta_{t-1}\n$$\n\n三个待定系数，两个方程，所以说会有一个可变参数。我们设方差项 $\\sigma_t^2$ 为可变参数，把 $\\kappa$ 和 $\\lambda$ 解出来：\n\n$$\n\\kappa_t = \\frac{\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\\\\\n\\lambda_t = \\bar\\alpha_{t-1} - \\frac{\\bar\\alpha_t\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\n$$\n\n> DDPM 里面这三个参数都可以求，怎么求出来的？其实就是多了一个方程可以把 $\\sigma_t$ 求出来。这个方程就是我们刚刚扔掉的扩散过程的方程，代表 $p(x_t|x_{t-1})$：\n> $$\n> \\begin{align*}\n> x_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1 \\\\\n> x_t &= \\alpha_tx_{t-1} + \\beta_t\\varepsilon_0\\\\\n> &= \\alpha_t(\\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1) + \\beta_t\\varepsilon_0\\\\\n> &= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\alpha_t\\sigma_t\\varepsilon_1 + \\beta_t\\varepsilon_0\\\\\n> &= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n>  (1 - \\kappa_t\\alpha_t)x_{t} &= \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n> \\end{align*}\n> $$\n> 由于 $x_{t} = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$，比较系数可得\n> $$\n> (1 - \\kappa_t\\alpha_t)\\bar\\alpha_{t} = \\alpha_t\\lambda_t\\\\\n> \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\\\\\n> $$\n> 第一个方程重复了，实际上就是多了一个方程\n> $$\n> (1 - \\kappa_t\\alpha_t)\\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\n> $$\n> 因此求得\n> $$\n> \n> $$","slug":"DDIM","published":1,"updated":"2025-08-11T13:41:19.288Z","_id":"cme6lwlgp0000y0tg3jqr0e33","comments":1,"layout":"post","photos":[],"link":"","content":"<p>还记得我们在 DDPM 学习的最后讨论了“采样时为什么需要加入高斯噪声”，当时我们提到这是由 DDPM 扩散过程的定义决定的，如果不加则相当于令噪声项的方差等于 0，在这种情况下所有的公式都要重写。那么，要是令噪声的方差为 0 到底能不能行呢？凑巧的是，DDIM 就是这么做的。它重新定义了 DDPM 的扩散过程（不是一步一步加噪声，而是直接给原图像加不同级别的噪声），从而使得噪声项的方差变成了一个可调的参数！实验发现让这个可调的方差等于 0 的时候效果反而是最好的，速度也比 DDPM 更快。并且，当方差等于 0 的时候，图像扩散过程实际上可以表示为一个常微分方程，其中扩散模型预测的是噪声图像向原始图像移动的“速度”矢量，图像就是在这个速度的牵引下从一个噪声变成了有意义的图像。</p>\n<p>本文主要参考自苏剑林老师的博客：<a href=\"https://spaces.ac.cn/archives/9181\">生成扩散模型漫谈（四）：DDIM &#x3D; 高观点DDPM</a>。</p>\n<h2 id=\"背景设置\"><a href=\"#背景设置\" class=\"headerlink\" title=\"背景设置\"></a>背景设置</h2><p>DDPM 里面对于扩散过程的约束，是给定 $x_{t-1}$ 输出 $x_t$，即 $x_t$ 与 $x_{t-1}$ 的关系 $p(x_t|x_{t-1})$：</p>\n<div>$$\nx_t = \\alpha_tx_{t-1} + \\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\alpha_t^2 + \\beta_t^2 = 1\n$$</div>\n\n<p>然而，在 DDPM 的训练过程中，我们并没有用到这个公式一步步生成加噪图像。我们直接给原图 $x_0$ 混合一个高斯噪声一步到位得到 $x_t$，这样速度更快。这是等价的，上述方程不断迭代就得到了 $x_t$ 与 $x_0$ 的关系 $p(x_t|x_0)$：</p>\n<div>$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\bar\\alpha_t = \\alpha_t\\alpha_{t-1}\\dots\\alpha_0\n$$</div>\n\n<p>推理过程，我们想从 $x_t$ 还原出上一步 $x_{t-1}$，但是 $p(x_{t-1}|x_{t})$ 求不出来，用 $p(x_{t-1}|x_t,x_0)$ 估计它：</p>\n<div>$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0)\n$$</div>\n\n<p>训练过程，模型学习的是直接从 $x_t$ 预测 $x_0$（或者其噪声），跟扩散过程的定义 $p(x_t|x_{t-1})$ 没有任何关系！然而推理过程却需要一步步反推扩散过程得到结果，凭什么训练和推理过程不一致呢？</p>\n<p>对于这个问题，DDIM 可能会给我们一些启发。它做了一件疯狂的事情：推理可以扔掉扩散过程，让训练和推理过程更一致，不仅速度快，而且效果更好。</p>\n<p>现在，最基本的关系不再是 $x_t$ 与 $x_{t-1}$ 的关系，而是 $x_{t}$ 与 $x_{0}$ 的关系。为此，我们要把 $\\bar\\alpha_t$ 和 $\\bar\\beta_t$ 作为最基本的参数，而 $\\alpha_t$ 和 $\\beta_t$ 不再重要：</p>\n<div>$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\alpha_t = \\frac{\\bar\\alpha_t}{\\bar\\alpha_{t-1}}, \\beta_t = \\sqrt{1 - \\alpha_t^2}\n$$</div>\n\n<p>$x_1, x_2, \\dots, x_t$ 不再是一条马尔科夫链，而是相互独立的加噪过程，随着 $t$ 的增大，噪声的强度越来越大。</p>\n<h2 id=\"推理过程\"><a href=\"#推理过程\" class=\"headerlink\" title=\"推理过程\"></a>推理过程</h2><p>DDIM 并不改变训练过程，它只是加速了推理过程。推理过程中，我们仍然需要从 $x_t$ 还原出“上一步” $x_{t-1}$，即计算 $p(x_{t-1}|x_t)$，根据贝叶斯公式：</p>\n<div>$$\np(x_{t-1}|x_t) = \\frac{p(x_t|x_{t-1})p(x_{t-1})}{p(x_t)}\n$$</div>\n\n<p>和 DDPM 一样，上面这个 $p(x_{t-1}|x_{t})$ 求不出来，改成用 $p(x_{t-1}|x_t,x_0)$ 估计它：</p>\n<div>$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0) = \\frac{p(x_t|x_{t-1})p(x_{t-1}|x_0)}{p(x_t|x_0)}\n$$</div>\n\n<p>但是，DDPM 里面我们是知道 $p(x_t|x_{t-1})$ 就是扩散过程，表达式是已知的，现在我们把它扔掉，左边这个概率就算不出来了吧？</p>\n<p>实则不然，把 $p(x_t|x_{t-1})$ 扔掉之后，我们反而更加自由了，直接设</p>\n<div>$$\np(x_{t-1}|x_t,x_0) = \\mathcal N(x_{t-1};\\kappa_tx_t + \\lambda_tx_0, \\sigma^2_tI)\n$$</div>\n\n<p>是否感觉非常奇怪？DDPM 里面，这三个待定系数 $\\kappa, \\lambda, \\sigma$ 是可以用贝叶斯公式全部求出来的。然而因为扔掉了 $p(x_t|x_{t-1})$ 的表达式，实际上会多出来一个可变参数。让我们看看：</p>\n<div>$$\n\\begin{align*}\nx_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_0 \\\\\n&= \\kappa_t(\\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon_1) + \\lambda_tx_0 + \\sigma_t\\varepsilon \\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\kappa_t\\bar\\beta_t\\varepsilon_1 + \\sigma_t\\varepsilon_0\\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2}\\varepsilon_2\\\\\n\\end{align*}\n$$</div>\n\n<p>第二行用到了背景设置中的“基本等式” $x_{t} &#x3D; \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$。根据基本等式我们还知道 $x_{t-1} &#x3D; \\bar\\alpha_{t-1}x_{0} + \\bar\\beta_{t-1}\\varepsilon$，因此和上面的结果比较一下系数可得到：</p>\n<div>$$\n\\kappa_t\\bar\\alpha_t + \\lambda_t = \\bar\\alpha_{t-1}\\\\\n\\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2} = \\bar\\beta_{t-1}\n$$</div>\n\n<p>三个待定系数，两个方程，所以说会有一个可变参数。我们设方差项 $\\sigma_t^2$ 为可变参数，把 $\\kappa$ 和 $\\lambda$ 解出来：</p>\n<div>$$\n\\kappa_t = \\frac{\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\\\\\n\\lambda_t = \\bar\\alpha_{t-1} - \\frac{\\bar\\alpha_t\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\n$$</div>\n\n<blockquote>\n<p>DDPM 里面这三个参数都可以求，怎么求出来的？其实就是多了一个方程可以把 $\\sigma_t$ 求出来。这个方程就是我们刚刚扔掉的扩散过程的方程，代表 $p(x_t|x_{t-1})$：</p>\n<div>$$\n\\begin{align*}\nx_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1 \\\\\nx_t &= \\alpha_tx_{t-1} + \\beta_t\\varepsilon_0\\\\\n&= \\alpha_t(\\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1) + \\beta_t\\varepsilon_0\\\\\n&= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\alpha_t\\sigma_t\\varepsilon_1 + \\beta_t\\varepsilon_0\\\\\n&= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n (1 - \\kappa_t\\alpha_t)x_{t} &= \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n\\end{align*}\n$$</div>\n由于 $x_{t} = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$，比较系数可得\n<div>$$\n(1 - \\kappa_t\\alpha_t)\\bar\\alpha_{t} = \\alpha_t\\lambda_t\\\\\n\\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\\\\\n$$</div>\n第一个方程重复了，实际上就是多了一个方程\n<div>$$\n(1 - \\kappa_t\\alpha_t)\\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\n$$</div>\n因此求得\n<div>$$\n\n<p>$$</div></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p>还记得我们在 DDPM 学习的最后讨论了“采样时为什么需要加入高斯噪声”，当时我们提到这是由 DDPM 扩散过程的定义决定的，如果不加则相当于令噪声项的方差等于 0，在这种情况下所有的公式都要重写。那么，要是令噪声的方差为 0 到底能不能行呢？凑巧的是，DDIM 就是这么做的。它重新定义了 DDPM 的扩散过程（不是一步一步加噪声，而是直接给原图像加不同级别的噪声），从而使得噪声项的方差变成了一个可调的参数！实验发现让这个可调的方差等于 0 的时候效果反而是最好的，速度也比 DDPM 更快。并且，当方差等于 0 的时候，图像扩散过程实际上可以表示为一个常微分方程，其中扩散模型预测的是噪声图像向原始图像移动的“速度”矢量，图像就是在这个速度的牵引下从一个噪声变成了有意义的图像。</p>\n<p>本文主要参考自苏剑林老师的博客：<a href=\"https://spaces.ac.cn/archives/9181\">生成扩散模型漫谈（四）：DDIM &#x3D; 高观点DDPM</a>。</p>\n<h2 id=\"背景设置\"><a href=\"#背景设置\" class=\"headerlink\" title=\"背景设置\"></a>背景设置</h2><p>DDPM 里面对于扩散过程的约束，是给定 $x_{t-1}$ 输出 $x_t$，即 $x_t$ 与 $x_{t-1}$ 的关系 $p(x_t|x_{t-1})$：</p>\n<div>$$\nx_t = \\alpha_tx_{t-1} + \\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\alpha_t^2 + \\beta_t^2 = 1\n$$</div>\n\n<p>然而，在 DDPM 的训练过程中，我们并没有用到这个公式一步步生成加噪图像。我们直接给原图 $x_0$ 混合一个高斯噪声一步到位得到 $x_t$，这样速度更快。这是等价的，上述方程不断迭代就得到了 $x_t$ 与 $x_0$ 的关系 $p(x_t|x_0)$：</p>\n<div>$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\bar\\alpha_t = \\alpha_t\\alpha_{t-1}\\dots\\alpha_0\n$$</div>\n\n<p>推理过程，我们想从 $x_t$ 还原出上一步 $x_{t-1}$，但是 $p(x_{t-1}|x_{t})$ 求不出来，用 $p(x_{t-1}|x_t,x_0)$ 估计它：</p>\n<div>$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0)\n$$</div>\n\n<p>训练过程，模型学习的是直接从 $x_t$ 预测 $x_0$（或者其噪声），跟扩散过程的定义 $p(x_t|x_{t-1})$ 没有任何关系！然而推理过程却需要一步步反推扩散过程得到结果，凭什么训练和推理过程不一致呢？</p>\n<p>对于这个问题，DDIM 可能会给我们一些启发。它做了一件疯狂的事情：推理可以扔掉扩散过程，让训练和推理过程更一致，不仅速度快，而且效果更好。</p>\n<p>现在，最基本的关系不再是 $x_t$ 与 $x_{t-1}$ 的关系，而是 $x_{t}$ 与 $x_{0}$ 的关系。为此，我们要把 $\\bar\\alpha_t$ 和 $\\bar\\beta_t$ 作为最基本的参数，而 $\\alpha_t$ 和 $\\beta_t$ 不再重要：</p>\n<div>$$\nx_t = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon, \\varepsilon \\sim \\mathcal N(0, I)\\\\\n\\bar\\alpha_t^2 + \\bar\\beta_t^2 = 1\\\\\n\\alpha_t = \\frac{\\bar\\alpha_t}{\\bar\\alpha_{t-1}}, \\beta_t = \\sqrt{1 - \\alpha_t^2}\n$$</div>\n\n<p>$x_1, x_2, \\dots, x_t$ 不再是一条马尔科夫链，而是相互独立的加噪过程，随着 $t$ 的增大，噪声的强度越来越大。</p>\n<h2 id=\"推理过程\"><a href=\"#推理过程\" class=\"headerlink\" title=\"推理过程\"></a>推理过程</h2><p>DDIM 并不改变训练过程，它只是加速了推理过程。推理过程中，我们仍然需要从 $x_t$ 还原出“上一步” $x_{t-1}$，即计算 $p(x_{t-1}|x_t)$，根据贝叶斯公式：</p>\n<div>$$\np(x_{t-1}|x_t) = \\frac{p(x_t|x_{t-1})p(x_{t-1})}{p(x_t)}\n$$</div>\n\n<p>和 DDPM 一样，上面这个 $p(x_{t-1}|x_{t})$ 求不出来，改成用 $p(x_{t-1}|x_t,x_0)$ 估计它：</p>\n<div>$$\np(x_{t-1}|x_{t}) \\approx p(x_{t-1}|x_t,x_0) = \\frac{p(x_t|x_{t-1})p(x_{t-1}|x_0)}{p(x_t|x_0)}\n$$</div>\n\n<p>但是，DDPM 里面我们是知道 $p(x_t|x_{t-1})$ 就是扩散过程，表达式是已知的，现在我们把它扔掉，左边这个概率就算不出来了吧？</p>\n<p>实则不然，把 $p(x_t|x_{t-1})$ 扔掉之后，我们反而更加自由了，直接设</p>\n<div>$$\np(x_{t-1}|x_t,x_0) = \\mathcal N(x_{t-1};\\kappa_tx_t + \\lambda_tx_0, \\sigma^2_tI)\n$$</div>\n\n<p>是否感觉非常奇怪？DDPM 里面，这三个待定系数 $\\kappa, \\lambda, \\sigma$ 是可以用贝叶斯公式全部求出来的。然而因为扔掉了 $p(x_t|x_{t-1})$ 的表达式，实际上会多出来一个可变参数。让我们看看：</p>\n<div>$$\n\\begin{align*}\nx_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_0 \\\\\n&= \\kappa_t(\\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon_1) + \\lambda_tx_0 + \\sigma_t\\varepsilon \\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\kappa_t\\bar\\beta_t\\varepsilon_1 + \\sigma_t\\varepsilon_0\\\\\n&= (\\kappa_t\\bar\\alpha_t + \\lambda_t)x_{0} + \\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2}\\varepsilon_2\\\\\n\\end{align*}\n$$</div>\n\n<p>第二行用到了背景设置中的“基本等式” $x_{t} &#x3D; \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$。根据基本等式我们还知道 $x_{t-1} &#x3D; \\bar\\alpha_{t-1}x_{0} + \\bar\\beta_{t-1}\\varepsilon$，因此和上面的结果比较一下系数可得到：</p>\n<div>$$\n\\kappa_t\\bar\\alpha_t + \\lambda_t = \\bar\\alpha_{t-1}\\\\\n\\sqrt{\\kappa_t^2\\bar\\beta_t^2 + \\sigma_t^2} = \\bar\\beta_{t-1}\n$$</div>\n\n<p>三个待定系数，两个方程，所以说会有一个可变参数。我们设方差项 $\\sigma_t^2$ 为可变参数，把 $\\kappa$ 和 $\\lambda$ 解出来：</p>\n<div>$$\n\\kappa_t = \\frac{\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\\\\\n\\lambda_t = \\bar\\alpha_{t-1} - \\frac{\\bar\\alpha_t\\sqrt{\\bar\\beta_{t-1}^2 - \\sigma^2_t}}{\\bar\\beta_t}\n$$</div>\n\n<blockquote>\n<p>DDPM 里面这三个参数都可以求，怎么求出来的？其实就是多了一个方程可以把 $\\sigma_t$ 求出来。这个方程就是我们刚刚扔掉的扩散过程的方程，代表 $p(x_t|x_{t-1})$：</p>\n<div>$$\n\\begin{align*}\nx_{t-1} &= \\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1 \\\\\nx_t &= \\alpha_tx_{t-1} + \\beta_t\\varepsilon_0\\\\\n&= \\alpha_t(\\kappa_tx_t + \\lambda_tx_0 + \\sigma_t\\varepsilon_1) + \\beta_t\\varepsilon_0\\\\\n&= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\alpha_t\\sigma_t\\varepsilon_1 + \\beta_t\\varepsilon_0\\\\\n&= \\alpha_t\\kappa_tx_t + \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n (1 - \\kappa_t\\alpha_t)x_{t} &= \\alpha_t\\lambda_tx_0 + \\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2}\\varepsilon_2\\\\\n\\end{align*}\n$$</div>\n由于 $x_{t} = \\bar\\alpha_tx_{0} + \\bar\\beta_t\\varepsilon$，比较系数可得\n<div>$$\n(1 - \\kappa_t\\alpha_t)\\bar\\alpha_{t} = \\alpha_t\\lambda_t\\\\\n\\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\\\\\n$$</div>\n第一个方程重复了，实际上就是多了一个方程\n<div>$$\n(1 - \\kappa_t\\alpha_t)\\sqrt{\\alpha_t^2\\sigma_t^2 + \\beta_t^2} = \\bar\\beta_{t}\n$$</div>\n因此求得\n<div>$$\n\n<p>$$</div></p>\n</blockquote>\n"},{"title":"最优化方法","katex":true,"date":"2025-09-18T03:01:39.000Z","_content":"约定向量 x 大于常数等价于 x 的每个分量大于某个常数\n\n## 基础知识\n\n\n### 多面集的表示定理\n\n定理：设 $S=\\lbrace x|Ax\\boldsymbol{=}b,x\\boldsymbol{\\geqslant}0\\rbrace$ 为非空多面集，则有\n\n(1) 极点集非空，且存在有限个极点$x^(1),\\cdots,x^(k).$\n\n(2) 极方向集合为空集的充要条件是S有界；若S无界，则存在有限个极方向$d^{(1)},d^{(2)},\\cdots,d^{(l)}.$\n\n$x\\in S$的充要条件是\n\n$$\nx=\\sum_{j=1}^k\\lambda_jx^{(j)}+\\sum_{j=1}^l\\mu_jd^{(j)}\n$$\n\n其中$\\lambda_j\\geq0,j=1,2,\\cdots,k,\\sum_{j=1}^k\\lambda_j=1$\n\n$$\n\\mu_j\\geq0,j=1,2,\\cdots,l.\n$$\n\n\n## 线性规划\n\nLP 的标准形式\n\n1. 极小化型\n2. 约束方程为等式\n3. 所有的决策变量为非负值\n4. 约束方程的右端项系数为非负值\n\n$$\n\\min z = cx, \\\\\ns.t.\\ Ax = b,\\\\\nx \\ge 0\n$$\n\n非标准型 LP 模型可以转化为标准型 LP 模型\n\n1. 取个负号\n2. 约束方程为不等式：加一个松弛变量变为等式。\n3. 变量无非负约束：令 $x_j = x_j^\\prime - x_j^{\\prime\\prime}$\n4. 决策变量有上下界：平移到0处。\n\n### LP 问题的基本性质\n\n#### 可行解\n\n线性规划的可行域是凸集。\n\n#### 最优极点\n\n考虑标准形式：\n\n$$\n\\begin{cases}\\min&cx\\\\s.t.&Ax=b\\\\&x\\geq0&\\end{cases}\n$$\n\n把多面集表示定理代入其中：\n\n$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}+\\sum_{j=1}^l\\mu_jcd^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\\\&\\mu_j\\geq0,j=1,\\cdots,l.&\\end{cases}\n$$\n\n若存在 $j$ 使得 $cd^{(j)} \\lt 0$，此时可以取 $\\mu_j\\to-\\infty$，则 $f(x)\\to-\\infty$。\n\n若所有的 d 都满足 $cd^{(j)} \\ge 0$，取 $\\mu_j = 0, j = 1, 2, \\dots, l$，得到\n\n$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\end{cases}\n$$\n\n此时只需要找到 $p = \\arg\\min_{j}cx^{(j)}$，取 $\\lambda_p = 1$, $\\lambda_j = 0 (j\\ne p)$ 即可得到最大值。\n\n定理2．设线性规划(L)的可行域非空，则\n\n（1）(L)存在最优解的充要条件是对任意的$j$, $cd^{(j)}≥0$, 其中$d^{(j)}$为可行域的极方向。\n\n（2）若(L)存在最优解，则目标函数的最优值可在某个极点达到。\n\n#### 基和基本解\n\n设标准形式中 $\\text{rank}(A_{m\\times n}) = m = (P_1\\ P_2\\ \\dots\\ P_n)$，$Ax = P_1x_1+\\dots+P_nx_n$，则可以从 $A$ 的列中取出 $m$ 个 $P_j$组合成一个可逆矩阵 $B$ 称为基，与取出来的 $P_j$ 对应的 $x_j$ 称为基向量。\n\n设 $A = [B\\ N]$，$Ax = Bx_b + Nx_N = b$，解得\n\n$$\nx_B = B^{-1}b - B^{-1}Nx_N\n$$\n\n取 $x_N = 0$，此时 $x = \\begin{bmatrix}B^{-1}b\\\\0\\end{bmatrix}$ 为 (LP) 的基本解。\n\n若 $B^{-1}b \\ge 0$，则 $x$ 称为基本可行解，$B$ 为可行基矩阵，$x_{B_1}, x_{B_2}, \\dots, x_{B_m}$ 为一组可行基。\n\n若 $B^{-1}b \\gt 0$，则称基本可行解是非退化的，否则是退化的。\n\n**基本可行解与极点之间的关系**\n\n引理1：对于可行解 $\\bar x$， $\\bar x$ 是基本可行解的充要条件是 $\\bar x$ 的非零分量对应到 $A$ 中的列向量线性无关。\n\n定理2：设 $S$ 是 $(L)$ 的可行域，$\\bar x \\in S$，则 $\\bar x$ 是 $S$ 极点的充要条件为 $\\bar x$ 是 $(L)$ 的基本可行解。\n\n> 思考：本质上是因为“极点”的唯一性，正好对应了基矩阵可逆，求解出来的基本可行解也是唯一的。\n\n> 从几何意义思考标准形式：1. $Ax=b$ 本质上代表了一个 k 维的子空间，k 是矩阵的秩，如果 k = 1 就是直线，k = 2 就是平面；2. $x\\ge0$ 是一组边界，它会截取子空间的一部分，以 k = 2，n = 3 为例，这意味着我们用一个平面去与三维空间的第一卦限相交的部分作为可行域，不考虑退化的情况，通常它是一个 n 条边界的图形，正好对应 n 个变量分别等于 0 的情况。3. $cx$ 不用解释了，这就是一个 n - 1 维的空间。\n\n定理3：设 $S = {x| Ax=b, x\\ge 0}$ 的方向 $d$ 有 $k$ 个非零分量，则 $d$ 是 $S$ 的极方向 等价于 $d$ 的非零分量对应到 A 的列向量的秩为 k - 1。\n\n**基本可行解的存在问题**\n\n定理1．如果(LP)有可行解,则一定存在基本可行解.\n\n定理2．如果(LP)有最优解，则存在一个基本可行解是最优解。\n\n### 单纯形法\n\n设 $A = (B\\ N)$\n\n$$\nx\n$$","source":"_posts/最优化方法.md","raw":"---\ntitle: 最优化方法\nkatex: true\ndate: 2025-09-18 11:01:39\ntags:\n---\n约定向量 x 大于常数等价于 x 的每个分量大于某个常数\n\n## 基础知识\n\n\n### 多面集的表示定理\n\n定理：设 $S=\\lbrace x|Ax\\boldsymbol{=}b,x\\boldsymbol{\\geqslant}0\\rbrace$ 为非空多面集，则有\n\n(1) 极点集非空，且存在有限个极点$x^(1),\\cdots,x^(k).$\n\n(2) 极方向集合为空集的充要条件是S有界；若S无界，则存在有限个极方向$d^{(1)},d^{(2)},\\cdots,d^{(l)}.$\n\n$x\\in S$的充要条件是\n\n$$\nx=\\sum_{j=1}^k\\lambda_jx^{(j)}+\\sum_{j=1}^l\\mu_jd^{(j)}\n$$\n\n其中$\\lambda_j\\geq0,j=1,2,\\cdots,k,\\sum_{j=1}^k\\lambda_j=1$\n\n$$\n\\mu_j\\geq0,j=1,2,\\cdots,l.\n$$\n\n\n## 线性规划\n\nLP 的标准形式\n\n1. 极小化型\n2. 约束方程为等式\n3. 所有的决策变量为非负值\n4. 约束方程的右端项系数为非负值\n\n$$\n\\min z = cx, \\\\\ns.t.\\ Ax = b,\\\\\nx \\ge 0\n$$\n\n非标准型 LP 模型可以转化为标准型 LP 模型\n\n1. 取个负号\n2. 约束方程为不等式：加一个松弛变量变为等式。\n3. 变量无非负约束：令 $x_j = x_j^\\prime - x_j^{\\prime\\prime}$\n4. 决策变量有上下界：平移到0处。\n\n### LP 问题的基本性质\n\n#### 可行解\n\n线性规划的可行域是凸集。\n\n#### 最优极点\n\n考虑标准形式：\n\n$$\n\\begin{cases}\\min&cx\\\\s.t.&Ax=b\\\\&x\\geq0&\\end{cases}\n$$\n\n把多面集表示定理代入其中：\n\n$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}+\\sum_{j=1}^l\\mu_jcd^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\\\&\\mu_j\\geq0,j=1,\\cdots,l.&\\end{cases}\n$$\n\n若存在 $j$ 使得 $cd^{(j)} \\lt 0$，此时可以取 $\\mu_j\\to-\\infty$，则 $f(x)\\to-\\infty$。\n\n若所有的 d 都满足 $cd^{(j)} \\ge 0$，取 $\\mu_j = 0, j = 1, 2, \\dots, l$，得到\n\n$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\end{cases}\n$$\n\n此时只需要找到 $p = \\arg\\min_{j}cx^{(j)}$，取 $\\lambda_p = 1$, $\\lambda_j = 0 (j\\ne p)$ 即可得到最大值。\n\n定理2．设线性规划(L)的可行域非空，则\n\n（1）(L)存在最优解的充要条件是对任意的$j$, $cd^{(j)}≥0$, 其中$d^{(j)}$为可行域的极方向。\n\n（2）若(L)存在最优解，则目标函数的最优值可在某个极点达到。\n\n#### 基和基本解\n\n设标准形式中 $\\text{rank}(A_{m\\times n}) = m = (P_1\\ P_2\\ \\dots\\ P_n)$，$Ax = P_1x_1+\\dots+P_nx_n$，则可以从 $A$ 的列中取出 $m$ 个 $P_j$组合成一个可逆矩阵 $B$ 称为基，与取出来的 $P_j$ 对应的 $x_j$ 称为基向量。\n\n设 $A = [B\\ N]$，$Ax = Bx_b + Nx_N = b$，解得\n\n$$\nx_B = B^{-1}b - B^{-1}Nx_N\n$$\n\n取 $x_N = 0$，此时 $x = \\begin{bmatrix}B^{-1}b\\\\0\\end{bmatrix}$ 为 (LP) 的基本解。\n\n若 $B^{-1}b \\ge 0$，则 $x$ 称为基本可行解，$B$ 为可行基矩阵，$x_{B_1}, x_{B_2}, \\dots, x_{B_m}$ 为一组可行基。\n\n若 $B^{-1}b \\gt 0$，则称基本可行解是非退化的，否则是退化的。\n\n**基本可行解与极点之间的关系**\n\n引理1：对于可行解 $\\bar x$， $\\bar x$ 是基本可行解的充要条件是 $\\bar x$ 的非零分量对应到 $A$ 中的列向量线性无关。\n\n定理2：设 $S$ 是 $(L)$ 的可行域，$\\bar x \\in S$，则 $\\bar x$ 是 $S$ 极点的充要条件为 $\\bar x$ 是 $(L)$ 的基本可行解。\n\n> 思考：本质上是因为“极点”的唯一性，正好对应了基矩阵可逆，求解出来的基本可行解也是唯一的。\n\n> 从几何意义思考标准形式：1. $Ax=b$ 本质上代表了一个 k 维的子空间，k 是矩阵的秩，如果 k = 1 就是直线，k = 2 就是平面；2. $x\\ge0$ 是一组边界，它会截取子空间的一部分，以 k = 2，n = 3 为例，这意味着我们用一个平面去与三维空间的第一卦限相交的部分作为可行域，不考虑退化的情况，通常它是一个 n 条边界的图形，正好对应 n 个变量分别等于 0 的情况。3. $cx$ 不用解释了，这就是一个 n - 1 维的空间。\n\n定理3：设 $S = {x| Ax=b, x\\ge 0}$ 的方向 $d$ 有 $k$ 个非零分量，则 $d$ 是 $S$ 的极方向 等价于 $d$ 的非零分量对应到 A 的列向量的秩为 k - 1。\n\n**基本可行解的存在问题**\n\n定理1．如果(LP)有可行解,则一定存在基本可行解.\n\n定理2．如果(LP)有最优解，则存在一个基本可行解是最优解。\n\n### 单纯形法\n\n设 $A = (B\\ N)$\n\n$$\nx\n$$","slug":"最优化方法","published":1,"updated":"2025-09-26T08:46:53.142Z","_id":"cmg0ehgv20000pgtggcm6ce7o","comments":1,"layout":"post","photos":[],"link":"","content":"<p>约定向量 x 大于常数等价于 x 的每个分量大于某个常数</p>\n<h2 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h2><h3 id=\"多面集的表示定理\"><a href=\"#多面集的表示定理\" class=\"headerlink\" title=\"多面集的表示定理\"></a>多面集的表示定理</h3><p>定理：设 <div style=\"display: inline;\">$S&#x3D;\\lbrace x|Ax\\boldsymbol{&#x3D;}b,x\\boldsymbol{\\geqslant}0\\rbrace$</div> 为非空多面集，则有</p>\n<p>(1) 极点集非空，且存在有限个极点<div style=\"display: inline;\">$x^(1),\\cdots,x^(k).$</div></p>\n<p>(2) 极方向集合为空集的充要条件是S有界；若S无界，则存在有限个极方向<div style=\"display: inline;\">$d^{(1)},d^{(2)},\\cdots,d^{(l)}.$</div></p>\n<div style=\"display: inline;\">$x\\in S$</div>的充要条件是\n\n<div>$$\nx=\\sum_{j=1}^k\\lambda_jx^{(j)}+\\sum_{j=1}^l\\mu_jd^{(j)}\n$$</div>\n\n<p>其中<div style=\"display: inline;\">$\\lambda_j\\geq0,j&#x3D;1,2,\\cdots,k,\\sum_{j&#x3D;1}^k\\lambda_j&#x3D;1$</div></p>\n<div>$$\n\\mu_j\\geq0,j=1,2,\\cdots,l.\n$$</div>\n\n\n<h2 id=\"线性规划\"><a href=\"#线性规划\" class=\"headerlink\" title=\"线性规划\"></a>线性规划</h2><p>LP 的标准形式</p>\n<ol>\n<li>极小化型</li>\n<li>约束方程为等式</li>\n<li>所有的决策变量为非负值</li>\n<li>约束方程的右端项系数为非负值</li>\n</ol>\n<div>$$\n\\min z = cx, \\\\\ns.t.\\ Ax = b,\\\\\nx \\ge 0\n$$</div>\n\n<p>非标准型 LP 模型可以转化为标准型 LP 模型</p>\n<ol>\n<li>取个负号</li>\n<li>约束方程为不等式：加一个松弛变量变为等式。</li>\n<li>变量无非负约束：令 <div style=\"display: inline;\">$x_j &#x3D; x_j^\\prime - x_j^{\\prime\\prime}$</div></li>\n<li>决策变量有上下界：平移到0处。</li>\n</ol>\n<h3 id=\"LP-问题的基本性质\"><a href=\"#LP-问题的基本性质\" class=\"headerlink\" title=\"LP 问题的基本性质\"></a>LP 问题的基本性质</h3><h4 id=\"可行解\"><a href=\"#可行解\" class=\"headerlink\" title=\"可行解\"></a>可行解</h4><p>线性规划的可行域是凸集。</p>\n<h4 id=\"最优极点\"><a href=\"#最优极点\" class=\"headerlink\" title=\"最优极点\"></a>最优极点</h4><p>考虑标准形式：</p>\n<div>$$\n\\begin{cases}\\min&cx\\\\s.t.&Ax=b\\\\&x\\geq0&\\end{cases}\n$$</div>\n\n<p>把多面集表示定理代入其中：</p>\n<div>$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}+\\sum_{j=1}^l\\mu_jcd^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\\\&\\mu_j\\geq0,j=1,\\cdots,l.&\\end{cases}\n$$</div>\n\n<p>若存在 <div style=\"display: inline;\">$j$</div> 使得 <div style=\"display: inline;\">$cd^{(j)} \\lt 0$</div>，此时可以取 <div style=\"display: inline;\">$\\mu_j\\to-\\infty$</div>，则 <div style=\"display: inline;\">$f(x)\\to-\\infty$</div>。</p>\n<p>若所有的 d 都满足 <div style=\"display: inline;\">$cd^{(j)} \\ge 0$</div>，取 <div style=\"display: inline;\">$\\mu_j &#x3D; 0, j &#x3D; 1, 2, \\dots, l$</div>，得到</p>\n<div>$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\end{cases}\n$$</div>\n\n<p>此时只需要找到 <div style=\"display: inline;\">$p &#x3D; \\arg\\min_{j}cx^{(j)}$</div>，取 <div style=\"display: inline;\">$\\lambda_p &#x3D; 1$</div>, <div style=\"display: inline;\">$\\lambda_j &#x3D; 0 (j\\ne p)$</div> 即可得到最大值。</p>\n<p>定理2．设线性规划(L)的可行域非空，则</p>\n<p>（1）(L)存在最优解的充要条件是对任意的<div style=\"display: inline;\">$j$</div>, <div style=\"display: inline;\">$cd^{(j)}≥0$</div>, 其中<div style=\"display: inline;\">$d^{(j)}$</div>为可行域的极方向。</p>\n<p>（2）若(L)存在最优解，则目标函数的最优值可在某个极点达到。</p>\n<h4 id=\"基和基本解\"><a href=\"#基和基本解\" class=\"headerlink\" title=\"基和基本解\"></a>基和基本解</h4><p>设标准形式中 <div style=\"display: inline;\">$\\text{rank}(A_{m\\times n}) &#x3D; m &#x3D; (P_1\\ P_2\\ \\dots\\ P_n)$</div>，<div style=\"display: inline;\">$Ax &#x3D; P_1x_1+\\dots+P_nx_n$</div>，则可以从 <div style=\"display: inline;\">$A$</div> 的列中取出 <div style=\"display: inline;\">$m$</div> 个 <div style=\"display: inline;\">$P_j$</div>组合成一个可逆矩阵 <div style=\"display: inline;\">$B$</div> 称为基，与取出来的 <div style=\"display: inline;\">$P_j$</div> 对应的 <div style=\"display: inline;\">$x_j$</div> 称为基向量。</p>\n<p>设 <div style=\"display: inline;\">$A &#x3D; [B\\ N]$</div>，<div style=\"display: inline;\">$Ax &#x3D; Bx_b + Nx_N &#x3D; b$</div>，解得</p>\n<div>$$\nx_B = B^{-1}b - B^{-1}Nx_N\n$$</div>\n\n<p>取 <div style=\"display: inline;\">$x_N &#x3D; 0$</div>，此时 <div style=\"display: inline;\">$x &#x3D; \\begin{bmatrix}B^{-1}b\\0\\end{bmatrix}$</div> 为 (LP) 的基本解。</p>\n<p>若 <div style=\"display: inline;\">$B^{-1}b \\ge 0$</div>，则 <div style=\"display: inline;\">$x$</div> 称为基本可行解，<div style=\"display: inline;\">$B$</div> 为可行基矩阵，<div style=\"display: inline;\">$x_{B_1}, x_{B_2}, \\dots, x_{B_m}$</div> 为一组可行基。</p>\n<p>若 <div style=\"display: inline;\">$B^{-1}b \\gt 0$</div>，则称基本可行解是非退化的，否则是退化的。</p>\n<p><strong>基本可行解与极点之间的关系</strong></p>\n<p>引理1：对于可行解 <div style=\"display: inline;\">$\\bar x$</div>， <div style=\"display: inline;\">$\\bar x$</div> 是基本可行解的充要条件是 <div style=\"display: inline;\">$\\bar x$</div> 的非零分量对应到 <div style=\"display: inline;\">$A$</div> 中的列向量线性无关。</p>\n<p>定理2：设 <div style=\"display: inline;\">$S$</div> 是 <div style=\"display: inline;\">$(L)$</div> 的可行域，<div style=\"display: inline;\">$\\bar x \\in S$</div>，则 <div style=\"display: inline;\">$\\bar x$</div> 是 <div style=\"display: inline;\">$S$</div> 极点的充要条件为 <div style=\"display: inline;\">$\\bar x$</div> 是 <div style=\"display: inline;\">$(L)$</div> 的基本可行解。</p>\n<blockquote>\n<p>思考：本质上是因为“极点”的唯一性，正好对应了基矩阵可逆，求解出来的基本可行解也是唯一的。</p>\n</blockquote>\n<blockquote>\n<p>从几何意义思考标准形式：1. <div style=\"display: inline;\">$Ax&#x3D;b$</div> 本质上代表了一个 k 维的子空间，k 是矩阵的秩，如果 k &#x3D; 1 就是直线，k &#x3D; 2 就是平面；2. <div style=\"display: inline;\">$x\\ge0$</div> 是一组边界，它会截取子空间的一部分，以 k &#x3D; 2，n &#x3D; 3 为例，这意味着我们用一个平面去与三维空间的第一卦限相交的部分作为可行域，不考虑退化的情况，通常它是一个 n 条边界的图形，正好对应 n 个变量分别等于 0 的情况。3. <div style=\"display: inline;\">$cx$</div> 不用解释了，这就是一个 n - 1 维的空间。</p>\n</blockquote>\n<p>定理3：设 <div style=\"display: inline;\">$S &#x3D; {x| Ax&#x3D;b, x\\ge 0}$</div> 的方向 <div style=\"display: inline;\">$d$</div> 有 <div style=\"display: inline;\">$k$</div> 个非零分量，则 <div style=\"display: inline;\">$d$</div> 是 <div style=\"display: inline;\">$S$</div> 的极方向 等价于 <div style=\"display: inline;\">$d$</div> 的非零分量对应到 A 的列向量的秩为 k - 1。</p>\n<p><strong>基本可行解的存在问题</strong></p>\n<p>定理1．如果(LP)有可行解,则一定存在基本可行解.</p>\n<p>定理2．如果(LP)有最优解，则存在一个基本可行解是最优解。</p>\n<h3 id=\"单纯形法\"><a href=\"#单纯形法\" class=\"headerlink\" title=\"单纯形法\"></a>单纯形法</h3><p>设 <div style=\"display: inline;\">$A &#x3D; (B\\ N)$</div></p>\n<div>$$\nx\n$$</div>","site":{"data":{}},"excerpt":"","more":"<p>约定向量 x 大于常数等价于 x 的每个分量大于某个常数</p>\n<h2 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h2><h3 id=\"多面集的表示定理\"><a href=\"#多面集的表示定理\" class=\"headerlink\" title=\"多面集的表示定理\"></a>多面集的表示定理</h3><p>定理：设 <div style=\"display: inline;\">$S&#x3D;\\lbrace x|Ax\\boldsymbol{&#x3D;}b,x\\boldsymbol{\\geqslant}0\\rbrace$</div> 为非空多面集，则有</p>\n<p>(1) 极点集非空，且存在有限个极点<div style=\"display: inline;\">$x^(1),\\cdots,x^(k).$</div></p>\n<p>(2) 极方向集合为空集的充要条件是S有界；若S无界，则存在有限个极方向<div style=\"display: inline;\">$d^{(1)},d^{(2)},\\cdots,d^{(l)}.$</div></p>\n<div style=\"display: inline;\">$x\\in S$</div>的充要条件是\n\n<div>$$\nx=\\sum_{j=1}^k\\lambda_jx^{(j)}+\\sum_{j=1}^l\\mu_jd^{(j)}\n$$</div>\n\n<p>其中<div style=\"display: inline;\">$\\lambda_j\\geq0,j&#x3D;1,2,\\cdots,k,\\sum_{j&#x3D;1}^k\\lambda_j&#x3D;1$</div></p>\n<div>$$\n\\mu_j\\geq0,j=1,2,\\cdots,l.\n$$</div>\n\n\n<h2 id=\"线性规划\"><a href=\"#线性规划\" class=\"headerlink\" title=\"线性规划\"></a>线性规划</h2><p>LP 的标准形式</p>\n<ol>\n<li>极小化型</li>\n<li>约束方程为等式</li>\n<li>所有的决策变量为非负值</li>\n<li>约束方程的右端项系数为非负值</li>\n</ol>\n<div>$$\n\\min z = cx, \\\\\ns.t.\\ Ax = b,\\\\\nx \\ge 0\n$$</div>\n\n<p>非标准型 LP 模型可以转化为标准型 LP 模型</p>\n<ol>\n<li>取个负号</li>\n<li>约束方程为不等式：加一个松弛变量变为等式。</li>\n<li>变量无非负约束：令 <div style=\"display: inline;\">$x_j &#x3D; x_j^\\prime - x_j^{\\prime\\prime}$</div></li>\n<li>决策变量有上下界：平移到0处。</li>\n</ol>\n<h3 id=\"LP-问题的基本性质\"><a href=\"#LP-问题的基本性质\" class=\"headerlink\" title=\"LP 问题的基本性质\"></a>LP 问题的基本性质</h3><h4 id=\"可行解\"><a href=\"#可行解\" class=\"headerlink\" title=\"可行解\"></a>可行解</h4><p>线性规划的可行域是凸集。</p>\n<h4 id=\"最优极点\"><a href=\"#最优极点\" class=\"headerlink\" title=\"最优极点\"></a>最优极点</h4><p>考虑标准形式：</p>\n<div>$$\n\\begin{cases}\\min&cx\\\\s.t.&Ax=b\\\\&x\\geq0&\\end{cases}\n$$</div>\n\n<p>把多面集表示定理代入其中：</p>\n<div>$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}+\\sum_{j=1}^l\\mu_jcd^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\\\&\\mu_j\\geq0,j=1,\\cdots,l.&\\end{cases}\n$$</div>\n\n<p>若存在 <div style=\"display: inline;\">$j$</div> 使得 <div style=\"display: inline;\">$cd^{(j)} \\lt 0$</div>，此时可以取 <div style=\"display: inline;\">$\\mu_j\\to-\\infty$</div>，则 <div style=\"display: inline;\">$f(x)\\to-\\infty$</div>。</p>\n<p>若所有的 d 都满足 <div style=\"display: inline;\">$cd^{(j)} \\ge 0$</div>，取 <div style=\"display: inline;\">$\\mu_j &#x3D; 0, j &#x3D; 1, 2, \\dots, l$</div>，得到</p>\n<div>$$\n\\begin{cases}\\min&\\sum_{j=1}^k\\lambda_jcx^{(j)}=f\\left(x\\right)\\\\s.t.&\\sum_{j=1}^k\\lambda_j=1\\\\&\\lambda_j\\geq0,j=1,\\cdots,k\\end{cases}\n$$</div>\n\n<p>此时只需要找到 <div style=\"display: inline;\">$p &#x3D; \\arg\\min_{j}cx^{(j)}$</div>，取 <div style=\"display: inline;\">$\\lambda_p &#x3D; 1$</div>, <div style=\"display: inline;\">$\\lambda_j &#x3D; 0 (j\\ne p)$</div> 即可得到最大值。</p>\n<p>定理2．设线性规划(L)的可行域非空，则</p>\n<p>（1）(L)存在最优解的充要条件是对任意的<div style=\"display: inline;\">$j$</div>, <div style=\"display: inline;\">$cd^{(j)}≥0$</div>, 其中<div style=\"display: inline;\">$d^{(j)}$</div>为可行域的极方向。</p>\n<p>（2）若(L)存在最优解，则目标函数的最优值可在某个极点达到。</p>\n<h4 id=\"基和基本解\"><a href=\"#基和基本解\" class=\"headerlink\" title=\"基和基本解\"></a>基和基本解</h4><p>设标准形式中 <div style=\"display: inline;\">$\\text{rank}(A_{m\\times n}) &#x3D; m &#x3D; (P_1\\ P_2\\ \\dots\\ P_n)$</div>，<div style=\"display: inline;\">$Ax &#x3D; P_1x_1+\\dots+P_nx_n$</div>，则可以从 <div style=\"display: inline;\">$A$</div> 的列中取出 <div style=\"display: inline;\">$m$</div> 个 <div style=\"display: inline;\">$P_j$</div>组合成一个可逆矩阵 <div style=\"display: inline;\">$B$</div> 称为基，与取出来的 <div style=\"display: inline;\">$P_j$</div> 对应的 <div style=\"display: inline;\">$x_j$</div> 称为基向量。</p>\n<p>设 <div style=\"display: inline;\">$A &#x3D; [B\\ N]$</div>，<div style=\"display: inline;\">$Ax &#x3D; Bx_b + Nx_N &#x3D; b$</div>，解得</p>\n<div>$$\nx_B = B^{-1}b - B^{-1}Nx_N\n$$</div>\n\n<p>取 <div style=\"display: inline;\">$x_N &#x3D; 0$</div>，此时 <div style=\"display: inline;\">$x &#x3D; \\begin{bmatrix}B^{-1}b\\0\\end{bmatrix}$</div> 为 (LP) 的基本解。</p>\n<p>若 <div style=\"display: inline;\">$B^{-1}b \\ge 0$</div>，则 <div style=\"display: inline;\">$x$</div> 称为基本可行解，<div style=\"display: inline;\">$B$</div> 为可行基矩阵，<div style=\"display: inline;\">$x_{B_1}, x_{B_2}, \\dots, x_{B_m}$</div> 为一组可行基。</p>\n<p>若 <div style=\"display: inline;\">$B^{-1}b \\gt 0$</div>，则称基本可行解是非退化的，否则是退化的。</p>\n<p><strong>基本可行解与极点之间的关系</strong></p>\n<p>引理1：对于可行解 <div style=\"display: inline;\">$\\bar x$</div>， <div style=\"display: inline;\">$\\bar x$</div> 是基本可行解的充要条件是 <div style=\"display: inline;\">$\\bar x$</div> 的非零分量对应到 <div style=\"display: inline;\">$A$</div> 中的列向量线性无关。</p>\n<p>定理2：设 <div style=\"display: inline;\">$S$</div> 是 <div style=\"display: inline;\">$(L)$</div> 的可行域，<div style=\"display: inline;\">$\\bar x \\in S$</div>，则 <div style=\"display: inline;\">$\\bar x$</div> 是 <div style=\"display: inline;\">$S$</div> 极点的充要条件为 <div style=\"display: inline;\">$\\bar x$</div> 是 <div style=\"display: inline;\">$(L)$</div> 的基本可行解。</p>\n<blockquote>\n<p>思考：本质上是因为“极点”的唯一性，正好对应了基矩阵可逆，求解出来的基本可行解也是唯一的。</p>\n</blockquote>\n<blockquote>\n<p>从几何意义思考标准形式：1. <div style=\"display: inline;\">$Ax&#x3D;b$</div> 本质上代表了一个 k 维的子空间，k 是矩阵的秩，如果 k &#x3D; 1 就是直线，k &#x3D; 2 就是平面；2. <div style=\"display: inline;\">$x\\ge0$</div> 是一组边界，它会截取子空间的一部分，以 k &#x3D; 2，n &#x3D; 3 为例，这意味着我们用一个平面去与三维空间的第一卦限相交的部分作为可行域，不考虑退化的情况，通常它是一个 n 条边界的图形，正好对应 n 个变量分别等于 0 的情况。3. <div style=\"display: inline;\">$cx$</div> 不用解释了，这就是一个 n - 1 维的空间。</p>\n</blockquote>\n<p>定理3：设 <div style=\"display: inline;\">$S &#x3D; {x| Ax&#x3D;b, x\\ge 0}$</div> 的方向 <div style=\"display: inline;\">$d$</div> 有 <div style=\"display: inline;\">$k$</div> 个非零分量，则 <div style=\"display: inline;\">$d$</div> 是 <div style=\"display: inline;\">$S$</div> 的极方向 等价于 <div style=\"display: inline;\">$d$</div> 的非零分量对应到 A 的列向量的秩为 k - 1。</p>\n<p><strong>基本可行解的存在问题</strong></p>\n<p>定理1．如果(LP)有可行解,则一定存在基本可行解.</p>\n<p>定理2．如果(LP)有最优解，则存在一个基本可行解是最优解。</p>\n<h3 id=\"单纯形法\"><a href=\"#单纯形法\" class=\"headerlink\" title=\"单纯形法\"></a>单纯形法</h3><p>设 <div style=\"display: inline;\">$A &#x3D; (B\\ N)$</div></p>\n<div>$$\nx\n$$</div>"},{"title":"泛函分析","katex":true,"date":"2025-09-16T07:21:26.000Z","_content":"## 度量空间\n度量空间必须满足四个性质：(1) 非负性；(2) 非退化性；(3) 对称性；(4) 三角不等式。\n\n$C[a, b]$ 上的 $d_p$ 度量不够好，有的时候不收敛；而 $d_\\infty$ 度量比较好用。\n\n离散度量：\n\n$$\nd(x, y) = \\begin{cases}\n0, x=y\\\\\n1, x\\ne y\n\\end{cases}\n$$\n\np 阶可和：  \n\n$$\n\\sum_{i=1}^\\infty|x_n|^p \\lt \\infty\n$$\n\n### 开集和闭集\n\n设 $(X, d)$ 为度量空间，令\n\n\n$$\nB(x_0,r)=\\lbrace x\\in X{:}d(x_0,x) < r\\rbrace \\\\\n\\bar{B}(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)\\leqslant r\\rbrace \\\\\nS(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)=r\\rbrace\n$$\n\n\n称 $B$, $\\bar{B}$, $S$ 分别为开球、闭球、球面。\n\n对于 $M \\subset X$, $x_0 \\in M$，如果存在 $r > 0$ 使得 $B(x_0, r)\\subset M$，则 $x_0$ 为 $M$ 的内点，$M$ 的所有内点称为“内部”，记为 $M\\degree$。如果 $M = M\\degree$，则称 $M$ 为开集。若 $F^c = X\\setminus F$ 为开集，则 $F$ 称为闭集。\n\n$M\\degree$ 是 M 内的最大开集。\n\n开集的基本性质：\n\n(1) $X$，空集都是开集。（X 本身可以是闭区间、半开半闭区间，这都无所谓，因为我们是在度量空间 (X, d) 上定义的开和闭）\n\n(2) 任意多个开集的并集仍然是开集。\n\n(3) 有限个开集的交集仍然是开集。（无限多个开集的交集未必是开集，$X=\\R$，$G_n=(\\frac1n, +\\infty)$，则 $\\cap_{n=1}^\\infty G_n = [0, \\infty]$ 不是开集，因为 0 不是它的内点。）\n\n基于上述的三条性质还可以定义拓扑空间的概念，度量空间属于一种特殊的拓扑空间。\n\n离散度量空间中，所有的集合都是开集，并且所有的集合也都是闭集。\n\n闭集的基本性质：\n\n(1) $X$，空集都是闭集。\n\n(2) 任意多个闭集的交集仍然是闭集。\n\n(3) 有限个闭集的并集仍然是闭集。\n\n闭集可以定义聚点，导集 $M^\\prime$，闭包 $\\bar{M}$ 的概念。如果某个集合 $M$ 满足 $M=\\bar{M}$，则可以断定 $M$ 为闭集。同时，闭包是包含 M 的最小闭集。（这概念的定义是否与内点、内部的概念对偶？一个是并，一个是交。相交非空，取反就是集合的包含关系。）\n\n连续映射：\n设两个度量空间 $(X_1, d_1)$，$(X_2, d_2)$，映射 T 满足对任意 $\\varepsilon > 0$，存在 $\\delta > 0$，当 $d(x_1, x_2) < \\varepsilon$\n\n\n反直觉的事情：离散度量空间 $(X_1, d_1)$ 的映射总是连续映射。\n\n连续映射可以用逆像的开集刻画：连续映射的充要条件是任意开集的逆像为开集。类似的，闭集的逆像为闭集同样可以刻画映射的连续性。\n\n稠密子集：如果 $M\\sub X$ 且 $\\bar M = X$，称 $M$ 为 $X$ 的稠密子集。如果 $X$ 有 至多可数的稠密子集，称 $X$ 为可分度量空间。（我一直理解错了，认为是“至多可数个”稠密子集，实际上是“存在一个稠密子集，它是至多可数的”。\n\n$M \\sub X$ 可以推出 $\\bar M \\sub X$（奇怪，X 是整个空间，我们讨论的任意集合都应该被包含于 $X$，不需要任何条件才对），因此稠密实际上是说 $X \\sub \\bar M$，也就是给定任意 $x\\in X, r>0$，一定存在 $m\\in M$ 使得 $d(x,m) < r$。稠密本质上就是说 X 中任意元素可以用 M 的元素任意逼近。另外，$K^n$ 是可分的。\n\n### 可数\n\n关于映射的性质：\n\n1. 单射的复合是单射；\n2. 满射和满射的复合是满射；\n3. 双射的复合是双射。\n\n逆映射：\n\n$$\nT T^{-1} = I_Y\\\\\nT^{-1}T = I_X\n$$\n\n如何比较两个集合的大小？\n\n有限集：直接计算个数即可；\n\n无穷集：如果存在 $A\\to B$ 的双射，则 $A, B$ 为等势。记为 $A\\sim B$。等势关系具有反身性，对称性，传递性。\n\n可数集：如 $A \\sim \\N = \\lbrace1,2, 3,\\dots\\rbrace$，称 $A$ 为可数集。\n\n可以证明：如果我能够把集合的所有元素列出来：$A = \\lbrace a_1, a_2, \\dots, a_n, \\dots\\rbrace$，元素两两不等，那么 $A$ 就是一个可数集。\n\n有理数是可数的，这个好证。另外，代数数也是可数的。\n\n至多可数：如果一个集合为有限集或者可数集，则称之为至多可数。\n\n一个可数集的子集是至多可数的。\n\n至多可数个可数集的并集为可数集。（证明：对角线遍历即可）由此可以推出，有限个可数集的笛卡尔积还是可数集。因此 $\\mathbb Q^n$ 是可数集。\n\n$(0,1)$ 不是可数集。$\\R \\setminus \\mathbb Q$ 是可数集, $(a, b) \\cap \\mathbb Q$ 是可数集。\n\n$(0,1)\\sim(a, b)\\sim\\R$\n\n可数个可数集的笛卡尔积不一定是可数集。例子：无限长的二进制序列$\\lbrace0,1\\rbrace^\\N = \\lbrace0,1\\rbrace \\times \\lbrace0,1\\rbrace \\times ...$ 不是可数集。\n\n$\\mathcal P_n$ 为次数≤ n 的整系数多项式集合。代数数集合$\\mathcal A = \\lbrace P_1的根, P_2的根, ...\\rbrace$ 是可数的。\n\n### 可分度量\n\n回到稠密和可分度量空间的讨论来。\n\n$({\\mathcal l}^p, d_p)$ 为可分空间。例如，$\\mathbb K = \\R$ 的情况下， $M=\\lbrace(x_n)_{n\\ge1}, x_n\\in\\mathbb Q, \\exist N, \\forall n \\gt N,x_n=0\\rbrace \\subset l^p$ 是一个稠密子集。首先可以证明 $\\bar M = l^p$。接下来，对 M “分层”：$M=\\bigcup_{n=1}^{\\infty}\\lbrace(x_n)_{n\\ge1}| x_n\\in \\mathbb Q, \\forall n\\ge m, x_n=0\\rbrace$，可数个可数集的并集还是可数集，因此 $M$ 是可数的，$l^p$ 是可分度量空间。\n\n\n但是，$(l^\\infty, d_\\infty)$ 不是可分度量空间。我们可以构造 $M=\\lbrace \\lbrace x_n\\rbrace \\in\\ell^\\infty:x_n=0,\\text{或者 }x_n=1\\rbrace  \\sim \\lbrace0, 1\\rbrace^\\N$，对任意稠密子集 $N$，利用稠密性可以构造一个从 $M\\to N$ 的单射（$m_1\\ne m_2\\Rightarrow n_1\\ne n_2$），$M$ 是不可数的，从而 $M$ 的像集也是不可数的，而 $M$ 的像集是 $N$ 的子集，一个可数集的子集怎么可能是不可数的呢？所以 $N$ 一定是不可数的。\n\n可以证明 $\\bar {\\mathbb Q^n} = \\R^n$，$\\overline{\\mathbb Q^n + i\\mathbb Q^n} = \\mathbb C^n$，因此 $K^n$ 是可分的。\n\n对于离散度量空间，$X$ 为至多可数集是 $(X, d)$ 可分的充要条件。因为离散度量空间中任何子集都是闭集，因此 $M = \\bar M$，稠密又必须有 $\\bar M = X$，因此只能是 $M = X$ 成立，$M$ 至多可数等价于 $X$ 至多可数。\n\n$C[a, b]$ 也是可分度量空间。实际上整系数多项式集合 $\\mathcal P$ 满足 $\\bar{\\mathcal P} = C[a, b]$。对于 $d_\\infty$ 度量，可以用 stone-weirstrass 定理直接证明，而对于 $d_p$ 度量，$d_p(x, y) \\le (b-a)^{1/p}d_\\infty(x, y)$，自然也可证明。\n\n### 收敛性，完备性及紧性\n\n若存在 $x\\in X$ 使得\n\n\n$$\n\\underset{n\\to\\infty}{\\operatorname*{\\operatorname*{\\lim}}}d(x_n,x)=0,\n$$\n\n则称 ${x_n}$ 在 $X$ 中收敛。记为 $\\lim_{n\\to\\infty}x_{n}=x$，或者$x_n\\to x$。\n\n如果非空子集 $M$ 被包含在 $X$ 的某个开球内，称 $M$ 为有界集。实际上，$M$ 有界等价于 $\\forall x \\in X，\\exists r > 0，M\\subset B(x, r)$。\n\n定理：$x_n\\to x$，则\n\n（1）${x_n: n\\ge1}$ 为有界集。\n\n（2）$x$ 唯一。\n\n利用序列的收敛性，我们可以更方便地证明一个集合为闭集了。\n\n定理：对于 $M\\subset X$\n\n(1) $x\\in \\bar M$ 当且仅当存在 $M$ 的序列 $x_n$，满足 $x_n\\to x$；\n\n(2) $M$ 为闭集 当且仅当 对任意收敛到 $x$ 的 $M$ 中序列 $x_n$，有 $x\\in M$。\n\n(1) 证明：若 $x\\in M$，则必然存在 $x_n \\in B(x, \\frac1n)\\cap \\bar M$，因此 $0\\le d(x, x_n) \\le \\frac1n$，取极限即可；\n\n若从右边证明左边，对任意 $\\delta \\gt 0$，存在 $n \\gt N$ 使得 $d(x, x_n) \\lt \\delta$，因此，$x_n \\in B(x, \\delta)$，又因为 $x_n\\in M$，因此$B(x, \\delta)\\cap M \\ne \\empty$，从而 $x \\in \\bar M$。\n\n(2) 证明：从左到右：由于 $x_n\\to x$，根据 (1) 从右推左，得到 $x\\in \\bar M = M$；\n\n从右到左：首先 $M \\subset M\\cup M^\\prime = \\bar M$ 显然成立。接下来，对任意 $x\\in \\bar M$，根据 (1) 左推右，存在 M 中序列 $x_n$ 使得 $x_n\\to x\\in \\bar M$，又根据条件可以推出 $x\\in M$，因此 $\\forall x\\in \\bar M \\Rightarrow x\\in M$，从而得知 $\\bar M \\subset M$。综合得到 $\\bar M = M$，即 $M$ 为闭集。\n\n> 这里最迷惑的地方是 (2) 的“对任意收敛到 $x$ 的 $M$ 中序列 $x_n$”，我们知道任意可以推存在而存在不能推任意。但是 (2) 的从左到右证明是证明任意性成立，过程用到了 (1) ，而(1) 是一个存在性的定理，存在怎么推任意呢，似乎出现了逻辑问题。（我有点难以表达这段话的意思，总之就是在这里的理解出现了差错。）实际上并不矛盾，因为他们的“任意”和“存在”描述的并不是同一个对象！实际上我们完全可以把 (1) 的充分性定理写成：“对任意$M$中序列 $x_n$，如果 $x_n$ 收敛到 $x$，则 $x\\in \\bar M$”，所谓的存在性本质上也是任意性罢了，当然这样写的话必要性定理就不好表达，所以书上没有采用这种写法。","source":"_posts/泛函分析.md","raw":"---\ntitle: 泛函分析\nkatex: true\ndate: 2025-09-16 15:21:26\ntags:\n---\n## 度量空间\n度量空间必须满足四个性质：(1) 非负性；(2) 非退化性；(3) 对称性；(4) 三角不等式。\n\n$C[a, b]$ 上的 $d_p$ 度量不够好，有的时候不收敛；而 $d_\\infty$ 度量比较好用。\n\n离散度量：\n\n$$\nd(x, y) = \\begin{cases}\n0, x=y\\\\\n1, x\\ne y\n\\end{cases}\n$$\n\np 阶可和：  \n\n$$\n\\sum_{i=1}^\\infty|x_n|^p \\lt \\infty\n$$\n\n### 开集和闭集\n\n设 $(X, d)$ 为度量空间，令\n\n\n$$\nB(x_0,r)=\\lbrace x\\in X{:}d(x_0,x) < r\\rbrace \\\\\n\\bar{B}(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)\\leqslant r\\rbrace \\\\\nS(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)=r\\rbrace\n$$\n\n\n称 $B$, $\\bar{B}$, $S$ 分别为开球、闭球、球面。\n\n对于 $M \\subset X$, $x_0 \\in M$，如果存在 $r > 0$ 使得 $B(x_0, r)\\subset M$，则 $x_0$ 为 $M$ 的内点，$M$ 的所有内点称为“内部”，记为 $M\\degree$。如果 $M = M\\degree$，则称 $M$ 为开集。若 $F^c = X\\setminus F$ 为开集，则 $F$ 称为闭集。\n\n$M\\degree$ 是 M 内的最大开集。\n\n开集的基本性质：\n\n(1) $X$，空集都是开集。（X 本身可以是闭区间、半开半闭区间，这都无所谓，因为我们是在度量空间 (X, d) 上定义的开和闭）\n\n(2) 任意多个开集的并集仍然是开集。\n\n(3) 有限个开集的交集仍然是开集。（无限多个开集的交集未必是开集，$X=\\R$，$G_n=(\\frac1n, +\\infty)$，则 $\\cap_{n=1}^\\infty G_n = [0, \\infty]$ 不是开集，因为 0 不是它的内点。）\n\n基于上述的三条性质还可以定义拓扑空间的概念，度量空间属于一种特殊的拓扑空间。\n\n离散度量空间中，所有的集合都是开集，并且所有的集合也都是闭集。\n\n闭集的基本性质：\n\n(1) $X$，空集都是闭集。\n\n(2) 任意多个闭集的交集仍然是闭集。\n\n(3) 有限个闭集的并集仍然是闭集。\n\n闭集可以定义聚点，导集 $M^\\prime$，闭包 $\\bar{M}$ 的概念。如果某个集合 $M$ 满足 $M=\\bar{M}$，则可以断定 $M$ 为闭集。同时，闭包是包含 M 的最小闭集。（这概念的定义是否与内点、内部的概念对偶？一个是并，一个是交。相交非空，取反就是集合的包含关系。）\n\n连续映射：\n设两个度量空间 $(X_1, d_1)$，$(X_2, d_2)$，映射 T 满足对任意 $\\varepsilon > 0$，存在 $\\delta > 0$，当 $d(x_1, x_2) < \\varepsilon$\n\n\n反直觉的事情：离散度量空间 $(X_1, d_1)$ 的映射总是连续映射。\n\n连续映射可以用逆像的开集刻画：连续映射的充要条件是任意开集的逆像为开集。类似的，闭集的逆像为闭集同样可以刻画映射的连续性。\n\n稠密子集：如果 $M\\sub X$ 且 $\\bar M = X$，称 $M$ 为 $X$ 的稠密子集。如果 $X$ 有 至多可数的稠密子集，称 $X$ 为可分度量空间。（我一直理解错了，认为是“至多可数个”稠密子集，实际上是“存在一个稠密子集，它是至多可数的”。\n\n$M \\sub X$ 可以推出 $\\bar M \\sub X$（奇怪，X 是整个空间，我们讨论的任意集合都应该被包含于 $X$，不需要任何条件才对），因此稠密实际上是说 $X \\sub \\bar M$，也就是给定任意 $x\\in X, r>0$，一定存在 $m\\in M$ 使得 $d(x,m) < r$。稠密本质上就是说 X 中任意元素可以用 M 的元素任意逼近。另外，$K^n$ 是可分的。\n\n### 可数\n\n关于映射的性质：\n\n1. 单射的复合是单射；\n2. 满射和满射的复合是满射；\n3. 双射的复合是双射。\n\n逆映射：\n\n$$\nT T^{-1} = I_Y\\\\\nT^{-1}T = I_X\n$$\n\n如何比较两个集合的大小？\n\n有限集：直接计算个数即可；\n\n无穷集：如果存在 $A\\to B$ 的双射，则 $A, B$ 为等势。记为 $A\\sim B$。等势关系具有反身性，对称性，传递性。\n\n可数集：如 $A \\sim \\N = \\lbrace1,2, 3,\\dots\\rbrace$，称 $A$ 为可数集。\n\n可以证明：如果我能够把集合的所有元素列出来：$A = \\lbrace a_1, a_2, \\dots, a_n, \\dots\\rbrace$，元素两两不等，那么 $A$ 就是一个可数集。\n\n有理数是可数的，这个好证。另外，代数数也是可数的。\n\n至多可数：如果一个集合为有限集或者可数集，则称之为至多可数。\n\n一个可数集的子集是至多可数的。\n\n至多可数个可数集的并集为可数集。（证明：对角线遍历即可）由此可以推出，有限个可数集的笛卡尔积还是可数集。因此 $\\mathbb Q^n$ 是可数集。\n\n$(0,1)$ 不是可数集。$\\R \\setminus \\mathbb Q$ 是可数集, $(a, b) \\cap \\mathbb Q$ 是可数集。\n\n$(0,1)\\sim(a, b)\\sim\\R$\n\n可数个可数集的笛卡尔积不一定是可数集。例子：无限长的二进制序列$\\lbrace0,1\\rbrace^\\N = \\lbrace0,1\\rbrace \\times \\lbrace0,1\\rbrace \\times ...$ 不是可数集。\n\n$\\mathcal P_n$ 为次数≤ n 的整系数多项式集合。代数数集合$\\mathcal A = \\lbrace P_1的根, P_2的根, ...\\rbrace$ 是可数的。\n\n### 可分度量\n\n回到稠密和可分度量空间的讨论来。\n\n$({\\mathcal l}^p, d_p)$ 为可分空间。例如，$\\mathbb K = \\R$ 的情况下， $M=\\lbrace(x_n)_{n\\ge1}, x_n\\in\\mathbb Q, \\exist N, \\forall n \\gt N,x_n=0\\rbrace \\subset l^p$ 是一个稠密子集。首先可以证明 $\\bar M = l^p$。接下来，对 M “分层”：$M=\\bigcup_{n=1}^{\\infty}\\lbrace(x_n)_{n\\ge1}| x_n\\in \\mathbb Q, \\forall n\\ge m, x_n=0\\rbrace$，可数个可数集的并集还是可数集，因此 $M$ 是可数的，$l^p$ 是可分度量空间。\n\n\n但是，$(l^\\infty, d_\\infty)$ 不是可分度量空间。我们可以构造 $M=\\lbrace \\lbrace x_n\\rbrace \\in\\ell^\\infty:x_n=0,\\text{或者 }x_n=1\\rbrace  \\sim \\lbrace0, 1\\rbrace^\\N$，对任意稠密子集 $N$，利用稠密性可以构造一个从 $M\\to N$ 的单射（$m_1\\ne m_2\\Rightarrow n_1\\ne n_2$），$M$ 是不可数的，从而 $M$ 的像集也是不可数的，而 $M$ 的像集是 $N$ 的子集，一个可数集的子集怎么可能是不可数的呢？所以 $N$ 一定是不可数的。\n\n可以证明 $\\bar {\\mathbb Q^n} = \\R^n$，$\\overline{\\mathbb Q^n + i\\mathbb Q^n} = \\mathbb C^n$，因此 $K^n$ 是可分的。\n\n对于离散度量空间，$X$ 为至多可数集是 $(X, d)$ 可分的充要条件。因为离散度量空间中任何子集都是闭集，因此 $M = \\bar M$，稠密又必须有 $\\bar M = X$，因此只能是 $M = X$ 成立，$M$ 至多可数等价于 $X$ 至多可数。\n\n$C[a, b]$ 也是可分度量空间。实际上整系数多项式集合 $\\mathcal P$ 满足 $\\bar{\\mathcal P} = C[a, b]$。对于 $d_\\infty$ 度量，可以用 stone-weirstrass 定理直接证明，而对于 $d_p$ 度量，$d_p(x, y) \\le (b-a)^{1/p}d_\\infty(x, y)$，自然也可证明。\n\n### 收敛性，完备性及紧性\n\n若存在 $x\\in X$ 使得\n\n\n$$\n\\underset{n\\to\\infty}{\\operatorname*{\\operatorname*{\\lim}}}d(x_n,x)=0,\n$$\n\n则称 ${x_n}$ 在 $X$ 中收敛。记为 $\\lim_{n\\to\\infty}x_{n}=x$，或者$x_n\\to x$。\n\n如果非空子集 $M$ 被包含在 $X$ 的某个开球内，称 $M$ 为有界集。实际上，$M$ 有界等价于 $\\forall x \\in X，\\exists r > 0，M\\subset B(x, r)$。\n\n定理：$x_n\\to x$，则\n\n（1）${x_n: n\\ge1}$ 为有界集。\n\n（2）$x$ 唯一。\n\n利用序列的收敛性，我们可以更方便地证明一个集合为闭集了。\n\n定理：对于 $M\\subset X$\n\n(1) $x\\in \\bar M$ 当且仅当存在 $M$ 的序列 $x_n$，满足 $x_n\\to x$；\n\n(2) $M$ 为闭集 当且仅当 对任意收敛到 $x$ 的 $M$ 中序列 $x_n$，有 $x\\in M$。\n\n(1) 证明：若 $x\\in M$，则必然存在 $x_n \\in B(x, \\frac1n)\\cap \\bar M$，因此 $0\\le d(x, x_n) \\le \\frac1n$，取极限即可；\n\n若从右边证明左边，对任意 $\\delta \\gt 0$，存在 $n \\gt N$ 使得 $d(x, x_n) \\lt \\delta$，因此，$x_n \\in B(x, \\delta)$，又因为 $x_n\\in M$，因此$B(x, \\delta)\\cap M \\ne \\empty$，从而 $x \\in \\bar M$。\n\n(2) 证明：从左到右：由于 $x_n\\to x$，根据 (1) 从右推左，得到 $x\\in \\bar M = M$；\n\n从右到左：首先 $M \\subset M\\cup M^\\prime = \\bar M$ 显然成立。接下来，对任意 $x\\in \\bar M$，根据 (1) 左推右，存在 M 中序列 $x_n$ 使得 $x_n\\to x\\in \\bar M$，又根据条件可以推出 $x\\in M$，因此 $\\forall x\\in \\bar M \\Rightarrow x\\in M$，从而得知 $\\bar M \\subset M$。综合得到 $\\bar M = M$，即 $M$ 为闭集。\n\n> 这里最迷惑的地方是 (2) 的“对任意收敛到 $x$ 的 $M$ 中序列 $x_n$”，我们知道任意可以推存在而存在不能推任意。但是 (2) 的从左到右证明是证明任意性成立，过程用到了 (1) ，而(1) 是一个存在性的定理，存在怎么推任意呢，似乎出现了逻辑问题。（我有点难以表达这段话的意思，总之就是在这里的理解出现了差错。）实际上并不矛盾，因为他们的“任意”和“存在”描述的并不是同一个对象！实际上我们完全可以把 (1) 的充分性定理写成：“对任意$M$中序列 $x_n$，如果 $x_n$ 收敛到 $x$，则 $x\\in \\bar M$”，所谓的存在性本质上也是任意性罢了，当然这样写的话必要性定理就不好表达，所以书上没有采用这种写法。","slug":"泛函分析","published":1,"updated":"2025-09-26T09:20:43.698Z","_id":"cmg0ehgv40001pgtg13hkg9up","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"度量空间\"><a href=\"#度量空间\" class=\"headerlink\" title=\"度量空间\"></a>度量空间</h2><p>度量空间必须满足四个性质：(1) 非负性；(2) 非退化性；(3) 对称性；(4) 三角不等式。</p>\n<p>$C[a, b]$ 上的 $d_p$ 度量不够好，有的时候不收敛；而 $d_\\infty$ 度量比较好用。</p>\n<p>离散度量：</p>\n<div>$$ \nd(x, y) = \\begin{cases}\n0, x=y\\\\\n1, x\\ne y\n\\end{cases}\n $$</div>\n\n<p>p 阶可和：  </p>\n<div>$$ \n\\sum_{i=1}^\\infty|x_n|^p \\lt \\infty\n $$</div>\n\n<h3 id=\"开集和闭集\"><a href=\"#开集和闭集\" class=\"headerlink\" title=\"开集和闭集\"></a>开集和闭集</h3><p>设 $(X, d)$ 为度量空间，令</p>\n<div>$$ \nB(x_0,r)=\\lbrace x\\in X{:}d(x_0,x) <  r\\rbrace \\\\\n\\bar{B}(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)\\leqslant r\\rbrace \\\\\nS(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)=r\\rbrace\n $$</div>\n\n\n<p>称 $B$, $\\bar{B}$, $S$ 分别为开球、闭球、球面。</p>\n<p>对于 $M \\subset X$, $x_0 \\in M$，如果存在 $r &gt; 0$ 使得 $B(x_0, r)\\subset M$，则 $x_0$ 为 $M$ 的内点，$M$ 的所有内点称为“内部”，记为 $M\\degree$。如果 $M &#x3D; M\\degree$，则称 $M$ 为开集。若 $F^c &#x3D; X\\setminus F$ 为开集，则 $F$ 称为闭集。</p>\n<p>$M\\degree$ 是 M 内的最大开集。</p>\n<p>开集的基本性质：</p>\n<p>(1) $X$，空集都是开集。（X 本身可以是闭区间、半开半闭区间，这都无所谓，因为我们是在度量空间 (X, d) 上定义的开和闭）</p>\n<p>(2) 任意多个开集的并集仍然是开集。</p>\n<p>(3) 有限个开集的交集仍然是开集。（无限多个开集的交集未必是开集，$X&#x3D;\\R$，$G_n&#x3D;(\\frac1n, +\\infty)$，则 $\\cap_{n&#x3D;1}^\\infty G_n &#x3D; [0, \\infty]$ 不是开集，因为 0 不是它的内点。）</p>\n<p>基于上述的三条性质还可以定义拓扑空间的概念，度量空间属于一种特殊的拓扑空间。</p>\n<p>离散度量空间中，所有的集合都是开集，并且所有的集合也都是闭集。</p>\n<p>闭集的基本性质：</p>\n<p>(1) $X$，空集都是闭集。</p>\n<p>(2) 任意多个闭集的交集仍然是闭集。</p>\n<p>(3) 有限个闭集的并集仍然是闭集。</p>\n<p>闭集可以定义聚点，导集 $M^\\prime$，闭包 $\\bar{M}$ 的概念。如果某个集合 $M$ 满足 $M&#x3D;\\bar{M}$，则可以断定 $M$ 为闭集。同时，闭包是包含 M 的最小闭集。（这概念的定义是否与内点、内部的概念对偶？一个是并，一个是交。相交非空，取反就是集合的包含关系。）</p>\n<p>连续映射：<br>设两个度量空间 $(X_1, d_1)$，$(X_2, d_2)$，映射 T 满足对任意 $\\varepsilon &gt; 0$，存在 $\\delta &gt; 0$，当 $d(x_1, x_2) &lt;  \\varepsilon$</p>\n<p>反直觉的事情：离散度量空间 $(X_1, d_1)$ 的映射总是连续映射。</p>\n<p>连续映射可以用逆像的开集刻画：连续映射的充要条件是任意开集的逆像为开集。类似的，闭集的逆像为闭集同样可以刻画映射的连续性。</p>\n<p>稠密子集：如果 $M\\sub X$ 且 $\\bar M &#x3D; X$，称 $M$ 为 $X$ 的稠密子集。如果 $X$ 有 至多可数的稠密子集，称 $X$ 为可分度量空间。（我一直理解错了，认为是“至多可数个”稠密子集，实际上是“存在一个稠密子集，它是至多可数的”。</p>\n<p>$M \\sub X$ 可以推出 $\\bar M \\sub X$（奇怪，X 是整个空间，我们讨论的任意集合都应该被包含于 $X$，不需要任何条件才对），因此稠密实际上是说 $X \\sub \\bar M$，也就是给定任意 $x\\in X, r&gt;0$，一定存在 $m\\in M$ 使得 $d(x,m) &lt;  r$。稠密本质上就是说 X 中任意元素可以用 M 的元素任意逼近。另外，$K^n$ 是可分的。</p>\n<h3 id=\"可数\"><a href=\"#可数\" class=\"headerlink\" title=\"可数\"></a>可数</h3><p>关于映射的性质：</p>\n<ol>\n<li>单射的复合是单射；</li>\n<li>满射和满射的复合是满射；</li>\n<li>双射的复合是双射。</li>\n</ol>\n<p>逆映射：</p>\n<div>$$ \nT T^{-1} = I_Y\\\\\nT^{-1}T = I_X\n $$</div>\n\n<p>如何比较两个集合的大小？</p>\n<p>有限集：直接计算个数即可；</p>\n<p>无穷集：如果存在 $A\\to B$ 的双射，则 $A, B$ 为等势。记为 $A\\sim B$。等势关系具有反身性，对称性，传递性。</p>\n<p>可数集：如 $A \\sim \\N &#x3D; \\lbrace1,2, 3,\\dots\\rbrace$，称 $A$ 为可数集。</p>\n<p>可以证明：如果我能够把集合的所有元素列出来：$A &#x3D; \\lbrace a_1, a_2, \\dots, a_n, \\dots\\rbrace$，元素两两不等，那么 $A$ 就是一个可数集。</p>\n<p>有理数是可数的，这个好证。另外，代数数也是可数的。</p>\n<p>至多可数：如果一个集合为有限集或者可数集，则称之为至多可数。</p>\n<p>一个可数集的子集是至多可数的。</p>\n<p>至多可数个可数集的并集为可数集。（证明：对角线遍历即可）由此可以推出，有限个可数集的笛卡尔积还是可数集。因此 $\\mathbb Q^n$ 是可数集。</p>\n<p>$(0,1)$ 不是可数集。$\\R \\setminus \\mathbb Q$ 是可数集, $(a, b) \\cap \\mathbb Q$ 是可数集。</p>\n<p>$(0,1)\\sim(a, b)\\sim\\R$</p>\n<p>可数个可数集的笛卡尔积不一定是可数集。例子：无限长的二进制序列$\\lbrace0,1\\rbrace^\\N &#x3D; \\lbrace0,1\\rbrace \\times \\lbrace0,1\\rbrace \\times …$ 不是可数集。</p>\n<p>$\\mathcal P_n$ 为次数≤ n 的整系数多项式集合。代数数集合$\\mathcal A &#x3D; \\lbrace P_1的根, P_2的根, …\\rbrace$ 是可数的。</p>\n<h3 id=\"可分度量\"><a href=\"#可分度量\" class=\"headerlink\" title=\"可分度量\"></a>可分度量</h3><p>回到稠密和可分度量空间的讨论来。</p>\n<p>$({\\mathcal l}^p, d_p)$ 为可分空间。例如，$\\mathbb K &#x3D; \\R$ 的情况下， $M&#x3D;\\lbrace(x_n)<em>{n\\ge1}, x_n\\in\\mathbb Q, \\exist N, \\forall n \\gt N,x_n&#x3D;0\\rbrace \\subset l^p$ 是一个稠密子集。首先可以证明 $\\bar M &#x3D; l^p$。接下来，对 M “分层”：$M&#x3D;\\bigcup_{n&#x3D;1}^{\\infty}\\lbrace(x_n)</em>{n\\ge1}| x_n\\in \\mathbb Q, \\forall n\\ge m, x_n&#x3D;0\\rbrace$，可数个可数集的并集还是可数集，因此 $M$ 是可数的，$l^p$ 是可分度量空间。</p>\n<p>但是，$(l^\\infty, d_\\infty)$ 不是可分度量空间。我们可以构造 $M&#x3D;\\lbrace \\lbrace x_n\\rbrace \\in\\ell^\\infty:x_n&#x3D;0,\\text{或者 }x_n&#x3D;1\\rbrace  \\sim \\lbrace0, 1\\rbrace^\\N$，对任意稠密子集 $N$，利用稠密性可以构造一个从 $M\\to N$ 的单射（$m_1\\ne m_2\\Rightarrow n_1\\ne n_2$），$M$ 是不可数的，从而 $M$ 的像集也是不可数的，而 $M$ 的像集是 $N$ 的子集，一个可数集的子集怎么可能是不可数的呢？所以 $N$ 一定是不可数的。</p>\n<p>可以证明 $\\bar {\\mathbb Q^n} &#x3D; \\R^n$，$\\overline{\\mathbb Q^n + i\\mathbb Q^n} &#x3D; \\mathbb C^n$，因此 $K^n$ 是可分的。</p>\n<p>对于离散度量空间，$X$ 为至多可数集是 $(X, d)$ 可分的充要条件。因为离散度量空间中任何子集都是闭集，因此 $M &#x3D; \\bar M$，稠密又必须有 $\\bar M &#x3D; X$，因此只能是 $M &#x3D; X$ 成立，$M$ 至多可数等价于 $X$ 至多可数。</p>\n<p>$C[a, b]$ 也是可分度量空间。实际上整系数多项式集合 $\\mathcal P$ 满足 $\\bar{\\mathcal P} &#x3D; C[a, b]$。对于 $d_\\infty$ 度量，可以用 stone-weirstrass 定理直接证明，而对于 $d_p$ 度量，$d_p(x, y) \\le (b-a)^{1&#x2F;p}d_\\infty(x, y)$，自然也可证明。</p>\n<h3 id=\"收敛性，完备性及紧性\"><a href=\"#收敛性，完备性及紧性\" class=\"headerlink\" title=\"收敛性，完备性及紧性\"></a>收敛性，完备性及紧性</h3><p>若存在 $x\\in X$ 使得</p>\n<div>$$ \n\\underset{n\\to\\infty}{\\operatorname*{\\operatorname*{\\lim}}}d(x_n,x)=0,\n $$</div>\n\n<p>则称 ${x_n}$ 在 $X$ 中收敛。记为 $\\lim_{n\\to\\infty}x_{n}&#x3D;x$，或者$x_n\\to x$。</p>\n<p>如果非空子集 $M$ 被包含在 $X$ 的某个开球内，称 $M$ 为有界集。实际上，$M$ 有界等价于 $\\forall x \\in X，\\exists r &gt; 0，M\\subset B(x, r)$。</p>\n<p>定理：$x_n\\to x$，则</p>\n<p>（1）${x_n: n\\ge1}$ 为有界集。</p>\n<p>（2）$x$ 唯一。</p>\n<p>利用序列的收敛性，我们可以更方便地证明一个集合为闭集了。</p>\n<p>定理：对于 $M\\subset X$</p>\n<p>(1) $x\\in \\bar M$ 当且仅当存在 $M$ 的序列 $x_n$，满足 $x_n\\to x$；</p>\n<p>(2) $M$ 为闭集 当且仅当 对任意收敛到 $x$ 的 $M$ 中序列 $x_n$，有 $x\\in M$。</p>\n<p>(1) 证明：若 $x\\in M$，则必然存在 $x_n \\in B(x, \\frac1n)\\cap \\bar M$，因此 $0\\le d(x, x_n) \\le \\frac1n$，取极限即可；</p>\n<p>若从右边证明左边，对任意 $\\delta \\gt 0$，存在 $n \\gt N$ 使得 $d(x, x_n) \\lt \\delta$，因此，$x_n \\in B(x, \\delta)$，又因为 $x_n\\in M$，因此$B(x, \\delta)\\cap M \\ne \\empty$，从而 $x \\in \\bar M$。</p>\n<p>(2) 证明：从左到右：由于 $x_n\\to x$，根据 (1) 从右推左，得到 $x\\in \\bar M &#x3D; M$；</p>\n<p>从右到左：首先 $M \\subset M\\cup M^\\prime &#x3D; \\bar M$ 显然成立。接下来，对任意 $x\\in \\bar M$，根据 (1) 左推右，存在 M 中序列 $x_n$ 使得 $x_n\\to x\\in \\bar M$，又根据条件可以推出 $x\\in M$，因此 $\\forall x\\in \\bar M \\Rightarrow x\\in M$，从而得知 $\\bar M \\subset M$。综合得到 $\\bar M &#x3D; M$，即 $M$ 为闭集。</p>\n<blockquote>\n<p>这里最迷惑的地方是 (2) 的“对任意收敛到 $x$ 的 $M$ 中序列 $x_n$”，我们知道任意可以推存在而存在不能推任意。但是 (2) 的从左到右证明是证明任意性成立，过程用到了 (1) ，而(1) 是一个存在性的定理，存在怎么推任意呢，似乎出现了逻辑问题。（我有点难以表达这段话的意思，总之就是在这里的理解出现了差错。）实际上并不矛盾，因为他们的“任意”和“存在”描述的并不是同一个对象！实际上我们完全可以把 (1) 的充分性定理写成：“对任意$M$中序列 $x_n$，如果 $x_n$ 收敛到 $x$，则 $x\\in \\bar M$”，所谓的存在性本质上也是任意性罢了，当然这样写的话必要性定理就不好表达，所以书上没有采用这种写法。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"度量空间\"><a href=\"#度量空间\" class=\"headerlink\" title=\"度量空间\"></a>度量空间</h2><p>度量空间必须满足四个性质：(1) 非负性；(2) 非退化性；(3) 对称性；(4) 三角不等式。</p>\n<p>$C[a, b]$ 上的 $d_p$ 度量不够好，有的时候不收敛；而 $d_\\infty$ 度量比较好用。</p>\n<p>离散度量：</p>\n<div>$$ \nd(x, y) = \\begin{cases}\n0, x=y\\\\\n1, x\\ne y\n\\end{cases}\n $$</div>\n\n<p>p 阶可和：  </p>\n<div>$$ \n\\sum_{i=1}^\\infty|x_n|^p \\lt \\infty\n $$</div>\n\n<h3 id=\"开集和闭集\"><a href=\"#开集和闭集\" class=\"headerlink\" title=\"开集和闭集\"></a>开集和闭集</h3><p>设 $(X, d)$ 为度量空间，令</p>\n<div>$$ \nB(x_0,r)=\\lbrace x\\in X{:}d(x_0,x) <  r\\rbrace \\\\\n\\bar{B}(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)\\leqslant r\\rbrace \\\\\nS(x_0,r)=\\lbrace x\\in X{:}d(x_0,x)=r\\rbrace\n $$</div>\n\n\n<p>称 $B$, $\\bar{B}$, $S$ 分别为开球、闭球、球面。</p>\n<p>对于 $M \\subset X$, $x_0 \\in M$，如果存在 $r &gt; 0$ 使得 $B(x_0, r)\\subset M$，则 $x_0$ 为 $M$ 的内点，$M$ 的所有内点称为“内部”，记为 $M\\degree$。如果 $M &#x3D; M\\degree$，则称 $M$ 为开集。若 $F^c &#x3D; X\\setminus F$ 为开集，则 $F$ 称为闭集。</p>\n<p>$M\\degree$ 是 M 内的最大开集。</p>\n<p>开集的基本性质：</p>\n<p>(1) $X$，空集都是开集。（X 本身可以是闭区间、半开半闭区间，这都无所谓，因为我们是在度量空间 (X, d) 上定义的开和闭）</p>\n<p>(2) 任意多个开集的并集仍然是开集。</p>\n<p>(3) 有限个开集的交集仍然是开集。（无限多个开集的交集未必是开集，$X&#x3D;\\R$，$G_n&#x3D;(\\frac1n, +\\infty)$，则 $\\cap_{n&#x3D;1}^\\infty G_n &#x3D; [0, \\infty]$ 不是开集，因为 0 不是它的内点。）</p>\n<p>基于上述的三条性质还可以定义拓扑空间的概念，度量空间属于一种特殊的拓扑空间。</p>\n<p>离散度量空间中，所有的集合都是开集，并且所有的集合也都是闭集。</p>\n<p>闭集的基本性质：</p>\n<p>(1) $X$，空集都是闭集。</p>\n<p>(2) 任意多个闭集的交集仍然是闭集。</p>\n<p>(3) 有限个闭集的并集仍然是闭集。</p>\n<p>闭集可以定义聚点，导集 $M^\\prime$，闭包 $\\bar{M}$ 的概念。如果某个集合 $M$ 满足 $M&#x3D;\\bar{M}$，则可以断定 $M$ 为闭集。同时，闭包是包含 M 的最小闭集。（这概念的定义是否与内点、内部的概念对偶？一个是并，一个是交。相交非空，取反就是集合的包含关系。）</p>\n<p>连续映射：<br>设两个度量空间 $(X_1, d_1)$，$(X_2, d_2)$，映射 T 满足对任意 $\\varepsilon &gt; 0$，存在 $\\delta &gt; 0$，当 $d(x_1, x_2) &lt;  \\varepsilon$</p>\n<p>反直觉的事情：离散度量空间 $(X_1, d_1)$ 的映射总是连续映射。</p>\n<p>连续映射可以用逆像的开集刻画：连续映射的充要条件是任意开集的逆像为开集。类似的，闭集的逆像为闭集同样可以刻画映射的连续性。</p>\n<p>稠密子集：如果 $M\\sub X$ 且 $\\bar M &#x3D; X$，称 $M$ 为 $X$ 的稠密子集。如果 $X$ 有 至多可数的稠密子集，称 $X$ 为可分度量空间。（我一直理解错了，认为是“至多可数个”稠密子集，实际上是“存在一个稠密子集，它是至多可数的”。</p>\n<p>$M \\sub X$ 可以推出 $\\bar M \\sub X$（奇怪，X 是整个空间，我们讨论的任意集合都应该被包含于 $X$，不需要任何条件才对），因此稠密实际上是说 $X \\sub \\bar M$，也就是给定任意 $x\\in X, r&gt;0$，一定存在 $m\\in M$ 使得 $d(x,m) &lt;  r$。稠密本质上就是说 X 中任意元素可以用 M 的元素任意逼近。另外，$K^n$ 是可分的。</p>\n<h3 id=\"可数\"><a href=\"#可数\" class=\"headerlink\" title=\"可数\"></a>可数</h3><p>关于映射的性质：</p>\n<ol>\n<li>单射的复合是单射；</li>\n<li>满射和满射的复合是满射；</li>\n<li>双射的复合是双射。</li>\n</ol>\n<p>逆映射：</p>\n<div>$$ \nT T^{-1} = I_Y\\\\\nT^{-1}T = I_X\n $$</div>\n\n<p>如何比较两个集合的大小？</p>\n<p>有限集：直接计算个数即可；</p>\n<p>无穷集：如果存在 $A\\to B$ 的双射，则 $A, B$ 为等势。记为 $A\\sim B$。等势关系具有反身性，对称性，传递性。</p>\n<p>可数集：如 $A \\sim \\N &#x3D; \\lbrace1,2, 3,\\dots\\rbrace$，称 $A$ 为可数集。</p>\n<p>可以证明：如果我能够把集合的所有元素列出来：$A &#x3D; \\lbrace a_1, a_2, \\dots, a_n, \\dots\\rbrace$，元素两两不等，那么 $A$ 就是一个可数集。</p>\n<p>有理数是可数的，这个好证。另外，代数数也是可数的。</p>\n<p>至多可数：如果一个集合为有限集或者可数集，则称之为至多可数。</p>\n<p>一个可数集的子集是至多可数的。</p>\n<p>至多可数个可数集的并集为可数集。（证明：对角线遍历即可）由此可以推出，有限个可数集的笛卡尔积还是可数集。因此 $\\mathbb Q^n$ 是可数集。</p>\n<p>$(0,1)$ 不是可数集。$\\R \\setminus \\mathbb Q$ 是可数集, $(a, b) \\cap \\mathbb Q$ 是可数集。</p>\n<p>$(0,1)\\sim(a, b)\\sim\\R$</p>\n<p>可数个可数集的笛卡尔积不一定是可数集。例子：无限长的二进制序列$\\lbrace0,1\\rbrace^\\N &#x3D; \\lbrace0,1\\rbrace \\times \\lbrace0,1\\rbrace \\times …$ 不是可数集。</p>\n<p>$\\mathcal P_n$ 为次数≤ n 的整系数多项式集合。代数数集合$\\mathcal A &#x3D; \\lbrace P_1的根, P_2的根, …\\rbrace$ 是可数的。</p>\n<h3 id=\"可分度量\"><a href=\"#可分度量\" class=\"headerlink\" title=\"可分度量\"></a>可分度量</h3><p>回到稠密和可分度量空间的讨论来。</p>\n<p>$({\\mathcal l}^p, d_p)$ 为可分空间。例如，$\\mathbb K &#x3D; \\R$ 的情况下， $M&#x3D;\\lbrace(x_n)<em>{n\\ge1}, x_n\\in\\mathbb Q, \\exist N, \\forall n \\gt N,x_n&#x3D;0\\rbrace \\subset l^p$ 是一个稠密子集。首先可以证明 $\\bar M &#x3D; l^p$。接下来，对 M “分层”：$M&#x3D;\\bigcup_{n&#x3D;1}^{\\infty}\\lbrace(x_n)</em>{n\\ge1}| x_n\\in \\mathbb Q, \\forall n\\ge m, x_n&#x3D;0\\rbrace$，可数个可数集的并集还是可数集，因此 $M$ 是可数的，$l^p$ 是可分度量空间。</p>\n<p>但是，$(l^\\infty, d_\\infty)$ 不是可分度量空间。我们可以构造 $M&#x3D;\\lbrace \\lbrace x_n\\rbrace \\in\\ell^\\infty:x_n&#x3D;0,\\text{或者 }x_n&#x3D;1\\rbrace  \\sim \\lbrace0, 1\\rbrace^\\N$，对任意稠密子集 $N$，利用稠密性可以构造一个从 $M\\to N$ 的单射（$m_1\\ne m_2\\Rightarrow n_1\\ne n_2$），$M$ 是不可数的，从而 $M$ 的像集也是不可数的，而 $M$ 的像集是 $N$ 的子集，一个可数集的子集怎么可能是不可数的呢？所以 $N$ 一定是不可数的。</p>\n<p>可以证明 $\\bar {\\mathbb Q^n} &#x3D; \\R^n$，$\\overline{\\mathbb Q^n + i\\mathbb Q^n} &#x3D; \\mathbb C^n$，因此 $K^n$ 是可分的。</p>\n<p>对于离散度量空间，$X$ 为至多可数集是 $(X, d)$ 可分的充要条件。因为离散度量空间中任何子集都是闭集，因此 $M &#x3D; \\bar M$，稠密又必须有 $\\bar M &#x3D; X$，因此只能是 $M &#x3D; X$ 成立，$M$ 至多可数等价于 $X$ 至多可数。</p>\n<p>$C[a, b]$ 也是可分度量空间。实际上整系数多项式集合 $\\mathcal P$ 满足 $\\bar{\\mathcal P} &#x3D; C[a, b]$。对于 $d_\\infty$ 度量，可以用 stone-weirstrass 定理直接证明，而对于 $d_p$ 度量，$d_p(x, y) \\le (b-a)^{1&#x2F;p}d_\\infty(x, y)$，自然也可证明。</p>\n<h3 id=\"收敛性，完备性及紧性\"><a href=\"#收敛性，完备性及紧性\" class=\"headerlink\" title=\"收敛性，完备性及紧性\"></a>收敛性，完备性及紧性</h3><p>若存在 $x\\in X$ 使得</p>\n<div>$$ \n\\underset{n\\to\\infty}{\\operatorname*{\\operatorname*{\\lim}}}d(x_n,x)=0,\n $$</div>\n\n<p>则称 ${x_n}$ 在 $X$ 中收敛。记为 $\\lim_{n\\to\\infty}x_{n}&#x3D;x$，或者$x_n\\to x$。</p>\n<p>如果非空子集 $M$ 被包含在 $X$ 的某个开球内，称 $M$ 为有界集。实际上，$M$ 有界等价于 $\\forall x \\in X，\\exists r &gt; 0，M\\subset B(x, r)$。</p>\n<p>定理：$x_n\\to x$，则</p>\n<p>（1）${x_n: n\\ge1}$ 为有界集。</p>\n<p>（2）$x$ 唯一。</p>\n<p>利用序列的收敛性，我们可以更方便地证明一个集合为闭集了。</p>\n<p>定理：对于 $M\\subset X$</p>\n<p>(1) $x\\in \\bar M$ 当且仅当存在 $M$ 的序列 $x_n$，满足 $x_n\\to x$；</p>\n<p>(2) $M$ 为闭集 当且仅当 对任意收敛到 $x$ 的 $M$ 中序列 $x_n$，有 $x\\in M$。</p>\n<p>(1) 证明：若 $x\\in M$，则必然存在 $x_n \\in B(x, \\frac1n)\\cap \\bar M$，因此 $0\\le d(x, x_n) \\le \\frac1n$，取极限即可；</p>\n<p>若从右边证明左边，对任意 $\\delta \\gt 0$，存在 $n \\gt N$ 使得 $d(x, x_n) \\lt \\delta$，因此，$x_n \\in B(x, \\delta)$，又因为 $x_n\\in M$，因此$B(x, \\delta)\\cap M \\ne \\empty$，从而 $x \\in \\bar M$。</p>\n<p>(2) 证明：从左到右：由于 $x_n\\to x$，根据 (1) 从右推左，得到 $x\\in \\bar M &#x3D; M$；</p>\n<p>从右到左：首先 $M \\subset M\\cup M^\\prime &#x3D; \\bar M$ 显然成立。接下来，对任意 $x\\in \\bar M$，根据 (1) 左推右，存在 M 中序列 $x_n$ 使得 $x_n\\to x\\in \\bar M$，又根据条件可以推出 $x\\in M$，因此 $\\forall x\\in \\bar M \\Rightarrow x\\in M$，从而得知 $\\bar M \\subset M$。综合得到 $\\bar M &#x3D; M$，即 $M$ 为闭集。</p>\n<blockquote>\n<p>这里最迷惑的地方是 (2) 的“对任意收敛到 $x$ 的 $M$ 中序列 $x_n$”，我们知道任意可以推存在而存在不能推任意。但是 (2) 的从左到右证明是证明任意性成立，过程用到了 (1) ，而(1) 是一个存在性的定理，存在怎么推任意呢，似乎出现了逻辑问题。（我有点难以表达这段话的意思，总之就是在这里的理解出现了差错。）实际上并不矛盾，因为他们的“任意”和“存在”描述的并不是同一个对象！实际上我们完全可以把 (1) 的充分性定理写成：“对任意$M$中序列 $x_n$，如果 $x_n$ 收敛到 $x$，则 $x\\in \\bar M$”，所谓的存在性本质上也是任意性罢了，当然这样写的话必要性定理就不好表达，所以书上没有采用这种写法。</p>\n</blockquote>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"clu1gtfht0007rsug1d0g4rt1","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfhv000arsug99nndb4b"},{"post_id":"clu1gtfhr0003rsug8v0ha8dw","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfhw000crsugdmdg9n98"},{"post_id":"clu1gtfhv000brsug87o2hmyi","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfhx000frsugdhil3eq9"},{"post_id":"clu1gtfhr0004rsug72ka1b2s","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfhx000hrsug7lkx3i4t"},{"post_id":"clu1gtfhx000grsugc4mdblt2","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfhy000jrsug6tnxaijg"},{"post_id":"clu1gtfht0006rsug8hc34xd4","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfhz000lrsug7m0fbmwj"},{"post_id":"clu1gtfhy000krsug67af63bt","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfhz000nrsugdg4h4pyp"},{"post_id":"clu1gtfhz000prsug0s1ggyqq","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfi0000rrsug34zc0zbi"},{"post_id":"clu1gtfi0000trsug4b5s2zgs","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfi1000vrsugg7t8dx4r"},{"post_id":"clu1gtfi1000ursug79zm1v1u","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfi1000xrsug9xm9gptx"},{"post_id":"clu1gtfi1000wrsugbb00a844","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfi2000zrsug6rx582bo"},{"post_id":"clu1gtfi1000yrsugca7h6bkt","tag_id":"clu1gtfhs0005rsugdlx3231q","_id":"clu1gtfi20010rsugbl7mbqhx"},{"post_id":"clysv8fd20000k8ugfm2m25v9","tag_id":"clysv8fd50002k8ugak9zfjwl","_id":"clysv8fdg0007k8ug8wibgcl1"},{"post_id":"clysv8fd20000k8ugfm2m25v9","tag_id":"clysv8fdd0003k8ug2954d2mi","_id":"clysv8fdg0008k8ug1lpvb6qt"},{"post_id":"clysv8fd40001k8ugbhwmbmut","tag_id":"clysv8fd50002k8ugak9zfjwl","_id":"clysv8fdg000bk8ug18bmavwf"},{"post_id":"clysv8fd40001k8ugbhwmbmut","tag_id":"clysv8fdg0009k8ug9ca4e028","_id":"clysv8fdg000ck8ug6ecr6o10"},{"post_id":"clysv8fd40001k8ugbhwmbmut","tag_id":"clysv8fdd0003k8ug2954d2mi","_id":"clysv918k000ek8ug75l33eop"},{"post_id":"clysv8fd40001k8ugbhwmbmut","tag_id":"clysv918i000dk8uge9f6hd99","_id":"clysv918l000fk8ug8lm391gd"},{"post_id":"clysv8fd20000k8ugfm2m25v9","tag_id":"clysv980b000gk8ug8vduayu5","_id":"clysv980g000hk8ugai34g044"},{"post_id":"clysv8fd20000k8ugfm2m25v9","tag_id":"clysv918i000dk8uge9f6hd99","_id":"clysv980g000ik8ug4e4lb9y3"},{"post_id":"cm5kyhfxi00005otg6v3l2ysp","tag_id":"clysv918i000dk8uge9f6hd99","_id":"cm5kyhfy100025otgd0ei3bup"},{"post_id":"cm5kyhfxi00005otg6v3l2ysp","tag_id":"cm5kyhfxl00015otgah939pqp","_id":"cm5kyhfy100035otg0xo1gkys"}],"Tag":[{"name":"note","_id":"clu1gtfhs0005rsugdlx3231q"},{"name":"paper","_id":"clysv8fd50002k8ugak9zfjwl"},{"name":"Mobile","_id":"clysv8fdd0003k8ug2954d2mi"},{"name":"RL+LLM","_id":"clysv8fde0005k8ug3s729mrb"},{"name":"survey","_id":"clysv8fdg0009k8ug9ca4e028"},{"name":"LLM","_id":"clysv918i000dk8uge9f6hd99"},{"name":"RL","_id":"clysv980b000gk8ug8vduayu5"},{"name":"multimodal","_id":"cm5kyhfxl00015otgah939pqp"}]}}